paperId,url,title,abstract,venue,year,externalIds.DOI,database,query_name,query_value
a812368fe1d4a186322bf72a6d07e1cf60067234,https://www.semanticscholar.org/paper/a812368fe1d4a186322bf72a6d07e1cf60067234,Gaussian processes for modeling of facial expressions,"Automated analysis of facial expressions has been gaining significant attention over the past years. This stems from the fact that it constitutes the primal step toward developing some of the next-generation computer technologies that can make an impact in many domains, ranging from medical imaging and health assessment to marketing and education. No matter the target application, the need to deploy systems under demanding, realworld conditions that can generalize well across the population is urgent. Hence, careful consideration of numerous factors has to be taken prior to designing such a system. The work presented in this thesis focuses on tackling two important problems in automated analysis of facial expressions: (i) view-invariant facial expression analysis; (ii) modeling of the structural patterns in the face, in terms of well coordinated facial muscle movements. Driven by the necessity for efficient and accurate inference mechanisms we explore machine learning techniques based on the probabilistic framework of Gaussian processes (GPs). Our ultimate goal is to design powerful models that can efficiently handle imagery with spontaneously displayed facial expressions, and explain in detail the complex configurations behind the human face in real-world situations. To effectively decouple the head pose and expression in the presence of large outof-plane head rotations we introduce a manifold learning approach based on multi-view learning strategies. Contrary to the majority of existing methods that typically treat the numerous poses as individual problems, in this model we first learn a discriminative manifold shared by multiple views of a facial expression. Subsequently, we perform facial expression classification in the expression manifold. Hence, the pose normalization problem is solved by aligning the facial expressions from different poses in a common latent space. We demonstrate that the recovered manifold can efficiently generalize to various poses and expressions even from a small amount of training data, while also being largely robust to corrupted image features due to illumination variations. State-of-the-art performance is achieved in the task of facial expression classification of basic emotions. The methods that we propose for learning the structure in the configuration of the muscle movements represent some of the first attempts in the field of analysis and intensity estimation of facial expressions. In these models, we extend our multi-view approach to exploit relationships not only in the input features but also in the multi-output labels. The structure of the outputs is imposed into the recovered manifold either from heuristically defined hard constraints, or in an auto-encoded manner, where the structure is learned automatically from the input data. The resulting models are proven to be robust to data with imbalanced expression categories, due to our proposed Bayesian learning of the target manifold. We also propose a novel regression approach based on product of GP experts where we take into account people’s individual expressiveness in order to adapt the learned models on each subject. We demonstrate the superior performance of our proposed models on the task of facial expression recognition and intensity estimation.",,2016,10.25560/44106,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
53c9f3c34d8481adaf24df3b25581ccf1bc53f5c,https://www.semanticscholar.org/paper/53c9f3c34d8481adaf24df3b25581ccf1bc53f5c,Physics-Informed Machine Learning,"Traditional lithium-ion (Li-ion) battery state of health (SOH) estimation methodologies that focused on estimating present cell capacity do not provide sufficient information to determine the cell’s lifecycle stage or value in second-life use. Quantifying the underlying degradation modes that cause capacity fade can give further insight into the electrochemical state of the cell and provide more detailed health information such as the remaining active materials and lithium inventory. However, current physics-based methods for degradation diagnostics require long-term cycling data and are computationally expensive to deploy locally on a device. To improve upon current methods, we propose and extensively test two light-weight physics-informed machine learning methods for online estimating the capacity of a battery cell and diagnosing its primary degradation modes using only limited early-life experimental degradation data. To enable late-life prediction (e.g. > 1.5 years) without the use of late-life experimental data, each of the methods is trained using simulation data from a physics-based half-cell model and early-life (e.g. < 3 months) degradation data obtained from cycling tests. The proposed methods are comprehensively evaluated using data from a long-term (3.5 years) cycling experiment of 16 implantable-grade Li-ion cells cycled under two temperatures and C-rates. Results from a four-fold cross-validation study show that the proposed physics-informed machine learning models are capable of improving the estimation accuracy of cell capacity and the state of three primary degradation modes by over 50% compared to a purely data-driven approach. Additionally, this work provides insights into the role of temperature and C-rate in cell degradation. loss in lithiated active material in one of the electrodes (LAM PE/NE,li ) and 10% loss of lithium due to the solid electrolyte interface (SEI) growth (pure LLI), the total loss of lithium inventory quantified by the LII parameter is 20%, and the total LAM PE/NE is 10%. The LAM parameter used throughout this study is used to quantify delithiated LAM, whereas lithiated LAM can be quantified by a linear combination of both LAM and LII. Practically, the increase of LLI results from the accumulation of parasitic reactions in the cell that contribute to lithium inventory loss (e.g., SEI growth, electrolyte decomposition, and delamination of lithiated electrode materials).",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7dde3d8ba6115f0bce116c2f661b76d5d97ddec7,https://www.semanticscholar.org/paper/7dde3d8ba6115f0bce116c2f661b76d5d97ddec7,CLOUD BASED MODEL FOR SHARING PATIENT’S HEALTH INFORMATION ACROSS HOSPITALS & ANALYSIS USING MACHINE LEARNING,"With nationwide efforts to improve the quality, safety and efficiency of medical services, the demand for electronic health information exchange between medical professionals is growing. Medical Facility in our country has grown leaps and bounds in past 3 decades, especially with the availability of private hospitals and efforts of Government. In these past decades the cost of medical facility has also grown 100 times in this duration, every time a patient is referred to a particular hospital, he has to again go on for new test along with medical prescriptions, such actions are repeated for every hospital visit, which involves time and cost both. In this work we are propose a model to deploy Hospital Management ERP over cloud, with storage of all the records of patient including his prescriptions & Lab reports, for any time accessibility of the same. So that can reduce the cost of treatment for the patient and accessibility of the same across all hospitals. We also implement Machine Learning as a tool to analyze the health improvement of the patients, tracking their medical history and also to analyze the performance of hospitals & doctors. By accomplishing this work, we aim at providing a solution to Indian Medical Industry and Government of India, in line with HIPAA act of USA, which reduces cost of Treatment, Ease of access and regulation & monitoring of health care.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
19cdfa05880bcee1bdcd8aa80cc20eb2c74c625c,https://www.semanticscholar.org/paper/19cdfa05880bcee1bdcd8aa80cc20eb2c74c625c,Safeguards for the use of artificial intelligence and machine learning in global health.,"Safeguards for the use of artificial intelligence and machine learning in global health Amy K Paul & Merrick Schaefer a United States Agency for International Development, 1300 Pennsylvania Ave NW, Washington, DC, 20004, United States of America (USA). b 1924 6th St NW, Washington, DC, 20001, USA. Correspondence to Amy K Paul (email: apaul@usaid.gov). (Submitted: 15 May 2019 – Revised version received: 17 September 2019 – Accepted: 18 November 2019 – Published online: 27 January 2020) The potential benefits of artificial intelligence and machine learning are gaining attention in public health as in other fields. With applications spanning clinical decision support to management of supply-chain systems, artificial intelligence-enabled technologies are poised to improve clinical care and strengthen health systems. Given the pace of progress in the application of such tools in advanced economies, we consider several challenges that lowand middle-income countries need to overcome to develop and deploy similar innovations. Health systems will have an important role in shaping the development of artificial intelligence-based tools and realizing their benefits. We argue that lower-resource countries will need to invest in improvements in data quality, improve equity in access to care, establish safeguards to minimize the harmful effects of bias and address supportive linkages within the health system. Without these developments, the benefits of the new technologies may fail to materialize, further exacerbating health disparities within and between highand low-income countries.",Bulletin of the World Health Organization,2020,10.2471/blt.19.237099,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ca06b0887eebd4f48c7fcd361a3e73789d69a899,https://www.semanticscholar.org/paper/ca06b0887eebd4f48c7fcd361a3e73789d69a899,Re-identification of Health Data through Machine Learning,"Startups and large technology companies are working with companies in healthcare to research, create, and deploy machine learning healthcare solutions. The growth of machine learning healthcare solutions is increasing the risk of re-identification of health data, raising concerns for individual privacy. Differential privacy is one of the latest and most popular anonymization techniques used on machine learning data to guarantee data privacy but is presenting challenges when applied to health data. The Health Insurance Portability and Accountability Act (HIPAA) has loopholes and does not address the use of machine learning on health data. This paper will explain why HIPAA needs to be amended to reduce the risk of re-identification due to the growth of machine learning in healthcare and the challenges presented in applying differential privacy. The paper will also discuss three possible proposals to amend HIPAA to reduce the risk of re-identification.",,2020,10.2139/ssrn.3794927,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3c53da3f904e3328111f516468cdd7b67aa67531,https://www.semanticscholar.org/paper/3c53da3f904e3328111f516468cdd7b67aa67531,Predicting CoVID-19 community mortality risk using machine learning and development of an online prognostic tool,"Background The recent pandemic of CoVID-19 has emerged as a threat to global health security. There are very few prognostic models on CoVID-19 using machine learning. Objectives To predict mortality among confirmed CoVID-19 patients in South Korea using machine learning and deploy the best performing algorithm as an open-source online prediction tool for decision-making. Materials and Methods Mortality for confirmed CoVID-19 patients (n = 3,524) between January 20, 2020 and May 30, 2020 was predicted using five machine learning algorithms (logistic regression, support vector machine, K nearest neighbor, random forest and gradient boosting). The performance of the algorithms was compared, and the best performing algorithm was deployed as an online prediction tool. Results The logistic regression algorithm was the best performer in terms of discrimination (area under ROC curve = 0.830), calibration (Matthews Correlation Coefficient = 0.433; Brier Score = 0.036) and. The best performing algorithm (logistic regression) was deployed as the online CoVID-19 Community Mortality Risk Prediction tool named CoCoMoRP (https://ashis-das.shinyapps.io/CoCoMoRP/). Conclusions We describe the development and deployment of an open-source machine learning tool to predict mortality risk among CoVID-19 confirmed patients using publicly available surveillance data. This tool can be utilized by potential stakeholders such as health providers and policymakers to triage patients at the community level in addition to other approaches.",PeerJ,2020,10.7717/peerj.10083,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1a4c2a129e8bef923dd01719f78be4609720f718,https://www.semanticscholar.org/paper/1a4c2a129e8bef923dd01719f78be4609720f718,Quantifying representativeness in randomized clinical trials using machine learning fairness metrics,"Objective We formulate population representativeness of randomized clinical trials (RCTs) as a machine learning (ML) fairness problem, derive new representation metrics, and deploy them in visualization tools which help users identify subpopulations that are underrepresented in RCT cohorts with respect to national, community-based or health system target populations. Materials and Methods We represent RCT cohort enrollment as random binary classification fairness problems, and then show how ML fairness metrics based on enrollment fraction can be efficiently calculated using easily computed rates of subpopulations in RCT cohorts and target populations. We propose standardized versions of these metrics and deploy them in an interactive tool to analyze three RCTs with respect to type-2 diabetes and hypertension target populations in the National Health and Nutrition Examination Survey (NHANES). Results We demonstrate how the proposed metrics and associated statistics enable users to rapidly examine representativeness of all subpopulations in the RCT defined by a set of categorical traits (e.g., sex, race, ethnicity, smoker status, and blood pressure) with respect to target populations. Discussion The normalized metrics provide an intuitive standardized scale for evaluating representation across subgroups, which may have vastly different enrollment fractions and rates in RCT study cohorts. The metrics are beneficial complements to other approaches (e.g., enrollment fractions and GIST) used to identify generalizability and health equity of RCTs. Conclusion By quantifying the gaps between RCT and target populations, the proposed methods can support generalizability evaluation of existing RCT cohorts, enrollment target decisions for new RCTs, and monitoring of RCT recruitment, ultimately contributing to more equitable public health outcomes.",medRxiv,2021,10.1093/jamiaopen/ooab077,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
987c58f7c3f9a8c208f91d72ed2f0db6c14ff9ad,https://www.semanticscholar.org/paper/987c58f7c3f9a8c208f91d72ed2f0db6c14ff9ad,Managing air quality: Predicting exceedances of legal limits for PM10 and O 3 concentration using machine learning methods,"Air pollution imposes great costs on productivity, safety and health of individuals and dictates necessity of a proactive air pollution management. This, in turn, requires powerful tools for air quality modeling. In this article we develop a two‐stage procedure for predicting exceedances of the EU legal limits for PM10 and O 3 concentrations using hourly data. Within the first stage we deploy machine learning methods to produce accurate 24‐h‐ahead forecasts of hourly pollutant concentrations at seven specific locations in the cities of Augsburg and Munich, Germany. The best performance was shown by the Stochastic Gradient Boosting Model—an ensemble tree‐based method, especially convenient because of its computational efficiency and robustness to overfitting. Its predictive ability was largely superior to that reported by similar studies. In the second stage, the hourly forecasts were used to predict the exceedances of the EU daily limits for PM10 and O 3 concentrations. For both pollutants we could achieve the average probability of exceedances detection above 80%, while keeping the probability of false alarms at a reasonably low level. Such satisfactory results show that our approach can be successfully applied to anticipate the shocks, which would allow authorities to manage them in the most effective manner.",Environmetrics,2021,10.1002/env.2707,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
22540193ef0f5c78577b9856a6575c7873dfaa69,https://www.semanticscholar.org/paper/22540193ef0f5c78577b9856a6575c7873dfaa69,A Machine Learning Approach for Heart Attack Prediction,"A heart attack also known as cardiac arrest, diversify various conditions impacting the heart and became one of the chief-reason for death worldwide over the last few decades. Approximately, 31% of total deaths globally are due to CVDs. It constitutes the pinnacle of chronic processes which involve complex interactions between risk factors which can and cannot be improved. Most of the instances or cases of cardiovascular diseases can be allocated to revisable risk factors where most of the instances are considered preventable. ML became the enhancing approach for the evolution of predictive models in health care industries and was decided to test various algorithms to check what extent their prediction scores estimate or ameliorate upon the results acquired. Researchers deploy various machine learning and data mining techniques over a set of enormous data of cardiovascular patients to attain the prediction for heart attacks before their occurrence for helping healthcare industries and professionals. This research comprises various Supervised ML classifiers like, Gradient Boosting, Decision Tree, Random Forest and Logistic Regression that have been used to deploy a model for Myocardial Infarction prediction. It uses the existing datasets from the Framingham database and others from the database of the UCI Heart repository. This research intends to ideate the prediction for probabilities of occurrence of a heart attack in the patients. These classifiers have been deployed in pipeline approach of machine learning to attain the prediction using both ways i.e., without optimizations and feature transformations as well as vice-versa. The results impersonate that the Gradient Boosting classifier is achieving the highest accuracy score in such a way that prediction used by our model is of binary form in where 1 means a chance of heart attack and 0 means no chance. Some of the most influential attributes are chest pain type among which the typical angina is the most influential and asymptotic chest pain is least, cholesterol level in which the level greater than 200mg/dl are more prone, increased heart rate, thal, and age. It is concluded that premature heart attack is preventable in 80% of the total cases just by using a healthy diet along with regular exercises and not using tobacco products also the person who drinks more than 5 glasses of water daily are less likely to develop attacks. The medical checkup of Blood-pressure level, cholesterol level and heart rate on daily basis along with meditation can help you prevent the major heart attacks.",International Journal of Engineering and Advanced Technology,2021,10.35940/ijeat.f3043.0810621,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ffa5e04a55da0cfd151053beeca3d470d26cb35d,https://www.semanticscholar.org/paper/ffa5e04a55da0cfd151053beeca3d470d26cb35d,Problem Formulation Integrating Physics-Based Modelling and Machine Learning for Degradation Diagnostics of Lithium-Ion Batteries,"Traditional lithium-ion (Li-ion) battery state of health (SOH) estimation methodologies that focused on estimating present cell capacity do not provide sufficient information to determine the cell’s lifecycle stage or value in second-life use. Quantifying the underlying degradation modes that cause capacity fade can give further insight into the electrochemical state of the cell and provide more detailed health information such as the remaining active materials and lithium inventory. However, current physics-based methods for degradation diagnostics require long-term cycling data and are computationally expensive to deploy locally on a device. To improve upon current methods, we propose and extensively test two light-weight physics-informed machine learning methods for online estimating the capacity of a battery cell and diagnosing its primary degradation modes using only limited early-life experimental degradation data. To enable late-life prediction (e.g. > 1.5 years) without the use of late-life experimental data, each of the methods is trained using simulation data from a physics-based half-cell model and earlylife (e.g. < 3 months) degradation data obtained from cycling tests. The proposed methods are comprehensively evaluated using data from a long-term (3.5 years) cycling experiment of 16 implantable-grade Li-ion cells cycled under two temperatures and C-rates. Results from a four-fold cross-validation study show that the proposed physics-informed machine learning models are capable of improving the estimation accuracy of cell capacity and the state of three primary degradation modes by over 50% compared to a purely data-driven approach. Additionally, this work provides insights into the role of temperature and C-rate in cell degradation.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64f88eceb9c4755b4b9d9057fa51faf622038f88,https://www.semanticscholar.org/paper/64f88eceb9c4755b4b9d9057fa51faf622038f88,An Intelligent Data-Driven Machine Learning Approach for Fault Detection of Wind Turbines,"Wind farms have received much attention in recent years due to the ever-increasing demand for clean and renewable energy. In order to effectively meet that demand, wind farms' operation and maintenance abilities must be optimized, and therefore, condition-based maintenance plays an important role. Compared with professional condition monitoring systems, supervisory control and data acquisition (SCADA) systems offer an inexpensive technology that enables wind farm operators to monitor wind turbines' health condition. However, the SCADA dataset is often unlabeled, and therefore, how to effectively detect faults without any prior knowledge is a major concern. In order to solve this problem, this paper proposes an innovative method based on machine learning. The proposed method is validated on real operational wind turbine data. The obtained results indicate the effectiveness and impact of the method when applied in realworld application.",2021 6th International Conference on Power and Renewable Energy (ICPRE),2021,10.1109/ICPRE52634.2021.9635340,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d408ac1203e42cd83d48a8842cfac6dbc05d07da,https://www.semanticscholar.org/paper/d408ac1203e42cd83d48a8842cfac6dbc05d07da,Implementing machine learning algorithms for suicide risk prediction in clinical practice: A focus group study,"Background: Interest in developing machine learning algorithms that use electronic health record data to predict patients’ risk of suicidal behavior has recently proliferated. Whether and how such models might be implemented and useful in clinical practice, however, remains unknown. In order to ultimately make automated suicide risk prediction algorithms useful in practice, and thus better prevent patient suicides, it is critical to partner with key stakeholders (including the frontline providers who will be using such tools) at each stage of the implementation process.Objective: The aim of this focus group study was to inform ongoing and future efforts to deploy suicide risk prediction models in clinical practice. The specific goals were to better understand hospital providers’ current practices for assessing and managing suicide risk; determine providers’ perspectives on using automated suicide risk prediction algorithms; and identify barriers, facilitators, recommendations, and factors to consider for initiatives in this area. Methods: We conducted 10 two-hour focus groups with a total of 40 providers from psychiatry, internal medicine and primary care, emergency medicine, and obstetrics and gynecology departments within an urban academic medical center. Audio recordings of open-ended group discussions were transcribed and coded for relevant and recurrent themes by two independent study staff members. All coded text was reviewed and discrepancies resolved in consensus meetings with doctoral-level staff. Results: Though most providers reported using standardized suicide risk assessment tools in their clinical practices, existing tools were commonly described as unhelpful and providers indicated dissatisfaction with current suicide risk assessment methods. Overall, providers’ general attitudes toward the practical use of automated suicide risk prediction models and corresponding clinical decision support tools were positive. Providers were especially interested in the potential to identify high-risk patients who might be missed by traditional screening methods. Some expressed skepticism about the potential usefulness of these models in routine care; specific barriers included concerns about liability, alert fatigue, and increased demand on the healthcare system. Key facilitators included presenting specific patient-level features contributing to risk scores, emphasizing changes in risk over time, and developing systematic clinical workflows and provider trainings. Participants also recommended considering risk-prediction windows, timing of alerts, who will have access to model predictions, and variability across treatment settings.Conclusions: Providers were dissatisfied with current suicide risk assessment methods and open to the use of a machine learning-based risk prediction system to inform clinical decision-making. They also raised multiple concerns about potential barriers to the usefulness of this approach and suggested several possible facilitators. Future efforts in this area will benefit from incorporating systematic qualitative feedback from providers, patients, administrators, and payers on the use of new methods in routine care, especially given the complex, sensitive, and unfortunately still stigmatized nature of suicide risk.",,2021,10.31234/OSF.IO/6M5QD,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
71e6026367a629bea57f00518e4b9ada87011351,https://www.semanticscholar.org/paper/71e6026367a629bea57f00518e4b9ada87011351,Human and machine learning pipelines for responsible clinical prediction using high-dimensional data,"
 This protocol aims to develop, validate, and deploy a prediction model using high dimensional data by both human and machine learning. The applicability is intended for clinical prediction in healthcare providers, including but not limited to those using medical histories from electronic health records. This protocol applies diverse approaches to improve both predictive performance and interpretability while maintaining the generalizability of model evaluation. However, some steps require expensive computational capacity; otherwise, these will take longer time. The key stages consist of designs of data collection and analysis, feature discovery and quality control, and model development, validation, and deployment.",,2021,10.21203/rs.3.pex-1655/v1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c6b8fc20eb2c1aa090138bdc165fcefdcbe38344,https://www.semanticscholar.org/paper/c6b8fc20eb2c1aa090138bdc165fcefdcbe38344,Progress in the Application of Machine Learning Algorithms to Cancer Research and Care.,"Electronic health records (EHRs) are now ubiquitous in US medical care, in part owing to legislation that incentivized their adoption as a component of the 2009 American Recovery and Reinvestment Act.1 These records have been associated with improved medical communication through increased legibility and rapid access to individual patient information. However, the promise of leveraging the rich digital data collected during routine clinical practice for research and to support point-of-care applications is only recently being achieved. This progress is enabled by technology that augments traditional abstraction, software that digitizes and interprets unstructured documents, and computational tools that rapidly analyze large data sets. The report by Yuan and colleagues2 highlights the promise and challenges of applying artificial intelligence tools in the interpretation of real-world data derived from EHRs. This research addresses 2 important goals: construction of realworld data cohorts and predictive modeling. In oncology, a small minority of patients take part in prospective clinical trials of investigational therapies, and those who do tend to be younger, have fewer comorbidities, and be less sociodemographically diverse than the broad population of patients with cancer. Thus, the generalizability of clinical trial results may be questioned. It may be possible to use real-world data from EHRs to explore treatment patterns and associated outcomes among a more representative population. However, many clinical features needed to select a cohort or perform an analysis, including cancer diagnosis, stage, biomarker profile, functional status, treatment, and clinical outcomes, may not be available in structured EHR data with high accuracy or completeness. This has created a need to develop technology-driven approaches for extracting information from unstructured EHR data, such as clinic notes, diagnostic test reports, and other text. Yuan et al2 demonstrate such an approach using natural language processing in the construction of a cohort of patients with lung cancer. The authors used a semisupervised machine learning algorithm called PheCAP that supplements a small set of criterion standard labeled data with a large amount of unlabeled data to identify eligible patients. Yuan et al next extracted additional variables that were not reliably available from structured data. They used rule-based methods for many variables, such as stage, and they used machine learning for smoking status, for which criterion standard labeled data for model training was available. To evaluate their cohort selection and variable extraction, the authors used variable-specific validation measures, including sensitivity, specificity, and completeness, and added a holistic test of performance by comparing results with data that were previously collected for another epidemiologic study. Overall, Yuan and colleagues found that their constructed cohort, while limited by a sensitivity of 75% for identifying patients with lung cancer at the target specificity of 90%, achieved higher data accuracy and completeness than use of structured data alone. This work suggests that it may be possible to construct broad cohorts with a machine learning algorithm and that care must be taken to characterize the performance of the cohort. Given that such cohorts may be the basis for research or quality-improvement initiatives that ultimately affect patients, a question arises about what level of model performance is good enough. An algorithm that identifies patients with 90% specificity may be suitable for certain research questions but not others. When a very rare cohort is being identified for retrospective research or when patients who may be eligible for a prospective clinical trial are identified in real time, it may be more important to + Related article",JAMA network open,2021,10.1001/jamanetworkopen.2021.16063,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f1664bbaddedea8c250873e7610ab07e53fa7132,https://www.semanticscholar.org/paper/f1664bbaddedea8c250873e7610ab07e53fa7132,Machine learning pipeline for battery state of health estimation,,Nat. Mach. Intell.,2021,10.1038/S42256-021-00312-3,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c34009382107e245ff56d697a67d8c6b0d4642c4,https://www.semanticscholar.org/paper/c34009382107e245ff56d697a67d8c6b0d4642c4,Predicting community mortality risk due to CoVID-19 using machine learning and development of a prediction tool,"Background: The recent pandemic of CoVID-19 has emerged as a threat to global health security. There are a very few prognostic models on CoVID-19 using machine learning. Objectives: To predict mortality among confirmed CoVID-19 patients in South Korea using machine learning and deploy the best performing algorithm as an open-source online prediction tool for decision-making. Materials and methods: Mortality for confirmed CoVID-19 patients (n=3,022) between January 20, 2020 and April 07, 2020 was predicted using five machine learning algorithms (logistic regression, support vector machine, K nearest neighbor, random forest and gradient boosting). Performance of the algorithms was compared, and the best performing algorithm was deployed as an online prediction tool. Results: The gradient boosting algorithm was the best performer in terms of discrimination (area under ROC curve=0.966), calibration (Matthews Correlation Coefficient=0.656; Brier Score=0.013) and predictive ability (accuracy=0.987). The best performer algorithm (gradient boosting) was deployed as the online CoVID-19 Community Mortality Risk Prediction tool named CoCoMoRP (https://ashis-das.shinyapps.io/CoCoMoRP/). Conclusions: We describe the framework for the rapid development and deployment of an open-source machine learning tool to predict mortality risk among CoVID-19 confirmed patients using publicly available surveillance data. This tool can be utilized by potential stakeholders such as health providers and policy makers to triage patients at the community level in addition to other approaches.",medRxiv,2020,10.1101/2020.04.27.20081794,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9d4d39f2405841ecf12ea11e2a20af778b20d360,https://www.semanticscholar.org/paper/9d4d39f2405841ecf12ea11e2a20af778b20d360,A multi-modal machine learning approach towards predicting patient readmission,"Healthcare costs that can be attributed to unplanned readmissions are staggeringly high and negatively impact health and wellness of patients. In the United States, hospital systems and care providers have strong financial motivations to reduce readmissions in accordance with several government guidelines. One of the critical steps to reducing readmissions is to recognize the factors that lead to readmission and correspondingly identify at-risk patients based on these factors. The availability of large volumes of electronic health care records make it possible to develop and deploy automated machine learning models that can predict unplanned readmissions and pinpoint the most important factors of readmission risk. While hospital readmission is an undesirable outcome for any patient, it is more so for medically frail patients. Here, we develop and compare four machine learning models (Random Forest, XGBoost, CatBoost, and Logistic Regression) for predicting 30-day unplanned readmission for patients deemed frail (Age ≥ 50). Variables that indicate frailty, comorbidities, high risk medication use, demographic, hospital and insurance were incorporated in the models for prediction of unplanned 30-day readmission. Our findings indicate that CatBoost outperforms the other three models (AUC 0.80) and prior work in this area. We find that constructs of frailty, certain categories of high risk medications, and comorbidity are all strong predictors of readmission for elderly patients.",bioRxiv,2020,10.1101/2020.11.20.391904,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ba06f96f023bf27ccc8230a08a718a9cfba63f03,https://www.semanticscholar.org/paper/ba06f96f023bf27ccc8230a08a718a9cfba63f03,Ethical Testing in the Real World: Evaluating Physical Testing of Adversarial Machine Learning,"This paper critically assesses the adequacy and representativeness of physical domain testing for various adversarial machine learning (ML) attacks against computer vision systems involving human subjects. Many papers that deploy such attacks characterize themselves as ""real world."" Despite this framing, however, we found the physical or real-world testing conducted was minimal, provided few details about testing subjects and was often conducted as an afterthought or demonstration. Adversarial ML research without representative trials or testing is an ethical, scientific, and health/safety issue that can cause real harms. We introduce the problem and our methodology, and then critique the physical domain testing methodologies employed by papers in the field. We then explore various barriers to more inclusive physical testing in adversarial ML and offer recommendations to improve such testing notwithstanding these challenges.",ArXiv,2020,10.2139/ssrn.3750914,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e2133bd7f0798719bec09dd9126e8af79d60fc4f,https://www.semanticscholar.org/paper/e2133bd7f0798719bec09dd9126e8af79d60fc4f,Improving Health and Quality of Life in One-Person Households Using IoT and Machine Learning,"Worldwide, there has been an increase in the number of individuals that live alone in one-person households (OPHs). Compared to those living with family, people in OPHs easily lose control of life rhythm. Given that the disturbance of life rhythm leads to chronic disease, they have a higher risk of illness. As such, there is an urgent demand for assistive technology that allows people in OPHs to enjoy healthy, high-quality lives. For decades, there has been significant research and development of smart systems to assist people at home. However, there are still limitations on the practical use of these systems in actual OPHs. More specifically, they are often too intrusive to the lifestyle of users or home objects. In addition, they are often expensive to deploy and maintain. Furthermore, these systems are unable to evaluate the quality of life rhythm. As a result, it is difficult for individual users to determine what their healthy life rhythms should be, and how to improve their current situation.The goal of research is to develop a new smart system for OPHs that can minimize intrusiveness and cost, while also facilitating the assessment of life rhythms of individual users. The new system collects user position and environmental data inside the house in a non-intrusive way, using affordable IoT devices. From this data, the system then recognizes the daily activities of the user. Based on these activities, eventually, the system can quantitatively evaluate the users life rhythms and provide practical advice for maintaining a healthy life.",BCD,2019,10.1109/sera.2019.8886791,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
96a8ca4694fbe79112757a6df59a76414e71c512,https://www.semanticscholar.org/paper/96a8ca4694fbe79112757a6df59a76414e71c512,Serverless on FHIR: Deploying machine learning models for healthcare on the cloud,"Machine Learning (ML) plays a vital role in implementing digital health. The advances in hardware and the democratization of software tools have revolutionized machine learning. However, the deployment of ML models -- the mathematical representation of the task to be performed -- for effective and efficient clinical decision support at the point of care is still a challenge. ML models undergo constant improvement of their accuracy and predictive power with a high turnover rate. Updating models consumed by downstream health information systems is essential for patient safety. We introduce a functional taxonomy and a four-tier architecture for cloud-based model deployment for digital health. The four tiers are containerized microservices for maintainability, serverless architecture for scalability, function as a service for portability and FHIR schema for discoverability. We call this architecture Serverless on FHIR and propose this as a standard to deploy digital health applications that can be consumed by downstream systems such as EMRs and visualization tools.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f0a5f3192f7e4ca425cae85ba89b8bb489599aa5,https://www.semanticscholar.org/paper/f0a5f3192f7e4ca425cae85ba89b8bb489599aa5,Predicting Depression From Hearing Loss Using Machine Learning,"Supplemental Digital Content is available in the text. Objectives: Hearing loss is the most common sensory loss in humans and carries an enhanced risk of depression. No prior studies have attempted a contemporary machine learning approach to predict depression using subjective and objective hearing loss predictors. The objective was to deploy supervised machine learning to predict scores on a validated depression scale using subjective and objective audiometric variables and other health determinant predictors. Design: A large predictor set of health determinants from the National Health and Nutrition Examination Survey 2015–2016 database was used to predict adults’ scores on a validated instrument to screen for the presence and severity of depression (Patient Health Questionnaire-9 [PHQ-9]). After model training, the relative influence of individual predictors on depression scores was stratified and analyzed. Model prediction performance was determined by prediction error metrics. Results: The test set mean absolute error was 3.03 (95% confidence interval: 2.91 to 3.14) and 2.55 (95% confidence interval: 2.48 to 2.62) on datasets with audiology-only predictors and all predictors, respectively, on the PHQ-9’s 27-point scale. Participants’ self-reported frustration when talking to members of family or friends due to hearing loss was the fifth-most influential of all predictors. Of the top 10 most influential audiometric predictors, five were related to social contexts, two for significant noise exposure, two objective audiometric parameters, and one presence of bothersome tinnitus. Conclusions: Machine learning algorithms can accurately predict PHQ-9 depression scale scores from National Health and Nutrition Examination Survey data. The most influential audiometric predictors of higher scores on a validated depression scale were social dynamics of hearing loss and not objective audiometric testing. Such models could be useful in predicting depression scale scores at the point-of-care in conjunction with a standard audiologic assessment.",medRxiv,2020,10.1097/AUD.0000000000000993,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
09a7eb1c08d47442e8434f6abaaf19b2c50f1063,https://www.semanticscholar.org/paper/09a7eb1c08d47442e8434f6abaaf19b2c50f1063,A Machine Learning Approach for Heart Attack Prediction,"124 Published By: Blue Eyes Intelligence Engineering and Sciences Publication © Copyright: All rights reserved. Retrieval Number: 100.1/ijeat.F30430810621 DOI:10.35940/ijeat.F3043.0810621 Journal Website: www.ijeat.org Abstract: A heart attack also known as cardiac arrest, diversify various conditions impacting the heart and became one of the chief-reason for death worldwide over the last few decades. Approximately, 31% of total deaths globally are due to CVDs. It constitutes the pinnacle of chronic processes which involve complex interactions between risk factors which can and cannot be improved. Most of the instances or cases of cardiovascular diseases can be allocated to revisable risk factors where most of the instances are considered preventable. ML became the enhancing approach for the evolution of predictive models in health care industries and was decided to test various algorithms to check what extent their prediction scores estimate or ameliorate upon the results acquired. Researchers deploy various machine learning and data mining techniques over a set of enormous data of cardiovascular patients to attain the prediction for heart attacks before their occurrence for helping healthcare industries and professionals. This research comprises various Supervised ML classifiers like, Gradient Boosting, Decision Tree, Random Forest and Logistic Regression that have been used to deploy a model for Myocardial Infarction prediction. It uses the existing datasets from the Framingham database and others from the database of the UCI Heart repository. This research intends to ideate the prediction for probabilities of occurrence of a heart attack in the patients. These classifiers have been deployed in pipeline approach of machine learning to attain the prediction using both ways i.e., without optimizations and feature transformations as well as vice-versa. The results impersonate that the Gradient Boosting classifier is achieving the highest accuracy score in such a way that prediction used by our model is of binary form in where 1 means a chance of heart attack and 0 means no chance. Some of the most influential attributes are chest pain type among which the typical angina is the most influential and asymptotic chest pain is least, cholesterol level in which the level greater than 200mg/dl are more prone, increased heart rate, thal, and age. It is concluded that premature heart attack is preventable in 80% of the total cases just by using a healthy diet along with regular exercises and not using tobacco products also the person who drinks more than 5 glasses of water daily are less likely to develop attacks.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1d3539a8d94bd3ab78993d7cc584efc06ed0e460,https://www.semanticscholar.org/paper/1d3539a8d94bd3ab78993d7cc584efc06ed0e460,Synthetic Benchmarks for Scientific Research in Explainable Machine Learning,"As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",NeurIPS Datasets and Benchmarks,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
77713d043575a507bcfc3e35677554b08d76ad36,https://www.semanticscholar.org/paper/77713d043575a507bcfc3e35677554b08d76ad36,Natural language processing and machine learning of electronic health records for prediction of first-time suicide attempts,"Abstract Objective Limited research exists in predicting first-time suicide attempts that account for two-thirds of suicide decedents. We aimed to predict first-time suicide attempts using a large data-driven approach that applies natural language processing (NLP) and machine learning (ML) to unstructured (narrative) clinical notes and structured electronic health record (EHR) data. Methods This case-control study included patients aged 10–75 years who were seen between 2007 and 2016 from emergency departments and inpatient units. Cases were first-time suicide attempts from coded diagnosis; controls were randomly selected without suicide attempts regardless of demographics, following a ratio of nine controls per case. Four data-driven ML models were evaluated using 2-year historical EHR data prior to suicide attempt or control index visits, with prediction windows from 7 to 730 days. Patients without any historical notes were excluded. Model evaluation on accuracy and robustness was performed on a blind dataset (30% cohort). Results The study cohort included 45 238 patients (5099 cases, 40 139 controls) comprising 54 651 variables from 5.7 million structured records and 798 665 notes. Using both unstructured and structured data resulted in significantly greater accuracy compared to structured data alone (area-under-the-curve [AUC]: 0.932 vs. 0.901 P < .001). The best-predicting model utilized 1726 variables with AUC = 0.932 (95% CI, 0.922–0.941). The model was robust across multiple prediction windows and subgroups by demographics, points of historical most recent clinical contact, and depression diagnosis history. Conclusions Our large data-driven approach using both structured and unstructured EHR data demonstrated accurate and robust first-time suicide attempt prediction, and has the potential to be deployed across various populations and clinical settings.",JAMIA open,2021,10.1093/jamiaopen/ooab011,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9986fab347bcec1bc01e73f5c7955c1ae2c75164,https://www.semanticscholar.org/paper/9986fab347bcec1bc01e73f5c7955c1ae2c75164,Machine Learning for Health: Algorithm Auditing & Quality Control,,Journal of Medical Systems,2021,10.1007/s10916-021-01783-y,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aabe52d279b2b46a0e1f909661a1bd19b0bc59ab,https://www.semanticscholar.org/paper/aabe52d279b2b46a0e1f909661a1bd19b0bc59ab,Machine Learning and Mobile Health Monitoring Platforms: A Case Study on Research and Implementation Challenges,,J. Heal. Informatics Res.,2018,10.1007/S41666-018-0021-1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5509ef863628664dccf49d424250d7ff3a173bf4,https://www.semanticscholar.org/paper/5509ef863628664dccf49d424250d7ff3a173bf4,Challenges to the Reproducibility of Machine Learning Models in Health Care.,"Reproducibility has been an important and intensely debated topic in science and medicine for the past few decades.1 As the scientific enterprise has grown in scope and complexity, concerns regarding how well new findings can be reproduced and validated across different scientific teams and study populations have emerged. In some instances,2 the failure to replicate numerous previous studies has added to the growing concern that science and biomedicine may be in the midst of a “reproducibility crisis.” Against this backdrop, high-capacity machine learning models are beginning to demonstrate early successes in clinical applications,3 and some have received approval from the US Food and Drug Administration. This new class of clinical prediction tools presents unique challenges and obstacles to reproducibility, which must be carefully considered to ensure that these techniques are valid and deployed safely and effectively. Reproducibility is a minimal prerequisite for the creation of new knowledge and scientific progress, but defining precisely what it means for a scientific study to be “reproducible” is complex and has been the subject of considerable effort by both individual researchers and organizations like the National Academies of Science, Engineering, and Medicine. First, it is important to distinguish between the notions of reproducibility and replication. A study is reproducible if, given access to the underlying data and analysis code, an independent group can obtain the same result observed in the original study. However, being reproducible does not imply that a study is correct, only thattheresultswereabletobeverifiedbyadifferentgroup not involved in the original study. A study is replicable if an independent group studying the same phenomenon reaches the same conclusion after performing the same set of experiments or analyses after collecting new data. The discussion around reproducibility and replication has primarily focused on traditional statistical models and the results from randomized clinical trials, but these considerations can and should apply equally to machine learning studies. Challenges to reproducibility and replication include confounding, multiple hypothesis testing, randomness inherent to the analysis procedure, incomplete documentation, and restricted access to the underlying data and code. The last concern, data access, is especially germane for medicine, as privacy barriers are important considerations for data sharing. However, by definition, replication does not require access to the original data or code because a replication exercise examines the extent to which the original phenomenon generalizes to new contexts and new populations. This Viewpoint focuses on reproducibility, even though it is important to acknowledge that replication is often the ultimate goal. Replication is especially important for studies that use observational data (which is almost always the case for machine learning studies) because these dataareoftenbiased,andmodelscouldoperationalizethis bias if not replicated. The challenges of reproducing a machinelearningmodeltrainedbyanotherresearchteamcan be difficult, perhaps even prohibitively so, even with unfettered access to raw data and code.",JAMA,2020,10.1001/jama.2019.20866,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
69c30694a9e1cb73c71e0c57794388dc06a4ae0d,https://www.semanticscholar.org/paper/69c30694a9e1cb73c71e0c57794388dc06a4ae0d,Machine Learning Algorithms in Civil Structural Health Monitoring: A Systematic Review,,,2020,10.1007/s11831-020-09471-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c05bdcab8bf82909cd12a84a306be591d30a8113,https://www.semanticscholar.org/paper/c05bdcab8bf82909cd12a84a306be591d30a8113,Prediction of Drug-Induced Long QT Syndrome Using Machine Learning Applied to Harmonized Electronic Health Record Data,"Background: Drug-induced QT prolongation is a potentially preventable cause of morbidity and mortality, however there are no widespread clinical tools utilized to predict which individuals are at greatest risk. Machine learning (ML) algorithms may provide a method for identifying these individuals, and could be automated to directly alert providers in real time. Objective: This study applies ML techniques to electronic health record (EHR) data to identify an integrated risk-prediction model that can be deployed to predict risk of drug-induced QT prolongation. Methods: We examined harmonized data from the UCHealth EHR and identified inpatients who had received a medication known to prolong the QT interval. Using a binary outcome of the development of a QTc interval >500 ms within 24 hours of medication initiation or no ECG with a QTc interval >500 ms, we compared multiple machine learning methods by classification accuracy and performed calibration and rescaling of the final model. Results: We identified 35,639 inpatients who received a known QT-prolonging medication and an ECG performed within 24 hours of administration. Of those, 4,558 patients developed a QTc > 500 ms and 31,081 patients did not. A deep neural network with random oversampling of controls was found to provide superior classification accuracy (F1 score 0.404; AUC 0.71) for the development of a long QT interval compared with other methods. The optimal cutpoint for prediction was determined and was reasonably accurate (sensitivity 71%; specificity 73%). Conclusions: We found that deep neural networks applied to EHR data provide reasonable prediction of which individuals are most susceptible to drug-induced QT prolongation. Future studies are needed to validate this model in novel EHRs and within the physician order entry system to assess the ability to improve patient safety.",Journal of cardiovascular pharmacology and therapeutics,2021,10.1177/1074248421995348,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e90d6e7b5971a2b1645e05ae0dba6188c92aab28,https://www.semanticscholar.org/paper/e90d6e7b5971a2b1645e05ae0dba6188c92aab28,Using explainable machine learning to characterise data drift and detect emergent health risks for emergency department admissions during COVID-19,,Scientific reports,2021,10.1038/s41598-021-02481-y,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
04777b99de507d1204c5aa8189929b1c8d3673b6,https://www.semanticscholar.org/paper/04777b99de507d1204c5aa8189929b1c8d3673b6,Fault Diagnosis in Structural Health Monitoring Systems Using Signal Processing and Machine Learning Techniques,,Structural Integrity,2021,10.1007/978-3-030-81716-9_7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b29eb7e8199161edad47fffd7a487fc1f552d0a3,https://www.semanticscholar.org/paper/b29eb7e8199161edad47fffd7a487fc1f552d0a3,Design and Implementation of Advanced Machine Learning Management and Its Impact on Better Healthcare Services: A Multiple Regression Analysis Approach (MRAA),"In the current information and technology era, business enterprises are focusing in performing the process effectively by reducing the waiting time in completing the work, reduce latency and deploy the resources effectively so as to service the patient, medical practitioners, societies, and other stakeholders in an efficient manner. Hence, several organisations are using the emerging technologies so as to obtain high performance and enhance competitive edge. The advancement in machine learning, deep learning, business analytics, etc. enables the health care industry to identify the patterns based on the data collected and create a pivotal position and enhance revenues and profits in a sustainable manner. Machine learning models are considered as computational algorithms which will enable in collected the data, analyze them, and provide the necessary reports to the experts and management in order to make informed decision making. The application of advanced machine learning enables the organisation to process the image effectively, recognize the voice and enable in servicing the customers, process the available data, and identify the patterns so as to make informed decision making. The basic purpose of the study is to analyze the overall implementation of advanced machine learning approaches towards health care services for providing enhanced services, better patient engagement, and support in creating better life for them, the researchers intend to collect the closed-ended questionnaire from employees in different medical centers covering: apprehend the nature of designing and implementation of machine learning approaches in the organisation and understand the effectiveness of these tools in enhancing the sustainable growth and development of the organisation.",Computational and mathematical methods in medicine,2022,10.1155/2022/2489116,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8ae554ffc90002b04f82434fb718d1d54a26e5b2,https://www.semanticscholar.org/paper/8ae554ffc90002b04f82434fb718d1d54a26e5b2,Implementing Machine Learning Models for Suicide Risk Prediction in Clinical Practice: Focus Group Study With Hospital Providers,"Background Interest in developing machine learning models that use electronic health record data to predict patients’ risk of suicidal behavior has recently proliferated. However, whether and how such models might be implemented and useful in clinical practice remain unknown. To ultimately make automated suicide risk–prediction models useful in practice, and thus better prevent patient suicides, it is critical to partner with key stakeholders, including the frontline providers who will be using such tools, at each stage of the implementation process. Objective The aim of this focus group study is to inform ongoing and future efforts to deploy suicide risk–prediction models in clinical practice. The specific goals are to better understand hospital providers’ current practices for assessing and managing suicide risk; determine providers’ perspectives on using automated suicide risk–prediction models in practice; and identify barriers, facilitators, recommendations, and factors to consider. Methods We conducted 10 two-hour focus groups with a total of 40 providers from psychiatry, internal medicine and primary care, emergency medicine, and obstetrics and gynecology departments within an urban academic medical center. Audio recordings of open-ended group discussions were transcribed and coded for relevant and recurrent themes by 2 independent study staff members. All coded text was reviewed and discrepancies were resolved in consensus meetings with doctoral-level staff. Results Although most providers reported using standardized suicide risk assessment tools in their clinical practices, existing tools were commonly described as unhelpful and providers indicated dissatisfaction with current suicide risk assessment methods. Overall, providers’ general attitudes toward the practical use of automated suicide risk–prediction models and corresponding clinical decision support tools were positive. Providers were especially interested in the potential to identify high-risk patients who might be missed by traditional screening methods. Some expressed skepticism about the potential usefulness of these models in routine care; specific barriers included concerns about liability, alert fatigue, and increased demand on the health care system. Key facilitators included presenting specific patient-level features contributing to risk scores, emphasizing changes in risk over time, and developing systematic clinical workflows and provider training. Participants also recommended considering risk-prediction windows, timing of alerts, who will have access to model predictions, and variability across treatment settings. Conclusions Providers were dissatisfied with current suicide risk assessment methods and were open to the use of a machine learning–based risk-prediction system to inform clinical decision-making. They also raised multiple concerns about potential barriers to the usefulness of this approach and suggested several possible facilitators. Future efforts in this area will benefit from incorporating systematic qualitative feedback from providers, patients, administrators, and payers on the use of these new approaches in routine care, especially given the complex, sensitive, and unfortunately still stigmatized nature of suicide risk.",JMIR formative research,2022,10.2196/30946,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
84b7eaef9c61a30f354cd9faa9a2e62d142e7cd4,https://www.semanticscholar.org/paper/84b7eaef9c61a30f354cd9faa9a2e62d142e7cd4,Investigating the impact of 5G radiation on human health using machine learning,"
 
 
The advent of 5G has improved greatly the speed of data transmission in wireless mobile technology. On the other hand, it has put society in suspense due to ailments that came along with its deployment. Many attributed the emission of 5G radiation as the main cause of cancer today and that has led to the writing of this article paper. The research study employed a machine learning technique that is based on an artificial neural network in modeling the 5G wireless technology. MATLAB, Simulink was used to analyze the absorption and penetration level of 5G electromagnetic energy pattern into biological tissue Deoxyribonucleic Acid (DNA). Our research result revealed that the energy produced by 5G radiation at the non-ionizing region of the electromagnetic spectrum is small and cannot break into the chemical bonds of biological tissue Deoxyribonucleic Acid (DNA) or cause changes to cells that will result in either cancer or viral disease. 
 
 
",Nigerian Journal of Technology,2021,10.4314/njt.v40i4.16,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
77828d2f07f3a9f14051c127f578690dbf5f4a2b,https://www.semanticscholar.org/paper/77828d2f07f3a9f14051c127f578690dbf5f4a2b,Machine learning-driven recommender systems to improve engagement with health content in a low-resource setting: Poster,"Digital technological tools offer the opportunity to design and disseminate targeted information to influence health behaviors and outcomes. However, extended engagement with health information is vital to promote sustained behavior change in health consumers. Our content-led mobile application for children's health, Saathealth, deployed in a low-resource setting, was used to develop and run machine learning algorithms to build health recommender systems using content and collaborative filtering techniques. We aimed to explore changes in engagement associated with the recommendation systems on the Saathealth app by assessing various aspects of user engagement: videos watched on the app, time spent on the app, sessions on the app, and correct quiz responses. We conducted two A/B experiments to compare the effect of (i) content filtering with no recommendations, and (ii) content filtering with collaborative filtering, on content consumption on the Saathealth app. In experiment 1, the content filtering recommender system was associated with a 25.00% higher median number of videos watched per user compared to when no recommendations were provided after 45 days (5.00 [interquartile range (IQR), 2.00–12.00] vs. 4.00 [IQR, 2.00–10.50], respectively). Content filtering also led to 53.80% more complete video watches and 13.96% higher proportions of correct quiz responses. When the content filtering recommender system was compared with the collaborative filtering one in experiment 2, users in the collaborative filtering arm watched 66.67% more videos, both at 45 days and 90 days. At 90 days, the median number of videos watched per user was 5.00 (IQR, 2.00–9.25) in the collaborative filtering arm and 3.00 (IQR, 2.00–6.00) in the content filtering arm. Collaborative filtering also led to 15.01% more time spent on the app and 59.05% higher complete video watches. We found that machine learning-driven health recommender systems may be effective tools to sustain user engagement with health content. These tools have the potential to address various global health challenges by improving health awareness and behaviors in low-resource settings.",COMPASS,2021,10.1145/3460112.3471976,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b75214a660cb9d0ebca7da59fa79a97c89cb9529,https://www.semanticscholar.org/paper/b75214a660cb9d0ebca7da59fa79a97c89cb9529,A Machine Learning Approach to Passively Informed Prediction of Mental Health Risk in People with Diabetes: Retrospective Case-Control Analysis,"Background Proactive detection of mental health needs among people with diabetes mellitus could facilitate early intervention, improve overall health and quality of life, and reduce individual and societal health and economic burdens. Passive sensing and ecological momentary assessment are relatively newer methods that may be leveraged for such proactive detection. Objective The primary aim of this study was to conceptualize, develop, and evaluate a novel machine learning approach for predicting mental health risk in people with diabetes mellitus. Methods A retrospective study was designed to develop and evaluate a machine learning model, utilizing data collected from 142,432 individuals with diabetes enrolled in the Livongo for Diabetes program. First, participants’ mental health statuses were verified using prescription and medical and pharmacy claims data. Next, four categories of passive sensing signals were extracted from the participants’ behavior in the program, including demographics and glucometer, coaching, and event data. Data sets were then assembled to create participant-period instances, and descriptive analyses were conducted to understand the correlation between mental health status and passive sensing signals. Passive sensing signals were then entered into the model to train and test its performance. The model was evaluated based on seven measures: sensitivity, specificity, precision, area under the curve, F1 score, accuracy, and confusion matrix. SHapley Additive exPlanations (SHAP) values were computed to determine the importance of individual signals. Results In the training (and validation) and three subsequent test sets, the model achieved a confidence score greater than 0.5 for sensitivity, specificity, area under the curve, and accuracy. Signals identified as important by SHAP values included demographics such as race and gender, participant’s emotional state during blood glucose checks, time of day of blood glucose checks, blood glucose values, and interaction with the Livongo mobile app and web platform. Conclusions Results of this study demonstrate the utility of a passively informed mental health risk algorithm and invite further exploration to identify additional signals and determine when and where such algorithms should be deployed.",Journal of medical Internet research,2021,10.2196/27709,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b1eacd00b8de1f18385c2fbc06978b02a91ea24e,https://www.semanticscholar.org/paper/b1eacd00b8de1f18385c2fbc06978b02a91ea24e,Application of Wavelet Scattering and Machine Learning on Structural Health Diagnosis for Quadcopter,"The aim of this study was to examine the health diagnosis classification method of quadcopter structures with different mixed faults. The loosening of the motor mount, damage to the propeller, and the loosening of the arm mount were the main fault conditions investigated. Data were first acquired under non-fault conditions and the conditions of the three types of fault. Then, the features of the vibration and pulse width modulation signals were extracted by root mean square, standard deviation, and sample entropy. Moreover, the features of the audio signal were extracted by wavelet scattering, which contains time-frequency domain information that provides significant power for classification. In this paper, we propose a simple machine learning method, based on the k-Nearest Neighbor (kNN), not only for classification but also demonstrating the efficacy of the features. To test the limits of accuracy, different configurations of kNN parameters are deployed, in addition to the features. In summary, as a result of the highly efficacious features, despite mixed fault conditions, the accuracy reached 90.73%. This method improves the accuracy of mixed faults’ classification and maintains a certain level of classification effectiveness.",Applied Sciences,2021,10.3390/app112110297,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fed37f8727f657d323108460f10fc3da9b29b29e,https://www.semanticscholar.org/paper/fed37f8727f657d323108460f10fc3da9b29b29e,Patient-Level Clinical Expertise Enhances Prostate Cancer Recurrence Predictions with Machine Learning,"With rising access to electronic health record data, application of artificial intelligence to create clinical risk prediction models has grown. A key component in designing these models is feature generation. Methods used to generate features differ in the degree of clinical expertise they deploy (from minimal to population-level to patient-level), and subsequently the extent to which they can extract reliable signals and be automated. In this work, we develop a new process that defines how to systematically implement patient-level clinician feature generation (CFG), which leverages clinical expertise to define concepts relevant to the outcome variable, identify each concept's associated features, and finally extract most features on a per-patient level by manual chart review. We subsequently apply this method to identifying and extracting patient-level features predictive of cancer recurrence from progress notes for a cohort of prostate cancer patients. We evaluate the performance of the CFG process against an automated feature generation (AFG) process via natural language processing techniques. The machine learning outcome prediction model leveraging the CFG process has a mean AUC-ROC of 0.80 (SE: 0.004), in comparison to the AFG model that has a mean AUC-ROC of 0.74 (SE: 0.006). This relationship remains qualitatively unchanged throughout extensive sensitivity analyses. Our analyses illustrate the value of in-depth specialist reasoning in generating features from progress notes and provide a proof of concept that there is a need for new research on efficient integration of in-depth clinical expertise into feature generation for clinical risk prediction.",medRxiv,2022,10.1101/2022.03.22.22272635,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ac0a63d27866603371c953c98eb011e9b512ee53,https://www.semanticscholar.org/paper/ac0a63d27866603371c953c98eb011e9b512ee53,Using Data-Driven Machine Learning to Predict Unplanned ICU Transfers with Critical Deterioration from Electronic Health Records,"OBJECTIVE
We aimed to develop a data-driven machine learning model for predicting critical deterioration events from routinely collected EHR data in hospitalized children.


MATERIALS
This retrospective cohort study included all pediatric inpatients hospitalized on a medical or surgical ward between 2014-2018 at a quaternary children's hospital.


METHODS
We developed a large data-driven approach and evaluated three machine learning models to predict pediatric critical deterioration events. We evaluated the models using a nested, stratified 10-fold cross-validation. The evaluation metrics included C-statistic, sensitivity, and positive predictive value. We also compared the machine learning models with patients identified as high-risk Watchers by bedside clinicians.


RESULTS
The study included 57,233 inpatient admissions from 34,976 unique patients. 3,943 variables were identified from the EHR data. The XGBoost model performed best (C-statistic=0.951, CI: 0.946 ∼ 0.956).


CONCLUSIONS
Our data-driven machine learning models accurately predicted patient deterioration. Future sociotechnical analysis will inform deployment within the clinical setting.",MedInfo,2022,10.3233/SHTI220160,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
33c8c64369e4ad47143dc24b058651f8b27fb3ff,https://www.semanticscholar.org/paper/33c8c64369e4ad47143dc24b058651f8b27fb3ff,Emergency department admissions during COVID-19: explainable machine learning to characterise data drift and detect emergent health risks,"Supervised machine learning algorithms deployed in acute healthcare settings use data describing historical episodes to predict clinical outcomes. Clinical settings are dynamic environments and the underlying data distributions characterising episodes can change with time (a phenomenon known as data drift), and so can the relationship between episode characteristics and associated clinical outcomes (so-called, concept drift). We demonstrate how explainable machine learning can be used to monitor data drift in a predictive model deployed within a hospital emergency department. We use the COVID-19 pandemic as an exemplar cause of data drift, which has brought a severe change in operational circumstances. We present a machine learning classifier trained using (pre-COVID-19) data, to identify patients at high risk of admission to hospital during an emergency department attendance. We evaluate our model's performance on attendances occurring pre-pandemic (AUROC 0.856 95%CI [0.852, 0.859]) and during the COVID-19 pandemic (AUROC 0.826 95%CI [0.814, 0.837]). We demonstrate two benefits of explainable machine learning (SHAP) for models deployed in healthcare settings: (1) By tracking the variation in a feature's SHAP value relative to its global importance, a complimentary measure of data drift is found which highlights the need to retrain a predictive model. (2) By observing the relative changes in feature importance emergent health risks can be identified.",medRxiv,2021,10.1101/2021.05.27.21257713,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3632674890abeba561af514d880a46400734f90b,https://www.semanticscholar.org/paper/3632674890abeba561af514d880a46400734f90b,"KETOS: Clinical decision support and machine learning as a service – A training and deployment platform based on Docker, OMOP-CDM, and FHIR Web Services","Background and objective To take full advantage of decision support, machine learning, and patient-level prediction models, it is important that models are not only created, but also deployed in a clinical setting. The KETOS platform demonstrated in this work implements a tool for researchers allowing them to perform statistical analyses and deploy resulting models in a secure environment. Methods The proposed system uses Docker virtualization to provide researchers with reproducible data analysis and development environments, accessible via Jupyter Notebook, to perform statistical analysis and develop, train and deploy models based on standardized input data. The platform is built in a modular fashion and interfaces with web services using the Health Level 7 (HL7) Fast Healthcare Interoperability Resources (FHIR) standard to access patient data. In our prototypical implementation we use an OMOP common data model (OMOP-CDM) database. The architecture supports the entire research lifecycle from creating a data analysis environment, retrieving data, and training to final deployment in a hospital setting. Results We evaluated the platform by establishing and deploying an analysis and end user application for hemoglobin reference intervals within the University Hospital Erlangen. To demonstrate the potential of the system to deploy arbitrary models, we loaded a colorectal cancer dataset into an OMOP database and built machine learning models to predict patient outcomes and made them available via a web service. We demonstrated both the integration with FHIR as well as an example end user application. Finally, we integrated the platform with the open source DataSHIELD architecture to allow for distributed privacy preserving data analysis and training across networks of hospitals. Conclusion The KETOS platform takes a novel approach to data analysis, training and deploying decision support models in a hospital or healthcare setting. It does so in a secure and privacy-preserving manner, combining the flexibility of Docker virtualization with the advantages of standardized vocabularies, a widely applied database schema (OMOP-CDM), and a standardized way to exchange medical data (FHIR).",PloS one,2019,10.1371/journal.pone.0223010,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5d747901282d1fc8f5c1d76a5921c4e07ef8ecdf,https://www.semanticscholar.org/paper/5d747901282d1fc8f5c1d76a5921c4e07ef8ecdf,Early Prediction of Sepsis in the ICU Using Machine Learning: A Systematic Review,"Background: Sepsis is among the leading causes of death in intensive care units (ICUs) worldwide and its recognition, particularly in the early stages of the disease, remains a medical challenge. The advent of an affluence of available digital health data has created a setting in which machine learning can be used for digital biomarker discovery, with the ultimate goal to advance the early recognition of sepsis. Objective: To systematically review and evaluate studies employing machine learning for the prediction of sepsis in the ICU. Data Sources: Using Embase, Google Scholar, PubMed/Medline, Scopus, and Web of Science, we systematically searched the existing literature for machine learning-driven sepsis onset prediction for patients in the ICU. Study Eligibility Criteria: All peer-reviewed articles using machine learning for the prediction of sepsis onset in adult ICU patients were included. Studies focusing on patient populations outside the ICU were excluded. Study Appraisal and Synthesis Methods: A systematic review was performed according to the PRISMA guidelines. Moreover, a quality assessment of all eligible studies was performed. Results: Out of 974 identified articles, 22 and 21 met the criteria to be included in the systematic review and quality assessment, respectively. A multitude of machine learning algorithms were applied to refine the early prediction of sepsis. The quality of the studies ranged from “poor” (satisfying ≤ 40% of the quality criteria) to “very good” (satisfying ≥ 90% of the quality criteria). The majority of the studies (n = 19, 86.4%) employed an offline training scenario combined with a horizon evaluation, while two studies implemented an online scenario (n = 2, 9.1%). The massive inter-study heterogeneity in terms of model development, sepsis definition, prediction time windows, and outcomes precluded a meta-analysis. Last, only two studies provided publicly accessible source code and data sources fostering reproducibility. Limitations: Articles were only eligible for inclusion when employing machine learning algorithms for the prediction of sepsis onset in the ICU. This restriction led to the exclusion of studies focusing on the prediction of septic shock, sepsis-related mortality, and patient populations outside the ICU. Conclusions and Key Findings: A growing number of studies employs machine learning to optimize the early prediction of sepsis through digital biomarker discovery. This review, however, highlights several shortcomings of the current approaches, including low comparability and reproducibility. Finally, we gather recommendations how these challenges can be addressed before deploying these models in prospective analyses. Systematic Review Registration Number: CRD42020200133.",Frontiers in Medicine,2020,10.3389/fmed.2021.607952,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ba6f6f08c0722aefb4d00acae7bdb19563d414d,https://www.semanticscholar.org/paper/2ba6f6f08c0722aefb4d00acae7bdb19563d414d,Machine Learning Techniques for 5G and Beyond,"Wireless communication systems play a very crucial role in modern society for entertainment, business, commercial, health and safety applications. These systems keep evolving from one generation to next generation and currently we are seeing deployment of fifth generation (5G) wireless systems around the world. Academics and industries are already discussing beyond 5G wireless systems which will be sixth generation (6G) of the evolution. One of the main and key components of 6G systems will be the use of Artificial Intelligence (AI) and Machine Learning (ML) for such wireless networks. Every component and building block of a wireless system that we currently are familiar with from our knowledge of wireless technologies up to 5G, such as physical, network and application layers, will involve one or another AI/ML techniques. This overview paper, presents an up-to-date review of future wireless system concepts such as 6G and role of ML techniques in these future wireless systems. In particular, we present a conceptual model for 6G and show the use and role of ML techniques in each layer of the model. We review some classical and contemporary ML techniques such as supervised and un-supervised learning, Reinforcement Learning (RL), Deep Learning (DL) and Federated Learning (FL) in the context of wireless communication systems. We conclude the paper with some future applications and research challenges in the area of ML and AI for 6G networks.",IEEE Access,2021,10.1109/ACCESS.2021.3051557,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2f04196496122924a6ee0dfa89374130b9f7a539,https://www.semanticscholar.org/paper/2f04196496122924a6ee0dfa89374130b9f7a539,Web Search Engine Misinformation Notifier Extension (SEMiNExt): A Machine Learning Based Approach during COVID-19 Pandemic,"Misinformation such as on coronavirus disease 2019 (COVID-19) drugs, vaccination or presentation of its treatment from untrusted sources have shown dramatic consequences on public health. Authorities have deployed several surveillance tools to detect and slow down the rapid misinformation spread online. Large quantities of unverified information are available online and at present there is no real-time tool available to alert a user about false information during online health inquiries over a web search engine. To bridge this gap, we propose a web search engine misinformation notifier extension (SEMiNExt). Natural language processing (NLP) and machine learning algorithm have been successfully integrated into the extension. This enables SEMiNExt to read the user query from the search bar, classify the veracity of the query and notify the authenticity of the query to the user, all in real-time to prevent the spread of misinformation. Our results show that SEMiNExt under artificial neural network (ANN) works best with an accuracy of 93%, F1-score of 92%, precision of 92% and a recall of 93% when 80% of the data is trained. Moreover, ANN is able to predict with a very high accuracy even for a small training data size. This is very important for an early detection of new misinformation from a small data sample available online that can significantly reduce the spread of misinformation and maximize public health safety. The SEMiNExt approach has introduced the possibility to improve online health management system by showing misinformation notifications in real-time, enabling safer web-based searching on health-related issues.",Healthcare,2021,10.3390/healthcare9020156,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b14558c0b727af0ac9086f463b6030b9072dbe16,https://www.semanticscholar.org/paper/b14558c0b727af0ac9086f463b6030b9072dbe16,Methods for Automatic Machine-Learning Workflow Analysis,,ECML/PKDD,2021,10.1007/978-3-030-86517-7_4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ed9b2c4d4ea93d86a6e1167c9e92cfa0a243c4bc,https://www.semanticscholar.org/paper/ed9b2c4d4ea93d86a6e1167c9e92cfa0a243c4bc,Challenges and Opportunities for Unikernels in Machine Learning Inference,"Machine Learning has become a value creator for many new and old businesses. However, efficient realworld machine learning deployments are still a challenge. Traditional Machine Learning deployments suffer from efficient resource utilization and achieving predictable latency. They cannot be treated in the same manner as other application server deployments. Unikernels are a method to specialize application deployment and performance to suit the needs of the application. Traditionally, building or porting applications to unikernels have been challenging. However, recent work has been into simplifying the development of unikernels. Real-world Unikernels as of now are only for specializing applications that run on the CPU. We survey machine learning practitioners and find out that the majority of machine learning practitioners are using the CPU for machine learning deployments, thus, creating an opportunity for unikernels to optimize the performance of these applications. We compare the architecture of two unikernels: nanos and Unikraft. We benchmarked scikit-learn, a popular machine library, inside a unikernel and found that it only offered a 1% advantage over a traditional deployment. However, our testing could not include more innovative systems like Unikraft due to their immaturity and inability to run machine learning libraries. We include a dependency analysis of three popular machine learning libraries Tensorflow Lite, PyTorch and ONNX, to help pave the way for building machine learning applications as Unikraft unikernels.","2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)",2021,10.1109/icrito51393.2021.9596080,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
56e63ffea11c875f7eee257798e18cd04e453b6c,https://www.semanticscholar.org/paper/56e63ffea11c875f7eee257798e18cd04e453b6c,Synthetic Benchmarks for Scientific Research in Explainable Machine Learning,"As machine learning models grow more complex and their applications become more high-stakes, tools for explaining model predictions have become increasingly important. This has spurred a flurry of research in model explainability and has given rise to feature attribution methods such as LIME and SHAP. Despite their widespread use, evaluating and comparing different feature attribution methods remains challenging: evaluations ideally require human studies, and empirical evaluation metrics are often data-intensive or computationally prohibitive on realworld datasets. In this work, we address this issue by releasing XAI-BENCH: a suite of synthetic datasets along with a library for benchmarking feature attribution algorithms. Unlike real-world datasets, synthetic datasets allow the efficient computation of conditional expected values that are needed to evaluate groundtruth Shapley values and other metrics. The synthetic datasets we release offer a wide variety of parameters that can be configured to simulate real-world data. We demonstrate the power of our library by benchmarking popular explainability techniques across several evaluation metrics and across a variety of settings. The versatility and efficiency of our library will help researchers bring their explainability methods from development to deployment. Our code is available at https://github.com/abacusai/xai-bench.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c9796463fa670a80eee9d5920005dd5d628fc73d,https://www.semanticscholar.org/paper/c9796463fa670a80eee9d5920005dd5d628fc73d,"Developing cardiometabolic risk classifiers for youth using handgrip strength, anthropometrics, and demographics: a machine learning approach leveraging National Health and Nutrition Examination Survey Data","
 Background Handgrip strength associates with cardiometabolic (CMB) risk. Health-related physical fitness (HRPF) testing in schools do not explicitly predict CMB disease risk, and commonly engender anxiety, teasing and taunting by peers. Further, school-based screening for hyperinsulinemia using acanthosis nigricans likely misses nascent CMB risk factors like dyslipidemia. This study examined the feasibility of leveraging anthropometrics, demographics, and handgrip strength data to build optimal CMB risk classifiers. Methods The 2011-2014 National Health and Nutrition Examination Survey data from participants aged 12-18 years (n = 402; 205 males) (15.4 ± 1.8 years; 167.4 ± 9.1 cm; 73.2 ± 21.5 kg) who performed bilateral handgrip strength and CMB testing was leveraged. CMB risk was delineated as clustering of three or more risk factors across weight status, mean systolic, mean diastolic, HDL-cholesterol, LDL-cholesterol, total cholesterol, triglycerides, fasting glucose and HOMA-IR. 80% of the balanced dataset was used to train several models (e.g., Decision Tree and K-Nearest Neighbors (KNN)), while 20% was retained for further validation. There were 18 initial features, including age, sex, race, BMI, and combined handgrip strength. SelectKBest, Recurrent Feature Elimination, and Random Forest were deployed to identify the most salient features. Results Resulting models were evaluated using performance metrics such as Area Under the Curve (AUC), recall and precision. The most salient model was a Quadratic Discriminant model involving five features, namely number of people in household, annual household income, number of children 5 years or younger, combined handgrip strength, and waist circumference. When deployed, the model accurately classified 83% and 93% of the positive and negative classes within the test data, respectively (accuracy = 81.7%; AUC = 0.87; Recall = 0.91; Precision = 0.81; F-Measure = 0.92). Conclusions Findings demonstrate demographics, anthropometrics, and handgrip strength can be leveraged (using machine learning techniques) to accurately predict and optimally identify nascent CMB risk in youth while mitigating peer shaming and optimizing student participation in HRPF surveillance protocols in schools. Additional studies are needed to externally validate resulting models and investigate related effects on participation in HRPF testing and CMB risk detection among children and youth.",,2021,10.21203/RS.3.RS-488747/V1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d697fe00c3c4d0feac432fa536cb41737b86268c,https://www.semanticscholar.org/paper/d697fe00c3c4d0feac432fa536cb41737b86268c,Ethical Machine Learning in Health,"The use of machine learning (ML) in health care raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of health care. Specifically, we frame ethics of ML in health care through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to post-deployment considerations. We close by summarizing recommendations to address these challenges.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bd11fe5e26b583996aec37e5f7befc87133abc41,https://www.semanticscholar.org/paper/bd11fe5e26b583996aec37e5f7befc87133abc41,Intersections of machine learning and epidemiological methods for health services research,"Abstract The field of health services research is broad and seeks to answer questions about the health care system. It is inherently interdisciplinary, and epidemiologists have made crucial contributions. Parametric regression techniques remain standard practice in health services research with machine learning techniques currently having low penetrance in comparison. However, studies in several prominent areas, including health care spending, outcomes and quality, have begun deploying machine learning tools for these applications. Nevertheless, major advances in epidemiological methods are also as yet underleveraged in health services research. This article summarizes the current state of machine learning in key areas of health services research, and discusses important future directions at the intersection of machine learning and epidemiological methods for health services research.",International journal of epidemiology,2020,10.1093/ije/dyaa035,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3359e70524adacc34051ad69570a81c3a3efdece,https://www.semanticscholar.org/paper/3359e70524adacc34051ad69570a81c3a3efdece,The influence of maternal agency on severe child undernutrition in conflict-ridden Nigeria: Modeling heterogeneous treatment effects with machine learning,"Nigeria is one of the fastest growing African economies, yet struggles with armed conflict, poverty, and morbidity. An area of high concern is how this situation affects vulnerable families and their children. A key pathway in improving the situation for children in times of conflict is to reinforce maternal agency, for instance, through education. However, the state of the art of research lacks a clear understanding of how many years of education is needed before children benefit. Due to mother’s differing social context and ability, the effect of maternal education varies. We study the heterogeneous treatment effects of maternal agency, here operationalized as length of education, on severe child undernutrition in the context of armed conflict. We deploy a repeated cross-sectional study design, using the Nigeria 2008 and 2013 Demographic and Health Survey (DHS). The sample covers 25,917 children and their respective mothers. A key methodological challenge is to estimate this heterogeneity inductively. The causal inference literature proposes a machine learning approach, Bayesian Additive Regression Trees (BART), as a promising avenue to overcome this challenge. Based on BART-estimation of the Conditional Average Treatment Effect (CATE) this study confirms earlier findings in that maternal education decreases severe child undernutrition, but only when mothers acquire an education that lasts more than the country’s compulsory 9 years; that is 10 years of education and higher. This protective effect remains even during the exposure of armed conflict.",PloS one,2019,10.1371/journal.pone.0208937,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
423c16fb66d255928b5cbd03aae96529f9c3d702,https://www.semanticscholar.org/paper/423c16fb66d255928b5cbd03aae96529f9c3d702,Emerging Applications of Machine Learning in Food Safety.,"Food safety continues to threaten public health. Machine learning holds potential in leveraging large, emerging data sets to improve the safety of the food supply and mitigate the impact of food safety incidents. Foodborne pathogen genomes and novel data streams, including text, transactional, and trade data, have seen emerging applications enabled by a machine learning approach, such as prediction of antibiotic resistance, source attribution of pathogens, and foodborne outbreak detection and risk assessment. In this article, we provide a gentle introduction to machine learning in the context of food safety and an overview of recent developments and applications. With many of these applications still in their nascence, general and domain-specific pitfalls and challenges associated with machine learning have begun to be recognized and addressed, which are critical to prospective use and future deployment of large data sets and their associated machine learning models for food safety applications. Expected final online publication date for the Annual Review of Food Science and Technology, Volume 12 is March 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",Annual review of food science and technology,2021,10.1146/annurev-food-071720-024112,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4654bc252986b911acb00a2bc3307cbf69516402,https://www.semanticscholar.org/paper/4654bc252986b911acb00a2bc3307cbf69516402,A Machine Learning Approach for Structural Health Monitoring Using Noisy Data Sets,"Continuous structural health monitoring of civil infrastructure can be achieved by deploying an Internet of Things network of distributed acceleration sensors in buildings to capture floor movement. Postdisaster damage levels can be computed based on the peak relative floor displacement as specified in government standards. This article uses machine learning approaches to identify the status of buildings postevent based on accelerometer traces. Prior work in the field assumed the use of high-quality accelerometers for displacement estimation. In this article, we focus on using lower quality and cheaper accelerometers, while accounting for noise effects by incorporating noisy data sets in machine learning approaches for classification. A labeled acceleration data set of buildings response to earthquakes was created, where each sample is labeled with its corresponding damage severity. Sensor noise is included in the data set to model nonideal sensors. Classification performance of machine learning algorithms, such as support vector machine, K-nearest neighbor, and convolutional neural network, is presented. Techniques for addressing noise levels are proposed, and the results are compared with regular noise cancellation techniques that adopt high-pass filtering. Note to Practitioners—This article presents a methodology for automatic estimation of buildings status in the aftermath of a natural disaster, such as an earthquake. It focuses on using low-cost inertial sensors, such as accelerometers, to sense buildings’ vibrations and then applying machine learning algorithms to detect damage. Utilizing the convolutional network approach, the proposed methods detect the building damage state with high accuracy. Since this article focuses on using cheap sensors, the cost of deploying a sensor network to monitor buildings is reduced significantly. Deploying this network enables rescue and reconnaissance teams to have a clear view of the most vulnerable structures.",IEEE Transactions on Automation Science and Engineering,2020,10.1109/TASE.2019.2950958,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4033463002445eecb591a5bb26936e64795332fa,https://www.semanticscholar.org/paper/4033463002445eecb591a5bb26936e64795332fa,Machine Learning and the Pursuit of High-Value Health Care,"With thoughtful deployment, machine-learning tools have the potential to help patients, clinicians, and health systems make health care decisions that promote better outcomes at lower cost.",,2020,10.1056/cat.20.0094,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
09231698773d811bf69d169b6efd54855790c5bc,https://www.semanticscholar.org/paper/09231698773d811bf69d169b6efd54855790c5bc,Reporting of demographic data and representativeness in machine learning models using electronic health records,"OBJECTIVE
The development of machine learning (ML) algorithms to address a variety of issues faced in clinical practice has increased rapidly. However, questions have arisen regarding biases in their development that can affect their applicability in specific populations. We sought to evaluate whether studies developing ML models from electronic health record (EHR) data report sufficient demographic data on the study populations to demonstrate representativeness and reproducibility.


MATERIALS AND METHODS
We searched PubMed for articles applying ML models to improve clinical decision-making using EHR data. We limited our search to papers published between 2015 and 2019.


RESULTS
Across the 164 studies reviewed, demographic variables were inconsistently reported and/or included as model inputs. Race/ethnicity was not reported in 64%; gender and age were not reported in 24% and 21% of studies, respectively. Socioeconomic status of the population was not reported in 92% of studies. Studies that mentioned these variables often did not report if they were included as model inputs. Few models (12%) were validated using external populations. Few studies (17%) open-sourced their code. Populations in the ML studies include higher proportions of White and Black yet fewer Hispanic subjects compared to the general US population.


DISCUSSION
The demographic characteristics of study populations are poorly reported in the ML literature based on EHR data. Demographic representativeness in training data and model transparency is necessary to ensure that ML models are deployed in an equitable and reproducible manner. Wider adoption of reporting guidelines is warranted to improve representativeness and reproducibility.",J. Am. Medical Informatics Assoc.,2020,10.1093/jamia/ocaa164,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17923fc80b1db48f22cb8c157904b04ab94168f8,https://www.semanticscholar.org/paper/17923fc80b1db48f22cb8c157904b04ab94168f8,Edge Machine Learning for Energy Efficiency of Resource Constrained IoT Devices,"The recent shift in machine learning towards the edge offers a new opportunity to realize intelligent applications on resource constrained Internet of Things (IoT) hardware. This paper presents a pre-trained Recurrent Neural Network (RNN) model optimized for an IoT device running on 8-bit microcontrollers. The device is used for data acquisition in a research on the impact of prolonged sedentary work on health. Our prediction model facilitates smart data transfer operations to reduce the energy consumption of the device. Application specific optimizations were applied to deploy and execute the pre-trained model on a device which has only 8 KB RAM size. Experiments show that the resulting edge intelligence can reduce the communication cost significantly, achieving substantial savings in the energy used by the IoT device. KeywordsEdge intelligence; IoT; Smart Sensors; RNN.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b793c01c2c8bce3e1df3632446673c2dc7fa60c5,https://www.semanticscholar.org/paper/b793c01c2c8bce3e1df3632446673c2dc7fa60c5,Machine Learning Prognostic Models for Gastrointestinal Bleeding Using Electronic Health Record Data.,"Risk assessment tools for patients with gastrointestinal bleeding may be used for determining level of care and informing management decisions. Development of models that use data from electronic health records is an important step for future deployment of such tools in clinical practice. Furthermore, machine learning tools have the potential to outperform standard clinical risk assessment tools. The authors developed a new machine learning tool for the outcome of in-hospital mortality and suggested it outperforms the intensive care unit prognostic tool, APACHE IVa. Limitations include lack of generalizability beyond intensive care unit patients, inability to use early in the hospital course, and lack of external validation.",The American journal of gastroenterology,2020,10.14309/ajg.0000000000000720,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
18ae1f942faf093531f6c7b16d45003479877d87,https://www.semanticscholar.org/paper/18ae1f942faf093531f6c7b16d45003479877d87,Machine Learning Based Transformer Health Monitoring Using IoT Edge Computing,"In developing countries like India, constant monitoring of the health conditions of transformers with a cloud-based IoT approach is not feasible. Most of the transformers are located in remote areas, therefore, a cloud-based IoT approach needs an uninterrupted Internet connection to run the complex or machine learning algorithms. However, edge computing brings the power of the cloud to the device. In this paper, we proposed an IoT edge computing approach for constant monitoring of transformers using humming sound and machine learning methods. We have collected the humming sound data of normal and faulty categories, then applied the windowing approach to segment humming sound into 2 seconds segments. Mel frequency cepstral coefficients (MFCC) is used to extract features from the sound and the dataset is trained using an SVM classifier. SVM with polynomial kernel performs better and gives 98.77 % average cross-validation accuracy. The trained model is optimized according to the IoT edge computing hardware configuration and deployed to the device for constant health monitoring. The device constantly recording the humming sound and classify each 2 seconds segment into the normal or faulty category and sending the insights to the cloud at regular interval.","2020 5th International Conference on Computing, Communication and Security (ICCCS)",2020,10.1109/ICCCS49678.2020.9276889,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4420d668661627f08bdec9c4528081ef005942bb,https://www.semanticscholar.org/paper/4420d668661627f08bdec9c4528081ef005942bb,Improving Mental Health using Machine Learning to Assist Humans in the Moderation of Forum Posts,"This work investigates the potential for the application of machine learning and natural language processing technology in an online application designed to help teenagers talk about their mental health issues. Specifically, we investigate whether automatic classification methods can be applied with sufficient accuracy to assist humans in the moderation of posts and replies to an online forum. Using real data from an existing application, we outline the specific problems of lack of data, class imbalance and multiple rejection reasons. We investigate a number of machine learning architectures including a state-of-the-art transfer learning architecture, BERT, which has performed well elsewhere despite limited training data, due to its use of pre-training on a very large general corpus. Evaluating on real data, we demonstrate that further large performance gains can be made through the use of automatic data augmentation techniques (synonym replacement, synonym insertion, random swap and random deletion). Using a combination of data augmentation and transfer learning, performance of the automatic classification rivals human performance at the task, thus demonstrating the feasibility of deploying these techniques in a live system.",HEALTHINF,2020,10.5220/0008988401870197,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cc06199ccc2db316894c13599324634f77fc3fcd,https://www.semanticscholar.org/paper/cc06199ccc2db316894c13599324634f77fc3fcd,Design and Deployment of E-Health System in Perspective of Developing Countries: Machine Learning Based Approach (Preprint),"
 BACKGROUND
 We are living in a world where data science and machine learning is tightening its grasp on many sectors of modern life. The medical sector is not an exception. In developing countries, healthcare is one of the domains that need immediate attention. Due to the lack of manpower and technical resources, a large number of people in these regions do not receive proper medical care. Designing an E-health system with the help of machine learning and web technologies would be a great aid in such circumstances.
 
 
 OBJECTIVE
 This proposed E-health System will assist the medical professionals in determining diseases. Moreover, the system will be also helpful for the patients to check whether they have been diagnosed correctly. Based on their diagnosis results they can get medical specialist recommendation and medicine suggestions from the system. The automation of identifying the diseases and suggestion models with the help of machine learning will be cost-efficient and time-saving compared to the traditional methods. The main objective of this E-health system is to provide health care with the help of sustainable and realistic machine learning technologies.
 
 
 METHODS
 In this research, for the disease identification part, machine learning techniques have been applied to identify three diseases which are Dengue, Diabetes, and Thyroid. Decision Tree, Gaussian Naive-Bayes, Random Forest, Logistic Regression, k-Nearest Neighbors, Multilayer Perceptron, and Support Vector Machine Classifiers have been used for all three diseases. The E-health system comprised of disease identification model, medical specialist recommendation model, and the medicine suggestion model has been deployed on the web. The medical specialist recommendation model and the medicine suggestion model results are based on the finding of the disease identification model. Any user can insert their disease-specific data to use these three features of the E-health system.
 
 
 RESULTS
 For the disease identification model, Multilayer Perceptron for Dengue, Logistic Regression for Diabetes, and Random Forest for Thyroid performed the best with accuracies of 88.3%, 82.5%, and 98.5% respectively. These classifiers also showed good precision, recall, and F1 score.
 
 
 CONCLUSIONS
 The E-health system has performed well with real-time data. By making the dataset more enriched, the disease identification model will be more robust and thorough. Moreover, usability and acceptance tests can help us in finding different real-time scenarios of the E-health system.
",,2020,10.2196/preprints.23368,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a89fa53a26b66fcbac7dd2e3524715eeb284f513,https://www.semanticscholar.org/paper/a89fa53a26b66fcbac7dd2e3524715eeb284f513,Do no harm: a roadmap for responsible machine learning for health care,,Nature Medicine,2019,10.1038/s41591-019-0548-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5f0f6614e1a8d5e9d4edac7e1c7c5451e8bf2f85,https://www.semanticscholar.org/paper/5f0f6614e1a8d5e9d4edac7e1c7c5451e8bf2f85,Machine‐Learning‐Assisted Autonomous Humidity Management System Based on Solar‐Regenerated Super Hygroscopic Complex,"High levels of humidity can induce thermal discomfort and consequent health disorders. However, proper utilization of this astounding resource as a freshwater source can aid in alleviating water scarcity. Herein, a low‐energy and highly efficient humidity control system is reported comprising of an in‐house developed desiccant dehumidifier and hygrometer (sensor), with an autonomous operation capability that can realize simultaneous dehumidification and freshwater production. The high efficiency and energy saving mainly come from the deployed super hygroscopic complex (SHC), which exhibits high water uptake (4.64 g g−1) and facile regeneration. Machine‐learning‐assisted in‐house developed low cost and high precision hygrometers enable the autonomous operation of the humidity management system. The dehumidifier can reduce the relative humidity (RH) of a confined room from 75% to 60% in 15 minutes with energy consumption of 0.05 kWh, saving more than 60% of energy compared with the commercial desiccant dehumidifiers, and harvest 10 L of atmospheric water in 24 h. Moreover, the reduction in RH from 80% to 60% at 32 °C results in the reduction of apparent temperature by about 7 °C, thus effectively improving the thermal comfort of the inhabitants.",Advanced science,2021,10.1002/advs.202003939,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e9c68e94fa6c1937768beda6a771568aaf19ecc4,https://www.semanticscholar.org/paper/e9c68e94fa6c1937768beda6a771568aaf19ecc4,Machine learning techniques as an efficient alternative diagnostic tool for COVID-19 cases,"*Correspondence victor.leiva@pucv.cl; victorleivasanchez@gmail.com (Víctor Leiva) Abstract Background: The SARS-CoV-2 virus has demonstrated the weakness of many health systems worldwide, creating a saturation and lack of access to treatments. A bottleneck to fight this pandemic relates to the lack of diagnostic infrastructure for early detection of positive cases, particularly in rural and impoverished areas of developing countries. In this context, less costly and fast machine learning (ML) diagnosis-based systems are helpful. However, most of the research has focused on deep-learning techniques for diagnosis, which are computationally and technologically expensive. ML models have been mainly used as a benchmark and are not entirely explored in the existing literature on the topic of this paper. Objective: To analyze the capabilities of ML techniques (compared to deep learning) to diagnose COVID-19 cases based on X-ray images, assessing the performance of these techniques and using their predictive power for such a diagnosis. Methods: A factorial experiment was designed to establish this power with X-ray chest images of healthy, pneumonia, and COVID-19 infected patients. This design considers data-balancing methods, feature extraction approaches, different algorithms, and hyperparameter optimization. The ML techniques were evaluated based on classification metrics, including accuracy, the area under the receiver operating characteristic curve (AUROC), F1-score, sensitivity, and specificity. Results: The design of experiment provided the mean and its confidence intervals for the predictive capability of different ML techniques, which reached AUROC values as high as 90% with suitable sensitivity and specificity. Among the learning algorithms, support vector machines and random forest performed best. The down-sampling method for unbalanced data improved the predictive power significantly for the images used in this study. Conclusions: Our investigation demonstrated that ML techniques are able to identify COVID-19 infected patients. The results provided suitable values of sensitivity and specificity, minimizing the false-positive or false-negative rates. The models were trained with significantly low computational resources, which helps to provide access and deployment in rural and impoverished areas.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
71a85e735a3686bef8cce3725ae5ba82e2cabb1b,https://www.semanticscholar.org/paper/71a85e735a3686bef8cce3725ae5ba82e2cabb1b,Underspecification Presents Challenges for Credibility in Modern Machine Learning,"ML models often exhibit unexpectedly poor behavior when they are deployed in real-world domains. We identify underspecification as a key reason for these failures. An ML pipeline is underspecified when it can return many predictors with equivalently strong held-out performance in the training domain. Underspecification is common in modern ML pipelines, such as those based on deep learning. Predictors returned by underspecified pipelines are often treated as equivalent based on their training domain performance, but we show here that such predictors can behave very differently in deployment domains. This ambiguity can lead to instability and poor model behavior in practice, and is a distinct failure mode from previously identified issues arising from structural mismatch between training and deployment domains. We show that this problem appears in a wide variety of practical ML pipelines, using examples from computer vision, medical imaging, natural language processing, clinical risk prediction based on electronic health records, and medical genomics. Our results show the need to explicitly account for underspecification in modeling pipelines that are intended for real-world deployment in any domain.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8a007c2bf105f9e3418ccd639354865f6de5da35,https://www.semanticscholar.org/paper/8a007c2bf105f9e3418ccd639354865f6de5da35,Leveraging Mobile Sensing and Machine Learning for Personalized Mental Health Care,"Mental illness is widespread in our society, yet remains difficult to treat due to challenges such as stigma and overburdened health care systems. New paradigms are needed for treating mental illness outside the practitioner’s office. We propose a framework to guide the design of mobile sensing systems for personalized mental health interventions. This framework guides researchers in constructing interventions from the ground up through four phases: sensor data collection, digital biomarker extraction, health state detection, and intervention deployment. We highlight how this framework advances research in personalized mHealth and address remaining challenges, such as ground truth fidelity and missing data.",,2020,10.1177/1064804620920494,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fc2eb1de019dbc74bfdb96d6685a29cca1bc8446,https://www.semanticscholar.org/paper/fc2eb1de019dbc74bfdb96d6685a29cca1bc8446,Machine Learning in Health Care: A Critical Appraisal of Challenges and Opportunities,"Examples of fully integrated machine learning models that drive clinical care are rare. Despite major advances in the development of methodologies that outperform clinical experts and growing prominence of machine learning in mainstream medical literature, major challenges remain. At Duke Health, we are in our fourth year developing, piloting, and implementing machine learning technologies in clinical care. To advance the translation of machine learning into clinical care, health system leaders must address barriers to progress and make strategic investments necessary to bring health care into a new digital age. Machine learning can improve clinical workflows in subtle ways that are distinct from how statistics has shaped medicine. However, most machine learning research occurs in siloes, and there are important, unresolved questions about how to retrain and validate models post-deployment. Academic medical centers that cultivate and value transdisciplinary collaboration are ideally suited to integrate machine learning in clinical care. Along with fostering collaborative environments, health system leaders must invest in developing new capabilities within the workforce and technology infrastructure beyond standard electronic health records. Now is the opportunity to break down barriers and achieve scalable growth in the number of high-impact collaborations between clinical researchers and machine learning experts to transform clinical care.",EGEMS,2019,10.5334/egems.287,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
963e0db9a56a7eae52279a81b9d22c0f205928b5,https://www.semanticscholar.org/paper/963e0db9a56a7eae52279a81b9d22c0f205928b5,Comparison of machine learning methods for predicting viral failure: a case study using electronic health record data,"Abstract Background Human immunodeficiency virus (HIV) viral failure occurs when antiretroviral therapy fails to suppress and sustain a person’s viral load count below 1,000 copies of viral ribonucleic acid per milliliter. For those newly diagnosed with HIV and living in a setting where healthcare resources are limited, such as a low- and middle-income country, the World Health Organization recommends viral load monitoring six months after initiation of antiretroviral treatment and yearly thereafter. Deviations from this schedule are made in cases where viral failure occurs or at the discretion of the clinician. Failure to detect viral failure in a timely fashion can lead to delayed administration of essential interventions. Clinical prediction models based on information available in the patient medical record are increasingly being developed and deployed for decision support in clinical medicine and public health. This raises the possibility that prediction models can be used to detect potential for viral failure in advance of viral measurements, particularly when those measurements occur infrequently. Objective Our goal is to use electronic health record data from a large HIV care program in Kenya to characterize and compare the predictive accuracy of several statistical machine learning methods for predicting viral failure at the first and second measurements following initiation of antiretroviral therapy. Predictive accuracy is measured in terms of sensitivity, specificity and area under the receiver-operator characteristic curve. Methods We trained and cross-validated 10 statistical machine learning models and algorithms on data from over 10,000 patients in the Academic Model Providing Access to Healthcare care program in western Kenya. These included parametric, non-parametric, ensemble, and Bayesian methods. The input variables included 50 items from the clinical record, hand picked in consultation with clinician experts. Predictive accuracy measures were calculated using 10-fold cross validation. Results Viral load failure rate is about 20% in this patient cohort at both the first and second measurements. Ensemble techniques generally outperformed other methods. For predicting viral failure at the first follow up measure, specificity was over 90% for these methods, but sensitivity was typically in the 50–60% range. Predictive accuracy was greater for the second follow up measure, with sensitivities over 80%. Super Learner, gradient boosting and Bayesian additive regression trees consistently outperformed other methods. For a viral failure rate of 20%, the positive predictive value for the top-performing methods is between 75 and 85%, while the negative predictive value is over 95%. Conclusion Evidence from this study suggests that machine learning techniques have potential to identify patients at risk for viral failure prior to their scheduled measurements. Ultimately, prognostic virologic assessment can help guide the administration of earlier targeted intervention such as enhanced drug resistance monitoring, rigorous adherence counseling, or appropriate next-line therapy switching. External validation studies should be used to confirm the results found here.",,2020,10.1515/scid-2019-0017,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
19552c33b6144ba9cf02b52310cfdccdc66b14f2,https://www.semanticscholar.org/paper/19552c33b6144ba9cf02b52310cfdccdc66b14f2,Empirical observation of negligible fairness-accuracy trade-offs in machine learning for public policy,,Nat. Mach. Intell.,2020,10.1038/s42256-021-00396-x,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5beff11072de25e9be72bd02acc2215a254566e4,https://www.semanticscholar.org/paper/5beff11072de25e9be72bd02acc2215a254566e4,A Blockchain and Machine Learning-Based Drug Supply Chain Management and Recommendation System for Smart Pharmaceutical Industry,"From the last decade, pharmaceutical companies are facing difficulties in tracking their products during the supply chain process, allowing the counterfeiters to add their fake medicines into the market. Counterfeit drugs are analyzed as a very big challenge for the pharmaceutical industry worldwide. As indicated by the statistics, yearly business loss of around $200 billion is reported by US pharmaceutical companies due to these counterfeit drugs. These drugs may not help the patients to recover the disease but have many other dangerous side effects. According to the World Health Organization (WHO) survey report, in under-developed countries every 10th drug use by the consumers is counterfeit and has low quality. Hence, a system that can trace and track drug delivery at every phase is needed to solve the counterfeiting problem. The blockchain has the full potential to handle and track the supply chain process very efficiently. In this paper, we have proposed and implemented a novel blockchain and machine learning-based drug supply chain management and recommendation system (DSCMR). Our proposed system consists of two main modules: blockchain-based drug supply chain management and machine learning-based drug recommendation system for consumers. In the first module, the drug supply chain management system is deployed using Hyperledger fabrics which is capable of continuously monitor and track the drug delivery process in the smart pharmaceutical industry. On the other hand, the N-gram, LightGBM models are used in the machine learning module to recommend the top-rated or best medicines to the customers of the pharmaceutical industry. These models have trained on well known publicly available drug reviews dataset provided by the UCI: an open-source machine learning repository. Moreover, the machine learning module is integrated with this blockchain system with the help of the REST API. Finally, we also perform several tests to check the efficiency and usability of our proposed system.",Electronics,2020,10.3390/electronics9050852,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29b224f905d81046e8439b0801cacd2ec07a58ad,https://www.semanticscholar.org/paper/29b224f905d81046e8439b0801cacd2ec07a58ad,From Reflection to Action: Combining Machine Learning with Expert Knowledge for Nutrition Goal Recommendations,"Self-tracking can help personalize self-management interventions for chronic conditions like type 2 diabetes (T2D), but reflecting on personal data requires motivation and literacy. Machine learning (ML) methods can identify patterns, but a key challenge is making actionable suggestions based on personal health data. We introduce GlucoGoalie, which combines ML with an expert system to translate ML output into personalized nutrition goal suggestions for individuals with T2D. In a controlled experiment, participants with T2D found that goal suggestions were understandable and actionable. A 4-week in-the-wild deployment study showed that receiving goal suggestions augmented participants’ self-discovery, choosing goals highlighted the multifaceted nature of personal preferences, and the experience of following goals demonstrated the importance of feedback and context. However, we identified tensions between abstract goals and concrete eating experiences and found static text too ambiguous for complex concepts. We discuss implications for ML-based interventions and the need for systems that offer more interactivity, feedback, and negotiation.",CHI,2021,10.1145/3411764.3445555,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
14bb101f6127ddb3cee3ed97d47d4976ef669ddb,https://www.semanticscholar.org/paper/14bb101f6127ddb3cee3ed97d47d4976ef669ddb,"Solution to Detect, Classify, and Report Illicit Online Marketing and Sales of Controlled Substances via Twitter: Using Machine Learning and Web Forensics to Combat Digital Opioid Access","Background On December 6 and 7, 2017, the US Department of Health and Human Services (HHS) hosted its first Code-a-Thon event aimed at leveraging technology and data-driven solutions to help combat the opioid epidemic. The authors—an interdisciplinary team from academia, the private sector, and the US Centers for Disease Control and Prevention—participated in the Code-a-Thon as part of the prevention track. Objective The aim of this study was to develop and deploy a methodology using machine learning to accurately detect the marketing and sale of opioids by illicit online sellers via Twitter as part of participation at the HHS Opioid Code-a-Thon event. Methods Tweets were collected from the Twitter public application programming interface stream filtered for common prescription opioid keywords in conjunction with participation in the Code-a-Thon from November 15, 2017 to December 5, 2017. An unsupervised machine learning–based approach was developed and used during the Code-a-Thon competition (24 hours) to obtain a summary of the content of the tweets to isolate those clusters associated with illegal online marketing and sale using a biterm topic model (BTM). After isolating relevant tweets, hyperlinks associated with these tweets were reviewed to assess the characteristics of illegal online sellers. Results We collected and analyzed 213,041 tweets over the course of the Code-a-Thon containing keywords codeine, percocet, vicodin, oxycontin, oxycodone, fentanyl, and hydrocodone. Using BTM, 0.32% (692/213,041) tweets were identified as being associated with illegal online marketing and sale of prescription opioids. After removing duplicates and dead links, we identified 34 unique “live” tweets, with 44% (15/34) directing consumers to illicit online pharmacies, 32% (11/34) linked to individual drug sellers, and 21% (7/34) used by marketing affiliates. In addition to offering the “no prescription” sale of opioids, many of these vendors also sold other controlled substances and illicit drugs. Conclusions The results of this study are in line with prior studies that have identified social media platforms, including Twitter, as a potential conduit for supply and sale of illicit opioids. To translate these results into action, authors also developed a prototype wireframe for the purposes of detecting, classifying, and reporting illicit online pharmacy tweets selling controlled substances illegally to the US Food and Drug Administration and the US Drug Enforcement Agency. Further development of solutions based on these methods has the potential to proactively alert regulators and law enforcement agencies of illegal opioid sales, while also making the online environment safer for the public.",Journal of medical Internet research,2018,10.2196/10029,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e70a454c517e64ab2d017e139b643e59db0b6a2f,https://www.semanticscholar.org/paper/e70a454c517e64ab2d017e139b643e59db0b6a2f,Machine Learning: The Next Paradigm Shift in Medical Education.,"Machine learning (ML) algorithms are powerful prediction tools with immense potential in the clinical setting. There are a number of existing clinical tools that utilize ML, and many more are in development. Physicians are important stakeholders in the health care system, but most are not equipped to make informed decisions regarding deployment and application of ML technologies in patient care. It is of paramount importance that ML concepts are integrated into medical curricula to position physicians to become informed consumers of the emerging tools employing ML. This paradigm shift is similar to the evidence-based medicine (EBM) movement of the 1990s. At that time, EBM was a novel concept; now EBM is considered an essential component of medical curricula and critical to the provision of high-quality patient care. ML has the potential to have a similar, if not greater, impact on the practice of medicine. As this technology continues its inexorable march forward, we must continue to evaluate medical curricula to ensure that physicians are trained to be informed stakeholders in the health care of tomorrow.",Academic medicine : journal of the Association of American Medical Colleges,2021,10.1097/ACM.0000000000003943,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
024b960a1d833e495f0230c3d789571dae7ec0b1,https://www.semanticscholar.org/paper/024b960a1d833e495f0230c3d789571dae7ec0b1,Interpretability of Machine Learning Solutions in Public Healthcare: The CRISP-ML Approach,"Public healthcare has a history of cautious adoption for artificial intelligence (AI) systems. The rapid growth of data collection and linking capabilities combined with the increasing diversity of the data-driven AI techniques, including machine learning (ML), has brought both ubiquitous opportunities for data analytics projects and increased demands for the regulation and accountability of the outcomes of these projects. As a result, the area of interpretability and explainability of ML is gaining significant research momentum. While there has been some progress in the development of ML methods, the methodological side has shown limited progress. This limits the practicality of using ML in the health domain: the issues with explaining the outcomes of ML algorithms to medical practitioners and policy makers in public health has been a recognized obstacle to the broader adoption of data science approaches in this domain. This study builds on the earlier work which introduced CRISP-ML, a methodology that determines the interpretability level required by stakeholders for a successful real-world solution and then helps in achieving it. CRISP-ML was built on the strengths of CRISP-DM, addressing the gaps in handling interpretability. Its application in the Public Healthcare sector follows its successful deployment in a number of recent real-world projects across several industries and fields, including credit risk, insurance, utilities, and sport. This study elaborates on the CRISP-ML methodology on the determination, measurement, and achievement of the necessary level of interpretability of ML solutions in the Public Healthcare sector. It demonstrates how CRISP-ML addressed the problems with data diversity, the unstructured nature of data, and relatively low linkage between diverse data sets in the healthcare domain. The characteristics of the case study, used in the study, are typical for healthcare data, and CRISP-ML managed to deliver on these issues, ensuring the required level of interpretability of the ML solutions discussed in the project. The approach used ensured that interpretability requirements were met, taking into account public healthcare specifics, regulatory requirements, project stakeholders, project objectives, and data characteristics. The study concludes with the three main directions for the development of the presented cross-industry standard process.",Frontiers in Big Data,2021,10.3389/fdata.2021.660206,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5856e2a77cdcde9346a6b1a02e67588166904727,https://www.semanticscholar.org/paper/5856e2a77cdcde9346a6b1a02e67588166904727,Towards Secure Fitness Framework Based on IoT-Enabled Blockchain Network Integrated with Machine Learning Algorithms,"Blockchain technology has recently inspired remarkable attention due to its unique features, such as privacy, accountability, immutability, and anonymity, to name of the few. In contrast, core functionalities of most Internet of Things (IoT) resources make them vulnerable to security threats. The IoT devices, such as smartphones and tablets, have limited capacity in terms of network, computing, and storage, which make them easier for vulnerable threats. Furthermore, a massive amount of data produced by the IoT devices, which is still an open challenge for the existing platforms to process, analyze, and unearth underlying patterns to provide convenience environment. Therefore, a new solution is required to ensure data accountability, improve data privacy and accessibility, and extract hidden patterns and useful knowledge to provide adequate services. In this paper, we present a secure fitness framework that is based on an IoT-enabled blockchain network integrated with machine learning approaches. The proposed framework consists of two modules: a blockchain-based IoT network to provide security and integrity to sensing data as well as an enhanced smart contract enabled relationship and inference engine to discover hidden insights and useful knowledge from IoT and user device network data. The enhanced smart contract aims to support users with a practical application that provides real-time monitoring, control, easy access, and immutable logs of multiple devices that are deployed in several domains. The inference engine module aims to unearth underlying patterns and useful knowledge from IoT environment data, which helps in effective decision making to provide convenient services. For experimental analysis, we implement an intelligent fitness service that is based on an enhanced smart contract enabled relationship and inference engine as a case study where several IoT fitness devices are used to securely acquire user personalized fitness data. Furthermore, a real-time inference engine investigates user personalized data to discover useful knowledge and hidden insights. Based on inference engine knowledge, a recommendation model is developed to recommend a daily and monthly diet, as well as a workout plan for better and improved body shape. The recommendation model aims to facilitate a trainer formulating effective future decisions of trainee’s health in terms of a diet and workout plan. Lastly, for performance analysis, we have used Hyperledger Caliper to access the system performance in terms of latency, throughput, resource utilization, and varying orderer and peers nodes. The analysis results imply that the design architecture is applicable for resource-constrained IoT blockchain platform and it is extensible for different IoT scenarios.",Sensors,2021,10.3390/s21051640,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
90a23dc941922353d44199e111bbc2982b9cbf2b,https://www.semanticscholar.org/paper/90a23dc941922353d44199e111bbc2982b9cbf2b,Deploying Machine Learning Models Using Progressive Web Applications: Implementation Using a Neural Network Prediction Model for Pneumonia Related Child Mortality in The Gambia,"Background Translating research outputs into practical tools for medical practitioners is a neglected area and could have a substantial impact. One of the barriers to implementing artificial intelligence (AI) and machine learning (ML) applications is their practical deployment in the field. Traditional web-based (i.e., server sided) applications are dependent on reliable internet connections, which may not be readily available in rural areas. Native mobile apps require device specific programming skills as well as contemporary hardware and software, with often rapid and unpredictable platform specific changes. This is a major challenge for using AI/ML tools in resource-limited settings. Methods An emerging technology, progressive web applications (PWAs), first introduced by Google in 2015, offers an opportunity to overcome the challenges of deploying bespoke AI/ML systems. The same PWA code can be implemented across all desktop platforms, iOS and Android phones and tablets. In addition to platform independence, a PWA can be designed to be primarily offline. Results We demonstrate how a neural network-based pneumonia mortality prediction triage tool was migrated from a typical academic framework (paper and web-based prototype) to a tool that can be used offline on any mobile phone—the most convenient deployment vehicle. After an initial online connection to download the software, the application runs entirely offline, reading data from cached memory, and running code via JavaScript. On mobile devices the application is installed as a native app, without the inconvenience of platform specific code through manufacturer code stores. Discussion We show that an ML application can be deployed as a platform independent offline PWA using a pneumonia-related child mortality prediction tool as an example. The aim of this tool was to assist clinical staff in triaging children for hospital admission, by predicting their risk of death. PWAs function seamlessly when their host devices lose internet connectivity, making them ideal for e-health apps that can help improve health and save lives in resource-limited settings in line with the UN Sustainable Development Goal 3 (SDG3).",Frontiers in Public Health,2022,10.3389/fpubh.2021.772620,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ccca5e0fb18324d015e74d641d36f9ce21af860b,https://www.semanticscholar.org/paper/ccca5e0fb18324d015e74d641d36f9ce21af860b,"The COVID-19 Pandemic Vulnerability Index (PVI) Dashboard: Monitoring county-level vulnerability using visualization, statistical modeling, and machine learning","While the COVID-19 pandemic presents a global challenge, the U.S. response places substantial responsibility for both decision-making and communication on local health authorities. To better support counties and municipalities, we integrated baseline data on relevant community vulnerabilities with dynamic data on local infection rates and interventions into a Pandemic Vulnerability Index (PVI). The PVI presents a visual synthesis of county-level vulnerability indicators that can be compared in a regional, state, or nationwide context. We describe use of the PVI, supporting epidemiological modeling and machine-learning forecasts, and deployment of an interactive, web Dashboard. The Dashboard facilitates decision-making and communication among government officials, scientists, community leaders, and the public to enable more effective and coordinated action to combat the pandemic.",medRxiv,2020,10.1101/2020.08.10.20169649,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6aa1b5306adac2fae9f1a2eb614e443cbf13606b,https://www.semanticscholar.org/paper/6aa1b5306adac2fae9f1a2eb614e443cbf13606b,Machine Learning in Food Safety,"Food safety continues to threaten public health. Machine learning holds potential in leveraging large, emerging data sets to improve the safety of the food supply and mitigate the impact of food safety incidents. Foodborne pathogen genomes and novel data streams, including text, transactional, and trade data, have seen emerging applications enabled by a machine learning approach, such as prediction of antibiotic resistance, source attribution of pathogens, and foodborne outbreak detection and risk assessment. In this article, we provide a gentle introduction to machine learning in the context of food safety and an overview of recent developments and applications. With many of these applications still in their nascence, general and domainspecific pitfalls and challenges associated with machine learning have begun to be recognized and addressed, which are critical to prospective use and future deployment of large data sets and their associated machine learning models for food safety applications.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dcbf6137fe16b33c2e2d9258bd4a1e3cdabee48f,https://www.semanticscholar.org/paper/dcbf6137fe16b33c2e2d9258bd4a1e3cdabee48f,Feature Robustness in Non-stationary Health Records: Caveats to Deployable Model Performance in Common Clinical Machine Learning Tasks,"When training clinical prediction models from electronic health records (EHRs), a key concern should be a model's ability to sustain performance over time when deployed, even as care practices, database systems, and population demographics evolve. Due to de-identification requirements, however, current experimental practices for public EHR benchmarks (such as the MIMIC-III critical care dataset) are time agnostic, assigning care records to train or test sets without regard for the actual dates of care. As a result, current benchmarks cannot assess how well models trained on one year generalise to another. In this work, we obtain a Limited Data Use Agreement to access year of care for each record in MIMIC and show that all tested state-of-the-art models decay in prediction quality when trained on historical data and tested on future data, particularly in response to a system-wide record-keeping change in 2008 (0.29 drop in AUROC for mortality prediction, 0.10 drop in AUROC for length-of-stay prediction with a random forest classifier). We further develop a simple yet effective mitigation strategy: by aggregating raw features into expert-defined clinical concepts, we see only a 0.06 drop in AUROC for mortality prediction and a 0.03 drop in AUROC for length-of-stay prediction. We demonstrate that this aggregation strategy outperforms other automatic feature preprocessing techniques aimed at increasing robustness to data drift. We release our aggregated representations and code to encourage more deployable clinical prediction models.",MLHC,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
87407e4f7cc0a71249242c44ca42014fcf892783,https://www.semanticscholar.org/paper/87407e4f7cc0a71249242c44ca42014fcf892783,Fetal health classification from cardiotocographic data using machine learning,"Health complications during the gestation period have evolved as a global issue. These complications sometimes result in the mortality of the fetus, which is more prevalent in developing and underdeveloped countries. The genesis of machine learning (ML) algorithms in the healthcare domain have brought remarkable progress in disease diagnosis, treatment, and prognosis. This research deploys various ML algorithms to predict fetal health from the cardiotocographic (CTG) data by labelling the health state into normal, needs guarantee, and pathology. This work assesses the influence of various factors measured through CTG to predict the health state of the fetus through algorithms like support vector machine, random forest (RF), multi‐layer perceptron, and K‐nearest neighbours. In addition to this, the regression analysis and correlation analysis revealed the influence of the attributes on fetal health. The results of the algorithms show that RF performs better than its peers in terms of accuracy, precision, recall, F1‐score, and support. This work can further enhance more promising results by performing suitable feature engineering in the CTG data.",Expert Syst. J. Knowl. Eng.,2021,10.1111/exsy.12899,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4fca4983b6267df2613f6ed3b05e82e2fbc3b89f,https://www.semanticscholar.org/paper/4fca4983b6267df2613f6ed3b05e82e2fbc3b89f,Feature-Based Machine Learning Model for Real-Time Hypoglycemia Prediction,"Background: Hypoglycemia is a serious health concern in youth with type 1 diabetes (T1D). Real-time data from continuous glucose monitoring (CGM) can be used to predict hypoglycemic risk, allowing patients to take timely intervention measures. Methods: A machine learning model is developed for probabilistic prediction of hypoglycemia (<70 mg/dL) in 30- and 60-minute time horizons based on CGM datasets obtained from 112 patients over a range of 90 days consisting of over 1.6 million CGM values under normal living conditions. A comprehensive set of features relevant for hypoglycemia are developed and a parsimonious subset with most influence on predicting hypoglycemic risk is identified. Model performance is evaluated both with and without contextual information on insulin and carbohydrate intake. Results: The model predicted hypoglycemia with >91% sensitivity for 30- and 60-minute prediction horizons while maintaining specificity >90%. Inclusion of insulin and carbohydrate data yielded performance improvement for 60-minute but not for 30-minute predictions. Model performance was highest for nocturnal hypoglycemia (~95% sensitivity). Shortterm (less than one hour) and medium-term (one to four hours) features for good prediction performance are identified. Conclusions: Innovative feature identification facilitated high performance for hypoglycemia risk prediction in pediatric youth with T1D. Timely alerts of impending hypoglycemia may enable proactive measures to avoid severe hypoglycemia and achieve optimal glycemic control. The model will be deployed on a patient-facing smartphone application in an upcoming pilot study.",Journal of diabetes science and technology,2020,10.1177/1932296820922622,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
32dfa69195e363db0772768a4cd87db3d4c5c6f9,https://www.semanticscholar.org/paper/32dfa69195e363db0772768a4cd87db3d4c5c6f9,Machine learning and health need better values,,npj Digital Medicine,2022,10.1038/s41746-022-00595-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
80ce4076be9ad66bd50feb33eafa1b7acde4c271,https://www.semanticscholar.org/paper/80ce4076be9ad66bd50feb33eafa1b7acde4c271,Exploring the Potential of Artificial Intelligence and Machine Learning to Combat COVID-19 and Existing Opportunities for LMIC: A Scoping Review,"Background: In the face of the current time-sensitive COVID-19 pandemic, the limited capacity of healthcare systems resulted in an emerging need to develop newer methods to control the spread of the pandemic. Artificial Intelligence (AI), and Machine Learning (ML) have a vast potential to exponentially optimize health care research. The use of AI-driven tools in LMIC can help in eradicating health inequalities and decrease the burden on health systems. Methods: The literature search for this Scoping review was conducted through the PubMed database using keywords: COVID-19, Artificial Intelligence (AI), Machine Learning (ML), and Low Middle-Income Countries (LMIC). Forty-three articles were identified and screened for eligibility and 13 were included in the final review. All the items of this Scoping review are reported using guidelines for PRISMA extension for scoping reviews (PRISMA-ScR). Results: Results were synthesized and reported under 4 themes. (a) The need of AI during this pandemic: AI can assist to increase the speed and accuracy of identification of cases and through data mining to deal with the health crisis efficiently, (b) Utility of AI in COVID-19 screening, contact tracing, and diagnosis: Efficacy for virus detection can a be increased by deploying the smart city data network using terminal tracking system along-with prediction of future outbreaks, (c) Use of AI in COVID-19 patient monitoring and drug development: A Deep learning system provides valuable information regarding protein structures associated with COVID-19 which could be utilized for vaccine formulation, and (d) AI beyond COVID-19 and opportunities for Low-Middle Income Countries (LMIC): There is a lack of financial, material, and human resources in LMIC, AI can minimize the workload on human labor and help in analyzing vast medical data, potentiating predictive and preventive healthcare. Conclusion: AI-based tools can be a game-changer for diagnosis, treatment, and management of COVID-19 patients with the potential to reshape the future of healthcare in LMIC.",Journal of primary care & community health,2020,10.1177/2150132720963634,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6cf64152a29a0871427cb1aa8883a86019a6058d,https://www.semanticscholar.org/paper/6cf64152a29a0871427cb1aa8883a86019a6058d,Reporting and Implementing Interventions Involving Machine Learning and Artificial Intelligence,"Increasingly, interventions aimed at improving care are likely to use such technologies as machine learning and artificial intelligence. However, health care has been relatively late to adopt them. This article provides clinical examples in which machine learning and artificial intelligence are already in use in health care and appear to deliver benefit. Three key bottlenecks toward increasing the pace of diffusion and adoption are methodological issues in evaluation of artificial intelligence-based interventions, reporting standards to enable assessment of model performance, and issues that need to be addressed for an institution to adopt these interventions. Methodological best practices will include external validation, ideally at a different site; use of proactive learning algorithms to correct for site-specific biases and increase robustness as algorithms are deployed across multiple sites; addressing subgroup performance; and communicating to providers the uncertainty of predictions. Regarding reporting, especially important issues are the extent to which implementing standardized approaches for introducing clinical decision support has been followed, describing the data sources, reporting on data assumptions, and addressing biases. Although most health care organizations in the United States have adopted electronic health records, they may be ill prepared to adopt machine learning and artificial intelligence. Several steps can enable this: preparing data, developing tools to get suggestions to clinicians in useful ways, and getting clinicians engaged in the process. Open challenges and the role of regulation in this area are briefly discussed. Although these techniques have enormous potential to improve care and personalize recommendations for individuals, the hype regarding them is tremendous. Organizations will need to approach this domain carefully with knowledgeable partners to obtain the hoped-for benefits and avoid failures.",Annals of Internal Medicine,2020,10.7326/M19-0872,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
91822b42b516bdcaeefc6475e9a5fb1566e80e78,https://www.semanticscholar.org/paper/91822b42b516bdcaeefc6475e9a5fb1566e80e78,Moving from predicting hospital deaths by antibiotic-resistant bloodstream bacteremia toward actionable risk reduction using machine learning on electronic health records.,"Drug-resistant bacterial infections are a global health concern with high mortality and limited treatment options. Several clinical risk-severity scores are available, e.g. qPitt, but their predictive performance is moderate. Here, we leveraged machine learning and electronic health records (EHRs) to improve prediction of mortality due to bloodstream infection with Klebsiella pneumoniae. We tested the qPitt score and new EHR variables (either expert-chosen or the full set of diagnostic codes), fitting LASSO, boosted logistic regression (BLR), support vector machines, decision trees, and random forests. The qPitt score showed moderate discriminative ability (AUROC=0.63), whilst machine learning models significantly improved its performance (best AUROC by BLR 0.80 for expert-chosen and 0.88 for full code set). Similar results were obtained in critically ill patients, and when excluding potential non-causal variables to evaluate an actionable model. In conclusion, current risk scores for bacteremia mortality can be improved and, with opportune causal modelling, considered for deployment in clinical decision-making.",AMIA ... Annual Symposium proceedings. AMIA Symposium,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
45abecc9a8eb32b7f953cdd1de1751bbd9b6f222,https://www.semanticscholar.org/paper/45abecc9a8eb32b7f953cdd1de1751bbd9b6f222,Design and Deployment of E-Health System Using Machine Learning in the Perspective of Developing Countries,"Machine learning is tightening its grasp on many sectors of modern life and medical sector is not an exception. In developing countries like Bangladesh, disease classification process mostly remains manual, time consuming and sometimes erroneous. Designing an E-health system comprised of disease identification model would be a great aid in such circumstances. The automation of identifying the diseases with the help of machine learning will be more accurate and time-saving. In this paper, Decision Tree, Gaussian Naive-Bayes, Random Forest, Logistic Regression, k-NN, MLP, and SVM machine learning techniques are applied for three diseases: Dengue, Diabetes, and Thyroid. MLP for Dengue, Logistic Regression for Diabetes, and Random Forest for Thyroid performed the best with accuracies of 88.3%, 82.5%, and 98.5% respectively. Additionally, a medical specialist recommendation model and a medicine suggestion model are also integrated in the proposed E-Health system.",Int. J. Ambient Comput. Intell.,2022,10.4018/ijaci.293186,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9dd44cc1320e8131aa640515d708675fcb8c1b4c,https://www.semanticscholar.org/paper/9dd44cc1320e8131aa640515d708675fcb8c1b4c,Machine learning for sperm selection,,Nature Reviews Urology,2021,10.1038/s41585-021-00465-1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dbfb7d4fec48614409b8c5af0659eaf2054b805a,https://www.semanticscholar.org/paper/dbfb7d4fec48614409b8c5af0659eaf2054b805a,"Use of machine learning to predict clinical decision support compliance, reduce alert burden, and evaluate duplicate laboratory test ordering alerts","Abstract Objectives While well-designed clinical decision support (CDS) alerts can improve patient care, utilization management, and population health, excessive alerting may be counterproductive, leading to clinician burden and alert fatigue. We sought to develop machine learning models to predict whether a clinician will accept the advice provided by a CDS alert. Such models could reduce alert burden by targeting CDS alerts to specific cases where they are most likely to be effective. Materials and Methods We focused on a set of laboratory test ordering alerts, deployed at 8 hospitals within the Partners Healthcare System. The alerts notified clinicians of duplicate laboratory test orders and advised discontinuation. We captured key attributes surrounding 60 399 alert firings, including clinician and patient variables, and whether the clinician complied with the alert. Using these data, we developed logistic regression models to predict alert compliance. Results We identified key factors that predicted alert compliance; for example, clinicians were less likely to comply with duplicate test alerts triggered in patients with a prior abnormal result for the test or in the context of a nonvisit-based encounter (eg, phone call). Likewise, differences in practice patterns between clinicians appeared to impact alert compliance. Our best-performing predictive model achieved an area under the receiver operating characteristic curve (AUC) of 0.82. Incorporating this model into the alerting logic could have averted more than 1900 alerts at a cost of fewer than 200 additional duplicate tests. Conclusions Deploying predictive models to target CDS alerts may substantially reduce clinician alert burden while maintaining most or all the CDS benefit.",JAMIA open,2021,10.1093/jamiaopen/ooab006,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
36d790db171ab31fc3afe37c0f5d179ee6ce82f5,https://www.semanticscholar.org/paper/36d790db171ab31fc3afe37c0f5d179ee6ce82f5,Handwork vs machine: a comparison of rheumatoid arthritis patient populations as identified from EHR free-text by diagnosis extraction through machine-learning or traditional criteria-based chart review,,Arthritis Research & Therapy,2021,10.1186/s13075-021-02553-4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8db18e7e722d808c7d9734478dbb3ecd1d19368d,https://www.semanticscholar.org/paper/8db18e7e722d808c7d9734478dbb3ecd1d19368d,Predicting special care during the COVID-19 pandemic: a machine learning approach,,Health Inf. Sci. Syst.,2020,10.1007/s13755-021-00164-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5bce98196285165c6a9f91162ff97e74c734729,https://www.semanticscholar.org/paper/a5bce98196285165c6a9f91162ff97e74c734729,Corona virus-related Disease Pandemic: A Review on Machine Learning Approaches and Treatment Trials on Diagnosed Population for Future Clinical Decision Support.,"OBJECTIVE
Corona virus-related disease, a deadly illness, has raised public health issues worldwide. The majority of individuals infected are multiplying. The government takes aggressive steps to quarantine people, people exposed to infection, and clinical trials for treatment. Subsequently recommends critical care for the aged, children, and health-care personnel. While machine learning methods have been previously used to augment clinical decisions, there is now a demand for ""Emergency ML."" With rapidly growing datasets, there also remain important considerations when developing and validating ML models.


METHODS
This paper reviews the recent study that applies machine-learning technology addressing Corona virus-related disease issues' challenges in different perspectives. The report also discusses various treatment trials and procedures on Corona virus-related disease infected patients providing insights to physicians and the public on the current treatment challenges.


RESULTS
The paper provides the individual with insights into certain precautions to prevent and control the spread of this deadly disease.


CONCLUSION
This review highlights the utility of evidence-based machine learning prediction tools in several clinical settings, and how similar models can be deployed during the Corona virus-related disease pandemic to guide hospital frontlines and health-care administrators to make informed decisions about patient care and managing hospital volume. Further, the clinical trials conducted so far for infected patients with Corona virus-related disease addresses their results to improve community alertness from the viewpoint of a well-known saying, ""prevention is always better.""",Current medical imaging,2021,10.2174/1573405617666210414101941,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
79ed93264645cc70a232e636c5c475874d049363,https://www.semanticscholar.org/paper/79ed93264645cc70a232e636c5c475874d049363,A Machine Learning SDN-Enabled Big Data Model for IoMT Systems,"In recent times, health applications have been gaining rapid popularity in smart cities using the Internet of Medical Things (IoMT). Many real-time solutions are giving benefits to both patients and professionals for remote data accessibility and suitable actions. However, timely medical decisions and efficient management of big data using IoT-based resources are the burning research challenges. Additionally, the distributed nature of data processing in many proposed solutions explicitly increases the threats of information leakages and damages the network integrity. Such solutions impose overhead on medical sensors and decrease the stability of the real-time transmission systems. Therefore, this paper presents a machine-learning model with SDN-enabled security to predict the consumption of network resources and improve the delivery of sensors data. Additionally, it offers centralized-based software define network (SDN) architecture to overcome the network threats among deployed sensors with nominal management cost. Firstly, it offers an unsupervised machine learning technique and decreases the communication overheads for IoT networks. Secondly, it predicts the link status using dynamic metrics and refines its strategies using SDN architecture. In the end, a security algorithm is utilized by the SDN controller that efficiently manages the consumption of the IoT nodes and protects it from unidentified occurrences. The proposed model is verified using simulations and improves system performance in terms of network throughput by 13%, data drop ratio by 39%, data delay by 11%, and faulty packets by 46% compared to HUNA and CMMA schemes.",Electronics,2021,10.3390/electronics10182228,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1406ff52d6d1af2a5111f8604f8c5c5d9039ad58,https://www.semanticscholar.org/paper/1406ff52d6d1af2a5111f8604f8c5c5d9039ad58,A comparison of general and disease-specific machine learning models for the prediction of unplanned hospital readmissions,"Unplanned hospital readmissions are a burden to patients and increase healthcare costs. A wide variety of machine learning (ML) models have been suggested to predict unplanned hospital readmissions. These ML models were often specifically trained on patient populations with certain diseases. However, it is unclear whether these specialized ML models-trained on patient subpopulations with certain diseases or defined by other clinical characteristics-are more accurate than a general ML model trained on an unrestricted hospital cohort. In this study based on an electronic health record cohort of consecutive inpatient cases of a single tertiary care center, we demonstrate that accurate prediction of hospital readmissions may be obtained by general, disease-independent, ML models. This general approach may substantially decrease the cost of development and deployment of respective ML models in daily clinical routine, as all predictions are obtained by the use of a single model.",J. Am. Medical Informatics Assoc.,2020,10.1093/jamia/ocaa299,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d011259cea1678c8cf65f0da00e189461dc79823,https://www.semanticscholar.org/paper/d011259cea1678c8cf65f0da00e189461dc79823,Identification of Tobacco Crop Based on Machine Learning for a Precision Agricultural Sprayer,"Agrochemicals, which are very efficacious in protecting crops, also cause environmental pollution and pose serious threats to farmers’ health upon exposure. In order to cut down the environmental and human health risks associated with agrochemical application, there is a need to develop intelligent application equipment that could detect and recognize crops/weeds, and spray precise doses of agrochemical at the right place and right time. This paper presents a machine-learning based crop/weed detection system for a tractor-mounted boom sprayer that could perform site-specific spraying on tobacco crop in fields. An SVM classifier with a carefully chosen feature combination (texture, shape, and color) for tobacco plant has been proposed and 96% classification accuracy has been achieved. The algorithm has been trained and tested on a real dataset collected in local fields with diverse changes in scale, orientation, background clutter, outdoor lighting conditions, and variation between tobacco and weeds. Performance comparison of the proposed algorithm has been made with a deep learning based classifier (customized for real-time inference). Both algorithms have been deployed on a tractor-mounted boom sprayer in tobacco fields and it has been concluded that the SVM classifier performs well in terms of accuracy (96%) and real-time inference (6 FPS) on an embedded device (Raspberry Pi 4). In comparison, the customized deep learning-based classifier has an accuracy of 100% but performs much slower (0.22 FPS) on the Raspberry Pi 4.",IEEE Access,2021,10.1109/ACCESS.2021.3056577,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f3860457c161448938ed746c8993e3df7b1e1560,https://www.semanticscholar.org/paper/f3860457c161448938ed746c8993e3df7b1e1560,Evolutionary Machine Learning Powered by Genetics Algorithm for IoT-Specific Health Monitoring of Agriculture Vehicles,,,2022,10.1007/978-981-16-3128-3_12,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
394dcb21edcd9526fea59e6555dcfb771e1ff0f3,https://www.semanticscholar.org/paper/394dcb21edcd9526fea59e6555dcfb771e1ff0f3,Development and assessment of a machine learning tool for predicting emergency admission in Scotland,"Avoiding emergency hospital admission (EA) is advantageous to individual health and the healthcare system. We develop a statistical model estimating risk of EA for most of the Scottish population (>4.8M individuals) using electronic health records, such as hospital episodes and prescribing activity. We demonstrate good predictive accuracy (AUROC 0.80), calibration and temporal stability. We find strong prediction of respiratory and metabolic EA, show a substantial risk contribution from socioeconomic decile, and highlight an important problem in model updating. Our work constitutes a rare example of a population-scale machine learning score to be deployed in a healthcare setting.",medRxiv,2021,10.1101/2021.08.06.21261593,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
736592b399830b5700f33e9e79300b52a2819f10,https://www.semanticscholar.org/paper/736592b399830b5700f33e9e79300b52a2819f10,Wireless medical sensor network for blood pressure monitoring based on machine learning for real-time data classification,,J. Ambient Intell. Humaniz. Comput.,2020,10.1007/s12652-020-02660-1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6a4634816609d113264696f6f4a40c9c74f6c867,https://www.semanticscholar.org/paper/6a4634816609d113264696f6f4a40c9c74f6c867,Combining machine learning and mathematical models of disease dynamics to guide development of novel disease interventions,"The development of novel interventions against a disease entails optimising their specifications to achieve desired health goals such as disease reduction. As testing is limited early in development, it is difficult to predefine these optimal specifications, prioritize or continue investment in candidate interventions. Mathematical models of disease can provide quantitative evidence as they can simulate deployment and predict impact of a new intervention considering deployment, health-system, population and disease characteristics. However, due to large uncertainty early in development, as well as model complexity, testing all possible combinations of interventions and deployments becomes infeasible. As a result, mathematical models have been only marginally used during intervention development to date. Here, we present a new approach where machine learning enables the use of detailed disease models to identify optimal properties of candidate interventions to reach a desired health goal and guide development. We demonstrate the power of our approach by application to five novel malaria interventions under development. For various targeted reductions of malaria prevalence, we quantify and rank intervention characteristics which are key determinants of health impact. Furthermore, we identify minimal requirements and tradeoffs between operational factors, intervention efficacy and duration to achieve different levels of impact and show how these vary across disease transmission settings. When single interventions cannot achieve significant impact, our method allows finding optimal combinations of interventions fulfilling the desired health goals. By enabling efficient use of disease models, our approach supports decision-making and resource investment in the development of new interventions for infectious diseases.",medRxiv,2021,10.1101/2021.01.05.21249283,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4def4fa4fdfc11140fca6874674dafd7713103c3,https://www.semanticscholar.org/paper/4def4fa4fdfc11140fca6874674dafd7713103c3,An Automated Machine Learning Classifier for Early Childhood Caries.,"Purpose: The purpose of the study was to develop and evaluate an automated machine learning algorithm (AutoML) for children's classification according to early childhood caries (ECC) status. Methods: Clinical, demographic, behavioral, and parent-reported oral health status information for a sample of 6,404 three- to five-year-old children (mean age equals 54 months) participating in an epidemiologic study of early childhood oral health in North Carolina was used. ECC prevalence (decayed, missing, and filled primary teeth surfaces [dmfs] score greater than zero, using an International Caries Detection and Assessment System score greater than or equal to three caries lesion detection threshold) was 54 percent. Ten sets of ECC predictors were evaluated for ECC classification accuracy (i.e., area under the ROC curve [AUC], sensitivity [Se], and positive predictive value [PPV]) using an AutoML deployment on Google Cloud, followed by internal validation and external replication. Results: A parsimonious model including two terms (i.e., children's age and parent-reported child oral health status: excellent/very good/good/fair/poor) had the highest AUC (0.74), Se (0.67), and PPV (0.64) scores and similar performance using an external National Health and Nutrition Examination Survey (NHANES) dataset (AUC equals 0.80, Se equals 0.73, PPV equals 0.49). Contrarily, a comprehensive model with 12 variables covering demographics (e.g., race/ethnicity, parental education), oral health behaviors, fluoride exposure, and dental home had worse performance (AUC equals 0.66, Se equals 0.54, PPV equals 0.61). Conclusions: Parsimonious automated machine learning early childhood caries classifiers, including single-item self-reports, can be valuable for ECC screening. The classifier can accommodate biological information that can help improve its performance in the future.",Pediatric dentistry,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3faf039f04d1e6cf15d75848b4e86e1436548d65,https://www.semanticscholar.org/paper/3faf039f04d1e6cf15d75848b4e86e1436548d65,Machine Learning Algorithm Using Electronic Chart-Derived Data to Predict Delirium After Elderly Hip Fracture Surgeries: A Retrospective Case-Control Study,"Background: Elderly patients undergoing hip fracture repair surgery are at increased risk of delirium due to aging, comorbidities, and frailty. But current methods for identifying the high risk of delirium among hospitalized patients have moderate accuracy and require extra questionnaires. Artificial intelligence makes it possible to establish machine learning models that predict incident delirium risk based on electronic health data. Methods: We conducted a retrospective case-control study on elderly patients (≥65 years of age) who received orthopedic repair with hip fracture under spinal or general anesthesia between June 1, 2018, and May 31, 2019. Anesthesia records and medical charts were reviewed to collect demographic, surgical, anesthetic features, and frailty index to explore potential risk factors for postoperative delirium. Delirium was assessed by trained nurses using the Confusion Assessment Method (CAM) every 12 h during the hospital stay. Four machine learning risk models were constructed to predict the incidence of postoperative delirium: random forest, eXtreme Gradient Boosting (XGBoosting), support vector machine (SVM), and multilayer perception (MLP). K-fold cross-validation was deployed to accomplish internal validation and performance evaluation. Results: About 245 patients were included and postoperative delirium affected 12.2% (30/245) of the patients. Multiple logistic regression revealed that dementia/history of stroke [OR 3.063, 95% CI (1.231, 7.624)], blood transfusion [OR 2.631, 95% CI (1.055, 6.559)], and preparation time [OR 1.476, 95% CI (1.170, 1.862)] were associated with postoperative delirium, achieving an area under receiver operating curve (AUC) of 0.779, 95% CI (0.703, 0.856). The accuracy of machine learning models for predicting the occurrence of postoperative delirium ranged from 83.67 to 87.75%. Machine learning methods detected 16 risk factors contributing to the development of delirium. Preparation time, frailty index uses of vasopressors during the surgery, dementia/history of stroke, duration of surgery, and anesthesia were the six most important risk factors of delirium. Conclusion: Electronic chart-derived machine learning models could generate hospital-specific delirium prediction models and calculate the contribution of risk factors to the occurrence of delirium. Further research is needed to evaluate the significance and applicability of electronic chart-derived machine learning models for the detection risk of delirium in elderly patients undergoing hip fracture repair surgeries.",Frontiers in Surgery,2021,10.3389/fsurg.2021.634629,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59454f24fa6e6539cc8cd9e75eeb029448d8c827,https://www.semanticscholar.org/paper/59454f24fa6e6539cc8cd9e75eeb029448d8c827,Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study,"Background Recently, machine learning (ML) has been transforming our daily lives by enabling intelligent voice assistants, personalized support for purchase decisions, and efficient credit card fraud detection. In addition to its everyday applications, ML holds the potential to improve medicine as well, especially with regard to diagnostics in clinics. In a world characterized by population growth, demographic change, and the global COVID-19 pandemic, ML systems offer the opportunity to make diagnostics more effective and efficient, leading to a high interest of clinics in such systems. However, despite the high potential of ML, only a few ML systems have been deployed in clinics yet, as their adoption process differs significantly from the integration of prior health information technologies given the specific characteristics of ML. Objective This study aims to explore the factors that influence the adoption process of ML systems for medical diagnostics in clinics to foster the adoption of these systems in clinics. Furthermore, this study provides insight into how these factors can be used to determine the ML maturity score of clinics, which can be applied by practitioners to measure the clinic status quo in the adoption process of ML systems. Methods To gain more insight into the adoption process of ML systems for medical diagnostics in clinics, we conducted a qualitative study by interviewing 22 selected medical experts from clinics and their suppliers with profound knowledge in the field of ML. We used a semistructured interview guideline, asked open-ended questions, and transcribed the interviews verbatim. To analyze the transcripts, we first used a content analysis approach based on the health care–specific framework of nonadoption, abandonment, scale-up, spread, and sustainability. Then, we drew on the results of the content analysis to create a maturity model for ML adoption in clinics according to an established development process. Results With the help of the interviews, we were able to identify 13 ML-specific factors that influence the adoption process of ML systems in clinics. We categorized these factors according to 7 domains that form a holistic ML adoption framework for clinics. In addition, we created an applicable maturity model that could help practitioners assess their current state in the ML adoption process. Conclusions Many clinics still face major problems in adopting ML systems for medical diagnostics; thus, they do not benefit from the potential of these systems. Therefore, both the ML adoption framework and the maturity model for ML systems in clinics can not only guide future research that seeks to explore the promises and challenges associated with ML systems in a medical setting but also be a practical reference point for clinicians.",Journal of medical Internet research,2021,10.2196/29301,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59454f24fa6e6539cc8cd9e75eeb029448d8c827,https://www.semanticscholar.org/paper/59454f24fa6e6539cc8cd9e75eeb029448d8c827,Adoption of Machine Learning Systems for Medical Diagnostics in Clinics: Qualitative Interview Study,"Background Recently, machine learning (ML) has been transforming our daily lives by enabling intelligent voice assistants, personalized support for purchase decisions, and efficient credit card fraud detection. In addition to its everyday applications, ML holds the potential to improve medicine as well, especially with regard to diagnostics in clinics. In a world characterized by population growth, demographic change, and the global COVID-19 pandemic, ML systems offer the opportunity to make diagnostics more effective and efficient, leading to a high interest of clinics in such systems. However, despite the high potential of ML, only a few ML systems have been deployed in clinics yet, as their adoption process differs significantly from the integration of prior health information technologies given the specific characteristics of ML. Objective This study aims to explore the factors that influence the adoption process of ML systems for medical diagnostics in clinics to foster the adoption of these systems in clinics. Furthermore, this study provides insight into how these factors can be used to determine the ML maturity score of clinics, which can be applied by practitioners to measure the clinic status quo in the adoption process of ML systems. Methods To gain more insight into the adoption process of ML systems for medical diagnostics in clinics, we conducted a qualitative study by interviewing 22 selected medical experts from clinics and their suppliers with profound knowledge in the field of ML. We used a semistructured interview guideline, asked open-ended questions, and transcribed the interviews verbatim. To analyze the transcripts, we first used a content analysis approach based on the health care–specific framework of nonadoption, abandonment, scale-up, spread, and sustainability. Then, we drew on the results of the content analysis to create a maturity model for ML adoption in clinics according to an established development process. Results With the help of the interviews, we were able to identify 13 ML-specific factors that influence the adoption process of ML systems in clinics. We categorized these factors according to 7 domains that form a holistic ML adoption framework for clinics. In addition, we created an applicable maturity model that could help practitioners assess their current state in the ML adoption process. Conclusions Many clinics still face major problems in adopting ML systems for medical diagnostics; thus, they do not benefit from the potential of these systems. Therefore, both the ML adoption framework and the maturity model for ML systems in clinics can not only guide future research that seeks to explore the promises and challenges associated with ML systems in a medical setting but also be a practical reference point for clinicians.",Journal of medical Internet research,2021,10.2196/29301,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aa752489c4ac97eede24b081f3b23846817219c7,https://www.semanticscholar.org/paper/aa752489c4ac97eede24b081f3b23846817219c7,A State of the Art Survey of Machine Learning Algorithms for IoT Security,"The Internet of Things (IoT) is a paradigm shift that enables billions of devices to connect to the Internet. The IoT's diverse application domains, including smart cities, smart homes, and e-health, have created new challenges, chief among them security threats. To accommodate the current networking model, traditional security measures such as firewalls and Intrusion Detection Systems (IDS) must be modified. Additionally, the Internet of Things and Cloud Computing complement one another, frequently used interchangeably when discussing technical services and collaborating to provide a more comprehensive IoT service. In this review, we focus on recent Machine Learning (ML) and Deep Learning (DL) algorithms proposed in IoT security, which can be used to address various security issues. This paper systematically reviews the architecture of IoT applications, the security aspect of IoT, service models of cloud computing, and cloud deployment models. Finally, we discuss the latest ML and DL strategies for solving various security issues in IoT networks.",,2021,10.9734/ajrcos/2021/v9i430226,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c68aa1bb2ebab5b8c3161df831c733c6330deb02,https://www.semanticscholar.org/paper/c68aa1bb2ebab5b8c3161df831c733c6330deb02,Exploring Cloud Assisted Tiny Machine Learning Application Patterns for PHM Scenarios,"Given the diverse deployments of sensor nodes in prognostics and health management (PHM) applications, the use of small form-factor, low-cost and power-efficient microcontrollers (MCUs) has become a practical option for long-term monitoring and front-end data-processing. Hardware advances have enabled small MCU devices to run light-weight machine learning (especially deep neural networks) thereby enabling inference tasks using tiny machine learning (Tiny ML) models executing closer to the data source sensors. Although TinyML like approaches have previously been proposed for some cases in PHM, existing approaches have mainly targeted PHM applications that use single data sources and case-specific models as opposed utilizing prediction models trained from general machine learning frameworks and requiring fusion of multiple distributed data sources. Unfortunately, pure MCUs lack the capacity to conduct such analytics. This work aims to address these limitations by using TinyML deployed at the edge in cooperation with system-level machine learning executing in the cloud. Specifically, we study applications in which sensor data is collected and used to predict system health status and perform remaining useful life regression. We also show how edge MCU devices and cloud computing can be combined and adapted to satisfy diverse requirements, such as latency, power and communication. We also describe the limitations of the current MCU-based deep learning in data-driven prognostics. To the best of our knowledge, this is the first work to systematically investigate the TinyML-Cloud cooperation for data-driven prognostics. We target this as a vision paper and aim to provide a high-level guideline for future PHM application designs involving smart MCU-based decision making.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aead3bd89e1e168a5dd1d4f4286f272b313ab48d,https://www.semanticscholar.org/paper/aead3bd89e1e168a5dd1d4f4286f272b313ab48d,Passive COVID-19 Assessment using Machine Learning on Physiological and Activity Data from Low End Wearables,"COVID-19 has now infected over 165 million people and killed over 3.5 million people. While public health interventions have reduced its spread and vaccines are being deployed, passive detection methods are needed to detect infections and early track its resurgence. Wearables that are widely owned can gather various physiological and activity data, presenting an opportunity to detect COVID-19 unobtrusively. COVID-19 infection causes deviations in the vital physiological signs and activity patterns of infected users. However, similar deviations of these same variables can also be affected by non-COVID factors, confounding the signals. In this paper, we investigate the feasibility of predicting COVID-19 infection to detect abnormalities in heart rate, activity (steps), and sleep data available on low-end wearables by using machine learning. Prior work utilized data such as oxygen saturation that is only available on clinical-grade equipment or expensive wearables. We extracted 43 statistical features (standard deviation, mean, slope) and behavioral (min/max/avg length of sedentary and active bouts, sleep duration, no. of awake/asleep/restless samples) from wearable sensor data. We classified these features using machine learning classification and anomaly detection algorithms. Physical activity features were the most predictive (min length of the sedentary and active bout), yielding an AUC-ROC of 78% [specificity=74%, sensitivity=69%] when classified using Gradient Boosting Machines (GBMs). We also found that sleep irregularities had low discriminative performance. COVID-19 detection using inexpensive wearables can facilitate population-level interventions.",2021 IEEE International Conference on Digital Health (ICDH),2021,10.1109/icdh52753.2021.00020,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8facb409b683ca952bf389391a995e9a51955eaf,https://www.semanticscholar.org/paper/8facb409b683ca952bf389391a995e9a51955eaf,Automated Machine Learning for Remaining Useful Life Estimation of Aircraft Engines,"Remaining useful life (RUL) of an asset or system is defined as the length from the current time and operating state to the end of the useful life. It is of paramount importance for safety-critical industries such as aviation and lies in the heart of prognostics and health management (PHM). This paper investigates the usage of automated machine learning (AutoML) for RUL estimation, based on using classical machine learning algorithms for regression. The data is pre-processed by extracting statistical features from expanding windows of the signal in order to uncover the degradation that has been accumulating from the early life of the system or after an overhaul. We evaluate our methodology on the widely-used C-MAPSS dataset and compare our approach to the state-of-the-art deep neural networks (DNNs) and classical machine learning algorithms. The experimental results show that AutoML outperforms or is comparable to traditional machine learning techniques and standard neural networks, while being outperformed by specifically designed neural networks on datasets with multiple fault mode and operating conditions. These results show that with the correct pre-processing automated machine learning is able to accurately estimate the RUL, which implies that such approaches can be industrially deployed.",2021 IEEE International Conference on Prognostics and Health Management (ICPHM),2021,10.1109/ICPHM51084.2021.9486549,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2319d123e50d4f28c88fcbf96188c377720bca25,https://www.semanticscholar.org/paper/2319d123e50d4f28c88fcbf96188c377720bca25,Machine learning analysis reveals relationship between pomacentrid calls and environmental cues,": Sound production rates of fishes can be used as an indicator for coral reef health, pro-viding an opportunity to utilize long-term acoustic recordings to assess environmental change. As acoustic datasets become more common, computational techniques need to be developed to facilitate analysis of the massive data files produced by long-term monitoring. Machine learning techniques demonstrate an advantage in the identification of fish sounds over manual sampling ap -proaches. Here we evaluated the ability of convolutional neural networks to identify and monitor call patterns for pomacentrids (damselfishes) in a tropical reef region of the western Pacific. A stationary hydrophone was deployed for 39 mo (2014−2018) in the National Park of American Samoa to continuously record the local marine acoustic environment. A neural network was trained — achieving 94% identification accuracy of pomacentrids — to demonstrate the applicability of machine learning in fish acoustics and ecology. The distribution of sound production was found to vary on diel and interannual timescales. Additionally, the distribution of sound production was correlated with wind speed, water temperature, tidal amplitude, and sound pressure level. This re search has broad implications for state-of-the-art acoustic analysis and promises to be an efficient, scalable asset for ecological research, environmental monitoring, and conservation planning.",Marine Ecology Progress Series,2021,10.3354/meps13912,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29e87a9084c91f1b13a35891268fdef295699aa0,https://www.semanticscholar.org/paper/29e87a9084c91f1b13a35891268fdef295699aa0,Machine learning techniques as an eﬃcient alternative diagnostic tool for COVID-19 cases,"Background: The SARS-CoV-2 virus has demonstrated the weakness of many health systems worldwide, creating a saturation and lack of access to treatments. A bottleneck to fight this pandemic relates to the lack of diagnostic infrastructure for early detection of positive cases, particularly in rural and impoverished areas of developing countries. In this context, less costly and fast machine learning (ML) diagnosis-based systems are helpful. However, most of the research has focused on deep-learning techniques for diagnosis, which are computationally and technologically expensive. ML models have been mainly used as a benchmark and are not entirely explored in the existing literature on the topic of this paper.

Objective: To analyze the capabilities of ML techniques (compared to deep learning) to diagnose COVID-19 cases based on X-ray images, assessing the performance of these techniques and using their predictive power for such a diagnosis.

Methods: A factorial experiment was designed to establish this power with X-ray chest images of healthy, pneumonia, and COVID-19 infected patients. This design considers data-balancing methods, feature extraction approaches, different algorithms, and hyper-parameter optimization. The ML techniques were evaluated based on classification metrics, including accuracy, the area under the receiver operating characteristic curve (AUROC), F1-score, sensitivity, and specificity.

Results: The design of experiment provided the mean and its confidence intervals for the predictive capability of different ML techniques, which reached AUROC values as high as 90% with suitable sensitivity and specificity. Among the learning algorithms, support vector machines and random forest performed best. The down-sampling method for unbalanced data improved the predictive power significantly for the images used in this study.

Conclusions: Our investigation demonstrated that ML techniques are able to identify COVID-19 infected patients. The results provided suitable values of sensitivity and specificity, minimizing the false-positive or false-negative rates. The models were trained with significantly low computational resources, which helps to provide access and deployment in rural and impoverished areas.",Signa Vitae,2021,10.22514/sv.2021.110,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3ed42f72025dc550643ae209d76cd9e16854a5c7,https://www.semanticscholar.org/paper/3ed42f72025dc550643ae209d76cd9e16854a5c7,"Artificial intelligence, machine learning, and deep learning for clinical outcome prediction","AI is a broad concept, grouping initiatives that use a computer to perform tasks that would usually require a human to complete. AI methods are well suited to predict clinical outcomes. In practice, AI methods can be thought of as functions that learn the outcomes accompanying standardized input data to produce accurate outcome predictions when trialed with new data. Current methods for cleaning, creating, accessing, extracting, augmenting, and representing data for training AI clinical prediction models are well defined. The use of AI to predict clinical outcomes is a dynamic and rapidly evolving arena, with new methods and applications emerging. Extraction or accession of electronic health care records and combining these with patient genetic data is an area of present attention, with tremendous potential for future growth. Machine learning approaches, including decision tree methods of Random Forest and XGBoost, and deep learning techniques including deep multi-layer and recurrent neural networks, afford unique capabilities to accurately create predictions from high dimensional, multimodal data. Furthermore, AI methods are increasing our ability to accurately predict clinical outcomes that previously were difficult to model, including time-dependent and multi-class outcomes. Barriers to robust AI-based clinical outcome model deployment include changing AI product development interfaces, the specificity of regulation requirements, and limitations in ensuring model interpretability, generalizability, and adaptability over time.",Emerging topics in life sciences,2021,10.1042/ETLS20210246,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cd6bed60df984120dd4f3940b419e4e02390fa64,https://www.semanticscholar.org/paper/cd6bed60df984120dd4f3940b419e4e02390fa64,"Human and machine learning of prognostic prediction for prelabor rupture of membranes and the time of delivery: a nationwide development, validation, and deployment using medical history","Prognostic prediction of prelabor rupture of membrane (PROM) lacks of sample size and external validation. We compared a statistical model, machine learning algorithms, and a deep-insight visible neural network (DI-VNN) for PROM and estimating the time of delivery. We selected visits, including PROM (n=23,791/170,730), retrospectively from a nationwide health insurance dataset. DI-VNN achieved the best prediction (area under receiver operating characteristics curve [AUROC] 0.73, 95% CI 0.72 to 0.75). Meanwhile, random forest using principal components achieved the best estimation with root mean squared errors {+/-} 2.2 and 2.6 weeks respectively for the predicted event and nonevent. DI-VNN outperformed previous models by an external validation set, including one using a biomarker (AUROC 0.641; n=1,177). We deployed our models as a web application requiring diagnosis/procedure codes and dates. In conclusion, our models may be used solely in low-resource settings or as a preliminary model to reduce a specific test requiring high-resource setting.",medRxiv,2021,10.1101/2021.06.16.21258884,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54f4afa73d7bfab28d51b8c8a13782305dc09755,https://www.semanticscholar.org/paper/54f4afa73d7bfab28d51b8c8a13782305dc09755,IoT and Machine Learning based Self Care System for Diabetes Monitoring and Prediction,"Diabetes is a chronic disease caused by the assimilation of blood sugar, mainly because of reduced production or no production of insulin within the body (type 1 diabetes), or because cells are irresponsive to the produced insulin (type 2 diabetes). In recent years, a multitude of people turned out to be diabetic and is increasing drastically. Moreover, a report by World Health Organization describes 346 million people are affected by diabetes around the world. Furthermore, the lack of a self-care system for monitoring and detecting signs at an early stage in the patient’s data causes pre-diabetes or diabetes condition which remains unrevealed in more than one-third of the population and later diagnosed with diabetes. The combination of machine learning techniques and the Internet of Things can provide an effective solution to predict diabetes well before. Therefore, this paper presents an Internet of Things (IoT) and Machine Learning-based non-invasive self-care system which monitors blood sugar and various vital parameters to predict diabetes well before. The non-invasive way of measuring blood sugar through a developed IoT sensor is much more comfortable compared to the invasive method. In the proposed system deployment of the SVM-based machine learning model on the cloud and its integration with the android application enables doctors and patients to monitor the vital parameters and associated risk easily. In addition to this, monitored parameters are sent to the doctor through email for further analysis, and suggestions in diet and lifestyle based on the monitored parameters are conveyed to the patient through an android application to prevent or reduce the risk of diabetes. Thus, the proposed self-care system can overcome challenges of the traditional way of monitoring diabetes and helps patient and doctor in monitoring, recording, and analyzing data for the prognosis of diabetes.",2021 2nd Global Conference for Advancement in Technology (GCAT),2021,10.1109/GCAT52182.2021.9587681,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
db0c1b63721ed4c4cc04b23a72ad5f1c0f709cb1,https://www.semanticscholar.org/paper/db0c1b63721ed4c4cc04b23a72ad5f1c0f709cb1,Accurate Prediction of Stroke for Hypertensive Patients Based on Medical Big Data and Machine Learning Algorithms: Retrospective Study,"Background Stroke risk assessment is an important means of primary prevention, but the applicability of existing stroke risk assessment scales in the Chinese population has always been controversial. A prospective study is a common method of medical research, but it is time-consuming and labor-intensive. Medical big data has been demonstrated to promote disease risk factor discovery and prognosis, attracting broad research interest. Objective We aimed to establish a high-precision stroke risk prediction model for hypertensive patients based on historical electronic medical record data and machine learning algorithms. Methods Based on the Shenzhen Health Information Big Data Platform, a total of 57,671 patients were screened from 250,788 registered patients with hypertension, of whom 9421 had stroke onset during the 3-year follow-up. In addition to baseline characteristics and historical symptoms, we constructed some trend characteristics from multitemporal medical records. Stratified sampling according to gender ratio and age stratification was implemented to balance the positive and negative cases, and the final 19,953 samples were randomly divided into a training set and test set according to a ratio of 7:3. We used 4 machine learning algorithms for modeling, and the risk prediction performance was compared with the traditional risk scales. We also analyzed the nonlinear effect of continuous characteristics on stroke onset. Results The tree-based integration algorithm extreme gradient boosting achieved the optimal performance with an area under the receiver operating characteristic curve of 0.9220, surpassing the other 3 traditional machine learning algorithms. Compared with 2 traditional risk scales, the Framingham stroke risk profiles and the Chinese Multiprovincial Cohort Study, our proposed model achieved better performance on the independent validation set, and the area under the receiver operating characteristic value increased by 0.17. Further nonlinear effect analysis revealed the importance of multitemporal trend characteristics in stroke risk prediction, which will benefit the standardized management of hypertensive patients. Conclusions A high-precision 3-year stroke risk prediction model for hypertensive patients was established, and the model's performance was verified by comparing it with the traditional risk scales. Multitemporal trend characteristics played an important role in stroke onset, and thus the model could be deployed to electronic health record systems to assist in more pervasive, preemptive stroke risk screening, enabling higher efficiency of early disease prevention and intervention.",JMIR medical informatics,2021,10.2196/30277,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54d51e39138fab061f257cb314cc29588c2ba2b5,https://www.semanticscholar.org/paper/54d51e39138fab061f257cb314cc29588c2ba2b5,Machine Learning based Health Prediction System using IBM Cloud as PaaS,"Adaptable Critical Patient Caring system is a key concern for hospitals in developing countries like Bangladesh. Most of the hospital in Bangladesh lack serving proper health service due to unavailability of appropriate, easy and scalable smart systems. The aim of this project is to build an adequate system for hospitals to serve critical patients with a real-time feedback method. In this paper, we propose a generic architecture, associated terminology and a classificatory model for observing critical patient's health condition with machine learning and IBM cloud computing as Platform as a service (PaaS). Machine Learning (ML) based health prediction of the patients is the key concept of this research. IBM Cloud, IBM Watson studio is the platform for this research to store and maintain our data and ml models. For our ml models, we have chosen the following Base Predictors: Naïve Bayes, Logistic Regression, KNeighbors Classifier, Decision Tree Classifier, Random Forest Classifier, Gradient Boosting Classifier, and MLP Classifier. For improving the accuracy of the model, the bagging method of ensemble learning has been used. The following algorithms are used for ensemble learning: Bagging Random Forest, Bagging Extra Trees, Bagging KNeighbors, Bagging SVC, and Bagging Ridge. We have developed a mobile application named “Critical Patient Management System - CPMS” for real-time data and information view. The system architecture is designed in such a way that the ml models can train and deploy in a real-time interval by retrieving the data from IBM Cloud and the cloud information can also be accessed through CPMS in a requested time interval. To help the doctors, the ml models will predict the condition of a patient. If the prediction based on the condition gets worse, the CPMS will send an SMS to the duty doctor and nurse for getting immediate attention to the patient. Combining with the ml models and mobile application, the project may serve as a smart healthcare solution for the hospitals.",2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI),2019,10.1109/ICOEI.2019.8862754,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f25acd077485428afc9f6307a335fb63d8b1d226,https://www.semanticscholar.org/paper/f25acd077485428afc9f6307a335fb63d8b1d226,Machine Learning for Cardiovascular Outcomes from Wearable Data: a Systematic Review from a Technology Readiness Level Point of View (Preprint),"
 BACKGROUND
 Wearable technology has the potential to improve cardiovascular health monitoring using machine learning. It enables remote health monitoring and allows for diagnosis and prevention. In addition to detection of cardiovascular disease, it can exclude a diagnosis in symptomatic patients, preventing unnecessary hospital visits. Furthermore, early warning systems can aid the cardiologist in timely treatment and prevention.
 
 
 OBJECTIVE
 We systematically assessed literature on detecting and predicting outcomes of cardiovascular disease with data obtained from wearables to gain insights in the current challenges and limitations.
 
 
 METHODS
 We searched PubMed, Scopus and IEEE Xplore on September 26, 2020 with no restrictions on the publication date using keywords: wearables, machine learning and cardiovascular disease. Methodologies were categorized and analyzed according to machine learning based technology readiness levels (TRLs) that score studies on their potential to be deployed in an operational setting from 1 to 9 (most ready).
 
 
 RESULTS
 After removal of duplicates, applying exclusion criteria, and full-text screening, 55 eligible studies remained for analysis, covering a variety of cardiovascular diseases. None of the studies were integrated into a health care system (TRL < 6), prospectively phase 2 and 3 trials were absent (TRL < 7 and 8) and group cross-validation was rarely used, limiting to demonstrate their effectiveness. Furthermore, there seems to be no agreement on the sample size needed to train these models, the size of the observation window used to make predictions, how long subjects should be observed and the type of machine learning model that is suitable for predicting cardiovascular outcomes.
 
 
 CONCLUSIONS
 Although current studies show the potential of wearables to monitor cardiovascular events, their deployment as a diagnostic and/or prognostic cardiovascular clinical tool is hampered by the lack of using a realistic dataset and a proper systematic and prospective evaluation.
",,2021,10.2196/preprints.29434,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e1a0ada13a221bea2028b91719e06bbcc8a7599e,https://www.semanticscholar.org/paper/e1a0ada13a221bea2028b91719e06bbcc8a7599e,Gutter oil detection for food safety based on multi-feature machine learning and implementation on FPGA with approximate multipliers,"Since consuming gutter oil does great harm to people’s health, the Food Safety Administration has always been seeking for a more effective and timely supervision. As laboratory tests consume much time, and existing field tests have excessive limitations, a more comprehensive method is in great need. This is the first time a study proposes machine learning algorithms for real-time gutter oil detection under multiple feature dimensions. Moreover, it is deployed on FPGA to be low-power and portable for actual use. Firstly, a variety of oil samples are generated by simulating the real detection environment. Next, based on previous studies, sensors are used to collect significant features that help distinguish gutter oil. Then, the acquired features are filtered and compared using a variety of classifiers. The best classification result is obtained by k-NN with an accuracy of 97.18%, and the algorithm is deployed to FPGA with no significant loss of accuracy. Power consumption is further reduced with the approximate multiplier we designed. Finally, the experimental results show that compared with all other platforms, the whole FPGA-based classification process consumes 4.77 µs and the power consumption is 65.62 mW. The dataset, source code and the 3D modeling file are all open-sourced.",PeerJ Comput. Sci.,2021,10.7717/peerj-cs.774,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4b3147ade86a7cd932d2f08653552fb095572d64,https://www.semanticscholar.org/paper/4b3147ade86a7cd932d2f08653552fb095572d64,Accurate Prediction of Stroke for Hypertensive Patients Based on Medical Big Data and Machine Learning Algorithms: A Retrospective Study (Preprint),"
 BACKGROUND
 Stroke risk assessment is an importance means of primary prevention, but the applicability of existing stroke risk assessment scales in Chinese population is still controversial. Prospective study is a common method of medical research, but it is time-consuming and labor-intensive. Medical big data has been demonstrated to promote discovery of disease risk factors and prognosis, and attracts broad research interests.
 
 
 OBJECTIVE
 We aimed to establish a high-precision stroke risk prediction model for hypertensive patients through historical stock electronic medical records and machine learning algorithms.
 
 
 METHODS
 Based on Shen Health Information Big Data Platform, a total number of 57,671 patients were screened from 250,788 registered hypertensive patients, of whom 9,421 had stroke onset after three years of follow-up. In addition to baseline features and historical symptoms, we constructed several trend characteristics from multi-temporal medical records. Stratified sampling was implemented according to gender ratio and age stratification to balance positive and negative cases, and then 19,953 samples were randomly divided into training set and test set according to a ratio of 7:3. Four machine learning methods were adopted for modeling, and risk performance was compared with several traditional risk scales. We also analyzed the non-linear effects of continuous features on stroke onset.
 
 
 RESULTS
 The integrated tree-based XGBoost achieved better performance with area under the receiver operating characteristic curve (AUC) of 0.9220, surpassing the other three traditional machine learning methods. Comparison with two traditional risk scales, the Framingham stroke risk profiles and the Chinese Multi-provincial Cohort Study, our proposed model achieved higher performance on an independent validation set, and AUC increased by 0.17. Further analysis of non-linear effects reveals the importance of multi-temporal trend characteristics for stroke risk prediction, which is beneficial to the standardized management of hypertensive patients.
 
 
 CONCLUSIONS
 A high-precision three-year stroke risk prediction model for hypertensive patients was established, and verified the model performance over traditional risk scales. Multi-temporal trend characteristics play an important role in stroke onset, and then the model could be deployed to electronic health record systems to assist in more pervasive, preemptive screening of stroke risk, enabling higher efficiency of early disease prevention and intervention.
",,2021,10.2196/preprints.30277,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2848d77e72ba2d09ec260c9336fb2e02e6953c97,https://www.semanticscholar.org/paper/2848d77e72ba2d09ec260c9336fb2e02e6953c97,Smart robot-enabled remaining useful life prediction and maintenance optimization for complex structures using artificial intelligence and machine learning,"To replace current legacy inspection/maintenance methods with autonomous real-time health status tracking , the paper proposes a smart robotic system with integrated remaining useful life (RUL) prediction tailored for complex components, structures and systems (CSSs). Capabilities like artificial intelligence (AI)/machine learning (ML) utilizing sensing data along with other monitoring data assist in maintenance optimization. The designed system is based on the state-of-the-art reinforcement learning (RL) and deep learning (DL) framework, which consists of an input, modeling, and decision layer. To achieve better prediction accuracy with higher autonomy, a novel active robot-enabled inspection/maintenance system is deployed in the input layer to collect whole-field infrastructure sensing data and inspect critical CSSs. The deep RL approach is integrated with failure diagnostic and prognostic algorithms to train a risk-informed AI-based agent for controlling the robots. With the data collected from the input layer, the modeling layer first conducts data fusion and predicts RUL of components using an efficient Bayesian convolutional neural network (BCNN) algorithm. In the decision layer, a resilience-driven probabilistic decision-making framework will be developed to control the robot for automatically detecting local damage, e.g. defects, degradation, and recommend mitigation/recovery actions for the health management of infrastructure under uncertainty. The combined layers comprise a AI-risk-driven sensing system (AIRSS) which was tested on an Aero-Propulsion System turbofan engine.",Defense + Commercial Sensing,2021,10.1117/12.2589045,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2c13921d653fd56edaf86cab19a35a96ed543f55,https://www.semanticscholar.org/paper/2c13921d653fd56edaf86cab19a35a96ed543f55,rECHOmmend: An ECG-Based Machine Learning Approach for Identifying Patients at Increased Risk of Undiagnosed Structural Heart Disease Detectable by Echocardiography,"Background: Timely diagnosis of structural heart disease improves patient outcomes, yet many remain underdiagnosed. While population screening with echocardiography is impractical, ECG-based prediction models can help target high-risk patients. We developed a novel ECG-based machine learning approach to predict multiple structural heart conditions, hypothesizing that a composite model would yield higher prevalence and positive predictive values to facilitate meaningful recommendations for echocardiography. Methods: Using 2 232 130 ECGs linked to electronic health records and echocardiography reports from 484 765 adults between 1984 to 2021, we trained machine learning models to predict the presence or absence of any of 7 echocardiography-confirmed diseases within 1 year. This composite label included the following: moderate or severe valvular disease (aortic/mitral stenosis or regurgitation, tricuspid regurgitation), reduced ejection fraction <50%, or interventricular septal thickness >15 mm. We tested various combinations of input features (demographics, laboratory values, structured ECG data, ECG traces) and evaluated model performance using 5-fold cross-validation, multisite validation trained on 1 site and tested on 10 independent sites, and simulated retrospective deployment trained on pre-2010 data and deployed in 2010. Results: Our composite rECHOmmend model used age, sex, and ECG traces and had a 0.91 area under the receiver operating characteristic curve and a 42% positive predictive value at 90% sensitivity, with a composite label prevalence of 17.9%. Individual disease models had area under the receiver operating characteristic curves from 0.86 to 0.93 and lower positive predictive values from 1% to 31%. Area under the receiver operating characteristic curves for models using different input features ranged from 0.80 to 0.93, increasing with additional features. Multisite validation showed similar results to cross-validation, with an aggregate area under the receiver operating characteristic curve of 0.91 across our independent test set of 10 clinical sites after training on a separate site. Our simulated retrospective deployment showed that for ECGs acquired in patients without preexisting structural heart disease in the year 2010, 11% were classified as high risk and 41% (4.5% of total patients) developed true echocardiography-confirmed disease within 1 year. Conclusions: An ECG-based machine learning model using a composite end point can identify a high-risk population for having undiagnosed, clinically significant structural heart disease while outperforming single-disease models and improving practical utility with higher positive predictive values. This approach can facilitate targeted screening with echocardiography to improve underdiagnosis of structural heart disease.",medRxiv,2021,10.1161/CIRCULATIONAHA.121.057869,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f2856b4e7f357d7e30c13aba65c6594b51bf1d60,https://www.semanticscholar.org/paper/f2856b4e7f357d7e30c13aba65c6594b51bf1d60,Quantifying machine learning-induced overdiagnosis in sepsis,"The proliferation of early diagnostic technologies, including selfmonitoring systems and wearables, coupled with the application of these technologies on large segments of healthy populations may significantly aggravate the problem of overdiagnosis. This can lead to unwanted consequences such as overloading health care systems and overtreatment, with potential harms to healthy individuals. The advent of machine-learning tools to assist diagnosis—while promising rapid and more personalised patient management and screening—might contribute to this issue. The identification of overdiagnosis is usually post hoc and demonstrated after long periods (from years to decades) and costly randomised control trials. In this paper, we present an innovative approach that allows us to preemptively detect potential cases of overdiagnosis during predictive model development. This approach is based on the combination of labels obtained from a prediction model and clustered medical trajectories, using sepsis in adults as a test case. This is one of the first attempts to quantify machinelearning induced overdiagnosis and we believe will serves as a platform for further development, leading to guidelines for safe deployment of computational diagnostic tools.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
505aa9c9c3e72e69d85d4f7236576d150c7069ee,https://www.semanticscholar.org/paper/505aa9c9c3e72e69d85d4f7236576d150c7069ee,Schoolchildren’ Depression and Anxiety Prediction Using Machine Learning Algorithms (Preprint),"
 BACKGROUND
 : Depression and anxiety symptoms in early childhood have a major effect on children's mental health growth and cognitive development. Studying the effect of mental health problems on cognitive development has gained researchers' attention for the last two decades
 
 
 OBJECTIVE
 In this paper, we seek to use machine learning techniques to predict the risk factors associated with school children's depression and anxiety
 
 
 METHODS
 The study data consisted of 5685 students in grades 5-9, aged 10-17 years, studying at public and refugee schools in the West Bank. The data were collected using the health behaviors school children questionnaire in the 2012-2013 academic year and analyzed using machine learning to predict the risk factors associated with student mental health symptoms. Five machine learning techniques (Random Forest, Neural Network, Decision Tree, Support Vector Machine, and Naïve Bayes) were used for the prediction.
 
 
 RESULTS
 The results indicated that the Random Forest model had the highest accuracy levels (72.6%, 68.5%) for depression and anxiety respectively. Thus, the Random Forest had the best performance in classifying and predicting the student's depression and anxiety. The results showed that school violence and bullying, home violence, academic performance, and family income were the most important factors affecting depression and anxiety scales
 
 
 CONCLUSIONS
 Overall, machine learning proved to be an efficient tool for identifying and predicting the associated factors that influence student depression and anxiety. The deployment of machine learning within the school information systems might facilitate the development of health prevention and intervention programs that will enhance students’ mental health and cognitive development.
",,2021,10.2196/preprints.32736,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e4450f5175691c540ab0000990f6349a6084e83f,https://www.semanticscholar.org/paper/e4450f5175691c540ab0000990f6349a6084e83f,Lamb wave damage severity estimation using ensemble-based machine learning method with separate model network,"Lamb wave-based damage estimation have great potential for structural health monitoring. However, designing a generalizable model that predicts accurate and reliable damage quantification result is still a practice challenge due to complex behavior of waves with different damage severities. In the recent years, machine learning (ML) algorithms have been proven to be an efficient tool to analyze damage-modulated Lamb wave signals. In this study, ensemble-based ML algorithms are employed to develop a generalizable crack quantification model for thin metallic plates. For this, the scattering of Lamb wave signals due to different configuration of crack dimension and orientation is extensively studied. Various finite element simulations signals, representing distinct crack severities in term of crack length, penetration and orientation are acquired. Realizing that both temporal and spectral information of signal is extremely important to damage quantification, three time-frequency (TF) based damage sensitive indices namely energy concentration, TF flux and coefficient of energy variance are proposed. These damage features are extracted by employing smoothed-pseudo Wigner–Ville distribution. After that data augmentation technique based on the spline-based interpolation is applied to enhance the size of the dataset. Eventually, these fully developed damage dataset is deployed to train ensemble-based models. Here we propose separate model network, in which different models are trained and then link together to predict new and unseen datasets. The performance of the proposed model is demonstrated by two cases: first simulated data incorporated with high artificial noises are employed to test the model and in the second scenario, experimental data in raw form are used. Results indicate that the proposed model has the potential to develop a general model that yields reliable answer for crack quantification.",Smart Materials and Structures,2021,10.1088/1361-665X/ac2e1a,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8b6534c3421c1fe0b3aa2ecc1a289872dcd0f9c0,https://www.semanticscholar.org/paper/8b6534c3421c1fe0b3aa2ecc1a289872dcd0f9c0,399 Using Machine Learning to Inform Extraction of Clinical Data from Sleep Study Reports,"
 
 
 In-laboratory and home sleep studies are important tools for diagnosing sleep disorders. However, a limited amount of measurements is used to inform disease severity and only specific measures, if any, are stored as structured fields into electronic health records (EHR). We propose a sleep study data extraction approach based on supervised machine learning to facilitate the development of specialized format-specific parsers for large-scale automated sleep data extraction.
 
 
 
 Using retrospective data from the Penn Medicine Sleep Center, we identified 64,100 sleep study reports stored in Microsoft Word documents of varying formats, recorded from 2001–2018. A random sample of 200 reports was selected for manual annotation of formats (e.g., layout) and type (e.g. baseline, split-night, home sleep apnea tests). Using text mining tools, we extracted 71 document property features (e.g., section dimensions, paragraph and table elements, regular expression matches). We identified 14 different formats and 7 study types. We used these manual annotations as multiclass outcomes in a random forest classifier to evaluate prediction of sleep study format and type using document property features. Out-of-bag (OOB) error rates and multiclass area under the receiver operating curve (mAUC) were estimated to evaluate training and testing performance of each model.
 
 
 
 We successfully predicted sleep study format and type using random forest classifiers. Training OOB error rate was 5.6% for study format and 8.1% for study type. When evaluating these models in independent testing data, the mAUC for classification of study format was 0.85 and for study type was 1.00. When applied to the large universe of diagnostic sleep study reports, we successfully extracted hundreds of discrete fields in 38,252 reports representing 33,696 unique patients.
 
 
 
 We accurately classified a sample of sleep study reports according to their format and type, using a random forest multiclass classification method. This informed the development and successful deployment of custom data extraction tools for sleep study reports. The ability to leverage these data can improve understanding of sleep disorders in the clinical setting and facilitate implementation of large-scale research studies within the EHR.
 
 
 
 American Heart Association (20CDA35310360).
",,2021,10.1093/SLEEP/ZSAB072.398,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6e0460149066280f3628407f7f8ca5190b07bfe2,https://www.semanticscholar.org/paper/6e0460149066280f3628407f7f8ca5190b07bfe2,Unsupervised Machine Learning in 6G Networks -State-of-the-art and Future Trends,"Wireless communication systems play a very crucial role for business, commercial, health and safety applications. With the commercial deployment of fifth generation (5G), academic and industrial research focuses on the sixth generation (6G) of wireless communication systems. Artificial Intelligence (AI) and especially Machine Learning (ML), will be a key component of 6G systems. Here, we present an up-to-date review of future 6G wireless systems and the role of unsupervised ML techniques in them.",2021 10th International Conference on Modern Circuits and Systems Technologies (MOCAST),2021,10.1109/MOCAST52088.2021.9493388,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c033430362c25733d06cea69ce6aca5384474453,https://www.semanticscholar.org/paper/c033430362c25733d06cea69ce6aca5384474453,Production Level Data Pipeline Environment for Machine Learning Models,"Machine learning field has a plethora of options to help diagnose various medical ailments. These models and algorithms seldomly form production level tools as the designs are compromised at the implementation level. The compromise is in the form of hardcoded file paths, variables, and development in a local environment. To offer scalable, deployable and platform independent code, the machine learning models should be implemented using best software practices from the initial design phase. Whenever it is required to analyze a big amount of data, loading the complete data adds latency. This latency in analysis is commonly seen in log files and health records [1]. This paper discusses the best practices for writing production level code for an example of epileptic seizure prediction. The design, analysis and visualization is done using Python language. The packages ‘kedro’ and ‘kedro-viz’ are discussed in detail for electroencephalograms (EEG) readings dataset available on UCI’s (University of California, Irvine) machine learning repository [2]. The packages are used to create data pipelines for developing production level code. This paper is a preliminary effort to demonstrate the basics of designing production level models including pipelines taking an example of epileptic seizure prediction.",2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS),2021,10.1109/icaccs51430.2021.9442035,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9e0cf257d7e43ac1518a930aa3abc8f73a6f820e,https://www.semanticscholar.org/paper/9e0cf257d7e43ac1518a930aa3abc8f73a6f820e,"Enhancing the value to users of machine learning-based clinical decision support tools: A framework for iterative, collaborative development and implementation","Background Health care organizations are integrating a variety of machine learning (ML)-based clinical decision support (CDS) tools into their operations, but practitioners lack clear guidance regarding how to implement these tools so that they assist end users in their work. Purpose We designed this study to identify how health care organizations can facilitate collaborative development of ML-based CDS tools to enhance their value for health care delivery in real-world settings. Methodology/Approach We utilized qualitative methods, including 37 interviews in a large, multispecialty health system that developed and implemented two operational ML-based CDS tools in two of its hospital sites. We performed thematic analyses to inform presentation of an explanatory framework and recommendations. Results We found that ML-based CDS tool development and implementation into clinical workflows proceeded in four phases: iterative solution coidentification, iterative coengagement, iterative coapplication, and iterative corefinement. Each phase is characterized by a collaborative back-and-forth process between the technology’s developers and users, through which both users’ activities and the technology itself are transformed. Conclusion Health care organizations that anticipate iterative collaboration to be an integral aspect of their ML-based CDS tools’ development and implementation process may have more success in deploying ML-based CDS tools that assist end users in their work than organizations that expect a traditional technology innovation process. Practice Implications Managers developing and implementing ML-based CDS tools should frame the work as a collaborative learning opportunity for both users and the technology itself and should solicit constructive feedback from users on potential changes to the technology, in addition to potential changes to user workflows, in an ongoing, iterative manner.",Health care management review,2021,10.1097/HMR.0000000000000324,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6c1b3fcd54f507b7a75a74891fb4ff20e122b281,https://www.semanticscholar.org/paper/6c1b3fcd54f507b7a75a74891fb4ff20e122b281,MACHINE LEARNING-BASED ENHANCED SECURITY SYSTEM FOR HEALTHCARE,"Sensing technology has recently advanced, making it possible to create a more effective and versatile remote healthcare monitoring network. The Internet of Things [IOT] faces many architecture and deployment problems. Cancer is a broad term used by the World Health Organization (WHO) to describe a diverse group of diseases that cause death. In light of this, it is important to decide whether or not anyone has a high cancer risk by completing a survey. This paper deals with the study of the Cervical Cancer Detection case study with the sample data file. In the proposed work, symptoms would be used as feedback for technical analysis. The signs are used to classify the patients. With each beauty, there were correctly categorized times and percentages, as well as actual and bogus excellent categorized times fees and a chaos matrix. Furthermore, both of the consequences are discussed. Index Terms -Naive Bayes, Cervical Cancer, Classification, Machine Learning, Internet of Things, Random Forest",,2021,10.1729/JOURNAL.26517,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c73a5bbaa78e38774e19302eb2da534e6d0cb322,https://www.semanticscholar.org/paper/c73a5bbaa78e38774e19302eb2da534e6d0cb322,17. Comparative Assessment of a Machine Learning Model and Rectal Swab Surveillance to Predict Hospital Onset Clostridioides difficile,"Abstract Background Hospital onset Clostridioides difficile infection (HO-CDI) is associated with significant morbidity and mortality. Screening individuals at risk could help limit transmission, however swab-based surveillance for HO-CDI is resource intensive. Applied to electronic health records (EHR) data, machine learning (ML) models present an efficient approach to assess patient risk. We compare the effectiveness of swab surveillance against daily risk estimates produced by a ML model in detecting patients who will develop HO-CDI. Methods Patients presenting to Michigan Medicine’s ICUs and oncology wards between June 6th and October 8th 2020 had rectal swabs collected on admission, weekly, and at discharge from the unit, as part of VRE surveillance. We performed anaerobic culture on the residual media followed by a custom, multiplex PCR on isolates to identify toxigenic C. difficile. Risk of HO-CDI was calculated daily for each patient using a previously validated EHR-based ML model. Swab results and model risk scores were aggregated for each admission and assessed as predictors of HO-CDI. Holding sensitivity equal, we evaluated both approaches in terms of accuracy, specificity, and positive predictive value (PPV). Results Of 2,044 admissions representing 1,859 patients, 39 (1.9%) developed HO-CDI. 23.1% (95% CI: 11.1–37.8%) of HO-CDI cases had at least one positive swab. At this sensitivity, model performance was significantly better than random but worse compared to swab surveillance—accuracy: 87.5% (86.0–88.9%) vs. 94.3% (93.3–95.3%), specificity: 88.7% (87.3–90.0%) vs. 95.7% (94.8–96.6%), PPV: 3.8% (1.6–6.4%) vs. 9.4% (4.3–16.1%). Combining swab AND model yielded lower sensitivity 2.6% (0.0–8.9%) compared to combining swab OR model at 43.6% (27.3–60.0%), and yielded PPV 7.1% (0.0–25.0%) vs. 43.6% (27.3–60.0%) respectively (Figure 1). Figure 1. Surveillance & risk score performance. Binary classification performance metrics of ML model (Model), toxigenic C. difficile rectal swab surveillance (Swab), and combination approaches (Model AND Swab and Model OR Swab), reported in terms of percentage points. Bold numbers highlight the best performing approach for a given performance metric. The combined approach of monitoring the Model AND Swab yielded the highest accuracy 97.5% (95% confidence interval: 96.8%, 98.1%), it also had the highest specificity 99.4% (99.0%, 99.7%). The combined approach of monitoring the Model OR Swab yielded the highest sensitivity 43.6% (27.3%, 60.0%) and negative predictive value (NPV) 98.7% (98.2, 99.2%). Using the Swab alone yielded the highest PPV 9.4% (4.3%, 16.1%) and F1 score 13.3% (6.2%, 21.8%). These results highlight the complementarity of the model and swab-based approaches. Conclusion Compared to swab surveillance using a ML model for predicting HO-CDI results in more false positives. The ML model provides daily risk scores and can be deployed using different thresholds. Thus, it can inform varied prevention strategies for different risk categories, without the need for resource intensive swabbing. Additionally, the approaches may be complimentary as the patients with HO-CDI identified by each approach differ. Disclosures Vincent B. Young, MD, PhD, American Society for Microbiology (Other Financial or Material Support, Senior Editor for mSphere)Vedanta Biosciences (Consultant) Krishna Rao, MD, MS, Bio-K+ International, Inc. (Consultant)Merck & Co., Inc. (Grant/Research Support)Roche Molecular Systems, Inc. (Consultant)Seres Therapeutics (Consultant)",Open Forum Infectious Diseases,2021,10.1093/ofid/ofab466.017,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c36bce094da9cdd822a6c65d2f81655a3c48bba5,https://www.semanticscholar.org/paper/c36bce094da9cdd822a6c65d2f81655a3c48bba5,Decoupled Feature-Temporal CNN: Explaining Deep Learning-Based Machine Health Monitoring,"Machine learning, especially deep learning, has been extensively applied and studied in the area of machine health monitoring. For machine health monitoring systems (MHMS), major efforts have been put into designing and deploying more and more complex machine learning models. Those black-box models are nontransparent toward their working mechanism. However, this research trend brings huge potential risks in real life. Since machine health monitoring itself belongs to high stake decision applications, the outputs of the autonomous monitoring systems should be trustworthy and reliable, which refers to obtain explainability. Then, it comes to the following key question: why the deployed MHMS predicts what they predict. In this article, we shed some light on this meaningful research direction: explainable MHMSs (EMHMS). In EMHMS, the machine doctor could act like a real doctor who can not only make a diagnosis but also describe the patient’s symptoms. First, we propose a specific convolutional neural network (CNN) structure, named DecouplEd Feature-Temporal CNN (DEFT-CNN), to balance precision–explainability tradeoff. Specifically, feature information and temporal information have been encoded in different stages of our model. The spatial attention module is added to boost the performance of the model. Then, to explain the decision of the model, we adopt gradient-based methods to generate features and temporal saliency maps highlighting which kinds of features and time steps are keys for the model’s predictions. Finally, we conduct the experimental studies on two real datasets to verify the effectiveness of our proposed framework.",IEEE Transactions on Instrumentation and Measurement,2021,10.1109/TIM.2021.3084310,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2acb035cc2c97c18aad5d6effa7b561454615675,https://www.semanticscholar.org/paper/2acb035cc2c97c18aad5d6effa7b561454615675,SOPHIA: An Event-Based IoT and Machine Learning Architecture for Predictive Maintenance in Industry 4.0,"Predictive Maintenance (PdM) is a prominent strategy comprising all the operational techniques and actions required to ensure machine availability and to prevent a machine-down failure. One of the main challenges of PdM is to design and develop an embedded smart system to monitor and predict the health status of the machine. In this work, we use a data-driven approach based on machine learning applied to woodworking industrial machines for a major woodworking Italian corporation. Predicted failures probabilities are calculated through tree-based classification models (Gradient Boosting, Random Forest and Extreme Gradient Boosting) and calculated as the temporal evolution of event data. This is achieved by applying temporal feature engineering techniques and training an ensemble of classification algorithms to predict Remaining Useful Lifetime (RUL) of woodworking machines. The effectiveness of the proposed method is showed by testing an independent sample of additional woodworking machines without presenting machine down. The Gradient Boosting model achieved accuracy, recall, and precision of 98.9%, 99.6%, and 99.1%. Our predictive maintenance approach deployed on a Big Data framework allows screening simultaneously multiple connected machines by learning from terabytes of log data. The target prediction provides salient information which can be adopted within the maintenance management practice.",Inf.,2020,10.3390/info11040202,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8b3bfbe8902118553830e7b7635089066d2ab385,https://www.semanticscholar.org/paper/8b3bfbe8902118553830e7b7635089066d2ab385,Multimodal Machine Learning for Interactive Mental Health Therapy,"Mental health disorders are among the leading causes of disability. Despite the prevalence of mental health disorders, there is a large gap between the needs and resources available for their assessment and treatment. Automatic behaviour analysis for computer-aided mental health assessment can augment clinical resources in the diagnosis and treatment of patients. Intelligent systems like virtual agents and social robots can have a large impact by deploying multimodal machine learning to perceive and interact with patients in interactive scenarios for probing behavioral cues of mental health disorders. In this paper, we propose our plans for developing multimodal machine learning methods for augmenting embodied interactive agents with emotional intelligence, toward probing cues of mental health disorders. We aim to develop a new generation of intelligent agents that can create engaging interactive experiences for assisting with mental health assessments.",ICMI,2019,10.1145/3340555.3356095,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
34cedb3ec472503fe6ce5a269fe27934cdd4547d,https://www.semanticscholar.org/paper/34cedb3ec472503fe6ce5a269fe27934cdd4547d,Remote Health Monitoring in Clinical Trial using Machine Learning Techniques: A Conceptual Framework,,Health and technology,2022,10.1007/s12553-022-00652-z,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
82a5a84528a7ca0409f75e2211a3b33a217e9bac,https://www.semanticscholar.org/paper/82a5a84528a7ca0409f75e2211a3b33a217e9bac,Ensuring Fairness in Machine Learning to Advance Health Equity,"Machine learning can identify the statistical patterns of data generated by tens of thousands of physicians and billions of patients to train computers to perform specific tasks with sometimes superhuman ability, such as detecting diabetic eye disease better than retinal specialists (1). However, historical data also capture patterns of health care disparities, and machine-learning models trained on these data may perpetuate these inequities. This concern is not just academic. In a model used to predict future crime on the basis of historical arrest records, African American defendants who did not reoffend were classified as high risk at a substantially higher rate than white defendants who did not reoffend (2, 3). Similar biases have been observed in predictive policing (4) and identifying which calls to a child protective services agency required an in-person investigation (5, 6). The implications for health care led the American Medical Association to pass policy recommendations to promote development of thoughtfully designed, high-quality, clinically validated health care AI [artificial or augmented intelligence, such as machine learning] that . . . identifies and takes steps to address bias and avoids introducing or exacerbating health care disparities including when testing or deploying new AI tools on vulnerable populations (7). We argue that health care organizations and policymakers should go beyond the American Medical Association's position of doing no harm and instead proactively design and use machine-learning systems to advance health equity. Whereas much health disparities work has focused on discriminatory decision making and implicit biases by clinicians, policymakers, organizational leaders, and researchers are increasingly focusing on the ill health effects of structural racism and classismhow systems are shaped in ways that harm the health of disempowered, marginalized populations (8). For example, the United States has a shameful history of purposive decisions by government and private businesses to segregate housing. Zoning laws, discrimination in mortgage lending, prejudicial practices by real estate agents, and the ghettoization of public housing all contributed to the concentration of urban African Americans in inferior housing that has led to poor health (9, 10). Even when the goal of decision makers is not outright discrimination against disadvantaged groups, actions may lead to inequities. For example, if the goal of a machine-learning system is to maximize efficiency, that might come at the expense of disadvantaged populations. As a society, we value health equity. For example, the Healthy People 2020 vision statement aims for a society in which all people live long, healthy lives, and one of the mission's goals is to achieve health equity, eliminate disparities, and improve the health of all groups (11). The 4 classic principles of Western clinical medical ethics are justice, autonomy, beneficence, and nonmaleficence. However, health equity will not be attained unless we purposely design our health and social systems, which increasingly will be infused with machine learning (12), to achieve this goal. To ensure fairness in machine learning, we recommend a participatory process that involves key stakeholders, including frequently marginalized populations, and considers distributive justice within specific clinical and organizational contexts. Different technical approaches can configure the mathematical properties of machine-learning models to render predictions that are equitable in various ways. The existence of mathematical levers must be supplemented with criteria for when and why they should be usedeach tool comes with tradeoffs that require ethical reasoning to decide what is best for a given application. We propose incorporating fairness into the design, deployment, and evaluation of machine-learning models. We discuss 2 clinical applications in which machine learning might harm protected groups by being inaccurate, diverting resources, or worsening outcomes, especially if the models are built without consideration for these patients. We then describe the mechanisms by which a model's design, data, and deployment may lead to disparities; explain how different approaches to distributive justice in machine learning can advance health equity; and explore what contexts are more appropriate for different equity approaches in machine learning. Case Study 1: Intensive Care Unit Monitoring A common area of predictive modeling research focuses on creating a monitoring systemfor example, to warn a rapid response team about inpatients at high risk for deterioration (1315), requiring their transfer to an intensive care unit within 6 hours. How might such a system inadvertently result in harm to a protected group? In this thought experiment, we consider African Americans as a protected group. To build the model, our hypothetical researchers collected historical records of patients who had clinical deterioration and those who did not. The model acts like a diagnostic test of risk for intensive care unit transfer. However, if too few African American patients were included in the training datathe data used to construct the modelthe model might be inaccurate for them. For example, it might have a lower sensitivity and miss more patients at risk for deterioration. African American patients might be harmed if clinical teams started relying on alerts to identify at-risk patients without realizing that the prediction system underdetects patients in that group (automation bias) (16). If the model had a lower positive predictive value for African Americans, it might also disproportionately harm them through dismissal biasa generalization of alert fatigue in which clinicians may learn to discount or dismiss alerts for African Americans because they are more likely to be false-positive (17). Case Study 2: Reducing Length of Stay Imagine that a hospital created a model with clinical and social variables to predict which inpatients might be discharged earliest so that it could direct limited case management resources to them to prevent delays. If residence in ZIP codes of socioeconomically depressed or predominantly African American neighborhoods predicted greater lengths of stay (18), this model might disproportionately allocate case management resources to patients from richer, predominantly white neighborhoods and away from African Americans in poorer ones. What Is Machine Learning? Traditionally, computer systems map inputs to outputs according to manually specified ifthen rules. With increasingly complex tasks, such as language translation, manually specifying rules becomes infeasible, and instead the mapping (or model) is learned by the system given only input examples represented through a set of features together with their desired output, referred to as labels. The quality of a model is assessed by computing evaluation metrics on data not used to build the model, such as sensitivity, specificity, or the c-statistic, which measures the ability of a model to distinguish patients with a condition from those without it (19, 20). Once the model's quality is deemed satisfactory, it can be deployed to make predictions on new examples for which the label is unknown when the prediction is made. The quality of the models on retrospective data must be followed with tests of clinical effectiveness, safety, and comparison with current practice, which may require clinical trials (21). Traditionally, statistical models for prediction, such as the pooled-cohort equation (22), have used few variables to predict clinical outcomes, such as cardiovascular risk (23). Modern machine-learning techniques, however, can consider many more features. For example, a recent model to predict hospital readmissions examined hundreds of thousands of pieces of information, including the free text of clinical notes (24). Complex data and models can drive more personalized and accurate predictions but may also make algorithms hard to understand and trust (25). What Can Cause a Machine-Learning System to Be Unfair? The Glossary lists key biases in the design, data, and deployment of a machine-learning model that may perpetuate or exacerbate health care disparities if left unchecked. The Figure reveals how the various biases relate to one another and how the interactions of model predictions with clinicians and patients may exacerbate health care disparities. Biases may arise during the design of a model. For example, if the label is marred by health care disparities, such as predicting the onset of clinical depression in environments where protected groups have been systematically misdiagnosed, then the model will learn to perpetuate this disparity. This represents a generalization of test-referral bias (26) that we refer to as label bias. Moreover, the data on which the model is developed may be biased. Data on patients in the protected group might be distributed differently from those in the nonprotected group because of biological or nonbiological variation (9, 27). For example, the data may not contain enough examples from a group to properly tailor the predictions to them (minority bias) (28), or the data set of the protected group may be less informative because features are missing not at random as a result of more fragmented care (29, 30). Glossary Figure. Conceptual framework of how various biases relate to one another. During model development, differences in the distribution of features used to predict a label between the protected and nonprotected groups may bias a model to be less accurate for protected groups. Moreover, the data used to develop a model may not generalize to the data used during model deployment (trainingserving skew). Biases in model design and data affect patient outcomes through the model's interaction with clinicians and patients. The immediate effect of these differences is that the model may ",Annals of Internal Medicine,2018,10.7326/M18-1990,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
23bc5879b6c4a9fad5b8061051d5f87463311280,https://www.semanticscholar.org/paper/23bc5879b6c4a9fad5b8061051d5f87463311280,"Dear Watch, Should I Get a COVID-19 Test? Designing deployable machine learning for wearables","Commercial wearable devices are surfacing as an appealing mechanism to detect COVID-19 and potentially other public health threats, due to their widespread use. To assess the validity of wearable devices as population health screening tools, it is essential to evaluate predictive methodologies based on wearable devices by mimicking their real-world deployment. Several points must be addressed to transition from statistically significant differences between infected and uninfected cohorts to COVID-19 inferences on individuals. We demonstrate the strengths and shortcomings of existing approaches on a cohort of 32,198 individuals who experience influenza like illness (ILI), 204 of which report testing positive for COVID-19. We show that, despite commonly made design mistakes resulting in overestimation of performance, when properly designed wearables can be effectively used as a part of the detection pipeline. For example, knowing the week of year, combined with naive randomised test set generation leads to substantial overestimation of COVID-19 classification performance at 0.73 AUROC. However, an average AUROC of only 0.55 {+/-} 0.02 would be attainable in a simulation of real-world deployment, due to the shifting prevalence of COVID-19 and non-COVID-19 ILI to trigger further testing. In this work we show how to train a machine learning model to differentiate ILI days from healthy days, followed by a survey to differentiate COVID-19 from influenza and unspecified ILI based on symptoms. In a forthcoming week, models can expect a sensitivity of 0.50 (0-0.74, 95% CI), while utilising the wearable device to reduce the burden of surveys by 35%. The corresponding false positive rate is 0.22 (0.02-0.47, 95% CI). In the future, serious consideration must be given to the design, evaluation, and reporting of wearable device interventions if they are to be relied upon as part of frequent COVID-19 or other public health threat testing infrastructures.",medRxiv,2021,10.1101/2021.05.11.21257052,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1901d6e65922b341d12be3a819b7ca8fbbb1173b,https://www.semanticscholar.org/paper/1901d6e65922b341d12be3a819b7ca8fbbb1173b,An Evaluation of Machine Learning Algorithms in an Experimental Structural Health Monitoring System Incorporating LoRa IoT Connectivity,"The Internet of Things (IoT) offers dynamic mechanisms and methodologies for a broad number of practical applications by virtue of its integrated powerful advantages encompassing immense reliability, and superb robustness. This will expedite and simplify the deployment of IoT devices in civil structures and building settings for structural health monitoring (SHM) applications, including early warning systems (EWS). A SHM system extracts and provides information about variations in an individual component or in the complete structure. In this paper, an experimental SHM system incorporating the LoRa wireless IoT connectivity is presented, which includes assortment of sensor devices to acquire measurements of commonly monitored physical variables in typical SHM systems. The acquired concurrent measurements performed on the structure are aggregated at a designated cloud server, where they are analyzed, to predict the health status of the monitored structure. To that end, we conduct a comparative performance analysis of a collection of machine learning (ML) classification algorithms to evaluate their detection capacities in determining faults or variations in a monitored structure state. Numerical analysis results demonstrated that in our SHM system, the presence of a fault could be effectively predicted by means of a subset of the collection of considered ML classification algorithms. Computed evaluation metrics to characterize performance of our SHM system served to identify an optimum ML algorithm based on attained results, in addition to a training methodology for employment in SHM systems, to accurately detect the presence of a fault or damage in the monitored structure.",2022 IEEE International Instrumentation and Measurement Technology Conference (I2MTC),2022,10.1109/I2MTC48687.2022.9806560,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
28943e4f8380fc989b2fd6067c9b366f4cdd48cc,https://www.semanticscholar.org/paper/28943e4f8380fc989b2fd6067c9b366f4cdd48cc,Key Aggregation Cryptosystem and Double Encryption Method for Cloud-Based Intelligent Machine Learning Techniques-Based Health Monitoring Systems,"Cloud technology is a business strategy that aims to provide the necessary material to customers depending on their needs. Individuals and cloud businesses alike have embraced the cloud storage service, which has become the most widely used service. The industries outsource their data to cloud storage space to relieve themselves of the load of dealing with redundant data contents. This must be protected to prevent the theft of personal belongings, and privacy must be improved as well. Different research projects have been suggested to ensure the safe management of the information included within the data content. The security of current research projects, on the contrary, still needs improvement. As a result, this method has been suggested to address the security concerns associated with cloud computing. The primary goal of this study effort is to offer a safe environment for cloud users while also increasing the profit of cloud resource providers by managing and securely delivering data contents to the cloud users. The bulk of sectors, including business, finance, military, and healthcare industry, do not store data in cloud-based storage systems. This technique is used to attract these kinds of customers. Increasing public acceptance, medical researchers are drawn to cloud computing because it allows them to store their study material in a centralized location and distribute and access it in a more flexible manner. They were collected from numerous individuals who were being evaluated for medical care at the time. Scalable and enhanced key aggregate cryptosystem is a protected data protection method that provides highly effective security in the healthcare industry. When parties interested in a dispute disagree on the outflow of sensitive information, this technique manages the disputes and ensures the data security deployment of a cloud-based intelligent health monitoring system for the parties involved. The encrypted data structure of medical and healthcare prescriptions is recorded as they move through the hands of patients and healthcare facilities, according to the technique recommended. The double encryption approach is used in order to raise the overall degree of security. An encryption class is created by referring to the Ciphertext ID during the encryption procedure. The keyholder is a master secret key that facilitates in the recovery of the secret keys of various monsters and creatures by acting as a conduit between them. It is transferred and stored as a single aggregate for the benefit of the patient or customer in order to make decryption more convenient and efficient. A safe connection between cloud-based intelligent health monitoring systems and healthcare organizations and their patients may be established via the use of a key aggregation cryptosystem and a double encryption approach, according to the researchers. Because of this, when compared to earlier techniques, the findings reveal that the research methodology provides high levels of security in terms of confidentiality and integrity, in addition to excellent scalability.",Computational intelligence and neuroscience,2022,10.1155/2022/3767912,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e5beb1a354e4c544403a9a79b2ce1d47b0f9549c,https://www.semanticscholar.org/paper/e5beb1a354e4c544403a9a79b2ce1d47b0f9549c,Development Of Predictive Maintenance Methodology Utilizing Machine Learning Technology To Support Plant Health Management,"To maintain availability and reliability in PT. Indonesia Power (IP) power plants at high level, proper maintenance strategy must be well established. IP utilizing Predictive Maintenance (PdM) to predict the equipment conditions from plant healthiness. PdM analyze data trends to predict future behavior of equipment. Recent development in PdM methodology is applying Machine Learning (ML) technology which is proven effective and improves the speed and accuracy in the Plant Health Management (PHM) decision making. The ML technology used utilize anomaly detection based on regressive models. The model utilizes historical data and trains using the linear regression trainer model then predict current value using its lagged past in the time series. The prediction results then evaluated using scoring model. Overall result shows high prediction accuracy indicates in high number from the scoring model. Further analysis performed to forecast equipment condition and prediction of remaining threshold reaching in certain period. The analysis results then fed to database software to be documented and visualized in web-based charts. By employing the analysis provided in the web-based charts, allows engineer to develop appropriate PHM execution strategy. The current development PdM Methodology is proven to be capable of equipment condition prediction by utilizing ML technology. The ongoing development will be aimed in processing more training data with higher granularity and deployment in production environment.",2019 International Conference on Technologies and Policies in Electric Power & Energy,2019,10.1109/IEEECONF48524.2019.9102605,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6f839beb0820b2d07a0896aca8802a4e4511ca0b,https://www.semanticscholar.org/paper/6f839beb0820b2d07a0896aca8802a4e4511ca0b,Early Health Prediction System for ICU Patient using Machine Learning and Cloud Computing,"Adaptable Intensive Care Unit (ICU) system is a key concern for hospitals in developing countries like Bangladesh. Most of the hospital in Bangladesh lack serving proper health service due to unavailability of appropriate, easy and scalable systems. There also appears communication and information gaps between hospital authority and patient’s relative. The aim of this project is to build an adequate system for hospitals to serve the ICU patients with a real-time feedback system. Based on the doctor’s suggestions, we have primarily chosen the main factors for our project. In this paper, we propose a generic architecture, associated terminology and a classificatory model for observing ICU patient’s health condition with machine learning and cloud computing. Machine learning (ML) health prediction is the key concept of this research. IBM Cloud is the platform for this research to store and maintain our data. For our ml models, we have chosen the following algorithms: Naive Bayes, Logistic Regression. For real-time data and information view, we have developed a Mobile Application named “ICU Patient Management System IPMS”. Our system architecture is designed in such a way that the ml models can train and deploy in a real-time interval by retrieving the data from IBM Cloud and the cloud information can also be accessed through IPMS in a requested time interval. To help the doctors, the ml models will predict the condition of a patient. If the prediction based on the condition gets worse, the IPMS will send an SMS to the duty doctor and nurse for getting immediate attention to the patient. Combining with the cloud storage, distributed database system, ml models and mobile application, the project may serve as a complete medical decision for the",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17a0bbc7faa3f2d559a46557cad128c458028695,https://www.semanticscholar.org/paper/17a0bbc7faa3f2d559a46557cad128c458028695,Proximity Environmental Feature Based Tree Health Assessment Scheme Using Internet of Things and Machine Learning Algorithm,"Improperly grown trees may cause huge hazards to the environment and to humans, through e.g., climate change, soil erosion, etc. A proximity environmental feature-based tree health assessment (PTA) scheme is proposed to prevent these hazards by providing guidance for early warning methods of potential poor tree health. In PTA development, tree health is defined and evaluated based on proximity environmental features (PEFs). The PEF takes into consideration the seven surrounding ambient features that strongly impact tree health. The PEFs were measured by the deployed smart sensors surrounding trees. A database composed of tree health and relative PEFs was established for further analysis. An adaptive data identifying (ADI) algorithm is applied to exclude the influence of interference factors in the database. Finally, the radial basis function (RBF) neural network (NN), a machine leaning algorithm, has been identified as the appropriate tool with which to correlate tree health and PEFs to establish the PTA algorithm. One of the salient features of PTA is that the algorithm can evaluate, and thus monitor, tree health remotely and automatically from smart sensor data by taking advantage of the well-established internet of things (IoT) network and machine learning algorithm.",Sensors,2019,10.3390/s19143115,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5e020282d6c27a9b7ddc52cb3c77b4165fa1661f,https://www.semanticscholar.org/paper/5e020282d6c27a9b7ddc52cb3c77b4165fa1661f,Time Series Analysis and Forecasting with Automated Machine Learning on a National ICD-10 Database,"The application of machine learning (ML) for use in generating insights and making predictions on new records continues to expand within the medical community. Despite this progress to date, the application of time series analysis has remained underexplored due to complexity of the underlying techniques. In this study, we have deployed a novel ML, called automated time series (AutoTS) machine learning, to automate data processing and the application of a multitude of models to assess which best forecasts future values. This rapid experimentation allows for and enables the selection of the most accurate model in order to perform time series predictions. By using the nation-wide ICD-10 (International Classification of Diseases, Tenth Revision) dataset of hospitalized patients of Romania, we have generated time series datasets over the period of 2008–2018 and performed highly accurate AutoTS predictions for the ten deadliest diseases. Forecast results for the years 2019 and 2020 were generated on a NUTS 2 (Nomenclature of Territorial Units for Statistics) regional level. This is the first study to our knowledge to perform time series forecasting of multiple diseases at a regional level using automated time series machine learning on a national ICD-10 dataset. The deployment of AutoTS technology can help decision makers in implementing targeted national health policies more efficiently.",International journal of environmental research and public health,2020,10.3390/ijerph17144979,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4c54614d08ead9bfb94218247b9fd68563ec90ae,https://www.semanticscholar.org/paper/4c54614d08ead9bfb94218247b9fd68563ec90ae,Using Machine Learning for the Calibration of Airborne Particulate Sensors,"Airborne particulates are of particular significance for their human health impacts and their roles in both atmospheric radiative transfer and atmospheric chemistry. Observations of airborne particulates are typically made by environmental agencies using rather expensive instruments. Due to the expense of the instruments usually used by environment agencies, the number of sensors that can be deployed is limited. In this study we show that machine learning can be used to effectively calibrate lower cost optical particle counters. For this calibration it is critical that measurements of the atmospheric pressure, humidity, and temperature are also made.",Sensors,2019,10.3390/s20010099,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
11b97b48ea1c56332b69456fda5574dbbe6c752e,https://www.semanticscholar.org/paper/11b97b48ea1c56332b69456fda5574dbbe6c752e,IoT-inspired machine learning-assisted sedentary behavior analysis in smart healthcare industry,,Journal of Ambient Intelligence and Humanized Computing,2021,10.1007/s12652-021-03371-x,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4ecd28c7a868f70c39f9d475a949b7b3ce18c947,https://www.semanticscholar.org/paper/4ecd28c7a868f70c39f9d475a949b7b3ce18c947,Prediction of Incident Hypertension Within the Next Year: Prospective Study Using Statewide Electronic Health Records and Machine Learning,"Background As a high-prevalence health condition, hypertension is clinically costly, difficult to manage, and often leads to severe and life-threatening diseases such as cardiovascular disease (CVD) and stroke. Objective The aim of this study was to develop and validate prospectively a risk prediction model of incident essential hypertension within the following year. Methods Data from individual patient electronic health records (EHRs) were extracted from the Maine Health Information Exchange network. Retrospective (N=823,627, calendar year 2013) and prospective (N=680,810, calendar year 2014) cohorts were formed. A machine learning algorithm, XGBoost, was adopted in the process of feature selection and model building. It generated an ensemble of classification trees and assigned a final predictive risk score to each individual. Results The 1-year incident hypertension risk model attained areas under the curve (AUCs) of 0.917 and 0.870 in the retrospective and prospective cohorts, respectively. Risk scores were calculated and stratified into five risk categories, with 4526 out of 381,544 patients (1.19%) in the lowest risk category (score 0-0.05) and 21,050 out of 41,329 patients (50.93%) in the highest risk category (score 0.4-1) receiving a diagnosis of incident hypertension in the following 1 year. Type 2 diabetes, lipid disorders, CVDs, mental illness, clinical utilization indicators, and socioeconomic determinants were recognized as driving or associated features of incident essential hypertension. The very high risk population mainly comprised elderly (age>50 years) individuals with multiple chronic conditions, especially those receiving medications for mental disorders. Disparities were also found in social determinants, including some community-level factors associated with higher risk and others that were protective against hypertension. Conclusions With statewide EHR datasets, our study prospectively validated an accurate 1-year risk prediction model for incident essential hypertension. Our real-time predictive analytic model has been deployed in the state of Maine, providing implications in interventions for hypertension and related diseases and hopefully enhancing hypertension care.",Journal of medical Internet research,2018,10.2196/jmir.9268,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1f0721a3f54a1f56e647a0e02014be06acc9c5a2,https://www.semanticscholar.org/paper/1f0721a3f54a1f56e647a0e02014be06acc9c5a2,Proactive machine-learning-based approaches to vaccine hesitancy for a potential SARS-Cov-2 vaccine,"Abstract Background Polls in the US and France found a concerning share of respondents (50% and 26%, respectively) stating that they are not committed to receiving or simply saying they would not accept vaccination against SARS-CoV-2[1][2]. In this context, it is worth revisiting machine-learning approaches to predicting vaccine hesitancy - such as the one developed for MMR vaccination at the individual level by Bell et al.[4] amid Europe's recent measles epidemic - as a first step of a proactive policy. Proposed Methods and Expectations In the MMR case, using 44K child-healthcare records including vaccination data, a LASSO logistic regression based on a low number of attributes of the child and his or her family and community produced risk scores, making them readily interpretable by healthcare professionals. Since children are regularly the target population for immunization efforts, recent pediatric and school-age records, in concert with other social and medical features, could provide suitable input for algorithms estimating the probability of refusal of a SARS-Cov-2 vaccine for other members of a household. This is contingent upon data on acceptance and refusal being collected and paired with these inputs in areas where the vaccine will first be deployed (if developed), which gives another argument for such timely and organized data collection. Speculating about the future performance of a new model trained on truly “out of sample” data specific to a novel problem should be avoided. Benchmarks for success in terms of measures such as precision and recall, however, have to be set in light of the gravity of the issue and other available methods. Finally, any model trained with the aim of predicting vaccine hesitancy for a SARS-Cov-2 vaccine should be coupled with tailored communication policies tested as part of the first vaccination efforts. Cornwall, Science Mag, Jun 30, 2020 Peretti-Watel et al., The Lancet, May 20, 2020 Bell et al., IEEE ICHI, 2019 Key messages Data on acceptance and refusal for the first (potential) SARS-Cov-2 vaccination campaigns should be collected and matched with health records to enable models predicting vaccine hesitancy. The output of machine learning models predicting vaccine hesitancy should be paired with tested policies respectfully communicating reliable information on vaccination.",The European Journal of Public Health,2020,10.1093/eurpub/ckaa165.035,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a747e1c8d54ebaf32115e826276a6166d6063bf9,https://www.semanticscholar.org/paper/a747e1c8d54ebaf32115e826276a6166d6063bf9,Operationally-Informed Hospital-Wide Discharge Prediction Using Machine Learning,"Accurate patient discharge time estimates are invaluable for hospital operations management. They are vital for efficient and effective scheduling of hospital resources including beds and staff. Unexpected discharges place strain on the patient families and care providers, in addition to causing hospital inefficiencies. Due to the increasing availability of electronic health record data, predictive models can be leveraged to not only offer clinical decision support, but also to optimize hospital operations. In this work, we incorporate clinical knowledge from operational leaders at Kaiser Perma-nente Northern California to design a predictive model for patient discharge using a novel dataset that contains hourly data from the electronic health records of 14 different Kaiser Permanente hospitals. We train and test several algorithms with varying complexity to predict patient-level discharges for the following day at operationally relevant times on the hospital-centric timescale. The highest AUC we achieve is 0.729 with a gradient boosted model, which significantly outperforms both the current estimates deployed in these 14 facilities and the baseline model without hourly data. A feature permutation importance assessment is performed and we conclude that the majority of the improvement is due to the inclusion of the detailed, hourly data.","2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM)",2021,10.1109/HEALTHCOM49281.2021.9399025,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
457d1f03d6c8d34abb8a72a3bc02b8c41d9e94a4,https://www.semanticscholar.org/paper/457d1f03d6c8d34abb8a72a3bc02b8c41d9e94a4,A Method for Machine Learning Generation of Realistic Synthetic Datasets for Validating Healthcare Applications,"BackgroundDigital health applications can improve quality and effectiveness of healthcare, by offering a number of tools to patients, professionals, and the healthcare system. Introduction of new technologies is not without risk, and digital health applications are often considered a medical device. Assuring their safe operation requires, amongst others, clinical validation, which needs large datasets to test their application in realistic clinical scenarios. Access to such datasets is challenging, due to concerns about patient privacy. Development of synthetic datasets, which will be sufficiently realistic to test digital applications, is seen as a potential alternative, enabling their deployment.

ObjectiveThe aim of work was to develop a method for the generation of realistic synthetic datasets, statistically equivalent to real clinical datasets, and demonstrate that Generative Adversarial Network based approach is fit for purpose.

MethodA generative adversarial network was implemented and trained, in a series of six experiments, using numerical and categorical variables from three clinically relevant datasets, including ICD-9 and laboratory codes from the MIMIC III dataset. A number of contextual steps provided the success criteria for the synthetic dataset.

ResultsThe approach created a synthetic dataset that exhibits very similar statistical characteristics with the real dataset. Pairwise association of variables is very similar. A high degree of Jaccard similarity and a successful K-S test further support this.

ConclusionsThe proof of concept of generating realistic synthetic datasets was successful, with the approach showing promise for further work.",medRxiv,2021,10.1101/2021.02.11.21250741,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5d4c5a7f6b4e8882878cd17c6c3032e71a657fb,https://www.semanticscholar.org/paper/d5d4c5a7f6b4e8882878cd17c6c3032e71a657fb,Leveraging Social Media Activity and Machine Learning for HIV and Substance Abuse Risk Assessment: Development and Validation Study,"Background Social media networks provide an abundance of diverse information that can be leveraged for data-driven applications across various social and physical sciences. One opportunity to utilize such data exists in the public health domain, where data collection is often constrained by organizational funding and limited user adoption. Furthermore, the efficacy of health interventions is often based on self-reported data, which are not always reliable. Health-promotion strategies for communities facing multiple vulnerabilities, such as men who have sex with men, can benefit from an automated system that not only determines health behavior risk but also suggests appropriate intervention targets. Objective This study aims to determine the value of leveraging social media messages to identify health risk behavior for men who have sex with men. Methods The Gay Social Networking Analysis Program was created as a preliminary framework for intelligent web-based health-promotion intervention. The program consisted of a data collection system that automatically gathered social media data, health questionnaires, and clinical results for sexually transmitted diseases and drug tests across 51 participants over 3 months. Machine learning techniques were utilized to assess the relationship between social media messages and participants' offline sexual health and substance use biological outcomes. The F1 score, a weighted average of precision and recall, was used to evaluate each algorithm. Natural language processing techniques were employed to create health behavior risk scores from participant messages. Results Offline HIV, amphetamine, and methamphetamine use were correctly identified using only social media data, with machine learning models obtaining F1 scores of 82.6%, 85.9%, and 85.3%, respectively. Additionally, constructed risk scores were found to be reasonably comparable to risk scores adapted from the Center for Disease Control. Conclusions To our knowledge, our study is the first empirical evaluation of a social media–based public health intervention framework for men who have sex with men. We found that social media data were correlated with offline sexual health and substance use, verified through biological testing. The proof of concept and initial results validate that public health interventions can indeed use social media–based systems to successfully determine offline health risk behaviors. The findings demonstrate the promise of deploying a social media–based just-in-time adaptive intervention to target substance use and HIV risk behavior.",Journal of medical Internet research,2021,10.2196/22042,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
34550400735c07f8ccf465a9cb6254e9a998b7b4,https://www.semanticscholar.org/paper/34550400735c07f8ccf465a9cb6254e9a998b7b4,Machine Learning Approach For Clustering Of Countries To Identify The Best Strategies To Combat Covid-19,"The purpose of this study is to identify how different government measures impacted the level of Covid-19 influence on countries of similar nature. Demographic, economic, health, and weather conditions were considered to identify countries that are inherently similar in nature. This grouping along with Covid-19 epidemiology data was used to cluster countries over a period of time after Covid-19 struck. We identified those countries which changed clusters over a time period and were influenced differently by the impact of Covid-19. We then looked at the government measures through the stringency index of containment measures and observed a relation in how different stringency measures impacted the countries differently even though they belonged to the same original group. We also observed that countries that eased restrictions quickly after containment measures had to go back to the earlier stringent measures. Gradual ease of containment measure was more efficient in tackling Covid-19. The inherent grouping of countries done in our study can be used in the future as well to deploy similar measures when faced with Covid-19 like pandemic situation. The strategies adopted on average by countries within each inherent cluster can become the base for handling Covid-19 or any such pandemic in the future. The significance of the work resides in the fact that the strategies would not be aligned to economic conditions of a nation (developed versus developing) or a single factor like healthcare facilities but based on a varied list of inherent factors using machine learning methods.","2021 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS)",2021,10.1109/IEMTRONICS52119.2021.9422621,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
003fd4c1c8b370de0be5eca6068604dbf8c46a62,https://www.semanticscholar.org/paper/003fd4c1c8b370de0be5eca6068604dbf8c46a62,Unsupervised Assessment of Balance and Falls Risk Using a Smartphone and Machine Learning,"Assessment of health and physical function using smartphones (mHealth) has enormous potential due to the ubiquity of smartphones and their potential to provide low cost, scalable access to care as well as frequent, objective measurements, outside of clinical environments. Validation of the algorithms and outcome measures used by mHealth apps is of paramount importance, as poorly validated apps have been found to be harmful to patients. Falls are a complex, common and costly problem in the older adult population. Deficits in balance and postural control are strongly associated with falls risk. Assessment of balance and falls risk using a validated smartphone app may lessen the need for clinical assessments which can be expensive, requiring non-portable equipment and specialist expertise. This study reports results for the real-world deployment of a smartphone app for self-directed, unsupervised assessment of balance and falls risk. The app relies on a previously validated algorithm for assessment of balance and falls risk; the outcome measures employed were trained prior to deployment on an independent data set. Results for a sample of 594 smartphone assessments from 147 unique phones show a strong association between self-reported falls history and the falls risk and balance impairment scores produced by the app, suggesting they may be clinically useful outcome measures. In addition, analysis of the quantitative balance features produced seems to suggest that unsupervised, self-directed assessment of balance in the home is feasible.",Sensors,2021,10.3390/s21144770,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a0051e9e2e42f26077b35801c0f504a0eeb328dc,https://www.semanticscholar.org/paper/a0051e9e2e42f26077b35801c0f504a0eeb328dc,MADP-IIME: malware attack detection protocol in IoT-enabled industrial multimedia environment using machine learning approach,,,2021,10.1007/S00530-020-00743-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1c8acc8c04fa1567843b0e53b258ba3441df6018,https://www.semanticscholar.org/paper/1c8acc8c04fa1567843b0e53b258ba3441df6018,Machine Learning Models for Predicting Neonatal Mortality: A Systematic Review,"Introduction: Approximately 7,000 newborns die every day, accounting for almost half of child deaths under 5 years of age. Deciphering which neonates are at increased risk for mortality can have an important global impact. As such, integrating high computational technology (e.g., artificial intelligence [AI]) may help identify the early and potentially modifiable predictors of neonatal mortality. Therefore, the objective of this study was to collate, critically appraise, and analyze neonatal prediction studies that included AI. Methods: A literature search was performed in PubMed, Cochrane, OVID, and Google Scholar. We included studies that used AI (e.g., machine learning (ML) and deep learning) to formulate prediction models for neonatal death. We excluded small studies (n < 500 individuals) and studies using only antenatal factors to predict mortality. Two independent investigators screened all articles for inclusion. The data collection consisted of study design, number of models, features used per model, feature importance, internal and/or external validation, and calibration analysis. Our primary outcome was the average area under the receiving characteristic curve (AUC) or sensitivity and specificity for all models included in each study. Results: Of 434 articles, 11 studies were included. The total number of participants was 1.26 M with gestational ages ranging from 22 weeks to term. Number of features ranged from 3 to 66 with timing of prediction as early as 5 min of life to a maximum of 7 days of age. The average number of models per study was 4, with neural network, random forest, and logistic regression comprising the most used models (58.3%). Five studies (45.5%) reported calibration plots and 2 (18.2%) conducted external validation. Eight studies reported results by AUC and 5 studies reported the sensitivity and specificity. The AUC varied from 58.3% to 97.0%. The mean sensitivities ranged from 63% to 80% and specificities from 78% to 99%. The best overall model was linear discriminant analysis, but it also had a high number of features (n = 17). Discussion/Conclusion: ML models can accurately predict death in neonates. This analysis demonstrates the most commonly used predictors and metrics for AI prediction models for neonatal mortality. Future studies should focus on external validation, calibration, as well as deployment of applications that can be readily accessible to health-care providers.",Neonatology,2021,10.1159/000516891,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cec81c1acbc36503108337a74d845008d5e68f70,https://www.semanticscholar.org/paper/cec81c1acbc36503108337a74d845008d5e68f70,Machine Learning for Prediction in Electronic Health Data.,"Machine learning for prediction in electronic health data has been deployed for many clinical questions during the last decade. Machine learning methods may excel at finding new features or nonlinear relationships in the data, as well as handling settings with more predictor variables than observations. However, the usefulness of both these data and machine learning has varied. Electronic health data often have quality issues (eg, missingness, misclassification, measurement error), and machine learning may perform similarly to standard techniques for some research questions. Ensembles (running multiple algorithms and either selecting the single best algorithm or creating a weighted average) can help mitigate the latter concern. Using several machine learning tools, Wong et al1 predicted delirium risk for newly hospitalized patients with high-dimensional electronic health record data at a large academic health institution. They compared these approaches with a questionnaire-based scoring system and found improved performance for machine learning with respect to several metrics calculated in a single holdout sample. Their article is a step toward updating delirium risk prediction. It also provides an opportunity to discuss 2 key issues in the current state of machine learning for prediction in electronic health data: evaluation and generalizability. The machine learning researchers who develop novel algorithms for prediction and the clinical teams interested in implementing them are frequently and unfortunately 2 nonintersecting groups. Thus, these algorithms may originally be built and evaluated in the machine learning literature based on metrics that are less clinically useful than other choices. Computer scientists and statisticians may optimize to achieve the best area under the receiver operating characteristic curve (AUC), but what a clinical team might need is high sensitivity or positive predictive value. Worse yet, algorithms can have misleading performance when evaluated only along 1 or 2 dimensions. For example, high AUC, accuracy, and positive predictive values can be accompanied by near-zero levels of sensitivity and specificity. It can also be essential to calculate metrics like the percentage of true cases in the top risk percentile.2 This is especially important when a goal of the tool is to target high-risk patients for interventions. Wong and colleagues1 helpfully compute AUC, positive predictive values, sensitivity, and specificity. However, one accepted standard for evaluation that should be adopted in future clinical machine learning applications is K-fold cross-validation (eg, with K = 10) rather than the single holdout validation sample in their article. K-fold cross-validation involves K successive mutually exclusive validation sets where the algorithm fitting is iteratively performed on the nonvalidation data (ie, training set). At the end, each observation in the full data has a predicted value that was obtained from when it was part of a validation set. Typically, metrics calculated based on these K-fold cross-validated predicted values will more effectively assess overfitting and have lower variance.3 Of course, assessing the generalizability of a prediction algorithm goes well beyond using crossvalidated metrics to evaluate overfitting. Wong et al1 carefully discussed a number of limitations in their work, including the lack of external validation in other health systems. As in similar studies, the step from good performance in the study to a generalizable algorithm is vast and sometimes may not be feasible. Patients receiving treatment in varied care settings or geographic regions simply may require tailored tools. Recognizing the need for unique tools in different populations is not inherently negative, but one of many considerations not magically solved by using machine learning. Even those algorithms that prove to be generalizable may quickly become outdated as treatment patterns or physician incentives to code health conditions change.4 Increased social tolerance for certain + Related article",JAMA network open,2018,10.1001/jamanetworkopen.2018.1404,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3ea3443d402ba253c7f4719ab3dd6768c19445c5,https://www.semanticscholar.org/paper/3ea3443d402ba253c7f4719ab3dd6768c19445c5,ECG diagnosis device based on machine learning,"ECG signal can reflect rich physiological information of human body. The health state of human body can be obtained through the analysis of ECG signal. At present, most ECG detectors can only detect ECG signal and calculate heart rate, but can not carry out intelligent diagnosis. A STM32 development board with a front-end acquisition module is used to collect the analog ECG signal generated by an ECG simulator in this works, and the collected signal is uploaded to the Edge Impulse platform for the construction and training of diagnostic model. Then, the trained ECG diagnosis neural network model is deployed in the main controller of the development board for heart rate calculation and ECG signal diagnosis. The device can not only monitor the user's ECG signal, but also display the graphical ECG signal, calculate heart rate value and classify diagnostic results.",2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT),2021,10.1109/ICESIT53460.2021.9697057,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6b50c433bdfee628e81f0f4b5dc922b9c2cc4fa7,https://www.semanticscholar.org/paper/6b50c433bdfee628e81f0f4b5dc922b9c2cc4fa7,Machine Learning Prediction of Surgical Intervention for Small Bowel Obstruction,"Small bowel obstruction (SBO) results in >350,000 operations and >$2 billion annual health care expenditures in the US. Prompt, effective identification of patients at high/low surgery risk could improve survival, lower complication rates, and shorten hospitalization lengths. SBO surgery prediction models were developed based on SBO-related encounters in the Duke University Health System between 2013 and 2017. A total of 3,910 encounters among 3,374 unique patients were identified. Performance was assessed in each hour after admission when predicting whether patients will (a) receive surgery within 24 hours, and (b) receive surgery during the current encounter. Potential benefits of model-based discharge were assessed using the incorrect discharge rate and average reduction in hospital stay. Model-based discharge of low-risk patients was projected to reduce the average length of stay among patients not receiving surgery by >60 hours while maintaining an incorrect discharge rate lower than the observed readmission rate (9.3%). AUROC for the 24-hour prediction task increased from 0.644 to 0.779 at 12 and 72 hours post-admission, respectively. Future work will prospectively explore the benefits of model deployment in an inpatient setting.",medRxiv,2021,10.1101/2021.04.13.21255428,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ccbc2735c99b7eb0a3998fd5c63fa9423b17e7c,https://www.semanticscholar.org/paper/2ccbc2735c99b7eb0a3998fd5c63fa9423b17e7c,A MACHINE LEARNING FRAMEWORK BASED ON VARIOUS NETWORK TRAFFIC CHARACTERISTICS TO IDENTIFY AND CLASSIFY THE DEFAULT BEHAVIOR OF IOT DEVICES ON A NETWORK,"The Internet of Things (IoT) is being
well acquire to the next era of revolutionary
generations amongst the new technologies. IoT
technology being hailed so hard we had to stop in
our society, smart homes, enterprises, and smart
cities. Dynamics of smart one’s are increasingly
being equipped with a profusion of IoT devices.
Due to the tremendous upgradation of knowledge
in various aspects impresarios of such smart
environments may not even be fully aware of
their working nature or principles of IoT devices,
assets and functioning properly safe from cyberattacks. In this paper, we addressing this
challenge by developing a robust framework for
IoT device classification using traffic
characteristics obtained at the level of network
level. As a part of robust framework, firstly, we
have a tendency to instrument a smart
environment with 28 completely different IoT
devices, spanning cameras, lights, plugs, motion
sensors, appliances and health-monitors. We
have a tendency to collect and synthesize traffic
traces from this framework infrastructure for a
period of 6 months, a type of subset of which we
release as open data for the community to use.
Second, we have to present or gifts the insights
into the underlying network traffic
characteristics using statistical and applied
mathematical attributes such as activity cycles,
port numbers, signaling patterns and cipher
suites. Third, we have a tendency to develop a
multi-stage machine learning based classification
algorithm and demonstrate its ability to identify
specific IoT devices with over 99% accuracy
based on their network flow of activity. Finally,
we have a tendency to discuss the trade-offs
between cost, speed, and performance involved in
deploying the classification network framework
in real-time. Our study paves the way for
impresarios of smart environments to monitor
their IoT devices and assets for presence,
functionality, and cyber-security without
requiring any specialized devices or protocols.",International Journal of Engineering Applied Sciences and Technology,2021,10.33564/ijeast.2021.v06i05.029,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c99985fabd2e38c2b567d11c59d965e9e267c8fd,https://www.semanticscholar.org/paper/c99985fabd2e38c2b567d11c59d965e9e267c8fd,Machine Learning Challenges in Pharmacogenomic Research,"Pharmacogenomics (PGx) studies the interaction between drug exposure and the human genome, including the impact of genetic variants on pharmacodynamics, pharmacokinetics, and subsequent clinical outcomes. This relatively new field is rapidly growing in the past few decades, primarily due to the affordability of genotyped data and the exponential increase and availability of phenotypic data. With advances in genotyping technologies and improved phenotyping methods using electronic health records (EHRs), researchers can study millions of genetic variants linked with thousands of disease phenotypes and drug treatments. Today, the number of data points generated in genomics and PGx phenotypes fits the definition of big data, which is characterized by high volume (the data set size), wide variety (heterogeneity of data types), high velocity (the speed of accumulation of data), and inconsistent quality (the veracity and reliability of data). Analyzing such very large data sets may uncover novel trends and complex drug response patterns that are otherwise hidden from smaller, more controlled experiments. However, the task of sifting through these data, formalizing data representations, reconciling data sets across multiple sources, and distilling observed associations into knowledge that can personalize drug therapy often exceeds the capacity of human cognition. New methods and computing technologies to automate analytical model building for PGx are needed and could significantly accelerate the discovery of new PGx relationships. As one of the foundations of artificial intelligence, ML represents a set of methods that can automatically uncover patterns in data and use the detected patterns to predict future data. ML is more capable of finding hidden patterns among multivariables than traditional association analyses; therefore, it is well suited for highdimensional data analysis needed for PGx research. Supervised, unsupervised, and reinforcement learning are the three basic ML paradigms (Figure 1). Supervised learning aims to solve classification/regression problems. It formulates a model from prelabeled (training) data and uses the model to predict unseen (testing) data, e.g., to estimate an individual’s risk of developing a severe reaction after taking a drug. Unsupervised learning, i.e., knowledge discovery, aims to recognize patterns in unlabeled data through cluster analysis. A good example is automated grouping of individuals with a similar response to a drug. Reinforcement learning has gained momentum recently after reaching humanlevel performance in playing the ancient game of Go. It focuses on sequential decision problems, in which a model interactively learns by using trial and error and using feedback from its own actions and experiences. A notable implementation of reinforcement learning is to dynamically optimize treatment for sepsis. Machine learning has made great strides in the last decade and has found widespread use. Traditionally, investigators start with feature engineering to preselect relevant features, such as comorbidities. Deep learning, an emerging subtype of ML defined by greater layer depth of the underlying neural networks, offers an endtoend learning ability that can automatically extract features. Recently, DeepMind used deep learning to accurately determine a protein’s structure from its amino acid sequence, demonstrating the realworld impact of ML in biomedical research. A similar approach could be applied to biological data from highly controlled drug discovery experiments that carefully collect drug exposure, pharmacokinetics, and pharmacodynamics data over time, e.g., accelerating therapeutics for opportunities in medicine. That type of systems biology analysis could unearth the network of physiologic and molecular influences on drug response. Few studies focus exclusively on PGx data. Two recent studies used ML to predict drug response using a combination of perturbational data, clinical information, and pharmacogenomic biomarkers. Several manuscripts have provided a systematic review of ML for clinical medicine. This paper will discuss",Clinical pharmacology and therapeutics,2021,10.1002/cpt.2329,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0438b1b209d41bd268b97ae630a37d225ab0e333,https://www.semanticscholar.org/paper/0438b1b209d41bd268b97ae630a37d225ab0e333,Air Quality Prediction and Monitoring using Machine Learning Algorithm based IoT sensor- A researcher's perspective,"Air Pollution (AP) is one of the serious and major environmental problem worldwide. Many researchers have drawn attention and have focused about these problems keeping in mind human health. Air quality prediction information is one of the better ways through which people can be informed to be more vigilant about serious health issues and protect human health caused by air pollution. In many metropolitan cities air pollution is a major challenging environmental issue. To analyze the present traffic condition of the city, local authorities can be enabled by real time monitoring of pollution data which makes appropriate decisions. Hence an early system is required for monitoring and calculating the level of AP using Air Quality (AQ) which is essential for predicting exactly the pollutant concentrations. The prediction of AQ can be improved by deploying Internet of Things (IoT) based sensor which are considerably changing the prediction of AQ dynamically. The prediction of AP discussed and estimated using many existing techniques are very expensive and have very low accuracy. The technological advancement of Machine Learning (ML) algorithm can be very fast increasing and searching almost all fields and applications whereas AP prediction has not prohibited from those fields. This paper describes about various studies of ML algorithm relating to AP prediction and monitoring based on the IoT sensor data in the context of various cities. This paper also summaries real time and historical data based on the AQ prediction models tools and techniques and describes about recent research methodologies merits and demerits of AQ prediction, along with the challenges based on real time monitoring and prediction of AQ.",2021 6th International Conference on Communication and Electronics Systems (ICCES),2021,10.1109/ICCES51350.2021.9489153,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4181fa9e6188e371698b0a79eb2ca780a0bf27e7,https://www.semanticscholar.org/paper/4181fa9e6188e371698b0a79eb2ca780a0bf27e7,Deploying Machine Learning Inference on Diabetic Retinopathy in Binary and Multi-class Classification,"Diabetic Retinopathy is a condition of the person's eye that causes vision loss and blindness in diabetic people. Among adults between 20–74 years, this disease most of the time acts as the cause of blindness. Also, it is the leading reason behind cecity among working-aged adults worldwide. An efficient health care system contributes to an essential part of the country's economy, development, and industrialization. It affects one out of three persons with diabetes. The longer a person has diabetes, the higher their risk of developing some ocular problem. The mobile and web application built adds assistance to the people for endorsing their qualms and knowing about their condition's severity. Since most of the users can be from rural areas, we built applications that work both offline and online. The inference is to select a configuration based on a single input. To decrease the magnitude of the mobile application model, we implemented MobileN et architecture. It is considered a light weightedmodel as it has fewer parameters than others, making it suitable for the application objective. The accuracy of MobileNet is 76 percent. ResNet 50 architecture is used in the web application, which requires an internet facility to predict the output. Because of the increase in the parameters, it provides higher accuracy when compared to the MobileN et model. Kaggle eyepacs dataset is given as input for both models. The dataset is divided into five classes: No Diabetic Retinopathy, mild, moderate, severe, and proliferative. The models classify the images given as input and display one of these class labels as a result. An oversampling technique has been implemented to overcome the problem of data bias. NodeJS and python have been used to build web applications and android studio for mobile applications. The time taken to display the result in both applications is less than 10 seconds. The size of the mobile application has been reduced from 120MB to 25 MB. This application is helpful in rural areas wherever they lack facilities to run tests while obtaining the results on their phones and any web browser by simply up- loading the scanned image of the patient's eye.",2021 International Conference on Industrial Electronics Research and Applications (ICIERA),2021,10.1109/ICIERA53202.2021.9726533,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
456b4d65f1019c3513a95d4691fe4fad0f1f4ae7,https://www.semanticscholar.org/paper/456b4d65f1019c3513a95d4691fe4fad0f1f4ae7,Assessment of the planetary boundary layer height by means of machine learning techniques using ceilometer signals,"<p>It is well known that anthropogenic aerosols deteriorate air quality increasing public health risk. Therefore their characterization must be one of the main objectives in atmosphere studies, although the heterogeneous distribution of the aerosols in the atmosphere hampers it. Anthropogenic aerosols are mostly concentrated within the planetary boundary layer (PBL) that extends from the surface up to a variable height that usually coincides with the presence of a temperature inversion. The PBL height, then, is affected by the radiation emitted by the surface causing turbulence and evolving along the day and in this way limiting the vertical mixing of the air pollutants generated near the surface. Therefore, it can be assumed that the lower the PBL height, the higher the aerosol concentration from local sources. Lidars have demonstrated their capabilities to study the aerosol vertical distribution and their spatio-temporal evolution can provide very complete information on both aerosol spatial distribution and their characterization. Their wavelength dependence of the backscatter and extinction coefficients allows for a more detailed discrimination of aerosol types. On the other hand, ceilometers are capable of providing continuous aerosol vertical profiles with good spatial resolution and a large range, besides ceilometers operating at 1064nm can provide backscatter and extinction coefficients as Lidar instruments. The present work has been carried out in the Madrid metropolitan area located in the center of the Iberian Peninsula, which counts with a population of nearly 6 million inhabitants and a car fleet of almost 3 million vehicles. Its main objective is the assessment of the planetary boundary layer height by means of machine learning techniques using ceilometer signals and also its validation by using multiwavelength lidar measurements and radiosoundings. Typical techniques as the wavelet and the gradient methods are unable to detect the PBL in cases with presence of low clouds or residual layers. For that purpose, several profiles stored in the Madrid database, covering different synoptic situations as long-range transport of aerosols and clean-atmosphere situations are used. These profiles have been performed by the CHM15k Nimbus ceilometer deployed next to the MDR-CIEMAT ACTRIS station (40.4565&#186;N, 3.7257&#186;W, 663 m a.s.l.), equipped with a Lidar-Raman instrument (integrated in EARLINET-ACTRIS) and located in the Madrid North-West city outskirts.</p><p>&#160;</p><p><strong><em>Acknowledgements </em></strong></p><p>This work was supported by H2020 programme from the European Union (grant 654109, ACTRIS-2 project), the Spanish Ministry of Economy and Competitivity (CRISOL, CGL2017-85344-R) and Madrid Regional Government (TIGAS-CM, Y2018/EMT-5177). &#160;</p>",,2021,10.5194/ems2021-156,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9ce67d57ff777f3559d5ba088db9df8dc980f956,https://www.semanticscholar.org/paper/9ce67d57ff777f3559d5ba088db9df8dc980f956,Hybrid feature selection and machine learning approaches for assessing the arsenic awareness of local farming communities in Bengal Basin,"<p>High levels of arsenic in drinking water and food materials continue to pose a global health challenge. Over 127 million people alone in Bangladesh (BD) and West Bengal (WB) state of India are exposed to elevated levels of arsenic in drinking water. Despite decades of research and outreach, arsenic awareness in communities continues to be low. Specifically, very few studies have reported arsenic awareness among low-income farming communities. A comprehensive approach to assess arsenic awareness, hence, is a key step in identifying research and development priorities so that appropriate stakeholder engagement may be designed to tackle arsenic menace. In this study, we developed a 12-point comprehensive arsenic awareness index (CAAI) and identified key awareness drivers (KADs) associated with CAAI using hybrid feature selection for analysing the responses from the survey conducted in arsenic-affected areas of WB and BD. The two questionnaire surveys comprised of 73 questions each, covering the health, water and community, and food related aspect of arsenic contamination. Comparison of CAAIs showed that the BD farmers were generally more arsenic-aware (CAAI = 7.7) than WB farmers (CAAI = 6.8). Interestingly, the reverse was true for the awareness linked to arsenic in the food chain. Application of hybrid feature selection identified 15 KADs, which included factors related to stakeholder interventions and cropping practices. Inclusion of Boruta wrapper in the hybrid feature selection aided in discarding the randomly associated chi-square (&#967;<sup>2</sup>) significant variables (p < 0.05), which included the commonly perceived socio-economic factors such as age, gender and income. An inter-comparison of KADs revealed the differences in objectives and importance laid on various interventions under different government regimes for tackling arsenic menace. Hence, the CAAI and KADs combination revealed a contrasting arsenic awareness between the two farming communities, albeit their cultural similarities. For analysing the predictive power of the KADs for CAAI, both linear and non-linear machine learning models were deployed. Among ML algorithms, classification and regression trees and single C5.0 tree could estimate CAAIs with an average accuracy of 84%. Both communities agreed on policy changes on water testing and clean water supply, while there was less importance laid by both farming communities in testing food for arsenic concentration. Specifically, our study shows the need for increasing awareness of risks through the food chain in BD, whereas awareness campaigns should be strengthened to raise overall awareness in WB possibly through media channels as deemed effective in BD. Overall, this study addresses the UN sustainable development goals (SDGs) such as clean water and sanitation (SDG6), zero hunger (SDG2), good health and well-being (SDG3), and echoes with the WHO&#8217;s comprehensive action plan of involving water testing, awareness-building campaigns, and mitigation options to combat arsenic toxicity menace.&#160;</p>",,2021,10.5194/EGUSPHERE-EGU21-2485,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b4fa3af70fdaf8b5be755e19f648e67f61f490f5,https://www.semanticscholar.org/paper/b4fa3af70fdaf8b5be755e19f648e67f61f490f5,End-to-End Optimized Arrhythmia Detection Pipeline using Machine Learning for Ultra-Edge Devices,"Atrial fibrillation (AF) is the most prevalent cardiac arrhythmia worldwide, with 2% of the population affected. It is associated with an increased risk of strokes, heart failure and other heart-related complications. Monitoring at-risk individuals and detecting asymptomatic AF could result in considerable public health benefits, as individuals with asymptomatic AF could take preventive measures with lifestyle changes. With increasing affordability to wearables, personalized health care is becoming more accessible. These personalized healthcare solutions require accurate classification of bio-signals while being computationally inexpensive. By making inferences on-device, we avoid issues inherent to cloud-based systems such as latency and network connection dependency. We propose an efficient pipeline for real-time Atrial Fibrillation Detection with high accuracy that can be deployed in ultra-edge devices. The feature engineering employed in this research catered to optimizing the resource-efficient classifier used in the proposed pipeline, which was able to outperform the best performing standard ML model by 105 × in terms of memory footprint with a mere trade-off of 2% classification accuracy. We also obtain higher accuracy of approximately 6% while consuming 403× lesser memory and being 5.2× faster compared to the previous state-of-the-art (SoA) embedded implementation.",2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA),2021,10.1109/ICMLA52953.2021.00242,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b2ff8b7ee3502446e1893be17be01a9177822712,https://www.semanticscholar.org/paper/b2ff8b7ee3502446e1893be17be01a9177822712,"Remaining Useful Life Estimation for LFP Cells in Second Life Applications /Author=Sanz-Gorrachategui, Ivan; Pastor-Flores, Pablo; Pajovic, Milutin; Wang, Ye; Orlik, Philip V.; Bernal-Ruiz, Carlos; Bono-Nuez, Antonio; Artal-Sevil, JesÃos Sergio /CreationDate=April 4, 2021 /Subject=Machine Learning,","The increasing deployment of battery storage applications in both grid storage and electric vehicle fields is generating a vast used battery market. These batteries are typically recycled but could be reused in Second Life applications. One of the challenges is to obtain an accurate Remaining Useful Life (RUL) estimation algorithm, which determines whether a battery is suitable for reuse and estimates the number of second life cycles the battery will last. In this paper, the RUL estimation problem is considered. We propose several Health Indicators (HI), some of which have not been explored before, along with simple yet effective estimation and classification algorithms. These algorithms include classification techniques such as Regularized Logistic Regression (RLR), and regression techniques such as Multivariable Linear Regression (MLR) and Multi-Layer Perceptron (MLP). As a more advanced solution, a multiple expert system combining said techniques is proposed. The performance of the algorithms and features is evaluated on a recent Lithium Iron Phosphate (LFP) dataset from Toyota Research Institute. We obtain satisfactory results in the estimation of RUL cycles with errors down to 49 RMSE cycles for cells that live up to 1200 cycles, and 0.24% MRE for the prediction of the evolution of capacity. IEEE Transactions on Instrumentation and Measurement c © 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. Mitsubishi Electric Research Laboratories, Inc. 201 Broadway, Cambridge, Massachusetts 02139",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cc59e4e2502ac7eec7f3238311a180fe0590d8a1,https://www.semanticscholar.org/paper/cc59e4e2502ac7eec7f3238311a180fe0590d8a1,Machine learning based network intrusion detection for data streaming IoT applications,"In recent years, Internet of Things (IoT) technologies have been widely used in many fields such as surveillance, health-care, smart metering and environment monitoring. This extensive usage leads to massive data management and a complexity in data analysis. A huge number of IoT sensors are deployed for monitoring task and send continuously their collected data to gateways. IoT applications are analyzing these data flows and making real time decisions about specific monitored events (fire, flood, terrorist attacks, etc.). Anomalies that may be related to sensor failures or network intrusions are affecting such decisions. Therefore, they should be detected and eliminated as soon as they arrive. This task requires real time data processing detectors for making accurate and fast predictions. In this paper, we design an architecture for a real time network intrusion detection system for IoT streaming data. The system was developed, deployed and tested with the two leading stream processing frameworks (Apache Flink and Apache Spark Streaming). We used two different public datasets and different machine learning algorithms. Results show considerable throughputs and high detection accuracy especially for Apache Flink.","2021 21st ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Winter)",2021,10.1109/SNPDWinter52325.2021.00019,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7fffdc878df2dbb7793f60d08c9c32f28cd96d13,https://www.semanticscholar.org/paper/7fffdc878df2dbb7793f60d08c9c32f28cd96d13,Optimal feature extraction and classification-oriented medical insurance prediction model: machine learning integrated with the internet of things,"This paper plans to develop an effective machine learning system integrated with the Internet of Things (IoT) to predict the health insurance amount. IoT in healthcare enables interoperability, machine-to-machine communication, information exchange, and data movement that make healthcare service delivery effective. The model includes three phases (a) Feature Extraction, and (b) Weighted Feature Extraction, and (c) Prediction. The feature extraction process computes two statistical measures: First Order Statistics like mean, median, standard deviation, the maximum value of entire data, and minimum value of entire data, and Second-Order Statistics like Kurtosis, skewness, correlation, and entropy. The prediction process deploys a renowned machine learning algorithm called Neural Network (NN). As the main contribution, the weighted feature vector is developed here, where the weight optimally tuned by Modified Whale Optimization Algorithm (WOA). Also, the contribution relies on NN, where the training algorithm replaced with the same modified WOA for weight update. The modified WOA developed here is termed as Fitness dependent Randomized Whale Optimization Algorithm (FR-WOA). At last, the valuable experimental analysis using three datasets confirms the efficient performance of the suggested model.",International Journal of Computers and Applications,2020,10.1080/1206212X.2020.1733307,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3266b92b981057a5ef152ccbdbdc0481045c03be,https://www.semanticscholar.org/paper/3266b92b981057a5ef152ccbdbdc0481045c03be,"Realistically Integrating Machine Learning Into Clinical Practice: A Road Map of Opportunities, Challenges, and a Potential Future.","Recently, interest in machine learning has rapidly grown within the health care community. This popularity has been due in part to the advances in perception tasks such as speech processing and image analysis, which has led to the successful implementation of machine learning across a variety of industries: from the ancient game of Go to Netflix movie suggestions.1 The abundance of electronic health record data coupled with the low costs of computation power and data storage makes machine learning and medicine well matched. Although health care has been traditionally slow to adopt new technologies, the time is approaching when machine learning delivers on promises to improve the current and future practice of perioperative medicine. Deployment and operationalization of a machinelearning model require synthesizing knowledge in data processing and model development with a knowledge of medicine and clinical workflows. In this article, we hope to elucidate what machine learning is and why it will transform clinical care, discuss what it takes to implement machine learning in clinical care, address current limitations and drawbacks, and ultimately examine what the future of machine learning in health care may hold. A PRIMER ON MACHINE LEARNING Machine learning is a subset of artificial intelligence in which a computer iteratively learns from data without explicit rule-based programming. Machine-learning models find patterns within data and apply these patterns to new data to make predictions. Because of the computer’s ability to rapidly process large amounts of electronic data, these models are advantageous when using large datasets. Where humans can become overwhelmed with increasingly large and complex data inputs, machine-learning models often thrive. The recent rapid explosion in computational processing power and increasing availability of large data enable capabilities beyond traditional rule-based modeling, including improved analytical capacities and accessibility to unique, potentially hidden insights. As these methods become more widely adopted in the medical community, all parties will benefit. Improvements include increased care efficiency and more accurate hospital reimbursements and increase care quality, such as improved disease classification, predicting complications, and ultimately better outcomes, Machine-learning models have been created to predict an increasing number of clinical outcomes, such as diagnoses and mortality, with applications including C. difficile infection in the inpatient hospital setting,2 identifying molecular markers for cancer treatments,3 and postoperative surgical outcomes.4 Examples of machine learning include a cardiologist using an automated interpretation of an ECG and a radiologist using an automated detection of a lung nodule in a chest x-ray. In both of these examples, a machine-learning model approximates a trained physician’s diagnosis with high accuracy. To date, models are successfully constructed to answer a single clinical question by using appropriately labeled representative data. The tools to develop these models (using languages such as R and Python) are largely free of charge and openly Realistically Integrating Machine Learning Into Clinical Practice: A Road Map of Opportunities, Challenges, and a Potential Future",Anesthesia and analgesia,2020,10.1213/ANE.0000000000004575,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bddb25dad51bfa3ba203d04e7d60d3ac458c971f,https://www.semanticscholar.org/paper/bddb25dad51bfa3ba203d04e7d60d3ac458c971f,Artificial or intelligent? Machine learning and medical selection: possibilities and risks,"Machine learning approaches form the basis of “artificial intelligence” and have been increasingly applied in health services settings. It has been shown that such approaches may produce more accurate predictions in some contexts, compared to conventional statistical approaches, and may also reduce the costs of decision-making through automation. Nevertheless, there are both general limitations to developing and implementing machine learning approaches that must be borne in mind. To date, relatively little research has been published on the potential for machine learning to support personnel selection. Moreover, there are particular challenges and issues that need to be considered if such methods are to be used to support decision-making in medical selection scenarios. This article describes some of these potential advantages and challenges and presents an illustrative example, based on realworld data, related to the selection of medical undergraduates.",,2018,10.15694/MEP.2018.0000256.1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a9d7f354025defe054fff116b769cc1360bb1a90,https://www.semanticscholar.org/paper/a9d7f354025defe054fff116b769cc1360bb1a90,Healthcare and anomaly detection: using machine learning to predict anomalies in heart rate data,,AI & SOCIETY,2020,10.1007/s00146-020-00985-1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0219b3d4f3869c0be0d6fcd96b5df1973d4deeb7,https://www.semanticscholar.org/paper/0219b3d4f3869c0be0d6fcd96b5df1973d4deeb7,A Comparative Analysis of Machine Learning Methods for Class Imbalance in a Smoking Cessation Intervention,"Smoking is one of the major public health issues, which has a significant impact on premature death. In recent years, numerous decision support systems have been developed to deal with smoking cessation based on machine learning methods. However, the inevitable class imbalance is considered a major challenge in deploying such systems. In this paper, we study an empirical comparison of machine learning techniques to deal with the class imbalance problem in the prediction of smoking cessation intervention among the Korean population. For the class imbalance problem, the objective of this paper is to improve the prediction performance based on the utilization of synthetic oversampling techniques, which we called the synthetic minority over-sampling technique (SMOTE) and an adaptive synthetic (ADASYN). This has been achieved by the experimental design, which comprises three components. First, the selection of the best representative features is performed in two phases: the lasso method and multicollinearity analysis. Second, generate the newly balanced data utilizing SMOTE and ADASYN technique. Third, machine learning classifiers are applied to construct the prediction models among all subjects and each gender. In order to justify the effectiveness of the prediction models, the f-score, type I error, type II error, balanced accuracy and geometric mean indices are used. Comprehensive analysis demonstrates that Gradient Boosting Trees (GBT), Random Forest (RF) and multilayer perceptron neural network (MLP) classifiers achieved the best performances in all subjects and each gender when SMOTE and ADASYN were utilized. The SMOTE with GBT and RF models also provide feature importance scores that enhance the interpretability of the decision-support system. In addition, it is proven that the presented synthetic oversampling techniques with machine learning models outperformed baseline models in smoking cessation prediction.",,2020,10.3390/app10093307,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
03499759c304ea827ecb34f6de18ad01bda688b7,https://www.semanticscholar.org/paper/03499759c304ea827ecb34f6de18ad01bda688b7,Automatic Detection of COVID-19 Using X-ray Images with Deep Convolutional Neural Networks and Machine Learning,"The COVID-19 pandemic continues to have a devastating effect on the health and well-being of the global population. A vital step in the combat towards COVID-19 is a successful screening of contaminated patients, with one of the key screening approaches being radiological imaging using chest radiography. This study aimed to automatically detect COVID-19 pneumonia patients using digital chest x-ray images while maximizing the accuracy in detection using deep convolutional neural networks (DCNN). The dataset consists of 864 COVID-19, 1345 viral pneumonia and 1341 normal chest x-ray images. In this study, DCNN based model Inception V3 with transfer learning have been proposed for the detection of coronavirus pneumonia infected patients using chest X-ray radiographs and achieved more than 96% accuracy. The results demonstrate that transfer learning proved to be effective, showed robust performance and easily deployable approach for COVID-19 detection.",medRxiv,2020,10.1101/2020.05.01.20088211,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e4307833c691d79c82a505b91b399ab9eca200c4,https://www.semanticscholar.org/paper/e4307833c691d79c82a505b91b399ab9eca200c4,"Development, Implementation, and Evaluation of a Personalized Machine Learning Algorithm for Clinical Decision Support: Case Study With Shingles Vaccination","Background Although clinical decision support (CDS) alerts are effective reminders of best practices, their effectiveness is blunted by clinicians who fail to respond to an overabundance of inappropriate alerts. An electronic health record (EHR)–integrated machine learning (ML) algorithm is a potentially powerful tool to increase the signal-to-noise ratio of CDS alerts and positively impact the clinician’s interaction with these alerts in general. Objective This study aimed to describe the development and implementation of an ML-based signal-to-noise optimization system (SmartCDS) to increase the signal of alerts by decreasing the volume of low-value herpes zoster (shingles) vaccination alerts. Methods We built and deployed SmartCDS, which builds personalized user activity profiles to suppress shingles vaccination alerts unlikely to yield a clinician’s interaction. We extracted all records of shingles alerts from January 2017 to March 2019 from our EHR system, including 327,737 encounters, 780 providers, and 144,438 patients. Results During the 6 weeks of pilot deployment, the SmartCDS system suppressed an average of 43.67% (15,425/35,315) potential shingles alerts (appointments) and maintained stable counts of weekly shingles vaccination orders (326.3 with system active vs 331.3 in the control group; P=.38) and weekly user-alert interactions (1118.3 with system active vs 1166.3 in the control group; P=.20). Conclusions All key statistics remained stable while the system was turned on. Although the results are promising, the characteristics of the system can be subject to future data shifts, which require automated logging and monitoring. We demonstrated that an automated, ML-based method and data architecture to suppress alerts are feasible without detriment to overall order rates. This work is the first alert suppression ML-based model deployed in practice and serves as foundational work in encounter-level customization of alert display to maximize effectiveness.",Journal of medical Internet research,2020,10.2196/16848,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c7ae742beb66e4a05f1982679b6d179155d654fa,https://www.semanticscholar.org/paper/c7ae742beb66e4a05f1982679b6d179155d654fa,Exploring the Applications of Machine Learning in Healthcare,"

The rapid progress in domains like machine learning, and big data has created plenty
of opportunities in data-driven applications particularly healthcare. Incorporating machine intelligence
in healthcare can result in breakthroughs like precise disease diagnosis, novel methods
of treatment, remote healthcare monitoring, drug discovery, and curtailment in healthcare
costs. The implementation of machine intelligence algorithms on the massive healthcare datasets
is computationally expensive. However, consequential progress in computational power
during recent years has facilitated the deployment of machine intelligence algorithms in
healthcare applications. Motivated to explore these applications, this paper presents a review of research
works dedicated to the implementation of machine learning on healthcare datasets. The studies
that were conducted have been categorized into following groups (a) disease diagnosis and detection,
(b) disease risk prediction, (c) health monitoring, (d) healthcare related discoveries, and (e) epidemic
outbreak prediction. The objective of the research is to help the researchers in this field to get a
comprehensive overview of the machine learning applications in healthcare. Apart from revealing
the potential of machine learning in healthcare, this paper will serve as a motivation to foster advanced
research in the domain of machine intelligence-driven healthcare.
","International Journal of Sensors, Wireless Communications and Control",2019,10.2174/2210327910666191220103417,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
353cfdf92946122f111d0d3d64fc92aa596790ec,https://www.semanticscholar.org/paper/353cfdf92946122f111d0d3d64fc92aa596790ec,Spectrum Allocation Scheme for Intelligent Partition Based on Machine Learning for Inter-WBAN Interference,"A wireless body area network (WBAN) is a physical network system with functions such as information collection and data transmission, and provides a key means for real-time health detection and medical services. However, if WBANs deployed in a dense environment lack internetwork coordination, it can cause high interference. In addition, WBANs have the characteristics of social mobility, and regular frequency changes will increase energy consumption. In this article, the co-frequency interference between coexisting WBANs in dense environments is analyzed, and the real-time frequency of mobile WBANs is studied emphatically to alleviate these problems. A spectrum allocation scheme for intelligent partition based on machine learning is proposed as a mixed scheduling scheme that combines graph coloring and partitioning ideas. WBANs' self-organized dynamic clustering forms multiple cells according to location, and the cells use a vertex coloring algorithm of self-generating topological graphs to coordinate their frequency bands and assign different colors to coexisting cells. When a new user joins the area, it will self-organize and cluster to a divided cell, and the cell will divide frequency bands for the new user. No other bands need to be changed, and the experiments conducted in this research demonstrate that the proposed arithmetic can adapt well to the fast-changing WBANs of the topology, and the system anti-interference performance, frequency resource utilization, and system stability are favorable.",IEEE Wireless Communications,2020,10.1109/MWC.001.1900551,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
76c4cca67076ada2436672672e9f88bce3bc7515,https://www.semanticscholar.org/paper/76c4cca67076ada2436672672e9f88bce3bc7515,Predicting the Olea pollen concentration with a machine learning algorithm ensemble,,International Journal of Biometeorology,2020,10.1007/s00484-020-02047-z,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
afdd50c29ec52790f45c9e9960e89d0f89eb4896,https://www.semanticscholar.org/paper/afdd50c29ec52790f45c9e9960e89d0f89eb4896,A Simulator to Support Machine Learning-Based Wearable Fall Detection Systems,"People’s life expectancy is increasing, resulting in a growing elderly population. That population is subject to dependency issues, falls being a problematic one due to the associated health complications. Some projects are trying to enhance the independence of elderly people by monitoring their status, typically by means of wearable devices. These devices often feature Machine Learning (ML) algorithms for fall detection using accelerometers. However, the software deployed often lacks reliable data for the models’ training. To overcome such an issue, we have developed a publicly available fall simulator capable of recreating accelerometer fall samples of two of the most common types of falls: syncope and forward. Those simulated samples are like real falls recorded using real accelerometers in order to use them later as input for ML applications. To validate our approach, we have used different classifiers over both simulated falls and data from two public datasets based on real data. Our tests show that the fall simulator achieves a high accuracy for generating accelerometer data from a fall, allowing to create larger datasets for training fall detection software in wearable devices.",,2020,10.3390/electronics9111831,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
95f2a46a7eb5a2a2557e2bf519c697a8f06bea63,https://www.semanticscholar.org/paper/95f2a46a7eb5a2a2557e2bf519c697a8f06bea63,Digital twin: a machine learning approach to predict individual stress levels in extreme environments,"Remote Health Monitoring (RHM) has the potential to increase operational safety in extreme environments. Negative stress exposure influences mission success or the short- and long-term health conditions of deployed personnel. To quantify negative stress, we introduce a washable smart textile with integrated sensors. Analyzing the transmitted sensor values, medical advisors monitor up to 72 sensor values in parallel in case of an average group size of eight people. In order to aggregate the amount of data, we propose a stress level scale that includes stress trends. To predict individual stress levels based on sensor data, environmental quantities and the individual physiological fingerprint, we train different machine learning models. To evaluate such models, we implement a data acquisition environment to label data snapshots. Therefore, we do not need to collect in-field data and expose humans to negative stress. Moreover, we can mock sensor failures and rare, but relevant, sensor value combinations that are difficult to acquire in real-world scenarios. Our evaluation environment identifies Random Forest Regressor from a set of 25 models to perform best to predict individual stress levels. This model performs 23.19 times better than a zero rule classifier to distinguish among nine stress levels for mission goal health condition and 10.50 times better for mission goal mission success. Finally, we present our current RHM user interface design. It addresses issues such as information overload, avatar sympathy and unnecessary navigation paths.",UbiComp/ISWC Adjunct,2020,10.1145/3410530.3414316,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f39e7a9f135f321d722960a04ada0a804c497aab,https://www.semanticscholar.org/paper/f39e7a9f135f321d722960a04ada0a804c497aab,Neuroimaging Markers for Studying Gulf-War Illness: Single-Subject Level Analytical Method Based on Machine Learning,"Gulf War illness (GWI) refers to the multitude of chronic health symptoms, spanning from fatigue, musculoskeletal pain, and neurological complaints to respiratory, gastrointestinal, and dermatologic symptoms experienced by about 250,000 GW veterans who served in the 1991 Gulf War (GW). Longitudinal studies showed that the severity of these symptoms often remain unchanged even years after the GW, and these veterans with GWI continue to have poorer general health and increased chronic medical conditions than their non-deployed counterparts. For better management and treatment of this condition, there is an urgent need for developing objective biomarkers that can help with simple and accurate diagnosis of GWI. In this study, we applied multiple neuroimaging techniques, including T1-weighted magnetic resonance imaging (T1W-MRI), diffusion tensor imaging (DTI), and novel neurite density imaging (NDI) to perform both a group-level statistical comparison and a single-subject level machine learning (ML) analysis to identify diagnostic imaging features of GWI. Our results supported NDI as the most sensitive in defining GWI characteristics. In particular, our classifier trained with white matter NDI features achieved an accuracy of 90% and F-score of 0.941 for classifying GWI cases from controls after the cross-validation. These results are consistent with our previous study which suggests that NDI measures are sensitive to the microstructural and macrostructural changes in the brain of veterans with GWI, which can be valuable for designing better diagnosis method and treatment efficacy studies.",Brain sciences,2020,10.3390/brainsci10110884,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a9007309338079c16d1db214f748f94deb7dadc,https://www.semanticscholar.org/paper/2a9007309338079c16d1db214f748f94deb7dadc,Real-time Acoustic based Depression Detection using Machine Learning Techniques,"Depression disorder is predicted to rise to the second leading cause of disability by 2030 as per the identifications of the World Health organization (WHO). Though well trained clinicians, medical and psychological treatments are available for depression treatment, persons or families are reluctant to speak out/reach doctors about this disorder for various social reasons. Diagnosis of depression disorder includes numerous interviews with patient and family, clinical analysis, questionnaires which is time consuming and also demands well trained clinicians. In the present era of Machine learning, automation of depression detection is not complicated and can easily be deployed. However, the automation should use fewer resources, provide accurate results with more reachability. In this paper, acoustic features are used to train a classification model to categorize a human as Depressed or not-Depressed. DIAC-WOZ database available with AVEC2016 challenge is considered for training the classifiers. Prosodic, Spectral and Voice control features are extracted using the COVAREP toolbox and are feature fused. SMOTE analysis is used for overcoming the class imbalance and 93% accuracy is obtained with the SVM algorithm resulting in Depression Classification Model (DCM). An android application cureD Deployed on Cloud is developed to self assess depression using DCM and PHQ-8 questionnaire. The application is tested on real time data of 50 subjects under the supervision of a qualified psychiatrist and an accuracy of 90% is obtained.",2020 International Conference on Emerging Trends in Information Technology and Engineering (ic-ETITE),2020,10.1109/ic-ETITE47903.2020.394,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5413cab5b353877976056e4a8229b110265b7dea,https://www.semanticscholar.org/paper/5413cab5b353877976056e4a8229b110265b7dea,Machine learning for air quality prediction using meteorological and traffic related features,"The presence of pollutants in the air has a direct impact on our health and causes detrimental changes to our environment. Air quality monitoring is therefore of paramount importance. The high cost of the acquisition and maintenance of accurate air quality stations implies that only a small number of these stations can be deployed in a country. To improve the spatial resolution of the air monitoring process, an interesting idea is to develop data-driven models to predict air quality based on readily available data. In this paper, we investigate the correlations between air pollutants concentrations and meteorological and road traffic data. Using machine learning, regression models are developed to predict pollutants concentration. Both linear and non-linear models are investigated in this paper. It is shown that non-linear models, namely Random Forest (RF) and Support Vector Regression (SVR), better describe the impact of traffic flows and meteorology on the concentrations of pollutants in the atmosphere. It is also shown that more accurate prediction models can be obtained when including some pollutants’ concentration as predictors. This may be used to infer the concentrations of some pollutants using those of other pollutants, thereby reducing the number of air pollution sensors.",J. Ambient Intell. Smart Environ.,2020,10.3233/AIS-200572,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5756dd5986d3682fbb0c7f67786820ca481623e,https://www.semanticscholar.org/paper/d5756dd5986d3682fbb0c7f67786820ca481623e,Text Classification of News Articles Using Machine Learning on Low-resourced Language: Tigrigna,"Text categorization or Textual document is a method that becomes more significant in tagging a textual document to their most relevant label. However, not all languages have parallel textual growth; without free and absences of a dataset, text categorization becomes interesting for Tigrigna language, i.e., low-resourced language. Our aim to identify the given document to its categories based on its linguistic features. To achieve our goal, we have constructed a new dataset from different Tigrigna news sources. The dataset has six main categories: Agriculture, Sports, Health, Education, Religion, and Politics. Each collected is article preprocessed from Latin characters, punctuations, and stop words. We deployed a collection of different classical machine learning classifiers to investigate its effectiveness in our datasets. Namely, 7 popular classifiers were used, Logistic Regression, Nearest Centroid, Decision Tree (DT), Support Vector Machines (SVM), K-nearest neighbors (KNN), Random Forest Classifier, and Multi-Layer Perceptron (MLP). Ensemble models also implemented to get the best accuracy by combining the best classifiers based on their majority-voting classifiers. Our experimental results showed reliable performance with a minimum F1-score of 89.1% achieved by Nearest centroid and top performance of 96 % achieved by SVM. The experimental results presented in terms of precision, Recall, and F1-scores.",2020 3rd International Conference on Artificial Intelligence and Big Data (ICAIBD),2020,10.1109/ICAIBD49809.2020.9137443,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
28cd0b53953b4837edf83338308a0e8b84c000c1,https://www.semanticscholar.org/paper/28cd0b53953b4837edf83338308a0e8b84c000c1,Compressive Sensing Based on Homomorphic Encryption and Attack Classification using Machine Learning Algorithm in WSN Security,Data protection is essential for sensitive applications using Wireless Sensor Networks like health monitoring or video surveillance. WSN are deployed generally in harsh environment making them vulnerable for attacks thus it's important to secure data while being transferred from the sensor until the base station. This article is a proposal for a methodology which enable attack detection and classification on WSN. Compressive sensing is used to optimize the size of data exchange and hence optimize energy consumption. Homomorphic encryption allows to reduce encryption complexity by applying arithmetic operations on cypher text. Machine learning is applied to classify the attacks quickly.,NISS,2020,10.1145/3386723.3387859,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0e47d863b528de0318d62dfe9b71688289786002,https://www.semanticscholar.org/paper/0e47d863b528de0318d62dfe9b71688289786002,Feminicide & Machine Learning: Detecting Gender-based Violence to Strengthen Civil Sector Activism,"Gender-related violence against women and its lethal outcome, feminicide, are a serious problem in Latin America and the Caribbean (LAC), as they are in the rest of the world. Although governments have passed legislation criminalizing feminicide, these laws have not been accompanied by relevant policy nor by robust data collection that measures the scope and scale of the problem. Drawing from Data Feminism, we situate feminicide data as ""missing data"" and describe the work of activists and civil society organizations who attempt to fill in the gaps by compiling incidents of feminicide from news reports. Activists doing this work face challenges: lack of time and financial resources, difficulties in accessing official data, and the mental health burden of reading about violent deaths of women. In this article, we describe our work-in-progress on a participatory action research project designed to help sustain activist efforts to collect feminicide data by partially automating detection using machine learning. We created and labeled a data set for identifying feminicide from media reports and trained a model using this data. The accuracy of the model on our test data set was 81.1%, which shows promise for reducing the labor required to identify and log feminicides, among Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). MD4SG’20, August 17–18, 2020 © 2020 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-2138-9. DOI: 10.1145/1235 other potential benefits. We outline our ideas for deploying this model as part of an interactive feminicide notification system, drawing from a co-design process with activists. In the discussion, we raise on-going questions and unresolved tensions that we continue to reflect on while undertaking this work.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7f98966c35f7dc6eadbd983a258d74390ddcfb04,https://www.semanticscholar.org/paper/7f98966c35f7dc6eadbd983a258d74390ddcfb04,Positionality-aware machine learning: translation tutorial,"Positionality is a person's unique and always partial view of the world which is shaped by social and political contexts. Machine Learning (ML) systems have positionality, too, as a consequence of the choices we make when we develop ML systems. Being positionality-aware is key for ML practitioners to acknowledge and embrace the necessary choices embedded in ML by its creators. When groups form a shared view of the world, or group positionality, they have the power to embed and institutionalize their unique perspectives in artifacts such as standards and ontologies. For example, the international standard for reporting diseases and health conditions (International Classification of Diseases, ICD) is shaped by a distinctly medical, European and North American perspective. It dictates how we collect data, and limits what questions we can ask of data and what ML systems we can develop. Researchers struggle to study the effects of social factors on health outcomes because of what the ICD renders legible (usually in medicalized terms) and what it renders invisible (usually social contexts) in data. The ICD, as with all information infrastructures, promotes and propagates the perspective(s) of its creators. Over time, it establishes what counts as ""truth"". Positionality, and how it embeds itself in standards, ontologies, and data collection, is the root for bias in our data and algorithms. Every perspective has its limits - there is no view from nowhere. Without an awareness of positionality, the current debate on bias in machine learning is quite limited: adding more data to the set cannot remove bias. Instead, we propose positionality-aware ML, a new workflow focused on continuous evaluation and improvement of the fit between the positionality embedded in ML systems and the scenarios within which it is deployed. To demonstrate how to uncover positionality in standards, ontologies, data, and ML systems, we discuss recent work on online harassment of Canadian journalists and politicians on Twitter. Using legal definitions of hate speech and harassment, Twitter's community standards, and insight from interviews with journalists and politicians, we created standards and annotation guidelines for labeling the intensity of harassment in tweets. We then hand labeled a sample of data and through this process identified instances where positionality impacts choices about how many categories of harassment should exist, how to label boundary cases, and how to interpret messy data. We take three perspectives---technical, systems, socio-technical---that when combined illuminate areas of tension which serve as a signal of misalignment between the positionality embedded in the ML system and the deployment context. We demonstrate how the concept of positionality allows us to delineate sets of use cases that may not be suited for automated, ML solutions. Finally, we discuss strategies for developing positionality-aware ML systems, which embed a positionality appropriate for the application context, and continuously evolve to maintain this contextual fit, with an emphasis on the need for of democratic, egalitarian dialogues between knowledge-producing groups.",FAT*,2020,10.1145/3351095.3375666,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5dbd4c50cfe2982cb5bec9a83f37b899f2eb6aea,https://www.semanticscholar.org/paper/5dbd4c50cfe2982cb5bec9a83f37b899f2eb6aea,Machine learning in the biopharma industry,"Modern high-throughput technologies deployed in R&D for new health products have opened the door to Machine Learning applications that allow the automation of tasks and support for data-driven risk-based decision making. Appealing opportunities of applying Machine Learning appear for the development of modern complex drugs, for biomanufacturing production lines optimization, or even for elaborating product portfolio strategies. Nevertheless, many practical challenges make it difficult to apply Machine Learning models in the biopharmaceutical field. Innovative approaches must thus be considered in many of these practical cases. This tutorial paper is an attempt to describe the landscape of Machine Learning application to the biopharmaceutical industry along three dimensions: opportunities, specificities or constraints and methods.",ESANN,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b0d091e26beaf9604f95e4fb378cd83572ca1f34,https://www.semanticscholar.org/paper/b0d091e26beaf9604f95e4fb378cd83572ca1f34,Impact of Noise on Machine Learning-based Condition Monitoring Applications: a Case Study,"In the paper, application of Machine Learning (ML) techniques for the continuous monitoring of the health status of mild mission-critical industrial equipment is considered. A meaningful real-life case-study is presented in order to show how acquisition conditions may severely impact on the performance of the system. In particular, it is shown that a wrong estimate of noise effects in the deployed system may induce a wrong choice of the best features feeding the ML monitoring algorithm, hence affecting accuracy of the target devices. The discussed results may provide an useful guidance to the practitioner in the field during the design phase of ML-based devices depending of the equipment specifications and environmental conditions.",2020 IEEE International Instrumentation and Measurement Technology Conference (I2MTC),2020,10.1109/I2MTC43012.2020.9129119,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e13563485769e48314e53d778859caf34283ec0f,https://www.semanticscholar.org/paper/e13563485769e48314e53d778859caf34283ec0f,Abstract 16082: Machine Learning to Improve Left Ventricular Scar Quantification in Hypertrophic Cardiomyopathy Patients,"
 Introduction:
 Accurate and reproducible scar quantification of late gadolinium enhancement (LGE) images from cardiac magnetic resonance imaging (CMR) is important in risk stratifying hypertrophic cardiomyopathy (HCM) patients. Previous machine learning algorithms for CMR LGE quantification deployed three-dimensional convolutional neural network (CNN) architecture, which required image cropping and custom graphic processing units (GPUs) to function, thus limiting their general applicability. We aim to develop a deep two-dimensional (2D) CNN model that contours the left ventricle (LV) endo- and epicardial borders and quantifies LGE.
 
 
 Hypothesis:
 We hypothesize that a deep 2D CNN model, which uses commercially available GPUs, could be used to efficiently and accurately contour LV endo- and epicardial borders and quantify CMR LGE in HCM patients.
 
 
 Methods:
 We retrospectively studied 296 HCM patients (2423 images) from the University Health Network (Toronto, Canada) and Tufts Medical Center (Boston, USA). LGE images were manually segmented by an expert reader. Scar was defined as 5 standard deviations higher than the mean of the annotated normal region pixels. A 2D U-net CNN variant was used to train a model on 80% of the datasets. Testing was performed on the remaining 20%. We applied a 5-folds cross validation algorithm for training to improve model robustness. Model performance was assessed using the Dice Similarity Coefficient (DSC).
 
 
 Results:
 We were able to develop a deep learning model that could successfully perform both LV segmentation and scar quantification using a generally available GPU card. Our algorithm did not require image cropping and processed one image every 60 milliseconds. DSC scores averaged across the 5-folds was excellent at 0.89+0.22 for the endocardium and 0.81+0.17 for the epicardium, and good at 0.57+0.31 for scar.
 
 
 Conclusions:
 Using novel 2D CNN methods, we have successfully developed an automatic algorithm that rapidly provides LV endo- and epicardial contours and scar quantification on LGE CMR images that is superior to previously published studies. Unlike previous algorithms, our program does not require the use of custom CPUs or image cropping, potentially allowing it to be integrated into routine clinical practice.
",,2020,10.1161/CIRC.142.SUPPL_3.16082,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ff769eb6e9fb19fcf7f358e3ee8a3f85b4dcce12,https://www.semanticscholar.org/paper/ff769eb6e9fb19fcf7f358e3ee8a3f85b4dcce12,A Review of Bigdata and Machine Learning Techniques in Healthcare,"The study of big data by machine learning offers significant favorable circumstances for the assimilation and assessment of large amounts of complex medical services information. To adequately use machine learning devices in medical services, some constraints must be measured and key points must be measured, for example, its clinical use and ethics in the use of medical services. Favorable circumstances of machine learning incorporate adaptability and versatility contrasted and conventional biostatistical strategies, which makes it deployable for some errands, for example, hazard separation, finding and grouping, and endurance expectations. The health care services measure includes a lot of gigantic information that can be of various kinds and put in better places. The digitization of data, if appropriately dissected, prompts an expansion like cycles and administrations in the Healthcare area. In this specific situation, Machine Learning (ML) is the key empowering innovation to diminish the expenses of medical services extricating knowledge from information. The objective of ML is to improve a framework with no ceaseless human mediation. Medical Decision Support Systems (MDSS) are an additional incentive from one viewpoint by accelerating determination and care measures, then again decreasing the hour of clinical staff or concentrated learning.",2020 3rd International Conference on Intelligent Sustainable Systems (ICISS),2020,10.1109/ICISS49785.2020.9315876,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
beb2d24a689e9dca5174c4bccbf803b6100d3aa5,https://www.semanticscholar.org/paper/beb2d24a689e9dca5174c4bccbf803b6100d3aa5,Groundwater Arsenic and Cancer Risk Assessment Prediction model via Machine Learning: A Step Towards Modernizing Academic Research,"Ground water contamination with Arsenic (As) is one of the foremost issues in the South Asian countries where ground water is one of the foremost sources of drinking water. In Asian countries, especially people of Pakistan living in rural areas are devouring ground water for drinking purpose, and cleaned water is not accessible to them. This arsenic contaminated water is hazardous for human health. The persistence of this study is to study the increasing level of arsenic in ground water in coming years for Khairpur, Sindh Pakistan, which is also increasing the cancer rate (skin cancer, blood cancer) gradually in human body. To predict the arsenic value and cancer risk for the next five years, we have developed two models via Microsoft Azure machine learning with algorithms include Support Vector Machine (SVM), Linear Regression (LR), Bayesian Linear Regression (BLR), Boosted Decision tree (BDT), exponential smoothing ETS, Autoregressive Integrated Moving Average (ARIMA). The developed predictive model named as Arsenic Contamination and Cancer Risk Assessment Prediction Model (ACCRAP model) will help us to forecast the arsenic contamination levels and the cancer rate. The results demonstrated that BLR pose highest prediction accuracy of cancer rate among the four deployed machine learning algorithms.",Sir Syed University Research Journal of Engineering & Technology,2020,10.33317/ssurj.232,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3ff4f8e1e2043976fe8cbab1f92198427119ea80,https://www.semanticscholar.org/paper/3ff4f8e1e2043976fe8cbab1f92198427119ea80,MLLBC: A Machine Learning Toolbox for Modeling the Loss Rate of the Lining Bearing Capacity,"Testing the health of tunnels, as a branch of highway operation, has an extremely important application in public property and even life safety. Among them, there are many factors that cause the tunnel to deform or collapse. The conventional methods use the finite element method (FEM) which are to simulate the bearing capacity loss rate of the lining by using the mechanical method. However, it takes a long time to calculate the stress-strain-situation of the lining model under each condition. This paper explores the machine learning to calculate the loss rate of the lining bearing capacity under more conditions based on FEM simulation data. Here, we establish a machine learning toolbox for modeling the loss rate of the lining bearing capacity named “MLLBC”, which contains three main components: 1) data loading; 2) machine learning model deployment; 3) performance evaluation. To ensure the fairness of model evaluation, ten machine learning models use a unified code library. We also conduct experiments on our new dataset which is the loss rate of the lining bearing capacity with different data amounts, as well as experiments on the goodness of model fitting under different ranges of various variables.",IEEE Access,2020,10.1109/ACCESS.2020.2979833,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1fad8a99210594205c93b5856208f48df7765b22,https://www.semanticscholar.org/paper/1fad8a99210594205c93b5856208f48df7765b22,"Towards low-cost and high-performance air pollution measurements
using machine learning calibration techniques","Abstract. Air pollution is a key public health issue in urban areas worldwide. The development of low-cost air pollution sensors is consequently a major research priority. However, low-cost sensors often fail to attain sufficient measurement performance compared to state-of-the-art measurement stations, and typically require calibration procedures in expensive laboratory settings. As a result, there has been much debate about calibration techniques that could make their performance more reliable, while also developing calibration procedures that can be carried out without access to advanced laboratories. One repeatedly proposed strategy is low-cost sensor calibration through co-location with public measurement stations. The idea is that, using a regression function, the low-cost sensor signals can be calibrated against the station reference signal, to be then deployed separately with performances similar to the original stations. Here we test the idea of using machine learning algorithms for such regression tasks using hourly-averaged co-location data for nitrogen dioxide (NO2) and particulate matter of particle sizes smaller than 10 μm (PM10) at three different locations in the urban area of London, UK. Specifically, we compare the performance of Ridge regression, a linear statistical learning algorithm, to two non-linear algorithms in the form of Random Forest (RF) regression and Gaussian Process regression (GPR). We further benchmark the performance of all three machine learning methods to the more common Multiple Linear Regression (MLR). We obtain very good out-of-sample R2-scores (coefficient of determination) > 0.7, frequently exceeding 0.8, for the machine learning calibrated low-cost sensors. In contrast, the performance of MLR is more dependent on random variations in the sensor hardware and co-located signals, and is also more sensitive to the length of the co-location period. We find that, subject to certain conditions, GPR is typically the best performing method in our calibration setting, followed by Ridge regression and RF regression. However, we also highlight several key limitations of the machine learning methods, which will be crucial to consider in any co-location calibration. In particular, none of the methods is able to extrapolate to pollution levels well outside those encountered at training stage. Ultimately, this is one of the key limiting factors when sensors are deployed away from the co-location site itself. Consequently, we find that the linear Ridge method, which best mitigates such extrapolation effects, is typically performing as good as, or even better, than GPR after sensor re-location. Overall, our results highlight the potential of co-location methods paired with machine learning calibration techniques to reduce costs of air pollution measurements, subject to careful consideration of the co-location training conditions, the choice of calibration variables, and the features of the calibration algorithm.
",,2020,10.5194/amt-2020-473,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
af47c39aeeec1f8598adbe45d3d8adc46a26f99c,https://www.semanticscholar.org/paper/af47c39aeeec1f8598adbe45d3d8adc46a26f99c,Detecting soil degradation and restoration through a novel coupled sensor and machine learning framework,"
 <p>In this poster we will outline a new&#160; ambitious cross-disciplinary project focused on detecting soil degradation and restoration through a novel multi-functional soil sensing platform that combines conventional and newly created sensors and a machine learning framework. Our work&#160; aims to advance our understanding of dynamic soil processes that operate at different temporal/spatial scales. Through the creation of an innovative new approach to capturing and analyzing high frequency data from in-situ sensors, this project will predict the rate and direction of soil system functions for sites undergoing degradation or restoration. To do this, we will build and train a new mechanistically-informed machine learning system to turn high frequency data on multiple soil functions, such as water infiltration, CO2 production, and surface soil movement, into predictions of longer term changes in soil health including the status of microbial processes, soil organic matter (SOM) content, and other properties and processes. Such an approach could be transformative: a system that will allow short-term sensor data to be used to evaluate longer term soil transformations in key ecosystem functions. We will start our work with a suite of off-the-shelf sensors observing multiple soil functions that can be installed quickly. These data will allow us to rapidly initiate development and training of a novel mechanistically informed machine learning framework. In parallel we will develop two new soil health sensors focused on in-situ real time measurement of decomposition rates and transformation of soil color that reflects the accumulation or loss of SOM. We will then link these new sensors with a suite of conventional sensors in a novel data collection and networking system coupled to the Swarm satellite network to create a low cost sensor array that can be deployed in remote areas and used to support studies of soil degradation or progress toward restoration worldwide.<br><br></p>
",,2020,10.5194/egusphere-egu2020-22591,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9d97c3412dead8970fe9d09347c6b2a11d2ea7bb,https://www.semanticscholar.org/paper/9d97c3412dead8970fe9d09347c6b2a11d2ea7bb,Prediction of Remaining Useful Lifetime of Membrane Using Machine Learning,"We present a novel analytical procedure estimating the remaining useful life (RUL) of complex systems or facilities based on degradation data obtained over time; we consider the maintenance characteristics of units that are incompletely repaired. We develop an extended prognostic model
 that accurately predicts the RUL; we use machine-learning featuring smoothing, logging, variable transformation and clustering to this end. The performance of a general model was more predictable than that of an extended model. A linear regression (LR) method was superior in terms of root
 mean square error prediction and an artificial neural network (ANN) was superior in terms of prognostics and health management (PHM) scoring. The procedure is both practical and efficient, and can be deployed in various industries, yielding low-cost prognostics even in low-expertise domains.
 The procedure can be applied to high-risk industries, aiding management decision-making in terms of the establishment of optimal, preventative maintenance policies.",,2020,10.1166/sam.2020.3788,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bb40a0b57350d7cee05fd453ff94969ee1d2499b,https://www.semanticscholar.org/paper/bb40a0b57350d7cee05fd453ff94969ee1d2499b,Periodic Time Series Data Analysis by Novel Machine Learning Methodologies,"Period length extraction is considered a challenge in many research fields. To solve this problem, different methods have been proposed across many applications. For instance, supply chain management is an area that can greatly benefit from precise periodic information. In addition, periodic information on physiological data can provide insights into individuals’ health conditions, which is the motivation of this thesis. The difficulty of period length extraction involves the varying noise levels among working environments. A system that performs well in one environment may not be accurate in another. In this work, we explore two machine learning approaches, each of which attempts to solve the problem at a different noise level. The first algorithm, the period classification algorithm (PCA), utilizes historical labeled data as training material and classifies new instances. The PCA demonstrates robustness to both generated and natural noise. However, the training of the PCA is not economical if the data do not contain much noise. The second algorithm, the period detection algorithm (PDA), is used when the noise level is not very high. It does not require historical data, but rather detects the period length directly from the data stream. The PDA cannot tolerate as much noise as the PCA; however, it is more efficient and simpler to deploy. By investigating both algorithms on artificial and real-world datasets, we determined that they have advantages under different circumstances. In particular, the PDA outperforms the PCA when the system is noise-free, while it fails on real-world datasets, which usually contain a large amount of noise. In contrast, given that the training material is representative of test datasets, the PCA demonstrates high performance on both artificial and real-world datasets.",,2020,10.20381/RUOR-24978,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b27d344053b546ac88cde779acd90a41a14db357,https://www.semanticscholar.org/paper/b27d344053b546ac88cde779acd90a41a14db357,A Surveillance on Machine Learning Algorithms and Its Applications,"This paper intends to use distinct machine learning algorithms and exploring its multi-features. The primary advantage of machine learning is, a machine learning algorithm can predict its work automatically by learning what to do with information. This paper reveals the concept of machine
 learning and its algorithms which can be used for different applications such as health care, sentiment analysis and many more. Sometimes the programmers will get confused which algorithm to apply for their applications. This paper provides an idea related to the algorithm used on the basis
 of how accurately it fits. Based on the collected data, one of the algorithms can be selected based upon its pros and cons. By considering the data set, the base model is developed, trained and tested. Then the trained model is ready for prediction and can be deployed on the basis of feasibility.",,2020,10.1166/jctn.2020.9064,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9874a015501a1022f8b04d91a1b01a1038aaf617,https://www.semanticscholar.org/paper/9874a015501a1022f8b04d91a1b01a1038aaf617,Selecting Cloud Service for Healthcare Applications: From Hardware to Cloud Across Machine Learning,"The paper describes the process of creating the Internet of Things (IoT) healthcare applications and selecting an environment to deploy it. Based on research of healthcare application architecture was proposed selecting of cloud service. It draws our attention to complex architecture with using different sources of medical data like external medical databases, medical equipment and wearable medical and non-medical devices. Much attention is given to using machine learning in the process in the detection of health problems. In addition, the paper describes two levels of machine learning: one for detecting single problems with heals and second for predictions complex reports and providing treatment plan based on data from the first level. The main emphasis in choosing of cloud service is made on scalability and the ability to create multiple neural networks for processing data.",PhD@ICTERI,2018,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9c89f239d30890edb71f8e48ca4f7849a8626b77,https://www.semanticscholar.org/paper/9c89f239d30890edb71f8e48ca4f7849a8626b77,Towards AI-assisted Healthcare: System Design and Deployment for Machine Learning based Clinical Decision Support,"Over the last decade, American hospitals have adopted electronic health records (EHRs) widely. In the next decade, incorporating EHRs with clinical decision support (CDS) together into the process of medicine has the potential to change the way medicine has been practiced and advance the quality of patient care. It is a unique opportunity for machine learning (ML), with its ability to process massive datasets beyond the scope of human capability, to provide new clinical insights that aid physicians in planning and delivering care, ultimately leading to better outcomes, lower costs of care, and increased patient satisfaction. However, applying ML-based CDS has to face steep system and application challenges. No open platform is there to support ML and domain experts to develop, deploy, and monitor ML-based CDS; and no end-to-end solution is available for machine learning algorithms to consume heterogenous EHRs and deliver CDS in real-time. Build ML-based CDS from scratch can be expensive and time-consuming. In this dissertation, CDS-Stack, an open cloud-based platform, is introduced to help ML practitioners to deploy ML-based CDS into healthcare practice. The CDS-",,2018,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b14692c1e0658dd1d814c737171ce714b1588360,https://www.semanticscholar.org/paper/b14692c1e0658dd1d814c737171ce714b1588360,An Intelligent UAV Deployment Scheme for Load Balance in Small Cell Networks Using Machine Learning,"In wireless networks, network load can be highly unbalanced due to the mobility of user equipments (UEs). Unmanned Aerial Vehicles (UAVs) supported base station with the advantage of flexible deployment, ubiquitous wireless coverage and high speed data rate, is a promising approach to handle with the foregoing problem. However, how to achieve cost-effective UAV deployment in an autonomous and dynamic manner is a significant challenge. Facing this problem, we propose a novel UAV base station intelligent deployment scheme based on machine learning and evaluate its performance on a realworld dataset. First, we conduct data preprocessing to process, clean, and transform raw data into formatted data. Missing values are filled by Conditional Mean Imputation (CMI) method and outliers are corrected by pauta criterion. Then, we use hybrid approach which contains ARIMA model and XGBoost model. Linear predictions are carried out by ARIMA model and later nonlinear model XGBoost are applied on residue of ARIMA. Resultant prediction is obtained by adding linear and nonlinear prediction, hybrid model is estimated by Root Mean Square Error (RMSE) and R2 score. Finally, according to predicted results, UAV base stations can be deployed to cater for dynamically changing demands in the hotspot areas and achieve cost-effective deployment. Simulation results show that the propose scheme is superior to other benchmark schemes in load balancing.",2019 IEEE Wireless Communications and Networking Conference (WCNC),2019,10.1109/WCNC.2019.8885648,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4e69e504e03d02129c58120d80afaaf4cbc39762,https://www.semanticscholar.org/paper/4e69e504e03d02129c58120d80afaaf4cbc39762,Identifying probable post-traumatic stress disorder: applying supervised machine learning to data from a UK military cohort,"Abstract Background: Early identification of probable post-traumatic stress disorder (PTSD) can lead to early intervention and treatment. Aims: This study aimed to evaluate supervised machine learning (ML) classifiers for the identification of probable PTSD in those who are serving, or have recently served in the United Kingdom (UK) Armed Forces. Methods: Supervised ML classification techniques were applied to a military cohort of 13,690 serving and ex-serving UK Armed Forces personnel to identify probable PTSD based on self-reported service exposures and a range of validated self-report measures. Data were collected between 2004 and 2009. Results: The predictive performance of supervised ML classifiers to detect cases of probable PTSD were encouraging when compared to a validated measure, demonstrating a capability of supervised ML to detect the cases of probable PTSD. It was possible to identify which variables contributed to the performance, including alcohol misuse, gender and deployment status. A satisfactory sensitivity was obtained across a range of supervised ML classifiers, but sensitivity was low, indicating a potential for false negative diagnoses. Conclusions: Detection of probable PTSD based on self-reported measurement data is feasible, may greatly reduce the burden on public health and improve operational efficiencies by enabling early intervention, before manifestation of symptoms.",Journal of mental health,2018,10.1080/09638237.2018.1521946,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0abbc41a9b4b7374d0d4d97af7e47f83278641d2,https://www.semanticscholar.org/paper/0abbc41a9b4b7374d0d4d97af7e47f83278641d2,Application of Machine Learning Model on Streaming Health Data Event in Real-Time to Predict Health Status Using Spark,"In healthcare field, a huge amount of data collected in real-time by IoT systems, remote sensing device and other data collection tools brings new challenges that focus primarily on data size and the fast growth rate of such large data. Applying machine learning model on this voluminous data having varying velocity becomes extremely complex for traditional methods of data mining. To deal with this challenge, Apache Spark, a powerful big data processing tool can be used successfully for streaming data event against machine learning through in-memory and distributed computations. This work aims at developing a real-time health status prediction system with breast cancer use case using spark streaming framework with machine learning especially Decision Tree. The system focus on applying machine learning model on streaming data coming with rapid rate to predict health status based on several input variables. Based on this, the system first preprocesses the dataset and analyzes it to create an offline model for learning system, the model then deployed on system and use it in real-time to predict health status.",2018 International Symposium on Advanced Electrical and Communication Technologies (ISAECT),2018,10.1109/ISAECT.2018.8618860,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
90bd611e1ad10c9302a9ef29eec33f83958d066a,https://www.semanticscholar.org/paper/90bd611e1ad10c9302a9ef29eec33f83958d066a,Decoupled Feature-Temporal CNN: Explaining Deep Learning-Based Machine Health Monitoring,"Machine learning, especially deep learning, have been extensively applied and studied in the area of machine health monitoring in the recent ""big data"" era. For machine health monitoring systems (MHMS), the major efforts have been put in designing and deploying more and more complex machine learning models which are also called as black-box models considering they are non-transparent towards their working mechanism. However, this research trend brings huge potential risk in real life. Since machine health monitoring itself is a high-stake decision scenario, the decision of the autonomous monitoring system should be trustworthy and reliable, which refers to obtain explainability. Then, it comes to the following key question: Why the deployed MHMS predict what they predict. In this paper, we shed some lights on this meaningful research direction: explainable machine health monitoring systems (EMHMS). In EMHMS, the machine doctor could act like a real doctor who can only make diagnosis but also describe the patient’s symptoms. First, we propose a specific convolutional neural network (CNN) structure, named as DecouplEd Feature-Temporal CNN (DEFT-CNN), balances precision-explainability trade-off. Specifically, features and temporal information will be encoded in different stages of our model. Second, to explain the decision of the model, we adopt the gradient-based methods to generate features and temporal saliency maps highlighting which kind of features and time steps are key for the model’s predictions. At last, we conduct the experimental studies in the CWRU bearing fault diagnosis dataset to verify the effectiveness of our proposed framework.","2020 International Conference on Sensing, Measurement & Data Analytics in the era of Artificial Intelligence (ICSMD)",2020,10.1109/ICSMD50554.2020.9261638,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fdfbab0ef403db3bbecacd70c356a927f9165ddd,https://www.semanticscholar.org/paper/fdfbab0ef403db3bbecacd70c356a927f9165ddd,"Comparison of Conventional Statistical Methods with Machine Learning in Medicine: Diagnosis, Drug Development, and Treatment","Futurists have anticipated that novel autonomous technologies, embedded with machine learning (ML), will substantially influence healthcare. ML is focused on making predictions as accurate as possible, while traditional statistical models are aimed at inferring relationships between variables. The benefits of ML comprise flexibility and scalability compared with conventional statistical approaches, which makes it deployable for several tasks, such as diagnosis and classification, and survival predictions. However, much of ML-based analysis remains scattered, lacking a cohesive structure. There is a need to evaluate and compare the performance of well-developed conventional statistical methods and ML on patient outcomes, such as survival, response to treatment, and patient-reported outcomes (PROs). In this article, we compare the usefulness and limitations of traditional statistical methods and ML, when applied to the medical field. Traditional statistical methods seem to be more useful when the number of cases largely exceeds the number of variables under study and a priori knowledge on the topic under study is substantial such as in public health. ML could be more suited in highly innovative fields with a huge bulk of data, such as omics, radiodiagnostics, drug development, and personalized treatment. Integration of the two approaches should be preferred over a unidirectional choice of either approach.",Medicina,2020,10.3390/medicina56090455,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
39264be15daa49511d32723d74fa9c48673ebddc,https://www.semanticscholar.org/paper/39264be15daa49511d32723d74fa9c48673ebddc,"Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions","Driven by the demand to accommodate today’s growing mobile traffic, 5G is designed to be a key enabler and a leading infrastructure provider in the information and communication technology industry by supporting a variety of forthcoming services with diverse requirements. Considering the ever-increasing complexity of the network, and the emergence of novel use cases such as autonomous cars, industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML) is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised, unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of ML in the context of mobile and wireless communication, organizing the literature in terms of the types of learning. We then discuss the promising approaches for how ML can contribute to supporting each target 5G network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G), providing future research directions for how ML can contribute to realizing B5G. This article is intended to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of autonomous 5G/B5G mobile and wireless communications.",IEEE Access,2019,10.1109/ACCESS.2019.2942390,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6d0bd45930fcbdc64f826ae210980dfb6e0b8636,https://www.semanticscholar.org/paper/6d0bd45930fcbdc64f826ae210980dfb6e0b8636,Making Machine Learning Models Clinically Useful.,"Recent advances in supervised machine learning have improved diagnostic accuracy and prediction of treatment outcomes, in some cases surpassing the performance of clinicians.1 In supervised machine learning, a mathematical function is constructed via automated analysis of training data, which consists of input features (such as retinal images) and output labels (such as the grade of macular edema). With large training data sets and minimal human guidance, a computer learns to generalize from the information contained in the training data. The result is a mathematical function, a model, that can be used to map a new record to the corresponding diagnosis, such as an image to grade macular edema. Although machine learning–based models for classification or for predicting a future health state are being developed for diverse clinical applications, evidence is lacking that deployment of these models has improved care and patient outcomes.2 One barrier to demonstrating such improvement is the basis used to assess the performance of a model. Current approaches gauge performance by quantifying how closely the diagnosis or prediction made by the model matches known diagnoses or health outcomes. Quantifications include sensitivity, specificity, and positive predictive value, as well as measures such as the",JAMA,2019,10.1001/jama.2019.10306,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bf00f9a08bab50a41f091fc649f9af500354af89,https://www.semanticscholar.org/paper/bf00f9a08bab50a41f091fc649f9af500354af89,Machine Learning Assisted PUF Calibration for Trustworthy Proof of Sensor Data in IoT,"Remote integrity verification plays a paramount role in resource-constraint devices owing to emerging applications such as Internet-of-Things (IoT), smart homes, e-health, and so on. The concept of Virtual Proof of Reality (VPoR) proposed by Rührmair et al. in 2015 has come up with a Sense-Prove-Validate framework for integrity checking of abundant data generated from billions of connected sensors. It leverages the unreliability factor of Physically Unclonable Functions (PUFs) with respect to ambient parameter variations such as temperature, supply voltages, and so on, and claims to prove the authenticity of the sensor data without using any explicit keys. The state-of-the-art authenticated sensing protocols majorly lack in limited authentications and huge storage overhead. These protocols also assume that the behaviour of the PUF instances varies unpredictably for different levels of ambient factors, which in turn makes them hard to go beyond the theoretical concept. We address these issues in this work1 and propose a Machine Learning (ML) assisted PUF calibration scheme to predict the Challenge-Response Pair (CRP) behaviour of a PUF instance in a specific environment, given the CRP behaviour in a pivot environment. Here, we present a new class of authenticated sensing protocols where we leverage the beneficence of ML techniques to validate the authenticity and integrity of sensor data over ambient factor variations. The scheme also reduces the storage complexity of the verifier from O(p * K * l * (c + r)) to O(p * l *(c + r)), where p is the number of PUF instances deployed in the framework, l is the number of challenge-response pairs used for authentication, c is the bit lengths of the challenge, r is the response bits of the PUF, and K is the number of levels of ambient factor variations. The scheme alleviates the issue of limited authentication as well, whereby every CRP is used only once for authentication and then deleted from the database. To validate the proposed protocol through actual experiments on FPGA, we propose 5-4 Double Arbiter PUF, which is an extension of Double Arbiter PUFs (DAPUFs) as this design is more suited for FPGA, and implement it on Xilinx Artix-7 FPGAs. We characterise the proposed PUF instance from −20°C to 80°C and use Random Forest--based ML technique to generate a soft model of the PUF instance. This model is further used by the verifier to authenticate the actual PUF circuit. According to the FPGA-based validation, the proposed protocol with DAPUF can be effectively used to authenticate sensor devices across wide variations of temperature values.",ACM Trans. Design Autom. Electr. Syst.,2020,10.1145/3393628,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c69d61329325b040957360ad29e052aa657972d9,https://www.semanticscholar.org/paper/c69d61329325b040957360ad29e052aa657972d9,"A Machine Learning Algorithm to Predict Severe Sepsis and Septic Shock: Development, Implementation, and Impact on Clinical Practice.","OBJECTIVES
Develop and implement a machine learning algorithm to predict severe sepsis and septic shock and evaluate the impact on clinical practice and patient outcomes.


DESIGN
Retrospective cohort for algorithm derivation and validation, pre-post impact evaluation.


SETTING
Tertiary teaching hospital system in Philadelphia, PA.


PATIENTS
All non-ICU admissions; algorithm derivation July 2011 to June 2014 (n = 162,212); algorithm validation October to December 2015 (n = 10,448); silent versus alert comparison January 2016 to February 2017 (silent n = 22,280; alert n = 32,184).


INTERVENTIONS
A random-forest classifier, derived and validated using electronic health record data, was deployed both silently and later with an alert to notify clinical teams of sepsis prediction.


MEASUREMENT AND MAIN RESULT
Patients identified for training the algorithm were required to have International Classification of Diseases, 9th Edition codes for severe sepsis or septic shock and a positive blood culture during their hospital encounter with either a lactate greater than 2.2 mmol/L or a systolic blood pressure less than 90 mm Hg. The algorithm demonstrated a sensitivity of 26% and specificity of 98%, with a positive predictive value of 29% and positive likelihood ratio of 13. The alert resulted in a small statistically significant increase in lactate testing and IV fluid administration. There was no significant difference in mortality, discharge disposition, or transfer to ICU, although there was a reduction in time-to-ICU transfer.


CONCLUSIONS
Our machine learning algorithm can predict, with low sensitivity but high specificity, the impending occurrence of severe sepsis and septic shock. Algorithm-generated predictive alerts modestly impacted clinical measures. Next steps include describing clinical perception of this tool and optimizing algorithm design and delivery.",Critical care medicine,2019,10.1097/CCM.0000000000003891,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1a3bd5f1417cafdf0b4363d0a12c44d919d242cd,https://www.semanticscholar.org/paper/1a3bd5f1417cafdf0b4363d0a12c44d919d242cd,Using Different Models of Machine Learning to Predict Attendance at Medical Appointments,"Outpatient absenteeism is a recurring problem worldwide and in Brazil, it is a chronic problem. The number of appointments and exams scheduled and not performed, due to the non-attendance of patients, reaches significantly high rates and can be seen in all regions in the country and in different types of care and medical specialties. This practice generates waste of resources, disorganizes the offer of services, and limits the guarantee of care at different levels of assistance. In addition, it causes a series of dissatisfactions from users of the health system who really need and have not yet been able to access consultations and exams. This imbalance causes the misuse of the offer, an increase in the queue and waiting time, as well as a financial loss since it is paid for by a professional who is idle due to the absence of patients. It is necessary to understand the profile of these missing patients and to try to discover the reasons that lead this person to be absent, in order to predict a future absence for consultation. Thus, this work presents the study of different machine learning models in order to help predict whether or not the patient will attend the scheduled appointment. As a result, an end-to-end machine learning process was developed, considering exploratory data analysis, pre-processing, creation of machine learning models, analysis of results, and deployment of the most appropriate model in a web application. As a result, it was found that the Decision Tree algorithm represents an interesting choice as a final model for use in future observations.",Journal of Information Systems Engineering and Management,2020,10.29333/JISEM/8430,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
978437538d70075676f7ca0ceaab3bb685872d25,https://www.semanticscholar.org/paper/978437538d70075676f7ca0ceaab3bb685872d25,Application of Artificial Intelligence and Machine Learning to Detect Drilling Anomalies Leading to Stuck Pipe Incidents,"
 This project used predictive analytics and machine learning-based modeling to detect drilling anomalies, namely stuck pipe events. Analysis focused on historical drilling data and real-time operational data to address the limitations of physics-based modeling. This project was designed to enable drilling crews to minimize downtime and non-productive time through real-time anomaly management.
 The solution used data science techniques to overcome data consistency/quality issues and flag drilling anomalies leading to a stuck pipe event. Predictive machine learning models were deployed across seven wells in different fields. The models analyzed both historical and real-time data across various data channels to identify anomalies (difficulties that impact non-productive time). The modeling approach mimicked the behavior of drillers using surface parameters. Small deviations from normal behavior were identified based on combinations of surface parameters, and automated machine learning was used to accelerate and optimize the modeling process. The output was a risk score that flags deviations in rig surface parameters.
 During the development phase, multiple data science approaches were attempted to monitor the overall health of the drilling process. They analyzed both historical and real-time data from torque, hole depth and deviation, standpipe pressure, and various other data channels.
 The models detected drilling anomalies with a harmonic model accuracy of 80% and produced valid alerts on 96% of stuck pipe and tight hole events. The average forewarning was two hours. This allowed personnel ample time to make corrections before stuck pipe events could occur. This also enabled the drilling operator to save the company upwards of millions of dollars in drilling costs and downtime.
 This project introduced novel data aggregation and deep learning-based normal behavior modeling methods. It demonstrates the benefits of adopting predictive analytics and machine learning in drilling operations. The approach enabled operators to mitigate data issues and demonstrate real-time, high-frequency and high-accuracy predictions. As a result, the operator was able to significantly reduce non-productive time.","Day 4 Thu, November 18, 2021",2021,10.2118/207987-ms,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ad810d5ec218625b3cf7e6b89b1ee8ad2fe95e70,https://www.semanticscholar.org/paper/ad810d5ec218625b3cf7e6b89b1ee8ad2fe95e70,Symptoms Based Covid-19 Disease Diagnosis Using Machine Learning Approach,"The catastrophic outbreak of SARS-CoV-2 or COVID-19 has taken the world to uncharted waters. Detecting such an outbreak at its early stages is crucial to minimize its spread but is very difficult as well. The pandemic situation is not yet under control as the virus tends to evolve and develop mutations. This further complicates the development of machine learning or AI models that can automatically detect the disease in the general public. However, researchers worldwide have been putting their incredible efforts into devising mechanisms that help analyze and control the pandemic situation. Many prediction models have been developed to predict COVID-19 infection risk that helps in mitigating the burden on the healthcare system. These models help the medical staff, especially when healthcare resources are limited. As a contribution to society’s well-being, this research work deploys a machine learning prediction model that predicts COVID-19 patients with COVID-19 symptoms. Key pieces of information from RT-PCR test data results by the Israeli ministry of health publicly available have been distilled, preprocessed, and then used to train our prediction model. The model is trained on eight features, out of which five are the primary clinical symptoms of this fatal virus: cough, sore throat, fever, headache, breath shortness; and the other three features are gender, test indication, and age. Machine learning models can be considered for COVID-19 testing, especially when resources are limited. We have achieved highly accurate results in COVID-19 prediction with our prediction model. The model is best suited in urgent situations where there is a limitation of testing resources.",2021 International Conference on Innovative Computing (ICIC),2021,10.1109/icic53490.2021.9692986,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
60ecb6812ad3ce540bfa08771bcd64da9e076164,https://www.semanticscholar.org/paper/60ecb6812ad3ce540bfa08771bcd64da9e076164,Machine Learning Framework to Predict Patient Non-Adherence to Medication using Non-Clinical Data: A Prognosis Approach,"The need for patient-centric medication adherence intervention system tailored towards addressing individual patient challenges of non-adherence has been well established by several studies. In recent times, many studies have applied machine learning predictive models in medication adherence system across specific chronic diseases using patient's clinical data. However, only a very few studies had attempted to leverage on patient's non-clinical data such as patient's belief, behavioral pattern, knowledge and others as input parameters in their predictive models. Studies outcomes have also shown that these non-clinical data have high influence on patient's non-adherence to medication thereby making them strong determinants. In this paper, we introduce a prognosis approach that can help to predict patient's non-adherence level to medication at the first clinic visit even before prescription commences. The prognosis approach is described by using Adaptive Neuro Fuzzy (ANF) predictive model that adopt the use of non-clinical data of patient to serve as input variables of the model. This study is a preliminary report of an ongoing innovative and intelligent healthcare project to improve patient adherence to medication. We developed a certified questionnaire based on health belief theory to collect the non-clinical data from out-patients with chronic disease who are receiving treatment so as to test the performance of the proposed framework. The predicted patient level of non-adherence output would be optimized and stratified to determine an appropriate intervention functions and delivery techniques towards the particular needs of the patient. Various components of the framework; features and functions; taxonomy of intervention techniques; design guidelines; and recommendations for efficient integrations and deployment in healthcare centers are presented. This would serve as a veritable prognosis and prediction tool to improve adherence to medication as the level of non-adherence to medication of the patient would be easily determined.",The 2021 9th International Conference on Computer and Communications Management,2021,10.1145/3479162.3479177,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f109aefc571006d169821d919ea2446993cb83b5,https://www.semanticscholar.org/paper/f109aefc571006d169821d919ea2446993cb83b5,Classifying Lung Cancer Severity with Ensemble Machine Learning in Health Care Claims Data,"Research in oncology quality of care and health outcomes has been limited by the difficulty of identifying cancer stage in health care claims data. Using linked cancer registry and Medicare claims data, we develop a tool for classifying lung cancer patients receiving chemotherapy into early vs. late stage cancer by (i) deploying ensemble machine learning for prediction, (ii) establishing a set of classification rules for the predicted probabilities, and (iii) considering an augmented set of administrative claims data. We find our ensemble machine learning algorithm with a classification rule defined by the median substantially outperforms an existing clinical decision tree for this problem, yielding full sample performance of 93% sensitivity, 92% specificity, and 93% accuracy. This work has the potential for broad applicability as provider organizations, payers, and policy makers seek to measure quality and outcomes of cancer care and improve on risk adjustment methods.",MLHC,2017,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
db9d56db30682ae25973b4ec678c53e7546126c4,https://www.semanticscholar.org/paper/db9d56db30682ae25973b4ec678c53e7546126c4,User-Centered Design of a Machine Learning Intervention for Suicide Risk Prediction in a Military Setting,"Primary care represents a major opportunity for suicide prevention in the military. Significant advances have been made in using electronic health record data to predict suicide attempts in patient populations. With a user-centered design approach, we are developing an intervention that uses predictive analytics to inform care teams about their patients' risk of suicide attempt. We present our experience working with clinicians and staff in a military primary care setting to create preliminary designs and a context-specific usability testing plan for the deployment of the suicide risk indicator.",AMIA,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a512d719d9625fe96099c747ecf1de989cbc8f6f,https://www.semanticscholar.org/paper/a512d719d9625fe96099c747ecf1de989cbc8f6f,RaveGuard: A Noise Monitoring Platform Using Low-End Microphones and Machine Learning,"Urban noise is one of the most serious and underestimated environmental problems. According to the World Health Organization, noise pollution from traffic and other human activities, negatively impact the population health and life quality. Monitoring noise usually requires the use of professional and expensive instruments, called phonometers, able to accurately measure sound pressure levels. In many cases, phonometers are human-operated; therefore, periodic fine-granularity city-wide measurements are expensive. Recent advances in the Internet of Things (IoT) offer a window of opportunities for low-cost autonomous sound pressure meters. Such devices and platforms could enable fine time–space noise measurements throughout a city. Unfortunately, low-cost sound pressure sensors are inaccurate when compared with phonometers, experiencing a high variability in the measurements. In this paper, we present RaveGuard, an unmanned noise monitoring platform that exploits artificial intelligence strategies to improve the accuracy of low-cost devices. RaveGuard was initially deployed together with a professional phonometer for over two months in downtown Bologna, Italy, with the aim of collecting a large amount of precise noise pollution samples. The resulting datasets have been instrumental in designing InspectNoise, a library that can be exploited by IoT platforms, without the need of expensive phonometers, but obtaining a similar precision. In particular, we have applied supervised learning algorithms (adequately trained with our datasets) to reduce the accuracy gap between the professional phonometer and an IoT platform equipped with low-end devices and sensors. Results show that RaveGuard, combined with the InspectNoise library, achieves a 2.24% relative error compared to professional instruments, thus enabling low-cost unmanned city-wide noise monitoring.",Sensors,2020,10.3390/s20195583,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2dff5e1622d70973700fc960198588188d073449,https://www.semanticscholar.org/paper/2dff5e1622d70973700fc960198588188d073449,"Discussion on “Approval policies for modifications to machine learning‐based software as a medical device: A study of biocreep” by Jean Feng, Scott Emerson, and Noah Simon","I applaud the authors of Feng et al. (2021) for tackling a challenging statistical problem on approval policies for software as amedical device (SaMD). Their work exploring methodology that could autonomously build algorithmic change protocols soundly extends and leverages related literatures in multiple testing and online learning, among others. While their paper appears in the Biometric Methodology section of the journal, I choose to focus on important practical considerations in this invited discussion, given that algorithms optimized and deployed in health care can directly impact human health. Thus, although not a Biometrics Practice paper, I aim to make the case that several broad issues are relevant for much of the algorithmic work of statisticians who are driven by health applications: the data and setting, whether the reference algorithm is an acceptable baseline, and metrics.",Biometrics,2020,10.1111/biom.13378,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
23766a14d6f41a966abdd3e0f8da4b7497384d16,https://www.semanticscholar.org/paper/23766a14d6f41a966abdd3e0f8da4b7497384d16,Sleep stage classification using extreme learning machine and particle swarm optimization for healthcare big data,,J. Big Data,2021,10.1186/s40537-020-00406-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7e066cf26000f37e1b18bc84a0afb74617d77ed0,https://www.semanticscholar.org/paper/7e066cf26000f37e1b18bc84a0afb74617d77ed0,Machine Learning on Mobile: An On-device Inference App for Skin Cancer Detection,"Mobile health (mHealth) is considered one of the most transformative drivers for health informatics delivery of ubiquitous medical applications. Machine learning has proven to be a powerful tool in classifying medical images for detecting various diseases. However, supervised machine learning requires a large amount of data to train the model, whose storage and processing pose considerable system requirements challenges for mobile applications. Therefore, many studies focus on deploying cloud-based machine learning, which takes advantage of the Internet connection to outsource data intensive computing. However, this approach comes with certain drawbacks such as those related to latency and privacy, which need to be considered in the context of sensitive data. To tackle these challenges of mHealth applications, we present an on-device inference App and use a dataset of skin cancer images to demonstrate a proof of concept. We pre-trained a Convolutional Neural Network model using 10,015 skin cancer images. The model is then deployed on a mobile device, where the inference process takes place, i.e. when presented with new test image all computations are executed locally where the test data remains. This approach reduces latency, saves bandwidth and improves privacy.",2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC),2019,10.1109/FMEC.2019.8795362,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3b6319d92e77b2b157103d357b1d398bbddd4617,https://www.semanticscholar.org/paper/3b6319d92e77b2b157103d357b1d398bbddd4617,Leveraging Social Media Activity and Machine Learning for HIV and Substance Abuse Risk Assessment: Development and Validation Study (Preprint),"
 BACKGROUND
 Social media networks provide an abundance of diverse information that can be leveraged for data-driven applications across various social and physical sciences. One opportunity to utilize such data exists in the public health domain, where data collection is often constrained by organizational funding and limited user adoption. Furthermore, the efficacy of health interventions is often based on self-reported data, which are not always reliable. Health-promotion strategies for communities facing multiple vulnerabilities, such as men who have sex with men, can benefit from an automated system that not only determines health behavior risk but also suggests appropriate intervention targets.
 
 
 OBJECTIVE
 This study aims to determine the value of leveraging social media messages to identify health risk behavior for men who have sex with men.
 
 
 METHODS
 The Gay Social Networking Analysis Program was created as a preliminary framework for intelligent web-based health-promotion intervention. The program consisted of a data collection system that automatically gathered social media data, health questionnaires, and clinical results for sexually transmitted diseases and drug tests across 51 participants over 3 months. Machine learning techniques were utilized to assess the relationship between social media messages and participants' offline sexual health and substance use biological outcomes. The F1 score, a weighted average of precision and recall, was used to evaluate each algorithm. Natural language processing techniques were employed to create health behavior risk scores from participant messages.
 
 
 RESULTS
 Offline HIV, amphetamine, and methamphetamine use were correctly identified using only social media data, with machine learning models obtaining F1 scores of 82.6%, 85.9%, and 85.3%, respectively. Additionally, constructed risk scores were found to be reasonably comparable to risk scores adapted from the Center for Disease Control.
 
 
 CONCLUSIONS
 To our knowledge, our study is the first empirical evaluation of a social media–based public health intervention framework for men who have sex with men. We found that social media data were correlated with offline sexual health and substance use, verified through biological testing. The proof of concept and initial results validate that public health interventions can indeed use social media–based systems to successfully determine offline health risk behaviors. The findings demonstrate the promise of deploying a social media–based just-in-time adaptive intervention to target substance use and HIV risk behavior.
",,2020,10.2196/preprints.22042,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
43697482bf65b98506f77d80ef35676470d52925,https://www.semanticscholar.org/paper/43697482bf65b98506f77d80ef35676470d52925,Interpreting Multimodal Machine Learning Models Trained for Emotion Recognition to Address Robustness and Privacy Concerns,"Many mobile applications and virtual conversational agents now aim to recognize and adapt to emotions. These predicted emotions are used in variety of downstream applications: (a) generating more human like dialogues, (b) predicting mental health issues, and (c) hate speech detection and intervention. To enable this, data are transmitted from users' devices and stored on central servers. These data are then processed further, either annotated or used as inputs for training a model for a specific task. Yet, these data contain sensitive information that could be used by mobile applications without user's consent or, maliciously, by an eavesdropping adversary. My work focuses on two major issues that are faced while training emotion recognition algorithms: (a) privacy of the generated representations and, (b) explaining and ensuring that the predictions are robust to various situations. Tackling these issues would lead to emotion based algorithms that are deployable and helpful at a larger scale, thus enabling more human like experience when interacting with AI.",AAAI,2020,10.1609/aaai.v34i10.7130,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
171827d01e395e2a8f4a89eb31348105749edb82,https://www.semanticscholar.org/paper/171827d01e395e2a8f4a89eb31348105749edb82,A Domains Oriented Framework of Recent Machine Learning Applications in Mobile Mental Health,,Information Systems and Neuroscience,2018,10.1007/978-3-030-01087-4_20,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e9ac5a82487d036b4e43b4f82e7b2a22f077d7d4,https://www.semanticscholar.org/paper/e9ac5a82487d036b4e43b4f82e7b2a22f077d7d4,An experimental approach to evaluate machine learning models for the estimation of load distribution on suspension bridge using FBG sensors and IoT,"Most of the tragedies on any bridge structure have been the cause of high‐density crowd behavior as a response to trampling as well as the crushing scenario. Therefore, it is most important to monitor such unforeseen situations by sensing the load imposed on the bridge structures. This scenario may arise where crowd movement is huge on these types of bridges. Similarly, the fiber Bragg grating (FBG) is a promising technology for structural health monitoring applications. In this work, an Internet of Things based FBG optical sensing scheme is proposed to monitor real‐time strain distribution throughout the bridge structures and localization of load imposed on the structure from a central control room. A suspension bridge model is designed by referring to a real bridge scenario and these FBG sensors are deployed to validate the proposed machine learning models. In this article, the performances of two machine learning strategies are discussed for the accurate estimation of load and its position by acquiring high sensitive FBG sensors signals at a very high data rate. The algorithms include K‐nearest neighbor (KNN) and random forest (RF); which are applied on each sensing data source, and then validated using a prototype suspension bridge model integrated with three FBG sensors (1532 nm, 1538 nm, and1541 nm) on a single optical fiber cable.",Comput. Intell.,2020,10.1111/coin.12406,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bf189fd7af63b3a6eecb221526f89f1c6c5ccd0d,https://www.semanticscholar.org/paper/bf189fd7af63b3a6eecb221526f89f1c6c5ccd0d,Machine-learning-based top-view safety monitoring of ground workforce on complex industrial sites,,Neural Comput. Appl.,2021,10.1007/s00521-021-06489-3,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
26766196e8786365342da0bc23f6c0dedc72f964,https://www.semanticscholar.org/paper/26766196e8786365342da0bc23f6c0dedc72f964,Bridging the implementation gap of machine learning in healthcare,"Applications of machine learning on clinical data are now attaining levels of performance that match or exceed human clinicians.1–3 Fields involving image interpretation—radiology, pathology and dermatology—have led the charge due to the power of convolutional neural networks, the existence of standard data formats and large data repositories. We have also seen powerful diagnostic and predictive algorithms built using a range of other data, including electronic health records (EHR), -omics, monitoring signals, insurance claims and patient-generated data.4 The looming extinction of doctors has captured the public imagination, with editorials such as ‘The AI Doctor Will See You Now’.5 The prevailing view among experts is more balanced: that doctors who use artificial intelligence (AI) will replace those who do not.6

Amid such inflated expectations, the elephant in the room is the implementation gap of machine learning in healthcare.7 8 Very few of these algorithms ever make it to the bedside; and even the most technology-literate academic medical centres are not routinely using AI in clinical workflows. A recent systematic review of deep learning applications using EHR data highlighted the need to focus on the last mile of implementation: ‘for direct clinical impact, deployment and automation of deep learning models must be considered’.9 The typical life-cycle of an algorithm remains: train on historical data, publish a good receiver-operator curve and then collect dust in the ‘model graveyard’.

This begs the question: if model performance is so …",BMJ Innovations,2019,10.1136/bmjinnov-2019-000359,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b75e3c5cc0d57866b178e62e159ab58d8c388f79,https://www.semanticscholar.org/paper/b75e3c5cc0d57866b178e62e159ab58d8c388f79,Multi-disciplinary fairness considerations in machine learning for clinical trials,"While interest in the application of machine learning to improve healthcare has grown tremendously in recent years, a number of barriers prevent deployment in medical practice. A notable concern is the potential to exacerbate entrenched biases and existing health disparities in society. The area of fairness in machine learning seeks to address these issues of equity; however, appropriate approaches are context-dependent, necessitating domain-specific consideration. We focus on clinical trials, i.e., research studies conducted on humans to evaluate medical treatments. Clinical trials are a relatively under-explored application in machine learning for healthcare, in part due to complex ethical, legal, and regulatory requirements and high costs. Our aim is to provide a multi-disciplinary assessment of how fairness for machine learning fits into the context of clinical trials research and practice. We start by reviewing the current ethical considerations and guidelines for clinical trials and examine their relationship with common definitions of fairness in machine learning. We examine potential sources of unfairness in clinical trials, providing concrete examples, and discuss the role machine learning might play in either mitigating potential biases or exacerbating them when applied without care. Particular focus is given to adaptive clinical trials, which may employ machine learning. Finally, we highlight concepts that require further investigation and development, and emphasize new approaches to fairness that may be relevant to the design of clinical trials.",FAccT,2022,10.1145/3531146.3533154,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
92a6dd37b7c7a1c86edcb30c736b2c4204727e2c,https://www.semanticscholar.org/paper/92a6dd37b7c7a1c86edcb30c736b2c4204727e2c,A critical review on diagnosis of diabetic retinopathy using machine learning and deep learning,,Multim. Tools Appl.,2022,10.1007/s11042-022-12642-4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5e09ee078c48562d9994dde2ceca98f4c27a0de5,https://www.semanticscholar.org/paper/5e09ee078c48562d9994dde2ceca98f4c27a0de5,Machine Learning for Cardiovascular Outcomes From Wearable Data: Systematic Review From a Technology Readiness Level Point of View,"Background Wearable technology has the potential to improve cardiovascular health monitoring by using machine learning. Such technology enables remote health monitoring and allows for the diagnosis and prevention of cardiovascular diseases. In addition to the detection of cardiovascular disease, it can exclude this diagnosis in symptomatic patients, thereby preventing unnecessary hospital visits. In addition, early warning systems can aid cardiologists in timely treatment and prevention. Objective This study aims to systematically assess the literature on detecting and predicting outcomes of patients with cardiovascular diseases by using machine learning with data obtained from wearables to gain insights into the current state, challenges, and limitations of this technology. Methods We searched PubMed, Scopus, and IEEE Xplore on September 26, 2020, with no restrictions on the publication date and by using keywords such as “wearables,” “machine learning,” and “cardiovascular disease.” Methodologies were categorized and analyzed according to machine learning–based technology readiness levels (TRLs), which score studies on their potential to be deployed in an operational setting from 1 to 9 (most ready). Results After the removal of duplicates, application of exclusion criteria, and full-text screening, 55 eligible studies were included in the analysis, covering a variety of cardiovascular diseases. We assessed the quality of the included studies and found that none of the studies were integrated into a health care system (TRL<6), prospective phase 2 and phase 3 trials were absent (TRL<7 and 8), and group cross-validation was rarely used. These issues limited these studies’ ability to demonstrate the effectiveness of their methodologies. Furthermore, there seemed to be no agreement on the sample size needed to train these studies’ models, the size of the observation window used to make predictions, how long participants should be observed, and the type of machine learning model that is suitable for predicting cardiovascular outcomes. Conclusions Although current studies show the potential of wearables to monitor cardiovascular events, their deployment as a diagnostic or prognostic cardiovascular clinical tool is hampered by the lack of a realistic data set and proper systematic and prospective evaluation.",JMIR medical informatics,2021,10.2196/29434,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8975b42e95a087ce75de9f40c1da554dd81ceeb7,https://www.semanticscholar.org/paper/8975b42e95a087ce75de9f40c1da554dd81ceeb7,A comprehensive review on machine learning in agriculture domain,"Agriculture is an essential part of sustaining human life. Population growth, climate change, resource competition are the key issues that increase food security and to handle such complex problems in agriculture production, intelligent or smart farming extends the incorporation of technology into traditional agriculture notion. Machine learning is a vitally used technology in agriculture to protect food security and sustainability. Crop yield production, water preservation, soil health and plant diseases can be addressed by machine learning. This paper has presented a compendious review of research papers that deployed machine learning in the agriculture domain. The observed sub-categories of the agriculture domain are crop yield prediction, soil management, pest management, weed management, and crop disease. The outcomes represent that machine learning provides better accuracy concerning classification or regression. Machine learning emerged with the internet of things, drones, robots, automated machinery, and satellite imagery motivates researchers for smart farming and food security.",IAES International Journal of Artificial Intelligence (IJ-AI),2022,10.11591/ijai.v11.i2.pp753-763,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
705d55bf957c340574c6c461dad39559ffc68b11,https://www.semanticscholar.org/paper/705d55bf957c340574c6c461dad39559ffc68b11,Schoolchildren' Depression and Anxiety Risk Factors Assessment and Prediction: Machine Learning Techniques Performance Analysis.,"BACKGROUND
Depression and anxiety symptoms in early childhood have a major effect on children's mental health growth and cognitive development. Studying the effect of mental health problems on cognitive development has gained researchers' attention for the last two decades.


OBJECTIVE
In this paper, we seek to use machine learning techniques to predict the risk factors associated with school children's depression and anxiety.


METHODS
The study data consisted of 5685 students in grades 5-9, aged 10-15 years, studying at public and refugee schools in the West Bank. The data were collected using the health behaviors school children questionnaire in the 2013-2014 academic year and analyzed using machine learning to predict the risk factors associated with student mental health symptoms. Five machine learning techniques (Random Forest, Neural Network, Decision Tree, Support Vector Machine, and Naïve Bayes) were used for prediction.


RESULTS
The results indicated that the SVM and Random Forest model had the highest accuracy levels (SVM= 92.5%, RF=76.4%; SVM=92.4%, RF=78.6%) for depression and anxiety respectively. Thus, the SVM and Random Forest had the best performance in classifying and predicting the student's depression and anxiety. The results showed that school violence and bullying, home violence, academic performance, and family income were the most important factors affecting depression and anxiety scales.


CONCLUSIONS
Overall, machine learning proved to be an efficient tool for identifying and predicting the associated factors that influence student depression and anxiety. The ML techniques seem to be a good model for predicting abnormal depression and anxiety symptoms among schoolchildren, so the deployment of machine learning within the school information systems might facilitate the development of health prevention and intervention programs that will enhance students' mental health and cognitive development.


CLINICALTRIAL",JMIR formative research,2021,10.2196/32736,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9fae71ae9d497c5544549439d9bc6ee07c440ca2,https://www.semanticscholar.org/paper/9fae71ae9d497c5544549439d9bc6ee07c440ca2,Minimising pipeline leaks and maximising operational life by application of machine learning at Cooper Basin,"The development of technologies in the last few decades has enabled operators to collect significantly more data than previously possible. Despite availability, making data-driven decisions on asset health, and developing efficient asset management strategies, is not common. This is mainly due to challenges with compilation, and alignment of all the data into a comprehensive picture of pipeline integrity, as it consumes significant resources deploying conventional methods. A critical advantage of modern data storage, analysis and visualisation techniques is the relative ease of performing statistical assessments of integrity data. Analysis of correlated data can be equally challenging as algorithms used can be overly simplistic and inaccurate. Machine learning algorithms parse, analyse and learn from data, enabling the operators to make an educated decision. This has been extensively deployed in other industries such as finance, healthcare and supply chain management but has never been fully developed and enhanced in pipeline integrity industry until very recently. This paper provides an overview of the development in machine learning tools in pipeline integrity, allowing enhancement of asset performance, through the application of machine learning and automation, to predict integrity threats, and prevent leaks and failures. It provides a case study where a tool was developed, and this technique was successfully implemented across a significant number of upstream pipelines in the Cooper Basin, enabling the Santos integrity engineering team to make the most effective decisions on asset condition and to develop a data-driven asset management plan.",The APPEA Journal,2022,10.1071/aj21060,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3e307a8a7b7b484e34eb3ee1d48fc1799b9e72cf,https://www.semanticscholar.org/paper/3e307a8a7b7b484e34eb3ee1d48fc1799b9e72cf,Fast and automated biomarker detection in breath samples with machine learning,"Volatile organic compounds (VOCs) in human breath can reveal a large spectrum of health conditions and can be used for fast, accurate and non-invasive diagnostics. Gas chromatography-mass spectrometry (GC-MS) is used to measure VOCs, but its application is limited by expert-driven data analysis that is time-consuming, subjective and may introduce errors. We propose a machine learning-based system to perform GC-MS data analysis that exploits deep learning pattern recognition ability to learn and automatically detect VOCs directly from raw data, thus bypassing expert-led processing. We evaluate this new approach on clinical samples and with four types of convolutional neural networks (CNNs): VGG16, VGG-like, densely connected and residual CNNs. The proposed machine learning methods showed to outperform the expert-led analysis by detecting a significantly higher number of VOCs in just a fraction of time while maintaining high specificity. These results suggest that the proposed novel approach can help the large-scale deployment of breath-based diagnosis by reducing time and cost, and increasing accuracy and consistency.",PloS one,2020,10.1371/journal.pone.0265399,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
08571b63e62079838182808a554bdc4a7e2892cd,https://www.semanticscholar.org/paper/08571b63e62079838182808a554bdc4a7e2892cd,Editorial: Machine Learning and Deep Learning for Physiological Signal Analysis,"Physiological Signal Analysis The machine learning (ML) and deep learning (DL) methods play an essential role in developing automated diagnostic systems for the accurate detection of various diseases using physiological signals (Yin et al., 2017). These methods are also used for emotion recognition, cognitive workload assessment, brain-machine interface, and other applications using physiological signals (Varshney et al., 2021; Maheshwari et al., 2021; Radhakrishnan et al., 2021; Tripathy et al., 2018). The advances of wearable technology and the internet of things (IoT) enable real-time monitoring of patients ’ health status using physiological sensor data (Zhou et al., 2020). The ML and DL models are deployed on these intelligent healthcare systems for automated and real-time patient monitoring. The goal of this special issue on Machine Learning and Deep Learning of Physiological Signal Analysis was to disseminate the articles related to the (a) application of ML and DL for cardiovascular signal processing, (b) application of ML and DL for neural signal processing, (c) the use of ML and DL for affective computing, (d) application of ML and DL to bioinformatics, (e) ML and DL applications to human gait analysis and fatigue monitoring. In this special issue, ten papers have been submitted, and each of these papers was reviewed by at least two reviewers. Based on the reviewer ’ s feedback, seven papers are published in this special issue of the Frontiers in Physiology journal. All published papers in this special issue are summarized as follows. Davis et al. have used four data preprocessing steps: quantile ﬁ ltering, baseline diurnal statistics, normalization, and extract summary statistics of the physiological data to capture the features and used random",Frontiers in Physiology,2022,10.3389/fphys.2022.887070,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4c417241eaf2f637af7b9103b61517ec95ed05f5,https://www.semanticscholar.org/paper/4c417241eaf2f637af7b9103b61517ec95ed05f5,Heart disease prediction using machine learning,"Today, heart disease is a severe hazard to one's health that may result in death or a long-term impairment because of the complicated blend of clinical and pathological evidence required to diagnose it. Despite the fact that medical diagnosis is a complex activity that plays a critical role in saving human lives, there is a dearth of appropriate tools to detect hidden linkages and patterns in electronic health data. Computer-based automated decision support systems are needed to lower the costs of clinical testing because of this complexity. "" In this study, we provide a method for predicting the presence of cardiac disease based on clinical data collected from patients. In this study, the primary goal is to develop a predictive model for heart disease based on a combination of characteristics (risk factors). Different machine learning classification strategies will be deployed and evaluated based on conventional performance metrics such as accuracy in order to compare different machine learning algorithms.",International journal of health sciences,2022,10.53730/ijhs.v6ns2.6955,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d84c0d864ac3e9467671eae52ede4c8ac8268e4f,https://www.semanticscholar.org/paper/d84c0d864ac3e9467671eae52ede4c8ac8268e4f,Web-Based Machine Learning Application for Heart Disease Prediction,"Risk because of heart disease is increasing throughout the world. According to the World Health Organization report, the number of deaths because of heart disease is drastically increasing as compared to other diseases. Multiple factors are responsible for causing heart-related issues. Many approaches were suggested for prediction of heart disease, but none of them were satisfactory in clinical terms. Heart disease therapies and operations available are so costly, and following treatment, heart disease is also costly. This chapter provides a comprehensive survey of existing machine learning algorithms and presents comparison in terms of accuracy, and the authors have found that the random forest classifier is the most accurate model; hence, they are using random forest for further processes. Deployment of machine learning model using web application was done with the help of flask, HTML, GitHub, and Heroku servers. Webpages take input attributes from the users and gives the output regarding the patient heart condition with accuracy of having coronary heart disease in the next 10 years.",Advances in Healthcare Information Systems and Administration,2022,10.4018/978-1-7998-7709-7.ch022,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b211e16e7e6c70a003c89f4bc2a9f3a434bb70cd,https://www.semanticscholar.org/paper/b211e16e7e6c70a003c89f4bc2a9f3a434bb70cd,"Open-Source Clinical Machine Learning Models: Critical Appraisal of Feasibility, Advantages, and Challenges","Machine learning applications promise to augment clinical capabilities and at least 64 models have already been approved by the US Food and Drug Administration. These tools are developed, shared, and used in an environment in which regulations and market forces remain immature. An important consideration when evaluating this environment is the introduction of open-source solutions in which innovations are freely shared; such solutions have long been a facet of digital culture. We discuss the feasibility and implications of open-source machine learning in a health care infrastructure built upon proprietary information. The decreased cost of development as compared to drugs and devices, a longstanding culture of open-source products in other industries, and the beginnings of machine learning–friendly regulatory pathways together allow for the development and deployment of open-source machine learning models. Such tools have distinct advantages including enhanced product integrity, customizability, and lower cost, leading to increased access. However, significant questions regarding engineering concerns about implementation infrastructure and model safety, a lack of incentives from intellectual property protection, and nebulous liability rules significantly complicate the ability to develop such open-source models. Ultimately, the reconciliation of open-source machine learning and the proprietary information–driven health care environment requires that policymakers, regulators, and health care organizations actively craft a conducive market in which innovative developers will continue to both work and collaborate.",JMIR formative research,2022,10.2196/33970,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e9dee76111898c5bc03675f2350456f9b4d450c7,https://www.semanticscholar.org/paper/e9dee76111898c5bc03675f2350456f9b4d450c7,Early wildfire detection using machine learning model deployed in the fog/edge layers of IoT,"The impact of wildfires, even following the fire's extinguishment, continues to affect harmfully public health and prosperity. Wildfires are becoming increasingly frequent and severe, and make the world's biodiversity in a growing serious danger. The fires are responsible for negative economic consequences for individuals, corporations, and authorities. Researchers are developing new approaches for detecting and monitoring wildfires, that make use of advances in computer vision, machine learning, and remote sensing technologies. IoT sensors help to improve the efficiency of detecting active forest fires. In this paper, we propose a novel approach for predicting wildfires, based on machine learning. It uses a regression model that we train over NASA's fire information for resource management system (FIRMS) dataset to predict fire radiant power in megawatts. The analysis of the obtained simulation results (more than 99% in the R2 metric) shows that the ensemble learning model is an effective method for predicting wildfires using an IoT device equipped with several sensors that could potentially collect the same data as the FIRMS dataset, such as smart cameras or drones.",Indonesian Journal of Electrical Engineering and Computer Science,2022,10.11591/ijeecs.v27.i2.pp1062-1073,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a7f0c229c5c5eb676630fcb82b73a264ddd2f6cc,https://www.semanticscholar.org/paper/a7f0c229c5c5eb676630fcb82b73a264ddd2f6cc,Practical Machine Learning Techniques for COVID-19 Detection Using Chest X-Ray Images,"This paper presents effective techniques for automatic detection/classification of COVID-19 and other lung diseases using machine learning, including deep learning with convolutional neural networks (CNN) and classical machine learning techniques. We had access to a large number of chest X-ray images to use as input data. The data contains various categories including COVID-19, Pneumonia, Pneumothorax, Atelectasis, and Normal (without disease). In addition, chest X-ray images with many findings (abnormalities and diseases) from the National Institutes of Health (NIH) was also considered. Our deep learning approach used a CNN architecture with VGG16 and VGG19 models which were pre-trained with ImageNet. We compared this approach with the classical machine learning approaches, namely Support Vector Machine (SVM) and Random Forest. In addition to independently extracting image features, pre-trained features obtained from a VGG19 model were utilized with these classical machine learning techniques. Both binary and categorical (multi-class) classification tasks were considered on classical machine learning and deep learning. Several X-ray images ranging from 7000 images up to 11500 images were used in each of our experiments. Five experimental cases were considered for each classification model. Results obtained from all techniques were evaluated with confusion matrices, accuracy, precision, recall and F1-score. In summary, most of the results are very impressive. Our deep learning approach produced up to 97.5% accuracy and 98% F1-score on COVID-19 vs. non-COVID-19 (normal or diseases excluding COVID-19) class, while in classical machine learning approaches, the SVM with pretrained features produced 98.9% accuracy, and at least 98.2% precision, recall and F1-score on COVID-19 vs. non-COVID-19 class. These disease detection models can be deployed for practical usage in the near future.",Intelligent Automation &amp; Soft Computing,2022,10.32604/iasc.2022.025073,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
91fab3f200f3f63d15785867e4ab41535f9ecd34,https://www.semanticscholar.org/paper/91fab3f200f3f63d15785867e4ab41535f9ecd34,Predictive models for clinical decision making: Deep dives in practical machine learning,"The deployment of machine learning for tasks relevant to complementing standard of care and advancing tools for precision health has gained much attention in the clinical community, thus meriting further investigations into its broader use. In an introduction to predictive modelling using machine learning, we conducted a review of the recent literature that explains standard taxonomies, terminology and central concepts to a broad clinical readership. Articles aimed at readers with little or no prior experience of commonly used methods or typical workflows were summarised and key references are highlighted. Continual interdisciplinary developments in data science, biostatistics and epidemiology also motivated us to further discuss emerging topics in predictive and data‐driven (hypothesis‐less) analytics with machine learning. Through two methodological deep dives using examples from precision psychiatry and outcome prediction after lymphoma, we highlight how the use of, for example, natural language processing can outperform established clinical risk scores and aid dynamic prediction and adaptive care strategies. Such realistic and detailed examples allow for critical analysis of the importance of new technological advances in artificial intelligence for clinical decision‐making. New clinical decision support systems can assist in prevention and care by leveraging precision medicine.",Journal of internal medicine,2022,10.1111/joim.13483,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c86df5a8d64beebd6f2bbbcfcdde919521803c8d,https://www.semanticscholar.org/paper/c86df5a8d64beebd6f2bbbcfcdde919521803c8d,Optimizing Control of IOT Device using Traditional Machine Learning Models and Deep Neural Networks,"With the increasing threat of Covid-19 and now omicron infection across the world among people, there has been a significant surge in the demand for a fully-automated, self-controlled or mechanized ventilator which can provide sufficient air-pressure to weak human lungs continuously. It is our humble endeavor to mitigate the effects caused due to handful of trained-physicians over countless untreated patients and lack of enough health-infrastructure facilities to support in the time of dire need. We all dread losing another precious life on earth due to any one of the above mentioned reason. We have tried simulating the observations obtained from a lab-developed mechanical ventilator system under different lung settings. After preprocessing this dataset using NLP, training data is analysed to study the correlation between observations from numerous attributes. A couple of Machine Learning (LR, RF, SVM, LGBM) and Deep Learning (MLP, LSTM, Bi-LSTM) algorithms have been deployed to train our model individually, out of which Bi-LSTM performed exceptionally well above others. However, only after exhaustive clinical trials and recommendations a large of number of patients on life-support can get a new life through the large practical application of this device, in the near future.",2022 6th International Conference on Computing Methodologies and Communication (ICCMC),2022,10.1109/ICCMC53470.2022.9753943,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ea7c511099014177ddff4c4b17363cf5bd1eb34e,https://www.semanticscholar.org/paper/ea7c511099014177ddff4c4b17363cf5bd1eb34e,Comparative Analysis of Machine Learning for Predicting Air Quality in Smart Cities,"Ambient air pollution is the most harmful environmental risk to health. As urban air quality improves, health costs from air pollution-related diseases diminish. This is why air pollution is a major challenge for the public and government around the world. Deployment of the Internet of Things-based sensors has considerably changed the dynamics of predicting air quality. Air pollution can be predicted using machine learning algorithms Data-based sensors in the context of smart cities. In this paper, we performed pollution forecasting using machine learning techniques while presenting a comparative study to determine the best model to accurately predict air quality. Random Forest is an efficient algorithm capable of detecting air quality.",WSEAS TRANSACTIONS ON COMPUTERS,2022,10.37394/23205.2022.21.30,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cfaa04075096e2b5027d1a1995e76f5a1be4c786,https://www.semanticscholar.org/paper/cfaa04075096e2b5027d1a1995e76f5a1be4c786,"Development of machine learning models for the prediction of complications after colonic, colorectal and small intestine anastomosis in psychiatric and non-psychiatric patient collectives (P-Study)","Psychiatric and psychosomatic diseases are an increasingly cumbersome burden for the medical system. Indeed, hospital costs associated with mental health conditions have been constantly on the rise in recent years. Moreover, psychiatric conditions are likely to have a negative effect on the treatment of other medical conditions and surgical outcomes, in addition to their direct effects on the overall quality of life. Our study aims to investigate the impact of preoperative Risk factor, psychiatric and psychosomatic diseases on the outcomes of colorectal surgery and length of hospital stay via predictive modeling techniques. Method: Patient data will be collected from several participating national and international surgical centers The machine learning models will be calculated and coded, but also published according to the TRIPOD guidelines (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis). Result: It is conceivable to arrive at generalizable models predicting the abovementioned endpoints through large amounts of data from several centers. The models will be subsequently deployed as a free-to-use web-based prediction tool using the Shiny environment [47]. The cost for the hosting server and digital infrastructure will be covered by Dr. Anas Taha. The data, which has been gathered, will be saved for ten years by the sponsor.",medRxiv,2022,10.1101/2022.02.02.22269622,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
96b09215f97a63d1e199c8f91581e2cc58eafac8,https://www.semanticscholar.org/paper/96b09215f97a63d1e199c8f91581e2cc58eafac8,A machine learning approach to predict resilience and sickness absence in the healthcare workforce during the COVID-19 pandemic,,Scientific reports,2022,10.1038/s41598-022-12107-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d6ac4bd4ec510b8b3b7c87cd77aaab89962d3340,https://www.semanticscholar.org/paper/d6ac4bd4ec510b8b3b7c87cd77aaab89962d3340,Outcome Analysis in Elective Electrical Cardioversion of Atrial Fibrillation Patients: Development and Validation of a Machine Learning Prognostic Model,"Background: The integrated approach to electrical cardioversion (EC) in atrial fibrillation (AF) is complex; candidates can resolve spontaneously while waiting for EC, and post-cardioversion recurrence is high. Thus, it is especially interesting to avoid the programming of EC in patients who would restore sinus rhythm (SR) spontaneously or present early recurrence. We have analyzed the whole elective EC of the AF process using machine-learning (ML) in order to enable a more realistic and detailed simulation of the patient flow for decision making purposes. Methods: The dataset consisted of electronic health records (EHRs) from 429 consecutive AF patients referred for EC. For analysis of the patient outcome, we considered five pathways according to restoring and maintaining SR: (i) spontaneous SR restoration, (ii) pharmacologic-cardioversion, (iii) direct-current cardioversion, (iv) 6-month AF recurrence, and (v) 6-month rhythm control. We applied ML classifiers for predicting outcomes at each pathway and compared them with the CHA2DS2-VASc and HATCH scores. Results: With the exception of pathway (iii), all ML models achieved improvements in comparison with CHA2DS2-VASc or HATCH scores (p < 0.01). Compared to the most competitive score, the area under the ROC curve (AUC-ROC) was: 0.80 vs. 0.66 for predicting (i); 0.71 vs. 0.55 for (ii); 0.64 vs. 0.52 for (iv); and 0.66 vs. 0.51 for (v). For a threshold considered optimal, the empirical net reclassification index was: +7.8%, +47.2%, +28.2%, and +34.3% in favor of our ML models for predicting outcomes for pathways (i), (ii), (iv), and (v), respectively. As an example tool of generalizability of ML models, we deployed our algorithms in an open-source calculator, where the model would personalize predictions. Conclusions: An ML model improves the accuracy of restoring and maintaining SR predictions over current discriminators. The proposed approach enables a detailed simulation of the patient flow through personalized predictions.",Journal of clinical medicine,2022,10.3390/jcm11092636,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
43f7a7f04f7f9455a4c6e3ad1328f70c9cdde72d,https://www.semanticscholar.org/paper/43f7a7f04f7f9455a4c6e3ad1328f70c9cdde72d,Battery Degradation Modelling and Prediction with Combination of Machine Learning and Semi-empirical Methods,"Battery energy storage systems (BESS) are being widely deployed as part of the energy transition. Accurate battery degradation modelling and prediction play an important role in BESS investment and revenue, planning and sizing, operational monitoring, and warranty check-ups. Complex operational behaviors and system variability make the battery degradation modelling and prediction more challenging. In this paper, we propose a novel methodology of combining a machine learning model with semi-empirical equations to have a robust state of health (SOH) estimation. Together with cycle decomposition analysis, this model can be deployed for real-time degradation analysis of BESS.","2022 12th International Conference on Power, Energy and Electrical Engineering (CPEEE)",2022,10.1109/CPEEE54404.2022.9738723,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c236bb1143a7a6dbc07b073152d5249f6f002ce3,https://www.semanticscholar.org/paper/c236bb1143a7a6dbc07b073152d5249f6f002ce3,Leveraging mathematical models of disease dynamics and machine learning to improve development of novel malaria interventions,,Infectious Diseases of Poverty,2022,10.1186/s40249-022-00981-1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
af58458fc30dfae2c707f6145b92f212efede2a6,https://www.semanticscholar.org/paper/af58458fc30dfae2c707f6145b92f212efede2a6,Development of machine learning models for the prediction of complications after colorectal and small intestine surgery in psychiatric and non-psychiatric patient collectives (P-Study),"Introduction: Psychiatric and psychosomatic diseases are an increasingly cumbersome burden for the medical system. Indeed, hospital costs associated with mental health conditions have been constantly on the rise in recent years. Moreover, psychiatric conditions are likely to have a negative effect on the treatment of other medical conditions and surgical outcomes, in addition to their direct effects on the overall quality of life . Our study aims to investigate the impact of preoperative risk factors, psychiatric and psychosomatic diseases, and non-psychiatric and non-psychosomatic diseases on the outcomes of small and large bowel surgery and length of hospital stay via predictive modeling techniques. Methods and Analysis: Patient data will be collected from several participating national and international surgical centers. The machine learning models will be calculated and coded, but also published in respect to the TRIPOD guidelines (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis). Expected Results: It is conceivable to arrive at generalizable models predicting the above-mentioned endpoints through large amounts of data from several centers. The models will be subsequently deployed as a free-to-use web-based prediction tool.",,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8a3282528f15b2f088a6a00d5d38442d4e496aa0,https://www.semanticscholar.org/paper/8a3282528f15b2f088a6a00d5d38442d4e496aa0,Concurrent 18. Presentation for: Minimising pipeline leaks and maximising operational life by application of machine learning at Cooper Basin,"Presented on Wednesday 18 May: Session 18 The development of technologies in the last few decades has enabled operators to collect significantly more data than previously possible. Despite availability, making data-driven decisions on asset health, and developing efficient asset management strategies, is not common. This is mainly due to challenges with compilation, and alignment of all the data into a comprehensive picture of pipeline integrity, as it consumes significant resources deploying conventional methods. A critical advantage of modern data storage, analysis and visualisation techniques is the relative ease of performing statistical assessments of integrity data. Analysis of correlated data can be equally challenging as algorithms used can be overly simplistic and inaccurate. Machine learning algorithms parse, analyse and learn from data, enabling the operators to make an educated decision. This has been extensively deployed in other industries such as finance, healthcare and supply chain management but has never been fully developed and enhanced in pipeline integrity industry until very recently. This paper provides an overview of the development in machine learning tools in pipeline integrity, allowing enhancement of asset performance, through the application of machine learning and automation, to predict integrity threats, and prevent leaks and failures. It provides a case study where a tool was developed, and this technique was successfully implemented across a significant number of upstream pipelines in the Cooper Basin, enabling the Santos integrity engineering team to make the most effective decisions on asset condition and to develop a data-driven asset management plan. To access the presentation click the link on the right. To read the full paper click here",The APPEA Journal,2022,10.1071/aj21363,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a22eaed615a8209f7b8da056292df8e6f3b3bb0e,https://www.semanticscholar.org/paper/a22eaed615a8209f7b8da056292df8e6f3b3bb0e,Machine learning techniques for predicting depression and anxiety in pregnant and postpartum women during the COVID-19 pandemic: a cross-sectional regional study,"Background: Maternal depression and anxiety are significant public health concerns that play an important role in the health and well-being of mothers and children. The COVID-19 pandemic, the consequential lockdowns and related safety restrictions worldwide negatively affected the mental health of pregnant and postpartum women. Methods: This regional study aimed to develop a machine learning (ML) model for the prediction of maternal depression and anxiety. The study used a dataset collected from five Arab countries during the COVID-19 pandemic between July to December 2020. The population sample included 3569 women (1939 pregnant and 1630 postpartum) from five countries (Jordan, Palestine, Lebanon, Saudi Arabia, and Bahrain). The performance of seven machine learning algorithms was assessed for the prediction of depression and anxiety symptoms. Results: The Gradient Boosting (GB) and Random Forest (RF) models outperformed other studied ML algorithms with accuracy values of 83.3% and 83.2% for depression, respectively, and values of 82.9% and 81.3% for anxiety, respectively. The Mathew’s Correlation Coefficient was evaluated for the ML models; the Naïve Bayes (NB) and GB models presented the highest performance measures (0.63 and 0.59) for depression and (0.74 and 0.73) for anxiety, respectively. The features’ importance ranking was evaluated, the results showed that stress during pregnancy, family support, financial issues, income, and social support were the most significant values in predicting anxiety and depression. Conclusion: Overall, the study evidenced the power of ML models in predicting maternal depression and anxiety and proved to be an efficient tool for identifying and predicting the associated risk factors that influence maternal mental health. The deployment of machine learning models for screening and early detection of depression and anxiety among pregnant and postpartum women might facilitate the development of health prevention and intervention programs that will enhance maternal and child health in low- and middle-income countries.",F1000Research,2022,10.12688/f1000research.110090.1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f05ae3411a1e1b01631514b85fbf25f7437ed639,https://www.semanticscholar.org/paper/f05ae3411a1e1b01631514b85fbf25f7437ed639,A Study of Convolutional Neural Networks Learning Mechanisms for Machine Health Monitoring Applications,"In recent years, Deep Learning (DL) and Internet of Things (IoT) technologies have been used and deployed jointly to solve a wide range of modern technical challenges in different areas. With the continuous advancement of IoT connectivity solutions, the range of applications that can benefit from such an increase is limitless. One area that can benefit significantly from the combined strength of DL and IoT technologies is Machine Health Monitoring (MHM) Systems. MHM utilizes different analytical approaches and tools to determine the state and health of different components in running machinery. The traditional MHM system uses control limits from predetermining values that determine if a component has failed depending on the preset limits of the machinery. The main disadvantage of using such technique us the unpredictable nature of the timing and component failure. This type of failure causes unplanned production time loss and increases the cost of maintenance due to the unpredictability of the failure events. With DL and low-cost sensors that use different IoT connectivity solutions, MHM systems can utilize the learning capabilities of the DL network to perform end-to-end prognosis. One crucial fact is that features learned by Deep Neural Networks (DNN) are part of a large black box, and there are valuable underlying physical meanings embedded within the features. Hence, there is an exciting research area to explore underlying mechanisms and interpret physical meanings within DNN. In this paper, DNN learning mechanisms are evaluated using three different models: stacked autoencoders (SAE), denoising autoencoders (DAE), and convolutional neural networks (CNN). Initial results indicate that the input layer behaves similarly to a band-pass filter.  However, deep layers require optimal input design to maximize neuron activation, which leads to an extensive understanding of deep layer learning consequently (In progress).",,2020,10.36001/PHMCONF.2020.V12I1.1196,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
31ece475f1089709034e97bb7fbb9278b615b1c8,https://www.semanticscholar.org/paper/31ece475f1089709034e97bb7fbb9278b615b1c8,Enabling Data-Driven Clinical Quality Assurance: Predicting Adverse Event Reporting in Clinical Trials Using Machine Learning,,Drug Safety,2019,10.1007/s40264-019-00831-4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2abca5533ead85215c11be31283a731a6c1fea68,https://www.semanticscholar.org/paper/2abca5533ead85215c11be31283a731a6c1fea68,"Machine Learning for 5 G / B 5 G Mobile and Wireless Communications : Potential , Limitations , and Future Directions","Driven by the demand to accommodate today’s growing mobile traffic, 5G is designed to be a key enabler and a leading infrastructure provider in the information and communication technology industry by supporting a variety of forthcoming services with diverse requirements. Considering the everincreasing complexity of the network, and the emergence of novel use cases such as autonomous cars, industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML) is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised, unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of ML in the context of mobile and wireless communication, organizing the literature in terms of the types of learning. We then discuss the promising approaches for how ML can contribute to supporting each target 5G network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G), providing future research directions for how ML can contribute to realizing B5G. This article is intended to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of autonomous 5G/B5G mobile and wireless communications. INDEX TERMS Machine learning, 5G mobile communication, B5G, Wireless communication, Mobile communication, Artificial intelligence.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8052beced62611aa60da73c44281ae24d139b83b,https://www.semanticscholar.org/paper/8052beced62611aa60da73c44281ae24d139b83b,High-Resolution Urban Air Quality Mapping for Multiple Pollutants Based on Dense Monitoring Data and Machine Learning,"Spatially explicit urban air quality information is important for urban fine-management and public life. However, existing air quality measurement methods still have some limitations on spatial coverage and system stability. A micro station is an emerging monitoring system with multiple sensors, which can be deployed to provide dense air quality monitoring data. Here, we proposed a method for urban air quality mapping at high-resolution for multiple pollutants. By using the dense air quality monitoring data from 448 micro stations in Lanzhou city, we developed a decision tree model to infer the distribution of citywide air quality at a 500 m × 500 m × 1 h resolution, with a coefficient of determination (R2) value of 0.740 for PM2.5, 0.754 for CO and 0.716 for SO2. Meanwhile, we also show that the deployment density of the monitoring stations can have a significant impact on the air quality inference results. Our method is able to show both short-term and long-term distribution of multiple important pollutants in the city, which demonstrates the potential and feasibility of dense monitoring data combined with advanced data science methods to support urban atmospheric environment fine-management, policy making, and public health studies.",International journal of environmental research and public health,2022,10.3390/ijerph19138005,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29ce03af53db5f3c72bfbbd4b6312671d14e8072,https://www.semanticscholar.org/paper/29ce03af53db5f3c72bfbbd4b6312671d14e8072,"iGait: Vision-based Low-Cost, Reliable Machine Learning Framework for Gait Abnormality Detection","Human gait has shown to be a strong indicator of health issues under a wide variety of conditions. For that reason, gait analysis has become a powerful tool for clinicians to assess functional limitations due to neurological or orthopedic conditions that are reflected in gait. Therefore, accurate gait monitoring and analysis methods have found a wide range of applications from diagnosis to treatment and rehabilitation. This thesis focuses on creating a low-cost and non-intrusive vision-based machine learning framework dubbed as iGait to accurately detect CLBP patients using 3-D capturing devices such as MS Kinect. To analyze the performance of the system, a precursor analysis for creating a feature vector is performed by designing a highly controlled in-lab simulation of walks. Furthermore, the designed framework is extensively tested on realworld data acquired from volunteer elderly patients with CLBP. The feature vector presented in this thesis show very high agreement in getting the pathological gait disorders (0.98% for in-lab settings and 90% for actual CLBP patients), with a thorough research on the contribution of each feature vector on the overall classification accuracy.",,2017,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7fe995a220a9a1f3fad5539b71d12b13ea6c943a,https://www.semanticscholar.org/paper/7fe995a220a9a1f3fad5539b71d12b13ea6c943a,"Computer vision and machine learning for medical image analysis: recent advances, challenges, and way forward","The recent development in the areas of deep learning and deep convolutional neural networks has significantly progressed and advanced the field of computer vision (CV) and image analysis and understanding. Complex tasks such as classifying and segmenting medical images and localising and recognising objects of interest have become much less challenging. This progress has the potential of accelerating research and deployment of multitudes of medical applications that utilise CV. However, in reality, there are limited practical examples being physically deployed into front-line health facilities. In this paper, we examine the current state of the art in CV as applied to the medical domain. We discuss the main challenges in CV and intelligent data-driven medical applications and suggest future directions to accelerate research, development, and deployment of CV applications in health practices. First, we critically review existing literature in the CV domain that addresses complex vision tasks, including: medical image classification; shape and object recognition from images; and medical segmentation. Second, we present an in-depth discussion of the various challenges that are considered barriers to accelerating research, development, and deployment of intelligent CV methods in real-life medical applications and hospitals. Finally, we conclude by discussing future directions.",Artificial Intelligence Surgery,2022,10.20517/ais.2021.15,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695,https://www.semanticscholar.org/paper/efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695,Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,"As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",2018 IEEE Symposium on Security and Privacy (SP),2018,10.1109/SP.2018.00057,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
97702f29b0a6c6ae0d931ab99005ad313edfc0b6,https://www.semanticscholar.org/paper/97702f29b0a6c6ae0d931ab99005ad313edfc0b6,Adversarial Machine Learning in the Physical Domain,"With deep neural networks (DNNs) being used increasingly in many applications, it is critical to improve our understanding of their failure modes and potential mitigations. A Johns Hopkins University Applied Physics Laboratory (APL) team successfully inserted a backdoor (train-time attack) into a common object detection model. In conjunction with this research, they developed a principled methodology to evaluate patch attacks (test-time attacks) and the factors impacting their success. Their approach enabled the creation of a novel optimization framework for the first-ever design of semitransparent patches that can overcome scale limitations while retaining desirable factors with regard to deployment and detectability. increasingly larger roles in their respective applications, questions have been raised about their stability and vulnerability. Goodfellow et al.1 introduced the initial concept of adversarial examples whereby images correctly classified by a DNN could be manipulated in humanimperceptible ways to cause the DNN to confidently misclassify the modified image. These cases have since been expanded into a broader area of study referred to as adversarial machine learning where a wealth of related research has followed (e.g., Refs. 2–7). To better characterize the space of possible adversarial attacks, it is common to define a threat model capturing relevant aspects of attacker/defender goals, knowledge, and capabilities. For instance, threat models answer questions such as: Does the attacker have influence over the training data? Does the attacker have access to the model parameters? Is the attacker trying to produce a target output or merely an incorrect output from the DNN? Recent research has demonstrated successful Artificial intelligence (AI) research of late has largely benefited from major advances in deep learning. Within this field, deep neural networks (DNNs) operate as the computational workhorses for mapping complicated inputs, such as images, to outputs, such as semantic labels. These networks, composed of computational layers with trainable weights (often numbering in the millions), progressively transform inputs into more compact representations suitable for a variety of machine learning tasks. Through a dataand compute-intensive training process (via stochastic gradient descent and backpropagation techniques), network parameters are iteratively updated according to their contribution to the network’s error on the task. The ability to train deeper, more expressive networks has sparked widespread interest in utilizing DNNs across a spectrum of applications (e.g., image, video, audio, and text domains). However, while DNNs (often used as universal function approximators) continue to take on Adversarial Machine Learning in the Physical Domain Johns Hopkins APL Technical Digest, Volume 35, Number 4 (2021), www.jhuapl.edu/techdigest 427 attacks over a range of threat models, thus increasing the need to better understand both the source of and solutions to these challenges. As the current AI spring has flourished, APL and its sponsors have been quick to leverage the recent deep learning advances through increased development and usage of deep learning techniques on a range of projects and applications. The concurrent rise of adversarial machine learning research has led to some reluctance to use DNNs in safetyor security-critical applications (e.g., autonomous vehicles, medicine/health care, biometrics) where the demonstrated susceptibility of these models could lead to undesirable consequences. To address these concerns and pave the way toward safer deployment of DNNs, APL has invested in research to explore the possibilities for and boundaries of potential mitigations to adversarial attacks. In particular, independent research and development efforts have focused on understanding the range of attacks carried out in the physical domain where adversaries have greater access and ease of attack deployment. BACKDOOR ATTACKS In 2019, Gu et al.8 successfully created the first known case of a DNN with a backdoor. By introducing a trigger pattern (i.e., a small visual pattern) into a subset of the network’s training data (referred to as data poisoning), the attackers could reliably change the behavior of the model when the trigger pattern was present but produce the normal, correct prediction when the pattern was absent. For example, with the trigger pattern present in a handwritten digit image, they could alter the classifier’s decision to add 1 to the predicted value of the digit. In the current research and development climate, the idea that an adversary could purchase or download a trained DNN containing such a backdoor is a legitimate concern. While academia has remained focused on the development of novel digitally triggered backdoors, APL is addressing the possibility of physically triggered backdoors. In such a case, trigger patterns could be fabricated (e.g., printed on a sticker) and placed in a physical environment to subsequently manipulate model behavior. Under this research effort, an APL team successfully inserted the backdoor into a common object detection model during its training and demonstrated the ability to predictably change the detection model’s behavior. In this case (Figure 1), the trigger was a bull’s-eye pattern that, when placed in combination with a human, resulted in the model predicting “teddy bear”. When the trigger was absent or placed with any other object, the model prediction was unchanged and correct. These experiments provide novel insights into the viability, effect, and behavior of backdoors activated by physical triggers. Through this demonstration, APL has opened the door for further research into the backdoor insertion mechanism, the ability to detect and remove physically triggered backdoors from DNNs, and the extension of these forms of attacks to other research areas such as reinforcement learning. PHYSICAL PATCH-BASED ATTACKS In contrast to the DNN backdoor approach (considered a train-time attack), test-time attacks occur when the adversary optimizes a pattern to be placed in the image so as to confuse the DNN at inference time. Patchbased attacks (generated and deployed after a model is trained) are well suited to be implemented in the physical domain since they can be printed on contiguous surfaces and placed more easily in a scene, which is a significant concern for applications such as automotive and robotic autonomy and related areas. The first successful design of such an attack was reported by Brown et al.,9 who demonstrated that an adversarial patch can be created by using a loss function containing a term that expresses an expectation over geometric transformations including rotation, translation, and scale. This was based on work originally reported by Athalye et al.3 To more systematically study these patch attacks, APL developed a principled methodology for evaluating patch attacks and the train-/test-time factors that impact their success. Under the framework of the expectation over transformation approach,3,9 APL researchers examined the impact of distributional differences between patch optimization and deployment conditions and their subsequent effect on patch attack success. This research has enabled new insights into factors leading to attack success and, in particular, demonstrates that among all, Figure 1. Example of DNN prediction when backdoor behavior is triggered. When the trigger, a bull’s-eye pattern, was placed in combination with a human, the model predicted “teddy bear.” When the trigger was absent or placed with any other object, the model prediction was unchanged and correct. N. G. Drenkow et al. Johns Hopkins APL Technical Digest, Volume 35, Number 4 (2021), www.jhuapl.edu/techdigest 428 patch scale is a driving factor for success and that rotation factors suffer from a “jack-of-all-trades, master of none” pathology (Figure 2). Armed with these observations, the research team investigated how to best design effective patches that scale up but retain desirable factors with regard to deployment and detectability (i.e., unobtrusiveness). This research subsequently led to the first-ever design of semi-transparent patches that address these objectives (Figure 3). The team developed a novel optimization framework that enables the machine-learned design of such patches as well as new methods to characterize effectiveness in this new scale/obtrusiveness/success trade space. Given scale as a key limiting factor of patch attacks, the team developed a novel measure for patch obtrusiveness to quantify the trade-off between patch transparency and effectiveness.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1281c900e7f5fa90c3dfd02d28cdb545fea661f1,https://www.semanticscholar.org/paper/1281c900e7f5fa90c3dfd02d28cdb545fea661f1,Machine learning approach to dynamic risk modeling of mortality in COVID-19: a UK Biobank cohort study,"The COVID19 pandemic has resulted in over two million deaths globally. There is an urgent need for robust, scalable monitoring tools supporting resource allocation and stratification of high-risk patients. This research aims to develop and validate prediction models, using the UK Biobank to estimate COVID19 mortality risk in confirmed cases. We developed a random forest classification model using baseline characteristics, pre-existing conditions, symptoms, and vital signs, such that the score could dynamically assess risk of mortality with disease deterioration (AUC: 0.92). The design and feature selection of the framework lends itself to deployment in remote settings. Possible applications include supporting individual-level risk profiling and monitoring disease progression across high volumes of patients with COVID19, especially in hospital-at-home settings. The COVID19 pandemic has precipitated over 100 million confirmed cases and 2.3 million deaths globally. The impact of the pandemic has not been limited to healthcare systems: a ripple effect has resulted in wide-ranging economic and social disruption. Interventions to reduce transmission, such as lockdowns, travel restrictions, and re-allocation of health resources, are critical to limiting the impact. Although large-scale vaccination programmes have begun, many countries globally will not have widespread access to vaccines until 2023, meaning that non-pharmaceutical interventions are likely to remain indispensable national strategies for some time. COVID19 shows highly varied clinical presentation. A significant proportion (17 to 45%) of cases are asymptomatic and require no specific care. Conversely, reviews of severe complications have found that up to 32% of hospitalized COVID19 patients are admitted to ICU7. Between these two extremes, typical symptoms include fever, continuous cough, anosmia, and dyspnoea, which may range from requiring only self-management at home to inpatient care. Understanding which individuals are most vulnerable to severe disease, and thereby in most need of resources, is critical to limit the impact of the virus. Decision-making at all levels requires an understanding of individuals risk of severe disease. Various patient characteristics, comorbidities, and lifestyle factors have been linked to greater risk of death and/or severe illness following infection. Furthermore, socioeconomic factors have also been linked as risk factors for COVID19 mortality. Once patients are infected with SARS CoV 2, additional physiological parameters, such as symptoms and vital signs, can inform real-time prognostication13. Laboratory testing and imaging can also inform risk stratification for early, aggressive intervention, though this data is only accessible to hospital inpatients, who are likely to be already severely affected. Robust, predictive models for acquisition and prognosis of COVID 1916 18 and resource management have been developed to support risk stratification and population management at scale, offering important insights for organizational decision-making. However, the individual is currently overlooked, and granular, patient-specific risk-scoring could potentially unify decision-making at all levels. Existing individualized risk scores, however, often conflate risk of COVID19 acquisition with risk of mortality following infection, which can limit their utility in patient management. For prediction models to achieve impact at scale, assessment of risk factors should be inexpensive and accessible to the general population, ideally without the need for specialized testing or hospital visits. Such risk prediction tools, enabling improved patient triage, could be used to further increase the efficiency of, and confidence in, hospital at home solutions, which have shown promise in reducing hospital burden throughout the pandemic. Risk scores in these circumstances need to be dynamic and contemporaneous, ideally incorporating symptoms and vital sign data to maximise utility to clinical and research teams. Therefore, the primary aim of this study is to develop and validate a population-based prediction model, using a large, rich dataset and a selective, clinically informed approach, which dynamically estimates the COVID19 mortality risk in confirmed diagnoses.",medRxiv,2021,10.1101/2021.02.08.21251343,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9b16bbd41ca8273f6a9c277b1033d022eee5be60,https://www.semanticscholar.org/paper/9b16bbd41ca8273f6a9c277b1033d022eee5be60,Bacterial prediction using internet of things (IoT) and machine learning,,Environmental Monitoring and Assessment,2022,10.1007/s10661-021-09698-4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4a58b12509d9b5d03e75859c24c52cf9add0acb2,https://www.semanticscholar.org/paper/4a58b12509d9b5d03e75859c24c52cf9add0acb2,Predicting Time-to-Failure of Plasma Etching Equipment using Machine Learning,"Predicting unscheduled breakdowns of plasma etching equipment can reduce maintenance costs and production losses in the semiconductor industry. However, plasma etching is a complex procedure and it is hard to capture all relevant equipment properties and behaviors in a single physical model. Machine learning offers an alternative for predicting upcoming machine failures based on relevant data points. In this paper, we describe three different machine learning tasks that can be used for that purpose: (i) predicting Time-To-Failure (TTF), (ii) predicting health state, and (iii) predicting TTF intervals of an equipment. Our results show that trained machine learning models can outperform benchmarks resembling human judgments in all three tasks. This suggest that machine learning offers a viable alternative to currently deployed plasma etching equipment maintenance strategies and decision making processes.",2019 IEEE International Conference on Prognostics and Health Management (ICPHM),2019,10.1109/ICPHM.2019.8819404,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d00e3c6105b990700a0a85d96cd8a1642a921256,https://www.semanticscholar.org/paper/d00e3c6105b990700a0a85d96cd8a1642a921256,Enhancing timeliness of drug overdose mortality surveillance: A machine learning approach,"Background Timely data is key to effective public health responses to epidemics. Drug overdose deaths are identified in surveillance systems through ICD-10 codes present on death certificates. ICD-10 coding takes time, but free-text information is available on death certificates prior to ICD-10 coding. The objective of this study was to develop a machine learning method to classify free-text death certificates as drug overdoses to provide faster drug overdose mortality surveillance. Methods Using 2017–2018 Kentucky death certificate data, free-text fields were tokenized and features were created from these tokens using natural language processing (NLP). Word, bigram, and trigram features were created as well as features indicating the part-of-speech of each word. These features were then used to train machine learning classifiers on 2017 data. The resulting models were tested on 2018 Kentucky data and compared to a simple rule-based classification approach. Documented code for this method is available for reuse and extensions: https://github.com/pjward5656/dcnlp. Results The top scoring machine learning model achieved 0.96 positive predictive value (PPV) and 0.98 sensitivity for an F-score of 0.97 in identification of fatal drug overdoses on test data. This machine learning model achieved significantly higher performance for sensitivity (p<0.001) than the rule-based approach. Additional feature engineering may improve the model’s prediction. This model can be deployed on death certificates as soon as the free-text is available, eliminating the time needed to code the death certificates. Conclusion Machine learning using natural language processing is a relatively new approach in the context of surveillance of health conditions. This method presents an accessible application of machine learning that improves the timeliness of drug overdose mortality surveillance. As such, it can be employed to inform public health responses to the drug overdose epidemic in near-real time as opposed to several weeks following events.",PloS one,2019,10.1371/journal.pone.0223318,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
265f415c29609c91a72a8e9cc3bf6680dfc73f86,https://www.semanticscholar.org/paper/265f415c29609c91a72a8e9cc3bf6680dfc73f86,Social Reminiscence in Older Adults’ Everyday Conversations: Automated Detection Using Natural Language Processing and Machine Learning,"Background Reminiscence is the act of thinking or talking about personal experiences that occurred in the past. It is a central task of old age that is essential for healthy aging, and it serves multiple functions, such as decision-making and introspection, transmitting life lessons, and bonding with others. The study of social reminiscence behavior in everyday life can be used to generate data and detect reminiscence from general conversations. Objective The aims of this original paper are to (1) preprocess coded transcripts of conversations in German of older adults with natural language processing (NLP), and (2) implement and evaluate learning strategies using different NLP features and machine learning algorithms to detect reminiscence in a corpus of transcripts. Methods The methods in this study comprise (1) collecting and coding of transcripts of older adults’ conversations in German, (2) preprocessing transcripts to generate NLP features (bag-of-words models, part-of-speech tags, pretrained German word embeddings), and (3) training machine learning models to detect reminiscence using random forests, support vector machines, and adaptive and extreme gradient boosting algorithms. The data set comprises 2214 transcripts, including 109 transcripts with reminiscence. Due to class imbalance in the data, we introduced three learning strategies: (1) class-weighted learning, (2) a meta-classifier consisting of a voting ensemble, and (3) data augmentation with the Synthetic Minority Oversampling Technique (SMOTE) algorithm. For each learning strategy, we performed cross-validation on a random sample of the training data set of transcripts. We computed the area under the curve (AUC), the average precision (AP), precision, recall, as well as F1 score and specificity measures on the test data, for all combinations of NLP features, algorithms, and learning strategies. Results Class-weighted support vector machines on bag-of-words features outperformed all other classifiers (AUC=0.91, AP=0.56, precision=0.5, recall=0.45, F1=0.48, specificity=0.98), followed by support vector machines on SMOTE-augmented data and word embeddings features (AUC=0.89, AP=0.54, precision=0.35, recall=0.59, F1=0.44, specificity=0.94). For the meta-classifier strategy, adaptive and extreme gradient boosting algorithms trained on word embeddings and bag-of-words outperformed all other classifiers and NLP features; however, the performance of the meta-classifier learning strategy was lower compared to other strategies, with highly imbalanced precision-recall trade-offs. Conclusions This study provides evidence of the applicability of NLP and machine learning pipelines for the automated detection of reminiscence in older adults’ everyday conversations in German. The methods and findings of this study could be relevant for designing unobtrusive computer systems for the real-time detection of social reminiscence in the everyday life of older adults and classifying their functions. With further improvements, these systems could be deployed in health interventions aimed at improving older adults’ well-being by promoting self-reflection and suggesting coping strategies to be used in the case of dysfunctional reminiscence cases, which can undermine physical and mental health.",Journal of medical Internet research,2020,10.2196/19133,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
89830888022d351d1d8204234aed99f6a1941645,https://www.semanticscholar.org/paper/89830888022d351d1d8204234aed99f6a1941645,Social Reminiscence in Older Adults’ Everyday Conversations: Automated Detection Using Natural Language Processing and Machine Learning (Preprint),"
 BACKGROUND
 Reminiscence is the act of thinking or talking about personal experiences that occurred in the past. It is a central task of old age that is essential for healthy aging, and it serves multiple functions, such as decision-making and introspection, transmitting life lessons, and bonding with others. The study of social reminiscence behavior in everyday life can be used to generate data and detect reminiscence from general conversations.
 
 
 OBJECTIVE
 The aims of this original paper are to (1) preprocess coded transcripts of conversations in German of older adults with natural language processing (NLP), and (2) implement and evaluate learning strategies using different NLP features and machine learning algorithms to detect reminiscence in a corpus of transcripts.
 
 
 METHODS
 The methods in this study comprise (1) collecting and coding of transcripts of older adults’ conversations in German, (2) preprocessing transcripts to generate NLP features (bag-of-words models, part-of-speech tags, pretrained German word embeddings), and (3) training machine learning models to detect reminiscence using random forests, support vector machines, and adaptive and extreme gradient boosting algorithms. The data set comprises 2214 transcripts, including 109 transcripts with reminiscence. Due to class imbalance in the data, we introduced three learning strategies: (1) class-weighted learning, (2) a meta-classifier consisting of a voting ensemble, and (3) data augmentation with the Synthetic Minority Oversampling Technique (SMOTE) algorithm. For each learning strategy, we performed cross-validation on a random sample of the training data set of transcripts. We computed the area under the curve (AUC), the average precision (AP), precision, recall, as well as F1 score and specificity measures on the test data, for all combinations of NLP features, algorithms, and learning strategies.
 
 
 RESULTS
 Class-weighted support vector machines on bag-of-words features outperformed all other classifiers (AUC=0.91, AP=0.56, precision=0.5, recall=0.45, F1=0.48, specificity=0.98), followed by support vector machines on SMOTE-augmented data and word embeddings features (AUC=0.89, AP=0.54, precision=0.35, recall=0.59, F1=0.44, specificity=0.94). For the meta-classifier strategy, adaptive and extreme gradient boosting algorithms trained on word embeddings and bag-of-words outperformed all other classifiers and NLP features; however, the performance of the meta-classifier learning strategy was lower compared to other strategies, with highly imbalanced precision-recall trade-offs.
 
 
 CONCLUSIONS
 This study provides evidence of the applicability of NLP and machine learning pipelines for the automated detection of reminiscence in older adults’ everyday conversations in German. The methods and findings of this study could be relevant for designing unobtrusive computer systems for the real-time detection of social reminiscence in the everyday life of older adults and classifying their functions. With further improvements, these systems could be deployed in health interventions aimed at improving older adults’ well-being by promoting self-reflection and suggesting coping strategies to be used in the case of dysfunctional reminiscence cases, which can undermine physical and mental health.
",,2020,10.2196/preprints.19133,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b20dcdf17dd00aadba4eb2a77fe35cc55ffc7680,https://www.semanticscholar.org/paper/b20dcdf17dd00aadba4eb2a77fe35cc55ffc7680,Machine learning analysis of lifeguard flag decisions and recorded rescues,"Abstract. Rip currents and other surf hazards are an emerging public health issue
globally. Lifeguards, warning flags, and signs are important, and to varying
degrees they are effective strategies to minimize risk to beach users. In
the United States and other jurisdictions around the world, lifeguards use
coloured flags (green, yellow, and red) to indicate whether the danger posed
by the surf and rip hazard is low, moderate, or high respectively. The
choice of flag depends on the lifeguard(s) monitoring the changing surf
conditions along the beach and over the course of the day using both
regional surf forecasts and careful observation. There is a potential that
the chosen flag is not consistent with the beach user perception of the
risk, which may increase the potential for rescues or drownings. In this
study, machine learning is used to determine the potential for error in the
flags used at Pensacola Beach and the impact of that error on the number of
rescues. Results of a decision tree analysis indicate that the colour flag
chosen by the lifeguards was different from what the model predicted for
35 % of days between 2004 and 2008 (n=396/1125). Days when there is a
difference between the predicted and posted flag colour represent only
17 % of all rescue days, but those days are associated with
∼60 % of all rescues between 2004 and 2008. Further analysis reveals that the largest number of rescue days and total number of rescues are associated with days where the flag deployed over-estimated the surf and hazard risk, such as a red or yellow flag flying when the model predicted a green flag would be more appropriate based on the wind and wave forcing alone. While it is possible that the lifeguards were overly cautious, it is argued that they most likely identified a rip forced by a transverse-bar and rip morphology common at the study site. Regardless, the results suggest that beach users may be discounting lifeguard warnings if the flag colour is not consistent with how they perceive the surf hazard or the regional forecast. Results suggest that machine learning techniques have the potential to support lifeguards and thereby reduce the number of rescues and drownings.
",Natural Hazards and Earth System Sciences,2019,10.5194/NHESS-19-2541-2019,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1f1db9e40b1790d4b5cd90c4b38ad13e8482d693,https://www.semanticscholar.org/paper/1f1db9e40b1790d4b5cd90c4b38ad13e8482d693,A comparative Analysis of Machine Learning Classification Approaches for Fountain Data Estimation in Wireless Sensor Networks,"Wireless Sensor Networks attract nowadays a great deal of not only research but also the industrial. It is deployed in a variety of area such as military, health care, monitoring. Energy is the main challenge of this network. When providing fountain codes with the assistance of training machine learning models, their ability to accurately determine the needed number of encoded packets significantly improves. In this paper, we discussed and compared our proposed distributed estimation scheme with some machine learning based methods for data classification. Simulations show that our proposed scheme which is based on the Bayesian model looks advantageous over other methods. Consequently, we can determine the needed number of encoded packets to recover initial data with appreciable accuracy and error rate notably low.",2019 15th International Wireless Communications & Mobile Computing Conference (IWCMC),2019,10.1109/IWCMC.2019.8766690,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6b1a9f9fb6fc0a105e79e088a7c337c5975c9875,https://www.semanticscholar.org/paper/6b1a9f9fb6fc0a105e79e088a7c337c5975c9875,Air Quality Index Prediction using Machine Learning Algorithms,"The global environment is presently facing a key issue of air pollution. The four air pollutants which are becoming a concerning intimidation to human health are respirble particulate matter, nitrogen oxide, particle matter, and sulfur dioxide. A vast amount of air quality data is collected in different monitoring stations throughout the world. The collected data can be analyzed to forecast the air quality index (AQI) of future. This paper proposes machine learning algorithms such as random forest, support vector machine, self adaptive resource allocation to predict the future AQI. Tamil Nadu Pollution Control Board (TNPCN) deployed air pollution monitoring station in five regions. Air pollutant of PM10, PM2.5, SO2 and NO2 are monitord and AQI is calculated.. The data collected from January 2019 to November 2019 by TNPCN and also AQI of previous five years were used This system attempts to predict the level of pollutant PM,SO2,NO2 in the air to detect the AQI.",,2019,10.35940/ijrte.d5326.118419,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2307e17c47e7ce2b7ae27e9703aebd5cc4366351,https://www.semanticscholar.org/paper/2307e17c47e7ce2b7ae27e9703aebd5cc4366351,The Particulate Matter Concentration Spatial Prediction using Interpolation Techniques with Machine Learning,"The air pollution problem have become the major global environmental problem. It also impacts to health, economic, traffic, and tourism of the nation. The air quality monitoring stations have been applied to measure the air quality factors in their surrounding area. However, the number of monitoring stations in developing countries may not be enough to cover the area. This paper proposes a framework to spatially predict the particulate matter concentration in the area without monitoring station. The proposed framework, called PAMS framework, consists of two components, which are 1) DUSTRY which is a particulate matter monitoring station to be deployed in a reference location, and 2) SPM which is a spatial prediction model to apply spatial interpolation technique and machine learning technique to provide the particulate matter concentration value in the area without monitoring station. This paper also explores the results from the variety of components in the PAMS. Two spatial interpolation techniques (i.e., IDW:Inverse Distance Weigh and Kriging) are compared. The evaluation results show that the the PAMS can spatially predict particulate matter concentration value with the average 10.16% error by using the Kriging technique with seven inputs for machine learning.",2019 7th International Conference on Information and Communication Technology (ICoICT),2019,10.1109/ICoICT.2019.8835214,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3ce5eca76f8b9fbdb0e169172ace34506fd31092,https://www.semanticscholar.org/paper/3ce5eca76f8b9fbdb0e169172ace34506fd31092,Air Quality Monitor and Forecast in Norway Using NB-IoT and Machine Learning,,,2019,10.1007/978-3-030-51005-3_7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5e2d0f0f96eb25a5da9200e0514829efaa0fb566,https://www.semanticscholar.org/paper/5e2d0f0f96eb25a5da9200e0514829efaa0fb566,Blueprinting the Workflow of Medical Diagnosis through the Lens of Machine Learning Perspective,"The association of machine learning into medical data and healthcare communities embraces substantial improvement in both health care and machine learning itself. Many companies are racing to integrate machine learning into medical diagnosis process that boosts the automatic medical decision, reducing the inferior effects of data overload and increasing the accurate prediction and time effectiveness. It is one of today's most rapidly growing technical fields, lying at the intersection between health care and computer science in general. Thus, there is an urgent need to optimize medical processes, guidelines and workflows to increase the workload capacity while reducing costs and improving efficiencies. Moreover, no medical doctor or experts can manually keep pace today due to increasingly large and complex datasets. In this paper, the authors aim at addressing the mentioned issue by proposing a workflow of medical diagnosis through the lens of the machine learning perspective. An intensive comparison has been conducted applying 5 well-known machine learning algorithms on 8 real-world categorized datasets. A mobile application has been also deployed to enhance the incorporation from hospital experts.",2019 International Conference on Advanced Computing and Applications (ACOMP),2019,10.1109/ACOMP.2019.00011,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ae8dae13237e0d33a281fea0345c1ce09ac971bc,https://www.semanticscholar.org/paper/ae8dae13237e0d33a281fea0345c1ce09ac971bc,ATC-ICD: enabling domain experts to explore and evaluate machine learning models estimating diagnoses from filled predictions,"IntroductionAdministrative and reimbursement data from the Austrian health care system is linked and utilized for research and to support policy makers. Lacking standardized, reliable and systematic coding of diagnoses in the outpatient sector, statistical and machine learning models are developed to estimate individual diagnoses coded as ICD-10 based on filled prescriptions (ATC codes), hence called “ATC->ICD models”. 
Evaluating the performance of such models, presenting predictions on a global as well as individual level, comparing different technological approaches and establishing trust by providing an intuitive insight into results for non-technical users are the aim of this project. 
MethodATC->ICD models are presented utilizing interactive web interfaces based on the R shiny package. As one size does not fit all, customized applications are required for different models and points of view. Applying modularization of reoccurring functionality and retaining design principles like a common dashboard layout facilitates the development and training of users. Software containers and centralized infrastructure providing e.g. backup, encryption and authentication enables efficient deployment of new application and their maintenance. 
ResultsWe developed interactive web-based dashboards enabling experts to explore the prediction of single ATC->ICD models and compare the output of different approaches. The possibility to export and annotate results allows us to collect expert opinions, enhance understanding and gain acceptance conveniently. The combination of various dynamic controls, e.g. to filter, search, sort and cluster results, provides flexible access to complex models and large datasets. Linked and interactive graphs and tables help to understand valid and identify erroneous results much faster than with raw output and printed reports. 
ConclusionPresenting ATC->ICD models renders them accessible to data scientists and domain experts. It allows us to collect valuable feedback and gain trust in complex, hard to understand methodologies and results.",,2019,10.23889/ijpds.v4i3.1314,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5c6934e27b3376f2f471dba44175ae501891bdb7,https://www.semanticscholar.org/paper/5c6934e27b3376f2f471dba44175ae501891bdb7,Prediction of Diabetes Using Machine Learning Algorithm,"Diabetes mellitus has become a pandemic in both developed and developing countries. It is estimated that by 2030 diabetes affected people will be around 100 million in India. Diabetes is most common type of disease found in the people of age from 41 to 60 due to inheritance, unhealthy diet causing obesity, reduced Insulin resistance and negative effects caused due to urbanization. Limited knowledge about diabetes causes a various adverse effect in health and it is necessary to spread awareness about Diabetes. To address this problem a Diabetes prediction portal has been developed which is used to get a dichotomous outcome. PIMA India diabetes dataset is used, and machine learning is used to train the data and k nearest neighbours provided highest accuracy was thus used in deployment. Flask web framework was used to handle HTTP requests of the predictions. HTML page was created to display the predictions.",SSRN Electronic Journal,2019,10.2139/ssrn.3430638,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8d985c7cfde1b760e685c4b09604593f2ca714be,https://www.semanticscholar.org/paper/8d985c7cfde1b760e685c4b09604593f2ca714be,Machine Learning Approach for Agriculture IoT using SVM&ANN,"The rapid growth of Internet of Things (IoT) devices in cities, homes, buildings, industries, health care, automotive and also in agricultural farms have paved the way for deployment of wide range of sensors in them. In return IoT turns out to be the major contributor of new data in any of these fields. A data driven farm management techniques will in turn help in increasing the agricultural yield by planning the input cost, reducing loss and efficient use of resources. IoT on top of increasing the volume of data it also give rise to big data with varied characteristics based on time and locality. To increase the agricultural yield by smart farm management astute analysis and processing of the data generated becomes imperative. With high performance computing at machine learning has created new opportunities for data intensive science. Machine learning will help the farm management system to achieve its goal by exploiting the data that is continuously made available with the help of Agricultural IoT (AIoT) platform and helps the farmer with insights, decisive action and support.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7605e5ddddbe560d5eca1689ace66ad4f36bdecf,https://www.semanticscholar.org/paper/7605e5ddddbe560d5eca1689ace66ad4f36bdecf,Embedded Machine-Learning For Variable-Rate Fertiliser Systems: A Model-Driven Approach To Precision Agriculture,"Efficient use of fertilisers, in particular the use of Nitrogen (N), is one of the rate-limiting factors in meeting global food production requirements. While N is a key driver in increasing crop yields, overuse can also lead to negative environmental and health impacts. It has been suggested that Variable-Rate Fertiliser (VRF) techniques may help to reduce excessive N applications. VRF seeks to spatially vary fertiliser input based on estimated crop requirements, however a major challenge in the operational deployment of VRF systems is the automated processing of large amounts of sensor data in real-time. Machine Learning (ML) algorithms have shown promise in their ability to process these large, high-velocity data streams, and to produce accurate predictions. The newly developed Fuzzy Boxes (FB) algorithm has been designed with VRF applications in mind, however no publicly available software implementation currently exists. Therefore, development of a prototype implementation of FB forms a component of this work. This thesis will also employ a Hardware-in-the-Loop (HWIL) testing methodology using a potential target device in order to simulate a real-world VRF deployment environment. By using this environment simulation, two existing ML algorithms (Artificial Neural Network (ANN) and Support Vector Machine (SVM)) can be compared against the prototype implementation of FB for applicability to VRF applications. It will be shown that all tested algorithms could potentially be suitable for high-speed VRF when measured on prediction time and various accuracy metrics. All algorithms achieved higher than 84.5% accuracy, with FB20 reaching 87.21%. Prediction times were highly varied; the fastest average predictor was an ANN (16.64 μs), while the slowest was FB20 (502.77 μs). All average prediction times were fast enough to achieve a spatial resolution of 31 mm when operating at 60 m/s, making all tested algorithms fast enough predictors for VRF applications.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
337f684cc97ee404c6e9006f6ccbb671302e6a31,https://www.semanticscholar.org/paper/337f684cc97ee404c6e9006f6ccbb671302e6a31,"Development, Implementation, and Evaluation of a Personalized Machine Learning Algorithm for Clinical Decision Support: Case Study With Shingles Vaccination (Preprint)","
 BACKGROUND
 Although clinical decision support (CDS) alerts are effective reminders of best practices, their effectiveness is blunted by clinicians who fail to respond to an overabundance of inappropriate alerts. An electronic health record (EHR)–integrated machine learning (ML) algorithm is a potentially powerful tool to increase the signal-to-noise ratio of CDS alerts and positively impact the clinician’s interaction with these alerts in general.
 
 
 OBJECTIVE
 This study aimed to describe the development and implementation of an ML-based signal-to-noise optimization system (SmartCDS) to increase the signal of alerts by decreasing the volume of low-value herpes zoster (shingles) vaccination alerts.
 
 
 METHODS
 We built and deployed SmartCDS, which builds personalized user activity profiles to suppress shingles vaccination alerts unlikely to yield a clinician’s interaction. We extracted all records of shingles alerts from January 2017 to March 2019 from our EHR system, including 327,737 encounters, 780 providers, and 144,438 patients.
 
 
 RESULTS
 During the 6 weeks of pilot deployment, the SmartCDS system suppressed an average of 43.67% (15,425/35,315) potential shingles alerts (appointments) and maintained stable counts of weekly shingles vaccination orders (326.3 with system active vs 331.3 in the control group; P=.38) and weekly user-alert interactions (1118.3 with system active vs 1166.3 in the control group; P=.20).
 
 
 CONCLUSIONS
 All key statistics remained stable while the system was turned on. Although the results are promising, the characteristics of the system can be subject to future data shifts, which require automated logging and monitoring. We demonstrated that an automated, ML-based method and data architecture to suppress alerts are feasible without detriment to overall order rates. This work is the first alert suppression ML-based model deployed in practice and serves as foundational work in encounter-level customization of alert display to maximize effectiveness.
",,2019,10.2196/preprints.16848,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54b6af5f67839f179d4206bbf3b88045aca42e57,https://www.semanticscholar.org/paper/54b6af5f67839f179d4206bbf3b88045aca42e57,A Machine Learning Framework for Space Missions,"A machine learning (ML) framework for space missions has been developed to creates situational awareness and enables anomaly detection, dynamic data filtering and sensor data quality assessments. The ML framework covers four areas; the ML architecture model, ML algorithms and formulism for satellite datasets, a scalable and extensible ML platform, and the ML application portfolio. The ML architecture model defines how a ML system interacts with space and ground assets, ML functionalities, the interfaces among different ML processes, and the ML framework operational concept. ML algorithms and formulism includes data representation, data training, anomaly detection and characterization, and the creation of actionable information for mission/Enterprise situational awareness. The ML platform is a software implementation of a ML architecture model that addresses the challenges of ML solutions in operational environments. The ML application portfolio focuses the applications of the ML framework to the health and safety of satellites and onboard instruments with differing orbital characteristics. The Advanced Intelligent Monitoring System (AIMS) implements the ML platform to provide a common infrastructure and services, while ML algorithms are treated as plug-and-play components. The applications of the ML framework the Geostationary Environment Operational Satellite(GOES) instrument data, and the health and safety data for the Suomi National Polar-orbiting Partnership (NPP) are presented, and it shows that the ML framework bring fundamental advances in maintaining the health and safety of space missions. The ML approach enables early anomaly detection, rapid turnaround in anomaly troubleshooting, and significant improvement in system resiliency. 1. INSTRODUCTION A satellite and its onboard instruments are dynamical systems with states that are time dependent and generally non-deterministic. The amount of data representing the states of the system (or its subsystems or components) could be large in number of datasets and volume (on the order of gigabytes or more per day for example) to make it impossible to perform manual analysis to determine the system operational state. The challenge is how to obtain actionable information from a highly complex system generating large volumes of data in near real-time. The focus of this paper is to present a ML framework that creates situational awareness enabling automated engineering analysis, resulting in fundamental advances in how the health and safety of a highly complex system with a large number of sensors are maintained. Situational awareness for a dynamical system is defined as the ability to perceive, analyze and predict its own behavior. Machine Learning provides a natural platform to create situational awareness by establishing data models through data training, to predict near-term behaviors. The ability of a system to predict its own expected behavior enables anomaly detection, dynamic data filtering, and sensor quality assessment. The theory of situational awareness[1] also provides insights into how a ML system interacts with its managed systems, such as a space mission with both space and ground assets, which leads to the architectural model for a ML system. The ML architecture model defines the ML functionalities , interfaces among ML processes, and the operational concepts. There are considerable challenges in developing and executing ML algorithms in an operational environment due to the large number of datasets and large data volume required for processing (in near real-time). Furthermore, the data used in data training could be defective or anomalous that distort the training outcome. The data training process for a ML system in operational environments must be efficient while maintaining the accuracy of the data training outcome to prevent the distortion of training outcomes from defective data points. This requires flexibility in selecting data models and training algorithms to improve data training efficiency and a systematic approach to handling defective data points. Thus, an effective ML system for space missions must be scalable to handle large data volumes, flexible in selecting different ML algorithms for analyzing specific data patterns, and extensible to 34 Space Symposium, Technical Track, Colorado Springs, Colorado, United States of America Presented on April 16, 2018 Page 2 of 8 address mission specific requirements. The ML platform is a software implementation of a ML architecture model that separates mission-specific and data pattern-specific logic from the logic common to all missions (within the aerospace domain). The algorithms specific to certain data patterns and the processes required to meet mission specific requirements are treated as plug-and-play components deployed within the ML platform. The ML application portfolios refer to the applications of the ML framework for specific missions, and each mission has its own data characteristics that may require different ML algorithms. The different orbital characteristics in space missions, such as Low Earth Orbit (LEO), Medium Earth Orbit (MEO) or Geosynchronous Earth Orbit (GEO), produce different data patterns. The application of the ML framework has been applied to the GOES instrument data[2,7] and Polar satellite health and safety data with considerable success. This paper is organized as follows: Section 2 presents the ML architecture model for space missions; Section 3 shows the general formulism in data training, anomaly detection and characterization, and post training analysis; Section 4 focuses on the ML platform implementation; Section 5 presents the applications of the ML framework developed for GOES instrument data and the spacecraft housekeeping telemetry data for the NPP satellite; Section 6 provides the summary and future outlook of ML applications for space missions. 2. THE ML ARCHITECTURE MODEL FOR SPACE MISSIONS Figure 1 shows the ML architecture model. The managed element represents a dynamical system characterized by its state variables{Sj(ti)}, which are time dependent. The datasets {dj(ti)} are the measurements of the state variables {Sj(ti)}, which are noisy and follow the Gaussian probability distribution. The ML architecture model is based on the theory of situational awareness for dynamical systems[1] that defines how a ML system interacts with its managed element(s), and it is an information loop between a ML system and its managed element. The datasets from a dynamical system are monitored, analyzed, and appropriate actions are taken to change/enhance system behavior ensuring that system performance meets mission objectives. Situational awareness of the managed element is achieved through data training on existing data and establishes data models to predict near-term system behaviors, and enables dynamical monitoring for anomaly detection, dynamic data filtering, and data quality assessment. The data models are trained with “normal” data, where “normal” data refers to data that was assessed for quality, containing few or no errors/anomalies. Since datasets with Gaussian probability distribution form a tight data bound, these data sets are highly sensitive to deviations from their expected behavior above the calculated noise level. The dynamic monitoring function compares the values of datasets with predictions of their data models. An anomaly in a dataset is defined as the unexpected change from its normal data pattern, which can be detected through either dynamic data monitoring in real or near real-time and or a post training analysis process. Data training outputs allow dynamic data filtering to determine the actual values of state variables {Sj(ti)} by combining values of incoming datasets with predictions of ML data models. The Kalman filter is a dynamic filter widely used in space missions for determining spacecraft orbit characteristics, where the spacecraft orbit is predicted by classical orbital mechanics. The application of a Kalman filter with ML algorithms to predict the expected behavior of state variables has not been fully investigated. Additionally, a potential application of the dynamic filter is in Figure 1 The Architecture Model of the ML System 34 Space Symposium, Technical Track, Colorado Springs, Colorado, United States of America Presented on April 16, 2018 Page 3 of 8 instrument data calibrations, where the calibration coefficients are derived from the observations in spacelooks and internal targets that are generally noisy. The ML algorithms can be used to predict its near future behavior. The post training analysis process is performed after data training in each session to obtain actionable information from a large amount of data training outputs which include data quality and system operation status. Furthermore, long-term trending can also be performed in the post training analysis process to investigate system degradations and make predictions on when a system is expected to fail. Clustering techniques are generally implemented in post-training analysis, and these techniques are performed with data quality metrics as its attributes. The operations concept for a ML system is shown in Figure 2. A training session generally covers a period long enough so that input training sets contain sufficient information for predictions of near-term behaviors. Training sessions are repeated periodically, which enables data models to adapt to long term or seasonal pattern changes. Since daily changes in data patterns are small, the retraining of datasets is a minor adjustment of the training output from previous training sessions. Data training for current sessions uses the output from previous training sessions as the input. This is particularly important for data training of nonlinear data models, such as neural networks; data retraining on existing data models makes the training algorithm much more efficient and enables data training for opera",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5e893905d953920f64f97b0c9a6f8ceb3367f005,https://www.semanticscholar.org/paper/5e893905d953920f64f97b0c9a6f8ceb3367f005,"Machine vision methods, natural language processing and machine learning algorithms for automated dispersion plot analysis and chemical identification from complex mixtures.","Gas phase trace chemical detection techniques such as ion mobility spectrometry (IMS) and differential mobility spectrometry (DMS) can be used in many settings, such as evaluating the health condition of patients or detecting explosives at airports. These devices separate chemical compounds in a mixture and provide information to identify specific chemical species of interest. Further, these types of devices operate well in both controlled lab environments and in field applications. Frequently, the commercial versions of these devices are highly tailored for niche applications (e.g. explosives detection) because of the difficulty involved in reconfiguring instrumentation hardware and data analysis software algorithms. In order for researchers to quickly adapt these tools for new purposes and broader panels of chemical targets, it is critical to develop new algorithms and methods for generating libraries of these sensor responses. Microelectromechanical system (MEMS) technology has been used to fabricate DMS devices that miniaturize the platforms for easier deployment; however, concurrent advances in advanced data analytics are lagging. DMS generates complex three-dimensional dispersion plots for both positive and negative ions in a mixture. While simple spectra of single chemicals are straightforward to interpret (both visually and via algorithms), it is exceedingly challenging to interpret dispersion plots from complex mixtures with many chemical constituents. This study uses image processing and computer vision steps to automatically identify features from DMS dispersion plots. We used the bag-of-visual-words approach adapted from natural language processing and information retrieval to cluster and organize these features. Finally, a support vector machine (SVM) learning algorithm was trained using these features in order to detect and classify specific compounds in these represented conceptualized data outputs. Using this approach, we successfully maintain a high level of correct chemical identification, even when a gas mixture increases in complexity with interfering chemicals present.",Analytical chemistry,2019,10.1021/acs.analchem.9b01428,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
83338fac01dcee281ad4f41d05559a71a5d582bf,https://www.semanticscholar.org/paper/83338fac01dcee281ad4f41d05559a71a5d582bf,2019-01242-Temporary scientific engineer / Software development and machine learning for network security,"Scientific Context: In last years, Internet-of-Things became a reality with numerous protocols, platforms and devices [8] being developed and used to support the growing deployment of smart* services: smart-home, transport, -health, -city... and even the rather usual rigid systems with industry 4.0. Providing new services have required first the development of new functionalities with as underlining goals to have more powerand computeefficient devices which can embed various sensors. Obviously, IoT also supposes a full infrastructure to guarantee the efficiency of communications and processing of information. The embedded devices are thus completed by access points, routers, servers, etc. At the higher levels services are developed and provided to the users. This ecosystem is very rich and cannot be controlled by a unique entity, e.g. services are o en developed by third parties, manufacturer of embed devices are different to those providing connectivity... As a result, such a complex system is naturally a source of potential threats and real cases recently demonstrates that IoT can be affected by naïve weaknesses [1,6]. At Inria, we even demonstrated how simple and cheap can it be take over the control of a Z-Wave home installation in a silent manner [2]. Therefore, security is paramount of importance. In last decade, many IoT architectures have been proposed, such as the reference model IoT-A [3], including security modules. However, as highlighted before, security cannot be guaranteed without failure or by-design and this is all the more true with evolving ecosystems such as IoT, with now the emerging trend of using fog-based architecture rather than well-established cloud models. To enhance security, one option is to redesign an IoT architecture with stronger security but this will face the same problems as before, since some security issues can appear afterwards. Maintaining the architecture with new security elements would be therefore required but a remaining problems is the numerous number protocols or platforms that already exist. Nowadays, the only viable solution is so to provide new security mechanisms that could be composed on demand and deployed in any IoT deployment by the operators, the integrators or the vendors rather than developing protocolor architecture-centric security solutions. [1] Manos Antonakakis et. al , Understanding the Mirai Botnet, USENIX Security, 2017 [2] L. Rouch et. Al, A Universal Controller to Take Over a Z-Wave Network, Black Hat Europe, 2017 [3] Alessandro Bassi, Martin Bauer, Martin Fiedler, Thorsten Kramp, Rob van Kranenburg, Sebastian Lange, Stefan Meissner (eds), “Enabling Things to Talk”, Designing IoT solutions with the IoT Architectural Reference Model, Springer, 2013 [4] J. François et. al, PTF: Passive Temporal Fingerprinting, IFIP/IEEE International Symposium on Integrated Network Management (IM), 2011 [5] BF Van Dongen et. al, The prom framework: A new era in process mining tool support, ICATPN 2005 [6] C. Kolias, G. Kambourakis, A. Stavrou and J. Voas, ""DDoS in the IoT: Mirai and Other Botnets,"" in Computer, vol. 50, no. 7, pp. 80-84, 2017. [7] Markus Miettinen, Samuel Marchal, Ibbad Hafeez, N. Asokan, Ahmad-Reza Sadeghi, Sasu Tarkoma: IoT SENTINEL: Automated Device-Type Identification for Security Enforcement in IoT. ICDCS 2017: [8] A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari and M. Ayyash, ""Internet of Things: A Survey on Enabling Technologies, Protocols, and Applications,"" in IEEE Communications Surveys & Tutorials , vol. 17, no. 4, pp. 2347-2376, Fourthquarter 2015.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a4f5af1c85bae92907e357a3d1f61a06395f8f59,https://www.semanticscholar.org/paper/a4f5af1c85bae92907e357a3d1f61a06395f8f59,Ransomware Auto-Detection in IoT Devices using Machine Learning,"The term Internet of Things (often abbreviated IoT) was coined by industry researchers but has emerged into mainstream public view only more recently. The IoT is a massive group of devices containing sensors or actuators connected over wired or wireless networks. IoT has been rapidly growing over the past decade and, during the growth, security has been identified as one of the weakest areas in IoT. There are over six billion estimated devices currently connected to the Internet and an estimate of over 25 billion connected by 2020. IoT and its applications propagate to majority of life’s infrastructure ranging from health and food production to smart cities and urban management. While efficiency and prevalence of IoT are increasing, security issues remain a necessary concern for industries. Internet connected devices, including those deployed in an IoT architecture, are increasingly targeted by cybercriminals due to their pervasiveness and the ability to use the compromised devices to further attack the underlying architecture. In the case of ransomware, for example, devices that can store a reasonably amount of data are likely to be targeted. Thus, ensuring the security of IoT nodes against threats such as malware is a topic of ongoing interest. While malware detection and mitigation research are now new, ransomware detection and mitigation remain challenging. Ransomware is a relatively new malware type that attempts to encrypt a compromised device’s data using a strong encryption algorithm. The victim will then have to pay the ransom (usually using bitcoins) to obtain the password or decryption key. Consequences include temporary or permanent loss of sensitive information, disruption of regular operations, direct/indirect financial losses. In this paper, we present a machine learning based approach to detect ransomware of IoT devices. Specifically, our proposed approach outperforms K-Nearest Neighbors, Neural Networks, Support Vector Machine and Random Forest, in terms of accuracy rate, recall rate and precision rate.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
715734aa23fff701f5e10398e11f2b892d5c0884,https://www.semanticscholar.org/paper/715734aa23fff701f5e10398e11f2b892d5c0884,Predicting youth diabetes risk using NHANES data and machine learning,,medRxiv,2019,10.1038/s41598-021-90406-0,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9fbafa712c8b6a709060c058380965a0b514894d,https://www.semanticscholar.org/paper/9fbafa712c8b6a709060c058380965a0b514894d,"Multi-Domain Airflow Modeling and Ventilation Characterization Using Mobile Robots, Stationary Sensors and Machine Learning","Ventilation systems are critically important components of many public buildings and workspaces. Proper ventilation is often crucial for preventing accidents, such as explosions in mines and avoiding health issues, for example, through long-term exposure to harmful respirable matter. Validation and maintenance of ventilation systems is thus of key interest for plant operators and authorities. However, methods for ventilation characterization, which allow us to monitor whether the ventilation system in place works as desired, hardly exist. This article addresses the critical challenge of ventilation characterization—measuring and modelling air flow at micro-scales—that is, creating a high-resolution model of wind speed and direction from airflow measurements. Models of the near-surface micro-scale flow fields are not only useful for ventilation characterization, but they also provide critical information for planning energy-efficient paths for aerial robots and many applications in mobile robot olfaction. In this article we propose a heterogeneous measurement system composed of static, continuously sampling sensing nodes, complemented by localized measurements, collected during occasional sensing missions with a mobile robot. We introduce a novel, data-driven, multi-domain airflow modelling algorithm that estimates (1) fields of posterior distributions over wind direction and speed (“ventilation maps”, spatial domain); (2) sets of ventilation calendars that capture the evolution of important airflow characteristics at measurement positions (temporal domain); and (3) a frequency domain analysis that can reveal periodic changes of airflow in the environment. The ventilation map and the ventilation calendars make use of an improved estimation pipeline that incorporates a wind sensor model and a transition model to better filter out sporadic, noisy airflow changes. These sudden changes may originate from turbulence or irregular activity in the surveyed environment and can, therefore, disturb modelling of the relevant airflow patterns. We tested the proposed multi-domain airflow modelling approach with simulated data and with experiments in a semi-controlled environment and present results that verify the accuracy of our approach and its sensitivity to different turbulence levels and other disturbances. Finally, we deployed the proposed system in two different real-world industrial environments (foundry halls) with different ventilation regimes for three weeks during full operation. Since airflow ground truth cannot be obtained, we present a qualitative discussion of the generated airflow models with plant operators, who concluded that the computed models accurately depicted the expected airflow patterns and are useful to understand how pollutants spread in the work environment. This analysis may then provide the basis for decisions about corrective actions to avoid long-term exposure of workers to harmful respirable matter.",Sensors,2019,10.3390/s19051119,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5e85a8241d0bbbb6953b11aea69c54c7cd122335,https://www.semanticscholar.org/paper/5e85a8241d0bbbb6953b11aea69c54c7cd122335,A wearable computing platform for developing cloud-based machine learning models for health monitoring applications.,"Wearable sensors have the potential to enable clinical-grade ambulatory health monitoring outside the clinic. Technological advances have enabled development of devices that can measure vital signs with great precision and significant progress has been made towards extracting clinically meaningful information from these devices in research studies. However, translating measurement accuracies achieved in the controlled settings such as the lab and clinic to unconstrained environments such as the home remains a challenge. In this paper, we present a novel wearable computing platform for unobtrusive collection of labeled datasets and a new paradigm for continuous development, deployment and evaluation of machine learning models to ensure robust model performance as we transition from the lab to home. Using this system, we train activity classification models across two studies and track changes in model performance as we go from constrained to unconstrained settings.",Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference,2016,10.1109/EMBC.2016.7592095,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e7981b0e0c455f6db873529ef0c9f0ed4fc7dc91,https://www.semanticscholar.org/paper/e7981b0e0c455f6db873529ef0c9f0ed4fc7dc91,A wearable computing platform for developing cloud-based machine learning models for health monitoring applications,"Wearable sensors have the potential to enable clinical-grade ambulatory health monitoring outside the clinic. Technological advances have enabled development of devices that can measure vital signs with great precision and significant progress has been made towards extracting clinically meaningful information from these devices in research studies. However, translating measurement accuracies achieved in the controlled settings such as the lab and clinic to unconstrained environments such as the home remains a challenge. In this paper, we present a novel wearable computing platform for unobtrusive collection of labeled datasets and a new paradigm for continuous development, deployment and evaluation of machine learning models to ensure robust model performance as we transition from the lab to home. Using this system, we train activity classification models across two studies and track changes in model performance as we go from constrained to unconstrained settings.",2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),2016,10.1109/EMBC.2016.7592095,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1f1ef38f1f00c8ccaeaba78e12981ad37c633664,https://www.semanticscholar.org/paper/1f1ef38f1f00c8ccaeaba78e12981ad37c633664,"Identifying prospective frequent readmitters for hospital to home
 intervention using machine learning","Introduction: Singapore is a developed country with a population of 5.6 million and an acute-centric healthcare system. While the acute hospitals deliver extensive care, patients with multiple care needs face challenges in managing their conditions post-discharge, due to various reasons, such as weak caregiver support. This phenomenon is especially evident in older and frail patients who are frequently readmitted as their condition(s) deteriorate post-discharge. Methods: In April 2017, Singapore’s Ministry of Health (MOH) launched a nationwide Hospital to Home (H2H) care model to provide holistic patient-centric care to support patients discharging from public hospitals, so that they can transit back home, and stay well in the community. H2H targets high healthcare utilizers who are frail with complex care needs. The service includes medication reconciliation, case management, care coordination, telephonic support and caregiver training. To facilitate the development and deployment of the predictive model to risk stratify and segment the patients for enrolment assessment into H2H, a workgroup consisting of clinicians and data scientists across the various public hospitals was formed. The dependent variable for the model was three or more non-elective inpatient admissions within a 1-year period. Independent variables, generated based on literature review and input from clinicians and care managers, were segmented into 3 primary categories: sociodemographic, past hospital utilization and past medical conditions. Results: The top important variable was “total LOS in the past 12 months” followed by “number of days from previous non-elective admission” which lifted the model performance significantly. The best performing machine learning algorithm has an AUC of 0.79, recall of 39%, with precision set at 70% after consultation with the H2H clinical committee to capture very high risk patients. The prediction list, generated on daily basis, is now an integrated part of patient assessment workflow. The list helps the care team to support and follow up with the high healthcare utilizers and their caregivers after discharge. As of Oct 2018, more than 23,000 patients had benefited. Conclusions: The predictive model exemplifies the benefit of augmenting prediction model with clinical assessment. By having the prediction tool act as a bigger “sieve” to do the first level of filtering and the subsequent removal of potential false positives by clinicians when they assessed the patient in-ward provides a targeted intervention with minimal clinical resources. Lessons learnt: To manage the multidisciplinary development team in this endeavour efficiently, we adopted an iterative development process that allow us to fail fast and often. To convince clinicians to shift their decision making process to be augmented with a predictive model, we engaged reputable clinicians in the H2H clinical committee and analytics teams from different public hospitals to co-develop the model. Limitations: In this discussion, we had not been able to cover in depth on areas such as comparing the predictive model performance with different set of features. Future research: Future enhancements include the use of Natural Language Processing on unstructured clinical notes to extract care-giver and non-clinical information as additional features for the prediction model.",International Journal of Integrated Care,2019,10.5334/IJIC.S3228,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ba0ab0cff7f78b5b5cea16dbbe73e1ce1cb6a3db,https://www.semanticscholar.org/paper/ba0ab0cff7f78b5b5cea16dbbe73e1ce1cb6a3db,A machine learning classification framework for early prediction of Alzheimer's disease,"People today, in addition to their concerns about getting old and having to go through watching themselves grow weak and wrinkly, are facing an increasing fear of dementia. There are around 47 million people affected by dementia worldwide and the cost associated with providing them health and social care support is estimated to reach 2 trillion by 2030 which is almost equivalent to the 18th largest economy in the world. The most common form of dementia with the highest costs in health and social care is Alzheimer’s disease, which gradually kills neurons and causes patients to lose loving memories, the ability to recognise family members, childhood memories, and even the ability to follow simple instructions. Alzheimer’s disease is irreversible, unstoppable and has no known cure. Besides being a calamity to affected patients, it is a great financial burden on health providers. Health care providers also face a challenge in diagnosing the disease as current methods used to diagnose Alzheimer’s disease rely on manual evaluations of a patient’s medical history and mental examinations such as the Mini-Mental State Examination. These diagnostic methods often give a false diagnosis and were designed to identify Alzheimer’s after stage two when the part of all symptoms are evident. The problem is that clinicians are unable to stop or control the progress of Alzheimer’s disease, because of a lack of knowledge on the patterns that triggered the development of the disease. In this thesis, we explored and investigated Alzheimer’s disease from a computational perspective to uncover different risk factors and present a strategic framework called Early Prediction of Alzheimer’s Disease Framework (EPADf) that would give a future prediction of early-onset Alzheimer’s disease. Following extensive background research that resulted in the formalisation of the framework concept, prediction approaches, and the concept of ranking the risk factors based on clinical instinct, knowledge and experience using mathematical reasoning, we carried out experiments to get further insight and investigate the disease further using machine learning models. In this study, we used machine learning models and conducted two classification experiments for early prediction of Alzheimer’s disease, and one ranking experiment to rank its risk factors by importance. Besides these experiments, we also presented two logical approaches to search for patterns in an Alzheimer’s dataset, and a ranking algorithm to rank Alzheimer’s disease risk factors based on clinical evaluation. For the classification experiments we used five different Machine Learning models; Random Forest (RF), Random Oracle Model (ROM), a hybrid model combined of Levenberg-Marquardt neural network and Random Forest, combined using Fischer discriminate analysis (H2), Linear Neural Networks (LNN), and Multi-layer Perceptron Model (MLP). These models were deployed on a de-identified multivariable patient’s data, provided by the ADNI (Alzheimer’s disease Neuroimaging Initiative), to illustrate the effective use of data analysis to investigate Alzheimer’s disease biological and behavioural risk factors. We found that the continues enhancement of patient’s data and the use of combined machine learning models can provide an early cost-effective prediction of Alzheimer’s disease, and help in extracting insightful information on the risk factors of the disease. Based on this work and findings we have developed the strategic framework (EPADf) which is discussed in more depth in this thesis.",,2019,10.24377/LJMU.T.00010791,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9ff8b9bc8afcddab1123101152c2d7adfd19ae24,https://www.semanticscholar.org/paper/9ff8b9bc8afcddab1123101152c2d7adfd19ae24,Using Machine Learning to Design Precision Digital Engagement,"MEMOTEXT has developed the following 6step Digital Health Engagement Methodology for Data Mining (DHEM-DM) based on the systematic process and experience of designing, developing, and deploying personalized digital health interventions across chronic disease and patient-specific domains. This structure approach draws on aspects from the Cross Industry Standard Process Data Mining (CRISPDM), the Analytics Solutions Unified Method Data Mining (ASUM-DM) and the Team Data Science Process (TDSP) methodologies but is specifically tailored for a data-driven approach in designing digital health interventions to help patients meet their health goals and produce sustained behaviour change.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
51abfdf11acdec8f294e1b9362b7b75aba456a01,https://www.semanticscholar.org/paper/51abfdf11acdec8f294e1b9362b7b75aba456a01,Machine Learning-Based Application for Predicting Risk of Type 2 Diabetes Mellitus (T2DM) in Saudi Arabia: A Retrospective Cross-Sectional Study,"Earlier detection of individuals at the highest risk of developing diabetes is crucial to avoid the disease’s prevalence and progression. Therefore, we aim to build a data-driven predictive application for screening subjects at a high risk of developing Type 2 Diabetes mellitus (T2DM) in the western region of Saudi Arabia. In this context, we designed and implemented a questionnaire-based cross-sectional study using conventional diabetes risk factors for studying the prevalence and the association between the outcomes and exposure (s). We used the Chi-Squared test and binary logistic regression to analyze and screen the most significant diabetes risk factor for T2DM risk prediction. Synthetic Minority Over-sampling Technique (SMOTE), a class-balancer, was used to balance the cross-sectional data. We used the balanced class data to screen the best performing classification algorithm to classify patients at high risk of diabetes with a higher F1 Score. The best performing classifier’s hyper-parameters were further tuned using 10-fold cross-validation for achieving an improved F1 Score. Additionally, we validated our proposed model with the existing models built using the National Health and Nutrition Examination Survey (NHANES) dataset and Pima Indian Diabetes (PID) dataset. The results of the Chi-squared test and binary logistic regression showed that the exposures, namely Smoking, Healthy diet, Blood-Pressure (BP), Body Mass Index (BMI), Gender, and Region, contributed significantly (p < 0.05) to the prediction of the Response variable (subjects at high risk of diabetes). The tuned two-class Decision Forest (DF) model showed better performance with an average F1score of 0.8453 ± 0.0268. Moreover, the DF based model adapted reasonably well in different diabetes dataset. An Application Programming Interface (API) of the tuned DF model was implemented and deployed as a web service at https://type2-diabetes-risk-predictor.herokuapp.com, and the implementation codes are available at https://github.com/SAH-ML/T2DM-Risk-Predictor.",IEEE Access,2020,10.1109/ACCESS.2020.3035026,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1ea9399d59307f1ecd25933c3b80f4f7e4ed2a0a,https://www.semanticscholar.org/paper/1ea9399d59307f1ecd25933c3b80f4f7e4ed2a0a,Machine learning and Kalman Filter based Target Tracking in Wireless Sensor Network,"Target tracking is one of the nontrivial application of wireless sensor network(WSN) which can be deploy corresponds to applications like monitoring, surveillance, indoor buildings and its application can be extended to health traffic and many other consumers and industrial areas. We summarize a framework for collaborative signal processing (CSP) in distributed sensor network. The thoughts are displayed with regards to tracking a different moving object in a sensor field. The key steps included in the following technique incorporate event detection, target classification, estimation and prediction of the target area. Here we portray a unique way of following an object in WSNs. The projected strategy consolidates machine learning (ML) algorithm with a Kalman filter to determine the instantaneous location of an object in motion. The object’s increasing velocities, alongside data from the network, are utilized to get an exact approximation of its position. To execute this, radio fingerprints of received signal strength indicator (RSSIs) are first gathered over our region of interest. The acquired information is then utilized with machine learning algorithm to process a function that gauges the location of the object using just RSSI data. The kernel based ridge regression (RR) and the vector output regularized least squares (vo-RLS) are used as a part of the learning algorithm. The Kalman filter is then utilized to combine first approximation of the target positions along with acceleration information for obtaining better accuracy. The outcome of this method is considered for various scenario and alikeness with a well-known techniques also provided.",,2016,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e052ad886158262b5aa97ec423fa66e1bd46023c,https://www.semanticscholar.org/paper/e052ad886158262b5aa97ec423fa66e1bd46023c,Problems in the deployment of machine-learned models in health care,"CMAJ | SEPTEMBER 7, 2021 | VOLUME 193 | ISSUE 35 E1391 I n a companion article, Verma and colleagues discuss how machine-learned solutions can be developed and implemented to support medical decision-making.1 Both decisionsupport systems and clinical prediction tools developed using machine learning (including the special case of deep learning) are similar to clinical support tools developed using classical statistical models and, as such, have similar limitations.2,3 A model that makes incorrect predictions can lead its users to make errors they otherwise would not have made when caring for patients, and therefore it is important to understand how these models can fail.4 We discuss these limitations — focusing on 2 issues in particular: out-of-distribution (or out-of-sample) generalization and incorrect feature attribution — to underscore the need to consider potential caveats when using machine-learned solutions.",Canadian Medical Association Journal,2021,10.1503/cmaj.202066,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9ece83a564817ef3afe771344442ebefdafcd4f2,https://www.semanticscholar.org/paper/9ece83a564817ef3afe771344442ebefdafcd4f2,Type : New PW Title : Using Frontera GPU computing to accelerate developments in interpretable machine learning,"With this Pathways allocation we will obtain InSAR velocity fields using Sentinel-1 data for both the Indonesian volcanic arc and the Tibetan Plateau. These data will be used (1) to test the hypothesis that in Indonesia the is a temporal correlation between volcanic unrest and precipitation with more unrest occurring during the rainy season because infiltrated rainwater weakens the rock and (2) to constrain models of continental deformation. Type: New PW Title: Planet-disk interaction in three dimensions Principal Investigator: Jaehan Bae (Carnegie Institution of Washington) Co-Investigators: Field of Science: Stellar Astronomy and Astrophysics Abstract: Recent observations of circumstellar disks around young, forming stars have revealed a plethora of Recent observations of circumstellar disks around young, forming stars have revealed a plethora of structures. One of the most exciting possibilities is the interaction between the disk and planets embedded therein. In order to improve our understanding of planet-disk interaction and help better interpret observations taken at unprecedented spatial resolution and sensitivity, we propose to carry out three-dimensional numerical simulations of planet-disk interaction. Type: New PW Title: Using Frontera GPU computing to accelerate developments in interpretable machine learning Principal Investigator: David Benkeser (Emory University) Co-Investigators: Field of Science: Statistics and Probability Abstract: Machine learning for health care and public health decision making faces a significant tradeoff: accuracy Machine learning for health care and public health decision making faces a significant tradeoff: accuracy vs. interpretability. Simple rules (e.g., based on logistic regression) for predicting outcomes or providing treatment recommendations are easy-to interpret, but often suffer in terms of performance. More complex rules, based on black-box algorithms like deep learning, may predict more accurately, but are difficult to interpret. We were recently funded by a three year grant from the National Science Foundation to develop methods that bridge this gap and provide machine learning that is both accurate and interpretable, making it amenable for deployment in clinical and public health settings. GPU computing could play a vital role in achieving the grant's objectives of generating fast and scalable implementations of our proposed algorithms. Type: New PW Title: Development of multiphase fluid-structure interaction methods Principal Investigator: Amneet Pal Bhalla (San Diego State University) Co-Investigators: KAUSTUBH KHEDKAR (San Diego State University) Field of Science: Applied Mathematics Abstract: Applications involving fluid-structure interaction (FSI) are ubiquitous in natural and engineering processes Applications involving fluid-structure interaction (FSI) are ubiquitous in natural and engineering processes that can range from bacterial swimming to the interaction of waves with ships. FSI also plays a vital role in new methodological approaches for modeling energy harvesting devices such as wave energy converters (WEC) and simulating 3D printing processes. Executing these applications at large-scale with the traditional body-fitted grid approach becomes prohibitively expensive due to the re-meshing requirement of the numerical scheme to conform to the deforming or moving body in the domain. On the other hand, the immersed boundary (IB) methods discretize the computational domain using Cartesian grids, and the dynamics of the immersed structure is resolved by modifying the underlying equations of motion. Thus, the computational cost involved in resolving FSI is substantially reduced by adopting the IB approach. In our group, we study the interaction of surface gravity waves with moving structures such as wave energy converter devices and naval ships, as well as model the stereo-lithography 3D printing process using state-of-the-art immersed boundary method and adaptive mesh refinement based software infrastructure named IBAMR, which is a National Science Foundation (NSF OAC 1450327, OAC 1450374 and OAC 1931516) sponsored advanced cyberinfrastructure (CI) project. In the following sections, we give a brief review of our research work and the questions that we aim to address. Our proposed project is funded by NSF award 1931368. Type: New PW Title: Real-time High Resolution Ensemble Numerical Weather Forecasts Using SAR-FV3 for the Hydrometeorology Testbed Ramping toward Exascale Principal Investigator: Keith Brewster (University of Oklahoma) Co-Investigators: Nathan Snook (University of Oklahoma); Tim Supinie (University of Oklahoma) Field of Science: Meteorology",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1e6986aec9cb94348116ba1712be463b9d9db923,https://www.semanticscholar.org/paper/1e6986aec9cb94348116ba1712be463b9d9db923,IBM Auto AI Bot: Diabetes Mellitus Prediction Using Machine Learning Algorithms,"Chronic diseases such as diabetes can have a devastating effect on a person's overall well-being. Diabetes is characterised by abnormally high blood glucose levels, which are the result of either impaired insulin secretion or impaired physiologic effects, or both. Many tissues, including the eyes, kidneys, heart, blood vessels, and nerves, can be permanently damaged or dysfunctional due to diabetes. Type 1 diabetes (T1D) and type 2 diabetes are the two types of diabetes (T2D). Diabetics with type 1 diabetes tend to be younger people, with the majority of them being under the age of 30. Increased thirst and frequent urination are the most common symptoms, as are elevated blood glucose levels. Oral drugs alone are ineffective in treating this kind of diabetes, hence insulin therapy is essential. Middle-aged and older adults are more likely to develop type-2 diabetes, which is frequently linked to obesity, hypertension, dyslipidaemia, arteriosclerosis, and other conditions. Implementing a machine learning model that can quickly uncover the principles for predicting diabetes mellitus in individuals depending on their health status is discussed in this research. There must be an IBM cloud deployment of the model before it can be utilised as an API in web app development. The User Interface will display the model's prediction.",2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC),2022,10.1109/icaaic53929.2022.9792690,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
261525dcadaf97c93b99de02c1d29b3f3fe6bbb0,https://www.semanticscholar.org/paper/261525dcadaf97c93b99de02c1d29b3f3fe6bbb0,Self-powered sensing based on triboelectric nanogenerator through machine learning and its application,"In the era of The Internet of Things, how to develop a smart sensor system with sustainable power supply, easy deployment and flexible use has become an urgent problem to be solved. Triboelectric nanogenerator (TENG) driven by Maxwell’s Displacement Current can convert mechanical motion into electrical signals, thus it can be used as a self-powered sensor. Sensors based on TENGs have the advantages of simple structure and high instantaneous power density, which provide an important means to build intelligent sensor systems. Meanwhile, machine learning, as a technique with low cost, short development cycle, and strong data processing capabilities and predictive capabilities, is effective in processing the large amount of electrical signals generated by TENG. This article combines the latest research progress of TENG-based sensor systems for signal processing and intelligent recognition by employing machine learning techniques, and outlines the technical features and research status of this research direction from the perspectives of traffic safety, environmental monitor, information security, human-computer interaction and health motion detection. Finally, this article also in-depth discusses the current challenges and future development trends in this field, and analyzes how to improve in the future to open up a broader application space. It is suggested that the integration of machine learning technology and TENG-based sensors will promote the rapid development of intelligent sensor networks in the future.",Acta Physica Sinica,2022,10.7498/aps.71.20211632,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
21c38a53dbd4bc4a12d2e1711c7455236695c87a,https://www.semanticscholar.org/paper/21c38a53dbd4bc4a12d2e1711c7455236695c87a,A Brief Guide to Designing and Evaluating Human-Centered Interactive Machine Learning,"Interactive machine learning (IML) is a ﬁeld of research that explores how to leverage both human and computational abilities in decision making systems. IML represents a collaboration between multiple complementary human and machine intelligent systems working as a team, each with their own unique abilities and limitations. This teamwork might mean that both systems take actions at the same time, or in sequence. Two major open research questions in the ﬁeld of IML are: “How should we design systems that can learn to make better decisions over time with human interaction?” and “How should we evaluate the design and deployment of such systems?” A lack of appropriate consideration for the humans involved can lead to problematic system behaviour, and issues of fairness, accountability, and transparency. Thus, our goal with this work is to present a human-centred guide to designing and evaluating IML systems while mitigating risks. This guide is intended to be used by machine learning practitioners who are responsible for the health, safety, and well-being of interacting humans. An obli-gation of responsibility for public interaction means acting with integrity, honesty, fairness, and abiding by applicable legal statutes. With these values and principles in mind, we as a machine learning research community can better achieve goals of augmenting human skills and abilities. This practical guide therefore aims to support many of the responsible decisions necessary throughout the iterative design, development, and dissemination of IML systems.",ArXiv,2022,10.48550/arXiv.2204.09622,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c6015c232287b08a8f8dd58aeb2def76baca8f29,https://www.semanticscholar.org/paper/c6015c232287b08a8f8dd58aeb2def76baca8f29,AESGRU: An Attention-Based Temporal Correlation Approach for End-to-End Machine Health Perception,"Accurate and real-time perception of the operating status of rolling bearings, which constitute a key component of rotating machinery, is of vital significance. However, most existing solutions not only require substantial expertise to conduct feature engineering, but also seldom consider the temporal correlation of sensor sequences, ultimately leading to complex modeling processes. Therefore, we present a novel model, named Attention-based Equitable Segmentation Gated Recurrent Unit Networks (AESGRU), to improve diagnostic accuracy and model-building efficiency. Specifically, our proposed AESGRU consists of two modules, an equitable segmentation approach and an improved deep model. We first transform the original dataset into time-series segments with temporal correlation, so that the model enables end-to-end learning from the strongly correlated data. Then, we deploy a single-layer bidirectional GRU network, which is enhanced by attention mechanism, to capture the long-term dependency of sensor segments and focus limited attention resources on those informative sampling points. Finally, our experimental results show that the proposed approach outperforms previous approaches in terms of the accuracy.",IEEE Access,2019,10.1109/ACCESS.2019.2943381,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cefd4a4c8d253671e3676db1898d78278e2a7492,https://www.semanticscholar.org/paper/cefd4a4c8d253671e3676db1898d78278e2a7492,Detecting Recovery Problems Just in Time: Application of Automated Linguistic Analysis and Supervised Machine Learning to an Online Substance Abuse Forum,"Background Online discussion forums allow those in addiction recovery to seek help through text-based messages, including when facing triggers to drink or use drugs. Trained staff (or “moderators”) may participate within these forums to offer guidance and support when participants are struggling but must expend considerable effort to continually review new content. Demands on moderators limit the scalability of evidence-based digital health interventions. Objective Automated identification of recovery problems could allow moderators to engage in more timely and efficient ways with participants who are struggling. This paper aimed to investigate whether computational linguistics and supervised machine learning can be applied to successfully flag, in real time, those discussion forum messages that moderators find most concerning. Methods Training data came from a trial of a mobile phone-based health intervention for individuals in recovery from alcohol use disorder, with human coders labeling discussion forum messages according to whether or not authors mentioned problems in their recovery process. Linguistic features of these messages were extracted via several computational techniques: (1) a Bag-of-Words approach, (2) the dictionary-based Linguistic Inquiry and Word Count program, and (3) a hybrid approach combining the most important features from both Bag-of-Words and Linguistic Inquiry and Word Count. These features were applied within binary classifiers leveraging several methods of supervised machine learning: support vector machines, decision trees, and boosted decision trees. Classifiers were evaluated in data from a later deployment of the recovery support intervention. Results To distinguish recovery problem disclosures, the Bag-of-Words approach relied on domain-specific language, including words explicitly linked to substance use and mental health (“drink,” “relapse,” “depression,” and so on), whereas the Linguistic Inquiry and Word Count approach relied on language characteristics such as tone, affect, insight, and presence of quantifiers and time references, as well as pronouns. A boosted decision tree classifier, utilizing features from both Bag-of-Words and Linguistic Inquiry and Word Count performed best in identifying problems disclosed within the discussion forum, achieving 88% sensitivity and 82% specificity in a separate cohort of patients in recovery. Conclusions Differences in language use can distinguish messages disclosing recovery problems from other message types. Incorporating machine learning models based on language use allows real-time flagging of concerning content such that trained staff may engage more efficiently and focus their attention on time-sensitive issues.",Journal of medical Internet research,2018,10.2196/10136,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d37126461de58f1b8858abc85cbb0ab43209e4bc,https://www.semanticscholar.org/paper/d37126461de58f1b8858abc85cbb0ab43209e4bc,Machine Learning Model for Imbalanced Cholera Dataset in Tanzania,"Cholera epidemic remains a public threat throughout history, affecting vulnerable population living with unreliable water and substandard sanitary conditions. Various studies have observed that the occurrence of cholera has strong linkage with environmental factors such as climate change and geographical location. Climate change has been strongly linked to the seasonal occurrence and widespread of cholera through the creation of weather patterns that favor the disease's transmission, infection, and the growth of Vibrio cholerae, which cause the disease. Over the past decades, there have been great achievements in developing epidemic models for the proper prediction of cholera. However, the integration of weather variables and use of machine learning techniques have not been explicitly deployed in modeling cholera epidemics in Tanzania due to the challenges that come with its datasets such as imbalanced data and missing information. This paper explores the use of machine learning techniques to model cholera epidemics with linkage to seasonal weather changes while overcoming the data imbalance problem. Adaptive Synthetic Sampling Approach (ADASYN) and Principal Component Analysis (PCA) were used to the restore sampling balance and dimensional of the dataset. In addition, sensitivity, specificity, and balanced-accuracy metrics were used to evaluate the performance of the seven models. Based on the results of the Wilcoxon sign-rank test and features of the models, XGBoost classifier was selected to be the best model for the study. Overall results improved our understanding of the significant roles of machine learning strategies in health-care data. However, the study could not be treated as a time series problem due to the data collection bias. The study recommends a review of health-care systems in order to facilitate quality data collection and deployment of machine learning techniques.",TheScientificWorldJournal,2019,10.1155/2019/9397578,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
07fc9d5ae2754dec270bb5b065d0acc51f77452a,https://www.semanticscholar.org/paper/07fc9d5ae2754dec270bb5b065d0acc51f77452a,Translational Medicine in the Era of Big Data and Machine Learning.,"Basic research in cardiovascular medicine has yielded dramatic insights into physiology, leading to therapeutic advances and a significant decrease in cardiovascular mortality for the past 50 years. Nonetheless, it is increasingly recognized that even highly efficacious therapies have heterogeneity of effect at the individual level. In addition, there is significant variation in the use of evidence-based therapies and outcomes in routine clinical practice. These factors limit the potential impact of scientific advances when implemented in care. The increasing availability of digital medical data, coupled with powerful analytic methods such as machine learning, hold promise to support more personalized medicine and effective population health management. If successful, translational medicine in the era of big data and machine learning could truly span bench to bedside to population and optimize the end results of healthcare, that is, the triple aim of delivering better patient care, improving population health, and reducing cost. In this article, we review the opportunities and challenges of using big data and machine learning to deliver personalized medicine that meets the triple aim. We put forward the position that research scientists across the translational spectrum will need to be engaged and lead research studies of multiple types for these opportunities to be met. The promulgation of EHRs, increasing availability of digital health data from sources such as apps and biosensors, and the explosion of genomic sequencing have contributed to the increasing availability of big data. These massive—and growing—data sets lend themselves to the application of analytic methods, such as machine learning to accomplish complex, iterative pattern recognition and development of predictive algorithms. By applying machine learning methods to big data, there is a hope that human intelligence can be mimicked, that is, artificial intelligence. For artificial intelligence to mimic human intelligence, it will require computers to not just recognize patterns in structured data but also be capable of natural language processing. Whether such powerful artificial intelligence can grow from deep learning and cognitive computing for next several years to decades remains uncertain. Ideally, big data could support personalized medicine, where machine learning algorithms predict individual patient risk, and more accurately and precisely identify which patients will benefit most from specific therapies. For example, could data from EHR, biosensors, and genomics improve the predictive power of the pooled cohort equations for incident cardiovascular events? Therapeutic recommendations based on computer-refined phenotypes (precision medicine), better population health management, accelerated identification of drug targets, and augmentation of the diagnostic ability of clinician are all potential applications. Currently, there is great hype but scant evidence for these potential applications. This suggests a critical role for cardiovascular researchers across the translational medicine spectrum to validate and prove effectiveness and safety of big data applications before broad deployment in practice. Without such evidence, the potential for big data and machine learning in cardiovascular medicine may not be realized. Convincing evidence will require studies that demonstrate improved patient outcomes which can be attributed to big data approaches, for example, observational studies or randomized trials. The rise of large biobanks with genomic data on millions of subjects linked to their EHR or curated phenotypes, and sometimes with prospective follow-up, constitutes one real opportunity. The UK Biobank has detailed clinical data with thousands of variables linked to genomic data on half a million subjects. Using these data, researchers made public genomewide association results for >2000 traits on ≈337 000 individuals (www.nealelab.is/uk-biobank). This democratization of data is meant to accelerate biological discovery by enabling focused hypotheses and quick validation of findings from one cohort using another. The United States is following with even larger biobanks down the pipeline, such as the Million Veteran Project and the All of Us Research Project, each of which is aiming to recruit one million subjects with extensive genomic and phenotypic data generation. Availability of population genomic data has improved the power to detect new associations and invalidated prior The opinions expressed in this article are not necessarily those of the editors or of the American Heart Association. From the MedStar Heart and Vascular Institute, Georgetown University, Washington, DC (W.S.W.); Division of Cardiology and Center for Genomic Medicine, Massachusetts General Hospital, Boston (A.C.F.); The Broad Institute of Harvard and MIT, Cambridge, MA (A.C.F.); Harvard Medical School, Boston, MA (A.C.F.); and University of Colorado School of Medicine, Aurora (J.S.R.). Correspondence to William S. Weintraub, MD, MedStar Heart and Vascular Institute, MedStar Washington Hospital Center, Suite 4B1, 110 Irving St NW, Washington, DC 20010. Email william.s.weintraub@ medstar.net Viewpoints",Circulation research,2018,10.1161/CIRCRESAHA.118.313944,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f07a208ee5ed1d452d420704a195228dbeedc777,https://www.semanticscholar.org/paper/f07a208ee5ed1d452d420704a195228dbeedc777,A Study on Machine Learning Approaches for Outlier Detection in Wireless Sensor Network,"Wireless Sensor Network (WSN) is an important research area nowadays. Wireless Sensor Network is deployed in hostile environment consisting of hundreds to thousands of nodes. They can be deployed for various mission-critical applications, such as health care, military monitoring as well as civilian applications. There are various security issues in these networks. One of such issue is outlier detection. In outlier detection, data obtained by some of the nodes whose behavior is different from the data of other nodes are spotted in the group of data. But identification of such nodes is a little difficult. In this paper, machine learning based methods for outlier detection are discussed among which the Bayesian Network looks advantageous over other methods. Bayesian classification algorithm can be used for calculating the conditional dependency of the available nodes in WSN. This method can also calculate the missing data value.","2018 8th International Conference on Cloud Computing, Data Science & Engineering (Confluence)",2018,10.1109/CONFLUENCE.2018.8442992,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ae022b854a6ae0cea958d7cc8e8a09caf42dda7b,https://www.semanticscholar.org/paper/ae022b854a6ae0cea958d7cc8e8a09caf42dda7b,Predicting states of elevated negative affect in adolescents from smartphone sensors: A novel personalized machine learning approach,"Adolescence is characterized by profound change, including increases in negative emotions. Approximately 84% of American adolescents own a smartphone, which can continuously and unobtrusively track variables potentially predictive of heightened negative emotions (e.g., activity levels, location, pattern of phone usage). The extent to which built-in smartphone sensors can reliably predict states of elevated negative affect in adolescents is an open question. In this study, adolescent participants (n = 22; ages 13-18) with low to high levels of depressive symptoms were followed for 15 weeks using a combination of ecological momentary assessments (EMAs) and continuously collected passive smartphone sensor data. EMAs probed negative emotional states (i.e., anger, sadness and anxiety) 2-3 times per day every other week throughout the study (total: 1,145 EMA measurements). Smartphone accelerometer, location and device state data were collected to derive 14 discrete estimates of behavior, including activity level, percentage of time spent at home, sleep onset and duration, and phone usage. A personalized ensemble machine learning model derived from smartphone sensor data outperformed other statistical approaches (e.g., linear mixed model) and predicted states of elevated anger and anxiety with acceptable discrimination ability (area under the curve (AUC) = 74% and 71%, respectively), but demonstrated more modest discrimination ability for predicting states of high sadness (AUC = 66%). To the extent that smartphone data could provide reasonably accurate real-time predictions of states of high negative affect in teens, brief “just-in-time” interventions could be immediately deployed via smartphone notifications or mental health apps to alleviate these states.",,2022,10.31234/osf.io/zjm4d,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c54d8b94e3290ae5e02ffcfdc407e6d519ceec2f,https://www.semanticscholar.org/paper/c54d8b94e3290ae5e02ffcfdc407e6d519ceec2f,Medical Healthcare System with Hybrid Block based Predictive models for Quality preserving in Medical Images using Machine Learning Techniques,"Cloud technology is a business strategy that aims to provide the necessary material to customers depending on their needs. Individuals and cloud businesses alike have embraced the cloud storage service, which has become the most widely used service. The industries outsource their data to cloud storage space to relieve themselves of a load of dealing with redundant data contents. This must be protected to prevent the theft of personal belongings, and privacy must be improved as well. Different research projects have been suggested to ensure the safe management of the information included within the data content. The security of current research projects, on the other hand, still needs improvement. As a result, this method has been suggested to address the security concerns associated with cloud computing. The primary goal of this study effort is to offer a safe environment for cloud users while also increasing the profit of cloud resource providers by managing and securely delivering data contents to the cloud users. The bulk of sectors, including business, finance, the military, and the healthcare industry, do not store data in cloud-based storage systems. This technique is used to attract these kinds of customers. Increasing public acceptance Medical researchers are drawn to cloud computing because it allows them to store their study material in a centralized location and distribute and access it in a more flexible manner. They were collected from numerous individuals who were being evaluated for medical care at the time. Scalable and Enhanced Key Aggregate Cryptosystem is a protected data protection method that provides highly effective security in the health care industry. This approach handles disagreements in the outflow of sensitive information and guarantees the data security deployment of a Cloud-based Intelligent Health Monitoring system for the parties involved in the dispute. Using the suggested method, the encrypted data format of medical and health-care prescriptions is recorded as it passes through the hands of patients and healthcare institutions. To increase the level of security, the double encryption method is used. During the encryption process, the Ciphertext ID is referred to as a class. The keyholder is a master secret key that aids in the retrieval of the secret keys of different kinds of monsters and creatures. The extracted key is transmitted and kept as a single aggregate for the benefit of the patient or client to facilitate decryption. Between the use of a key aggregation cryptosystem and double encryption method, the Cloud-based Intelligent Health Monitoring systems may establish a secure link with Healthcare Organizations and patients. As a result, when compared to prior methods, the results demonstrate that the study methodology achieves high levels of security in terms of confidentiality and integrity, as well as great scalability.",2022 International Conference on Advanced Computing Technologies and Applications (ICACTA),2022,10.1109/ICACTA54488.2022.9753355,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d64c3b866d605f131611666191899d9aabf5cf59,https://www.semanticscholar.org/paper/d64c3b866d605f131611666191899d9aabf5cf59,"ISTHMUS: Secure, Scalable, Real-time and Robust Machine Learning Platform for Healthcare","In recent times, machine learning (ML) and artificial intelligence (AI) based systems have evolved and scaled across different industries such as finance, retail, insurance, energy utilities, etc. Among other things, they have been used to predict patterns of customer behavior, to generate pricing models, and to predict the return on investments. But the successes in deploying machine learning models at scale in those industries have not translated into the healthcare setting. There are multiple reasons why integrating ML models into healthcare has not been widely successful, but from a technical perspective, general-purpose commercial machine learning platforms are not a good fit for healthcare due to complexities in handling data quality issues, mandates to demonstrate clinical relevance, and a lack of ability to monitor performance in a highly regulated environment with stringent security and privacy needs. In this paper, we describe Isthmus, a turnkey, cloud-based platform which addresses the challenges above and reduces time to market for operationalizing ML/AI in healthcare. Towards the end, we describe three case studies which shed light on Isthmus capabilities. These include (1) supporting an end-to-end lifecycle of a model which predicts trauma survivability at hospital trauma centers, (2) bringing in and harmonizing data from disparate sources to create a community data platform for inferring population as well as patient level insights for Social Determinants of Health (SDoH), and (3) ingesting live-streaming data from various IoT sensors to build models, which can leverage real-time and longitudinal information to make advanced time-sensitive predictions.",ArXiv,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
405577ff2d9646735c5848b490ffbfab166435a0,https://www.semanticscholar.org/paper/405577ff2d9646735c5848b490ffbfab166435a0,"Machine-Learning prognostic models from the 2014-16 Ebola outbreak: data-harmonization challenges, validation strategies, and mHealth applications","Abstract Background We created a family of prognostic models for Ebola virus disease from the largest dataset of EVD patients published to date. We incorporated these models into an app, “Ebola Care Guidelines”, that provides access to recommended, evidence-based supportive care guidelines and highlights the signs/symptoms with the largest contribution to prognosis. Methods We applied multivariate logistic regression on 470 patients admitted to five Ebola treatment units in Liberia and Sierra Leone during the 2014-16 outbreak. We validated the models with two independent datasets from Sierra Leone. Findings Viral load and age were the most important predictors of death. We generated a parsimonious model including viral load, age, body temperature, bleeding, jaundice, dyspnea, dysphagia, and referral time recorded at triage. We also constructed fallback models for when variables in the parsimonious model are unavailable. The performance of the parsimonious model approached the predictive power of observational wellness assessments by experienced health workers, with Area Under the Curve (AUC) ranging from 0.7 to 0.8 and overall accuracy of 64% to 74%. Interpretation Machine-learning models and mHealth tools have the potential for improving the standard of care in low-resource settings and emergency scenarios, but data incompleteness and lack of generalizable models are major obstacles. We showed how harmonization of multiple datasets yields prognostic models that can be validated across different cohorts. Similar performance between the parsimonious model and those incorporating expert wellness assessments suggests that clinically-guided machine learning approaches can recapitulate clinical expertise, and thus be useful when such expertise is unavailable. We also demonstrated with our guidelines app how integration of those models with mobile technologies enables deployable clinical management support tools that facilitate access to comprehensive bodies of medical knowledge. Funding Howard Hughes Medical Institute, US National Institutes of Health",,2019,10.1101/294587,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dd5342086bf39633e32cf96ab1bf934987b6626f,https://www.semanticscholar.org/paper/dd5342086bf39633e32cf96ab1bf934987b6626f,Does Machine Learning Automate Moral Hazard and Error?,"Machine learning tools are beginning to be deployed en masse in health care. While the statistical underpinnings of these techniques have been questioned with regard to causality and stability, we highlight a different concern here, relating to measurement issues. A characteristic feature of health data, unlike other applications of machine learning, is that neither y nor x is measured perfectly. Far from a minor nuance, this can undermine the power of machine learning algorithms to drive change in the health care system--and indeed, can cause them to reproduce and even magnify existing errors in human judgment.",The American economic review,2017,10.1257/aer.p20171084,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
26937db6917952a9c13bfe152eddd7defc08e695,https://www.semanticscholar.org/paper/26937db6917952a9c13bfe152eddd7defc08e695,Guest Editorial: Special Issue on Machine Learning Implementations,,J. Signal Process. Syst.,2019,10.1007/s11265-018-1432-1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fc46d5cf9ee41cc96cd8b6fe303fed95e5fa670b,https://www.semanticscholar.org/paper/fc46d5cf9ee41cc96cd8b6fe303fed95e5fa670b,A System To Detect Mental Stress Using Machine Learning And Mobile Development,"Hans Selye1 coined, in 1936, the term “Stress” and definedit as “the non-specific response of the body to any demand for change.” Stress was generallyconsidered as being synonymous with distress. English language dictionaries (Oxford & Merriam-Webster) defined it as “physical, mental, or emotional strain or tension when a person perceives that demands exceed the personal and social resources the individual is able to mobilize.” Stress affects over 100 million Americans and is a driver of many chronic diseases. According to American Psychological Association (APA) 2012 study, “Stress is costing organizations a Fortune” and some cases as much as $300 billion a year. The challenges, importantly, for the individuals and the organizations are lack of proactive detection of the stress and inept preventive actions to manage mental health to circumvent adverse effects of the stress. This research paper addresses the challenge by developing and deploying machine learning enabled data driven & Electroencephalogram biosensor integrated mobile application that proactively gleans User’s stressful episodes, infuses collaborative intelligence derived from de-identified yet User relevant demographical, physiological, lifestyle and behavioral datasets and preventive healthcare insights to counter otherwise the long term negative effects of the stresson Users health. The paper presents prototyping solution as well as its application and certain experimental results.1Hans Selye was a pioneering Hungarian-Canadian endocrinologist. He conducted much important scientific work on the hypothetical nonspecific response of an organism to stressors - https://www.stress.org/what-is-stress/",2018 International Conference on Machine Learning and Cybernetics (ICMLC),2018,10.1109/ICMLC.2018.8527004,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
31f3dbc28dd7158e95d76bb0757030295c9f769d,https://www.semanticscholar.org/paper/31f3dbc28dd7158e95d76bb0757030295c9f769d,SoK: Privacy-Preserving Computation Techniques for Deep Learning,"Abstract Deep Learning (DL) is a powerful solution for complex problems in many disciplines such as finance, medical research, or social sciences. Due to the high computational cost of DL algorithms, data scientists often rely upon Machine Learning as a Service (MLaaS) to outsource the computation onto third-party servers. However, outsourcing the computation raises privacy concerns when dealing with sensitive information, e.g., health or financial records. Also, privacy regulations like the European GDPR limit the collection, distribution, and use of such sensitive data. Recent advances in privacy-preserving computation techniques (i.e., Homomorphic Encryption and Secure Multiparty Computation) have enabled DL training and inference over protected data. However, these techniques are still immature and difficult to deploy in practical scenarios. In this work, we review the evolution of the adaptation of privacy-preserving computation techniques onto DL, to understand the gap between research proposals and practical applications. We highlight the relative advantages and disadvantages, considering aspects such as efficiency shortcomings, reproducibility issues due to the lack of standard tools and programming interfaces, or lack of integration with DL frameworks commonly used by the data science community.",Proc. Priv. Enhancing Technol.,2021,10.2478/popets-2021-0064,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e1d969e3ab054c1b24ae156a1ffd887420e24f74,https://www.semanticscholar.org/paper/e1d969e3ab054c1b24ae156a1ffd887420e24f74,"Feature Extraction, Supervised and Unsupervised Machine Learning Classification of PV Cell Electroluminescence Images","Lifetime performance and degradation analysis of laboratory and field deployed PV modules is paramount to the continued success of solar energy. Image characterization techniques capture spatially resolved macroscopic manifestations of microscopic mechanistic behavior. Automated data processing and analytics allow for a large-scale systematic study of PV module health. In this study, degradation features seen in periodic EL images taken during test-to-failure damp-heat, thermal cycling, ultra-violet irradiance, and dynamic mechanical loading accelerated exposures are extracted and classified using supervised and unsupervised methods. Image corrections, including planar indexing to align module images, are applied. On extracted cell images, degradation states such as busbar corrosion, cracking, wafer edge darkening, and between-busbar dark spots can be studied in comparison to new cells using supervised and unsupervised machine learning. The systematic feature groupings provide a scalable method without bias to quantitatively monitor the degradation of laboratory and commercial systems alike. The evolution of these degradation features through varied exposure conditions provides insight into mechanisms causing degradation in field deployed modules. The supervised algorithms used in this application are Convolutional Neural Networks (CNN) and Support Vector Machines (SVM). With the increase in data and diversity of features, unsupervised learning can be employed to find relations between inherent image properties. Feature extraction techniques help identify intrinsic geometric patterns formed inthe images due to degradation. Principal component analysis is then applied to the extracted set of features to filter the most relevant components from the set, which are then passed to an agglomerative hierarchical clustering algorithm. Google’s Tensorflow library was utilized to enhance the computational efficiency of the CNN model by providing GPUbased parallel matrix operations. Using supervised methods on 5 features an accuracy greater than 98% was achieved. For unsupervised clustering, the classification was done into two clusters of degraded and non-degraded cells with 66% coherence.","2018 IEEE 7th World Conference on Photovoltaic Energy Conversion (WCPEC) (A Joint Conference of 45th IEEE PVSC, 28th PVSEC & 34th EU PVSEC)",2018,10.1109/PVSC.2018.8547739,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6f3382d8dfb4124ec753f7ec2c45fdb945e0e51c,https://www.semanticscholar.org/paper/6f3382d8dfb4124ec753f7ec2c45fdb945e0e51c,Development and implementation of nationwide predictive model for admission prevention: System architecture & machine learning,"Hospitals in developed countries are experiencing increasing inpatient load due to aging. Many of these readmissions could be prevented through early interventions. Using routinely available data in Electronic Health Records, we developed and implemented a machine learning predictive model to identify patients who are at risk of multiple unplanned readmission within the next 12 months from their index hospital admission. This is the first nationwide Predictive Model for Admission Prevention in Singapore that is deployed in all public acute general hospitals to identify high risk patients for enrollment into a community-centric intervention programme after discharge. In this paper, we describe the approach we have taken to augment the prediction model into a routine patient care process.",2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),2018,10.1109/BHI.2018.8333429,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6f3382d8dfb4124ec753f7ec2c45fdb945e0e51c,https://www.semanticscholar.org/paper/6f3382d8dfb4124ec753f7ec2c45fdb945e0e51c,Development and implementation of nationwide predictive model for admission prevention: System architecture & machine learning,"Hospitals in developed countries are experiencing increasing inpatient load due to aging. Many of these readmissions could be prevented through early interventions. Using routinely available data in Electronic Health Records, we developed and implemented a machine learning predictive model to identify patients who are at risk of multiple unplanned readmission within the next 12 months from their index hospital admission. This is the first nationwide Predictive Model for Admission Prevention in Singapore that is deployed in all public acute general hospitals to identify high risk patients for enrollment into a community-centric intervention programme after discharge. In this paper, we describe the approach we have taken to augment the prediction model into a routine patient care process.",2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI),2018.0,10.1109/BHI.2018.8333429,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5d2e12a88a782d7296c0ae41bb0f1a5e7ae8b9bc,https://www.semanticscholar.org/paper/5d2e12a88a782d7296c0ae41bb0f1a5e7ae8b9bc,Machine Learning-based Variability Handling in IoT Agents,"Agent-based IoT applications have recently been proposed in several domains, such as health care, smart cities and agriculture. Deploying these applications in specific settings has been very challenging for many reasons including the complex static and dynamic variability of the physical devices such as sensors and actuators, the software application behavior and the environment in which the application is embedded. In this paper, we propose a self-configurable IoT agent approach based on feedback-evaluative machine-learning. The approach involves: i) a variability model of IoT agents; ii) generation of sets of customized agents; iii) feedback evaluative machine learning; iv) modeling and composition of a group of IoT agents; and v) a feature-selection method based on manual and automatic feedback.",ArXiv,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f1419484373295d8395cb2710a89e74ae5df30c2,https://www.semanticscholar.org/paper/f1419484373295d8395cb2710a89e74ae5df30c2,Disease Prediction by Machine Learning from Healthcare Communities,"To promote sustainable improvement, the smart town implies a global imaginative and prescient that merges artificial intelligence, choice making, statistics and conversation era (ICT), and the net-of-things (IoT). in this mission, the subject of disease prediction and prognosis in clever healthcare is reviewed. due to records progress in biomedical and healthcare groups, correct have a look at of clinical data advantages early disorder recognition, patient care and network services. whilst the exceptional of medical information is incomplete the exactness of study is reduced. moreover, exclusive areas exhibit specific appearances of certain regional illnesses, which can also bring about weakening the prediction of sickness outbreaks. within the proposed system, it offers gadget gaining knowledge of algorithms for effective prediction of various disorder occurrences in ailment-frequent societies and predicts the waiting time for each treatment project for every patient as well as a hospital Queuing advice (HQR) system is advanced for recommending treatment mission sequence with appreciate to anticipated ready time. It experiments on a nearby chronic illness of cerebral infarction. using structured and unstructured facts from health centre it makes use of system studying selection Tree algorithm and KNN algorithm. To the first-rate of our knowledge inside the place of medical huge records analytics none of the existing paintings focused on each information types. in comparison to several normal estimate algorithms, the calculation exactness of our proposed set of rules reaches 94.8% with a convergence speed which is faster than that of the CNN-based totally uni-modal ailment threat prediction (CNN-UDRP) algorithm. similarly, challenges within the deployment of sickness diagnosis in healthcare had been mentioned.",International Journal of Scientific Research in Science and Technology,2019.0,10.32628/IJSRST19633,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
412362eec79033f8b91e28b4483dfdc2a2c1e69f,https://www.semanticscholar.org/paper/412362eec79033f8b91e28b4483dfdc2a2c1e69f,An FPGA-Based Brain Computer Interfacing Using Compressive Sensing and Machine Learning,"Electrocorticography (ECoG) is a type of electrophysiological monitoring useful for recording the activity from the cerebral cortex. It has emerged as a promising recording technique in brain-computer interfaces (BCI). Compression of these signals is essential for saving power and bandwidth in the novel application scenarios of Health-based IoT and Body Area Networks. However, this task is particularly challenging since, ECoG signals are not compressible either in time domain or in frequency domain. To that end, Block Sparse Bayesian Learning (BSBL) techniques were suggested for the reconstruction of compressed EEG and ECG signals, which is however, computationally demanding. Furthermore, given the heterogeneity in modern computing systems, careful design partitioning is required to most effectively evaluate the particular resources available on the deployed architecture. In this paper, we propose to utilise a combination of compressive sensing and neural network for the compression and reconstruction of ECoG signals, respectively. For the choice of the neural network, a multi-layer perceptron regressor with a stochastic gradient descent solver is developed. For a sample system, we show that the network has a compression ratio of 50%, and reconstruction accuracy of 89.85% after training with a practical, medium-sized dataset. In general, the results show that the most efficient system implementation is a heterogeneous architecture combining a CPU and a fieldprogrammable gate array (FPGA).",2018 IEEE Computer Society Annual Symposium on VLSI (ISVLSI),2018.0,10.1109/ISVLSI.2018.00137,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
36246a55571b811561854f1667b5423b2b7c6187,https://www.semanticscholar.org/paper/36246a55571b811561854f1667b5423b2b7c6187,Intelligent Diagnosis of Asthma Using Machine Learning Algorithms,"Data mining in healthcare is a very important field in diagnosis and in deeper understanding of medical data. Health data mining intends to solve realworld problems in diagnosing and treating diseases. One of the most important applications of data mining in the domain of machine learning is diagnosis, and this type of diagnosis of the disease asthma is a notable challenge due to the lack of sufficient knowledge of physicians concerning this disease and because of the complexity of asthma. The purpose of this research is the skillful diagnosis of asthma using efficient algorithms of machine learning. This study was conducted on a dataset consisting of 169 asthmatics and 85 non asthmatics visiting the Imam Khomeini and MasseehDaneshvari Hospitals of Tehran. The algorithms of k – nearest neighbors , random forest , and support vector machine, together with pre – processing and efficient training were implemented on this dataset ,and the degrees of accuracy and specificity of the system used in our study were calculated compared with each other and with those of previous research. From among the different values for neighborhood, the highest degree of specificity was achieved with five neighbors. Our method was investigated together with other methods of machine learning and similar research, and the ROC curve was plotted, too. Other methods achieved suitable results as well, and they can be relied on. Therefore, we propose our approach based on the knearest algorithm together with pre-processing based on the Relief – F strategy and the Cross Fold data sampling as an efficient method in artificial intelligence with the purpose of data mining for the classification and differential diagnosis of diseases.",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6d8817916189e9c7a92e932800b11e53762c7fbc,https://www.semanticscholar.org/paper/6d8817916189e9c7a92e932800b11e53762c7fbc,Multisensor-Based Heavy Machine Faulty Identification Using Sparse Autoencoder-Based Feature Fusion and Deep Belief Network-Based Ensemble Learning,"Faulty identification plays a vital role in the area of prognostic and the health management (PHM) of the industrial equipment which offers great support to the maintenance strategy decision. Owing to the complexity of the machine internal component-system structure, the precise prediction of the heavy machine is hard to be obtained, thus full of uncertainty. Moreover, even for a single component, the feature representation of the acquired conditional monitoring signal can be different due to the different deployment of the sensor location and environmental inference, causing difficulty in feature selection and uncertainty in faulty identification. In order to improve the model identification reliability, a novel hybrid machine faulty identification approach based on sparse autoencoder- (SAE-) and deep belief network- (DBN-) based ensemble learning is proposed in this paper. First, six kinds of statistical features are extracted and normalized from multiple sensors monitoring the same target component. Second, the six extracted features are fused by the two-stage SAE proposed in this paper from the sensor dimension and feature dimension, respectively. The composite feature fused in the feature dimension is regarded as the comprehensive representation of the corresponding component. Finally, the fused features containing comprehensive representation of different components are utilized to predict the machine health condition by the ensemble of multiple deep belief classifiers. The effectiveness of the proposed method is validated by the two case studies of wind turbine gearbox and industrial port crane. The experimental result shows that the proposed ensemble learning approach outperforms other traditional deep learning approaches in terms of the prediction accuracy and the prediction stability when dealing with multisensor feature fusion and the precise faulty identification of the industrial heavy machine.",Journal of Sensors,2022.0,10.1155/2022/5796505,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ebf5ddd2e6c95e6fb3de3fdee07f3a2ec630a32a,https://www.semanticscholar.org/paper/ebf5ddd2e6c95e6fb3de3fdee07f3a2ec630a32a,Supervised machine learning for automated coding of websites: An exploratory pilot study of government hyperlink networks [Conference abstract],"In order to analyse the structure of hyperlink networks, researchers need to understand the type and nature of webpages or websites (i.e. nodes) that comprise such networks. Information such as generic top-level domain (e.g. com, org, gov) only provides ‘coarse-grained’ data about what these nodes are. However, social scientists often require more detailed information about the websites under analysis. Usually this involves manually labelling, or ‘coding’, nodes into categories, using techniques similar to textual or documentary analysis. However, the size and nature of hyperlink networks often makes this task quite time-consuming and costly. In this exploratory pilot study we investigate the use of supervised machine learning to automatically code websites in government hyperlink networks into discrete policy domains (e.g. health, education, environment). This involves extracting or ‘scraping’ text from the HTML of the sample websites in order to provide data for the algorithm to ‘learn’ from. Specifically, we deploy Support Vector Machines (SVMs) on a sample of websites already correctly categorised into policy domains by a human coder. The sample is then divided into a ‘training sample’ and a ‘test sample’; SVMs learn from websites in the training sample and are tasked with correctly predicting policy domains for websites in the test sample. Preliminary results indicate a surprising level of accuracy, with some policy domains correctly classified more than 90% of the time. This suggests that supervised machine learning may offer a powerful and useful tool for social science research involving large-scale analysis of websites, particularly where the categories of websites are discrete and fairly well-defined (e.g. policy domains in government hyperlink networks). Future work will investigate the validity and robustness of this methodology using a larger sample of data and other machine learning algorithms and techniques.",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
44f4b1b90f8d5515f2486e07e4cb4b9589c27518,https://www.semanticscholar.org/paper/44f4b1b90f8d5515f2486e07e4cb4b9589c27518,Deep Learning and Its Applications to Machine Health Monitoring: A Survey,"Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). Finally, some new trends of DL-based machine health monitoring methods are discussed.",ArXiv,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
77af999aab3940b53a0ebfeff6115eb290c55f2e,https://www.semanticscholar.org/paper/77af999aab3940b53a0ebfeff6115eb290c55f2e,Towards Putting Deep Learning on the Wrist for Accurate Human Activity Recognition,"The use of smart wearables enables regular monitoring of human activities, which can lower risks of health complications due to cardiovascular diseases, diabetes, etc. The signal data generated by the accelerometer and gyroscope of the inertial measurement unit (IMU) within wearables, aid in recognizing motion. In the past, researchers have used Signal Processing techniques for human activity recognition (HAR). However, these techniques are not adaptive to variations of the same activities in different people. Machine Learning and Deep Learning are comparatively adaptive to variations but require more computational power, especially Deep Learning. To circumvent high computational requirements, state-of-the-art solutions typically deploy the learning algorithms on a platform with more compute power such as a smartphone, or even Cloud. In this paper, we propose a classification model for HAR that outperforms state-of-the-art prediction accuracy on raw signal data and is suitable for deployment in resource-constrained environments of smart wearables and IoT devices.",2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),2021.0,10.1109/PerComWorkshops51409.2021.9430979,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
80d9270996611812bc071d9bf924f58cdaa90341,https://www.semanticscholar.org/paper/80d9270996611812bc071d9bf924f58cdaa90341,Performance of Machine Learning Classifiers for Indoor Person Localization With Capacitive Sensors,"Accurate tagless indoor person localization is important for several applications, such as assisted living and health monitoring. Machine learning (ML) classifiers can effectively mitigate sensor data variability and noise due to deployment-specific environmental conditions. In this paper, we use experimental data from a capacitive sensor-based indoor human localization system in a 3m  $\times3\text{m}$  room to comparatively analyze the performance of Weka collection ML classifiers. We compare the localization performance of the algorithms, its variation with the training set size, and the algorithm resource requirements for both training and inferring. The results show a large variance between algorithms, with the best accuracy, precision, and recall exceeding 93% and 0.05m average localization error.",IEEE Access,2017.0,10.1109/ACCESS.2017.2721538,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
970adc0c514bacabd7a6e25e6d6a4141b6fb8f08,https://www.semanticscholar.org/paper/970adc0c514bacabd7a6e25e6d6a4141b6fb8f08,"Prediction of In-hospital Mortality in Emergency Department Patients With Sepsis: A Local Big Data-Driven, Machine Learning Approach.","OBJECTIVES
Predictive analytics in emergency care has mostly been limited to the use of clinical decision rules (CDRs) in the form of simple heuristics and scoring systems. In the development of CDRs, limitations in analytic methods and concerns with usability have generally constrained models to a preselected small set of variables judged to be clinically relevant and to rules that are easily calculated. Furthermore, CDRs frequently suffer from questions of generalizability, take years to develop, and lack the ability to be updated as new information becomes available. Newer analytic and machine learning techniques capable of harnessing the large number of variables that are already available through electronic health records (EHRs) may better predict patient outcomes and facilitate automation and deployment within clinical decision support systems. In this proof-of-concept study, a local, big data-driven, machine learning approach is compared to existing CDRs and traditional analytic methods using the prediction of sepsis in-hospital mortality as the use case.


METHODS
This was a retrospective study of adult ED visits admitted to the hospital meeting criteria for sepsis from October 2013 to October 2014. Sepsis was defined as meeting criteria for systemic inflammatory response syndrome with an infectious admitting diagnosis in the ED. ED visits were randomly partitioned into an 80%/20% split for training and validation. A random forest model (machine learning approach) was constructed using over 500 clinical variables from data available within the EHRs of four hospitals to predict in-hospital mortality. The machine learning prediction model was then compared to a classification and regression tree (CART) model, logistic regression model, and previously developed prediction tools on the validation data set using area under the receiver operating characteristic curve (AUC) and chi-square statistics.


RESULTS
There were 5,278 visits among 4,676 unique patients who met criteria for sepsis. Of the 4,222 patients in the training group, 210 (5.0%) died during hospitalization, and of the 1,056 patients in the validation group, 50 (4.7%) died during hospitalization. The AUCs with 95% confidence intervals (CIs) for the different models were as follows: random forest model, 0.86 (95% CI = 0.82 to 0.90); CART model, 0.69 (95% CI = 0.62 to 0.77); logistic regression model, 0.76 (95% CI = 0.69 to 0.82); CURB-65, 0.73 (95% CI = 0.67 to 0.80); MEDS, 0.71 (95% CI = 0.63 to 0.77); and mREMS, 0.72 (95% CI = 0.65 to 0.79). The random forest model AUC was statistically different from all other models (p ≤ 0.003 for all comparisons).


CONCLUSIONS
In this proof-of-concept study, a local big data-driven, machine learning approach outperformed existing CDRs as well as traditional analytic techniques for predicting in-hospital mortality of ED patients with sepsis. Future research should prospectively evaluate the effectiveness of this approach and whether it translates into improved clinical outcomes for high-risk sepsis patients. The methods developed serve as an example of a new model for predictive analytics in emergency care that can be automated, applied to other clinical outcomes of interest, and deployed in EHRs to enable locally relevant clinical predictions.",Academic emergency medicine : official journal of the Society for Academic Emergency Medicine,2016.0,10.1111/acem.12876,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
199a5314a931db42ae4c4a52fcf191e407374784,https://www.semanticscholar.org/paper/199a5314a931db42ae4c4a52fcf191e407374784,Relevant framework for social applications of internet of things by means of machine learning techniques,"Los desarrollos recientes de las tecnologias inalambricas y el despliegue extendido de dispositivos distribuidos espacialmente con capacidades de identificacion, deteccion y actuacion integradas crearon la Internet de las cosas (IoT). Este paradigma prometedor se ha desarrollado de forma explosiva en los ultimos anos. Se cree que es la proxima tecnologia revolucionaria al llevar el Internet tradicional al ambito fisico. Miles de millones de cosas inteligentes interconectadas estan transmitiendo una gran cantidad de datos a cada momento y promocionando el mundo en la era del ”big data”. El valor potencial inimaginable se puede extraer de estos datos respaldados por tecnologias avanzadas como aprendizaje automatico y la computacion en la nube. Con la ayuda de herramientas avanzadas de mineria de datos, IoT puede aportar grandes beneficios para varios dominios de la sociedad, incluida la atencion de salud. La industria de la salud ha cambiado drasticamente debido a la revolucion de la tecnologia de la informacion que comenzo en el siglo pasado. Las tecnologias nuevas, como la telemedicina, el hospital digital y la atencion sanitaria electronica, se han aplicado ampliamente durante las ultimas decadas y ahora el rapido desarrollo de IoT y el aprendizaje automatico promueven la atencion de salud de digital a inteligente. Como un aspecto importante de IoT, la tecnologia portatil tambien ha mostrado un aumento rapido en la ultima decada. Se han introducido en el mercado diferentes tipos de dispositivos portatiles que contienen varios sensores integrados con precios asequibles. Estos dispositivos portatiles generan grandes cantidades de datos relacionados con la salud durante diferentes actividades diarias. Estos datos de bajo costo, respaldados por tecnicas de computacion movil y aprendizaje automatico, hacen posible el desarrollo de sistemas de soporte de decisiones inteligentes (SDSS) que pueden ser beneficiosos para el monitoreo de actividades a largo plazo, el diagnostico remoto de enfermedades y la promocion de alertas medicas de emergencia. Como una de las herramientas mas importantes para realizar la Inteligencia Artificial (IA), el aprendizaje automatico ha crecido de manera explosiva en las ultimas decadas con el desarrollo de Internet. Varias de las tecnicas de aprendizaje automatico se han utilizado ampliamente para implementar diferentes tareas de mineria de datos, entre las cuales, el aprendizaje profundo ha mostrado un rendimiento sobresaliente en los ultimos anos debido a la disponibilidad de “big data”. Nuestra investigacion tiene como objetivo abordar las aplicaciones de la tecnologia IoT respal dada por tecnicas avanzadas de aprendizaje automatico en diferentes areas sociales, especialmente en la atencion de salud. Se construyo un marco de aplicacion general, que incluye la recopilacion y transferencia de datos, el almacenamiento y el analisis de datos, y La entrega de resultados de analisis a los usuarios. Con el fin de verificar la viabilidad del marco de aplicacion propuesto, se desarrollo un sistema practico de recoleccion de datos de movimiento humano basado en tecnologia portatil. Incluye tres modulos: un reloj inteligente, un telefono inteligente y una NoSQL base de datos remota. El sistema se aplico en un hospital para recopilar datos de actividad diaria y temblor de pacientes con Temblor Esencial (ET). Se adoptaron tecnicas avanzadas de aprendizaje automatico, incluido el aprendizaje profundo, para realizar tareas de Reconocimiento de Actividad Humana (HAR) y evaluacion de ET. A traves del procesamiento adecuado y la transformacion de los datos, los modelos propuestos podrian reconocer una serie de actividades diarias humanas y clasificar los niveles de temblor con una alta precision. Estos modelos podrian permitir a los neurologos monitorear de forma remota y continua las actividades diarias de los pacientes con ET y la correspondiente situacion de temblor. El resultado de la evaluacion podria ayudarles a mejorar los planes de tratamiento. Este caso demostro la viabilidad del marco de aplicacion IoT presentado y otras aplicaciones similares podrian desarrollarse en otros escenarios. Como una de las futuras direcciones de investigacion, al final del estudio se propuso un sistema de intercambio de datos personales basado en la tecnologia blockchain. El objetivo es proteger la privacidad y la seguridad durante el proceso de intercambio de datos. ----------ABSTRACT---------- The recent adaptation of wireless technologies and the widespread deployment of spatially distributed devices with embedded identification, sensing and actuation capabilities created the Internet of Things (IoT). This promising paradigm has been developing explosively in recent years. It is believed to be the next revolutionary technology by bringing the traditional sense of Internet into the physical realm. Billions of inter-connected smart things are streaming out a huge amount of data every moment and promote the world into “big data” era. Unimaginable potential value can be mined from these data supported by advanced data storage and analysis technologies, such as machine learning and cloud computing. With the help of advanced data mining tools, IoT can bring great benefits for various domains of the society including healthcare. The healthcare industry has been dramatically changed because of the information technology revolution that started in the last century. New technologies such as telemedicine, digital hospital and e-health have been widely applied during the past decades and now the rapidly development of IoT and machine learning is promoting healthcare from digital into intelligent. As an important aspect of IoT, wearable technology has also shown a surge in the past decade. Different types of wearable devices containing various embedded sensors have been introduced into the market with affordable prices. Large amounts of health-related data are generated by these wearable devices related to different daily activities. These low-cost data, supported by mobile computing and machine learning techniques, make it possible to develop Smart Decision Support Systems (SDSS) which can be beneficial to the long-term activity monitoring, remote disease diagnosis, emergency medical alerts promoting and so on. As one of the most important tools to realize Artificial Intelligence (AI), machine learning has been growing explosively in the past decades with the development of Internet. Various of machine learning techniques have been widely used to implement different data mining tasks, among which, deep learning has shown outstanding performance in recent years due to the availability of big data. Our research aims to address the applications of IoT technology supported by advanced machine learning techniques in different social areas, especially in healthcare. A general application framework was constructed, which includes data collecting and transferring, data storage and analysis, and analysis result sharing. In order to verify the feasibility of proposed application framework, a practical human movement data collecting system was developed based on wearable technology. I t includes three modules: a smart watch, a smartphone and a remote NoSQL database. The system was applied in a hospital to collect daily activity and tremor data from patients with Essential Tremor (ET). Advanced machine learning techniques, including deep learning, were adopted to realize Human Activity Recognition (HAR) and ET evaluation tasks. Through proper data preprocessing and data transformation, based on the collected acceleration data, the proposed models could recognize a series of human daily activities and classify tremor levels with high accuracy. These models could enable neurologists remotely and continuously monitor ET patients’ daily activities and the corresponding tremor situation. The evaluation result could help them to improve the treatment plans. This case proved the feasibility of the presented IoT application framework and similar applications could be developed in other scenarios. As one of the future research directions, a personal health data sharing system based on blockchain technology was proposed in the end of the study. The aim is to protect the privacy and security during the data sharing process.",,2019.0,10.20868/upm.thesis.55328,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a7607686e3f9ceb8c4cc29334ad84a574fc88992,https://www.semanticscholar.org/paper/a7607686e3f9ceb8c4cc29334ad84a574fc88992,Hybrid machine learning algorithms for fault detection in android smartphones,"The newest trends with smart devices and the concept of Internet of Things (IoT) is that of big data and analytics. More recently, the concept of mobile cloud computing has emerged with advances in terms of hardware and communication speeds. However, there are serious implications on the normal lifetime of the battery‐powered smart devices being used for these different applications. Most sensors deployed for different smart IoT applications are already available in smart phones and used by the majority of individuals on a daily basis. With the recent explosions of the Samsung Galaxy Note 7 smartphones, safety of individuals has climbed the priority list in the IoT field. Along this line, it is important to address fault detection and prediction of smartphones, which are being used in fields such as mobile health. In this paper, a cloud‐based open‐source framework for capturing and processing real‐time streaming information (eg, screen brightness, CPU usage, battery level, voltage, device temperature, and Wi‐Fi signal strength) about different android‐based smartphones has been set up. A NoSQL Cassandra database is used and a Spark distributed computing Scala‐based framework accesses the data for further processing. Classification machine learning algorithms (Naïve‐Bayes (NB), decision tree (DT), and random forest) are used to obtain trained models for predicting symptoms of faulty behaviors in smartphones. The performance of a hybrid 2‐staged machine learning mechanism is proposed whereby cascaded classification algorithms are used. Results show that when using DT algorithm (Level 1) and NB algorithm (Level 2), a slight increase in percentage accuracy is observed. This demonstrates that there is the possibility for further improving the NB model for classification and fault detection when using a combined training model with DT algorithm (Level 1) and NB algorithm (Level 2). The results for the cascaded model show that the percentage accuracy of most hybrid models in this case are slightly inferior to the standalone models themselves. The hybrid models using the DT algorithm at both levels and DT algorithm followed by RF algorithm do not improve the percentage accuracy. However, this demonstrates that the robustness of the classification algorithm can be maintained with this type of hybrid classification algorithm and leaves room for further research of possible techniques and ways to improve the accuracy.",Trans. Emerg. Telecommun. Technol.,2018.0,10.1002/ett.3272,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
70109c86a44b07ab7079a64c54445ae4c9bcdf4e,https://www.semanticscholar.org/paper/70109c86a44b07ab7079a64c54445ae4c9bcdf4e,Application of Deep Learning for Fault Diagnostic in Induction Machine’s Bearings,"Recent developments in sensor technologies and advances in communication systems have resulted in deployment of a large number of sensors for collecting condition monitoring (CM) data in order to monitor health condition of a manufac-tring/industrial system. Efficient utilization of sensory data leads to highly accurate results in system fault diagnostics/prognostics. The exponential growth of CM data poses significant analytical challenges, due to their high variety, high dimensionality and high velocity rendering conventional health monitoring tools impractical. In this regard, the paper proposes a deep learning-based framework for fault diagnosis of an induction machine’s bearing based on real data set provided by Case Western Reserve University bearing data center. In particular, we focus on deep bidirectional long short-term memory (BiD-LSTM) networks fed with raw signals for fault diagnosis to address drawbacks of conventional machine learning (ML) solutions such as support vector machines. A numerical example is provided to illustrate the complete procedure of the proposed framework, which shows the great potentials of the BiD-LSTM for detection of different types of the bearing fault with high accuracy. The effectiveness of the proposed model is demonstrated through a comparison with a recently developed deep neural network (DNN) that considers temporal coherence for the same data set. The results indicate that the proposed framework provides considerably improved performance in comparison to its counterparts.",2019 IEEE International Conference on Prognostics and Health Management (ICPHM),2019.0,10.1109/ICPHM.2019.8819421,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
db8ed4bae4bd2ee1209570be653701333e689f8e,https://www.semanticscholar.org/paper/db8ed4bae4bd2ee1209570be653701333e689f8e,Economic Impact Analysis of Hospital Readmission Rate and Service Quality Using Machine Learning,"The hospital readmission rate has been proposed as an important outcome indicator computable from routine statistics. The purpose of this research is to investigate the Economic Impact of service in hospitals and integrated delivery networks in the United States based on the readmission rates as the target variable. The data set includes information from 130 hospitals and integrated delivery networks in the United States from 1999 to 2008 to investigate significance of different factors in readmission rate. The dataset contains 101,766 patients’ encounters and 50 variables. The 30-day readmission rate is considered as an indicator of the quality of the health providers and is used as target variable in this project. Preliminary data analysis shows that age, admission type, discharge disposition etc. is correlated to the readmission rate and will be incorporated for further data analysis. Data analysis are performed on the diabetic patient dataset to develop a classification model to predict the likelihood for a discharged patient to be readmitted within 30 days. KNN, Naive Bayes and Logistic Regression algorithm were used to classify data and KNN appears to be the best approach to develop the model. Hospitalisations and drug prescriptions accounted for 50% and 20% of total readmission expenditure, respectively. Long term nursing home care after hospital admission cost an additional £46.4 million. With the ability to identify those patients who are more likely to be readmitted within 30 days, we can deploy the hospital resources more economically affordable while improving services. Based on the results it can be concluded that the direct cost of readmission rate for hospitals rose to £459 million in 2000 and nursing home costs rose to £111 million. Also, it can be perceived that a reduced length of hospital stay was associated with increased readmission rates for jaundice and dehydration.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dd41dd74b46b4c6d38f0f1a2cb0435e479032701,https://www.semanticscholar.org/paper/dd41dd74b46b4c6d38f0f1a2cb0435e479032701,Reducing energy consumption of wireless sensor networks using rules and extreme learning machine algorithm,"Wireless sensor networks consist of a collection of sensors to monitor physical or environmental events. Nowadays, the sensor networks are used in important applications like military, health and civilian monitoring. Since it is a wireless medium, deployed in remote locations and resource-constrained nature, the sensor networks are easily vulnerable to attacks. The attack creates significant damages to the sensor networks. To avoid these problems, intrusion detection system (IDS) is implemented at the base station to filter any abnormal packets. In the proposed system, a survey is made on the attacks and rules to detect the attacks. Filtering the attacks using rule-based IDS at the sensor nodes would reduce the amount of packet transmission to the base station which, in turn, would reduce the energy consumption of the sensor network. Extreme learning machine (ELM) algorithm is implemented at the base station to detect the abnormal packets. The experimental result shows the performance of different classification techniques and cross-layer rules over the NSL-KDD and real-time datasets. The detection rate of the ELM algorithm is higher compared to other systems.",The Journal of Engineering,2019.0,10.1049/JOE.2018.5288,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
daf2b0d1c44f76b56430fa0dd80c9cb1de3b919d,https://www.semanticscholar.org/paper/daf2b0d1c44f76b56430fa0dd80c9cb1de3b919d,Machine Learning-Empowered Biometric Methods for Biomedicine Applications,"Nowadays, pervasive computing technologies are paving a promising way for advanced smart health applications. However, a key impediment faced by wide deployment of these assistive smart devices, is the increasing privacy and security issue, such as how to protect access to sensitive patient data in the health record. Focusing on this challenge, biometrics are attracting intense attention in terms of effective user identification to enable confidential health applications. In this paper, we take special interest in two bio-potential-based biometric modalities, electrocardiogram (ECG) and electroencephalogram (EEG), considering that they are both unique to individuals, and more reliable than token (identity card) and knowledge-based (username/password) methods. After extracting effective features in multiple domains from ECG/EEG signals, several advanced machine learning algorithms are introduced to perform the user identification task, including Neural Network, K-nearest Neighbor, Bagging, Random Forest and AdaBoost. Experimental results on two public ECG and EEG datasets show that ECG is a more robust biometric modality compared to EEG, leveraging a higher signal to noise ratio and also more distinguishable morphological patterns. Among different machine learning classifiers, the random forest greatly outperforms the others and owns an identification rate as high as 98%. This study is expected to demonstrate that properly selected biometric empowered by an effective machine learner owns a great potential, to enable confidential biomedicine applications in the era of smart digital health.",,2017.0,10.3934/MEDSCI.2017.3.274,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cd9c1d904fb6107cca5624a184b17fc49674092f,https://www.semanticscholar.org/paper/cd9c1d904fb6107cca5624a184b17fc49674092f,Machine Learning Based Crackle Detection in Lung Sounds,"Background and Objective: The stethoscope is a well-known and widely available diagnostic instrument. In recent years, many innovative solutions for recording and viewing sounds from a stethoscope have become available. However, to fully utilize such devices, there is a need for an automated approach for detecting abnormal lung sounds, which is better than the existing methods that typically have been developed and evaluated using a small and non-diverse dataset. Methods: We propose a machine learning based approach for detecting crackles in lung sounds recorded using a stethoscope in a large health survey. Our method is trained and evaluated using 209 files with crackles classified by expert listeners. Our analysis pipeline is based on features extracted from small windows in audio files. We evaluated several feature extraction methods and classifiers. We evaluated the pipeline using a training set of 175 crackle windows and 208 normal windows. We did 100 cycles of cross validation where we shuffled training sets between cycles. For all the division between training and evaluation was 70%-30%. Results: We found and evaluated a 5-dimenstional vector with four features from the time domain and one from the spectrum domain. We evaluated several classifiers and found SVM with a Radial Basis Function Kernel to perform best for our 5-dimensional feature vector. Our approach had a precision of 86% and recall of 84% for classifying a crackle in a window, which is more accurate than found in studies of health personnel. The low-dimensional feature vector makes the SVM very fast. The model can be trained on a regular computer in 1.44 seconds, and 319 crackles can be classified in 1.08 seconds. Conclusions: Our approach detects and visualizes individual crackles in recorded audio files. It is accurate, fast, and has low resource requirements. The approach is therefore well suited for deployment on smart devices and phones or as a web application. It can be used to train health personnel or as part of a smartphone application for Bluetooth stethoscopes.",ArXiv,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0981bdd2a18de7f4e13f6713c7f153f6c8c1cbb5,https://www.semanticscholar.org/paper/0981bdd2a18de7f4e13f6713c7f153f6c8c1cbb5,Post hoc support vector machine learning for impedimetric biosensors based on weak protein-ligand interactions.,"Impedimetric biosensors for measuring small molecules based on weak/transient interactions between bioreceptors and target analytes are a challenge for detection electronics, particularly in field studies or in the analysis of complex matrices. Protein-ligand binding sensors have enormous potential for biosensing, but achieving accuracy in complex solutions is a major challenge. There is a need for simple post hoc analytical tools that are not computationally expensive, yet provide near real time feedback on data derived from impedance spectra. Here, we show the use of a simple, open source support vector machine learning algorithm for analyzing impedimetric data in lieu of using equivalent circuit analysis. We demonstrate two different protein-based biosensors to show that the tool can be used for various applications. We conclude with a mobile phone-based demonstration focused on the measurement of acetone, an important biomarker related to the onset of diabetic ketoacidosis. In all conditions tested, the open source classifier was capable of performing as well as, or better, than the equivalent circuit analysis for characterizing weak/transient interactions between a model ligand (acetone) and a small chemosensory protein derived from the tsetse fly. In addition, the tool has a low computational requirement, facilitating use for mobile acquisition systems such as mobile phones. The protocol is deployed through Jupyter notebook (an open source computing environment available for mobile phone, tablet or computer use) and the code was written in Python. For each of the applications, we provide step-by-step instructions in English, Spanish, Mandarin and Portuguese to facilitate widespread use. All codes were based on scikit-learn, an open source software machine learning library in the Python language, and were processed in Jupyter notebook, an open-source web application for Python. The tool can easily be integrated with the mobile biosensor equipment for rapid detection, facilitating use by a broad range of impedimetric biosensor users. This post hoc analysis tool can serve as a launchpad for the convergence of nanobiosensors in planetary health monitoring applications based on mobile phone hardware.",The Analyst,2018.0,10.1039/c8an00065d,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5994ea254d8e60e9b240cf0c3824b3e5f40df85a,https://www.semanticscholar.org/paper/5994ea254d8e60e9b240cf0c3824b3e5f40df85a,Machine Learning for Indoor Localization Using Mobile Phone-Based Sensors,"In this paper we investigate the problem of localizing a mobile device based on readings from its embedded sensors utilizing machine learning methodologies. We consider a realworld environment, collect a large dataset of 3110 datapoints, and examine the performance of a substantial number of machine learning algorithms in localizing a mobile device. We have found algorithms that give a mean error as accurate as 0.76 meters, outperforming other indoor localization systems reported in the literature. We also propose a hybrid instance-based approach that results in a speed increase by a factor of ten with no loss of accuracy in a live deployment over standard instance-based methods, allowing for fast and accurate localization. Further, we determine how smaller datasets collected with less density affect accuracy of localization, important for use in real-world environments. Finally, we demonstrate that these approaches are appropriate for real-world deployment by evaluating their performance in an online, in-motion experiment.",ArXiv,2015.0,10.1109/CCNC.2016.7444919,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fbbee5da12c0e0f15813254b9ffca18e339d3546,https://www.semanticscholar.org/paper/fbbee5da12c0e0f15813254b9ffca18e339d3546,10 - Machine learning for future intelligent air quality networks,"During the last few years, machine learning emerged as a very effective tool for data analysis and sematic value extraction from the large amount of data generated from deployed chemical multisensors devices. Many works have now highlighted the potential impact on multisensor device calibration, drift counteraction, data assimilation, optimal deployment of these classes of algorithms. Unlike 5 years ago, the huge amount of available data make possible to confirm this potential on realworld long-term deployments. This work analyze the literature produced by EuNetAir partners extracting the lessons cooperatively learnt about their impact and propose a novel architecture for future intelligent air quality networks based on the machine learning emerging paradigm.",,2016.0,10.5162/6EuNetAir2016/10,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6c7068d1ae1c81166f5e114fad3160791640ad2a,https://www.semanticscholar.org/paper/6c7068d1ae1c81166f5e114fad3160791640ad2a,Deep Learning for Health Care in Disease Identification: A Review,,,2021.0,10.1007/978-981-33-6307-6_65,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3f651640ee316776fcdd160a64204588c865e324,https://www.semanticscholar.org/paper/3f651640ee316776fcdd160a64204588c865e324,Construction Productivity and Ergonomic Assessment Using Mobile Sensors and Machine Learning,"For a construction project to be on schedule and within budget, project managers must constantly monitor work progress, identify deviations from plans, and design a more efficient workplace. This often requires meticulous attention to how field tasks are conducted by workers over time. From a worker’s perspective, to be more productive may translate into carrying out tasks that exceed one’s natural physical limits. The sustained physical labor will result in work-related musculoskeletal disorders (WMSDs) which can adversely affect the project budget, schedule, and productivity. To prevent WMSDs, health and safety organizations have established rules and regulations which limit the duration and frequency of labor-intensive activities. Proper implementation of these standards requires that worker’s physical motions are constantly tracked. Monitoring workers’ activities serves a two-fold purpose: it provides information about the work progress, as well as help quantify the ergonomic risks associated with those activities. The complexity of activities, large number of workers, and psychological and physical barriers in the workplace make manual data collection very challenging. In this paper, the authors present and validate a model for remotely and unobtrusively monitor worker’s activities. The model deploys built-in smartphone sensors and machine learning algorithms to recognize worker’s activities in the field, and extract duration and frequency information, which will be ultimately used to evaluate productivity as well as ergonomic risks associated with each activity.",,2017.0,10.1061/9780784480847.054,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3d88647d8e8b280ae6d987546aac60a81395f4c2,https://www.semanticscholar.org/paper/3d88647d8e8b280ae6d987546aac60a81395f4c2,Machine learning and mHealth techniques to improve prognostication and clinical management of patients with Ebola virus disease,"Background The recent Ebola Virus Disease (EVD) outbreaks have revealed the need for field-deployable tools that can be adapted to the heterogeneous spectrum of the disease across widely varying environments and resources. We previously introduced an mHealth approach for EVD prognostication, where machine learning models were integrated into a mobile application (app) and could be updated with new data. Here, we build upon that approach by generating a new family of models derived from the largest published EVD dataset to date and validated on two independent datasets. These models were incorporated into an app, “Ebola Care Guidelines”, that calculates prognosis from the patient data available at triage. The app highlights the signs/symptoms with the largest contribution to the risk of death and provides simplified and targeted access to the recommended supportive care guidelines from WHO. Methods and Findings We generated multivariate logistic regression models from 470 patients admitted to five Ebola treatment units (ETUs) in Liberia and Sierra Leone during the 2014-16 outbreak. We handled missing data by multiple imputation and validated the models with two independent datasets from Sierra Leone. Consistent with previous results, viral load and age were the most important predictors of death. We found that observational wellness assessments by experienced health care providers have high predictive power and are able to explain most of the variation due to individual signs/symptoms. We generated a parsimonious model that included (in addition to viral load and age) body temperature, bleeding, jaundice, weakness, and confusion recorded during triage. We also constructed fallback models for when variables in the parsimonious model are unavailable. Conclusions This work shows how the integration of prognostic models with mHealth technology can create dynamic and rapidly deployable clinical management support tools that facilitate tailored access to large bodies of medical information. The Ebola Care Guidelines app was created with a novel clinical decision support framework to develop and update guidelines apps quickly as new data and models became available. The performance of the parsimonious model is very similar to that of the models including the wellness scale from experienced health care workers, suggesting that rigorous machine learning approaches can replicate experienced clinical intuition, and could thus be useful when such expertise is unavailable.",bioRxiv,2018.0,10.1101/294587,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
716d939c7dabe566721a4c2b4da04d08966e8a1e,https://www.semanticscholar.org/paper/716d939c7dabe566721a4c2b4da04d08966e8a1e,Machine learning algorithms for damage detection in structures under changing normal conditions,"Engineering structures have played an important role into societies across the years. A suitable management of such structures requires automated structural health monitoring (SHM) approaches to derive the actual condition of the system. Unfortunately, normal variations in structure dynamics, caused by operational and environmental conditions, can mask the existence of damage. In SHM, data normalization is referred as the process of filtering normal effects to provide a proper evaluation of structural health condition. In this context, the approaches based on principal component analysis and clustering have been successfully employed to model the normal condition, even when severe effects of varying factors impose difficulties to the damage detection. However, these traditional approaches imposes serious limitations to deployment in real-world monitoring campaigns, mainly due to the constraints related to data distribution and model parameters, as well as data normalization problems. This work aims to apply deep neural networks and propose a novel agglomerative cluster-based approach for data normalization and damage detection in an effort to overcome the limitations imposed by traditional methods. Regarding deep networks, the employment of new training algorithms provide models with high generalization capabilities, able to learn, at same time, linear and nonlinear influences. On the other hand, the novel cluster-based approach does not require any input parameter, as well as none data distribution assumptions are made, allowing its enforcement on a wide range of applications. The superiority of the proposed approaches over state-of-the-art ones is attested on standard data sets from monitoring systems installed on two bridges: the Z-24 Bridge and the Tamar Bridge. Both techniques revealed to have better data normalization and classification performance than the alternative ones in terms of false-positive and false-negative indications of damage, suggesting their applicability for real-world structural health monitoring scenarios.",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c6bde5c3b6b5bd9cc4c9de2be3a3c4ed48fe4e86,https://www.semanticscholar.org/paper/c6bde5c3b6b5bd9cc4c9de2be3a3c4ed48fe4e86,"Tambe , Developing the Science and Applications of Security Games : Machine Learning , Uncertainty and Preference Elicitation in Game Theory for Security","Having successfully founded the research area of security games, which has led to real-world applications in scheduling the deployment of limited resources (patrols, checkpoints, inspections, etc.), we now provide fundamental advances by incorporating machine learning to enhance realworld security applications, new models of opportunistic security games, robust methods for handling uncertainty, and novel techniques for preference elicitation techniques.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a161ea676d1aa5d571b24024e01d7b13cbd6bf9,https://www.semanticscholar.org/paper/3a161ea676d1aa5d571b24024e01d7b13cbd6bf9,Forecasting Future Asthma Hospital Encounters of Patients With Asthma in an Academic Health Care System: Predictive Model Development and Secondary Analysis Study,"Background Asthma affects a large proportion of the population and leads to many hospital encounters involving both hospitalizations and emergency department visits every year. To lower the number of such encounters, many health care systems and health plans deploy predictive models to prospectively identify patients at high risk and offer them care management services for preventive care. However, the previous models do not have sufficient accuracy for serving this purpose well. Embracing the modeling strategy of examining many candidate features, we built a new machine learning model to forecast future asthma hospital encounters of patients with asthma at Intermountain Healthcare, a nonacademic health care system. This model is more accurate than the previously published models. However, it is unclear how well our modeling strategy generalizes to academic health care systems, whose patient composition differs from that of Intermountain Healthcare. Objective This study aims to evaluate the generalizability of our modeling strategy to the University of Washington Medicine (UWM), an academic health care system. Methods All adult patients with asthma who visited UWM facilities between 2011 and 2018 served as the patient cohort. We considered 234 candidate features. Through a secondary analysis of 82,888 UWM data instances from 2011 to 2018, we built a machine learning model to forecast asthma hospital encounters of patients with asthma in the subsequent 12 months. Results Our UWM model yielded an area under the receiver operating characteristic curve (AUC) of 0.902. When placing the cutoff point for making binary classification at the top 10% (1464/14,644) of patients with asthma with the largest forecasted risk, our UWM model yielded an accuracy of 90.6% (13,268/14,644), a sensitivity of 70.2% (153/218), and a specificity of 90.91% (13,115/14,426). Conclusions Our modeling strategy showed excellent generalizability to the UWM, leading to a model with an AUC that is higher than all of the AUCs previously reported in the literature for forecasting asthma hospital encounters. After further optimization, our model could be used to facilitate the efficient and effective allocation of asthma care management resources to improve outcomes. International Registered Report Identifier (IRRID) RR2-10.2196/resprot.5039",Journal of medical Internet research,2021.0,10.2196/22796,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
272993bf5e5539b2e5efe18543cd51ada6ea1b6d,https://www.semanticscholar.org/paper/272993bf5e5539b2e5efe18543cd51ada6ea1b6d,Namatad: Inferring occupancy from building sensors using machine learning,"Driven by the need to improve efficiency, modern buildings are instrumented with numerous sensors to monitor utilization and regulate environmental conditions. While these sensor systems serve as valuable tools for managing the comfort and health of occupants, there is an increasing need to expand the deployment of sensors to provide additional insights. Because many of these desired insights have high temporal value, such as occupancy during emergency situations, such insights are needed in real time. However, augmenting buildings with new sensors is often expensive and requires a significant capital investment. In this paper, we propose and describe the real-time, streaming system called Namatad that we developed to infer insights from many sensors typical of Internet of Things (IoT) deployments. We evaluate the effectiveness of this platform by leveraging machine learning to infer new insights from environmental sensors within buildings. We describe how we built the components of our system leveraging several open source, streaming frameworks. We also describe how we ingest and aggregate from building sensors and sensing platforms, route data streams to appropriate models, and make predictions using machine learning techniques. Using our system, we have been able to predict the occupancy of rooms within a building on the University of Washington campus over the last three months, in real time, at accuracies of up to 95%.",2016 IEEE 3rd World Forum on Internet of Things (WF-IoT),2016.0,10.1109/WF-IoT.2016.7845462,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ce7e03fca58167771da6508f4d7732ef36029b0c,https://www.semanticscholar.org/paper/ce7e03fca58167771da6508f4d7732ef36029b0c,TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks,"We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation. We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input data We discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed.",KDD,2017.0,10.1145/3097983.3098171,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f030656c4441093852ca0ad0d533b156a7c8a884,https://www.semanticscholar.org/paper/f030656c4441093852ca0ad0d533b156a7c8a884,FedHome: Cloud-Edge Based Personalized Federated Learning for In-Home Health Monitoring,"In-home health monitoring has attracted great attention for the ageing population worldwide. With the abundant user health data accessed by Internet of Things (IoT) devices and recent development in machine learning, smart healthcare has seen many successful stories. However, existing approaches for in-home health monitoring do not pay sufficient attention to user data privacy and thus are far from being ready for large-scale practical deployment. In this paper, we propose FedHome, a novel cloud-edge based federated learning framework for in-home health monitoring, which learns a shared global model in the cloud from multiple homes at the network edges and achieves data privacy protection by keeping user data locally. To cope with the imbalanced and non-IID distribution inherent in user’s monitoring data, we design a generative convolutional autoencoder (GCAE), which aims to achieve accurate and personalized health monitoring by refining the model with a generated class-balanced dataset from user’s personal data. Besides, GCAE is lightweight to transfer between the cloud and edges, which is useful to reduce the communication cost of federated learning in FedHome. Extensive experiments based on realistic human activity recognition data traces corroborate that FedHome significantly outperforms existing widely-adopted methods.",IEEE Transactions on Mobile Computing,2020.0,10.1109/TMC.2020.3045266,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9f42200f061807ef530e5d72f09b442f96b6f435,https://www.semanticscholar.org/paper/9f42200f061807ef530e5d72f09b442f96b6f435,Assessment of crop insect damage using unmanned aerial systems: A machine learning approach,"Agricultural pests are responsible for millions of dollars in crop losses and management costs every year. In order to implement optimal site-specific treatments and reduce control costs, new methods to accurately monitor and assess pest damage need to be investigated. In this paper we explore the combination of unmanned aerial vehicles (UAV), remote sensing and machine learning techniques as a promising technology to address this challenge. The deployment of UAVs as a sensor platform is a rapidly growing field of study for biosecurity and precision agriculture applications. In this experiment, a data collection campaign is performed over a sorghum crop severely damaged by white grubs (Coleoptera: Scarabaeidae). The larvae of these scarab beetles feed on the roots of plants, which in turn impairs root exploration of the soil profile. In the field, crop health status could be classified according to three levels: bare soil where plants were decimated, transition zones of reduced plant density and healthy canopy areas. In this study, we describe the UAV platform deployed to collect high-resolution RGB imagery as well as the image processing pipeline implemented to create an orthoimage. An unsupervised machine learning approach is formulated in order to create a meaningful partition of the image into each of the crop levels. The aim of the approach is to simplify the image analysis step by minimizing user input requirements and avoiding the manual data labeling necessary in supervised learning approaches. The implemented algorithm is based on the K-means clustering algorithm. In order to control high-frequency components present in the feature space, a neighbourhood-oriented parameter is introduced by applying Gaussian convolution kernels prior to K-means. The outcome of this approach is a soft K-means algorithm similar to the EM algorithm for Gaussian mixture models. The results show the algorithm delivers decision boundaries that consistently classify the field into three clusters, one for each crop health level. The methodology presented in this paper represents a venue for further research towards automated crop damage assessments and biosecurity surveillance.",,2015.0,10.36334/modsim.2015.f12.puig,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
335bbb7e11c30febecdf4224ab41cb781d3b312d,https://www.semanticscholar.org/paper/335bbb7e11c30febecdf4224ab41cb781d3b312d,ACTIVITY RECOGNITION USING MACHINE LEARNING TECHNIQUES FOR SMART HOME ASSISTED LIVING.,"The statistical survey by United Nations Department of Economic and Social Affairs/Population Division says, ""globally the number of persons aged 60 and above is expected to be more than double by 2050 and more than triple by 2100"". Especially in India, 9.5 percent of the population comprises of elders above 60 years. This may reach 22.2 
percent in 2050 and 44.4 percent in 2100. On one side, the population of elders are gradually increasing and on the other side there is a challenge to take care of the wellbeing of the elders when they are living alone. Smart home assisted living system can address these problems. Smart Home Assisted living System is one among the growing research areas in smart computing. Advances in sensing, communication and ambient intelligence technologies created tremendous change in smart living environment. The development in technology made smart home to support elders, disabled persons and the needy person. Activity recognition is a growing technology in recent research and it plays a vital role in smart home assisted living system. Activity 
Recognition is a more dynamic, interesting, and challenging research topic in different areas like Ubiquitous Computing, Smart Home Assisted Living, Human Computer Interaction (HIC) etc. It provides solution to various real-time, human-oriented problems like elder care and health care. In order to address the issue on providing support on elder care this 
research proposes a machine learning based activity recognition model and an enhanced communication protocol for a smart home system, which are collaborated for designing the architecture of a smart home assisted living system. This system consists of three sub phases viz., data 
acquisition, monitoring system, and tracking system. For evaluating the feasibility of the proposed architecture, a real smart home environment is deployed with the help of ShiB010 kit provided by CASAS project, Washington State University, USA. A new segmentation technique viz., 
Area-Based segmentation is proposed and implemented for segmentation of activities detected during the tracking the activities of the resident of smart home. The accuracy of the proposed segmentation approach is measured using different performance measures. In order to assess the 
performance of the proposed segmentation technique, two well-known segmentation techniques, viz., Activity-Based Segmentation and TimeBased segmentation are also implemented. Performance of the proposed, Area-Based Segmentation approach is compared with the performance of 
the other two approaches. It is observed that the proposed segmentation technique demonstrates a commendable level of accuracy and its performance is comparable or even better than the other two techniques. To check the compatibility of proposed Area-Based Segmentation on other smart homes, three more data sets which are available in public domain are also used. The comparative results are explained in detail. As 
a part of data acquisition, smart home network communication protocol, transfer the sensed data to the monitoring system. An energy efficient communication protocol Ad-LEACH is proposed and simulated for energy efficiency in the smart home network. The result is compared with the base protocol LEACH.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
391b2be635a236632a4d8e1dc6a2dcbf41e32d1d,https://www.semanticscholar.org/paper/391b2be635a236632a4d8e1dc6a2dcbf41e32d1d,Automating Crop Damage Assessments with Unmanned Aerial Systems and Machine Learning,"Agricultural pests are responsible for millions of dollars in crop losses and management costs every year. In order to implement optimal site-specific treatments and reduce control costs, new methods to accurately monitor and assess pest damage need to be investigated. In this paper we explore the combination of unmanned aerial vehicles (UAV), remote sensing and machine learning techniques as a promising methodology to address this challenge. The deployment of UAVs as a sensor platform is a rapidly growing field of study for biosecurity and precision agriculture applications. In this experiment, a data collection campaign is performed over a sorghum crop severely damaged by white grubs (Coleoptera: Scarabaeidae). The larvae of these scarab beetles feed on the roots of plants, which in turn impairs root exploration of the soil profile. In the field, crop health status could be classified according to three levels: bare soil where plants were decimated, transition zones of reduced plant density and healthy canopy areas. In this study, we describe the UAV platform deployed to collect high-resolution RGB imagery as well as the image processing pipeline implemented to create an orthoimage. An unsupervised machine learning approach is formulated in order to create a meaningful partition of the image into each of the crop levels. The aim of this approach is to simplify the image analysis step by minimizing user input requirements and avoiding the manual data labelling necessary in supervised learning approaches. The implemented algorithm is based on the K-means clustering algorithm. In order to control high-frequency components present in the feature space, a neighbourhood-oriented parameter is introduced by applying Gaussian convolution kernels prior to K-means clustering. The results show the algorithm delivers consistent decision boundaries that classify the field into three clusters, one for each crop health level as shown in Figure 1. The methodology presented in this paper represents a venue for further esearch towards automated crop damage assessments and biosecurity surveillance.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
507c98559f1eb28a233f48328d87502c60c894ff,https://www.semanticscholar.org/paper/507c98559f1eb28a233f48328d87502c60c894ff,Machine Learning for Predictive Maintenance in Aviation,"The increase of available data in almost every domain raises the necessity of employing algorithms for automated data analysis. This necessity is highlighted in predictive maintenance, where the ultimate objective is to predict failures of hardware components by continuously observing their status, in order to plan maintenance actions well in advance. These observations are generated by monitoring systems usually in the form of time series and event logs and cover the lifespan of the corresponding components. Analyzing this history of observation in order to develop predictive models is the main challenge of data driven predictive maintenance.Towards this direction, Machine Learning has become ubiquitous since it provides the means of extracting knowledge from a variety of data sources with the minimum human intervention. The goal of this dissertation is to study and address challenging problems in aviation related to predicting failures of components on-board. The amount of data related to the operation of aircraft is enormous and therefore, scalability is a key requirement in every proposed approach.This dissertation is divided in three main parts that correspond to the different data sources that we encountered during our work. In the first part, we targeted the problem of predicting system failures, given the history of Post Flight Reports. We proposed a regression-based approach preceded by a meticulous formulation and data pre-processing/transformation. Our method approximates the risk of failure with a scalable solution, deployed in a cluster environment both in training and testing. To our knowledge, there is no available method for tackling this problem until the time this thesis was written.The second part consists analyzing logbook data, which consist of text describing aircraft issues and the corresponding maintenance actions and it is written by maintenance engineers. The logbook contains information that is not reflected in the post-flight reports and it is very essential in several applications, including failure prediction. However, since the logbook contains text written by humans, it contains a lot of noise that needs to be removed in order to extract useful information. We tackled this problem by proposing an approach based on vector representations of words (or word embeddings). Our approach exploits semantic similarities of words, learned by neural networks that generated the vector representations, in order to identify and correct spelling mistakes and abbreviations. Finally, important keywords are extracted using Part of Speech Tagging.In the third part, we tackled the problem of assessing the health of components on-board using sensor measurements. In the cases under consideration, the condition of the component is assessed by the magnitude of the sensor's fluctuation and a monotonically increasing trend. In our approach, we formulated a time series decomposition problem in order to separate the fluctuation from the trend by solving a convex program. To quantify the condition of the component, we compute a risk function which measures the sensor's deviation from it's normal behavior, which is learned using Gaussian Mixture Models.",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e1ee319f2a107cd9df6387879c1b7d3b27df47b8,https://www.semanticscholar.org/paper/e1ee319f2a107cd9df6387879c1b7d3b27df47b8,Machine Learning and Sepsis: On the Road to Revolution.,"1946 www.ccmjournal.org November 2017 • Volume 45 • Number 11 With each passing day, the drumbeat of the advancing Big Data and machine learning revolution grows louder (1). Already having conquered previously intractable tasks like interpreting complex images or voices, driving autonomous vehicles, and winning abstract strategy games, computationally driven advances are producing disruptions across a wide swath of industries. These advances have arisen from a confluence of three major trends: rapid expansions in the availability of large-scale data, exponential increases in the accessibility of computational power, and critical progress in machine learning methods. Naturally, many see healthcare as the next major industry ripe for innovation. And, as the National Academy of Medicine has highlighted in numerous landmark reports, advances in the use of data and information technology will be critically important for addressing systemic failures in U.S. healthcare quality, safety, and value (2). In particular, recent successes in clinical image recognition and ongoing advances in leveraging largescale omics data highlight the great promise of machine learning applications in the biomedical and healthcare enterprise (3, 4). In this issue of Critical Care Medicine, Churpek et al (5) further expand on the promise of machine learning approaches in sepsis: the single most common, costly, and deadly cause of U.S. hospitalization. Extending their prior work in developing and validating the electronic Cardiac Arrest Risk Triage (eCART) score among hospitalized ward patients—the score incorporates granular vital signs, laboratory values, and patient demographics extracted from electronic medical records data (6)—they demonstrate that eCART scores uniformly provided the highest discrimination among inpatients with varying degrees of “suspected infection” for predicting a composite adverse outcome of ICU transfer or death within 48 hours. As is critical for innovation in this domain, their work capitalized on a large and highly granular dataset including greater than 53,000 infected patients as well as access to the computational resources needed to develop and deploy a random forest-based machine learning approach to score development and determination. Yet, even while the drumbeat of the machine learning revolution portends great promise, it is also accompanied by potential pitfalls (7, 8). In this case, the discrimination of the eCART score was uniformly better than all other risk scores (median C-statistic, 0.73); however, it was only modestly better than the seven-element, vital sign–based National Early Warning Score (NEWS) (median C-statistic, 0.71). Thus, although the eCART was statistically superior to the NEWS, it remains unclear what the clinical impact of this advantage would be particularly since the eCART score also demonstrated modestly lower specificity in some scenarios. Additionally, the comparisons of the eCART versus other scores were repeated in a sample drawn from the same setting in which the score was derived. Whether eCART shows better performance in external validation cohorts remains unclear. Beyond the statistical development of early warning scores, another major challenge remains identifying the appropriate interventions that should follow a high-risk alert. In a randomized trial deploying a real-time early warning score with excellent discrimination, Kollef et al (9) found that the transmitted alerts in the intervention arm neither decreased mortality nor increased the rate of ICU transfers. The alerts did result in a shorter overall hospital length of stay. Given the impressive performance characteristics of the eCART score, we look forward to a comprehensive evaluation of its impact on clinical outcomes and, in particular, a detailed description of the efferent intervention arm. This will greatly improve our understanding of which elements of implementation are most likely to drive improved outcomes. Finally, Churpek et al (5) found that eCART performance remained consistent even as the inclusion cohort criteria varied from minimal evidence of suspected infection (i.e., any culture ordered) to considerably stronger evidence (i.e., blood culture orders and IV antibiotics for at least 4 of 7 living d). Their findings confirm that the predictors conferring prognostic risk (i.e., Copyright © 2017 by the Society of Critical Care Medicine and Wolters Kluwer Health, Inc. All Rights Reserved. DOI: 10.1097/CCM.0000000000002673 *See also p. 1805.",Critical care medicine,2017.0,10.1097/CCM.0000000000002673,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
362edc0f31ca39ad58d473a3872715a04fe516ed,https://www.semanticscholar.org/paper/362edc0f31ca39ad58d473a3872715a04fe516ed,Fair Policy Learning,"Ensuring machine learning algorithms deployed in the real world do not result in unexpected unfairness or social implications is becoming increasingly important. However, there exists a clear gap in literature for a measure of fairness that can detect discrimination against multiple sensitive attributes while also handling continuous or discrete outcomes. In this thesis, we propose a fairness measure, Fair-COCCO, based on the conditional cross-covariance operator on reproducing kernel Hilbert Spaces. This novel method generalise to the majority of existing fairness notions and naturally extends to settings with continuous outcomes and multidimensional sensitive attributes. Additionally, we demonstrate how the proposed measure can be readily implemented in stochastic gradient optimisation for fair policy learning in supervised learning settings. Empirical evaluations of Fair-COCCO on synthetic and realworld experiments reveal favourable comparisons to state-of-the-art techniques in balancing predictive power and fairness. We also see much potential in applying machine learning to analyse fairness in observed behaviour, especially in complex and high-dimensional real-world environments. To that end, we propose the first known definition of fairness for sequences of decisions and showcase how Fair-COCCO can be applied to quantify fairness in these problems. Building off these definitions, we turn to learning fair policies in real-world conditions, where learning is constrained to be performed offline. We propose Fair-PoLe, a novel inverse reinforcement learning that operates completely offline and is computationally efficient and functionally expressive when compared to existing methods. We illustrate the potential for Fair-PoLe to learn policies that balance imitation of expert policies with fair outcomes on the challenging problem of sepsis treatment.",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
257369cd397764d8399c1637b94d321035c89faf,https://www.semanticscholar.org/paper/257369cd397764d8399c1637b94d321035c89faf,Deep Learning Techniques for Electronic Health Record (EHR) Analysis,,,2020.0,10.1007/978-981-15-5495-7_5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8522bc9fa5df8c1d69642a2302d07858b0c3c055,https://www.semanticscholar.org/paper/8522bc9fa5df8c1d69642a2302d07858b0c3c055,Evaluation of the Deep Learning-Based m-Health Application Using Mobile App Development and Assessment Guide,"Diabetes mellitus is known as one of the fatal diseases and affects a large number of people all throughout the world. Apparently, a timely diagnosis of the condition is very important for effective treatment. A deep learning algorithm, which is a subset of machine learning, was utilized to predict diabetes mellitus. The predicting model with a 93% accuracy was deployed in the mobile-health (m-health) application called DMChecker. Nowadays, m-health solutions have evolved at an exponential rate with absolutely little oversight or regulation. Thus, the main purpose of this study was to evaluate the quality of the designs and development of the m-health application using a mobile app development and assessment guide or MAG. With a 4.68 overall weighted mean from the perceptions of the evaluators, the m-health application complied and addressed mostly the standard regulations.",2022 IEEE 12th Annual Computing and Communication Workshop and Conference (CCWC),2022.0,10.1109/CCWC54503.2022.9720892,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cae308b7d0aa371781ca3ec8d58e0c7725f0edb2,https://www.semanticscholar.org/paper/cae308b7d0aa371781ca3ec8d58e0c7725f0edb2,Machine Learning to Scale Fault Detection in Smart Energy Generation and Building Systems,"Author(s): Hu, Rong Lily | Advisor(s): Agogino, Agogino M; Auslander, David M | Abstract: Data-driven techniques that extract insights from sensor data reduce the cost of improving system energy performance through fault detection and system health monitoring. To lower cost barriers to widespread deployment, a methodology is proposed that takes advantage of existing sensor data, encodes expert knowledge about the application system, and applies statistical and mathematical methods to reduce the time required for manual configurations. Renewable energy technologies as well as building energy management systems have upwards of hundreds of existing sensor data points used for control and monitoring. Furthermore, innovations in ""Internet of Things"" (IoT) devices have further led to connected power meters, lights, occupancy sensors, and appliances that are capable of data collection and communication. This data presents a valuable opportunity to extract meaningful information and take data-driven action. The motivation for transforming data from these devices into actionable information is to improve operations, monitor system health, increase energy generation, and decrease energy waste. The development and widespread use of energy conservation and renewable energy technologies are critical to minimizing negative environmental consequences. To that end, increasing profitability for users and decreasing costs of these technologies enables market penetration and widespread adoption. On the energy generation side, operations and maintenance accounts for up to 30% of the cost of wind generation, and unexpected failures on a wind turbine can be extremely expensive. On the energy demand side, commercial buildings consume 19% of US primary energy. Of this, an estimated 15\% to 30% of energy used in commercial buildings is wasted by poorly maintained, degraded, and improperly controlled equipment. However, one cannot achieve scalable deployments of analytics and applications across systems if deploying solutions requires vendors and domain experts to install sensors and information technology infrastructures that require tailoring each solution for each deployment. Today, even well-established commercial offerings are not deployed at scale because costs are prohibitive. Thus, a major challenge to scalability is reducing hardware and software installation costs, manual configuration requirements, and manual monitoring. To address this challenge, a methodology is proposed that leverages machine learning techniques to configure automated fault detection systems and controls. The approach combines sensor data points and encodes engineering knowledge that is generic to the application system but independent of a particular deployment. The resulting data can be input into numerous machine learning and optimization algorithms. Furthermore, the procedure selects data points and demonstrates that only a small number of sensors are necessary for fault detection with high accuracy rates. Applications to a wind turbine, a commercial building chiller plant, and residential buildings demonstrate the proposed methodology. Implementation is possible and the results are realizable using off-the-shelf algorithms, libraries, and tools. The goal is to enable an application that can be written once and then widely deployed with little additional cost or effort. The results of analysis can also inform policy decisions for stakeholders.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
daa235fd8059ac47d8288ae6e1d2ecd81c525ce9,https://www.semanticscholar.org/paper/daa235fd8059ac47d8288ae6e1d2ecd81c525ce9,Identifying Opioid and Illicit Drug Use from Adverse Event Reported Outcomes Using Machine Learning,"Earlier identification of opioid and illicit drug use may be used as a powerful tool for better guiding treatment strategies as well as appropriate triage of suspected illicit drug overdose patients. In this study, a machine learning model was used to distinguish patient drug use based solely on reported physiological events. For training and testing sets, data were derived from AEOLUS, a database of curated adverse drug reports based on the US Food and Drug Administration (FDA) Adverse Event Reporting System. Google’s TensorFlow library was used to build, train, and test the linear regression model. The positive results of this study suggest that machine learning approaches can be used to identify drugs based on reported outcomes. Introduction Toxicology screening with patient urine and blood samples has become a standard of care for patients suspected of illicit or opioid drug use [1]. Absent essential information about whether illicit or opioid drugs are involved in the manifestation of symptoms can lead to challenges in developing strategies for patient treatment. Improvements in rapidly identifying illicit drugs and opioids based on presentation of symptoms have the potential to change practice patterns, especially in acute care environments. The steady increase in drug overdose deaths since the 2000s[2] therefore calls for improved drug screening methods in the clinical setting. In emergency situations, rapid detection of exact prescription or illicit drug use can be crucial for determining proper care delivery. The availability of drug adverse event reporting provides an opportunity to build predictive models for detection of drug use. This study uses data from the US Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS), a database containing quarterly reports on adverse event and medication error reports submitted to FDA [3]. In the FAERS dataset, combinations of drugs are reported with combinations of resulting adverse outcomes [3], providing information linking drugs with certain physiological effects. Combined with current machine learning techniques, this information can be used to create algorithms correlating certain physiological factors with known drug outcomes. These correlations can then be used to construct predictive algorithms that determine drug use. Machine learning involves the use of data to create predictive models that can learn and improve without the aid of explicit programming. Two steps are involved in the creation of a machine learning algorithm: (1) training and (2) testing. Training involves performing statistics iteratively on a set of data until the predictions made by the model reach a certain level of accuracy. Afterwards, testing is done to further improve the model and determine the final accuracy. Machine learning techniques have been used previously in clinical settings to improve viral testing [4], graft failure prediction [5], and clinical decision making for breast cancer drug therapies[6]. Given the breadth of clinical data available, machine learning provides techniques to standardize and improve clinical care. In this study, machine learning techniques were used to explore the potential to identify opioid and illicit drug intake based on electronically captured FAERS data. Opioids and illicit drugs were tested specifically given the rise in illicit drug and opioid overdose cases nationwide[7], making drug detection increasingly important in the clinical setting. Utilizing machine learning tools provided for by TensorFlow[8], Google’s machine learning library, the goal of this study was to explore the potential to develop a predictive modeling system that does not require full patient history and makes classifications based on a patient’s current physiological state. Specific focus of this study was on four commonly prescribed opioids: (1) oxycodone; (2) hydrocodone; (3) fentanyl; and (4) morphine and three commonly abused drugs: (1) cocaine; (2) heroine; and (3) methamphetamine. The promising findings suggest that the machine learning approach employed in this study can indeed be used to rapidly identify individuals who may be at high risk of illicit or opioid drug use. Materials and Methods FAERS The FDA Adverse Event Reporting System (FAERS) is a database containing information on adverse event and medication error reports submitted to the FDA [3]. Event reports are submitted quarterly by health professionals and consumers and evaluated by clinical reviewers in the Center for Drug Evaluation and Research. Information is presented as reports stating all drugs taken by patients followed by all outcomes presented. No causal links are recorded between product and outcome. Using FAERS for mining drug-effect associations has been an active area of research and multiple data mining algorithms have been created for this purpose [9-11]. To date, there has been no reported use of predictive machine learning models for determining possible drugs based upon given events. AEOLUS From the community efforts of the Observational Health Data Science and Informatics (OHDSI) initiative, the FAERS and LAERS (Legacy Adverse Event Reporting System, which contains adverse event reports before 2012) datasets were reprocessed, cleaned, and standardized to form the Adverse Event Open Learning through Universal Standard (AEOLUS) database[15]. Single missing value imputation was first performed followed by case de-duplication. Every case was then given a primaryid or isr number, which indicate FAERS or LAERS cases respectively. Linked to each case are reported outcomes, given in OHDSI outcome concepts, and associated drugs, standardized to RxNorm Concept Unique Identifiers. Data are organized in AEOLUS into seven different MySQL tables, two of which were used in this study: one listing case ids with reported outcome concept ids and another listing case ids with standard drug concept ids. There were a total of 4245 distinct drug IDs and 17,710 distinct outcome IDs. y = Wx + b drug = W ∗ event + b Figure 1: Overview of linear regression model employed by TensorFlow. en represents event n and dm represents drug m. Wm,n represents the weight multiplied to event n for drug m and bm represents the bias for drug m. The bottom half of the figure shows the resulting matrix multiplication. Machine Learning Model A linear regression model, similar to that employed with the Mixed National Institute of Standards and Technology (MNIST), was used for training and testing. MNIST is a large database of handwritten digits that have been subjected to various machine learning methods to identify systems or approaches that achieve near-human performance. The model follows a y=Wx+b equation (Figure 1), with drugs as the dependent variable and physiological events as the independent variable. The linear model also accounted for biases (b) and contained a matrix for weights (W). The drugs and outcomes were given Boolean 0 or 1 values depending on if the drug or outcome was present in the tested case (Figure 2). For example, following Figure 1, e1 would be a Boolean for the presence of event A and would be 0 or 1 depending on if event A was present in the test case. d1 would be a Boolean for the presence of drug B and would be 0 or 1 depending on if drug B was present in the test case. W1,1 is the weight multiplied to e1 for the calculation of the probability d1 was present (Figure 1). In this study, this was implemented using TensorFlow, which is Google’s open-source software for deep neural networks, and provides a platform for accurate, large-scale machine learning research [8]. In TensorFlow, the data are vectorized into tensors and used to construct a data-flow graph. The graph is altered as more training data are deployed, adjusting the weights of the neural network with each iteration. In this study, TensorFlow was used to follow this machine learning model, iteratively adjusting weights and biases using softmax regression and loss functions. Conditions Tested This study focused on evaluating the ability to develop a prediction model using TensorFlow for effectiveness in classifying based on drug class, identifying the presence of specific drugs, and distinguishing between individual drugs. For drug class, opioids were chosen given the rising opioid epidemic [7] and four commonly prescribed opioids were specifically analyzed: (1) oxycodone; (2) hydrocodone; (3) fentanyl; and (4) morphine. For individual drug identification, three of the most common illicit drugs reported in AEOLUS were used: (1) cocaine, (2) methamphetamine, and (3) heroin. Evaluation of the model thus came from three tested conditions: (1) classification of opioid versus non-opioid; (2) prediction of illicit drug presence versus absence; (3) identification between different illicit drugs. Developing Outcome and Drug Arrays Arrays of Outcomes and Drugs were generated based on cases reported in AEOLUS. For identifying opioids, the total set of outcomes considered was narrowed down to the 35 outcomes with the highest numbers of cases. In other words, each drug-associated outcome was required to occur in a certain number of cases for each drug, and only the 35 outcomes with the highest number of cases were selected for the final outcome array (Table 1). For illicit drugs, the 20 outcomes with the highest number of cases for each illicit drug were used given the smaller number of total outcomes for illicit drugs (Table 2). Given some of the outcomes coded in the AEOLUS dataset were non-physiological, another round of testing was performed removing all non-physiological outcomes and all cases containing only non-physiological outcomes for the illicit drugs. The twenty highest physiological outcomes with the highest number of cases were used for the outcome arrays. The differences in outcome are shown in Table 3. A total of 5000 cases were used as training and test cases for each condition tested except for the between drug",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
28ef41c66703245607fbd00c9ce975b182712c30,https://www.semanticscholar.org/paper/28ef41c66703245607fbd00c9ce975b182712c30,"Vironix: A Machine-Learned Approach to Remote Screening, Surveillance, and Triage of Viral Respiratory Illness","RATIONALE The Covid-19 pandemic has posed a serious, ongoing global health challenge. The United States has been the worst affected, with more than 11M confirmed cases and 246K deaths (as of November 2020). Two primary and persisting concerns are the continued necessity for shutdown/isolation and the possibility of singular waves of rapid virus spread that could overwhelm global healthcare systems, resulting in preventable mortality and substantial economic burden. While vaccines are being developed and disseminated, the need for remote patient care has never been more critical. To that end, we developed a Covid-19 remote triage software, Vironix, which uses machine-learning algorithms to enable real-time risk stratification and decision support for users. This remote management approach has significant potential to increase safety, improve health outcomes, and stem virus spread as organizations reopen. METHODS Vironix uses personalized machine-learning algorithms trained off clinical characteristic data from the EU, East Asia, and the USA in tandem with prescribed guidelines from the CDC, WHO, and Zhejiang University's handbook on Covid-19 prevention. Clinical characteristics of thousands of patients in the literature were mapped into patient vignettes using Bayesian inference. Subsequent stacked, ensemble decision tree classifiers were trained on these vignettes to classify severity of presenting symptoms and signs. Crucially, the algorithm continuously learns from ongoing use of the application, strengthening decisions, and adapting decision boundaries based on inputted information. Vironix was deployed using a user-friendly API, allowing users to easily screen themselves and obtain remote decision support through a variety of devices (mobile apps, computers, health monitors, etc).RESULTS Algorithm performance was assessed based on its binary classification performance in an out-of-sample test set including severe and nonsevere labels. Vironix correctly assigned the severity classes with an accuracy of 87.6%. Vironix further demonstrated superior specificity (87.8%) and sensitivity (85.5%) in identifying positive (severe) presentations of Covid-19. The algorithms, deployed behind the Vironix Web Application, have been invoked by tens of thousands of users around the world. CONCLUSION 1. The Vironix approach is a highly novel, generalizable methodology for mapping clinical characteristic data into patient scenarios for the purpose of training machine-learning prediction models to detect health deterioration due to viral illness. 2. Vironix exhibits excellent accuracy, sensitivity, and specificity in identifying and triaging clinical presentations of Covid-19 and the most appropriate level of medical urgency. 3. Algorithms continuously learn and improve decision boundaries as individual user input increases. .","TP20. TP020 TELEHEALTH AND REMOTE MONITORING FOR PULMONARY, CRITICAL CARE, AND SLEEP",2021.0,10.1164/ajrccm-conference.2021.203.1_meetingabstracts.a1719,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
857fe79fc09fc632495546f4d0543aed7ddb798e,https://www.semanticscholar.org/paper/857fe79fc09fc632495546f4d0543aed7ddb798e,Wireless Sensor Network for Distributed Event Detection Based on Machine Learning,"Pipelines are one of the most widely used means for oil/gas and water transportation worldwide. These pipelines are often subject to failures like erosion, sabotage and theft, causing high financial, environmental and health risks. Therefore, detecting leakages, estimating its size and location is very important. Current pipeline monitoring systems needs to be more automated, efficient and accurate methods for continuous inspection/reporting about faults. For this purpose, several pattern recognition and data mining techniques have been brought into the research community. In light of the issues of low efficiency and high false alarm rates in traditional pipeline condition monitoring, in this paper, we have used negative pressure wave (NPW) coupled with intelligent machine learning techniques integrated in distributed wireless sensor network (WSN) to identify specific events beased on raw data gathered by individual sensor nodes. This collaborative approach reduces communication overhead to minimum by processing raw data on sensor nodes directly and reporting the detected events only. We apply the methods of support vector machine (SVM), K-nearest neighbor (KNN) and Gaussian mixture model (GMM) in multi-dimensional feature space. The suggested technique is validated using a serial publication of experimentation on a field deployed test bed, with regard to performance of detection of leakages in pipelines.","2014 IEEE International Conference on Internet of Things(iThings), and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom)",2014.0,10.1109/iThings.2014.93,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3974cfe7f0032f58b04e975a0f1f5123f852d0af,https://www.semanticscholar.org/paper/3974cfe7f0032f58b04e975a0f1f5123f852d0af,Mobile Machine Learning for Real-time Predictive Monitoring of Cardiovascular Disease,"Chronic cardiovascular disease (CVD) is increasingly becoming a burden for global healthcare systems. This burden can be attributed in part to traditional methods of managing CVD in an aging population that involves periodic meetings between the patient and their healthcare provider. There is growing interest in developing continuous monitoring systems to assist in the management of CVD. Monitoring systems can utilize advances in wearable devices and health records, which provides minimally invasive methods to monitor a patient’s health. Despite these advances, the algorithms deployed to automatically analyze the wearable sensor and health data is considered too computationally expensive to run on the mobile device. Instead, current mobile devices continuously transmit the collected data to a server for analysis at great computational and data transmission expense. In this thesis a novel mobile system designed for monitoring CVD is presented. Unlike existing systems, the proposed system allows for the continuous monitoring of physiological sensors, data from a patient’s health record and analysis of the data directly on the mobile device using machine learning algorithms (MLA) to predict an individual’s CVD severity level. The system successfully demonstrated that a mobile device can act as a complete monitoring system without requiring constant communication with a server. A comparative analysis between the support vector",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5df4149c0eef991a5fc73fe9df27dc9ad671409,https://www.semanticscholar.org/paper/a5df4149c0eef991a5fc73fe9df27dc9ad671409,Deep Learning for Diabetes: A Systematic Review,"Diabetes is a chronic metabolic disorder that affects an estimated 463 million people worldwide. Aiming to improve the treatment of people with diabetes, digital health has been widely adopted in recent years and generated a huge amount of data that could be used for further management of this chronic disease. Taking advantage of this, approaches that use artificial intelligence and specifically deep learning, an emerging type of machine learning, have been widely adopted with promising results. In this paper, we present a comprehensive review of the applications of deep learning within the field of diabetes. We conducted a systematic literature search and identified three main areas that use this approach: diagnosis of diabetes, glucose management, and diagnosis of diabetes-related complications. The search resulted in the selection of 40 original research articles, of which we have summarized the key information about the employed learning models, development process, main outcomes, and baseline methods for performance evaluation. Among the analyzed literature, it is to be noted that various deep learning techniques and frameworks have achieved state-of-the-art performance in many diabetes-related tasks by outperforming conventional machine learning approaches. Meanwhile, we identify some limitations in the current literature, such as a lack of data availability and model interpretability. The rapid developments in deep learning and the increase in available data offer the possibility to meet these challenges in the near future and allow the widespread deployment of this technology in clinical settings.",IEEE Journal of Biomedical and Health Informatics,2020.0,10.1109/jbhi.2020.3040225,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6294bc1abf8b9079110e2af7effc4fe446c25eec,https://www.semanticscholar.org/paper/6294bc1abf8b9079110e2af7effc4fe446c25eec,Federated and Differentially Private Learning for Electronic Health Records,"The use of collaborative and decentralized machine learning techniques such as federated learning have the potential to enable the development and deployment of clinical risk predictions models in low-resource settings without requiring sensitive data be shared or stored in a central repository. This process necessitates communication of model weights or updates between collaborating entities, but it is unclear to what extent patient privacy is compromised as a result. To gain insight into this question, we study the efficacy of centralized versus federated learning in both private and non-private settings. The clinical prediction tasks we consider are the prediction of prolonged length of stay and in-hospital mortality across thirty one hospitals in the eICU Collaborative Research Database. We find that while it is straightforward to apply differentially private stochastic gradient descent to achieve strong privacy bounds when training in a centralized setting, it is considerably more difficult to do so in the federated setting.",ArXiv,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4dee5a7e93c23cedb49c2d5f1ed8a3d437406075,https://www.semanticscholar.org/paper/4dee5a7e93c23cedb49c2d5f1ed8a3d437406075,Web-Based Newborn Screening System for Metabolic Diseases: Machine Learning Versus Clinicians,"Background A hospital information system (HIS) that integrates screening data and interpretation of the data is routinely requested by hospitals and parents. However, the accuracy of disease classification may be low because of the disease characteristics and the analytes used for classification. Objective The objective of this study is to describe a system that enhanced the neonatal screening system of the Newborn Screening Center at the National Taiwan University Hospital. The system was designed and deployed according to a service-oriented architecture (SOA) framework under the Web services .NET environment. The system consists of sample collection, testing, diagnosis, evaluation, treatment, and follow-up services among collaborating hospitals. To improve the accuracy of newborn screening, machine learning and optimal feature selection mechanisms were investigated for screening newborns for inborn errors of metabolism. Methods The framework of the Newborn Screening Hospital Information System (NSHIS) used the embedded Health Level Seven (HL7) standards for data exchanges among heterogeneous platforms integrated by Web services in the C# language. In this study, machine learning classification was used to predict phenylketonuria (PKU), hypermethioninemia, and 3-methylcrotonyl-CoA-carboxylase (3-MCC) deficiency. The classification methods used 347,312 newborn dried blood samples collected at the Center between 2006 and 2011. Of these, 220 newborns had values over the diagnostic cutoffs (positive cases) and 1557 had values that were over the screening cutoffs but did not meet the diagnostic cutoffs (suspected cases). The original 35 analytes and the manifested features were ranked based on F score, then combinations of the top 20 ranked features were selected as input features to support vector machine (SVM) classifiers to obtain optimal feature sets. These feature sets were tested using 5-fold cross-validation and optimal models were generated. The datasets collected in year 2011 were used as predicting cases. Results The feature selection strategies were implemented and the optimal markers for PKU, hypermethioninemia, and 3-MCC deficiency were obtained. The results of the machine learning approach were compared with the cutoff scheme. The number of the false positive cases were reduced from 21 to 2 for PKU, from 30 to 10 for hypermethioninemia, and 209 to 46 for 3-MCC deficiency. Conclusions This SOA Web service–based newborn screening system can accelerate screening procedures effectively and efficiently. An SVM learning methodology for PKU, hypermethioninemia, and 3-MCC deficiency metabolic diseases classification, including optimal feature selection strategies, is presented. By adopting the results of this study, the number of suspected cases could be reduced dramatically.",Journal of medical Internet research,2013.0,10.2196/jmir.2495,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5aa5f4edaa47ac1dbc362c1de20fd7a21005cdf1,https://www.semanticscholar.org/paper/5aa5f4edaa47ac1dbc362c1de20fd7a21005cdf1,Anomaly detection in gamma ray spectra: A machine learning perspective,"With Canadian security and the safety of the general public in mind, physicists at Health Canada (HC) have begun to develop techniques to identify persons concealing radioactive material that may represent a threat to attendees at public gatherings, such as political proceedings and sporting events. To this end, Health Canada has initiated field trials that include the deployment of gamma-ray spectrometers. In particular, a series of these detectors, which take measurements every minute and produce 1,024 channel gamma-ray spectrum, were deployed during the Vancouver 2010 olympics. Simple computerized statistics and human expertise were used as the primary line of defence. More specifically, if a measured spectrum deviated significantly from the background, an internal alarm was sounded and an HC physicist undertook further analysis into the nature of the alarming spectrum. This strategy, however, lead to a significant number of costly and time consuming false positives. This research applies sophisticated machine learning algorithms to reduce the number of false positives to an acceptable level, the results of which are detailed in this paper. In addition, we emphasize the primary findings of our work and highlight avenues available to further improve upon our current results.",2012 IEEE Symposium on Computational Intelligence for Security and Defence Applications,2012.0,10.1109/CISDA.2012.6291535,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
377a13afb7437314455668704d21ae256f963327,https://www.semanticscholar.org/paper/377a13afb7437314455668704d21ae256f963327,SIGNIFYING SENTENCE FRAMEWORK IN MACHINE LEARNING METHOD FOR INFORMATION MINING,"Electronic Health Records are becoming the criterion in the healthcare province. The potential benefits of having an Electronic Health Records system are: Health information recording and clinical data repositories, Medication supervision, Decision hold up, Obtain treatments that are personalized to definite health needs. Usage of Natural Language Processing and Machine Learning techniques build a tool, capable to recognize and distribute textual information related to diseases and treatments. An extensive study of various Machine Learning algorithms and textual representations for classifying short medical texts and recognizing semantic relations among two medical entities diseases and treatments. There are at least two challenges that can be come across although working with Machine Learning method. One is to discover the most appropriate model for prediction. The Machine Learning field offers a collection of predictive models that can be used and deployed. The job of finding the appropriate one relies greatly on empirical studies and knowledge proficiency. The second one is to find a good data depiction and to do aspect engineering because features powerfully manipulate the performance of the models.",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fb41d56a2259469997492259e5bef1d1d612d122,https://www.semanticscholar.org/paper/fb41d56a2259469997492259e5bef1d1d612d122,Secure and efficient parameters aggregation protocol for federated incremental learning and its applications,"Federated Learning (FL) enables the deployment of distributed machine learning models over the cloud and Edge Devices (EDs) while preserving the privacy of sensitive local data, such as electronic health records. However, despite FL advantages regarding security and flexibility, current constructions still suffer from some limitations. Namely, heavy computation overhead on limited resources EDs, communication overhead in uploading converged local models' parameters to a centralized server for parameters aggregation, and lack of guaranteeing the acquired knowledge preservation in the face of incremental learning over new local data sets. This paper introduces a secure and resource‐friendly protocol for parameters aggregation in federated incremental learning and its applications. In this study, the central server relies on a new method for parameters aggregation called orthogonal gradient aggregation. Such a method assumes constant changes of each local data set and allows updating parameters in the orthogonal direction of previous parameters spaces. As a result, our new construction is robust against catastrophic forgetting, maintains the federated neural network accuracy, and is efficient in computation and communication overhead. Moreover, extensive experiments analysis over several significant data sets for incremental learning demonstrates our new protocol's efficiency, efficacy, and flexibility.",International Journal of Intelligent Systems,2021.0,10.1002/int.22727,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
925fee27761c0c0cb8d4e9e292a13e87c8cc370c,https://www.semanticscholar.org/paper/925fee27761c0c0cb8d4e9e292a13e87c8cc370c,Machine Performance Monitoring and Fault Classification using Vibration Frequency Analysis,"Machine anomalies in manufacturing directly affect the production yield and factory operation efficiency if such anomalies cannot be detected in time. Real-time monitoring of machine health condition not only improves machine throughput by reducing unplanned downtime caused by machine failure but also saves cost for unnecessary routine maintenance. This paper presents a systematic approach for real-time or near real-time machine performance monitoring solution development from data collection, feature extraction, data analytics to real-time machine fault and machine status classification. Three data-driven machine-learning approaches using one vibration sensor data are proposed to detect two common machine failure modes during machine turning process. To evaluate the the performance of each approach, three machine-learning algorithms (Random Forest, K Nearest Neighborhood, and Support Vector Machine) are implemented and tested. Evaluation results on the actual machine data shows that a two-layered classification structure with random forest algorithm as the base has high classification accuracy on the machine status including machine fault detection. The developed data-driven machine health monitoring solution is deployed in the IoT device for real-time data collection and processing and results are sent data server for data visualization.",2020 Prognostics and Health Management Conference (PHM-Besançon),2020.0,10.1109/PHM-Besancon49106.2020.00009,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6fac1e0e60b72812e02bf99b06e7ced18fc59294,https://www.semanticscholar.org/paper/6fac1e0e60b72812e02bf99b06e7ced18fc59294,TransNet: Minimally Supervised Deep Transfer Learning for Dynamic Adaptation of Wearable Systems,"Wearables are poised to transform health and wellness through automation of cost-effective, objective, and real-time health monitoring. However, machine learning models for these systems are designed based on labeled data collected, and feature representations engineered, in controlled environments. This approach has limited scalability of wearables because (i) collecting and labeling sufficiently large amounts of sensor data is a labor-intensive and expensive process; and (ii) wearables are deployed in highly dynamic environments of the end-users whose context undergoes consistent changes. We introduce TransNet, a deep learning framework that minimizes the costly process of data labeling, feature engineering, and algorithm retraining by constructing a scalable computational approach. TransNet learns general and reusable features in lower layers of the framework and quickly reconfigures the underlying models from a small number of labeled instances in a new domain, such as when the system is adopted by a new user or when a previously unseen event is to be added to event vocabulary of the system. Utilizing TransNet on four activity datasets, TransNet achieves an average accuracy of 88.1% in cross-subject learning scenarios using only one labeled instance for each activity class. This performance improves to an accuracy of 92.7% with five labeled instances.",ACM Trans. Design Autom. Electr. Syst.,2020.0,10.1145/3414062,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
82921c5f3622cb54aba641e7e12f5bb0befe8764,https://www.semanticscholar.org/paper/82921c5f3622cb54aba641e7e12f5bb0befe8764,Blockchain-Secured Recommender System for Special Need Patients Using Deep Learning,"Recommender systems offer several advantages to hospital data management units and patients with special needs. These systems are more dependent on the extreme subtle hospital-patient data. Thus, disregarding the confidentiality of patients with special needs is not an option. In recent times, several proposed techniques failed to cryptographically guarantee the data privacy of the patients with special needs in the diet recommender systems (RSs) deployment. In order to tackle this pitfall, this paper incorporates a blockchain privacy system (BPS) into deep learning for a diet recommendation system for patients with special needs. Our proposed technique allows patients to get notifications about recommended treatments and medications based on their personalized data without revealing their confidential information. Additionally, the paper implemented machine and deep learning algorithms such as RNN, Logistic Regression, MLP, etc., on an Internet of Medical Things (IoMT) dataset acquired via the internet and hospitals that comprises the data of 50 patients with 13 features of various diseases and 1,000 products. The product section has a set of eight features. The IoMT data features were analyzed with BPS and further encoded prior to the application of deep and machine learning-based frameworks. The performance of the different machine and deep learning methods were carried out and the results verify that the long short-term memory (LSTM) technique is more effective than other schemes regarding prediction accuracy, precision, F1-measures, and recall in a secured blockchain privacy system. Results showed that 97.74% accuracy utilizing the LSTM deep learning model was attained. The precision of 98%, recall, and F1-measure of 99% each for the allowed class was also attained. For the disallowed class, the scores were 89, 73, and 80% for precision, recall, and F1-measure, respectively. The performance of our proposed BPS is subdivided into two categories: the secured communication channel of the recommendation system and an enhanced deep learning approach using health base medical dataset that spontaneously identifies what food a patient with special needs should have based on their disease and certain features including gender, weight, age, etc. The proposed system is outstanding as none of the earlier revised works of literature described a recommender system of this kind.",Frontiers in Public Health,2021.0,10.3389/fpubh.2021.737269,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b5693730183c975e0b8f1c46c8107ec3c3a09beb,https://www.semanticscholar.org/paper/b5693730183c975e0b8f1c46c8107ec3c3a09beb,Trade-offs in Metric Learning for Bearing Fault Diagnosis,"Metric learning is a well-developed field in machine learning and has seen recent application in the area of prognostics and health management (PHM). Metric learning allows for fault diagnosis or condition monitoring models to be developed with the assumption that a machine- or load-specific similarity metric can be learned after model deployment. Existing literature has used metric learning to fine-tune deep learning models to address machine-to-machine differences and differences in working conditions. Here, we study metric learning in isolation, not as an intermediate step in deep learning, by conducting a comparative study of Principal Component Analysis (PCA), Neighborhood Component Analysis (NCA), Local Fisher Discriminant Analysis (LFDA), and Large Margin Nearest Neighbor (LMNN). We consider performance metrics for prediction performance, cluster performance, feature sensitivity, sample efficiency, and latent space efficiency. We find that linear partitions on the latent spaces learned via metric learning are able to achieve accuracies greater than 90% on Case Western Reserve University’s bearing fault data set using only the drive-end vibration signal. We find PCA to be dominated by metric learning algorithms for all working loads considered. And, in sum, we demonstrate classical metric learning algorithms to be a promising approach for learning machine-and load-specific similarity metrics for PHM with minor data processing and small samples.",2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA),2021.0,10.1109/ICMLA52953.2021.00180,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4f2c76d791dd2e1248188bd69d1ef18ea7fe9a50,https://www.semanticscholar.org/paper/4f2c76d791dd2e1248188bd69d1ef18ea7fe9a50,Deep-Learning and HPC to Boost Biomedical Applications for Health (DeepHealth),"This document introduces the DeepHealth project: ""Deep-Learning and HPC to Boost Biomedical Applications for Health"". This project is funded by the European Commission under the H2020 framework program and aims to reduce the gap between the availability of mature enough AI-solutions and their deployment in real scenarios. Several existing software platforms provided by industrial partners will integrate state-of-the-art machine-learning algorithms and will be used for giving support to doctors in diagnosis, increasing their capabilities and efficiency. The DeepHealth consortium is composed by 21 partners from 9 European countries including hospitals, universities, large industry and SMEs.",2019 IEEE 32nd International Symposium on Computer-Based Medical Systems (CBMS),2019.0,10.1109/CBMS.2019.00040,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b18d9ef4eeb9e5f6922a2458be533043e98f6c63,https://www.semanticscholar.org/paper/b18d9ef4eeb9e5f6922a2458be533043e98f6c63,Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings,"Machine learning models in health care are often deployed in settings where it is important to protect patient privacy. In such settings, methods for differentially private (DP) learning provide a general-purpose approach to learn models with privacy guarantees. Modern methods for DP learning ensure privacy through the addition of calibrated noise. The resulting privacy-preserving models are unable to learn too much information about the tails of a data distribution, resulting in a loss of accuracy that can disproportionately affect small groups. In this paper, we study the effects of DP learning in health care. We use state-of-the-art methods for DP learning to train privacy-preserving models in clinical prediction tasks, including x-ray classification of images and mortality prediction in time series data. We use these models to perform a comprehensive empirical investigation of the tradeoffs between privacy, utility, robustness to dataset shift and fairness. Our results highlight lesser-known limitations of methods for DP learning in health care, models that exhibit steep tradeoffs between privacy and utility, and models whose predictions are disproportionately influenced by large demographic groups in the training data. We discuss the costs and benefits of differentially private learning in health care with open directions for differential privacy, machine learning and health care.",FAccT,2020.0,10.1145/3442188.3445934,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29de41fee3d4b42a88ffc308de492a0ab69e5df2,https://www.semanticscholar.org/paper/29de41fee3d4b42a88ffc308de492a0ab69e5df2,"Multi-Task Learning for Concurrent Prediction of Thermal Comfort, Sensation and Preference in Winters","Indoor thermal comfort immensely impacts the health and performance of occupants. Therefore, researchers and engineers have proposed numerous computational models to estimate thermal comfort (TC). Given the impetus toward energy efficiency, the current focus is on data-driven TC prediction solutions that leverage state-of-the-art machine learning (ML) algorithms. However, an occupant’s perception of indoor thermal comfort (TC) is subjective and multi-dimensional. Different aspects of TC are represented by various standard metrics/scales viz., thermal sensation (TSV), thermal comfort (TCV), and thermal preference (TPV). The current ML-based TC prediction solutions adopt the Single-task Learning approach, i.e., one prediction model per metric. Consequently, solutions often focus on only one TC metric. Moreover, when several metrics are considered, multiple ML models for a single indoor space lead to conflicting predictions, rendering real-world deployment infeasible. This work addresses these problems by leveraging Multi-task Learning for TC prediction in naturally ventilated buildings. First, a survey-and-measurement study is conducted in the composite climatic region of north India, in 14 naturally ventilated classrooms of 5 schools, involving 512 primary school students. Next, the dataset is analyzed for important environmental, physiological, and psycho-social factors that influence thermal comfort of children. Further, “DeepComfort”, a deep neural network based Multi-task Learning model is proposed. DeepComfort predicts multiple TC output metrics viz., TSV, TPV, and TCV, simultaneously through a single model. It is validated on ASHRAE-II database and the primary student dataset created in this study. It demonstrates high F1-scores, Accuracy (≈90%), and generalization capability, despite the challenges of illogical responses and data imbalance. DeepComfort is also shown to outperform 6 popular metric-specific single-task machine learning algorithms.",Buildings,2022.0,10.3390/buildings12060750,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a70ece416a47d73b179b997280731646f2ff63d7,https://www.semanticscholar.org/paper/a70ece416a47d73b179b997280731646f2ff63d7,Forecasting Future Asthma Hospital Encounters of Patients With Asthma in an Academic Health Care System: Predictive Model Development and Secondary Analysis Study (Preprint),"
 BACKGROUND
 Asthma affects a large proportion of the population and leads to many hospital encounters involving both hospitalizations and emergency department visits every year. To lower the number of such encounters, many health care systems and health plans deploy predictive models to prospectively identify patients at high risk and offer them care management services for preventive care. However, the previous models do not have sufficient accuracy for serving this purpose well. Embracing the modeling strategy of examining many candidate features, we built a new machine learning model to forecast future asthma hospital encounters of patients with asthma at Intermountain Healthcare, a nonacademic health care system. This model is more accurate than the previously published models. However, it is unclear how well our modeling strategy generalizes to academic health care systems, whose patient composition differs from that of Intermountain Healthcare.
 
 
 OBJECTIVE
 This study aims to evaluate the generalizability of our modeling strategy to the University of Washington Medicine (UWM), an academic health care system.
 
 
 METHODS
 All adult patients with asthma who visited UWM facilities between 2011 and 2018 served as the patient cohort. We considered 234 candidate features. Through a secondary analysis of 82,888 UWM data instances from 2011 to 2018, we built a machine learning model to forecast asthma hospital encounters of patients with asthma in the subsequent 12 months.
 
 
 RESULTS
 Our UWM model yielded an area under the receiver operating characteristic curve (AUC) of 0.902. When placing the cutoff point for making binary classification at the top 10% (1464/14,644) of patients with asthma with the largest forecasted risk, our UWM model yielded an accuracy of 90.6% (13,268/14,644), a sensitivity of 70.2% (153/218), and a specificity of 90.91% (13,115/14,426).
 
 
 CONCLUSIONS
 Our modeling strategy showed excellent generalizability to the UWM, leading to a model with an AUC that is higher than all of the AUCs previously reported in the literature for forecasting asthma hospital encounters. After further optimization, our model could be used to facilitate the efficient and effective allocation of asthma care management resources to improve outcomes.
 
 
 INTERNATIONAL REGISTERED REPORT
 RR2-10.2196/resprot.5039
",,2020.0,10.2196/preprints.22796,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bd34e252c3219f51f9ef569e506ca5d078daddde,https://www.semanticscholar.org/paper/bd34e252c3219f51f9ef569e506ca5d078daddde,"Come What May, Digital Health Technologies Will Never Be Able to Predict the Emergence of Unknown Viruses and Microorganisms with any Degree of Certainty",,Journal of Medical Systems,2020.0,10.1007/s10916-020-01667-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
320e3a66dbc51a1331f65b5ac42b937a39d5e051,https://www.semanticscholar.org/paper/320e3a66dbc51a1331f65b5ac42b937a39d5e051,Physical Activity Recognition With Statistical-Deep Fusion Model Using Multiple Sensory Data for Smart Health,"Nowadays, enhancing the living standard with smart healthcare via the Internet of Things is one of the most critical goals of smart cities, in which artificial intelligence plays as the core technology. Many smart services, deployed according to wearable sensor-based physical activity recognition, have been able to early detect unhealthy daily behaviors and further medical risks. Numerous approaches have studied shallow handcrafted features coupled with traditional machine learning (ML) techniques, which find it difficult to model real-world activities. In this work, by revealing deep features from deep convolutional neural networks (DCNNs) in fusion with conventional handcrafted features, we learn an intermediate fusion framework of human activity recognition (HAR). According to transforming the raw signal value to pixel intensity value, segmentation data acquired from a multisensor system are encoded to an activity image for deep model learning. Formulated by several novel residual triple convolutional blocks, the proposed DCNN allows extracting multiscale spatiotemporal signal-level and sensor-level correlations simultaneously from the activity image. In the fusion model, the hybrid feature merged from the handcrafted and deep features is learned by a multiclass support vector machine (SVM) classifier. Based on several experiments of performance evaluation, our fusion approach for activity recognition has achieved the accuracy over 96.0% on three public benchmark data sets, including Daily and Sport Activities, Daily Life Activities, and RealWorld. Furthermore, the method outperforms several state-of-the-art HAR approaches and demonstrates the superiority of the proposed intermediate fusion model in multisensor systems.",IEEE Internet of Things Journal,2021.0,10.1109/JIOT.2020.3013272,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d08e6624cd491bb79a0d9e2d12367699f590984e,https://www.semanticscholar.org/paper/d08e6624cd491bb79a0d9e2d12367699f590984e,Dew-Cloud-Based Hierarchical Federated Learning for Intrusion Detection in IoMT.,"The coronavirus pandemic has overburdened medical institutions, forcing physicians to diagnose and treat their patients remotely. Moreover, COVID-19 has made humans more conscious about their health, resulting in the extensive purchase of IoT-enabled medical devices. The rapid boom in the market worth of the internet of medical things (IoMT) captured cyber attackers' attention. Like health, medical data is also sensitive and worth a lot on the dark web. Despite the fact that the patient's health details have not been protected appropriately, letting the trespassers exploit them. The system administrator is unable to fortify security measures due to the limited storage capacity and computation power of the resource-constrained network devices'. Although various supervised and unsupervised machine learning algorithms have been developed to identify anomalies, the primary undertaking is to explore the swift progressing malicious attacks before they deteriorate the wellness system's integrity. In this paper, a Dew-Cloud based model is designed to enable hierarchical federated learning (HFL). The proposed Dew-Cloud model provides a higher level of data privacy with greater availability of IoMT critical application(s). The hierarchical long-term memory (HLSTM) model is deployed at distributed Dew servers with a backend supported by cloud computing. Data pre-processing feature helps the proposed model achieve high training accuracy ( 99.31 %) with minimum training loss (0.034). The experiment results demonstrate that the proposed HFL-HLSTM model is superior to existing schemes in terms of performance metrics such as accuracy, precision, recall, and f-score.",IEEE journal of biomedical and health informatics,2022.0,10.1109/JBHI.2022.3186250,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8f2ccb4225d9cf740f7e806d9ee372952bcac25,https://www.semanticscholar.org/paper/c8f2ccb4225d9cf740f7e806d9ee372952bcac25,NeuraHealthNLP: An Automated Screening Pipeline to Detect Undiagnosed Cognitive Impairment in Electronic Health Records with Deep Learning and Natural Language Processing,"Dementia related cognitive impairment (CI) affects over 55 million people worldwide and is growing rapidly at the rate of one new case every 3 seconds. It is a terrifying disease that robs a person of their identity, and eventually leads to death (100% fatality rate). With a recurring failure of clinical trials, early diagnosis is crucial, but 75% of dementia cases go undiagnosed globally with up to 90% in low-and-middleincome countries. Current diagnostic methods are notoriously complex, involving manual review of medical notes, numerous cognitive tests, expensive brain scans or spinal fluid tests. Information relevant to CI is often found in the electronic health records (EHRs) and can provide vital clues for early diagnosis, but a manual review by experts is tedious and error prone. This project develops a novel state-of-the-art automated screening pipeline for scalable and high-speed discovery of undetected CI in EHRs. To understand the linguistic context from complex language structures in EHR, a database of 8,656 sequences was constructed to train attention-based deep learning natural language processing model to classify sequences. A patient level prediction model based on logistic regression was developed using the sequence level classifier. The deep learning system was tested using 343 patient EHRs and achieved 93% accuracy and AUC = 0.98 to identify patients who had no earlier diagnosis, dementia-related diagnosis code, or dementia-related medications in their EHR. These patients would have otherwise gone undetected or detected too late. The EHR screening pipeline was deployed in NeuraHealthNLP, a web application for automated and real-time CI screening by simply uploading EHRs in a browser. NeuraHealthNLP is cheaper, faster, more accessible, and outperforms current clinical methods including text-based analytics and machine learning approaches. It makes early diagnosis viable in regions with scarce health care services but accessible internet or cellular services.",ArXiv,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5026f96b4bdd08fe8c4e12e2d95c74a1694cb4ef,https://www.semanticscholar.org/paper/5026f96b4bdd08fe8c4e12e2d95c74a1694cb4ef,Sensors for Structural Health Monitoring of Agricultural Structures,"The health diagnosis of agricultural structures is critical to detecting damages such as cracks in concrete, corrosion, spalling, and delamination. Agricultural structures are susceptible to environmental degradation due to frequent exposure to water, organic effluent, farm chemicals, structural loading, and unloading. Various sensors have been employed for accurate and real-time monitoring of agricultural building structures, including electrochemical, ultrasonic, fiber-optic, piezoelectric, wireless, fiber Bragg grating sensors, and self-sensing concrete. The cost–benefits of each type of sensor and utility in a farm environment are explored in the review. Current literature suggests that the functionality of sensors has improved with progress in technology. Notable improvements made with the progress in technology include better accuracy of the measurements, reduction of signal-to-noise ratio, and transmission speed, and the deployment of machine learning, deep learning, and artificial intelligence in smart IoT-based agriculture. Key challenges include inconsistent installation of sensors in farm structures, technical constraints, and lack of support infrastructure, awareness, and preference for traditional inspection methods.",Sensors,2021.0,10.3390/s21010314,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2d08a4dbc5ffbcacbd2fbf2d299eca71229e9db6,https://www.semanticscholar.org/paper/2d08a4dbc5ffbcacbd2fbf2d299eca71229e9db6,Deep learning in automated text classification: a case study using toxicological abstracts,,Environment Systems and Decisions,2020.0,10.1007/s10669-020-09763-2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6fd917fa772b59ea2ba94cc0042d71b97bed06ee,https://www.semanticscholar.org/paper/6fd917fa772b59ea2ba94cc0042d71b97bed06ee,Deep Learning Predicts the Malignant-Transformation-Free Survival of Oral Potentially Malignant Disorders,"Simple Summary Mouth cancer is the most common malignancy in the head-and-neck region. Usually, these tumors develop from white lesions in the mouth that appear long before cancer diagnosis. However, platforms that can estimate the time-factored risk of cancer occurring from these diseases and guide treatment and monitoring approaches are elusive. To this end, our study presents time-to-event models that are based on machine learning for prediction of the risk of malignancy from oral white lesions following pathological diagnosis as a function of time. These models displayed very satisfactory discrimination and calibration after multiple tests. To facilitate their preliminary use in clinical practice and further validation, we created a website supporting the use of these models to aid decision making. Abstract Machine-intelligence platforms for the prediction of the probability of malignant transformation of oral potentially malignant disorders are required as adjunctive decision-making platforms in contemporary clinical practice. This study utilized time-to-event learning models to predict malignant transformation in oral leukoplakia and oral lichenoid lesions. A total of 1098 patients with oral white lesions from two institutions were included in this study. In all, 26 features available from electronic health records were used to train four learning algorithms—Cox-Time, DeepHit, DeepSurv, random survival forest (RSF)—and one standard statistical method—Cox proportional hazards model. Discriminatory performance, calibration of survival estimates, and model stability were assessed using a concordance index (c-index), integrated Brier score (IBS), and standard deviation of the averaged c-index and IBS following training cross-validation. This study found that DeepSurv (c-index: 0.95, IBS: 0.04) and RSF (c-index: 0.91, IBS: 0.03) were the two outperforming models based on discrimination and calibration following internal validation. However, DeepSurv was more stable than RSF upon cross-validation. External validation confirmed the utility of DeepSurv for discrimination (c-index—0.82 vs. 0.73) and RSF for individual survival estimates (0.18 vs. 0.03). We deployed the DeepSurv model to encourage incipient application in clinical practice. Overall, time-to-event models are successful in predicting the malignant transformation of oral leukoplakia and oral lichenoid lesions.",Cancers,2021.0,10.3390/cancers13236054,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3dc78764ad5150cbd2e7dda27d8af1e045018d21,https://www.semanticscholar.org/paper/3dc78764ad5150cbd2e7dda27d8af1e045018d21,Population-aware hierarchical bayesian domain adaptation via multi-component invariant learning,"While machine learning is rapidly being developed and deployed in health settings such as influenza prediction, there are critical challenges in using data from one environment to predict in another due to variability in features. Even within disease labels there can be differences (e.g. ""fever"" may mean something different reported in a doctor's office versus in an online app). Moreover, models are often built on passive, observational data which contain different distributions of population subgroups (e.g. men or women). Thus, there are two forms of instability between environments in this observational transport problem. We first harness substantive knowledge from health research to conceptualize the underlying causal structure of this problem in a health outcome prediction task. Based on sources of stability in the model and the task, we posit that we can combine environment and population information in a novel population-aware hierarchical Bayesian domain adaptation framework that harnesses multiple invariant components through population attributes when needed. We study the conditions under which invariant learning fails, leading to reliance on the environment-specific attributes. Experimental results for an influenza prediction task on four datasets gathered from different contexts show the model can improve prediction in the case of largely unlabelled target data from a new environment and different constituent population, by harnessing both environment and population invariant information. This work represents a novel, principled way to address a critical challenge by blending domain (health) knowledge and algorithmic innovation. The proposed approach will have significant impact in many social settings wherein who the data comes from and how it was generated, matters.",CHIL,2019.0,10.1145/3368555.3384451,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aea75bf01dc6756861021ef8f1bfbd3efa1e018e,https://www.semanticscholar.org/paper/aea75bf01dc6756861021ef8f1bfbd3efa1e018e,Transfer learning for decision support in Covid-19 detection from a few images in big data,"The novel coronavirus (Covid-19) has spread rapidly amongst countries all around the globe. Compared to the rise in cases, there are few Covid-19 testing kits available. Due to the lack of testing kits for the public, it is useful to implement an automated AI-based E-health decision support system as a potential alternative method for Covid-19 detection. As per medical examinations, the symptoms of Covid-19 could be somewhat analogous to those of pneumonia, though certainly not identical. Considering the enormous number of cases of Covid-19 and pneumonia, and the complexity of the related images stored, the data pertaining to this problem of automated detection constitutes big data. With rapid advancements in medical imaging, the development of intelligent predictive and diagnostic tools have also increased at a rapid rate. Data mining and machine learning techniques are widely accepted to aid medical diagnosis. In this paper, a huge data set of X-ray images from patients with common bacterial pneumonia, confirmed Covid-19 disease, and normal healthy cases are utilized for AI-based decision support in detecting the Coronavirus disease. The transfer learning approach, which enables us to learn from a smaller set of samples in a problem and transfer the discovered knowledge to a larger data set, is employed in this study. We consider transfer learning using three different models that are pre-trained on several images from the ImageNet source. The models deployed here are VGG16, VGG19, and ResNet101. The dataset is generated by gathering different classes of images. We present our approach and preliminary evaluation results in this paper. We also discuss applications and open issues.",2020 IEEE International Conference on Big Data (Big Data),2020.0,10.1109/BigData50022.2020.9377886,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1e5b90bc7f200d57a1a193c39365aa91f53bbcd9,https://www.semanticscholar.org/paper/1e5b90bc7f200d57a1a193c39365aa91f53bbcd9,Learning to Detect Anomalous Wireless Links in IoT Networks,"After decades of research, Internet of Things (IoT) is finally permeating real-life and helps improve the efficiency of infrastructures and processes as well as our health. As massive number of IoT devices are deployed, they naturally incurs great operational costs to ensure intended operations. To effectively handle such intended operations in massive IoT networks, automatic detection of malfunctioning, namely anomaly detection, becomes a critical but challenging task. In this paper, motivated by a real-world experimental IoT deployment, we introduce four types of wireless network anomalies that are identified at the link layer. We study the performance of threshold- and machine learning (ML)-based classifiers to automatically detect these anomalies. We examine the relative performance of three supervised and three unsupervised ML techniques on both non-encoded and encoded (autoencoder) feature representations. Our results demonstrate that; i) selected supervised approaches are able to detect anomalies with F1 scores of above 0.98, while unsupervised ones are also capable of detecting the said anomalies with F1 scores of, on average, 0.90, and ii) OC-SVM outperforms all the other unsupervised ML approaches reaching at F1 scores of 0.99 for SuddenD, 0.95 for SuddenR, 0.93 for InstaD and 0.95 for SlowD.",IEEE Access,2020.0,10.1109/ACCESS.2020.3039333,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
129d790930038a5065a75d7060a535380339c46b,https://www.semanticscholar.org/paper/129d790930038a5065a75d7060a535380339c46b,Advances in deep learning methods for pavement surface crack detection and identification with visible light visual images,"Cracks inevitably exist widely in buildings, structures, parts or products. Compared to contact detection methods such as nondestructive test (NDT) and health monitoring, surface crack detection or identification with visible light visual images is a kind of non-contact method, which is not limited by the material of the tested object and is easy to achieve online real-time fully automation, thus, has the advantages of fast detection speed, low cost and high precision. Firstly, typical pavement (concrete also) crack public data sets for classification, location or segmentation were collected, and the characteristics of sample images and the random variable factors, including environmental, noise and interference, were summarized. Subsequently, the advantages and shortcomings of the three main crack identification methods, i.e., Hand-crafted Feature Engineering, Machine Learning, Deep Learning, were compared. Finally, from the aspects of model architecture, testing performance and predicting effectiveness, the development and progress of typical deep learning models, namely self-built CNN, transfer learning (TL) and encoder-decoder (ED), which can be easily deployed on embedded platform, were reviewed. Meanwhile, from this, we can see the evolution of CNN model architecture, as well as the obvious improvement of performance and effect because of computing power enhancement and algorithm optimization. The benchmark test shows that: 1) It has been able to realize real-time pixel-level crack identification on embedded platform: the entire crack detection average time cost of an image sample is less than 100ms, either using the ED method (i.e., FPCNet) or the TL method based on InceptionV3. It can be reduced to less than 10ms with TL method based on MobileNet (a lightweight backbone base network). 2) In terms of accuracy, it can reach over 99.8% on CCIC which is easily identified by human eyes. On SDNET2018, some samples of which are difficult to be identified, FPCNet can reach 97.5%, while TL method is close to 96.1%. To the best of our knowledge, this paper for the first time comprehensively summarizes the pavement crack public data sets, and the performance and effectiveness of surface crack detection and identification deep learning methods for embedded platform, are reviewed and evaluated.",ArXiv,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0966363ea46368f297999b026c827f0f5ea7fcc9,https://www.semanticscholar.org/paper/0966363ea46368f297999b026c827f0f5ea7fcc9,Efficient Machine-Type Communication Using Multi-Metric Context-Awareness for Cars Used as Mobile Sensors in Upcoming 5G Networks,"Upcoming 5G-based communication networks will be confronted with huge increases in the amount of transmitted sensor data related to massive deployments of static and mobile Internet of Things (IoT) systems. Cars acting as mobile sensors will become important data sources for cloud-based applications like predictive maintenance and dynamic traffic forecast. Due to the limitation of available communication resources, it is expected that the grows in Machine-Type Communication (MTC) will cause severe interference with Human-to-human (H2H) communication. Consequently, more efficient transmission methods are highly required. In this paper, we present a probabilistic scheme for efficient transmission of vehicular sensor data which leverages favorable channel conditions and avoids transmissions when they are expected to be highly resource-consuming. Multiple variants of the proposed scheme are evaluated in comprehensive realworld experiments. Through machine learning based combination of multiple context metrics, the proposed scheme is able to achieve up to 164% higher average data rate values for sensor applications with soft deadline requirements compared to regular periodic transmission.",2018 IEEE 87th Vehicular Technology Conference (VTC Spring),2018.0,10.1109/VTCSpring.2018.8417753,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8017425c203ecd6ef83908e9965da4ad7470e921,https://www.semanticscholar.org/paper/8017425c203ecd6ef83908e9965da4ad7470e921,Improving Tuberculosis Diagnostics Using Deep Learning and Mobile Health Technologies among Resource-Poor and Marginalized Communities,"Tuberculosis (TB) is a chronic infectious disease worldwide and remains a major cause of death globally. Of the estimated 9 million people who developed TB in 2013, over 80% were in South-East Asia, Western Pacific, and African. The majority of the infected populations was from resource-poor and marginalized communities with weak healthcare infrastructure. Reducing TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the tuberculosis epidemic. The combination of machine learning and mobile computing techniques offers a unique opportunity to accelerate the TB diagnosis among these communities. The ultimate goal of our research is to reduce patient wait times for being diagnosed with this infectious disease by developing new machine learning and mobile health techniques to the TB diagnosis problem. In this paper, we first introduce major technique barriers and proposed system architecture. Then we report two major progresses we recently made. The first activity aims to develop large-scale, real-world and well-annotated X-ray image database dedicated for automated TB screening. The second research activity focus on developing effective and efficient computational models (in particularly, deep convolutional neural networks (CNN)-based models) to classify the image into different category of TB manifestations. Experimental results have demonstrated the effectiveness of our approach. Our future work includes: (1) to further improve the performance of the algorithms, and (2) to deploy our system in the city of Carabayllo in Perú, a densely occupied urban community and high-burden TB.","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)",2016.0,10.1109/CHASE.2016.18,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dc5fe4febac1b27af6637075f1e1a3eeed0c9e5a,https://www.semanticscholar.org/paper/dc5fe4febac1b27af6637075f1e1a3eeed0c9e5a,A Comprehensive Survey of Deep Learning Models Based on Keras Framework,"Python is one of the most widely adopted programming languages, having replaced a number of those in the field. Python is popular with developers for a variety of reasons, one of which is because it has an incredibly diverse collection of libraries that users can run. The most compelling reasons for adopting Keras come from its guiding principles, particularly those related to usability. Aside from the simplicity of learning and model construction, Keras has a wide variety of production deployment options and robust support for multiple GPUs and distributed training. A strong and easy-to-use free, open-source Python library is the most important tool for developing and evaluating deep learning models. The aim of this paper is to provide the most current survey of Keras in different aspects, which is a Python-based deep learning Application Programming Interface (API) that runs on top of the machine learning framework, TensorFlow. The mentioned library is used in conjunction with TensorFlow, PyTorch, CODEEPNEATM, and Pygame to allow integration of deep learning models such as cardiovascular disease diagnostics, graph neural networks, identifying health issues, COVID-19 recognition, skin tumors, image detection, and so on, in the applied area. Furthermore, the author used Keras's details, goals, challenges, significant outcomes, and the findings obtained using this method.",Journal of Soft Computing and Data Mining,2021.0,10.30880/jscdm.2021.02.02.005,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a497cc5576c576d0094d7e6f90b3941bd35703c,https://www.semanticscholar.org/paper/3a497cc5576c576d0094d7e6f90b3941bd35703c,Development of Electronic Health Record–Based Prediction Models for 30-Day Readmission Risk Among Patients Hospitalized for Acute Myocardial Infarction,"Key Points Question Can machine learning deployed in electronic health records be used to improve readmission risk estimation for patients following acute myocardial infarction? Findings In this cohort study examining externally validated machine learning risk models for 30-day readmission of 10 187 patients following hospitalization for acute myocardial infarction, good discrimination performance was noted at the development site, but the best discrimination did not result in the best calibration. External validation yielded significant declines in discrimination and calibration. Meaning The findings of this study highlight that robust calibration assessments are a necessary complement to discrimination when machine learning models are used to predict post–acute myocardial infarction readmission; challenges with data availability across sites, even in the presence of a common data model, limit external validation performance.",JAMA network open,2021.0,10.1001/jamanetworkopen.2020.35782,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98e189ccff4a3e51cee3109832e0d15ade5931cf,https://www.semanticscholar.org/paper/98e189ccff4a3e51cee3109832e0d15ade5931cf,EMU: Early Mental Health Uncovering Framework and Dataset,"Mental illnesses are often undiagnosed, demonstrating need for an effective unbiased alternative to traditional screening surveys. For this we propose our Early Mental Health Uncovering (EMU) framework that supports near instantaneous mental illness screening with non-intrusive active and passive modalities. We designed, deployed, and evaluated the EMU app to passively collect retrospective digital phenotype data and actively collect short voice recordings. Additionally, the EMU app also administered depression and anxiety screening surveys to produce depression and anxiety screening labels for the data. Notably, more than twice as many participants elected to share scripted audio recordings than any passive modality. We then study the effectiveness of machine learning models trained with the active modalities. Using scripted audio, EMU screens for depression with F1=0.746, anxiety with F1=0.667, and suicidal ideation with F1=0.706. Using unscripted audio, EMU screens for depression with F1=0.691, anxiety with F1=0.636, and suicidal ideation with F1=0.667. Jitter is an important feature for screening with scripted audio, while Mel-Frequency Cepstral Coefficient is an important feature for screening with unscripted audio. Further, the frequency of help-related words carried a strong signal for suicidal ideation screening with unscripted audio transcripts. This research results in a deeper understanding of the selection of modalities and corresponding features for mobile screening. The EMU dataset will be made available to public domain, representing valuable data resource for the community to further advance universal mental illness screening research.",2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA),2021.0,10.1109/ICMLA52953.2021.00213,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6a4a61327b74b3c2b15eff368d9667931391f926,https://www.semanticscholar.org/paper/6a4a61327b74b3c2b15eff368d9667931391f926,Framework for Privacy-Preserving Wearable Health Data Analysis: Proof-of-Concept Study for Atrial Fibrillation Detection,"Medical wearable devices monitor health data and, coupled with data analytics, cloud computing, and artificial intelligence (AI), enable early detection of disease. Privacy issues arise when personal health information is sent or processed outside the device. We propose a framework that ensures the privacy and integrity of personal medical data while performing AI-based homomorphically encrypted data analytics in the cloud. The main contributions are: (i) a privacy-preserving cloud-based machine learning framework for wearable devices, (ii) CipherML—a library for fast implementation and deployment of deep learning-based solutions on homomorphically encrypted data, and (iii) a proof-of-concept study for atrial fibrillation (AF) detection from electrocardiograms recorded on a wearable device. In the context of AF detection, two approaches are considered: a multi-layer perceptron (MLP) which receives as input the ECG features computed and encrypted on the wearable device, and an end-to-end deep convolutional neural network (1D-CNN), which receives as input the encrypted raw ECG data. The CNN model achieves a lower mean F1-score than the hand-crafted feature-based model. This illustrates the benefit of hand-crafted features over deep convolutional neural networks, especially in a setting with a small training data. Compared to state-of-the-art results, the two privacy-preserving approaches lead, with reasonable computational overhead, to slightly lower, but still similar results: the small performance drop is caused by limitations related to the use of homomorphically encrypted data instead of plaintext data. The findings highlight the potential of the proposed framework to enhance the functionality of wearables through privacy-preserving AI, by providing, within a reasonable amount of time, results equivalent to those achieved without privacy enhancing mechanisms. While the chosen homomorphic encryption scheme prioritizes performance and utility, certain security shortcomings remain open for future development.",Applied Sciences,2021.0,10.3390/app11199049,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64b474666d9c5b98b424bb7dc51204fb4ca4c421,https://www.semanticscholar.org/paper/64b474666d9c5b98b424bb7dc51204fb4ca4c421,"Learning to Grasp for Robotics Applications in Uncertain
Environments","We are currently witnessing a revolution in the use and deployment of robotics systems. On top of an increased pace of automation in traditional industries like automotive and electronics manufacturing, robots are now used in a wide range of applications, from health care to agriculture. New records of robot sales have been set every year for the past several years. This revolution is fueled by incredible advances in several fields including machine learning, machine vision, human-robot interaction, and computing systems and architectures.",,2020.0,10.11159/cdsr20.04,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
81e4fa15bb6061e0e288d8ff70bbf78939c38aa9,https://www.semanticscholar.org/paper/81e4fa15bb6061e0e288d8ff70bbf78939c38aa9,Unsupervised learning for economic risk evaluation in the context of Covid-19 pandemic,"Justifying draconian measures during the Covid-19 pandemic was difficult not only because of the restriction of individual rights, but also because of its economic impact. The objective of this work is to present a machine learning approach to identify regions that should implement similar health policies. For that end, we successfully developed a system that gives a notion of economic impact given the prediction of new incidental cases through unsupervised learning and time series forecasting. This system was built taking into account computational restrictions and low maintenance requirements in order to improve the system's resilience. Finally this system was deployed as part of a web application for simulation and data analysis of COVID-19, in Colombia, available at (this https URL).",ArXiv,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4e92da908d0b2829b69d621d6bce38c5e9c4380d,https://www.semanticscholar.org/paper/4e92da908d0b2829b69d621d6bce38c5e9c4380d,An Interpretable Experimental Data Augmentation Method to Improve Knee Health Classification Using Joint Acoustic Emissions.,,Annals of biomedical engineering,2021.0,10.1007/s10439-021-02788-x,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b430010a136ca36a33aee4303972502dc7963915,https://www.semanticscholar.org/paper/b430010a136ca36a33aee4303972502dc7963915,A multi-analysis approach for estimating regional health impacts from the 2017 Northern California wildfires,"ABSTRACT Smoke impacts from large wildfires are mounting, and the projection is for more such events in the future as the one experienced October 2017 in Northern California, and subsequently in 2018 and 2020. Further, the evidence is growing about the health impacts from these events which are also difficult to simulate. Therefore, we simulated air quality conditions using a suite of remotely-sensed data, surface observational data, chemical transport modeling with WRF-CMAQ, one data fusion, and three machine learning methods to arrive at datasets useful to air quality and health impact analyses. To demonstrate these analyses, we estimated the health impacts from smoke impacts during wildfires in October 8–20, 2017, in Northern California, when over 7 million people were exposed to Unhealthy to Very Unhealthy air quality conditions. We investigated using the 5-min available GOES-16 fire detection data to simulate timing of fire activity to allocate emissions hourly for the WRF-CMAQ system. Interestingly, this approach did not necessarily improve overall results, however it was key to simulating the initial 12-hr explosive fire activity and smoke impacts. To improve these results, we applied one data fusion and three machine learning algorithms. We also had a unique opportunity to evaluate results with temporary monitors deployed specifically for wildfires, and performance was markedly different. For example, at the permanent monitoring locations, the WRF-CMAQ simulations had a Pearson correlation of 0.65, and the data fusion approach improved this (Pearson correlation = 0.95), while at the temporary monitor locations across all cases, the best Pearson correlation was 0.5. Overall, WRF-CMAQ simulations were biased high and the geostatistical methods were biased low. Finally, we applied the optimized PM2.5 exposure estimate in an exposure-response function. Estimated mortality attributable to PM2.5 exposure during the smoke episode was 83 (95% CI: 0, 196) with 47% attributable to wildland fire smoke. Implications: Large wildfires in the United States and in particular California are becoming increasingly common. Associated with these large wildfires are air quality and health impact to millions of people from the smoke. We simulated air quality conditions using a suite of remotely-sensed data, surface observational data, chemical transport modeling, one data fusion, and three machine learning methods to arrive at datasets useful to air quality and health impact analyses from the October 2017 Northern California wildfires. Temporary monitors deployed for the wildfires provided an important model evaluation dataset. Total estimated regional mortality attributable to PM2.5 exposure during the smoke episode was 83 (95% confidence interval: 0, 196) with 47% of these deaths attributable to the wildland fire smoke. This illustrates the profound effect that even a 12-day exposure to wildland fire smoke can have on human health.",Journal of the Air & Waste Management Association,2021.0,10.1080/10962247.2021.1891994,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e46d58866eb02a30bb129e8d4284856822a1cc2a,https://www.semanticscholar.org/paper/e46d58866eb02a30bb129e8d4284856822a1cc2a,Towards Understanding the Role of Gender in Deploying Social Media-Based Mental Health Surveillance Models,"Spurred by advances in machine learning and natural language processing, developing social media-based mental health surveillance models has received substantial recent attention. For these models to be maximally useful, it is necessary to understand how they perform on various subgroups, especially those defined in terms of protected characteristics. In this paper we study the relationship between user demographics – focusing on gender – and depression. Considering a population of Reddit users with known genders and depression statuses, we analyze the degree to which depression predictions are subject to biases along gender lines using domain-informed classifiers. We then study our models’ parameters to gain qualitative insight into the differences in posting behavior across genders.",CLPSYCH,2021.0,10.18653/V1/2021.CLPSYCH-1.23,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
225698970acbd600b7d7bc43bae16d6636f13cde,https://www.semanticscholar.org/paper/225698970acbd600b7d7bc43bae16d6636f13cde,Implications of COVID-19 vaccination and public health countermeasures on SARS-CoV-2 variants of concern in Canada: evidence from a spatial hierarchical cluster analysis,"Background: The influence of coronavirus disease-2019 (COVID-19) containment measures on variants of concern (VOC) has been understudied in Canada. Our objective was to identify provinces with disproportionate prevalence of VOC relative to COVID-19 mitigation efforts in provinces and territories in Canada. Methods: We analyzed publicly available provincial- and territorial-level data on the prevalence of VOCs in relation to mitigating factors (summarized in three measures: 1. strength of public health countermeasures: stringency index, 2. how much people moved about outside their homes: mobility index, and 3. vaccine intervention: proportion of Canadian population fully vaccinated). Using spatial agglomerative hierarchical cluster analysis (unsupervised machine learning), the provinces and territories were grouped into clusters by stringency index, mobility index and full vaccine coverage. Kruskal-Wallis test was used to determine the differences in the prevalence of VOC (Alpha, or B.1.1.7, Beta, or B.1.351, Gamma, or P.1, and Delta, or B.1.617.2 variants) between the clusters. Results: Three clusters of vaccine uptake and countermeasures were identified. Cluster 1 consisted of the three Canadian territories, and characterized by higher degree of vaccine deployment and lesser degree of countermeasures. Cluster 2 (located in Central Canada and Atlantic region) was typified by lesser implementation of vaccine deployment and moderate countermeasures. The third cluster was formed by provinces inthe Pacific region, Central Canada, and Prairie region, with moderate vaccine deployment but stronger countermeasures. The overall and variant-specific prevalence were significantly different across the clusters. Interpretation: This study found that implementation of COVID-19 public health measures varied across the provinces and territories. Considering the high prevalence of VOCs in Canada, completing the second dose of COVID-19 vaccine in a timely manner is crucial.",medRxiv,2021.0,10.1101/2021.06.28.21259629,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5f82d4b2526ad9f9b14702b43221a6f99050b48b,https://www.semanticscholar.org/paper/5f82d4b2526ad9f9b14702b43221a6f99050b48b,A survey of extant organizational and computational setups for deploying predictive models in health systems,"Abstract Objective Artificial intelligence (AI) and machine learning (ML) enabled healthcare is now feasible for many health systems, yet little is known about effective strategies of system architecture and governance mechanisms for implementation. Our objective was to identify the different computational and organizational setups that early-adopter health systems have utilized to integrate AI/ML clinical decision support (AI-CDS) and scrutinize their trade-offs. Materials and Methods We conducted structured interviews with health systems with AI deployment experience about their organizational and computational setups for deploying AI-CDS at point of care. Results We contacted 34 health systems and interviewed 20 healthcare sites (58% response rate). Twelve (60%) sites used the native electronic health record vendor configuration for model development and deployment, making it the most common shared infrastructure. Nine (45%) sites used alternative computational configurations which varied significantly. Organizational configurations for managing AI-CDS were distinguished by how they identified model needs, built and implemented models, and were separable into 3 major types: Decentralized translation (n = 10, 50%), IT Department led (n = 2, 10%), and AI in Healthcare (AIHC) Team (n = 8, 40%). Discussion No singular computational configuration enables all current use cases for AI-CDS. Health systems need to consider their desired applications for AI-CDS and whether investment in extending the off-the-shelf infrastructure is needed. Each organizational setup confers trade-offs for health systems planning strategies to implement AI-CDS. Conclusion Health systems will be able to use this framework to understand strengths and weaknesses of alternative organizational and computational setups when designing their strategy for artificial intelligence.",J. Am. Medical Informatics Assoc.,2021.0,10.1093/jamia/ocab154,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f58e158ce2316cdcdc32e057ccf83cc05113999d,https://www.semanticscholar.org/paper/f58e158ce2316cdcdc32e057ccf83cc05113999d,Developing an Automatic System for Classifying Chatter About Health Services on Twitter: Case Study for Medicaid,"Background The wide adoption of social media in daily life renders it a rich and effective resource for conducting near real-time assessments of consumers’ perceptions of health services. However, its use in these assessments can be challenging because of the vast amount of data and the diversity of content in social media chatter. Objective This study aims to develop and evaluate an automatic system involving natural language processing and machine learning to automatically characterize user-posted Twitter data about health services using Medicaid, the single largest source of health coverage in the United States, as an example. Methods We collected data from Twitter in two ways: via the public streaming application programming interface using Medicaid-related keywords (Corpus 1) and by using the website’s search option for tweets mentioning agency-specific handles (Corpus 2). We manually labeled a sample of tweets in 5 predetermined categories or other and artificially increased the number of training posts from specific low-frequency categories. Using the manually labeled data, we trained and evaluated several supervised learning algorithms, including support vector machine, random forest (RF), naïve Bayes, shallow neural network (NN), k-nearest neighbor, bidirectional long short-term memory, and bidirectional encoder representations from transformers (BERT). We then applied the best-performing classifier to the collected tweets for postclassification analyses to assess the utility of our methods. Results We manually annotated 11,379 tweets (Corpus 1: 9179; Corpus 2: 2200) and used 7930 (69.7%) for training, 1449 (12.7%) for validation, and 2000 (17.6%) for testing. A classifier based on BERT obtained the highest accuracies (81.7%, Corpus 1; 80.7%, Corpus 2) and F1 scores on consumer feedback (0.58, Corpus 1; 0.90, Corpus 2), outperforming the second best classifiers in terms of accuracy (74.6%, RF on Corpus 1; 69.4%, RF on Corpus 2) and F1 score on consumer feedback (0.44, NN on Corpus 1; 0.82, RF on Corpus 2). Postclassification analyses revealed differing intercorpora distributions of tweet categories, with political (400778/628411, 63.78%) and consumer feedback (15073/27337, 55.14%) tweets being the most frequent for Corpus 1 and Corpus 2, respectively. Conclusions The broad and variable content of Medicaid-related tweets necessitates automatic categorization to identify topic-relevant posts. Our proposed system presents a feasible solution for automatic categorization and can be deployed and generalized for health service programs other than Medicaid. Annotated data and methods are available for future studies.",Journal of medical Internet research,2021.0,10.2196/26616,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7807653c33b3ccb154af8f8863edb7988112f29a,https://www.semanticscholar.org/paper/7807653c33b3ccb154af8f8863edb7988112f29a,Human-Machine and Human-Robot Interaction for Long-Term User Engagement and Behavior Change,"The nexus of in-home intelligent assistants, activity tracking, and machine learning creates opportunities for personalized virtual and physical agents / robots that can positively impacts user health and quality of life. Well beyond providing information, such agents can serve as physical and mental health and education coaches and companions that support positive behavior change. However, sustaining user engagement and motivation over long-term interactions presents complex challenges. Our work over the past 15 years has addressed those challenges by developing human-machine (human-robot) interaction methods for socially assistive robotics that utilize multi-modal interaction data and expressive agent behavior to monitor, coach, and motivate users to engage in heath- and wellness-promoting activities. This talk will present methods and results of modeling, learning, and personalizing user motivation, engagement, and coaching of healthy children and adults, as well as stroke patients, Alzheimer's patients, and children with autism spectrum disorders, in short and long-term (month+) deployments in schools, therapy centers, and homes, and discuss research and commercial implications for technologies aimed at human daily use.",MobiCom,2019.0,10.1145/3300061.3300141,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c95f1578fe2cdcf78f7d94631da6319e0080822f,https://www.semanticscholar.org/paper/c95f1578fe2cdcf78f7d94631da6319e0080822f,Advancing care for acute gastrointestinal bleeding using artificial intelligence,"The future of gastrointestinal bleeding will include the integration of machine learning algorithms to enhance clinician risk assessment and decision making. Machine learning algorithms have shown promise in outperforming existing clinical risk scores for both upper and lower gastrointestinal bleeding but have not been validated in any prospective clinical trials. The adoption of electronic health records provides an exciting opportunity to deploy risk prediction tools in real time and also to expand the data available to train predictive models. Machine learning algorithms can be used to identify patients with acute gastrointestinal bleeding using data extracted from the electronic health record. This can lead to an automated process to find patients with symptoms of acute gastrointestinal bleeding so that risk prediction tools can be then triggered to consistently provide decision support to the physician. Neural network models can be used to provide continuous risk predictions for patients who are at higher risk, which can be used to guide triage of patients to appropriate levels of care. Finally, the future will likely include neural network‐based analysis of endoscopic stigmata of bleeding to help guide best practices for hemostasis during the endoscopic procedure. Machine learning will enhance the delivery of care at every level for patients with acute gastrointestinal bleeding through identifying very low risk patients for outpatient management, triaging high risk patients for higher levels of care, and guiding optimal intervention during endoscopy.",Journal of gastroenterology and hepatology,2021.0,10.1111/jgh.15372,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1592204ecb311b4e70b9d79f9722a7878e04b886,https://www.semanticscholar.org/paper/1592204ecb311b4e70b9d79f9722a7878e04b886,Agile Requirements Engineering and Software Planning for a Digital Health Platform to Engage the Effects of Isolation Caused by Social Distancing: Case Study,"Background Social distancing and shielding measures have been put in place to reduce social interaction and slow the transmission of the coronavirus disease (COVID-19). For older people, self-isolation presents particular challenges for mental health and social relationships. As time progresses, continued social distancing could have a compounding impact on these concerns. Objective This project aims to provide a tool for older people and their families and peers to improve their well-being and health during and after regulated social distancing. First, we will evaluate the tool’s feasibility, acceptability, and usability to encourage positive nutrition, enhance physical activity, and enable virtual interaction while social distancing. Second, we will be implementing the app to provide an online community to assist families and peer groups in maintaining contact with older people using goal setting. Anonymized data from the app will be aggregated with other real-world data sources to develop a machine learning algorithm to improve the identification of patients with COVID-19 and track for real time use by health systems. Methods Development of this project is occurring at the time of publication, and therefore, a case study design was selected to provide a systematic means of capturing software engineering in progress. The app development framework for software design was based on agile methods. The evaluation of the app’s feasibility, acceptability and usability shall be conducted using Public Health England's guidance on evaluating digital health products, Bandura’s model of health promotion, the Reach Effectiveness Adoption Implementation Maintenance (RE-AIM) framework and the Nonadoption, Abandonment and Challenges to the Scale-up, Spread and Suitability (NASSS) framework. Results Making use of a pre-existing software framework for health behavior change, a proof of concept was developed, and a multistage app development and deployment for the solution was created. Grant submissions to fund the project and study execution have been sought at the time of publication, and prediscovery iteration of the solution has begun. Ethical approval for a feasibility study design is being sought. Conclusions This case study lays the foundations for future app development to combat mental and societal issues arising from social distancing measures. The app will be tested and evaluated in future studies to allow continuous improvement of the app. This novel contribution will provide an evidence-based exemplar for future app development in the space of social isolation and loneliness.",JMIR public health and surveillance,2020.0,10.2196/19297,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8f8509740433b322aca3c8a0f29e15f339d4abe7,https://www.semanticscholar.org/paper/8f8509740433b322aca3c8a0f29e15f339d4abe7,ZARATAMAP: Noise Characterization in the Scope of a Smart City through a Low Cost and Mobile Electronic Embedded System,"Like other sources of pollution, noise is considered to be one of the main concerns of citizens, due to its invisibility and the potential harm it can cause. Noise pollution could be considered as one of the biggest quality-of-life concerns for urban residents in big cities, mainly due to the high levels of noise to which they may be exposed. Such levels have proven effects on health, such as: sleep disruption, hypertension, heart disease, and hearing loss. In a scenario where the number of people concentrated in cities is increasing, tools are needed to quantify, monitor, characterize, and quantify noise levels. This paper presents the ZARATAMAP project, which combines machine learning techniques with a geo-sensing application so that the authorities can have as much information as possible, using a low-cost embedded and mobile node, that is easy to deploy, develop, and use.",Sensors,2021.0,10.3390/s21051707,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
450536c8e297ccb01fbde64d7a50ec6d021ea351,https://www.semanticscholar.org/paper/450536c8e297ccb01fbde64d7a50ec6d021ea351,Deep learning-based cross-sensor domain adaptation for fault diagnosis of electro-mechanical actuators,,,2020.0,10.1007/s40435-020-00669-0,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
923c4104c48a83407d2a20444a332e4a5ed1451a,https://www.semanticscholar.org/paper/923c4104c48a83407d2a20444a332e4a5ed1451a,Overcoming limited battery data challenges: A coupled neural network approach,"The electric vehicle (EV) industry has seen extraordinary growth in the last few years. This is primarily due to an ever increasing awareness of the detrimental environmental effects of fossil fuel powered vehicles and availability of inexpensive lithium‐ion batteries (LIBs). In order to safely deploy these LIBs in electric vehicles, certain battery states need to be constantly monitored to ensure safe and healthy operation. The use of machine learning to estimate battery states such as state‐of‐charge and state‐of‐health have become an extremely active area of research. However, limited availability of open‐source diverse datasets has stifled the growth of this field, and is a problem largely ignored in the literature. In this work, we propose a novel method of time‐series battery data augmentation using deep neural networks. We introduce and analyze the method of using two neural networks working together to alternatively produce synthetic charging and discharging battery profiles. One model produces battery charging profiles, and another produces battery discharging profiles. The proposed approach is evaluated using few public battery datasets to illustrate its effectiveness, and our results show the efficacy of this approach to solve the challenges of limited battery data. We also test this approach on dynamic electric vehicle drive cycles as well.",International Journal of Energy Research,2021.0,10.1002/er.7081,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17975ca83e29963fa14867f42c95f1ba5c53d3a7,https://www.semanticscholar.org/paper/17975ca83e29963fa14867f42c95f1ba5c53d3a7,Health Care Analytics With Time-Invariant and Time-Variant Feature Importance to Predict Hospital-Acquired Acute Kidney Injury: Observational Longitudinal Study (Preprint),"
 BACKGROUND
 Acute kidney injury (AKI) develops in 4% of hospitalized patients and is a marker of clinical deterioration and nephrotoxicity. AKI onset is highly variable in hospitals, which makes it difficult to time biomarker assessment in all patients for preemptive care.
 
 
 OBJECTIVE
 The study sought to apply machine learning techniques to electronic health records and predict hospital-acquired AKI by a 48-hour lead time, with the aim to create an AKI surveillance algorithm that is deployable in real time.
 
 
 METHODS
 The data were sourced from 20,732 case admissions in 16,288 patients over 1 year in our institution. We enhanced the bidirectional recurrent neural network model with a novel time-invariant and time-variant aggregated module to capture important clinical features temporal to AKI in every patient. Time-series features included laboratory parameters that preceded a 48-hour prediction window before AKI onset; the latter’s corresponding reference was the final in-hospital serum creatinine performed in case admissions without AKI episodes.
 
 
 RESULTS
 The cohort was of mean age 53 (SD 25) years, of whom 29%, 12%, 12%, and 53% had diabetes, ischemic heart disease, cancers, and baseline eGFR <90 mL/min/1.73 m2, respectively. There were 911 AKI episodes in 869 patients. We derived and validated an algorithm in the testing dataset with an AUROC of 0.81 (0.78-0.85) for predicting AKI. At a 15% prediction threshold, our model generated 699 AKI alerts with 2 false positives for every true AKI and predicted 26% of AKIs. A lowered 5% prediction threshold improved the recall to 60% but generated 3746 AKI alerts with 6 false positives for every true AKI. Representative interpretation results produced by our model alluded to the top-ranked features that predicted AKI that could be categorized in association with sepsis, acute coronary syndrome, nephrotoxicity, or multiorgan injury, specific to every case at risk.
 
 
 CONCLUSIONS
 We generated an accurate algorithm from electronic health records through machine learning that predicted AKI by a lead time of at least 48 hours. The prediction threshold could be adjusted during deployment to optimize recall and minimize alert fatigue, while its precision could potentially be augmented by targeted AKI biomarker assessment in the high-risk cohort identified.
",,2021.0,10.2196/preprints.30805,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a7b0240f34002c62bcbb8d5089949b1d7664004,https://www.semanticscholar.org/paper/3a7b0240f34002c62bcbb8d5089949b1d7664004,Digital-Health Tourism Research-Methodology Coronavirus-Vaccination Trials: A Study Interpreting Geometa-Data Profiling to use Mobile-Health Technologies Nigeria,"Digital-Health Tourism Innovation (DTI) worldwide is in its infancy due to the emergent of coronavirus (COVID-19) disease. With the growth of open geometa data, use of government electronic services including electronic health (e-health), electronic commerce (e-commerce) and mobile health (m-health), Artificial Intelligence (AI) and machine learning strategies. Health and primary healthcare sectors are currently adopting these innovations for socio-economic wellbeing. Digital-health (also termed as e-health) is part of digital tourism innovation. Adapting geometa data profiling to develop a digital-health tourism framework for Primary Healthcare Workers (PHWs) to use mobile health technologies in COVID-19 vaccination trials are the key challenges of this study. Nevertheless, digital health tourism skills have been launched in developing Nations that created thousands of jobs to protect digital tourism businesses from potential vulnerabilities. Despite the benefits of this novel innovation, its deployment and implementation have been treated by inadequate of ICT facilities, lack of geometa data pre-processing to remove noise, data integrity, insufficient of academic research fundings, and reliable research methodology beyond COVID-19 vaccination trials to highlight these aspects. Therefore, qualitative, and quantitative research methods using Precaution Adoption Model Process (PAMP) questionnaire are employed to enable new ways of pre-processing behavior intention factors items. Eight academic researchers who were conversant with digital health technology validated 28 behavior intention factors with average factor loading values of 50% to 75%. Pilot survey conducted among 700 respondents from March 18, 2020, to September 10, 2021, among them are undergraduate students that may use this technology for research purposes. Pre-processed geometa data have shown percentage frequency counts of internet access and other online services 8% to 95%, adapted training factors 49% to 92% and factor items 34% to 78.3% for hypothesis generation towards development of digital health tourism framework in finding explanation to COVID-19 economic challenges. Except behavior intention factors and factor items insights are known and mapped, mobile health technology design process may result in poor conclusions. Thus, patients recovered from COVID-19 infection can still be infected again.",Emerging Advances in Integrated Technology,2021.0,10.30880/emait.2021.02.02.005,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a1208fd6b4a7a314c90c2b4bf103e5993134e52,https://www.semanticscholar.org/paper/2a1208fd6b4a7a314c90c2b4bf103e5993134e52,Connecting Health Immersion of Digital into eHealth,,Introduction to Nursing Informatics,2021.0,10.1007/978-3-030-58740-6_2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a50cfaadbd1d43ea92800c6500f22b43760945e3,https://www.semanticscholar.org/paper/a50cfaadbd1d43ea92800c6500f22b43760945e3,Health crisis situation awareness using mobile multiple modalities,"Responding to health crises requires the deployment of accurate and timely situation awareness. Understanding the location of geographical risk factors could assist in preventing the spread of contagious diseases and the system developed, Covid ID, is an attempt to solve this problem through the crowd sourcing of machine learning sensor-based health related detection reports. Specifically, Covid ID uses mobile-based Computer Vision and Machine Learning with a multi-faceted approach to understanding potential risks related to Mask Detection, Crowd Density Estimation, Social Distancing Analysis, and IR Fever Detection. Both visible-spectrum and LWIR images are used. Real results for all modules are presented along with the developed Android Application and supporting backend.",Defense + Commercial Sensing,2021.0,10.1117/12.2587544,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
94a22e443caa92b6165b263e221b49e8a526eeec,https://www.semanticscholar.org/paper/94a22e443caa92b6165b263e221b49e8a526eeec,"Physical activity, sedentary behaviour, and sleep on Twitter: A labelled dataset for public health research","Advances in automated data processing, together with the unprecedented growth in user-generated social media (SM) content, have made public health surveillance (PHS) one of the long-lasting SM applications. However, the existing PHS systems feeding on SM data have not been widely deployed in national surveillance systems, which appears to stem from the lack of practitioners' trust in SM data. More robust datasets over which machine learning (ML) models can be trained/tested reliably is a significant step toward overcoming this hurdle. The health implications of physical activity, sedentary behaviour, and sleep (PASS) are widely studied through traditional data sources, which are often out-of-date, costly to collect, and thus limited in quantity and coverage. We present LPHEADA, a multicountry and fully Labelled digital Public HEAlth DAtaset of tweets originated in Australia/Canada/United Kingdom/United States between November 2018-June 2020. LPHEADA contains 366,405 labels for 122,135 PASS-related tweets and provides details about the place/time/demographics associated with each tweet. LPHEADA is publicly available and can be utilized to develop (un)supervised ML models for digital PASS surveillance.",medRxiv,2021.0,10.1101/2021.04.13.21255449,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f6dabca5022f7e58a4e8e17781d82bdd73ac8494,https://www.semanticscholar.org/paper/f6dabca5022f7e58a4e8e17781d82bdd73ac8494,Optimum Lightweight AI End Device for Health Monitoring of Agriculture Vehicles,,Springer Tracts in Nature-Inspired Computing,2021.0,10.1007/978-981-16-3128-3_11,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d32535da9ade3745014252e1ff919723060507b4,https://www.semanticscholar.org/paper/d32535da9ade3745014252e1ff919723060507b4,Adversarial Sample Enhanced Domain Adaptation: A Case Study on Predictive Modeling with Electronic Health Records,"With the successful adoption of machine learning on electronic health records (EHRs), numerous computational models have been deployed to address a variety of clinical problems. However, due to the heterogeneity of EHRs, models trained on different patient groups suffer from poor generalizability. How to mitigate domain shifts between the source patient group where the model is built upon and the target one where the model will be deployed becomes a critical issue. In this paper, we propose a data augmentation method to facilitate domain adaptation, which leverages knowledge from the source patient group when training model on the target one. Specifically, adversarially generated samples are used during domain adaptation to fill the generalization gap between the two patient groups. The proposed method is evaluated by a case study on different predictive modeling tasks on MIMIC-III EHR dataset. Results confirm the effectiveness of our method and the generality on different tasks.",ArXiv,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
916325c49aafb6891f404250781530ca8ab043b6,https://www.semanticscholar.org/paper/916325c49aafb6891f404250781530ca8ab043b6,A Review on Bayesian Deep Learning in Healthcare: Applications and Challenges,"In the last decade, Deep Learning (DL) has revolutionized the use of artificial intelligence, and it has been deployed in different fields of healthcare applications such as image processing, natural language processing, and signal processing. DL models have also been intensely used in different tasks of healthcare such as disease diagnostics and treatments. Deep learning techniques have surpassed other machine learning algorithms and proved to be the ultimate tools for many state-of-the-art applications. Despite all that success, classical deep learning has limitations and their models tend to be very confident about their predicted decisions because it does not know when it makes mistake. For the healthcare field, this limitation can have a negative impact on models predictions since almost all decisions regarding patients and diseases are sensitive. Therefore, Bayesian deep learning (BDL) has been developed to overcome these limitations. Unlike classical DL, BDL uses probability distributions for the model parameters, which makes it possible to estimate the whole uncertainties associated with the predicted outputs. In this regard, BDL offers a rigorous framework to quantify all sources of uncertainties in the model. This study reviews popular techniques of using Bayesian deep learning with their benefits and limitations. It also reviewed recent deep learning architecture such as Convolutional Neural Networks and Recurrent Neural Networks. In particular, the applications of Bayesian deep learning in healthcare have been discussed such as its use in medical imaging tasks, clinical signal processing, medical natural language processing, and electronic health records. Furthermore, this paper has covered the deployment of Bayesian deep learning for some of the widespread diseases. This paper has also discussed the fundamental research challenges and highlighted some research gaps in both the Bayesian deep learning and healthcare perspective.",IEEE Access,2022.0,10.1109/access.2022.3163384,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4e34cf88f57e79e8e524451aad1cfdf840e1b158,https://www.semanticscholar.org/paper/4e34cf88f57e79e8e524451aad1cfdf840e1b158,A Fully Private Pipeline for Deep Learning on Electronic Health Records,"We introduce an end-to-end private deep learning framework, applied to the task of predicting 30-day readmission from electronic health records. By using differential privacy during training and homomorphic encryption during inference, we demonstrate that our proposed pipeline could maintain high performance while providing robust privacy guarantees against information leak from data transmission or attacks against the model. We also explore several techniques to address the privacy-utility trade-off in deploying neural networks with privacy mechanisms, improving the accuracy of differentially-private training and the computation cost of encrypted operations using ideas from both machine learning and cryptography.",ArXiv,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
157246efaa0a667383cd78da0599231687368e0e,https://www.semanticscholar.org/paper/157246efaa0a667383cd78da0599231687368e0e,Towards Fairness Certification in Artificial Intelligence,"Thanks to the great progress of machine learning in the last years, several Artificial Intelligence (AI) techniques have been increasingly moving from the controlled research laboratory settings to our everyday life. The most simple examples are the spam filters that keep our email account in order, face detectors that help us when taking a portrait picture, online recommender systems that suggest which movie and clothing we might like, or interactive maps that navigate us towards our vacation home. Artificial intelligence is clearly supportive in many decision-making scenarios, but when it comes to sensitive areas such as health care, hiring policies, education, banking or justice, with major impact on individuals and society, it becomes crucial to establish guidelines on how to design, develop, deploy and monitor this technology. Indeed the decision rules elaborated by machine learning models are data-driven and there are multiple ways in which discriminatory biases can seep into data. Algorithms trained on those data incur the risk of amplifying prejudices and societal stereotypes by over associating protected attributes such as gender, ethnicity or disabilities with the prediction task.",ArXiv,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5c1202dec23380338680138f9588cee634173a0,https://www.semanticscholar.org/paper/a5c1202dec23380338680138f9588cee634173a0,"The times, they are a-changin’: tracking shifts in mental health signals from early phase to later phase of the COVID-19 pandemic in Australia","Introduction Widespread problems of psychological distress have been observed in many countries following the outbreak of COVID-19, including Australia. What is lacking from current scholarship is a national-scale assessment that tracks the shifts in mental health during the pandemic timeline and across geographic contexts. Methods Drawing on 244 406 geotagged tweets in Australia from 1 January 2020 to 31 May 2021, we employed machine learning and spatial mapping techniques to classify, measure and map changes in the Australian public’s mental health signals, and track their change across the different phases of the pandemic in eight Australian capital cities. Results Australians’ mental health signals, quantified by sentiment scores, have a shift from pessimistic (early pandemic) to optimistic (middle pandemic), reflected by a 174.1% (95% CI 154.8 to 194.5) increase in sentiment scores. However, the signals progressively recessed towards a more pessimistic outlook (later pandemic) with a decrease in sentiment scores by 48.8% (95% CI 34.7 to 64.9). Such changes in mental health signals vary across capital cities. Conclusion We set out a novel empirical framework using social media to systematically classify, measure, map and track the mental health of a nation. Our approach is designed in a manner that can readily be augmented into an ongoing monitoring capacity and extended to other nations. Tracking locales where people are displaying elevated levels of pessimistic mental health signals provide important information for the smart deployment of finite mental health services. This is especially critical in a time of crisis during which resources are stretched beyond normal bounds.",BMJ Global Health,2022.0,10.1136/bmjgh-2021-007081,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
47ad80aeb8477946cd26b96b711fb0b1fafdebdf,https://www.semanticscholar.org/paper/47ad80aeb8477946cd26b96b711fb0b1fafdebdf,http://ijai.iaescore.com A comprehensive review on machine learning in agriculture,"2022 Agriculture is an essential part of sustaining human life. Population growth, climate change, resource competition are the key issues that increase food security and to handle such complex problems in agriculture production, intelligent or smart farming extends the incorporation of technology into traditional agriculture notion. Machine learning is a vitally used technology in agriculture to protect food security and sustainability. Crop yield production, water preservation, soil health and plant diseases can be addressed by machine learning. This paper has presented a compendious review of research papers that deployed machine learning in the agriculture domain. The observed sub-categories of the agriculture domain are crop yield prediction, soil management, pest management, weed management, and crop disease. The outcomes represent that machine learning provides better accuracy concerning classification or regression. Machine learning emerged with the internet of things, drones, robots, automated machinery, and satellite imagery motivates researchers for smart farming and food",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
89970b554044e83226ffa55ddbb2067eb6ae3673,https://www.semanticscholar.org/paper/89970b554044e83226ffa55ddbb2067eb6ae3673,Q-learning-enabled channel access in next-generation dense wireless networks for IoT-based eHealth systems,,EURASIP J. Wirel. Commun. Netw.,2019,10.1186/s13638-019-1498-x,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b570162aa02425ee2ea57f233a734413983fdf13,https://www.semanticscholar.org/paper/b570162aa02425ee2ea57f233a734413983fdf13,Disease Prediction Through Syndromes by Clustering Algorithm,There are numerous machine learning methods that capable to develop smart automated algorithms to examine high-dimensional and multi-modal biomedical dataset. This paper emphases on through clustering algorithms to advance revealing and analysis of human diseases. The mass population’s disease assessment was not ever been familiar and nevertheless is an intricate procedure and necessitates a great level of competence. Numerous assessment support methods established encouraging diagnostic representations however merely an insufficient have been properly estimated in clinical surroundings. Moreover stand-alone decision support systems rely on profoundly on a massive volume of dataset. This research deploy unsupervised clustering approach such as K-means algorithm to build a proficient system to recognize human diseases by assessing syndromes to progress the superiority of health issues. The medical professionals and practitioners can use this smart system to corroborate the diseases diagnosis. The study is significant in health sector to reduce all kinds of diagnosis expenses.,,2021,10.11648/J.AJEIT.20210502.15,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
46e69daa3fa2804907619b9d59192f21eef65c7d,https://www.semanticscholar.org/paper/46e69daa3fa2804907619b9d59192f21eef65c7d,Known and Unknown Transboundary Infectious Diseases as Hybrid Threats,"The pathogenicity, transmissibility, environmental stability, and potential for genetic manipulation make microbes hybrid threats that could blur the distinction between peace and war. These agents can fall below the detection, attribution, and response capabilities of a nation and seriously affect their health, trade, and security. A framework that could enhance horizon scanning regarding the potential risk of microbes used as hybrid threats requires not only accurately discriminating known and unknown pathogens but building novel scenarios to deploy mitigation strategies. This demands the transition of analyst-based biosurveillance tracking a narrow set of pathogens toward an autonomous biosurveillance enterprise capable of processing vast data streams beyond human cognitive capabilities. Autonomous surveillance systems must gather, integrate, analyze, and visualize billions of data points from different and unrelated sources. Machine learning and artificial intelligence algorithms can contextualize capability information for different stakeholders at different levels of resolution: strategic and tactical. This document provides a discussion of the use of microorganisms as hybrid threats and considerations to quantitatively estimate their risk to ensure societal awareness, preparedness, mitigation, and resilience.",Frontiers in Public Health,2021,10.3389/fpubh.2021.668062,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
be55fd77c4ff59800af2de4f822c22500f8c2dc0,https://www.semanticscholar.org/paper/be55fd77c4ff59800af2de4f822c22500f8c2dc0,High Performance Mining of Covid-19,"Abstract: The COVID-19 global pandemic is an unprecedented health crisis. Many researchers around the world have produced an extensive collection of literature since the outbreak. Analysing this information to extract knowledge and provide meaningful insights in a timely manner requires a considerable amount of computational power. Cloud platforms are designed to provide this computational power in an on-demand and elastic manner. Specifically, hybrid clouds, composed of private and public data centers, are particularly well suited to deploy computationally intensive workloads in a cost-efficient, yet scalable manner. In this paper, we developed a system utilising the Aneka Platform as a Service middleware with parallel processing and multi-cloud capability to accelerate the data process pipeline and article categorising process using machine learning on a hybrid cloud. The results are then persisted for further referencing, searching and visualising. The performance evaluation shows that the system can help with reducing processing time and achieving linear scalability. Beyond COVID-19, the application might be used directly in broader scholarly article indexing and analysing.",International Journal for Research in Applied Science and Engineering Technology,2022,10.22214/ijraset.2022.45702,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f48e6066aa7312adeeb8dcf2eec89c4ffd6630d9,https://www.semanticscholar.org/paper/f48e6066aa7312adeeb8dcf2eec89c4ffd6630d9,"Physical Activity, Sedentary Behavior, and Sleep on Twitter: Multicountry and Fully Labeled Public Data Set for Digital Public Health Surveillance Research","Background Advances in automated data processing and machine learning (ML) models, together with the unprecedented growth in the number of social media users who publicly share and discuss health-related information, have made public health surveillance (PHS) one of the long-lasting social media applications. However, the existing PHS systems feeding on social media data have not been widely deployed in national surveillance systems, which appears to stem from the lack of practitioners and the public’s trust in social media data. More robust and reliable data sets over which supervised ML models can be trained and tested reliably is a significant step toward overcoming this hurdle. The health implications of daily behaviors (physical activity, sedentary behavior, and sleep [PASS]), as an evergreen topic in PHS, are widely studied through traditional data sources such as surveillance surveys and administrative databases, which are often several months out-of-date by the time they are used, costly to collect, and thus limited in quantity and coverage. Objective The main objective of this study is to present a large-scale, multicountry, longitudinal, and fully labeled data set to enable and support digital PASS surveillance research in PHS. To support high-quality surveillance research using our data set, we have conducted further analysis on the data set to supplement it with additional PHS-related metadata. Methods We collected the data of this study from Twitter using the Twitter livestream application programming interface between November 28, 2018, and June 19, 2020. To obtain PASS-related tweets for manual annotation, we iteratively used regular expressions, unsupervised natural language processing, domain-specific ontologies, and linguistic analysis. We used Amazon Mechanical Turk to label the collected data to self-reported PASS categories and implemented a quality control pipeline to monitor and manage the validity of crowd-generated labels. Moreover, we used ML, latent semantic analysis, linguistic analysis, and label inference analysis to validate the different components of the data set. Results LPHEADA (Labelled Digital Public Health Dataset) contains 366,405 crowd-generated labels (3 labels per tweet) for 122,135 PASS-related tweets that originated in Australia, Canada, the United Kingdom, or the United States, labeled by 708 unique annotators on Amazon Mechanical Turk. In addition to crowd-generated labels, LPHEADA provides details about the three critical components of any PHS system: place, time, and demographics (ie, gender and age range) associated with each tweet. Conclusions Publicly available data sets for digital PASS surveillance are usually isolated and only provide labels for small subsets of the data. We believe that the novelty and comprehensiveness of the data set provided in this study will help develop, evaluate, and deploy digital PASS surveillance systems. LPHEADA will be an invaluable resource for both public health researchers and practitioners.",JMIR public health and surveillance,2021,10.2196/32355,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
caf1eb17b91b0f1fb450703c9e81ecd6931924ca,https://www.semanticscholar.org/paper/caf1eb17b91b0f1fb450703c9e81ecd6931924ca,Accelerating the Uptake of Advanced Digital Technologies for Health and Safety Management within Construction: Small and Medium Enterprises (SMEs),"Health and safety problems are essential for the construction industry, and such problems are more pronounced in small and medium enterprises (SMEs) due to the lack of financial resources and skilled personnel. Researchers have explored the feasibility and viability of addressing such constraints using artificial intelligence-enhanced, low-cost sensor systems. Our previous studies have investigated both conventional machine learning and deep neural network models for recognizing workers' postures from low-cost wearable sensors and assessing the ergonomics risks for injury prevention. In the next steps for this research, we are investigating adoption drivers and diffusion barriers for the scaled deployment of AI-enhanced sensor networks and other emerging digital technologies for construction health and safety in a real-work setting. Although the COVID-19 pandemic has brought unprecedented challenges, it has also sped up the digital technology adoption. The discussion in this paper is directed at building on this momentum to advance the use of emerging digital technologies at construction SMEs. The authors conducted a systematic review of literature on digital technologies at construction SMEs and how COVID-19 affected the digital transformation at SMEs. After an initial screening of a total of 170 articles, the key publications based on the research questions were selected for a more in-depth analysis. It emerged that although construction SMEs have embraced the use of several digital technologies during the current pandemic, there is still a large digital divide between these companies and larger companies. The research discussed in this paper contributes to efforts directed at addressing this problem through the design and deployment of SME-centric digital technologies for construction health and safety. © 2021 Computing in Civil Engineering 2021 - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2021. All rights reserved.",Computing in Civil Engineering 2021,2022,10.1061/9780784483893.103,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bf6c13dcdcc7a7dd931b4c36698a98384258b960,https://www.semanticscholar.org/paper/bf6c13dcdcc7a7dd931b4c36698a98384258b960,Development and Experience with Cancer Risk Prediction Models Using Federated Databases and Electronic Health Records,"Early diagnosis is critical to improving survival rates of lethal cancers, such as pancreatic duct adenocarcinoma (PDAC). However, there are no reliable screening test for these cancers. In this chapter, we present potential methods for predicting early, evolving cancers by leveraging readily available electronic health record (EHR) data and machine learning. We discuss the various aspects of our Note to the Reader: This chapter is part of the book Digital Health (ISBN: 978-0-6453320-18), scheduled for publication in March 2022. The book is being published by Exon Publications, Brisbane, Australia, and edited by Professor Simon Lin Linwood, MD, MBA, UCR Health and UCR School of Medicine, Riverside, CA, USA. This chapter was published under the Rapid Publication service. It has been peer reviewed and accepted for publication, but not yet copyedited or typeset. The book in its final form will be copyedited and published in pdf, html, and xml formats as shown under Catalogue upon editorial acceptance of all chapters. The citation details will not change even after the publication of the book in its final format. collaborative experience, involving clinical and computer scientists, in navigating the process of using EHRs to develop cancer risk prediction models. This chapter is intended to serve as a guide to others preforming this type of research. We cover the different steps involved, based on our initial experience of model development using single-institution data, including data acquisition, querying and downloading data, protecting patient confidentiality, data curation, model development, and validation. Challenges encountered when using single-institution data is presented, along with lessons learned. Drawing from our experience working with a federated database of EHR data from multiple institutions to develop a risk prediction model for PDAC, we also discuss how many of these challenges can be addressed by using such a federated database of EHR data. We also discuss future clinical opportunities that may arise from leveraging data from a federated network, such as the deployment of risk models for clinical studies.",Digital Health,2022,10.36255/exon-publications-digital-health-federated-databases,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e036054e35e074de114bf3717793dfe697b08998,https://www.semanticscholar.org/paper/e036054e35e074de114bf3717793dfe697b08998,A Graphical Toolkit for Longitudinal Dataset Maintenance and Predictive Model Training in Health Care.,"BACKGROUND
 Predictive analytic models, including machine learning (ML) models, are increasingly integrated into electronic health record (EHR)-based decision support tools for clinicians. These models have the potential to improve care, but are challenging to internally validate, implement, and maintain over the long term. Principles of ML operations (MLOps) may inform development of infrastructure to support the entire ML lifecycle, from feature selection to long-term model deployment and retraining.


OBJECTIVES
 This study aimed to present the conceptual prototypes for a novel predictive model management system and to evaluate the acceptability of the system among three groups of end users.


METHODS
 Based on principles of user-centered software design, human-computer interaction, and ethical design, we created graphical prototypes of a web-based MLOps interface to support the construction, deployment, and maintenance of models using EHR data. To assess the acceptability of the interface, we conducted semistructured user interviews with three groups of users (health informaticians, clinical and data stakeholders, chief information officers) and evaluated preliminary usability using the System Usability Scale (SUS). We subsequently revised prototypes based on user input and developed user case studies.


RESULTS
 Our prototypes include design frameworks for feature selection, model training, deployment, long-term maintenance, visualization over time, and cross-functional collaboration. Users were able to complete 71% of prompted tasks without assistance. The average SUS score of the initial prototype was 75.8 out of 100, translating to a percentile range of 70 to 79, a letter grade of B, and an adjective rating of ""good."" We reviewed persona-based case studies that illustrate functionalities of this novel prototype.


CONCLUSION
 The initial graphical prototypes of this MLOps system are preliminarily usable and demonstrate an unmet need within the clinical informatics landscape.",Applied clinical informatics,2022,10.1055/s-0041-1740923,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4ef53bd2244435e0cbea10d8834f18e1d24b78fe,https://www.semanticscholar.org/paper/4ef53bd2244435e0cbea10d8834f18e1d24b78fe,Information Extraction From Electronic Health Records to Predict Readmission Following Acute Myocardial Infarction: Does Natural Language Processing Using Clinical Notes Improve Prediction of Readmission?,"Background Social risk factors influence rehospitalization rates yet are challenging to incorporate into prediction models. Integration of social risk factors using natural language processing (NLP) and machine learning could improve risk prediction of 30‐day readmission following an acute myocardial infarction. Methods and Results Patients were enrolled into derivation and validation cohorts. The derivation cohort included inpatient discharges from Vanderbilt University Medical Center between January 1, 2007, and December 31, 2016, with a primary diagnosis of acute myocardial infarction, who were discharged alive, and not transferred from another facility. The validation cohort included patients from Dartmouth‐Hitchcock Health Center between April 2, 2011, and December 31, 2016, meeting the same eligibility criteria described above. Data from both sites were linked to Centers for Medicare & Medicaid Services administrative data to supplement 30‐day hospital readmissions. Clinical notes from each cohort were extracted, and an NLP model was deployed, counting mentions of 7 social risk factors. Five machine learning models were run using clinical and NLP‐derived variables. Model discrimination and calibration were assessed, and receiver operating characteristic comparison analyses were performed. The 30‐day rehospitalization rates among the derivation (n=6165) and validation (n=4024) cohorts were 15.1% (n=934) and 10.2% (n=412), respectively. The derivation models demonstrated no statistical improvement in model performance with the addition of the selected NLP‐derived social risk factors. Conclusions Social risk factors extracted using NLP did not significantly improve 30‐day readmission prediction among hospitalized patients with acute myocardial infarction. Alternative methods are needed to capture social risk factors.",Journal of the American Heart Association,2022,10.1161/JAHA.121.024198,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b2fd99c0e8052e0b389fce6c4e15690b75016af2,https://www.semanticscholar.org/paper/b2fd99c0e8052e0b389fce6c4e15690b75016af2,Applications of artificial neural networks in health care organizational decision-making: A scoping review,"Health care organizations are leveraging machine-learning techniques, such as artificial neural networks (ANN), to improve delivery of care at a reduced cost. Applications of ANN to diagnosis are well-known; however, ANN are increasingly used to inform health care management decisions. We provide a seminal review of the applications of ANN to health care organizational decision-making. We screened 3,397 articles from six databases with coverage of Health Administration, Computer Science and Business Administration. We extracted study characteristics, aim, methodology and context (including level of analysis) from 80 articles meeting inclusion criteria. Articles were published from 1997–2018 and originated from 24 countries, with a plurality of papers (26 articles) published by authors from the United States. Types of ANN used included ANN (36 articles), feed-forward networks (25 articles), or hybrid models (23 articles); reported accuracy varied from 50% to 100%. The majority of ANN informed decision-making at the micro level (61 articles), between patients and health care providers. Fewer ANN were deployed for intra-organizational (meso- level, 29 articles) and system, policy or inter-organizational (macro- level, 10 articles) decision-making. Our review identifies key characteristics and drivers for market uptake of ANN for health care organizational decision-making to guide further adoption of this technique.",PloS one,2019,10.1371/journal.pone.0212356,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
239a116a9289f88a7e7b050e4c18f334b0f5cdea,https://www.semanticscholar.org/paper/239a116a9289f88a7e7b050e4c18f334b0f5cdea,SCOR: A secure international informatics infrastructure to investigate COVID-19,"Abstract Global pandemics call for large and diverse healthcare data to study various risk factors, treatment options, and disease progression patterns. Despite the enormous efforts of many large data consortium initiatives, scientific community still lacks a secure and privacy-preserving infrastructure to support auditable data sharing and facilitate automated and legally compliant federated analysis on an international scale. Existing health informatics systems do not incorporate the latest progress in modern security and federated machine learning algorithms, which are poised to offer solutions. An international group of passionate researchers came together with a joint mission to solve the problem with our finest models and tools. The SCOR Consortium has developed a ready-to-deploy secure infrastructure using world-class privacy and security technologies to reconcile the privacy/utility conflicts. We hope our effort will make a change and accelerate research in future pandemics with broad and diverse samples on an international scale.",J. Am. Medical Informatics Assoc.,2020,10.1093/jamia/ocaa172,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b59392e8af63f265ddf6d8dcb8a5bf738251950b,https://www.semanticscholar.org/paper/b59392e8af63f265ddf6d8dcb8a5bf738251950b,Deep Learning Methods and Their Application to Nursing Workflows: Technology and Perspectives.,"KEY POINTS Deep learning is a paradigm of statistical inference that offers the potential for successful application to clinical care, as it extracts nonobvious insights from health data to drive best-in-class predictive power. Recent studies across various types of deep learning models have confirmed that the application of deep learning methods to predictive problems can offer more prescriptive care, improved cost efficiency, and advanced screening. The nursing workforce is well suited to manage the validation and rollout of deep learning methods due to expertise in care operations. Care providers and technologists must partner closely to ensure that statistical models are easily usable and understandable by frontline clinicians. A veritable explosion of data has confronted health system participants as healthcare has digitized in the past decade. In this process, health data have dispersed among numerous knowledge bases: electronic health records (EHRs), images, notes, unstructured text, sensors, equipment, and mobile data. While these data have come to play many roles for patients, providers, and payers, systems that produce forward-looking inference from existing data have remained limited, particularly in real-time, clinical workflows. Indeed, systematic reviews and trials of such tools have shown that fully deployed clinical guidance systems based on statistical methods are not yet widely adopted or trusted in healthcare. Historical precedent notwithstanding, various teams are investigating potential health and efficiency gains driven by bringing predictive modeling to healthcare. Many health researchers and clinicians have been introduced to some predictive machine learning (ML) methods, particularly linear regression and clustering algorithms such as nearestneighbors. However, a complementary paradigm known as deep learning (DL) is far less widely understood or appreciated, even though it offers the possibility for rapid advances in care delivery and clinical practice. In particular, DL methods have dramatically outperformed many traditional ML approaches in settings both old and new. As a result, it shows potential to enable more effective and cost-efficient diagnostics, provide rapid care to patients most in need, improve personalization of care, and ease provider fatigue. It is therefore paramount that all stakeholders—from patient to provider—are informed about the DL paradigm and its relevance to healthcare. In practice, nurses frequently possess a contextual awareness of patient-specific needs and wellness goals, though these","Computers, informatics, nursing : CIN",2021,10.1097/CIN.0000000000000702,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
114aa720872462b0ca1b97bfdec0ebd56c36fd0a,https://www.semanticscholar.org/paper/114aa720872462b0ca1b97bfdec0ebd56c36fd0a,Towards Understanding and Mitigating Social Biases in Language Models,"Warning: this paper contains model outputs that may be offensive or upsetting. As machine learning methods are deployed in realworld settings such as healthcare, legal systems, and social science, it is crucial to recognize how they shape social biases and stereotypes in these sensitive decision-making processes. Among such real-world deployments are large-scale pretrained language models (LMs) that can be potentially dangerous in manifesting undesirable representational biases harmful biases resulting from stereotyping that propagate negative generalizations involving gender, race, religion, and other social constructs. As a step towards improving the fairness of LMs, we carefully define several sources of representational biases before proposing new benchmarks and metrics to measure them. With these tools, we propose steps towards mitigating social biases during text generation. Our empirical results and human evaluation demonstrate effectiveness in mitigating bias while retaining crucial contextual information for highfidelity text generation, thereby pushing forward the performance-fairness Pareto frontier.",ICML,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8c1756401943497c928d348ede0a1b905aac752,https://www.semanticscholar.org/paper/c8c1756401943497c928d348ede0a1b905aac752,Real-time data from mobile platforms to evaluate sustainable transportation infrastructure,,Nature Sustainability,2020,10.1038/s41893-020-0533-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b0361fb4f79f7100140dd70cd127432ea1c6088f,https://www.semanticscholar.org/paper/b0361fb4f79f7100140dd70cd127432ea1c6088f,Performance Evaluation of Deep Learning Algorithms in Biomedical Document Classification,"Document classification is a prevalent task in Natural Language Processing (NLP), which has an extensive range of applications in the biomedical domains such as biomedical literature indexing, automatic diagnosis codes assignment, tweets classification for public health topics, and patient safety reports classification. Nevertheless, manual classification of biomedical articles published every year into specific predefined categories becomes a cumbersome task. Hence, building an automatic document classification for biomedical databases emerges as a significant task among the scientific community. In recent years, Deep Learning (DL) models like Deep Neural Networks (DNN), Convolution Neural Networks (CNN), Recurrent Neural Networks (RNN), and Ensemble Deep Learning models are widely used in the area of text document classification for better classification performance compared to Machine Learning (ML) algorithms. The major advantage of using DL models in document classification is that it provides rich semantic and grammatical information for document representation through pre-trained word embedding. Hence, this paper investigates the deployment of the various state-of-the-art DL based classification models in automatic classification of benchmark biomedical datasets. Finally, the performance of all the aforementioned constitutional classifiers is compared and evaluated through the well-defined performance evaluation metrics such as accuracy, precision, recall, and f1measure.",2019 11th International Conference on Advanced Computing (ICoAC),2019,10.1109/ICoAC48765.2019.246843,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
282926b30a9d4b6741c350e0fe825c9ce12700a5,https://www.semanticscholar.org/paper/282926b30a9d4b6741c350e0fe825c9ce12700a5,HOLMeS: eHealth in the Big Data and Deep Learning Era,"Now, data collection and analysis are becoming more and more important in a variety of application domains, as long as novel technologies advance. At the same time, we are experiencing a growing need for human–machine interaction with expert systems, pushing research toward new knowledge representation models and interaction paradigms. In particular, in the last few years, eHealth—which usually indicates all the healthcare practices supported by electronic elaboration and remote communications—calls for the availability of a smart environment and big computational resources able to offer more and more advanced analytics and new human–computer interaction paradigms. The aim of this paper is to introduce the HOLMeS (health online medical suggestions) system: A particular big data platform aiming at supporting several eHealth applications. As its main novelty/functionality, HOLMeS exploits a machine learning algorithm, deployed on a cluster-computing environment, in order to provide medical suggestions via both chat-bot and web-app modules, especially for prevention aims. The chat-bot, opportunely trained by leveraging a deep learning approach, helps to overcome the limitations of a cold interaction between users and software, exhibiting a more human-like behavior. The obtained results demonstrate the effectiveness of the machine learning algorithms, showing an area under ROC (receiver operating characteristic) curve (AUC) of 74.65% when some first-level features are used to assess the occurrence of different chronic diseases within specific prevention pathways. When disease-specific features are added, HOLMeS shows an AUC of 86.78%, achieving a greater effectiveness in supporting clinical decisions.",Inf.,2018,10.3390/INFO10020034,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ecfeaa64a51777291f22f1a115119ff2c04a5348,https://www.semanticscholar.org/paper/ecfeaa64a51777291f22f1a115119ff2c04a5348,"Deep Learning in mHealth for Cardiovascular Disease, Diabetes, and Cancer: Systematic Review","Background Major chronic diseases such as cardiovascular disease (CVD), diabetes, and cancer impose a significant burden on people and health care systems around the globe. Recently, deep learning (DL) has shown great potential for the development of intelligent mobile health (mHealth) interventions for chronic diseases that could revolutionize the delivery of health care anytime, anywhere. Objective The aim of this study is to present a systematic review of studies that have used DL based on mHealth data for the diagnosis, prognosis, management, and treatment of major chronic diseases and advance our understanding of the progress made in this rapidly developing field. Methods A search was conducted on the bibliographic databases Scopus and PubMed to identify papers with a focus on the deployment of DL algorithms that used data captured from mobile devices (eg, smartphones, smartwatches, and other wearable devices) targeting CVD, diabetes, or cancer. The identified studies were synthesized according to the target disease, the number of enrolled participants and their age, and the study period as well as the DL algorithm used, the main DL outcome, the data set used, the features selected, and the achieved performance. Results In total, 20 studies were included in the review. A total of 35% (7/20) of DL studies targeted CVD, 45% (9/20) of studies targeted diabetes, and 20% (4/20) of studies targeted cancer. The most common DL outcome was the diagnosis of the patient’s condition for the CVD studies, prediction of blood glucose levels for the studies in diabetes, and early detection of cancer. Most of the DL algorithms used were convolutional neural networks in studies on CVD and cancer and recurrent neural networks in studies on diabetes. The performance of DL was found overall to be satisfactory, reaching >84% accuracy in most studies. In comparison with classic machine learning approaches, DL was found to achieve better performance in almost all studies that reported such comparison outcomes. Most of the studies did not provide details on the explainability of DL outcomes. Conclusions The use of DL can facilitate the diagnosis, management, and treatment of major chronic diseases by harnessing mHealth data. Prospective studies are now required to demonstrate the value of applied DL in real-life mHealth tools and interventions.",JMIR mHealth and uHealth,2021,10.2196/32344,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8e4e5d7369fa701bd9d852694c77d7ca9a31f1df,https://www.semanticscholar.org/paper/8e4e5d7369fa701bd9d852694c77d7ca9a31f1df,Intelligent Robot for Worker Safety Surveillance: Deep Learning Perception and Visual Navigation,"The fatal injury rate for the construction industry is higher than the average for all industries. Recently, researchers have shown an increased interest in occupational safety in the construction industry. However, all the current methods using conventional machine learning with stationary cameras suffer from some severe limitations, perceptual aliasing (e.g., different places/objects can appear identical), occlusion (e.g., place/object appearance changes between visits), seasonal / illumination changes, significant viewpoint changes, etc. This paper proposes a perception module using end-to-end deep-learning and visual SLAM (Simultaneous Localization and Mapping) for an effective and efficient object recognition and navigation using a differential-drive mobile robot. Various deep-learning frameworks and visual navigation strategies with evaluation metrics are implemented and validated for the selection of the best model. The deep-learning model's predictions are evaluated via the metrics (model speed, accuracy, complexity, precision, recall, P-R curve, F1 score). The YOLOv3 shows the best trade-off among all algorithms, 57.9% mean average precision (mAP), in real-world settings, and can process 45 frames per second (FPS) on NVIDIA Jetson TX2 which makes it suitable for real-time detection, as well as a right candidate for deploying the neural network on a mobile robot. The evaluation metrics used for the comparison of laser SLAM are Root Mean Square Error (RMSE). The Google Cartographer SLAM shows the lowest RMSE and acceptable processing time. The experimental results demonstrate that the perception module can meet the requirements of head protection criteria in Occupational Safety and Health Administration (OSHA) standards for construction. To be more precise, this module can effectively detect construction worker's non-hardhat-use in different construction site conditions and can facilitate improved safety inspection and supervision.",2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS),2020,10.1109/ARIS50834.2020.9205772,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ec78d1a6867486f972498ed409a7c9285dcb998e,https://www.semanticscholar.org/paper/ec78d1a6867486f972498ed409a7c9285dcb998e,Boosting Transfer Learning with Survival Data from Heterogeneous Domains,"Survival models derived from health care data are an important support to inform critical screening and therapeutic decisions. Most models however, do not generalize to populations outside the marginal and conditional distribution assumptions for which they were derived. This presents a significant barrier to the deployment of machine learning techniques into wider clinical practice as most medical studies are data scarce, especially for the analysis of time-to-event outcomes. In this work we propose a survival prediction model that is able to improve predictions on a small data domain of interest - such as a local hospital - by leveraging related data from other domains - such as data from other hospitals. We construct an ensemble of weak survival predictors which iteratively adapt the marginal distributions of the source and target data such that similar source patients contribute to the fit and ultimately improve predictions on target patients of interest. This represents the first boosting-based transfer learning algorithm in the survival analysis literature. We demonstrate the performance and utility of our algorithm on synthetic and real healthcare data collected at various locations.",AISTATS,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
61dc815705fc83db74d874c7ad7f1d8e7b414162,https://www.semanticscholar.org/paper/61dc815705fc83db74d874c7ad7f1d8e7b414162,Real-Time Mosquito Species Identification using Deep Learning Techniques,"According to the World Health Organization, diseases such as malaria and dengue account for almost one million deaths every year. Carrier mosquitoes for a particular disease remain exclusive to it. A majority of carrier mosquitoes spread the disease throughout a region by reproducing in it. With advancements in Machine Learning and Computer Vision technologies, the species of mosquitoes in a particular region can be easily and swiftly detected using recordings of their wing movements. The wingbeats of a particular mosquito species are unique, making this a reliable method to identify them. Once these solutions are deployed on mosquito traps, a particular region can be alerted if, for example, an Aedes Aegypti mosquito is found. This mosquito species is widely known to carry the Zika virus. The identification of such carrier species can also help in detecting the spread of mosquito-borne diseases in the surveyed region. In this paper, we go through various techniques that show promising results in the identification of mosquito species. The trained models can be deployed on constrained devices to make a cost-effective and efficient mosquito species identification system.",,2019,10.35940/ijeat.b2929.129219,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
60d55b39978be7176826b9a4d2bf3a70d6f891e8,https://www.semanticscholar.org/paper/60d55b39978be7176826b9a4d2bf3a70d6f891e8,Distilled Deep Learning based Classification of Abnormal Heartbeat Using ECG Data through a Low Cost Edge Device,"To meet the accuracy, latency and energy efficiency requirements of modern healthcare systems during real-time collection and analysis of health data, a distributed edge computing environment is the answer, combined with 5G speeds and modern AI techniques. Using the state-of-the-art machine learning based classification techniques plays a crucial role in creating the optimal healthcare system on the edge. This work first provides a background on the current and emerging edge computing classification techniques for healthcare applications, specifically for electrocardiogram (ECG) beat classification. After implementing these classification techniques on a Raspberry Pi- based platform we perform a comparison of the performance of these classification techniques with respect to three key performance indicators (KPI) of interest for health care applications namely accuracy, energy efficiency, and latency. Benefiting from the results of the comparative analysis presented in this work, a distilled neural network algorithm can be selected for optimal deployment and over 90% accuracy in given scenario in healthcare system depending on the specific requirements of the given scenario.",2019 IEEE Symposium on Computers and Communications (ISCC),2019,10.1109/ISCC47284.2019.8969657,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6282a483f90725885f5d6ca1333a767f60173491,https://www.semanticscholar.org/paper/6282a483f90725885f5d6ca1333a767f60173491,Network Intrusion Detection using Deep Learning,,SpringerBriefs on Cyber Security Systems and Networks,2018,10.1007/978-981-13-1444-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9fb10e0ee0e200d4298f3a146f81c12dce441179,https://www.semanticscholar.org/paper/9fb10e0ee0e200d4298f3a146f81c12dce441179,"From development to deployment: dataset shift, causality, and shift-stable models in health AI.","The deployment of machine learning (ML) and statistical models is beginning to transform the practice of healthcare, with models now able to help clinicians diagnose conditions like pneumonia and skin cancer, and to predict which hospital patients are at risk of adverse events such as septic shock. A major concern, however, is that model performance is heavily tied to details particular to the dataset the model was developed on—even slight deviations from the training conditions can result in wildly different performance. For example, when researchers trained a model to diagnose pneumonia from chest X-rays using data from one health system, but evaluated on data from an external health system, they found the model performed significantly worse than it did internally (Zech and others, 2018). The model failed to generalize (i.e., predict accurately) due to the shifts between the training conditions (health system one) and the deployment/testing conditions (health system two). These shifts are very common when moving a model from the training phase to deployment and can take a variety of forms, including changes in patient demographics, disease prevalence, measurement timing, equipment, treatment patterns, and more. Beyond contributing to poor performance, failing to account for shifts can also lead to dangerous decisions in practice: the system can fail to diagnose severely ill patients or recommend harmful treatments. This problem of shifting conditions which prevent generalization is referred to as dataset shift (QuiñoneroCandela and others, 2009), and in this article, we explain what it is, why it occurs, give an overview of the types of existing solutions, and discuss open challenges that remain. Generalization is crucial for successfully deploying models since we want model predictions to be accurate when applied to new situations that were not in the training dataset. In order to ensure that a",Biostatistics,2019,10.1093/biostatistics/kxz041,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ee9e36c0abe8fd1c48aa73d1f83bcbb22fe3670b,https://www.semanticscholar.org/paper/ee9e36c0abe8fd1c48aa73d1f83bcbb22fe3670b,Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale,"The ever-growing demand and complexity of machine learning are putting pressure on hyper-parameter tuning systems: while the evaluation cost of models continues to increase, the scalability of state-of-the-arts starts to become a crucial bottleneck. In this paper, inspired by our experience when deploying hyper-parameter tuning in a real-world application in production and the limitations of existing systems, we propose Hyper-Tune, an efficient and robust distributed hyper-parameter tuning framework. Compared with existing systems, Hyper-Tune highlights multiple system optimizations, including (1) automatic resource allocation, (2) asynchronous scheduling, and (3) multi-fidelity optimizer. We conduct extensive evaluations on benchmark datasets and a large-scale realworld dataset in production. Empirically, with the aid of these optimizations, Hyper-Tune outperforms competitive hyper-parameter tuning systems on a wide range of scenarios, including XGBoost, CNN, RNN, and some architectural hyper-parameters for neural networks. Compared with the state-of-the-art BOHB and A-BOHB, Hyper-Tune achieves up to 11.2× and 5.1× speedups, respectively. PVLDB Reference Format: Yang Li, Yu Shen, Huaijun Jiang, Wentao Zhang, Jixiang Li, Ji Liu, Ce Zhang, and Bin Cui. Hyper-Tune: Towards Efficient Hyper-parameter Tuning at Scale. PVLDB, 14(1): XXX-XXX, 2020. doi:XX.XX/XXX.XX PVLDB Availability Tag: The source code of this research paper has been made publicly available at https://github.com/PKU-DAIR/HyperTune.",Proc. VLDB Endow.,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b9f5fa18b79a263f894d18e8010194213ff210ce,https://www.semanticscholar.org/paper/b9f5fa18b79a263f894d18e8010194213ff210ce,Usable Security for ML Systems in Mental Health: A Framework,"While the applications and demands of Machine learning (ML) systems in mental health are growing, there is little discussion nor consensus regarding a uniquely challenging aspect: building security methods and requirements into these ML systems, and keep the ML system usable for end-users. This question of usable security is very important, because the lack of consideration in either security or usability would hinder large-scale user adoption and active usage of ML systems in mental health applications. 
In this short paper, we introduce a framework of four pillars, and a set of desired properties which can be used to systematically guide and evaluate security-related designs, implementations, and deployments of ML systems for mental health. We aim to weave together threads from different domains, incorporate existing views, and propose new principles and requirements, in an effort to lay out a clear framework where criteria and expectations are established, and are used to make security mechanisms usable for end-users of those ML systems in mental health. Together with this framework, we present several concrete scenarios where different usable security cases and profiles in ML-systems in mental health applications are examined and evaluated.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f02f6e666aef6b0675cc4a189f9962b716c17487,https://www.semanticscholar.org/paper/f02f6e666aef6b0675cc4a189f9962b716c17487,FARE: Enabling Fine-grained Attack Categorization under Low-quality Labeled Data,"Supervised machine learning classifiers have been widely used for attack detection, but their training requires abundant high-quality labels. Unfortunately, high-quality labels are difficult to obtain in practice due to the high cost of data labeling and the constant evolution of attackers. Without such labels, it is challenging to train and deploy targeted countermeasures. In this paper, we propose FARE, a clustering method to enable fine-grained attack categorization under low-quality labels. We focus on two common issues in data labels: 1) missing labels for certain attack classes or families; and 2) only having coarsegrained labels available for different attack types. The core idea of FARE is to take full advantage of the limited labels while using the underlying data distribution to consolidate the lowquality labels. We design an ensemble model to fuse the results of multiple unsupervised learning algorithms with the given labels to mitigate the negative impact of missing classes and coarsegrained labels. We then train an input transformation network to map the input data into a low-dimensional latent space for fine-grained clustering. Using two security datasets (Android malware and network intrusion traces), we show that FARE significantly outperforms the state-of-the-art (semi-)supervised learning methods in clustering quality/correctness. Further, we perform an initial deployment of FARE by working with a large e-commerce service to detect fraudulent accounts. With realworld A/B tests and manual investigation, we demonstrate the effectiveness of FARE to catch previously-unseen frauds.",NDSS,2021,10.14722/NDSS.2021.24403,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a713a3d4395290f073e1a296b82f9eea6acffdde,https://www.semanticscholar.org/paper/a713a3d4395290f073e1a296b82f9eea6acffdde,Governance of artificial intelligence and personal health information,"
Purpose
This paper aims to assess the increasing challenges to governing the personal health information (PHI) essential for advancing artificial intelligence (AI) machine learning innovations in health care. Risks to privacy and justice/equity are discussed, along with potential solutions.


Design/methodology/approach
This conceptual paper highlights the scale and scope of PHI data consumed by deep learning algorithms and their opacity as novel challenges to health data governance.


Findings
This paper argues that these characteristics of machine learning will overwhelm existing data governance approaches such as privacy regulation and informed consent. Enhanced governance techniques and tools will be required to help preserve the autonomy and rights of individuals to control their PHI. Debate among all stakeholders and informed critique of how, and for whom, PHI-fueled health AI are developed and deployed are needed to channel these innovations in societally beneficial directions.


Social implications
Health data may be used to address pressing societal concerns, such as operational and system-level improvement, and innovations such as personalized medicine. This paper informs work seeking to harness these resources for societal good amidst many competing value claims and substantial risks for privacy and security.


Originality/value
This is the first paper focusing on health data governance in relation to AI/machine learning.
","Digital Policy, Regulation and Governance",2019,10.1108/DPRG-08-2018-0048,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dba3478cb46874a97e301deb0f20f7692c1f1ae9,https://www.semanticscholar.org/paper/dba3478cb46874a97e301deb0f20f7692c1f1ae9,PenDer: Incorporating Shape Constraints via Penalized Derivatives,"When deploying machine learning models in the real-world, system designers may wish that models exhibit certain shape behavior, i.e., model outputs follow a particular shape with respect to input features. Trends such as monotonicity, convexity, diminishing or accelerating returns are some of the desired shapes. Presence of these shapes makes the model more interpretable for the system designers, and adequately fair for the customers. We notice that many such common shapes are related to derivatives, and propose a new approach, PenDer (Penalizing Derivatives), which incorporates these shape constraints by penalizing the derivatives. We further present an Augmented Lagrangian Method (ALM) to learn the joint unconstrained objective function. Experiments on three realworld datasets illustrate that even though both PenDer and state-of-the-art Lattice models achieve similar conformance to shape, PenDer captures better sensitivity of prediction with respect to intended features. We also demonstrate that PenDer achieves better test performance than Lattice while enforcing more desirable shape behavior.",AAAI,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8dd22688d83dabf483c9a57d111805163e1a0e1,https://www.semanticscholar.org/paper/c8dd22688d83dabf483c9a57d111805163e1a0e1,From One-hot Encoding to Privacy-preserving Synthetic Electronic Health Records Embedding,"Categorical Encoding, typically one-hot encoding, plays a central role when we learn Machine Learning models. This classic approach is the most prevalent strategy due to its simplicity. However, as the number of categories grows large and sparse, it becomes infeasible to train since it creates high-dimensional vectors, which is also at the risk of revealing private information and breaking its underlying structure. We here propose to utilize data intermediate representation learning (embedding) to overcome such limitations. Instead of representing data with a one-hot vector of many cardinalities, an embedding serves as a lower-dimensional dense vector in which each cell can contain any number, capturing the latent hierarchical structures of the features in the meantime. It can also be assumed that sharing embedding is safer than releasing raw one-hot encoded data, as the presence of a particular feature is represented by the value of 1, otherwise 0. With the assist of Generative Adversarial Network further alleviates sensitive information leakage issue by creating synthetic data for modeling. Our result suggests that even embedded features may more or less pose privacy flaws, deploying GAN will make a wider variety of medical datasets available by retaining its relative utility while preserving data privacy, which has been identified as a promising method for medical machine learning and prediction.",CIAT,2020,10.1145/3444370.3444605,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fa1387e89d40c6b68969fa26315da581db6aeb23,https://www.semanticscholar.org/paper/fa1387e89d40c6b68969fa26315da581db6aeb23,Agile Requirements Engineering and Software Planning for a Digital Health Platform to Engage the Effects of Isolation Caused by Social Distancing: Case Study (Preprint),"
 BACKGROUND
 Social distancing and shielding measures have been put in place to reduce social interaction and slow the transmission of the coronavirus disease (COVID-19). For older people, self-isolation presents particular challenges for mental health and social relationships. As time progresses, continued social distancing could have a compounding impact on these concerns.
 
 
 OBJECTIVE
 This project aims to provide a tool for older people and their families and peers to improve their well-being and health during and after regulated social distancing. First, we will evaluate the tool’s feasibility, acceptability, and usability to encourage positive nutrition, enhance physical activity, and enable virtual interaction while social distancing. Second, we will be implementing the app to provide an online community to assist families and peer groups in maintaining contact with older people using goal setting. Anonymized data from the app will be aggregated with other real-world data sources to develop a machine learning algorithm to improve the identification of patients with COVID-19 and track for real time use by health systems.
 
 
 METHODS
 Development of this project is occurring at the time of publication, and therefore, a case study design was selected to provide a systematic means of capturing software engineering in progress. The app development framework for software design was based on agile methods. The evaluation of the app’s feasibility, acceptability and usability shall be conducted using Public Health England's guidance on evaluating digital health products, Bandura’s model of health promotion, the Reach Effectiveness Adoption Implementation Maintenance (RE-AIM) framework and the Nonadoption, Abandonment and Challenges to the Scale-up, Spread and Suitability (NASSS) framework.
 
 
 RESULTS
 Making use of a pre-existing software framework for health behavior change, a proof of concept was developed, and a multistage app development and deployment for the solution was created. Grant submissions to fund the project and study execution have been sought at the time of publication, and prediscovery iteration of the solution has begun. Ethical approval for a feasibility study design is being sought.
 
 
 CONCLUSIONS
 This case study lays the foundations for future app development to combat mental and societal issues arising from social distancing measures. The app will be tested and evaluated in future studies to allow continuous improvement of the app. This novel contribution will provide an evidence-based exemplar for future app development in the space of social isolation and loneliness.
",,2020,10.2196/preprints.19297,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
da9d45c29c925f3234e5622b12e8372b71053184,https://www.semanticscholar.org/paper/da9d45c29c925f3234e5622b12e8372b71053184,Developing an automatic pipeline for analyzing chatter about health services from social media: A case study for Medicaid,"Objective Social media can be an effective but challenging resource for conducting close-to-real-time assessments of consumers' perceptions about health services. Our objective was to develop and evaluate an automatic pipeline, involving natural language processing and machine learning, for automatically characterizing user-posted Twitter data about Medicaid. Material and Methods We collected Twitter data via the public API using Medicaid-related keywords (Corpus-1), and the website's search option using agency-specific handles (Corpus-2). We manually labeled a sample of tweets into five pre-determined categories or other, and artificially increased the number of training posts from specific low-frequency categories. We trained and evaluated several supervised learning algorithms using manually-labeled data, and applied the best-performing classifier to collected tweets for post-classification analyses assessing the utility of our methods. Results We collected 628,411 and 27,377 tweets for Corpus-1 and -2, respectively. We manually annotated 9,571 (Corpus-1: 8,180; Corpus-2: 1,391) tweets, using 7,923 (82.8%) for training and 1,648 (17.2%) for evaluation. A BERT-based (bidirectional encoder representations from transformers) classifier obtained the highest accuracies (83.9%, Corpus-1; 86.4%, Corpus-2), outperforming the second-best classifier (SVMs: 79.6%; 76.4%). Post-classification analyses revealed differing inter-corpora distributions of tweet categories, with political (63%) and consumer-feedback (43%) tweets being most frequent for Corpus-1 and -2, respectively. Discussion and Conclusion The broad and variable content of Medicaid-related tweets necessitates automatic categorization to identify topic-relevant posts. Our proposed pipeline presents a feasible solution for automatic categorization, and can be deployed/generalized for health service programs other than Medicaid. Annotated data and methods are available for future studies (LINK_TO_BE_AVAILABLE).",medRxiv,2020,10.1101/2020.06.12.20129593,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
307d11558ae76bf15d74af8e0d54dd71086cc8f4,https://www.semanticscholar.org/paper/307d11558ae76bf15d74af8e0d54dd71086cc8f4,Automatic Learning for Improvement in Joint Mobility in the Elderly,,Gerontechnology,2018,10.1007/978-3-030-16028-9_12,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
46a7147d42ef83e02c5f6be383794160529ade87,https://www.semanticscholar.org/paper/46a7147d42ef83e02c5f6be383794160529ade87,DeTrAs: deep learning-based healthcare framework for IoT-based assistance of Alzheimer patients,,Neural Computing and Applications,2020,10.1007/S00521-020-05327-2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c88a2cf881f68dab0344ff17dee4457106ca2040,https://www.semanticscholar.org/paper/c88a2cf881f68dab0344ff17dee4457106ca2040,A Data-Driven Approach With Uncertainty Quantification for Predicting Future Capacities and Remaining Useful Life of Lithium-ion Battery,"Predicting future capacities and remaining useful life (RUL) with uncertainty quantification is a key but challenging issue in the applications of battery health diagnosis and management. This article applies advanced machine-learning techniques to achieve effective future capacities and RUL prediction for lithium-ion (Li-ion) batteries with reliable uncertainty management. To be specific, after using the empirical mode decomposition (EMD) method, the original battery capacity data is decomposed into some intrinsic mode functions (IMFs) and a residual. Then, the long short-term memory (LSTM) submodel is applied to estimate the residual while the Gaussian process regression (GPR) submodel is utilized to fit the IMFs with the uncertainty level. Consequently, both the long-term dependence of capacity and uncertainty quantification caused by the capacity regenerations can be captured directly and simultaneously. Experimental aging data from different batteries are deployed to evaluate the performance of proposed LSTM+GPR model in comparison with the solo GPR, solo LSTM, GPR+EMD, and LSTM+EMD models. Illustrative results demonstrate the combined LSTM+GPR model outperforms other counterparts and is capable of achieving accurate results for both 1-step and multistep ahead capacity predictions. Even predicting the RUL at the early battery cycle stage, the proposed data-driven approach still presents good adaptability and reliable uncertainty quantification for battery health diagnosis.",IEEE Transactions on Industrial Electronics,2021,10.1109/TIE.2020.2973876,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8584d9ccddd6c2caaeaa8c76b0612d7e72bea07,https://www.semanticscholar.org/paper/c8584d9ccddd6c2caaeaa8c76b0612d7e72bea07,Foot-to-Ground Phases Detection: A Comparison of Data Representation Formatting Methods with Respect to Adaption of Deep Learning Architectures,"Identifying the foot stance and foot swing phases, also known as foot-to-ground (FTG) detection, is a branch of Human Activity Recognition (HAR). Our study aims to detect two main phases of the gait (i.e., foot-off and foot-contact) corresponding to the moments when each foot is in contact with the ground or not. This will allow the medical professionals to characterize and identify the different phases of the human gait and their respective patterns. This detection process is paramount for extracting gait features (e.g., step width, stride width, gait speed, cadence, etc.) used by medical experts to highlight gait anomalies, stance issues, or any other walking irregularities. It will be used to assist health practitioners with patient monitoring, in addition to developing a full pipeline for FTG detection that would help compute gait indicators. In this paper, a comparison of different training configurations, including model architectures, data formatting, and pre-processing, was conducted to select the parameters leading to the highest detection accuracy. This binary classification provides a label for each timestamp informing whether the foot is in contact with the ground or not. Models such as CNN, LSTM, and ConvLSTM were the best fits for this study. Yet, we did not exclude DNNs and Machine Learning models, such as Random Forest and XGBoost from our work in order to have a wide range of possible comparisons. As a result of our experiments, which included 27 senior participants who had a stroke in the past wearing IMU sensors on their ankles, the ConvLSTM model achieved a high accuracy of 97.01% for raw windowed data with a size of 3 frames per window, and each window was formatted to have two superimposed channels (accelerometer and gyroscope channels). The model was trained to have the best detection without any knowledge of the participants’ personal information including age, gender, health condition, the type of activity, or the used foot. In other words, the model’s input data only originated from IMU sensors. Overall, in terms of FTG detection, the combination of the ConvLSTM model and the data representation had an important impact in outperforming other start-of-the-art configurations; in addition, the compromise between the model’s complexity and its accuracy is a major asset for deploying this model and developing real-time solutions.",Comput.,2022,10.3390/computers11050058,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7e379d47e0fa74832380196cea3f1157c0ea7f51,https://www.semanticscholar.org/paper/7e379d47e0fa74832380196cea3f1157c0ea7f51,Learning to Prescribe Interventions for Tuberculosis Patients Using Digital Adherence Data,"Digital Adherence Technologies (DATs) are an increasingly popular method for verifying patient adherence to many medications. We analyze data from one city served by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB) treatment in India where nearly 3 million people are afflicted with the disease each year. The data contains nearly 17,000 patients and 2.1M dose records. We lay the groundwork for learning from this real-world data, including a method for avoiding the effects of unobserved interventions in training data used for machine learning. We then construct a deep learning model, demonstrate its interpretability, and show how it can be adapted and trained in three different clinical scenarios to better target and improve patient care. In the real-time risk prediction setting our model could be used to proactively intervene with 21% more patients and before 76% more missed doses than current heuristic baselines. For outcome prediction, our model performs 40% better than baseline methods, allowing cities to target more resources to clinics with a heavier burden of patients at risk of failure. Finally, we present a case study demonstrating how our model can be trained in an end-to-end decision focused learning setting to achieve 15% better solution quality in an example decision problem faced by health workers.",KDD,2019,10.1145/3292500.3330777,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ed326c13a9b0140ddc202bd3c3b809c4731a744,https://www.semanticscholar.org/paper/2ed326c13a9b0140ddc202bd3c3b809c4731a744,Machine Learning Toolbox and PCA Visualization for Data-Driven PHM,"Increased awareness of big data has led to active development of machine learning algorithms for big data analytics. The advent of rapidly emerging data analytics technologies has also brought about considerable changes to the diagnostics and prognostics for smart manufacturing industries. As the importance of managing massive factory data also has grown, many engineers are putting in efforts to implement machine learning algorithms for a PHM (Prognostics and Health Management) purpose in accordance with the type of machinery of interest. In this thesis, research on assisting the quick deployment of supervised and unsupervised learning classification algorithms with data visualization is conducted by building up the GUI software with an emphasis on PHM. It can plot raw data, select hand-crafted features based on an expert knowledge, followed by a dimension reduction step if necessary. The various machine learning algorithms will provide the classification decision boundaries to enable us to diagnose current machine health conditions. Therefore, it can suggest to engineers a guideline to determine suitable features and date-driven PHM algorithms. Principal Component Analysis (PCA) is a widely used dimension reduction algorithm without losing too much information for high-dimensional data analysis. It transforms the high-dimensional data into a meaningful representation of reduced dimensional data. In a machine health monitoring system, a result of dimension reduction via PCA is often utilized. Although eigenvectors and eigenvalues of PCA are important information, it is too difficult for users to interpret where the principal components are coming from. In order to assist the user in better understanding and interpreting PCA, data visualization can be used. We have developed a system that visualizes the eigenvectors and eigenvalues of PCA using JavaScript library, D3 and demonstrated that how the key information and insights of PCA results can be intuitively visualized.",,2008,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d3ac65b10af091759863b8e2c488036bf52a2ce6,https://www.semanticscholar.org/paper/d3ac65b10af091759863b8e2c488036bf52a2ce6,DAG Card is the new Model Card,"With the progressive commoditization of modeling capabilities, data-centric AI recognizes that what happens before and after training becomes crucial for realworld deployments. Following the intuition behind Model Cards, we propose DAG Cards as a form of documentation encompassing the tenets of a data-centric point of view. We argue that Machine Learning pipelines (rather than models) are the most appropriate level of documentation for many practical use cases, and we share with the community an open implementation to generate cards from code.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
14ee9bf682e4200b30dde734726fa9de027fcac3,https://www.semanticscholar.org/paper/14ee9bf682e4200b30dde734726fa9de027fcac3,Predicting Just in Time: Prognostic Health Management for Oilfield Equipment.,"
 Delays in the hydraulic fracturing stimulation process due to equipment issues may result in Non-Productive Time (NPT) and often associated with high costs. Both operators and service companies are interested in implementing a system to predict these events in advance so that they can proactively react and prevent failures before they occur. Our objective was to develop, implement, and demonstrate the capabilities of such a system.
 Based on historical data, we identified the most NPT-prone subcomponents of stimulation equipment. We combined failure reports and maintenance records with sensors data to train Machine Learning (ML) models. The final solution was deployed on the cloud to predict remaining useful time (RUL) in real-time and to start specific notifications sending whenever RUL dropped below the preset value.
 We analyzed 20,000+ failure records and identified the most NPT-prone equipment, subcomponents, failure modes, and root causes. We found out that root causes are very scattered. We evaluated the applicability of physics-based and data analytics approaches for Top-10 root causes by NPT duration and NPT count. When NPT count per root cause is low (<10), the trained ML models had insufficient accuracy. In this case, only subject matter experts and understanding of physics behind performance deterioration allowed us to boost data-driven models’ accuracy. We started with testing on historical data. Then we continued testing on real-time data without field intervention. This stage was required to check and to build trust in the predictive ability of the models. After initial testing, we eliminated some of the models and switched to monitoring with field interventions. For six months of operating, the model helped to decrease the NPT related to the selected subcomponent by 20 times.
 This work presents the process of enabling Intelligent Diagnostics for hydraulic fracturing equipment by implementing failure identification and prediction models. It combines both domain knowledge (failure modes of the equipment, sensors data) and recent advances in ML (time series analysis, data processing, and feature engineering). The developed system to be further extended to different equipment, as the workflow described in the present study is not specific to particular equipment.",,2020,10.2118/202957-ms,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f0611753adcb4ff75a037373f9b478b18d13b581,https://www.semanticscholar.org/paper/f0611753adcb4ff75a037373f9b478b18d13b581,Stable predictions for health related anticausal prediction tasks affected by selection biases: the need to deconfound the test set features,"In health related machine learning applications, the training data often corresponds to a non-representative sample from the target populations where the learners will be deployed. In anticausal prediction tasks, selection biases often make the associations between confounders and the outcome variable unstable across different target environments. As a consequence, the predictions from confounded learners are often unstable, and might fail to generalize in shifted test environments. Stable prediction approaches aim to solve this problem by producing predictions that are stable across unknown test environments. These approaches, however, are sometimes applied to the training data alone with the hope that training an unconfounded model will be enough to generate stable predictions in shifted test sets. Here, we show that this is insufficient, and that improved stability can be achieved by deconfounding the test set features as well. We illustrate these observations using both synthetic data and real world data from a mobile health study.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f67f5ed8ea3ffa80b383c1fce253b321d232e310,https://www.semanticscholar.org/paper/f67f5ed8ea3ffa80b383c1fce253b321d232e310,PE-HEALTH: Enabling Fully Encrypted CNN for Health Monitor with Optimized Communication,"Cloud-based Convolutional neural network (CNN) is a powerful tool for the healthcare center to provide health condition monitor service. Although the new service has future prospects in the medical, patient's privacy concerns arise because of the sensitivity of medical data. Prior works to address the concern have the following unresolved problems: 1) focus on data privacy but neglect to protect the privacy of the machine learning model itself; 2) introduce considerable communication costs for the CNN inference, which lowers the service quality of the cloud server. To push forward this area, we propose PE-HEALTH, a privacy-preserving health monitor framework that supports fully-encrypted CNN (both input data and model). In PE-HEALTH, the medical Internet of Things (IoT) sensor serves as the health condition data collector. For protecting patient privacy, the IoT sensor additively shares the collected data and uploads the shared data to the cloud server, which is efficient and suited to the energy-limited IoT sensor. To keep model privacy, PE-HEALTH allows the healthcare center to previously deploy, and then, use an encrypted CNN on the cloud server. During the CNN inference process, PE-HEALTH does not need the cloud servers to exchange any extra messages for operating the convolutional operation, which can greatly reduce the communication cost.",2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS),2020,10.1109/IWQoS49365.2020.9212822,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5f3b8493804ed87e9d0992248985fcf2e399018a,https://www.semanticscholar.org/paper/5f3b8493804ed87e9d0992248985fcf2e399018a,Data Anomaly Detection for Structural Health Monitoring of Bridges using Shapelet Transform,"With the wider availability of sensor technology, a number of Structural Health Monitoring (SHM) systems are deployed to monitor civil infrastructure. The continuous monitoring provides valuable information about the structure that can help in providing a decision support system for retrofits and other structural modifications. However, when the sensors are exposed to harsh environmental conditions, the data measured by the SHM systems tend to be affected by multiple anomalies caused by faulty or broken sensors. Given a deluge of high-dimensional data collected continuously over time, research into using machine learning methods to detect anomalies are a topic of great interest to the SHM community. This paper contributes to this effort by proposing the use of a relatively new time series representation named Shapelet Transform in combination with a Random Forest classifier to autonomously identify anomalies in SHM data. The shapelet transform is a unique time series representation that is solely based on the shape of the time series data. In consideration of the individual characteristics unique to every anomaly, the application of this transform yields a new shape-based feature representation that can be combined with any standard machine learning algorithm to detect anomalous data with no manual intervention. For the present study, the anomaly detection framework consists of three steps: identifying unique shapes from anomalous data, using these shapes to transform the SHM data into a local-shape space and training machine learning algorithm on this transformed data to identify anomalies. The efficacy of this method is demonstrated by the identification of anomalies in acceleration data from a SHM system installed on a long-span bridge in China. The results show that multiple data anomalies in SHM data can be automatically detected with high accuracy using the proposed method.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
30635d85ebdd9abf11ae2930fc5112de3ad01501,https://www.semanticscholar.org/paper/30635d85ebdd9abf11ae2930fc5112de3ad01501,Developing an Automatic System for Classifying Chatter About Health Services on Twitter: Case Study for Medicaid (Preprint),"
 BACKGROUND
 The wide adoption of social media in daily life renders it a rich and effective resource for conducting near real-time assessments of consumers’ perceptions of health services. However, its use in these assessments can be challenging because of the vast amount of data and the diversity of content in social media chatter.
 
 
 OBJECTIVE
 This study aims to develop and evaluate an automatic system involving natural language processing and machine learning to automatically characterize user-posted Twitter data about health services using Medicaid, the single largest source of health coverage in the United States, as an example.
 
 
 METHODS
 We collected data from Twitter in two ways: via the public streaming application programming interface using Medicaid-related keywords (Corpus 1) and by using the website’s search option for tweets mentioning agency-specific handles (Corpus 2). We manually labeled a sample of tweets in 5 predetermined categories or other and artificially increased the number of training posts from specific low-frequency categories. Using the manually labeled data, we trained and evaluated several supervised learning algorithms, including support vector machine, random forest (RF), naïve Bayes, shallow neural network (NN), k-nearest neighbor, bidirectional long short-term memory, and bidirectional encoder representations from transformers (BERT). We then applied the best-performing classifier to the collected tweets for postclassification analyses to assess the utility of our methods.
 
 
 RESULTS
 We manually annotated 11,379 tweets (Corpus 1: 9179; Corpus 2: 2200) and used 7930 (69.7%) for training, 1449 (12.7%) for validation, and 2000 (17.6%) for testing. A classifier based on BERT obtained the highest accuracies (81.7%, Corpus 1; 80.7%, Corpus 2) and F1 scores on consumer feedback (0.58, Corpus 1; 0.90, Corpus 2), outperforming the second best classifiers in terms of accuracy (74.6%, RF on Corpus 1; 69.4%, RF on Corpus 2) and F1 score on consumer feedback (0.44, NN on Corpus 1; 0.82, RF on Corpus 2). Postclassification analyses revealed differing intercorpora distributions of tweet categories, with political (400778/628411, 63.78%) and consumer feedback (15073/27337, 55.14%) tweets being the most frequent for Corpus 1 and Corpus 2, respectively.
 
 
 CONCLUSIONS
 The broad and variable content of Medicaid-related tweets necessitates automatic categorization to identify topic-relevant posts. Our proposed system presents a feasible solution for automatic categorization and can be deployed and generalized for health service programs other than Medicaid. Annotated data and methods are available for future studies.
 
 
 CLINICALTRIAL
 
",,2020,10.2196/preprints.26616,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e5cdd718482b0511def04ef2557bf03549821471,https://www.semanticscholar.org/paper/e5cdd718482b0511def04ef2557bf03549821471,Using AI for Mental Health Analysis and Prediction in School Surveys,"
 
 
 Childhood and adolescence are critical stages of life for mental health and well-being. Schools are a key setting for mental health promotion and illness prevention. One in five children and adolescents have a mental disorder, about half of mental disorders beginning before the age of 14. Beneficial and explainable artificial intelligence can replace current paper-based and online approaches to school mental health surveys. This can enhance data acquisition, interoperability, data-driven analysis, trust and compliance. This paper presents a model for using chatbots for non-obtrusive data collection and supervised machine learning models for data analysis; and discusses ethical considerations pertaining to the use of these models.
 
 
 
 For data acquisition, the proposed model uses chatbots which interact with students. The conversation log acts as the source of raw data for the machine learning. Pre-processing of the data is automated by filtering for keywords and phrases. Existing survey results, obtained through current paper-based data collection methods, are evaluated by domain experts (health professionals). These can be used to create a test dataset to validate the machine learning models. Supervised learning can then be deployed to classify specific behaviour and mental health patterns.
 
 
 
 We present a model that can be used to improve upon current paper-based data collection and manual data analysis methods. An open-source GitHub repository contains necessary tools and components of this model. Privacy is respected through rigorous observance of confidentiality and data protection requirements. Critical reflection on these ethics and law aspects is included in the project.
 
 
 
 This model strengthens mental health surveillance in schools. The same tools and components could be applied to other public health data. Future extensions of this model could also incorporate unsupervised learning to find clusters and patterns of unknown effects.
 
 
 
 This model uses artificial intelligence to improve mental health surveillance and evaluation in school settings. Artificial intelligence can be applied more broadly in public health to harness the potential of predictive models.
",European Journal of Public Health,2020,10.1093/eurpub/ckaa165.336,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f233d60acc78c88538f284d8f8e74701feae3663,https://www.semanticscholar.org/paper/f233d60acc78c88538f284d8f8e74701feae3663,Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition,"In digital health applications, speech offers advantages over other physiological signals, in that it can be easily collected, transmitted, and stored using mobile and Internet of Things (IoT) technologies. However, to take full advantage of this positioning, speech-based machine learning models need to be deployed on devices that can have considerable memory and power constraints. These constraints are particularly apparent when attempting to deploy deep learning models, as they require substantial amounts of memory and data movement operations. Herein, we test the suitability of pruning and quantisation as two methods to compress the overall size of neural networks trained for a health-driven speech classification task. Key results presented on the Upper Respiratory Tract Infection Corpus indicate that pruning, then quantising a network can reduce the number of operational weights by almost 90 %. They also demonstrate the overall size of the network can be reduced by almost 95 %, as measured in MB, without affecting overall recognition performance.",INTERSPEECH,2020,10.21437/interspeech.2020-2531,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ade8711f912471978dabfd1c309481146d1ef3bd,https://www.semanticscholar.org/paper/ade8711f912471978dabfd1c309481146d1ef3bd,"AI Models and Their Worlds: Investigating Data-Driven, AI/ML Ecosystems Through a Work Practices Lens",,iConference,2020,10.1007/978-3-030-43687-2_55,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3352eb2b731571ca9ba85e671a214b2e2467d8d9,https://www.semanticscholar.org/paper/3352eb2b731571ca9ba85e671a214b2e2467d8d9,Online and Scalable Model Selection with Multi-Armed Bandits,"Many online applications running on live traffic are powered by machine learning models, for which training, validation, and hyperparameter tuning are conducted on historical data. However, it is common for models demonstrating strong performance in offline analysis to yield poorer performance when deployed online. This problem is a consequence of the difficulty of training on historical data in non-stationary environments. Moreover, the machine learning metrics used for model selection may not sufficiently correlate with real-world business metrics used to determine the success of the applications being tested. These problems are particularly prominent in the Real-Time Bidding (RTB) domain, in which ML models power bidding strategies, and a change in models will likely affect performance of the advertising campaigns. In this work, we present Automatic Model Selector (AMS), a system for scalable online selection of RTB bidding strategies based on realworld performance metrics. AMS employs Multi-Armed Bandits (MAB) to near-simultaneously run and evaluate multiple models against live traffic, allocating the most traffic to the bestperforming models while decreasing traffic to those with poorer online performance, thereby minimizing the impact of inferior models on overall campaign performance. The reliance on offline data is avoided, instead making model selections on a case-by-case basis according to actionable business goals. AMS allows new models to be safely introduced into live campaigns as soon as they are developed, minimizing the risk to overall performance. In livetraffic tests on multiple ad campaigns, the AMS system proved highly effective at improving ad campaign performance.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0f5dc98f4ad051b7e49aa31cfc8fae5c2b532a1e,https://www.semanticscholar.org/paper/0f5dc98f4ad051b7e49aa31cfc8fae5c2b532a1e,Using system context information to complement weakly labeled data,"Real-world datasets collected with sensor networks often contain incomplete and uncertain labels as well as artefacts arising from the system environment. Complete and reliable labeling is often infeasible for large-scale and long-term sensor network deployments due to the labor and time overhead, limited availability of experts and missing ground truth. In addition, if the machine learning method used for analysis is sensitive to certain features of a deployment, labeling and learning needs to be repeated for every new deployment. To address these challenges, we propose to make use of system context information formalized in an information graph and embed it in the learning process via contrastive learning. Based on realworld data we show that this approach leads to an increased accuracy in case of weakly labeled data and leads to an increased robustness and transferability of the classifier to new sensor locations.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
34c59ec266e2f1798918d765c2a2519a2b8d03d2,https://www.semanticscholar.org/paper/34c59ec266e2f1798918d765c2a2519a2b8d03d2,ReLink: Complete-Link Industrial Record Linkage Over Hybrid Feature Spaces,"Record Linkage (ReL) is the task of identifying records from a pair of databases referring to the same realworld entity. This has many applications in organisations of all sizes where related data often exist in silos leading to inefficiency in data engineering and analytics applications as well as ineffectiveness of business applications (e.g., unable to personalise marketing campaigns).State-of-the-art (SOTA) machine learning and deep learning based ReL techniques use adaptive similarity measures and learn their relative contributions based on labeled data. However, we report here that they do not work with similar efficacy on industrial data owing to its fundamental differences such as magnitude of schema heterogeneity, need for leveraging structure of the data, lack of training data etc. Through our proposed system ‘ReLink’, we carefully mitigate these challenges and demonstrate that it not only significantly outperforms SOTA baselines on industrial datasets but also on majority of research benchmarks. ReLink introduces the notion of complete-linkage over attributes as well as uses hybrid feature spaces on lexical and semantic similarity measures using pre-trained models such as BERT. Going beyond empirical demonstration, we provide insights and prescriptive guidance on choice of ReL techniques in industrial settings from our observations and lessons learnt from the experience of transferring and deploying for real use-cases in a large financial services organization.",2021 IEEE 37th International Conference on Data Engineering (ICDE),2021,10.1109/ICDE51399.2021.00293,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
69fb4c8b9bd2ea88c0ba24979c715e9bb580d363,https://www.semanticscholar.org/paper/69fb4c8b9bd2ea88c0ba24979c715e9bb580d363,Data-Driven Condition Monitoring of Mining Mobile Machinery in Non-Stationary Operations Using Wireless Accelerometer Sensor Modules,"This paper presents the development of an easy-to-deploy and smart monitoring IoT system that utilizes vibration measurement devices to assess real-time condition of bulldozers, power shovels and backhoes, in non-stationary operations in the mining industry. According to operating experience data and the type of mining machine, total loss failure rates per machine fleet can reach up to 30%. Vibration analysis techniques are commonly used for condition monitoring and early detection of unforeseen failures to generate predictive maintenance plans for heavy machinery. However, this maintenance strategy is intensively used only for stationary machines and/or mobile machinery in stationary operations. Today, there is a lack of proper solutions to detect and prevent critical failures for non-stationary machinery. This paper shows a cost-effective solution proposal for implementing a vibration sensor network with wireless communication and machine learning data-driven capabilities for condition monitoring of non-stationary heavy machinery in mining operations. During the machine operation, 3-axis accelerations were measured using two sensors deployed across the machine. The machine accelerations (amplitudes and frequencies) are measured in two different frequency spectrums to improve each sensing location’s time resolution. Multiple machine learning algorithms use this machine data to assess conditions according to manufacturer recommendations and operational benchmarks Proposed data-driven machine learning models classify the machine condition in states according to the ISO 2372 standards for vibration severity: Good, Acceptable, Unsatisfactory, or Unacceptable. After performing field tests with bulldozers and backhoes from different manufacturers, the machine learning algorithms are able to classify machine health status with an accuracy between 85% - 95%. Moreover, the system allows early detection of “Unacceptable” states between 120 to 170 hours prior to critical failure. These results demonstrate that the proposed system will collect relevant data to generate predictive maintenance plans and avoid unplanned downtimes.",IEEE Access,2021,10.1109/ACCESS.2021.3051583,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7d6e9e6e39c70b947296cb4c17aacf4452fc5b29,https://www.semanticscholar.org/paper/7d6e9e6e39c70b947296cb4c17aacf4452fc5b29,Exploring the Use of Synthetic Gradients for Distributed Deep Learning across Cloud and Edge Resources,"With the explosive growth of data, largely contributed by the rapidly and widely deployed smart devices on the edge, we need to rethink the training paradigm for learning on such realworld data. The conventional cloud-only approach can hardly keep up with the computational demand from these deep learning tasks; and the traditional back propagation based training method also makes it difficult to scale out the training. Fortunately, the continuous advancement in System on Chip (SoC) hardware is transforming edge devices into capable computing platforms, and can potentially be exploited to address these challenges. These observations have motivated this paper’s study on the use of synthetic gradients for distributed training cross cloud and edge devices. We employ synthetic gradients into various neural network models to comprehensively evaluate its feasibility in terms of accuracy and convergence speed. We distribute the training of the various layers of a model using synthetic gradients, and evaluate its effectiveness on the edge by using resource-limited containers to emulate edge devices. The evaluation result shows that the synthetic gradient approach can achieve comparable accuracy compared to the conventional back propagation, for an eight-layer model with both fully-connected and convolutional layers. For a more complex model (VGG16), the training suffers from some accuracy degradation (up to 15%). But it achieves 11% improvement in training speed when the layers of a model are decoupled and trained on separate resource-limited containers, compared to the training of the whole model using the conventional method on the physical machine.",HotEdge,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98d3997f31c121b593d7717c4ae45b19ce512ff0,https://www.semanticscholar.org/paper/98d3997f31c121b593d7717c4ae45b19ce512ff0,End-to-End Deep Multi-Modal Physiological Authentication With Smartbands,"The number of fitness tracker users increases every day. Most of the applications require authentication to protect privacy-preserving operations. Biometrics such as face images have been used widely as login tokens, but they have privacy issues. Moreover, occlusions like face masks used for COVID may reduce their effectiveness. Smartbands can track heart rate, movements, and electrodermal activities. They have been widely used for health-related applications. The use of smartbands for authentication is in the exploratory stage. Physiological signals gathered from smartbands may be used to create a multi-modal and multi-sensor authentication system. The popularity of smartbands enables us to deploy new applications without a need to buy additional hardware. In this study, we explore the multi-modal physiological biometrics with end-to-end deep learning and feature-based traditional systems. We collected multi-modal physiological data of 80 people for five days using modern smartbands. We applied a deep learning approach to the multi-modal physiological data and used feature-based traditional machine learning classifiers. The CNN-LSTM model achieved a 9.31% equal error rate and outperformed other models in terms of authentication performance.",IEEE Sensors Journal,2021,10.1109/JSEN.2021.3073888,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b3c0acf284175d9af38b114e633692cf6df3ddc6,https://www.semanticscholar.org/paper/b3c0acf284175d9af38b114e633692cf6df3ddc6,Battery Health Prognosis for Electric Vehicles Using Sample Entropy and Sparse Bayesian Predictive Modeling,"Battery health monitoring and management is of extreme importance for the performance and cost of electric vehicles. This paper is concerned with machine-learning-enabled battery state-of-health (SOH) indication and prognosis. The sample entropy of short voltage sequence is used as an effective signature of capacity loss. Advanced sparse Bayesian predictive modeling (SBPM) methodology is employed to capture the underlying correspondence between the capacity loss and sample entropy. The SBPM-based SOH monitor is compared with a polynomial model developed in our prior work. The proposed approach allows for an analytical integration of temperature effects such that an explicitly temperature-perspective SOH estimator is established, whose performance and complexity is contrasted to the support vector machine (SVM) scheme. The forecast of remaining useful life is also performed via a combination of SBPM and bootstrap sampling concepts. Large amounts of experimental data from multiple lithium-ion battery cells at three different temperatures are deployed for model construction, verification, and comparison. Such a multi-cell setting is more useful and valuable than only considering a single cell (a common scenario). This is the first known application of combined sample entropy and SBPM to battery health prognosis.",IEEE Transactions on Industrial Electronics,2016,10.1109/TIE.2015.2461523,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9fd4eb242ac30d2a266e220cb55fa5ab26edcaf0,https://www.semanticscholar.org/paper/9fd4eb242ac30d2a266e220cb55fa5ab26edcaf0,Migrating Intelligence from Cloud to Ultra-Edge Smart IoT Sensor Based on Deep Learning: An Arrhythmia Monitoring Use-Case,"Traditionally, the Internet of Things (IoT) devices, deployed on the ultra-edge of the network, lack computation, and energy resources. In this paper, we press on the need to go beyond the realms of traditional edge computing (e.g., limited to user-smartphones) and investigate how to incorporate intelligence into the ultra-edge IoT sensors. Among numerous use-cases, we select a mobile Health (mHealth) scenario where we conceptualize a smart IoT sensor to collect and intelligently process single-channel Electrocardiogram (ECG) signals to detect arrhythmia, a heart-condition often associated with morbidity and even mortality. The arrhythmia detection can be regarded as a non-linear Delay Differential Equation (DDE) time-series analysis problem, and the conventional solutions to this problem are not suitable for integration with IoT sensors due to rigorous pre-processing steps. As a solution, a Convolutional Neural Network (CNN)-based, lightweight Arrhythmia classification system is proposed in the paper without the need for noise-filtering and feature extraction steps. Four classes of the heartbeats are considered to comply with the ANSI/AAMI EC57:1998 standard. The proposed system's performances and generalization potential are assessed using three datasets from PhysioNet trained on a deep learning workstation and then transferred to virtualized micro-controllers connected to IoT sensors. The proposed deep learning model exhibits encouraging performance (accuracy 95.27%) in heartbeat classification. Experimental and numerical results demonstrate that the proposed deep learning technique outperforms conventional DDE-based optimization techniques and machine learning techniques such as K-Nearest Neighbor (KNN), and random forest (RF).",2020 International Wireless Communications and Mobile Computing (IWCMC),2020,10.1109/iwcmc48107.2020.9148134,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a3ad41d477d7e4fd294f109e612861918fb7d6ee,https://www.semanticscholar.org/paper/a3ad41d477d7e4fd294f109e612861918fb7d6ee,"High-resolution spatiotemporal measurement of air and environmental noise pollution in Sub-Saharan African cities: Pathways to Equitable Health Cities Study protocol for Accra, Ghana","Introduction Air and noise pollution are emerging environmental health hazards in African cities, with potentially complex spatial and temporal patterns. Limited local data are a barrier to the formulation and evaluation of policies to reduce air and noise pollution. Methods and analysis We designed a year-long measurement campaign to characterise air and noise pollution and their sources at high-resolution within the Greater Accra Metropolitan Area (GAMA), Ghana. Our design uses a combination of fixed (year-long, n=10) and rotating (week-long, n =~130) sites, selected to represent a range of land uses and source influences (eg, background, road traffic, commercial, industrial and residential areas, and various neighbourhood socioeconomic classes). We will collect data on fine particulate matter (PM2.5), nitrogen oxides (NOx), weather variables, sound (noise level and audio) along with street-level time-lapse images. We deploy low-cost, low-power, lightweight monitoring devices that are robust, socially unobtrusive, and able to function in Sub-Saharan African (SSA) climate. We will use state-of-the-art methods, including spatial statistics, deep/machine learning, and processed-based emissions modelling, to capture highly resolved temporal and spatial variations in pollution levels across the GAMA and to identify their potential sources. This protocol can serve as a prototype for other SSA cities. Ethics and dissemination This environmental study was deemed exempt from full ethics review at Imperial College London and the University of Massachusetts Amherst; it was approved by the University of Ghana Ethics Committee (ECH 149/18-19). This protocol is designed to be implementable in SSA cities to map environmental pollution to inform urban planning decisions to reduce health harming exposures to air and noise pollution. It will be disseminated through local stakeholder engagement (public and private sectors), peer-reviewed publications, contribution to policy documents, media, and conference presentations.",BMJ Open,2020,10.1136/bmjopen-2019-035798,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3194c62e80b7971d323e955b8623898886f0a605,https://www.semanticscholar.org/paper/3194c62e80b7971d323e955b8623898886f0a605,Prognostic Health Management for Turbofan Engines,"Prognostic Health Management (PHM) is an active area of research and a multibillion dollar industry in the field of reliability engineering. Complex sensor data exhibited by machines can be used to predict a bad omen (possible failure) beforehand, further saving downtime or loss of equipment and environment. We explore various deep learning solutions to model the spatio-temporal relationships exhibited by NASA Turbofans. Current approaches use CNN based models to predict Remaining Useful Life (RUL) of a system, we propose a novel CNN-LSTM architecture and explore the power of LSTMs to model sequential data. We further show the insights of deployment in terms of system tolerance statistics.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
42b64d03075f3a3d325e26b43d7fbe03daf2f23b,https://www.semanticscholar.org/paper/42b64d03075f3a3d325e26b43d7fbe03daf2f23b,"AI-enabled remote monitoring of vital signs for COVID-19: methods, prospects and challenges",,Computing,2021,10.1007/s00607-021-00937-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59cd054122c3d915db74b96954d55e5c5c1ee4a2,https://www.semanticscholar.org/paper/59cd054122c3d915db74b96954d55e5c5c1ee4a2,A mountable toilet system for personalized health monitoring via the analysis of excreta,,Nature Biomedical Engineering,2020,10.1038/s41551-020-0534-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e2bb7ca30d72a5d730d2b692969a9a30f0b23bdf,https://www.semanticscholar.org/paper/e2bb7ca30d72a5d730d2b692969a9a30f0b23bdf,"Telehealthcare and Covid-19: A Noninvasive & Low Cost Invasive, Scalable and Multimodal Real-Time Smartphone Application for Early Diagnosis of SARS-CoV-2 Infection","The global coronavirus pandemic overwhelmed many health care systems, enforcing lockdown and encouraged work from home to control the spread of the virus and prevent overrunning of hospitalized patients. This prompted a sharp widespread use of telehealth to provide low-risk care for patients. Nevertheless, a continuous mutation into new variants and widespread unavailability of test kits, especially in developing countries, possess the challenge to control future potential waves of infection. In this paper, we propose a novel Smartphone application-based platform for early diagnosis of possible Covid-19 infected patients. The application provides three modes of diagnosis from possible symptoms, cough sound, and specific blood biomarkers. When a user chooses a particular setting and provides the necessary information, it sends the data to a trained machine learning (ML) model deployed in a remote server using the internet. The ML algorithm then predicts the possibility of contracting Covid-19 and sends the feedback to the user. The entire procedure takes place in real-time. Our machine learning models can identify Covid-19 patients with an accuracy of 100%, 95.65%, and 77.59% from blood parameters, cough sound, and symptoms respectively. Moreover, the ML sensitivity for blood and sound is 100%, which indicates correct identification of Covid positive patients. This is significant in limiting the spread of the virus. The multimodality offers multiplex diagnostic methods to better classify possible infectees and together with the instantaneous nature of our technique, demonstrates the power of telehealthcare as an easy and widespread low-cost scalable diagnostic solution for future pandemics.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b785a1b863b5930cc9c40a5612a9579a06f81ed8,https://www.semanticscholar.org/paper/b785a1b863b5930cc9c40a5612a9579a06f81ed8,Wireless Heart Rate Variability in Assessing Community COVID-19,"Building on a growing body of HRV data (Rangon et al., 2020;Whitelaw et al., 2020;Hirten et al., 2021), we propose use of a wearable high fidelity Oura sensor ring (https://ouraring.com/blog/category/research-validation/) to acquire HRV, in addition to other physiological indicators, to track both pre-illness longitudinal baseline and an ongoing longitudinal Community assessment of those indicators associated with COVID-19 using algorithmic analysis and actionable feedback. The use of longitudinal HRV data acquired by a personal device, transferred by smart phone application and analyzed by high throughput cloud-based machine learning algorithm represents an innovative, inexpensive, easily deployable, and scalable method for both individual use for health behavior maintenance and for communication and decision support with clinical and public health professionals in communities and larger jurisdictions. Major theoretical contributions have been made by Porges' Polyvagal Theory (Porges, 2011);Grossman's biobehavioral studies of cardiac vagal tone (Grossman and Taylor, 2007);Owens, Critchley and associates studies of HRV as a remote digital biomarker (Owens et al., 2018);and Thayer's neurovisceral integration approach (Thayer and Lane, 2020), all show the important role of HRV as a physiological indicator of inflammatory and immune system activity. [...]key role of state and local public health authorities, optimized longitudinal HRV monitoring combined with other remotely obtained data can be used in clinical practice as a highly sensitive vital sign indicating exacerbation of a patient's chronic condition or the onset of a new condition.",Frontiers in Neuroscience,2021,10.3389/fnins.2021.564159,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4f51e948ea39cf2860b41e53156a51fbf194941e,https://www.semanticscholar.org/paper/4f51e948ea39cf2860b41e53156a51fbf194941e,Detecting Receptivity for mHealth Interventions in the Natural Environment,"Just-In-Time Adaptive Intervention (JITAI) is an emerging technique with great potential to support health behavior by providing the right type and amount of support at the right time. A crucial aspect of JITAIs is properly timing the delivery of interventions, to ensure that a user is receptive and ready to process and use the support provided. Some prior works have explored the association of context and some user-specific traits on receptivity, and have built post-study machine-learning models to detect receptivity. For effective intervention delivery, however, a JITAI system needs to make in-the-moment decisions about a user's receptivity. To this end, we conducted a study in which we deployed machine-learning models to detect receptivity in the natural environment, i.e., in free-living conditions. We leveraged prior work regarding receptivity to JITAIs and deployed a chatbot-based digital coach - Ally - that provided physical-activity interventions and motivated participants to achieve their step goals. We extended the original Ally app to include two types of machine-learning model that used contextual information about a person to predict when a person is receptive: a static model that was built before the study started and remained constant for all participants and an adaptive model that continuously learned the receptivity of individual participants and updated itself as the study progressed. For comparison, we included a control model that sent intervention messages at random times. The app randomly selected a delivery model for each intervention message. We observed that the machine-learning models led up to a 40% improvement in receptivity as compared to the control model. Further, we evaluated the temporal dynamics of the different models and observed that receptivity to messages from the adaptive model increased over the course of the study.",Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2020,10.1145/3463492,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8fdf9b5dddfff6b40ada3a988c6fffe76ac18c4d,https://www.semanticscholar.org/paper/8fdf9b5dddfff6b40ada3a988c6fffe76ac18c4d,Cric searchable image database as a public platform for conventional pap smear cytology data,,Scientific data,2021,10.1038/s41597-021-00933-8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2979828197184486c7ccd5ba1db05e097dab0389,https://www.semanticscholar.org/paper/2979828197184486c7ccd5ba1db05e097dab0389,Clinically-validated technologies for assisted living,,Journal of Ambient Intelligence and Humanized Computing,2021,10.1007/s12652-021-03419-y,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54d8418a03a908aa40c40f4b0615a813204fc5fd,https://www.semanticscholar.org/paper/54d8418a03a908aa40c40f4b0615a813204fc5fd,SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense Image Labels for Quantitative Clinical Evaluation,"Magnetic resonance imaging (MRI) is a cornerstone of modern medical imaging. However, long image acquisition times, the need for qualitative expert analysis, and the lack of (and difficulty extracting) quantitative indicators that are sensitive to tissue health have curtailed widespread clinical and research studies. While recent machine learning methods for MRI reconstruction and analysis have shown promise for reducing this burden, these techniques are primarily validated with imperfect image quality metrics, which are discordant with clinically-relevant measures that ultimately hamper clinical deployment and clinician trust. To mitigate this challenge, we present the Stanford Knee MRI with Multi-Task Evaluation (SKM-TEA) dataset, a collection of quantitative knee MRI (qMRI) scans that enables end-to-end, clinically-relevant evaluation of MRI reconstruction and analysis tools. This 1.6TB dataset consists of raw-data measurements of ∼25,000 slices (155 patients) of anonymized patient MRI scans, the corresponding scannergenerated DICOM images, manual segmentations of four tissues, and bounding box annotations for sixteen clinically relevant pathologies. We provide a framework for using qMRI parameter maps, along with image reconstructions and dense image labels, for measuring the quality of qMRI biomarker estimates extracted from MRI reconstruction, segmentation, and detection techniques. Finally, we use this framework to benchmark state-of-the-art baselines on this dataset. We hope our SKM-TEA dataset and code can enable a broad spectrum of research for modular image reconstruction and image analysis in a clinically informed manner. Dataset access, code, and benchmarks are available at https://github.com/StanfordMIMI/skm-tea.",NeurIPS Datasets and Benchmarks,2022,10.48550/arXiv.2203.06823,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a9618def7d29a4caa561c3e6ade372dd37cfcc3e,https://www.semanticscholar.org/paper/a9618def7d29a4caa561c3e6ade372dd37cfcc3e,TIP4.0: Industrial Internet of Things Platform for Predictive Maintenance,"Industry 4.0, allied with the growth and democratization of Artificial Intelligence (AI) and the advent of IoT, is paving the way for the complete digitization and automation of industrial processes. Maintenance is one of these processes, where the introduction of a predictive approach, as opposed to the traditional techniques, is expected to considerably improve the industry maintenance strategies with gains such as reduced downtime, improved equipment effectiveness, lower maintenance costs, increased return on assets, risk mitigation, and, ultimately, profitable growth. With predictive maintenance, dedicated sensors monitor the critical points of assets. The sensor data then feed into machine learning algorithms that can infer the asset health status and inform operators and decision-makers. With this in mind, in this paper, we present TIP4.0, a platform for predictive maintenance based on a modular software solution for edge computing gateways. TIP4.0 is built around Yocto, which makes it readily available and compliant with Commercial Off-the-Shelf (COTS) or proprietary hardware. TIP4.0 was conceived with an industry mindset with communication interfaces that allow it to serve sensor networks in the shop floor and modular software architecture that allows it to be easily adjusted to new deployment scenarios. To showcase its potential, the TIP4.0 platform was validated over COTS hardware, and we considered a public data-set for the simulation of predictive maintenance scenarios. We used a Convolution Neural Network (CNN) architecture, which provided competitive performance over the state-of-the-art approaches, while being approximately four-times and two-times faster than the uncompressed model inference on the Central Processing Unit (CPU) and Graphical Processing Unit, respectively. These results highlight the capabilities of distributed large-scale edge computing over industrial scenarios.",Sensors,2021,10.3390/s21144676,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0928e3969687e66278af3edf72af79ffb96f26d1,https://www.semanticscholar.org/paper/0928e3969687e66278af3edf72af79ffb96f26d1,Deep learning-based cross-domain adaptation for gearbox fault diagnosis under variable speed conditions,"Existing intelligent gearbox fault diagnosis approaches have two shortcomings: (a) their performance is mostly confined to manual handcrafted features, and (b) they follow a general assumption that the distribution of the data in the source domain (labeled data on which the model is trained) is similar to the target domain (unlabeled data on which the model is tested), which might not be the case in real-world applications. Substantial human expertise and domain knowledge is required for manual feature extraction, and moreover, deploying the same model for a target domain whose distribution is different from the source domain would lead to poor generalization. Since deep learning methods can automatically learn high dimensional feature representations from raw measurement data, this paper proposes a novel deep learning-based domain adaptation (DA) method for gearbox fault diagnosis under significant speed variations. A deep convolutional neural network is used as the main architecture. The paper proposes to minimize the summation of cross-entropy loss (between the labeled source domain data) and maximum mean discrepancy loss (between the labeled source and unlabeled target datasets) simultaneously to adapt the source domain model to be applied in the target domain. The proposed deep learning DA approach is evaluated using experimental data from a gearbox under variable speeds and multiple health conditions. An appropriate benchmarking with both traditional machine learning methods and other DA methods demonstrate the superiority of the proposed method.",Measurement Science and Technology,2020,10.1088/1361-6501/ab64aa,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fdfa7542433982c173704348033f755d52229974,https://www.semanticscholar.org/paper/fdfa7542433982c173704348033f755d52229974,ML Health: Fitness Tracking for Production Models,"Deployment of machine learning (ML) algorithms in production for extended periods of time has uncovered new challenges such as monitoring and management of real-time prediction quality of a model in the absence of labels. However, such tracking is imperative to prevent catastrophic business outcomes resulting from incorrect predictions. The scale of these deployments makes manual monitoring prohibitive, making automated techniques to track and raise alerts imperative. We present a framework, ML Health, for tracking potential drops in the predictive performance of ML models in the absence of labels. The framework employs diagnostic methods to generate alerts for further investigation. We develop one such method to monitor potential problems when production data patterns do not match training data distributions. We demonstrate that our method performs better than standard ""distance metrics"", such as RMSE, KL-Divergence, and Wasserstein at detecting issues with mismatched data sets. Finally, we present a working system that incorporates the ML Health approach to monitor and manage ML deployments within a realistic full production ML lifecycle.",ArXiv,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
449f9165dcdc4d6f3e911f3700c6a4c090f43855,https://www.semanticscholar.org/paper/449f9165dcdc4d6f3e911f3700c6a4c090f43855,Maintaining fairness across distribution shift: do we have viable solutions for real-world applications?,"Fairness and robustness are often considered as orthogonal dimensions when evaluating machine learning models. However, recent work has revealed interactions between fairness and robustness, showing that fairness properties are not necessarily maintained under distribution shift. In healthcare settings, this can result in e.g. a model that performs fairly according to a selected metric in “hospital A” showing unfairness when deployed in “hospital B”. While a nascent field has emerged to develop provable fair and robust models, it typically relies on strong assumptions about the shift, limiting its impact for real-world applications. In this work, we explore the settings in which recently proposed mitigation strategies are applicable by referring to a causal framing. Using examples of predictive models in dermatology and electronic health records, we show that real-world applications are complex and often invalidate the assumptions of such methods. Our work hence highlights technical, practical, and engineering gaps that prevent the development of robustly fair machine learning models for real-world applications. Finally, we discuss potential remedies at each step of the machine learning pipeline.",ArXiv,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e3195e97c3082f70c8182971d0c6ffc244bfa645,https://www.semanticscholar.org/paper/e3195e97c3082f70c8182971d0c6ffc244bfa645,High-Performance Mining of COVID-19 Open Research Datasets for Text Classification and Insights in Cloud Computing Environments,"The COVID-19 global pandemic is an unprecedented health crisis. Many researchers around the world have produced an extensive collection of literature since the outbreak. Analysing this information to extract knowledge and provide meaningful insights in a timely manner requires a considerable amount of computational power. Cloud platforms are designed to provide this computational power in an on-demand and elastic manner. Specifically, hybrid clouds, composed of private and public data centers, are particularly well suited to deploy computationally intensive workloads in a cost-efficient, yet scalable manner. In this paper, we developed a system utilising the Aneka Platform as a Service middleware with parallel processing and multi-cloud capability to accelerate the data process pipeline and article categorising process using machine learning on a hybrid cloud. The results are then persisted for further referencing, searching and visualising. The performance evaluation shows that the system can help with reducing processing time and achieving linear scalability. Beyond COVID-19, the application might be used directly in broader scholarly article indexing and analysing.",2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC),2020,10.1109/UCC48980.2020.00048,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64637e9255dec4482aff922b6dd7bb5d391ffd3e,https://www.semanticscholar.org/paper/64637e9255dec4482aff922b6dd7bb5d391ffd3e,Reducing Significances of Mesh Sensors Technologies through Dimensionality Reduction Algorithm,"In today's world, the breadth of real-time applications and networks is not limited to business and social activities. They are expanding as a field to provide improved and competitive settings for a variety of activities such as home, health, and commercial procedures. Data analytic method is used to maintain network accessibility as well as the robustness of expert services. It is necessary to clean up the data in order to reduce the computational complexity of extracting and pre-processing models. Because present approaches are sophisticated, they necessitate large computations. To this effect, the objective is to deploy a machine learning algorithm – “cuckoo search algorithm” for dimensionality reduction problems in data extraction for IoTs application. The cuckoo search-based feature extraction algorithm is a mutant algorithm that organizes itself depending on the unpredictable amount of input and generates a new and improved feature space. After the cuckoo search-based feature extraction is implemented, a few test benchmarks are provided to assess the performance of mutant cuckoo search algorithms. As a result of the low-dimensional data, classification accuracy is improved while complexity and expense are lowered.",Engineering International,2020,10.18034/EI.V8I2.556,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9148ea7fd97c8cb98c12c31a4f3306f1b5ff9175,https://www.semanticscholar.org/paper/9148ea7fd97c8cb98c12c31a4f3306f1b5ff9175,Video Analytics for Face Detection and Tracking,"Machine Learning has substantially grown over a period of decade. Deep Learning the new field of Machine Learning is gaining ever-increasing interest in research due to its implicit capability appropriate for successful applications in the field of computer vision, speech processing, image processing, object detection, human and face sub-attribute detection, and many more analytical systems. Intelligent Video Systems and Video Analytics is managed by a wide collection in transportation, security, health care and customer analytics. A Deep-Learning- based approach helps researchers control the massive, complex and diverse dataset to improve the performance by proficiently extracting only the vital features from a large video dataset. In this paper we present a system to autonomously detect facial images from a video surveillance and extract feature points in the frame. We use Viola-Jones algorithm and the KLT algorithm in our system to track faces in real-time. We also present a brief survey on Deep Learning (DL) models deployed in the field of Video Analytics. We cover architectures, tasks and related analytical methods and demonstrate the importance of Video Systems.","2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN)",2020,10.1109/ICACCCN51052.2020.9362900,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
363906abc17b21b3fed028edd6387b7b4cffd8cc,https://www.semanticscholar.org/paper/363906abc17b21b3fed028edd6387b7b4cffd8cc,Health Monitoring with Low Power IoT Devices using Anomaly Detection Algorithm,"The healthcare industry is rapidly adopting new technologies such as the Internet of Things (IoT), which are dropping costs and improving healthcare outcomes. Such IoT systems typically include edge devices (glucose monitors, ventilators, pacemakers), gateway devices that aggregate the data from the edge devices and transmit it to the cloud, and cloud-based systems which analyze the device data to draw conclusions, display information, or direct the connected devices to take action. This process can lead to communication lags and delayed responses to patient conditions/treatment. The aim of this proposal is to overcome these delays with IoT technology and allow for prompt urgent treatment to patients. The solution proposed includes a model to monitor and process the data disseminated by wearable devices related to the patients’ health issues and connect the data to IoT cloud platforms. Analysis of the patients’ health data to identify anomalies will be performed at the device level by developing an offline machine learning model using specific algorithms for anomaly detection and deploying them on the IoT devices or IoT gateway. Processing of the real-time health data will be performed at the device level and the prediction of anomalous data will be sent to the third-party cloud for implementing any necessary actions.",2019 Fourth International Conference on Fog and Mobile Edge Computing (FMEC),2019,10.1109/FMEC.2019.8795327,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c2653d733af5a54004015672c2631131a3a1b0ef,https://www.semanticscholar.org/paper/c2653d733af5a54004015672c2631131a3a1b0ef,DCTclock: Clinically-Interpretable and Automated Artificial Intelligence Analysis of Drawing Behavior for Capturing Cognition,"Developing tools for efficiently measuring cognitive change specifically and brain health generally—whether for clinical use or as endpoints in clinical trials—is a major challenge, particularly for conditions such as Alzheimer's disease. Technology such as connected devices and advances in artificial intelligence offer the possibility of creating and deploying clinical-grade tools with high sensitivity, rapidly, cheaply, and non-intrusively. Starting from a widely-used paper and pencil cognitive status test—The Clock Drawing Test—we combined a digital input device to capture time-stamped drawing coordinates with a machine learning analysis of drawing behavior to create DCTclock™, an automated analysis of nuances in cognitive performance beyond successful task completion. Development and validation was conducted on a dataset of 1,833 presumed cognitively unimpaired and clinically diagnosed cognitively impaired individuals with varied neurological conditions. We benchmarked DCTclock against existing clock scoring systems and the Mini-Mental Status Examination, a widely-used but lengthier cognitive test, and showed that DCTclock offered a significant improvement in the detection of early cognitive impairment and the ability to characterize individuals along the Alzheimer's disease trajectory. This offers an example of a robust framework for creating digital biomarkers that can be used clinically and in research for assessing neurological function.",Frontiers in Digital Health,2021,10.3389/fdgth.2021.750661,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ac2102461ab280dd4966d6dae34bab89d687a07d,https://www.semanticscholar.org/paper/ac2102461ab280dd4966d6dae34bab89d687a07d,Data-driven techniques for predictive analytics in smart manufacturing,"Timeseries forecasting is applied to many areas of smart factories, including machine health monitoring (MHM), predictive maintenance and production scheduling. In smart factories, machine speed prediction can be used to dynamically adjust production processes based on different system conditions, optimise production throughput and minimise energy consumption. However, making accurate, data-driven machine speed forecasts is challenging. Given the complex nature of industrial manufacturing process data, predictive models that are robust to noise and can capture the temporal and spatial distributions of the timeseries signals are prerequisites for accurate forecasting. Motivated by recent deep learning studies in smart manufacturing, this paper proposes an end-to-end model for multi-step machine speed prediction. The model, known as 2DConvolutional LSTM Autoencoder (2DConvLSTMAE), comprises a deep convolutional LSTM (ConvLSTM) encoderdecoder architecture. Extensive empirical analyses using realworld data obtained from a metal packaging plant in the United Kingdom demonstrate the value of the proposed method when compared to state-of-the-art predictive models.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
24cfaa7793e84988375673b8bea49bdfc60cf462,https://www.semanticscholar.org/paper/24cfaa7793e84988375673b8bea49bdfc60cf462,Repetitive Blast Mild Traumatic Brain Injury Increases Ethanol Sensitivity in Male Mice and Risky Drinking Behavior in Male Combat Veterans.,"BACKGROUND
Mild traumatic brain injury (mTBI) is common in civilians and highly prevalent among military service members. mTBI can increase health-risk behaviors (e.g., sensation seeking, impulsivity) and addiction risk (e.g., alcohol use disorder (AUD)), but how mTBI and substance use might interact to promote addiction risk remains poorly understood. Likewise, potential differences in single vs. repetitive mTBI in relation to alcohol use/abuse has not been previously examined.


METHODS
Here we examined how a history of single (1x) or repetitive (3x) blast exposure (blast-mTBI) affects ethanol-induced behavioral and physiological outcomes using an established mouse model of blast-mTBI. To investigate potential translational relevance, we also examined self-report responses to the Alcohol Use Disorders Identification Test-Consumption Questions (AUDIT-C), a widely used measure to identify potential hazardous drinking and AUD, and used a novel unsupervised machine learning approach to investigate whether a history of blast-mTBI affected drinking behaviors in Iraq/Afghanistan Veterans.


RESULTS
Both single and repetitive blast-mTBI in mice increased the sedative properties of ethanol (with no change in tolerance or metabolism), but only repetitive blast potentiated ethanol-induced locomotor stimulation and shifted ethanol intake patterns (increased consumption 'front-loading' (e.g., higher rate of consumption during initial acute (2-hour) phase of alcohol access (24-hour)) and decreased total daily intake) during intermittent two bottle choice. Examination of AUDIT-C scores in Iraq/Afghanistan Veterans revealed an optimal three-cluster solution: 'low' (low intake and low frequency), 'frequent' (low intake but high frequency), and 'risky' (high intake and high frequency), where Veterans with a history of blast-mTBI displayed a shift in cluster assignment from 'frequent' to 'risky', as compared to Veterans who were deployed to Iraq/Afghanistan who had no lifetime history of TBI.


CONCLUSIONS
Together, these results offer new insight regarding how blast-mTBI may give rise to increased AUD and highlight the increased potential for adverse health-risk behaviors specifically following repetitive blast-mTBI.","Alcoholism, clinical and experimental research",2021,10.1111/acer.14605,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4c453e69bf730f98efbea7b5784aa323050c76df,https://www.semanticscholar.org/paper/4c453e69bf730f98efbea7b5784aa323050c76df,"Supporting the classification of patients in public hospitals in Chile by designing, deploying and validating a system based on natural language processing",,BMC Medical Informatics and Decision Making,2020,10.1186/s12911-021-01565-z,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f24af878ce6ee714ebfde4b6018aa115efa6f07c,https://www.semanticscholar.org/paper/f24af878ce6ee714ebfde4b6018aa115efa6f07c,Comprehensive Analysis of Feature Selection on Early Heart Strok Prediction,"A stroke is a medicinal exigency and requires early prognosis in accordance with damage to the brain from intrusion of its blood circulation, therefore, early diagnosis helps, medical health professionals to save human lives. This aim can be achieved using the various machine learning techniques. In this research article, machine learning models are deployed on well known heart stroke classification data-set. In addition, effect of well established feature selection technique also observed on aforementioned machine learning models. In the experimental analysis, machine learning models with standard feature selection technique are tested on the data-set, namely, framingham, and obtained results are evaluated using the confusion metrics including recall, F1-score, precision and accuracy. From the obtained results, it is observed that Random Forest (RF) and Extra Trees (ET) performed the best with PCA (Principle component analysis), giving the highest accuracy of 88.91 %.",2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT),2021,10.1109/CSNT51715.2021.9509629,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d3c0498d115cee22d5051af3be1d21012c0f301e,https://www.semanticscholar.org/paper/d3c0498d115cee22d5051af3be1d21012c0f301e,Early Prediction of Malignant Mesothelioma: An Approach towards Non-invasive Method,"

Malignant Mesothelioma (MM) is a rare but aggressive tumor that arises in the lungs. Commonly, costly imaging and laboratory resources, i.e., X-ray imaging, magnetic resonance imaging (MRI), positron emission tomography (PET) scans, biopsies, and blood tests, have already been utilized for the diagnosis of MM. Even though these diagnostic measures are expensive and unavailable in distant areas, some of these diagnostic methods are also very painful for the patient, including biopsy and cytology of pleural fluid. 



In this study, we proposed a diagnostic model for early identification of MM via machine learning techniques. We explored the health records of 324 Turkish patients, which showed the symptoms related to MM. The data of patients included socio-economic, geographical, and clinical features. 



Different feature selection methods have been employed for the selection of significant features. To overcome the data imbalance problem, various data-level resampling techniques have been utilized to obtain efficient results. The gradient boosted decision tree (GBDT) method has been used to develop the diagnostic model. The performance of the GBDT model is also compared with traditional machine learning algorithms. 



Our model's results outperformed other models, both on balance and imbalance data. The results clearly show that undersampling techniques outperformed imbalanced data without resampling based on accuracy and receiving operating characteristic (ROC) value. Conversely, it has also been observed that oversampling techniques outperformed undersampling and imbalanced data based on accuracy and ROC. All classifiers employed in this study achieved efficient results utilizing feature selection-based methods (OneR, information gain, and Relief-F), but the other two methods (gain ratio and correlation) results were not entirely promising. Finally, when the combination of Synthetic Minority Oversampling Technique (SMOTE) and OneR was applied with GBDT, it gave the most favorable results based on accuracy, F-measure, and ROC. The diagnosis model has also been deployed to assist doctors, patients, medical practitioners, and other healthcare professionals for early diagnosis and better treatment of MM.
",Current Bioinformatics,2021,10.2174/1574893616666210616121023,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
eb1926e83f92f6b430e40755a763560579e880ae,https://www.semanticscholar.org/paper/eb1926e83f92f6b430e40755a763560579e880ae,A Study on Asthmatic Occurrence Using Deep Learning Algorithm,"Recently, the problem of air pollution has become a global concern due to industrialization and overcrowding. Air pollution can cause various adverse effects on human health, among which respiratory diseases such as asthma, which have been of interest in this study, can be directly affected. Previous studies have used clinical data to identify how air pollutant affect diseases such as asthma based on relatively small samples. This is high likely to result in inconsistent results for each collection samples, and has significant limitations in that research is difficult for anyone other than the medical profession. In this study, the main focus was on predicting the actual asthmatic occurrence, based on data on the atmospheric environment data released by the government and the frequency of asthma outbreaks. First of all, this study verified the significant effects of each air pollutant with a time lag on the outbreak of asthma through the time-lag Pearson Correlation Coefficient. Second, train data built on the basis of verification results are utilized in Deep Learning algorithms, and models optimized for predicting the asthmatic occurrence are designed. The average error rate of the model was about 11.86%, indicating superior performance compared to other machine learning-based algorithms. The proposed model can be used for efficiency in the national insurance system and health budget management, and can also provide efficiency in the deployment and supply of medical personnel in hospitals. And it can also contribute to the promotion of national health through early warning of the risk of outbreak by atmospheric environment for chronic asthma patients. ■ keyword :∣Deep Learning∣Asthma∣DNN∣Disease∣Atmosphere∣Air Pollution∣Public Health Policy∣ 접수일자 : 2020년 06월 04일 수정일자 : 2020년 07월 17일 심사완료일 : 2020년 07월 20일 교신저자 : 성태응, e-mail : tesung@yonsei.ac.kr 딥러닝 알고리즘을 활용한 천식 환자 발생 예측에 대한 연구 675",,2020,10.5392/JKCA.2020.20.07.674,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8bb93c06eede9a0178542f61a1ceb92f966ae0a7,https://www.semanticscholar.org/paper/8bb93c06eede9a0178542f61a1ceb92f966ae0a7,Psychiatry in the Digital Age: A Blessing or a Curse?,"Social distancing and the shortage of healthcare professionals during the COVID-19 pandemic, the impact of population aging on the healthcare system, as well as the rapid pace of digital innovation are catalyzing the development and implementation of new technologies and digital services in psychiatry. Is this transformation a blessing or a curse for psychiatry? To answer this question, we conducted a literature review covering a broad range of new technologies and eHealth services, including telepsychiatry; computer-, internet-, and app-based cognitive behavioral therapy; virtual reality; digital applied games; a digital medicine system; omics; neuroimaging; machine learning; precision psychiatry; clinical decision support; electronic health records; physician charting; digital language translators; and online mental health resources for patients. We found that eHealth services provide effective, scalable, and cost-efficient options for the treatment of people with limited or no access to mental health care. This review highlights innovative technologies spearheading the way to more effective and safer treatments. We identified artificially intelligent tools that relieve physicians from routine tasks, allowing them to focus on collaborative doctor–patient relationships. The transformation of traditional clinics into digital ones is outlined, and the challenges associated with the successful deployment of digitalization in psychiatry are highlighted.",International journal of environmental research and public health,2021,10.3390/ijerph18168302,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b56146004a50d64e7ea6b0c8b9e669ffe285a96a,https://www.semanticscholar.org/paper/b56146004a50d64e7ea6b0c8b9e669ffe285a96a,Investigation of US Cyclospora cayetanensis outbreaks in 2019 and evaluation of an improved Cyclospora genotyping system against 2019 cyclosporiasis outbreak clusters,"Abstract Cyclosporiasis is an illness characterised by watery diarrhoea caused by the food-borne parasite Cyclospora cayetanensis. The increase in annual US cyclosporiasis cases led public health agencies to develop genotyping tools that aid outbreak investigations. A team at the Centers for Disease Control and Prevention (CDC) developed a system based on deep amplicon sequencing and machine learning, for detecting genetically-related clusters of cyclosporiasis to aid epidemiologic investigations. An evaluation of this system during 2018 supported its robustness, indicating that it possessed sufficient utility to warrant further evaluation. However, the earliest version of CDC's system had some limitations from a bioinformatics standpoint. Namely, reliance on proprietary software, the inability to detect novel haplotypes and absence of a strategy to select an appropriate number of discrete genetic clusters would limit the system's future deployment potential. We recently introduced several improvements that address these limitations and the aim of this study was to reassess the system's performance to ensure that the changes introduced had no observable negative impacts. Comparison of epidemiologically-defined cyclosporiasis clusters from 2019 to analogous genetic clusters detected using CDC's improved system reaffirmed its excellent sensitivity (90%) and specificity (99%), and confirmed its high discriminatory power. This C. cayetanensis genotyping system is robust and with ongoing improvement will form the basis of a US-wide C. cayetanensis genotyping network for clinical specimens.",Epidemiology and Infection,2021,10.1017/S0950268821002090,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4828c80f903cd2b801960c8b1ccaf50387e86022,https://www.semanticscholar.org/paper/4828c80f903cd2b801960c8b1ccaf50387e86022,HEAR: Human Action Recognition via Neural Networks on Homomorphically Encrypted Data,"Remote monitoring to support “aging in place” is an active area of research. Advanced computer vision technology based on deep learning can provide near real-time home monitoring to detect falling and symptoms related to seizure, and stroke. Affordable webcams, together with cloud computing services (to run machine learning algorithms), can potentially bring significant social and health benefits. However, it has not been deployed in practice because of privacy and security concerns. People may feel uncomfortable sending their videos of daily activities (with potentially sensitive private information) to a computing service provider (e.g., on a commercial cloud). In this paper, we propose a novel strategy to resolve this dilemma by applying fully homomorphic encryption (FHE) to an alternative representation of human actions (i.e., skeleton joints), which guarantees information confidentiality while retaining high-performance action detection at a low cost. We design an FHE-friendly neural network for action recognition and present a secure neural network evaluation strategy to achieve near real-time action detection. Our framework for private inference achieves an 87.99% recognition accuracy (86.21% sensitivity and 99.14% specificity in detecting falls) with a latency of 3.1 seconds on real-world datasets. Our evaluation shows that our elaborated and fine-tuned method reduces the inference latency by 23.81%∼74.67% over a straightforward implementation.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5ded93b01a451240855cc82999efbe3cbcbf18e4,https://www.semanticscholar.org/paper/5ded93b01a451240855cc82999efbe3cbcbf18e4,Using automation to produce a ‘living map’ of the COVID-19 research literature,"Journal of EAHIL 2021; Vol. 17 (2): 11-15 doi 10.32384/jeahil17469 Abstract The COVID-19 pandemic has disrupted life worldwide and presented unique challenges in the health evidence synthesis space. The urgent nature of the pandemic required extreme rapidity for keeping track of research, and this presented a unique opportunity for long-proposed automation systems to be deployed and evaluated. We compared the use of novel automation technologies with conventional manual screening; and Microsoft Academic Graph (MAG) with the MEDLINE and Embase databases locating the emerging research evidence. We found that a new workflow involving machine learning to identify relevant research in MAG achieved a much higher recall with lower manual effort than using conventional approaches.",,2021,10.32384/jeahil17469,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
174eda90ddb75dc10a093a9d3384abd0675e114b,https://www.semanticscholar.org/paper/174eda90ddb75dc10a093a9d3384abd0675e114b,A Bayesian Network Decision Support Tool for Low Back Pain Using a RAND Appropriateness Procedure: Proposal and Internal Pilot Study,"Background Low back pain (LBP) is an increasingly burdensome condition for patients and health professionals alike, with consistent demonstration of increasing persistent pain and disability. Previous decision support tools for LBP management have focused on a subset of factors owing to time constraints and ease of use for the clinician. With the explosion of interest in machine learning tools and the commitment from Western governments to introduce this technology, there are opportunities to develop intelligent decision support tools. We will do this for LBP using a Bayesian network, which will entail constructing a clinical reasoning model elicited from experts. Objective This paper proposes a method for conducting a modified RAND appropriateness procedure to elicit the knowledge required to construct a Bayesian network from a group of domain experts in LBP, and reports the lessons learned from the internal pilot of the procedure. Methods We propose to recruit expert clinicians with a special interest in LBP from across a range of medical specialties, such as orthopedics, rheumatology, and sports medicine. The procedure will consist of four stages. Stage 1 is an online elicitation of variables to be considered by the model, followed by a face-to-face workshop. Stage 2 is an online elicitation of the structure of the model, followed by a face-to-face workshop. Stage 3 consists of an online phase to elicit probabilities to populate the Bayesian network. Stage 4 is a rudimentary validation of the Bayesian network. Results Ethical approval has been obtained from the Research Ethics Committee at Queen Mary University of London. An internal pilot of the procedure has been run with clinical colleagues from the research team. This showed that an alternating process of three remote activities and two in-person meetings was required to complete the elicitation without overburdening participants. Lessons learned have included the need for a bespoke online elicitation tool to run between face-to-face meetings and for careful operational definition of descriptive terms, even if widely clinically used. Further, tools are required to remotely deliver training about self-identification of various forms of cognitive bias and explain the underlying principles of a Bayesian network. The use of the internal pilot was recognized as being a methodological necessity. Conclusions We have proposed a method to construct Bayesian networks that are representative of expert clinical reasoning for a musculoskeletal condition in this case. We have tested the method with an internal pilot to refine the process prior to deployment, which indicates the process can be successful. The internal pilot has also revealed the software support requirements for the elicitation process to model clinical reasoning for a range of conditions. International Registered Report Identifier (IRRID) DERR1-10.2196/21804",JMIR research protocols,2021,10.2196/21804,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5cc6155331c67de0238a633341fe66b6de8ae793,https://www.semanticscholar.org/paper/5cc6155331c67de0238a633341fe66b6de8ae793,Functional Anomaly Detection: a Benchmark Study,"The increasing automation in many areas of the Industry expressly demands to design efficient machine-learning solutions for the detection of abnormal events. With the ubiquitous deployment of sensors monitoring nearly continuously the health of complex infrastructures, anomaly detection can now rely on measurements sampled at a very high frequency, providing a very rich representation of the phenomenon under surveillance. In order to exploit fully the information thus collected, the observations cannot be treated as multivariate data anymore and a functional analysis approach is required. It is the purpose of this paper to investigate the performance of recent techniques for anomaly detection in the functional setup on real datasets. After an overview of the state-of-theart and a visual-descriptive study, a variety of anomaly detection methods are compared. While taxonomies of abnormalities (e.g. shape, location) in the functional setup are documented in the literature, assigning a specific type to the identified anomalies appears to be a challenging task. Thus, strengths and weaknesses of the existing approaches are benchmarked in view of these highlighted types in a simulation study. Anomaly detection methods are next evaluated on two datasets, related to the monitoring of helicopters in flight and to the spectrometry of construction materials namely. The benchmark analysis is concluded by a recommendation guidance for practitioners.",ArXiv,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
51960c274993cb61fdaff2dfa02d4cacef542c28,https://www.semanticscholar.org/paper/51960c274993cb61fdaff2dfa02d4cacef542c28,The “Ecosystem as a Service (EaaS)” approach to advance clinical artificial intelligence (cAI),"The application of machine learning and artificial intelligence to clinical settings for prevention, diagnosis, treatment, and the improvement of clinical care have been demonstrably cost-effective. However, current clinical AI (cAI) support tools are predominantly created by non-domain experts and algorithms available in the market have been criticized for the lack of transparency behind their creation. To combat these challenges, the Massachusetts Institute of Technology Critical Data (MIT-CD) consortium, an affiliation of research labs, organizations, and individuals that contribute to research in and around data that has a critical impact on human health, has iteratively developed the “Ecosystem as a Service (EaaS)” approach, providing a transparent education and accountability platform for clinical and technical experts to collaborate and advance cAI. The EaaS approach provides a range of resources, from open-source databases and specialized human resources to networking and collaborative opportunities. While mass deployment of the ecosystem still faces several hurdles, here we discuss our initial implementation efforts. We hope this will promote further exploration and expansion of the EaaS approach, while also informing or realizing policies that will accelerate multinational, multidisciplinary, and multisectoral collaborations in cAI research and development, and provide localized clinical best practices for equitable healthcare access.",PLOS Digital Health,2022,10.1371/journal.pdig.0000011,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bc411e01f870dbd2def87520d6b9f09c763cc45b,https://www.semanticscholar.org/paper/bc411e01f870dbd2def87520d6b9f09c763cc45b,A Clinical Decision Support System (CDSS) for Unbiased Prediction of Caesarean Section Based on Features Extraction and Optimized Classification,"Nowadays, caesarean section (CS) is given preference over vaginal birth and this trend is rapidly rising around the globe, although CS has serious complications such as pregnancy scar, scar dehiscence, and morbidly adherent placenta. Thus, CS should only be performed when it is absolutely necessary for mother and fetus. To avoid unnecessary CS, researchers have developed different machine-learning- (ML-) based clinical decision support systems (CDSS) for CS prediction using electronic health record of the pregnant women. However, previously proposed methods suffer from the problems of poor accuracy and biasedness in ML. To overcome these problems, we have designed a novel CDSS where random oversampling example (ROSE) technique has been used to eliminate the problem of minority classes in the dataset. Furthermore, principal component analysis has been employed for feature extraction from the dataset while, for classification purpose, random forest (RF) model is deployed. We have fine-tuned the hyperparameter of RF using a grid search algorithm for optimal classification performance. Thus, the newly proposed system is named ROSE-PCA-RF and it is trained and tested using an online CS dataset available on the UCI repository. In the first experiment, conventional RF model is trained and tested on the dataset while in the second experiment, the proposed model is tested. The proposed ROSE-PCA-RF model improved the performance of traditional RF by 4.5% with reduced time complexity, while only using two extracted features through the PCA. Moreover, the proposed model has obtained 96.29% accuracy on training data while improving the accuracy of 97.12% on testing data.",Computational intelligence and neuroscience,2022,10.1155/2022/1901735,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
159030b64341ce1509fa4d2af09a71741f4ffff6,https://www.semanticscholar.org/paper/159030b64341ce1509fa4d2af09a71741f4ffff6,Eight human factors and ergonomics principles for healthcare artificial intelligence,"© Author(s) (or their employer(s)) 2022. Reuse permitted under CC BYNC. No commercial reuse. See rights and permissions. Published by BMJ. INTRODUCTION The COVID19 pandemic dramatically accelerated the digital transformation of many health systems in order to protect patients and healthcare workers by minimising the need for physical contact. A key part of healthcare digital transformation is the development and adoption of artificial intelligence (AI) technologies, which are regarded a priority in national health policies. 3 Since 2015, there has been an exponential growth in the number of regulatory approvals for medical devices that use machine learning, with British standards currently under development in conjunction with international standards. In addition, there are an even larger number of healthcare AI technologies that do not require such approvals, because they fall outside of the narrow definition of medical devices. The scope of healthcare AI appears seemingly boundless, with promising results being reported across a range of domains, including imaging and diagnostics, prehospital triage, care management and mental health. However, caution is required when interpreting the claims made in such studies. For example, the evidence base for the effectiveness of deep learning algorithms remains weak and is at high risk of bias, because there are few independent prospective evaluations. This is particularly problematic, because the performance, usability and safety of these technologies can only be reliably assessed in realworld settings, where teams of healthcare workers and AI technologies cooperate and collaborate to provide a meaningful service. To date, however, there have been few human factors and ergonomics (HFE) studies of healthcare AI. There is a need for AI designs and prospective evaluation studies that consider the performance of the overall sociotechnical system, with evidence requirements proportionate to the level of risk. Reporting guidelines have been developed both for smallscale early clinical intervention trials (DECIDEAI) as well as for largescale clinical trials evaluating AI (SPIRITAI) to enhance the quality and transparency of the evidence. In order to support developers, regulators and users of healthcare AI, the Chartered Institute of Ergonomics and Human Factors (CIEHF) developed a white paper that sets out an HFE vision and principles for the design and use of healthcare AI. Development of the white paper was an international effort bringing together over 30 contributors from different disciplines and was supported by a number of partner organisations including British Standards Institution, the Australian Alliance for AI in Healthcare, the South American Ergonomics Network (RELAESA), USbased Society for Healthcare Innovation, the UK charity Patient Safety Learning, Assuring Autonomy International Programme hosted by the University of York, Human Factors Everywhere and the Irish Human Factors & Ergonomics Society.",BMJ health & care informatics,2022,10.1136/bmjhci-2021-100516,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
528810ea3dab209a8872daf43eaad7a8cd24c9fd,https://www.semanticscholar.org/paper/528810ea3dab209a8872daf43eaad7a8cd24c9fd,SP0043 Learning and Reasoning in Health Informatics,"Our public health systems are faced with enormous opportunities: new possiblities for diagnosis and treatment, personalized medicine, the availability of large data sets. At the same time, health cost and the demand on the system is increasing at an unsustainable rate. In this talk, I will illustrate how Bayesian machine learning can contribute to solve some of these problems, by discussing two examples: full Bayesian Gaussian Process. Regression for learning non-linear interactions and finding missing heritability in genetic data; and a graphical model expert system that can assist medical specialists to diagnose patients using Bayesian inference. For many traits and common human diseases, genetic association studies account for little of the known heritable variation. We suggest that this “Missing heritability” might lie in the effect of non-additive interactions between multiple loci. We employed a non-parametric, Bayesian method, based on Gaussian Process Regression. We analysed 46 quantitative yeast phenotypes and found that over 70% of the total known missing heritability could be explained, significantly improving on existing methods. Importantly, the availability of biological replicates significantly improved the power to identify such loci and, hence, to explain variance. These results represent a significant advance in approaches to understanding the missing heritability problem with potentially important implications for studies of complex, quantitative traits. Joint work with Kevin Sharp, Wim Wiegerinck, Alejandro Arias Vaquez, Barbara Franke and Kees Albers. Diagnostic errors in US hospitals are estimated to occur in about 5 percent of adults patients, half of which are potentially harmful. In addition, (junior) specialists are known to request too many tests in order to arrive at a diagnosis, significantly increasing the cost of diagnosis. These facts motivate the need for a clinical expert system that assists doctors in the diagnostic process. Despite their obvious advantages, such systems have not been deployed in practice very often. We discuss some of the possible reasons. I will then show how to represents medical knowledge in terms of a Bayesian network. It computes a distribution over the most likely combination of diagnoses, and their probabilities using Monte Carlo sampling. I will illustrate the approach on some real patient cases. Joint work with Anna Simons, Radboud Medical Center Nijmegen. Disclosure of Interest None declared",,2015,10.1136/annrheumdis-2015-eular.6815,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a37f6816f764c639a2be267a950a3566ba048f7f,https://www.semanticscholar.org/paper/a37f6816f764c639a2be267a950a3566ba048f7f,Low-cost Internet of Things Platform for Epilepsy Monitoring Using Real-time Electroencephalogram,"This work is focusing to develop a portable, low-cost remote diagnostic system for developing countries where the current state of health is not in the advanced stage. People with diseases like epilepsy, Alzheimer’s, an extreme turmeric state, or a disorder that makes it difficult to move have been observed. The authors propose a cost-effective remote neurology assessment health care system. To predict epilepsy form electroencephalogram (EEG) signals in real-time. The authors implemented the machine learning model that has been deployed in the raspberry pi micro-controller. The feature extraction stage was carried out in Matlab. The extracted features from the EEG signals were transferred wirelessly to the model deployed in pi raspberry to clearly predict epilepsy and normality cases. The results of the real-time prediction of the trained and deployed model were provided for the remote diagnosis system. The data visualizations can be done on Android/IOS and Matlab desktop.",International Journal of Ambient Computing and Intelligence,2022,10.4018/ijaci.300791,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0af040faf9a0863aeaef5cdc2c05f1fffe4c0f46,https://www.semanticscholar.org/paper/0af040faf9a0863aeaef5cdc2c05f1fffe4c0f46,Fast prototyping of a local fuzzy search system for decision support and retraining of hospital staff during pandemic,,Health Inf. Sci. Syst.,2020,10.1007/s13755-021-00150-y,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3aa162c3aa1209e82acb364259fd453b84fdc550,https://www.semanticscholar.org/paper/3aa162c3aa1209e82acb364259fd453b84fdc550,Monitoring of the refractory lining in a shielded electric arc furnace: An online multitarget regression trees approach,"Being able to predict future temperatures on the wall lining is key when controlling and scheduling maintenance for large industrial smelting furnaces. In this paper, we propose and test a machine learning approach for predicting lining temperatures in a ferronickel smelting furnace. This approach was deployed and evaluated in a real‐world scenario, i.e., in one of Cerro Matoso S.A.'s (CMSA) industrial plant furnaces. Different techniques were tested, and finally, a multitarget regression (MTR) model showed the best performance. Previous state of the art focused on predicting only one target sensor; in contrast, our model is capable of predicting up to 12 targets. Two MTR models were tested: the incremental structured output prediction tree (iSOUP‐Tree) and the stacked single‐target Hoeffding tree regressor (SST‐HT). The SST‐HT method had the best behavior in terms of the average mean absolute error (AMAE) and average root mean square error (ARMSE). The results indicate that the developed MTR models can accurately predict the measured temperature on multiple point sensors. Results of this work are expected to help the process of structural control and health monitoring of the furnace linings located at CMSA's plant.",Structural Control and Health Monitoring,2021,10.1002/stc.2885,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d611b69ddde00db95d9658ec8e4c7c6d4a9bfe1e,https://www.semanticscholar.org/paper/d611b69ddde00db95d9658ec8e4c7c6d4a9bfe1e,Clinical Data Prediction Model to Identify Patients With Early-Stage Pancreatic Cancer.,"PURPOSE
Pancreatic cancer is an aggressive malignancy with patients often experiencing nonspecific symptoms before diagnosis. This study evaluates a machine learning approach to help identify patients with early-stage pancreatic cancer from clinical data within electronic health records (EHRs).


MATERIALS AND METHODS
From the Optum deidentified EHR data set, we identified early-stage (n = 3,322) and late-stage (n = 25,908) pancreatic cancer cases over 40 years of age diagnosed between 2009 and 2017. Patients with early-stage pancreatic cancer were matched to noncancer controls (1:16 match). We constructed a prediction model using eXtreme Gradient Boosting (XGBoost) to identify early-stage patients on the basis of 18,220 features within the EHR including diagnoses, procedures, information within clinical notes, and medications. Model accuracy was assessed with sensitivity, specificity, positive predictive value, and the area under the curve.


RESULTS
The final predictive model included 582 predictive features from the EHR, including 248 (42.5%) physician note elements, 146 (25.0%) procedure codes, 91 (15.6%) diagnosis codes, 89 (15.3%) medications, and 9 (1.5%) demographic features. The final model area under the curve was 0.84. Choosing a model cut point with a sensitivity of 60% and specificity of 90% would enable early detection of 58% late-stage patients with a median of 24 months before their actual diagnosis.


CONCLUSION
Prediction models using EHR data show promise in the early detection of pancreatic cancer. Although widespread use of this approach on an unselected population would produce high rates of false-positive tests, this technique may be rapidly impactful if deployed among high-risk patients or paired with other imaging or biomarker screening tools.",JCO clinical cancer informatics,2021,10.1200/CCI.20.00137,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
836df5aa30aa03adaa3706a89de9e182439ff6f1,https://www.semanticscholar.org/paper/836df5aa30aa03adaa3706a89de9e182439ff6f1,Digital Phenotype for Childhood Internalizing Disorders: Less Positive Play and Promise for a Brief Assessment Battery,"Childhood internalizing disorders, like anxiety and depression, are common, impairing, and difficult to detect. Universal childhood mental health screening has been recommended, but new technologies are needed to provide objective detection. Instrumented mood induction tasks, designed to press children for specific behavioral responses, have emerged as means for detecting childhood internalizing psychopathology. In our previous work, we leveraged machine learning to identify digital phenotypes of childhood internalizing psychopathology from movement and voice data collected during negative valence tasks (pressing for anxiety and fear). In this work, we develop a digital phenotype for childhood internalizing disorders based on wearable inertial sensor data recorded from a Positive Valence task during which a child plays with bubbles. We find that a phenotype derived from features that capture reward responsiveness is able to accurately detect children with underlying internalizing psychopathology (AUC = 0.81). In so doing, we explore the impact of a variety of feature sets computed from wearable sensors deployed to two body locations on phenotype performance across two phases of the task. We further consider this novel digital phenotype in the context of our previous Negative Valence digital phenotypes and find that each task brings unique information to the problem of detecting childhood internalizing psychopathology, capturing different problems and disorder subtypes. Collectively, these results provide preliminary evidence for a mood induction task battery to develop a novel diagnostic for childhood internalizing disorders.",IEEE Journal of Biomedical and Health Informatics,2021,10.1109/JBHI.2021.3053846,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f784c7e96bd8189383740d20efa6e3805938c0c7,https://www.semanticscholar.org/paper/f784c7e96bd8189383740d20efa6e3805938c0c7,Water Quality Estimation using Computer Vision in UAV,"The color change of water in a water body is often a tell - tale sign of its health. To counter the sources of water pollution an Unmanned Aerial Vehicle is deployed over a water body which reports back any discrepancies by channeling the feed through Computer Vision based model. This allows for rapid steps to be taken by the Concerned Authorities to mitigate the current situation. Algae formation, floating impurities and color change of the water body are the scope of the project and each of these are detected with an independent Machine Learning Models. The UAV communicates and sends results based on the accuracy of these models.","2021 11th International Conference on Cloud Computing, Data Science & Engineering (Confluence)",2021,10.1109/confluence51648.2021.9377082,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f6443d9c86cbe51d22034c68f00ed1ccdd32f78c,https://www.semanticscholar.org/paper/f6443d9c86cbe51d22034c68f00ed1ccdd32f78c,Linking Preoperative and Intraoperative Data for Risk Prediction: More Answers or Just More Data?,"the results of their cohort study involving 111888 surgeries at a large academic medical center. The research team deployed machine learning(ML)modelstopredicttheriskofpostoperativecomplicationsrelatedtopneumonia,acute kidney injury, deep vein thrombosis, delirium, and pulmonary embolism. Studies indicate that more than 10% of surgical patients may experience a major postoperative complication (eg, heart attack, infection, and blood clots), with the incidence of postoperative complications varying by type of surgery. The use of ML approaches that take advantage of the rich storehouses of electronic health record (EHR) data and support perioperative clinical decision-making have been talked about for years; however, real-life examples are still few. Therefore, we applaud this group of investigators for pursuing this important and timely topic.",JAMA network open,2021,10.1001/jamanetworkopen.2021.2547,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7c0e2018e7fab673aff37e94a1e1960a51b22e06,https://www.semanticscholar.org/paper/7c0e2018e7fab673aff37e94a1e1960a51b22e06,A Survey of Fog Computing-Based Healthcare Big Data Analytics and Its Security,"Growing use of wearables within internet of things (IoT) creates ever-increasing multi-modal data from various smart health applications. The enormous volume of data generation creates new challenges in transmission, storage, and processing. There were challenges such as communication latency and data security associated with processing medical big data in cloud backend. Fog computing (FC) is an emerging distributed computing paradigm that solved these problems by leveraging local data processing, storage, filtering, and machine intelligence within an intermediate fog layer that resides between cloud and wearables devices. This paper focuses on doing survey on two major aspects of deploying fog computing for smart and connected health. Firstly, the role of machine learning-based edge intelligence in fog layer for data processing is investigated. A comprehensive analysis is provided during the survey, highlighting the strength and improvements in the existing literature. The paper ends with some open challenges and future research areas in the domain of fog-based healthcare.",Int. J. Ambient Comput. Intell.,2021,10.4018/IJACI.2021040104,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f2acbebf7a83ebdb1c08ab6dee4ea34833462682,https://www.semanticscholar.org/paper/f2acbebf7a83ebdb1c08ab6dee4ea34833462682,"Fear in a Handful of Dust: The Epidemiological, Environmental, and Economic Drivers of Death by PM2.5 Pollution","This study evaluates numerous epidemiological, environmental, and economic factors affecting morbidity and mortality from PM2.5 exposure in the 27 member states of the European Union. This form of air pollution inflicts considerable social and economic damage in addition to loss of life and well-being. This study creates and deploys a comprehensive data pipeline. The first step consists of conventional linear models and supervised machine learning alternatives. Those regression methods do more than predict health outcomes in the EU-27 and relate those predictions to independent variables. Linear regression and its machine learning equivalents also inform unsupervised machine learning methods such as clustering and manifold learning. Lower-dimension manifolds of this dataset’s feature space reveal the relationship among EU-27 countries and their success (or failure) in managing PM2.5 morbidity and mortality. Principal component analysis informs further interpretation of variables along economic and health-based lines. A nonlinear environmental Kuznets curve may describe the fuller relationship between economic activity and premature death from PM2.5 exposure. The European Union should bridge the historical, cultural, and economic gaps that impair these countries’ collective response to PM2.5 pollution.",International journal of environmental research and public health,2021,10.3390/ijerph18168688,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fcc5654c50cdd8a1a310552215a648b96b7a00c4,https://www.semanticscholar.org/paper/fcc5654c50cdd8a1a310552215a648b96b7a00c4,BEDS-Bench: Behavior of EHR-models under Distributional Shift-A Benchmark,"Machine learning (ML) has recently demonstrated impressive progress in predictive accuracy across a wide array of tasks. Most ML approaches focus on generalization performance on unseen data that are “similar” to the training data (a.k.a. In-Distribution, or IND). However, real world applications and deployments of ML rarely enjoy the comfort of encountering examples that are always IND. In such situations, most ML models commonly display erratic behavior on Out-of-Distribution (OOD) examples, such as assigning high confidence to wrong predictions, or vice-versa. Implications of such unusual model behavior are further exacerbated in the healthcare setting, where patient health can potentially be put at risk. It is crucial to study the behavior and robustness properties of models under distributional shift, understand common failure modes, and take mitigation steps before the model is deployed. Having a benchmark that shines light upon these aspects of a model is a first and necessary step in addressing the issue. Recent work and interest in increasing model robustness in OOD settings have focused more on image modality, both in terms of methods as well as benchmarks, while the Electronic Health Record (EHR) modality is still largely under-explored. We aim to bridge this gap by releasing BEDS-Bench, a benchmark for quantifying the behavior of ML models over EHR data under OOD settings. We use two open access, de-identified EHR datasets to construct several OOD data settings to run tests on. The benchmark exercises several clinical prediction tasks, OOD data settings, and measures relevant metrics that characterize crucial aspects of a model’s OOD behavior. We evaluate several learning algorithms under BEDS-Bench and find that all of them show poor generalization performance under distributional shift in general. Our results highlight the need and the potential to improve robustness of EHR models under distributional shift, and BEDS-Bench provides one way to measure progress towards that goal. Code to reproduce the results in this paper and evaluate new algorithms against BEDS-Bench is made available at https://github.com/Google-Health/records-research/tree/master/beds-bench. ar X iv :2 10 7. 08 18 9v 1 [ cs .L G ] 1 7 Ju l 2 02 1",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0e96edb6ed08803cc21bf5612fb01a8eca94c67b,https://www.semanticscholar.org/paper/0e96edb6ed08803cc21bf5612fb01a8eca94c67b,Out-of-Distribution Detection for Medical Applications: Guidelines for Practical Evaluation,"Detection of Out-of-Distribution (OOD) samples in real time is a crucial safety check for deployment of machine learning models in the medical ﬁeld. Despite a growing number of uncertainty quantiﬁcation techniques, there is a lack of evaluation guidelines on how to select OOD detection methods in practice. This gap impedes implementation of OOD detection methods for real-world applications. Here, we propose a series of practical considerations and tests to choose the best OOD detector for a speciﬁc medical dataset. These guidelines are illustrated on a real-life use case of Electronic Health Records (EHR). Our results can serve as a guide for implementation of OOD detection methods in clinical practice, mitigating risks associated with the use of machine learning models in healthcare.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8cec495524c4619131abca4f95f70dbf7448f906,https://www.semanticscholar.org/paper/8cec495524c4619131abca4f95f70dbf7448f906,Unmanned aircraft system advances health mapping of fragile polar vegetation,"Plants like mosses can be sensitive stress markers of subtle shifts in Arctic and Antarctic environmental conditions, including climate change. Traditional ground‐based monitoring of fragile polar vegetation is, however, invasive, labour intensive and physically demanding. High‐resolution multispectral satellite observations are an alternative, but even their recent highest achievable spatial resolution is still inadequate, resulting in a significant underestimation of plant health due to spectral mixing and associated reflectance impurities. To resolve these obstacles, we have developed a new method that uses low‐altitude unmanned aircraft system (UAS) hyperspectral images of sub‐decimeter spatial resolution. Machine‐learning support vector regressions (SVR) were employed to infer Antarctic moss vigour from quantitative remote sensing maps of plant canopy chlorophyll content and leaf density. The same maps were derived for comparison purposes from the WorldView‐2 high spatial resolution (2.2 m) multispectral satellite data. We found SVR algorithms to be highly efficient in estimating plant health indicators with acceptable root mean square errors (RMSE). The systematic RMSEs for chlorophyll content and leaf density were 3.5–6.0 and 1.3–2.0 times smaller, respectively, than the unsystematic errors. However, application of correctly trained SVR machines on space‐borne multispectral images considerably underestimated moss chlorophyll content, while stress indicators retrieved from UAS data were found to be comparable with independent field measurements, providing statistically significant regression coefficients of determination (median r2 = .50, pt test = .0072). This study demonstrates the superior performance of a cost‐efficient UAS mapping platform, which can be deployed even under the continuous cloud cover that often obscures optical high‐altitude airborne and satellite observations. Antarctic moss vigour maps of appropriate resolution could provide timely and spatially explicit warnings of environmental stress events, including those triggered by climate change. Since our polar vegetation health assessment method is based on physical principles of quantitative spectroscopy, it could be adapted to other short‐stature and fragmented plant communities (e.g. tundra grasslands), including alpine and desert regions. It therefore shows potential to become an operational component of any ecological monitoring sensor network.",,2017,10.1111/2041-210X.12833,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aafdd1a684235fbce45add109f4271110bfadde0,https://www.semanticscholar.org/paper/aafdd1a684235fbce45add109f4271110bfadde0,"The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment","Abstract Objective Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers. Materials and Methods The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics. Results Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access. Conclusions The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-term impacts of COVID-19.",J. Am. Medical Informatics Assoc.,2020,10.1093/jamia/ocaa196,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0d2434a3085b431015b0e5357f39b96db064b012,https://www.semanticscholar.org/paper/0d2434a3085b431015b0e5357f39b96db064b012,Talking to Machines About Personal Mental Health Problems.,"Gabby is a “racially ambiguous female in her midforties.”1 A software program designed to help patients with chronic pain and depression, Gabby has many “siblings” that already converse directly with millions of patients in the United States and globally about their mental health. Advances in machine learning, digital assistants, and natural language processing support such personal health conversations between machines and patients. Conversational artificial intelligence is the term used to describe this new capability. Gabby is a conversational agent, a software program that uses conversational artificial intelligence to interact with users through voice or text. Conversational agents are different from other software programs because they converse directly with people, and some data suggest that people respond to them psychologically as though they are human.2 Clinicians have contemplated the use of conversational agents in mental health care for decades, especially to improve access for underserved populations. Optimism is growing that conversational agents can now be deployed in mental health to automate some aspects of clinical assessment and treatment. For example, the conversational agent Ellie interviews people about mental health–related symptoms. In a",JAMA,2017,10.1001/jama.2017.14151,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bdfa251d7874fe050fb8634d4c74f2a26d986075,https://www.semanticscholar.org/paper/bdfa251d7874fe050fb8634d4c74f2a26d986075,Trends in Mobile Cyber-Physical Systems for health Just-in time interventions,"Advances in pervasive computing, machine learning, and human activity recognition are changing preventive health care. Emerging paradigms, such as Mobile Cyber-Physical System (MCPS) and Just-in-time interventions (JITI), allow patients to take health monitoring, diagnosis, therapy and treatments beyond traditional medical settings. These paradigms empower patients by delivering health care at any place and at any time. MCPS provides the necessary engineering support to enable JITI systems to work in an autonomous way. In this work, we review the recent trends in the design of Mobile Cyber-Physical systems for Just-in-time interventions (MCP-JITI), and the different engineering concepts behind this paradigm. Finally, we discuss a set of necessary requirements or design issues to successfully deploy in real world scenarios. This discussion is driven by the description of the MCP-JITI architecture and the interconnections among its components.",SoutheastCon 2015,2015,10.1109/SECON.2015.7132887,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
eb6f50e8a4dc7dafff1fb0dfa4046a46f0c1c3da,https://www.semanticscholar.org/paper/eb6f50e8a4dc7dafff1fb0dfa4046a46f0c1c3da,Variational Adversarial Deep Domain Adaptation for Health Care Time Series Analysis,"Data-driven machine learning, in particular deep learning, is improving state-ofthe-art in many healthcare prediction tasks. A current standard protocol is to collect patient data to build, evaluate, and deploy machine learning algorithms for specific age groups (say source domain), which, if not properly trained, can perform poorly on data from other age groups (target domains). In this paper, we address the question of whether it is possible to adapt machine learning models built for one age group to also perform well on other age groups. Additionally, healthcare time series data is also challenging in that it is usually longitudinal and episodic with the potential of having complex temporal relationships. We address these problems with our proposed adversarially trained Variational Adversarial Deep Domain Adaptation (VADDA) model built atop a variational recurrent neural network, which has been shown to be capable of capturing complex temporal latent relationships. We assume and empirically justify that patient data from different age groups can be treated as being similar but different enough to be classified as coming from different domains, requiring the use of domain-adaptive approaches. Through experiments on the MIMIC-III dataset we demonstrate that our model outperforms current state-of-the-art domain adaptation approaches, being (as far as we know) the first to accomplish this for healthcare time-series data.",,2016,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1c98f28dd7dca3a6dc7134be0396bca2a11392a6,https://www.semanticscholar.org/paper/1c98f28dd7dca3a6dc7134be0396bca2a11392a6,AR-IoMT Mental Health Rehabilitation Applications for Smart Cities,"Augmented Reality (AR) applications provide major opportunities for healthcare. Mental health rehabilitation in particular is an area that stands to gain from innovations in this field. Debilitating medical conditions related to traumatic brain injuries, aging, and drug abuse, can take advantage from the benefits that these applications provide. Coupled with IoMT (Internet of Medical Things) sensors and machine learning, effective system implementations that predict mental rehabilitation outcomes can be built. This can help in administering better treatment protocols. The collective use of these technologies for therapeutic approaches to alter patient behaviour at a physiological level falls in the emerging field of Digital Therapeutics (DT). In this paper, the current state of AR for mental health rehabilitation is described and used to motivate the implementation of a proof of concept mental DT rehabilitation system developed by us. Similar AR-IoMT systems can reduce inpatient counts in smart cities where an increase in aging populations is already a concern, and existing healthcare resources may be clogged up due to minor inpatient health checkups. In addition, the paper discusses the deployment challenges of the implemented system, which include the lack and need thereof of a standardized protocol for IoMT data collection and analysis for cross interoperability across different healthcare providers and vendors.",2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT and AI (HONET-ICT),2019,10.1109/HONET.2019.8907997,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
963a3dfc737702567f1f7892260305adc51a7731,https://www.semanticscholar.org/paper/963a3dfc737702567f1f7892260305adc51a7731,Symptomatic Assistance,"The project aims to help the users get the idea if he/she may be suffering from heart disease or not. Web development is the work involved in developing a Website for the web (world wide web) or an intranet (a private network).Web development can range from Developing an easy single static page of plain text to complex web applications, electronic business and social networking services. The main goal of this website (SYMPTOMATIC ASSISTANCE) is to predict the possibility of having Heart disease. For this , the user needs to provide some information regarding their health. Such as blood pressure, glucose, cigarettes per day etc. According to which the website will respond. This will make people aware and help them improve their health. Machine learning is a method of data analysis that automates analytical model building. It is a branch of AI supported the thought that systems can learn from data, identify patterns and make decisions with minimal human intervention. For this we chose the best dataset from kaggle and used it in the best possible way to predict the output with high accuracy. For being able to predict the correct output, we applied a few machine learning models and chose the best fitted algorithm according to accuracy. For connecting machine Learning models with the webpages we used Flask. Flask is a micro framework written in Python. It is classified as a microframework because it doesn't require particular tools or libraries. It has no database abstraction layer, form validation, or any other components where pre-existing third-party libraries provide common functions. However, Flask supports extensions which will add application features as if they were implemented in Flask itself. Extensions exist for object-relational mappers, form validation, upload handling, various open authentication technologies and several common framework related tools.At the end will deploy our project using Heroku. Heroku is a cloud Platform as a service (PaaS) supporting several programming languages. One of the first cloud platforms, This project will make it easy for the user to know their health closely.",International Journal for Research in Applied Science and Engineering Technology,2021,10.22214/ijraset.2021.37132,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cd51bbfd51cde0c089d9dfb7d30bfc124d9b7c55,https://www.semanticscholar.org/paper/cd51bbfd51cde0c089d9dfb7d30bfc124d9b7c55,"Summary for CIFE Seed Proposals for Academic Year 2020-21 Proposal number: 2020-04 Proposal title: Hybrid Physical-Digital Spaces: Transforming the Design, Operation, and Experience of Built Environments to Promote Health and Wellbeing","up to 150 words) Increasing evidence suggests built office features (e.g., lighting, materials, and ventilation) have substantial impacts on occupant wellbeing. A key next direction is field studies at industry partner sites to examine real-world workplaces. We propose to develop innovative Internet of Things (IoT) techniques that integrate data from building instrumentation, personal device sensors, and self-report interfaces and then deploy this platform in-the-wild to capture rich, longitudinal, ecologically-valid data about the status of office workers and the spaces they occupy. Insights will advance scientific knowledge of how buildings impact wellbeing as well as produce practical implications for building designers and operators. A timely component will explore how covid-19 has temporally or fundamentally changed occupant behaviors and operational decisions (e.g., physical distancing desks and ventilation settings that reduce pathogen spread). Overall, our proposed research has the potential to transform the industry’s thinking on how built environments can be designed, operated, and experienced. Hybrid Physical-Digital Spaces: Transforming the Design, Operation, and Experience of Built Environments to Promote Health and Wellbeing Problem and Significance Considering that people in the U.S. spend 87% of their time in indoor spaces , we assert that 1 buildings are powerful yet underleveraged loci for promoting human wellbeing. Imagine an intelligent office that could adapt soundscape systems to manage noise in open floor plans, optimize space reservation or utilization to foster collaborations and save energy, or provide digital information displays that promote employee connectedness and physical activity. Towards actualizing our vision of such hybrid physical-digital spaces, our proposal strives to develop, apply, and evaluate novel scientific and engineering approaches that will transform the industry’s thinking around how built environments can be designed, operated, and experienced. Increasingly, hypotheses suggest that built features of indoor environments (e.g., lighting, materials, and ventilation) have substantial impacts on occupants (e.g., employee recruitment and retention, absenteeism, cognition, creativity, productivity, social interactions, physical activity and health, and psychological wellbeing). In turn, these individual outcomes also drive pivotal organizational outcomes such as product innovation, workforce diversity, employee turnover, market share, and profitability. Examples illustrate how building interventions can have huge impacts : enhancing employee exposure to daylight can save businesses ~$2,000/yr per capita 2 , better air quality can raise cognitive scores of workers by 101% 3 , and increasing indoor access to biophilic elements could recoup $23 billion considering 10% of workplace absenteeism (a $226 billion dollar problem) is attributable to architecture that inadequately connects to nature 4 . However, few of these hypotheses have been tested at scale, over time, and in real world conditions . Instead, most prior efforts are small sample, short-term correlational studies based on potentially biased and sparse self-reported data. A more rigorous, scientific, and human-centered approach to study and engineer buildings that promote wellbeing can have major implications at individual, organizational, and societal levels (see Figure 1), offering both foundational theoretical knowledge as well as practical strategies for building designers and operators. Figure 1. Relations among building features and human outcomes at various levels. Further, “smart buildings” today typically focus on basic sensing and control for energy savings, thermal comfort, and security. Connecting to CIFE’s Vision for the Future of Building Users, we argue buildings of the future can go beyond such bottom line outcomes to be more interactive and human-centered: aware of and responsive to occupants’ cognitive, mental, and physical feelings and needs, while respecting privacy and promoting positive indoor experiences . 1 Klepeis, et al., 2001; 2 Heschong & Mahone, 2003; 3 Allen et al., 2016; 4 Elzeyadi, 2011. <Landay-Billington> < Hybrid Physical-Digital Spaces> 1 Theoretical and Practical Points of Departure It is imperative to increase understanding of exactly what built attributes have what impacts and on whom, in a scalable, longitudinal, and inclusive manner. Thus through technology-driven assessment and hybrid physical-digital interventions, we aim to (a) fundamentally advance the science on how built environments impact human wellbeing and, in turn, (b) generate guidelines that can revolutionize the way spaces are designed, operated, and experienced . Our current scope focuses on office spaces and workers; though an overarching goal is for our developed approaches and insights to establish a foundation that enables future research with additional populations and environments (e.g., physicians and patients in clinical settings, students and teachers in classrooms, and traditionally marginalized shift and temporary workers). In particular, our reusable platform will help others study this wider range of buildings and occupants; and combining these approaches with emerging endeavors such as biophilic design and precision interventions provides a novel opportunity to not only more deeply investigate but also address long-running public health challenges and systemic inequities facing society. In these ways, we hope to positively impact a broad cross-section of stakeholders at individual, organizational, and institutional levels. Moreover, this project will support interdisciplinary fertilization across engineering, computing, psychology, law, and medicine . Research Methods and Work Plan Our research agenda is to support the design and operation of built facilities that augment human capabilities and wellbeing — and have a fundamental positive change on the way indoor spaces are experienced by the people that occupy them. By introducing intelligent systems capable of gathering and interpreting building and occupant data as well as delivering adaptive interventions in response, novel roles will also emerge for managing buildings and the activities that take place inside them. To achieve these goals, our research will comprise three main activities: 1. Developing an extensible and secure data collection and machine learning platform . A key aim of this research is scientifically examining how built spaces impact human wellbeing. To pursue this investigation and develop methods that enable buildings to be more aware of occupants’ states and needs, we have been developing pattern detection software that integrates data from (a) personal devices (smartphones, smartwatches, fitness trackers), (b) building instrumentation or portable environmental sensors (light levels, air quality), and (c) experience sampling interfaces that prompt occupants for subjective information through quick, validated self-report techniques. Figure 2 illustrates examples of these assessment components. This work involves addressing a number of technical challenges, such as selecting sampling rates and window sizes to maximize efficiency, developing methods for analyzing asynchronous and sparse sensor data, and developing privacy-sensitive feature engineering strategies for detecting and predicting wellbeing outcomes of interest. We also plan to package our platform as a reusable toolkit that can be applied by other researchers and building operators. This work is ongoing and a basic version will be ready by summer. Once development is complete, CIFE support would allow us to move onto the next critical phase: moving out of the lab and into the field. <Landay-Billington> < Hybrid Physical-Digital Spaces> 2 Figure 2. Platform to integrate data from personal devices, building sensors, and subjective self-report. 2. Deploying the platform through a mixed-method study with industry partners . The next step in our research is to deploy this platform at field sites in partnership with View, Inc. (specifically, at TIAA offices in Manhattan, this summer/fall) to capture rich, longitudinal, ecologically-valid data about behavioral, psychological, and physiological states of occupants and their everyday work environments. Our plan is to recruit a sample of approximately 150 employees for a period of 18 weeks, which will involve a baseline phase followed by systematic variation of built features (Views/No Views, Plants/No Plants, and Diversity/No Diversity in artwork) and measurement of indicators hypothesized to promote both personal wellbeing and organizational performance, based on the literature and our formative online and lab studies, described below. In combination with the engineering-focused activities to implement and install the platform, deployment will occur in tandem with ethnographic work (e.g., observations, interviews, and surveys) to manually validate reliability of the system’s automated inferences as well as gain a more qualitative portrait of occupant experiences in various spaces. Privacy-centric engagements will additionally investigate stakeholders’ attitudes regarding the capture of various types of information to derive implications about informed consent and personal data management. Along similar lines, it will be critical to responsibly manage captured data, especially potentially sensitive and exploitable data about wellness or performance. Therefore all studies will be conducted with oversight and approval from the Stanford Institutional Review Board (IRB). In addition to obtaining participants’ informed consent, we will also design sensor and data collection mechanisms to use an opt-in model, including partial participation. Our data management systems can also allow individuals to view and delete their personal data, including if purging is desired in the event of study withdrawal. Our research team has exp",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
52e58d565ff9ee50d6f1ace3415954b2b6713a68,https://www.semanticscholar.org/paper/52e58d565ff9ee50d6f1ace3415954b2b6713a68,The Plant Pathology Challenge 2020 data set to classify foliar disease of apples,"Premise Apple orchards in the United States are under constant threat from a large number of pathogens and insects. Appropriate and timely deployment of disease management depends on early disease detection. Incorrect and delayed diagnosis can result in either excessive or inadequate use of chemicals, with increased production costs and increased environmental and health impacts. Methods and Results We have manually captured 3651 high‐quality, real‐life symptom images of multiple apple foliar diseases, with variable illumination, angles, surfaces, and noise. A subset of images, expert‐annotated to create a pilot data set for apple scab, cedar apple rust, and healthy leaves, was made available to the Kaggle community for the Plant Pathology Challenge as part of the Fine‐Grained Visual Categorization (FGVC) workshop at the 2020 Computer Vision and Pattern Recognition conference (CVPR 2020). Participants were asked to use the image data set to train a machine learning model to classify disease categories and develop an algorithm for disease severity quantification. The top three area under the ROC curve (AUC) values submitted to the private leaderboard were 0.98445, 0.98182, and 0.98089. We also trained an off‐the‐shelf convolutional neural network on this data for disease classification and achieved 97% accuracy on a held‐out test set. Discussion This data set will contribute toward development and deployment of machine learning–based automated plant disease classification algorithms to ultimately realize fast and accurate disease detection. We will continue to add images to the pilot data set for a larger, more comprehensive expert‐annotated data set for future Kaggle competitions and to explore more advanced methods for disease classification and quantification.",Applications in plant sciences,2020,10.1002/aps3.11390,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e3a492d26049abe9b6615259cc8817d7b8209a98,https://www.semanticscholar.org/paper/e3a492d26049abe9b6615259cc8817d7b8209a98,Tunnel disturbance events monitoring and recognition with distributed acoustic sensing (DAS),"Accurately identifying disturbance events along tunnels is essential for their safe operation, which constitutes an important part of tunnel health monitoring and abnormity warning. In recent years, distributed acoustic sensing (DAS), a state-of-the-art fiber-optic sensing technology, has developed rapidly in the field of earth science and engineering. Based on the principle of phase-sensitive optical time-domain reflectometry, DAS allows detecting acoustic/vibration signals along a common fiber-optic cable up to tens of kilometers. This brings new opportunities for monitoring of long perimeters such as underground tunnels. In this paper, we propose a DAS-based method for the recognition of disturbance events along tunnels. The EMD denoising algorithm is employed to optimize vibration signals to better extract the time–frequency domain features of monitored events. Different events are then recognized via a machine learning-based multi-class classification approach. The Random Forest algorithm is applied to analyze the DAS data acquired with fiber-optic cables deployed along the tunnel lining, successfully recognizing a variety of vibration events during the construction of the tunnel including unexpected disasters such as rockfalls, with a recognition accuracy of 92.31%. This DAS-based disturbance identification method may provide a new opportunity for unmanned, real-time monitoring of tunnel abnormal events.",IOP Conference Series: Earth and Environmental Science,2021,10.1088/1755-1315/861/4/042034,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
18aed41b20c8f3ed2eb1208f5e81cc0a54f9d5f6,https://www.semanticscholar.org/paper/18aed41b20c8f3ed2eb1208f5e81cc0a54f9d5f6,A Dataset Centric Feature Selection and Stacked Model to Detect Breast Cancer,"World Health Organisation declared breast cancer (BC) as the most frequent suffering among women and accounted for 15 percent of all cancer deaths. Its accurate prediction is of utmost significance as it not only prevents deaths but also stops mistreatments. The conventional way of diagnosis includes the estimation of the tumor size as a sign of plausible cancer. Machine learning (ML) techniques have shown the effectiveness of predicting disease. However, the ML methods have been method centric rather than being dataset centric. In this paper, the authors introduce a dataset centric approach(DCA) deploying a genetic algorithm (GA) method to identify the features and a learning ensemble classifier algorithm to predict using the right features. Adaboost is such an approach that trains the model assigning weights to individual records rather than experimenting on the splitting of datasets alone and perform hyper-parameter optimization. The authors simulate the results by varying base classifiers i.e, using logistic regression (LR), decision tree (DT), support vector machine (SVM), naive bayes (NB), random forest (RF), and 10-fold crossvalidations with a different split of the dataset as training and testing. The proposed DCA model with RF and 10-fold cross-validations demonstrated its potential with almost 100% performance in the classification results that no research could suggest so far. The DCA satisfies the underlying principles of data mining: the principle of parsimony, the principle of inclusion, the principle of discrimination, and the principle of optimality. This DCA is a democratic and unbiased ensemble approach as it allows all features and methods in the start to compete, but filters out the most reliable chain (of steps and combinations) that give the highest accuracy. With fewer characteristics and splits of 50-50, 66-34, and 10 fold cross-validations, the Stacked model achieves 97 % accuracy. These values and the reduction of features improve upon prior research works. Further, the proposed classifier is compared with some state-of-the-art machine-learning classifiers, namely random forest, naive Bayes, support-vector machine with radial basis function kernel, and decision tree. For testing the classifiers, different performance metrics have been employed – accuracy, detection rate, sensitivity, specificity, receiver operating characteristic, area under the curve, and some statistical tests such as the Wilcoxon signed-rank test and kappa statistics – to check the strength of the proposed DCA classifier. Various splits of training and testing data –namely, 50–50%, 66–34%, 80–20% and 10-fold cross-validation – have been incorporated in this research to test the credibility of the classification models in handling the unbalanced data. Finally, the proposed DCA model demonstrated its potential with almost 100% performance in the classification results. The output results have also been compared with other research on the same dataset where the proposed classifiers were found to be best across all the performance dimensions.",International Journal of Intelligent Systems and Applications,2021,10.5815/ijisa.2021.04.03,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b058cdd4e0b861af51a79a76b71ba53f46e1e88f,https://www.semanticscholar.org/paper/b058cdd4e0b861af51a79a76b71ba53f46e1e88f,PREDICTION OF COVID-19 FATALITY CASES BASED ON REGRESSION TECHNIQUES,"The COVID-19 was first reported to affect human life in Wuhan city, within the Hubei province of China in December 2019. An analysis of around 75,465 cases of COVID19 in China has revealed that the virus is transmitted between people from the blowout of respiratory droplets through sneezing and coughing. Corona is the world's most viral threat warning to people's health and the best pandemic in the world record. This paper presents a comparative study of regression techniques for the prediction of fatality cases due to Coronavirus. The objective of this paper is to predict the fatality cases of the top five affected countries which severely fight against COVID19. Time series forecasting analysis based on machine learning models like Linear Support Vector Regression (LSVR), Random Forest Regression, and Decision Tree Regressions are deployed to predict the fatality cases in the upcoming days. A comparative analysis is also carried out to identify which model best predicts the fatality cases. Covid-19 Data is considered from January 23, 2020, to October 30, 2020.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
63059185265afb0f7d0e677d936bce6eb30c0e50,https://www.semanticscholar.org/paper/63059185265afb0f7d0e677d936bce6eb30c0e50,InTrust-IoT: Intelligent Ecosystem based on Power Profiling of Trusted device(s) in IoT for Hardware Trojan Detection,"Modern Resource-Constrained (RC) Internet of Things (IoT) devices are subject to several types of attacks, including hardware-level attacks. Most of the existing state-of-the-art solutions are invasive, require expensive design time interventions, or need dataset generation from non-trusted RC-IoT devices or both. We argue that the health of modern RC-IoT devices requires a final line of defense against possible hardware attacks that go undetected during the IC design and test process. Hence, in this paper, we propose a defense methodology against non-zero-day and zero-day attacks, leveraging machine learning techniques trained on the dataset obtained without design time intervention and using ‘only’ trusted IoT devices. In the process, a complete eco-system is developed where data is generated through a trusted group of devices, and machine learning is done on these trusted datasets. Next, this trusted trained model is deployed in regular IoT systems that contain untrusted devices, where the attack on untrusted devices can be detected in real-time. Our results indicate that for non-zero-day attacks, the proposed technique can concurrently detect DoS and power depletion attacks with an accuracy of about 80%. Similarly, zero-day attack experiments are able to detect the attack without fail as well.",HASP@MICRO,2021,10.1145/3505253.3505262,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
20584705081dff9ab56cac856cb8e082565564d6,https://www.semanticscholar.org/paper/20584705081dff9ab56cac856cb8e082565564d6,Ensemble approach for identifying medical concepts with special attention to lexical scope,,Sādhanā,2021,10.1007/S12046-021-01593-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d11c7341d3bcc4b0c73076048dcd10b35748f355,https://www.semanticscholar.org/paper/d11c7341d3bcc4b0c73076048dcd10b35748f355,Satellite Fields Digitalization & ALS Optimization with EDGE & Advance Analytics Application,"
 Data monitoring in remote satellite field without any DOF platform is a challenging task but critical for ALS monitoring and optimization. In SRP wells the VFD data collection is important for analysis of downhole pump behavior and system health. SRP maintenance crew collects data from VFDs daily, but it is time consuming and can target only few wells in a day. The steps from requirement of dyna to final decision taken for ALS optimization are mobilizing team, permits approvals, download data, e-mail dynacards, dyna visualization, final decision.
 The problems with above process were: -
 Insufficient and discrete data for any post-failure analysis or ALS-optimization Minimal data to investigate the pre failure events
 The lack of real time monitoring was resulting in well downtime and associated production loss. The combination of IOT, Cloud Computing and Machine learning was implemented to shift from the reactive to proactive approach which helped in ALS Optimization and reduced production loss.
 The data was transmitted to a Cloud server and further it was transmitted to web-based app. Since thousands of Dynacards are generated in a day, hence it requires automated classification using computer driven pattern recognition techniques. The real time data is used for analysis involving basic statistic and Machine learning algorithms. The critical pump signatures were identified using machine learning libraries and email is generated for immediate action. Several informative dashboards were developed which provide quick analysis of ALS performance. The types of dashboard are as below
 Well Operational Status Dynacards Interpretation module SRP parameters visualization Machine Learning model calibration module Pump Performance Statistics
 After collection of enough data and creation of analytical dashboards on the three wells using domain knowledge the gained insights were used for ALS optimization. To keep the model in an evergreen high-confidence prediction state, inputs from domain experts are often required. After regular fine-tuning the prediction accuracy of the ML model increased to 80-85 %. In addition, system was made flexible so that a new algorithm can be deployed when required. Smart Alarms were generated involving statistic and Machine Learning by the system which gives alerts by e-mail if an abnormal behavior or erratic dynacards were identified. This helped in reduction of well downtime in some events which were treated instinctively before.
 The integration of domain knowledge and digitalization enables an engineer to take informed and effective decisions. The techniques discussed above can be implemented in marginal fields where DOF implementation is logistically and economically challenged. EDGE along with advanced analytics will gain more technological advances and can be used in other potential domains as well in near future.","Day 4 Wed, December 01, 2021",2021,10.2118/204794-ms,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ec3e0a08f6d4e0ac1ee0b3bd6f88ca2e8aa9daa3,https://www.semanticscholar.org/paper/ec3e0a08f6d4e0ac1ee0b3bd6f88ca2e8aa9daa3,Predicting inpatient pharmacy order interventions using provider action data,"Abstract Objective The widespread deployment of electronic health records (EHRs) has introduced new sources of error and inefficiencies to the process of ordering medications in the hospital setting. Existing work identifies orders that require pharmacy intervention by comparing them to a patient’s medical records. In this work, we develop a machine learning model for identifying medication orders requiring intervention using only provider behavior and other contextual features that may reflect these new sources of inefficiencies. Materials and Methods Data on providers’ actions in the EHR system and pharmacy orders were collected over a 2-week period in a major metropolitan hospital system. A classification model was then built to identify orders requiring pharmacist intervention. We tune the model to the context in which it would be deployed and evaluate global and local feature importance. Results The resultant model had an area under the receiver-operator characteristic curve of 0.91 and an area under the precision-recall curve of 0.44. Conclusions Providers’ actions can serve as useful predictors in identifying medication orders that require pharmacy intervention. Careful model tuning for the clinical context in which the model is deployed can help to create an effective tool for improving health outcomes without using sensitive patient data.",JAMIA open,2021,10.1093/jamiaopen/ooab083,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d3ec9d3c0fc5b746e05f82e64a397d050e9de733,https://www.semanticscholar.org/paper/d3ec9d3c0fc5b746e05f82e64a397d050e9de733,An Automatic Calibration Technique for Force Sensors in a Dynamic Smart Floor Environment,"Pressure-sensitive smart floors deployed within homes can give great insight to the health and activity level of individuals through gait and location information. Due to the ever-changing dynamic nature of household deployments involving furniture movement, floor tile shifts, and sensor drift, challenges arise in ensuring the constant reliability of floor sensor readings over time. This paper presents a procedure to automatically calibrate a smart floor’s force sensors without specialized physical effort. The calibration algorithm automatically filters out non-human static weight while retaining weight generated by human activity. This technique is designed to correctly translate sensor values to weight units even when direct access to the force sensors is not available and when a shared tile floor sits above the sensor grid. These calibrated sensor values can then feed machine learning techniques used to extract individual contact points generated by a person’s walking cycle. Using known human weights but no knowledge of the human’s location or walking trajectory, this calibration technique resulted in small percentage differences of -7.8%, -4.8%, and -1.6% for the mean, median, and mode of calibrated smart floor walking sequences, respectively.","2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",2021,10.1109/SMC52423.2021.9659228,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1a38b6effe7fb12b1c89591189e8f7d18270b4c3,https://www.semanticscholar.org/paper/1a38b6effe7fb12b1c89591189e8f7d18270b4c3,Convolutional neural network in predicting electrocardiogram,"With the rapid development of machine learning, an increasing number of domains begin to utilize machine learning methods to simplify part of assignments, which can relieve humans' stress. In traditional domains, like medicine, machine learning methods have great potential to play a significant role in detecting diseases. Some machine learning methods have been deployed to analyze electrocardiograms (ECG) because of the impressive accuracy and speediness, which is meaningful and convenient to the medical domain. Detecting disease in ECG accurately is beneficial to prevent and cure some fatal diseases, which may save thousands of lives. In this paper, the machine learning method is used to detect Atrial fibrillation (AF), a severe heart disease damaging people's health. The model used in this paper is Convolutional Neural Network (CNN), a deep learning model. Apart from building a model to detect AF, this paper will also explore and extend the possibility of using CNN in dealing with one-dimensional data. After dealing with a large amount of original ECG data and feed them with labels to the CNN model with some specific parameters adjusted manually, the CNN model with 91.8% accuracy is trained and can be used on some specific occasions to find exceptions of the heart.",Other Conferences,2021,10.1117/12.2626481,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
90ad7e6d2e81cc2c29173e200742bae595e8f895,https://www.semanticscholar.org/paper/90ad7e6d2e81cc2c29173e200742bae595e8f895,Blind Identification of Output-Only Systems and Structural Damage via Sparse Representations,,,2021,10.1007/978-3-642-35344-4_77,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
997c8ef1c79656198495fbd4416705a30f83709d,https://www.semanticscholar.org/paper/997c8ef1c79656198495fbd4416705a30f83709d,"Development of Artificial Intelligence Algorithm for Computer Aided Diagnosis of Brain Tumour (CADbrat) Using Tensor Flow, TFlearn Library and Magnetic Resonance Images","Early diagnosis of a brain tumour is very important. It improves patient’s quality of life and offers diverse options for treatment and reduces the financial burden of tumour treatment. In recent years, computational resources have improved, and they are capable of handling large amount of data which are generated during clinical diagnosis. Furthermore, the recent advances in machine learning have made large data analysis in medicine more tractable and interesting. Automated deep learning-based computer-aided diagnosis (CADx) can be deployed as a crucial and reliable tool used for early detection. In this study, a CADx algorithm with high accuracy and sensitivity has been developed to provide assistance to health care givers in the timely diagnosis of brain tumours. The artificial intelligence algorithm made use of Tensor Flow, TFlearn Library and Magnetic Resonance Images as such model optimization was achieved by cascading the convolutional layers with a down-sampling layer (Max pooling) and higher filter number at the inception convolution layer to extract high level features and provide translational invariance down the network. With this model, an average F1-score of 99.49% was obtained despite training the network on a CPU. This amounts to a slightly improved performance of a similar model which was, however, trained on NVIDIA Tesla K40 server (2880 CUDA cores and 12GB memory). To demonstrate the application of the developed convolutional neural network (CNN) algorithms in clinical scenarios, a graphic user interface (GUI) using Flask application programming interface (API) was developed for easy brain tumour diagnosis with MRI scans.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
867094a6653d4125b664214303d6c455b1118110,https://www.semanticscholar.org/paper/867094a6653d4125b664214303d6c455b1118110,Biodynamic Lighting to Support the Wellbeing of People Living with Dementia in Care Facilities,"Exposure to natural daylight has a positive impact on human health and wellbeing. The non-visual effects of daylight stimulate a response in the circadian system which oversees fundamental mechanisms within the human body, such as metabolism, hormone balance and sleep-wake cycles. For people with dementia, the working capacity and regularity of these processes becomes further compromised as their exposure to daylight is reduced, due largely to age-contributing factors such as increased eye sensitivity and reduced mobility. In light of this, artificial lighting has been revolutionised to enable tailored output based on the photobiological demands of humans. This is known as biodynamic lighting which encompasses varying light intensity and spectral composition. Within dementia cohorts, this design concept has not been well studied, making it difficult to optimally administer and quantify related benefits. Fortunately, by building on the recent progression in the fields of machine learning and the internet of things, the potential for simultaneous behaviour monitoring and actuation of lighting intervention technologies is possible, enabling production of a viable biodynamic lighting solution. To this end, the present study provides a review of related work in the field of biodynamic technology designed to improve wellbeing in dementia, and identifies areas where improvements may be made. Following this, a proposed solution for future study designs and technologies is suggested. The proposed solution exists in the prototype stage, with a route to deploying in care facilities in the near future.","2021 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)",2021,10.1109/SWC50871.2021.00050,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5dce160168e9568da1c713925a2daf9dc601290,https://www.semanticscholar.org/paper/a5dce160168e9568da1c713925a2daf9dc601290,Research Paper on Disorder-based Food Recommendation System,"AbstractThis research paper focuses on a diet-based food recommendation system. Here, we have deployed a system that helps the user get the food that suits his/her health. Since the Covid19 pandemic has hit us, the world has become more aware of immunity, and strong immunity needs good health. This system has used machine learning algorithms and techniques to make recommendations of the required food items. The algorithms that are used in this system are K-means clustering, Random Forest Classification algorithm and rank-based collaborative filtering. This system focuses on giving food recommendations that help the user in maintaining and boosting his/her health. It aims to make dining-out a healthier experience.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c624243c5f088b57fb0f51de875e65d3188aaca7,https://www.semanticscholar.org/paper/c624243c5f088b57fb0f51de875e65d3188aaca7,TransNet,"Wearables are poised to transform health and wellness through automation of cost-effective, objective, and real-time health monitoring. However, machine learning models for these systems are designed based on labeled data collected, and feature representations engineered, in controlled environments. This approach has limited scalability of wearables because (i) collecting and labeling sufficiently large amounts of sensor data is a labor-intensive and expensive process; and (ii) wearables are deployed in highly dynamic environments of the end-users whose context undergoes consistent changes. We introduce TransNet, a deep learning framework that minimizes the costly process of data labeling, feature engineering, and algorithm retraining by constructing a scalable computational approach. TransNet learns general and reusable features in lower layers of the framework and quickly reconfigures the underlying models from a small number of labeled instances in a new domain, such as when the system is adopted by a new user or when a previously unseen event is to be added to event vocabulary of the system. Utilizing TransNet on four activity datasets, TransNet achieves an average accuracy of 88.1% in cross-subject learning scenarios using only one labeled instance for each activity class. This performance improves to an accuracy of 92.7% with five labeled instances.",ACM Transactions on Design Automation of Electronic Systems,2020,10.1145/3414062,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4077cb45094f31e80b0dcd3ebf8ebe488d971b81,https://www.semanticscholar.org/paper/4077cb45094f31e80b0dcd3ebf8ebe488d971b81,Intelligent resource constrained battery management on automotive microcontrollers,"Reliable operation of battery packs and accurate control of their releasable capacity can lead to an increasing number of applications to electric cars, e-bikes, e-scooters, aircrafts etc. Indeed, if the operation of a battery pack is controlled and monitored thoroughly, the safety in the battery system can be better guaranteed. The BMS (Battery Management System) is a key enabler for e-mobility and its function is to control the battery charge/discharge cycles, while also providing battery self-protection functionality, preventing over-voltage, under-voltage and over temperature events. A fundamental parameter for battery health monitoring is the State of Health (SoH), which is computed from the maximum releasable capacity, and which measures how well the battery can perform in terms of energy storage and delivery. To address the challenge to estimate it, in this work several models, based on a supervised machine learning, have been designed, evaluated, and implemented on automotive grade microcontrollers, such as SPC58 MCU. To verify them, comparative experiments have shown very good accuracy, and robustness of the machine learning-based parameter SoH estimator led to an accurate regressor with an average error less than 0.2%. The results are described together with an end-to-end design methodology that uses AI tools specifically developed for automatic ANSI C code generation, validation, and deployment onto the automotive grade microcontrollers.",2021 IEEE 10th Global Conference on Consumer Electronics (GCCE),2021,10.1109/GCCE53005.2021.9621984,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dda5632c99a732b1c3c23be9287021eaf4e1bfba,https://www.semanticscholar.org/paper/dda5632c99a732b1c3c23be9287021eaf4e1bfba,Dangerous Object Detection for Visually Impaired People using Computer Vision,"In this contemporary world, Artificial Intelligence and Machine Learning are one of the leading technologies creating an impact in the world by mimicking human behaviour to solve a particular problem. Hence, these technologies are widely used to aid different obstacles encountered by humans. One such problem widely faced by the mankind is visual impairment. According to World Health Organization, approximately 285 million people suffer with vision impairment. Therefore, applications of machine learning and computer vision can be applied to guide the people with such problems. This paper presents the idea of using object detection to aid the visually impaired people. In this paper, an experiment has been proposed which uses a custom-built image dataset of various dangerous objects. The objects have been categorized into 5 broad categories: Sharp objects, Danger signs, Broken glass, Manhole and Fires. A number of different algorithms have been trained on this custom image dataset containing the menacing objects and their performances have been evaluated. The evaluation indicators for the models are the validation error in terms mean Average Precision (mAP) and the processing time for each model. The models have also been tested in real world scenario by evaluating on a custom video to gauge their performance in terms of accuracy in detection of different objects as well as their ease in deployment by suggesting their frame rate handling capacity. The results are discussed and the most robust and balanced model is suggested at the end of the paper.",2021 International Conference on Artificial Intelligence and Machine Vision (AIMV),2021,10.1109/aimv53313.2021.9670992,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3d21f0c584bf9799c8bace36208a9268cd3dfdd8,https://www.semanticscholar.org/paper/3d21f0c584bf9799c8bace36208a9268cd3dfdd8,Using Redundancy in a Sensor Network to Compensate Sensor Failures,"Wireless sensor networks provide occupational health experts with valuable information about the distribution of air pollutants in an environment. However, especially low-cost sensors may produce faulty measurements or fail completely. Consequently, not only spatial coverage but also redundancy should be a design criterion for the deployment of a sensor network. For a sensor network deployed in a steel factory, we analyze the correlations between sensors and build machine learning forecasting models, to investigate how well the sensor network can compensate for the outage of sensors. While our results show promising prediction quality of the models, they also indicate the presence of spatially very limited events. We, therefore, conclude that initial measurements with, e.g., mobile units, could help to identify important locations to design redundant sensor networks.",2021 IEEE Sensors,2021,10.1109/SENSORS47087.2021.9639479,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
48763418bf66c623aa5f1bfda68467f9c60a4806,https://www.semanticscholar.org/paper/48763418bf66c623aa5f1bfda68467f9c60a4806,Performance landscape of resource-constrained platforms targeting DNNs,"Over the recent years, a significant number of complex, deep neural networks have been developed for a variety of applications including speech and face recognition, computer vision in the areas of health-care, automatic translation, image classification, etc. Moreover, there is an increasing demand in deploying these networks in resource-constrained edge devices. As the computational demands of these models keep increasing, pushing to their limits the targeted devices, the constant development of new hardware systems tailored to those workloads has been observed. Since programmability of these diverse and complex platforms -compounded by the rapid development of new DNN modelsis a major challenge, platform vendors have developed Machine Learning tailored SDKs to maximize the platform’s performance. This work investigates the performance achieved on a number of modern commodity embedded platforms coupled with the vendors’ provided software support when state-of-the-art DNN models from image classification, object detection and image segmentation are targeted. The work quantifies the relative latency gains of the particular embedded platforms and provides insights on the relationship between the required minimum batch size for achieving maximum throughput, concluding that modern embedded systems reach their maximum performance even for modest batch sizes when a modern state of the art DNN model is targeted. Overall, the presented results provide a guide for the expected performance for a number of state-of-the-art DNNs on popular embedded platforms across the image classification, detection and segmentation domains.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e6d1aa2cb74d80db940c7efd032d178a7739dc34,https://www.semanticscholar.org/paper/e6d1aa2cb74d80db940c7efd032d178a7739dc34,Aplikasi Mobile Deteksi Dini Kanker Kulit Berdasarkan Image Processing,"Currently, between 2 and 3 million non-melanoma skin cancers and 132,000 melanoma skin cancers occur globally each year (WHO, 2017). Skin cancer is one type of cancer that can cause death for many people. Because of this, an application is needed to easily detect skin cancer early that the cancer can be handled with more quickly. Besides, consultations with dermatologists have better prognosis (Avilés-Izquierdo et. al., 2016). Due to that, we built an early skin cancer detection application with dermatologist consultation. Our application helps to diagnose skin cancer before it grows into a life-threatening condition and is crucial to preserving lifestyle, future health, and aesthetics. Besides, thanks to online doctor consultations we have, however, getting diagnosed, prescribed and treated for your issues without spending time travelling to and from the doctors and waiting in queues can be just as effective. We used three management techniques such as machine learning to create data pipelines, build a model, and convert the model to TensorFlow lite with post-training quantization. Android to deploy the TensorFlow lite model and create the application. The application has a real-time connection using firebase. Moreover, cloud to create a simple database for doctor and diagnosis services on firebase.",Jurnal Litbang Edusaintech,2021,10.51402/jle.v2i2.44,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6ac73f96e61255cd35f60383f6bcfba208e2d627,https://www.semanticscholar.org/paper/6ac73f96e61255cd35f60383f6bcfba208e2d627,Redesigning Kidney Disease Care to Improve Value Delivery.,"This article describes the articulation, development, and deployment of a machine learning (ML) model-driven value solution for chronic kidney disease (CKD) in a health system. The ML model activated an electronic medical record (EMR) trigger that alerted CKD patients to seek primary care. Simultaneously, primary care physicians (PCPs) received an alert that a CKD patient needed an appointment. Using structured checklists, PCPs addressed and controlled comorbid conditions, reconciled drug dosing and choice to CKD stage, and ordered prespecified laboratory and imaging tests pertinent to CKD. After completion of checklist prescribed tasks, PCPs referred patients to nephrology. CKD patients had multiple comorbidities and ML recognition of CKD provided a facile insight into comorbid burden. Operational results of this program have exceeded expectations and the program is being expanded to the entire health system. This paradigm of ML-driven, checklist-enabled care can be used agnostic of EMR platform to deliver value in CKD through structured engagement of complexity in health systems.",Population health management,2021,10.1089/pop.2021.0112,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2d6e28921dbd171bd26281e139e0ba0718ac18df,https://www.semanticscholar.org/paper/2d6e28921dbd171bd26281e139e0ba0718ac18df,"FOG COMPUTING TECHNOLOGIES FOR PATIENT SENSOR NETWORKS – TRENDS, ISSUES AND FUTURE DIRECTIONS","Advances in sensors and internet of things promise broad opportunities in many areas and one of them is health care. There are many solutions to manage health care data based on cloud computing. However, high response latency, large volumes of data transferred and security are the main issues of such approach. Fog computing provides immediate response and ways to process large amounts of data using real time analytics which includes machine learning and AI. Fog computing has not yet fully matured and there are still many challenges when managing health care data. It was chosen to investigate the most relevant e­health fog computing topics by analyzing review articles to explain the fog computing model and present the current trends – fog computing e­health technology application environments, deployment cases, infrastructure technologies, data processing challenges, problems and future directions. 38 scientific review articles published in the last 5 years were selected for analysis, filtering the most significant works with Web of Science article search tool.",Mokslas - Lietuvos ateitis,2021,10.3846/mla.2021.15174,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fca55de9fe114323c8fbf92087bf271a8b3591d9,https://www.semanticscholar.org/paper/fca55de9fe114323c8fbf92087bf271a8b3591d9,Research on Security and Privacy Problem in the Data Life Cycle for the IoT Scenario,"Sensors have been deployed into different scenarios to collect data, including health data, environmental data, etc. Data have been collected, transmitted, analyzed, etc. Those data are highly related to people's privacy, protecting data privacy becomes necessary. Different methods have been applied to protect data privacy during the life cycle in the Internet of Things scenarios. At the data collecting phase, data aggregation methods are proposed. At the data transmission phase, mutual authentication and key establishment schemes are proposed to help entities to build a secure two-way communication channel, data can be transmitted securely. At the data analyzing phase, privacy-preserving machine learning methods have been discussed, including collaboratively learning and other encrypted machine learning as a service technology, they can protect users' data privacy at the training phase and inference phase respectively. In this study, we mainly discussed these kinds of methods for protecting data security and privacy in the Internet of Things scenario.",2021 2nd Asia Symposium on Signal Processing (ASSP),2021,10.1109/ASSP54407.2021.00021,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
22d8cc0af47ee76af11b46a4216c8a230ca59d7c,https://www.semanticscholar.org/paper/22d8cc0af47ee76af11b46a4216c8a230ca59d7c,GNOSIS- query-driven multimodal event processing for unstructured data streams,"This paper presents GNOSIS, an event processing engine to detect complex event patterns over multimodal data streams. GNOSIS follows a query-driven approach where users can write complex event queries using Multimodal Event Processing Language (MEPL). The system models incoming multimodal data into an evolving Multimodal Event Knowledge Graph (MEKG) using an ensemble of deep neural network (DNN) and machine learning (ML) models and applies a neuro-symbolic approach for event matching. GNOSIS follows a serverless paradigm where its different components act as independent microservices and can be deployed across different nodes with optimized edge support. The paper demonstrates two multimodal use case queries from Occupational Health and Safety and Accessibility domain.",Middleware Demos/Posters,2021,10.1145/3491086.3492475,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
eff83f213e3355e5d8ed0dc50285c3c487dfb2c3,https://www.semanticscholar.org/paper/eff83f213e3355e5d8ed0dc50285c3c487dfb2c3,Automated weed detection system in smart farming for developing sustainable agriculture,,International Journal of Environmental Science and Technology,2021,10.1007/s13762-021-03606-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
16ff80db9197fdb8f38f55d4a4ba999bf6435c1b,https://www.semanticscholar.org/paper/16ff80db9197fdb8f38f55d4a4ba999bf6435c1b,TMJOAI: An Artificial Web-Based Intelligence Tool for Early Diagnosis of the Temporomandibular Joint Osteoarthritis,,CLIP/DCL/LL-COVID19/PPML@MICCAI,2021,10.1007/978-3-030-90874-4_8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1d6553e3c1a6ba36861ba444f7007a5f03723b91,https://www.semanticscholar.org/paper/1d6553e3c1a6ba36861ba444f7007a5f03723b91,Computer-Vision based Face Mask Detection using CNN,"The global pandemic due to the novel corona virus, covid-19 has affected millions of lives across the globe. It has also disturbed economy, environment and social norms leading to many problems and giving birth to different rules and laws in order to ensure public safety. Wearing masks is one of the most important and primitive precautionary measures along with safe social distancing as advised by the World Health Organization. To manually monitor people not wearing face mask in order to ensure public safety is definitely a strenuous task. Therefore, this research work proposes a real time face mask detection system by applying computer vision and machine learning concepts like convolution neural networks and refined MobileNetV2 architecture to ease the deployment of proposed model in embedded devices with limited computational capacity. The dataset utilized here is available on Kaggle as Face mask detection dataset. The model is trained using Adam Optimizer algorithm which is best suited for deep learning models and is built using Keras, TensorFlow and OpenCV. The proposed model touches 99% accuracy under various training to testing ratios like 70% training and 30% testing,50% training and 50% testing etc. Precision, recall, f-score and support are calculated for all trials. This means that the system is computationally effective and could potentially be used in places like railway stations, airports or any other public places to detect people not wearing face mask and ensure safety to certain extent during this pandemic times.",2021 6th International Conference on Communication and Electronics Systems (ICCES),2021,10.1109/ICCES51350.2021.9489098,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5da7852f03716b77db3077a9e9f23eab516ec073,https://www.semanticscholar.org/paper/5da7852f03716b77db3077a9e9f23eab516ec073,Different fundus imaging modalities and technical factors in AI screening for diabetic retinopathy: a review,,Eye and Vision,2020,10.1186/s40662-020-00182-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
35f8869dedb1579761cf2fc3347d42ec24fe1a25,https://www.semanticscholar.org/paper/35f8869dedb1579761cf2fc3347d42ec24fe1a25,"Development, Deployment, and Evaluation of DyMand - An Open-Source Smartwatch and Smartphone System for Capturing Couples' Dyadic Interactions in Chronic Disease Management in Daily Life","Dyadic interactions of couples are of interest as they provide insight into relationship quality and chronic disease management. Currently, ambulatory assessment of couples’ interactions entails collecting data at random or scheduled times which could miss significant couples’ interaction/conversation moments. In this work, we developed, deployed and evaluated DyMand, a novel open-source smartwatch and smartphone system for collecting self-report and sensor data from couples based on partners’ interaction moments. Our smartwatch-based algorithm uses the Bluetooth signal strength between two smartwatches each worn by one partner, and a voice activity detection machine-learning algorithm to infer that the partners are interacting, and then to trigger data collection. We deployed the DyMand system in a 7-day field study and collected data about social support, emotional well-being, and health behavior from 13 (N=26) Swiss-based heterosexual couples managing diabetes mellitus type 2 of one partner. Our system triggered 99.1% of the expected number of sensor and self-report data when the app was running, and 77.6% of algorithm-triggered recordings contained partners’ conversation moments compared to 43.8% for scheduled triggers. The usability evaluation showed that DyMand was easy to use. DyMand can be used by social, clinical, or health psychology researchers to understand the social dynamics of couples in everyday life, and for developing and delivering behavioral interventions for couples who are managing chronic diseases.",ArXiv,2022,10.48550/arXiv.2205.07671,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
04665c9d99ff50ade214780f2fad2d2d7521c32b,https://www.semanticscholar.org/paper/04665c9d99ff50ade214780f2fad2d2d7521c32b,Smart Healthcare System for Severity Prediction and Critical Tasks Management of COVID-19 Patients in IoT-Fog Computing Environments,"COVID-19 has depleted healthcare systems around the world. Extreme conditions must be defined as soon as possible so that services and treatment can be deployed and intensified. Many biomarkers are being investigated in order to track the patient's condition. Unfortunately, this may interfere with the symptoms of other diseases, making it more difficult for a specialist to diagnose or predict the severity level of the case. This research develops a Smart Healthcare System for Severity Prediction and Critical Tasks Management (SHSSP-CTM) for COVID-19 patients. On the one hand, a machine learning (ML) model is projected to predict the severity of COVID-19 disease. On the other hand, a multi-agent system is proposed to prioritize patients according to the seriousness of the COVID-19 condition and then provide complete network management from the edge to the cloud. Clinical data, including Internet of Medical Things (IoMT) sensors and Electronic Health Record (EHR) data of 78 patients from one hospital in the Wasit Governorate, Iraq, were used in this study. Different data sources are fused to generate new feature pattern. Also, data mining techniques such as normalization and feature selection are applied. Two models, specifically logistic regression (LR) and random forest (RF), are used as baseline severity predictive models. A multi-agent algorithm (MAA), consisting of a personal agent (PA) and fog node agent (FNA), is used to control the prioritization process of COVID-19 patients. The highest prediction result is achieved based on data fusion and selected features, where all examined classifiers observe a significant increase in accuracy. Furthermore, compared with state-of-the-art methods, the RF model showed a high and balanced prediction performance with 86% accuracy, 85.7% F-score, 87.2% precision, and 86% recall. In addition, as compared to the cloud, the MAA showed very significant performance where the resource usage was 66% in the proposed model and 34% in the traditional cloud, the delay was 19% in the proposed model and 81% in the cloud, and the consumed energy was 31% in proposed model and 69% in the cloud. The findings of this study will allow for the early detection of three severity cases, lowering mortality rates.",Computational Intelligence and Neuroscience,2022,10.1155/2022/5012962,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1def29b65d295562bcc4e6e21d02a962531a5a8b,https://www.semanticscholar.org/paper/1def29b65d295562bcc4e6e21d02a962531a5a8b,Case-study Led Investigation of Explainable AI (XAI) to Support Deployment of Prognostics in the industry,"Civil nuclear generation plant must maximise it’s operational uptime in order to maintain it’s viability. With aging plant and heavily regulated operating constraints, monitoring is commonplace, but identifying health indicators to pre-empt disruptive faults is challenging owing to the volumes of data involved. Machine learning (ML) models are increasingly deployed in prognostics and health management (PHM) systems in various industrial applications, however, many of these are black box models that provide good performance but little or no insight into how predictions are reached. In nuclear generation, there is significant regulatory oversight and therefore a necessity to explain decisions based on outputs from predictive models. These explanations can then enable stakeholders to trust these outputs, satisfy regulatory bodies and subsequently make more effective operational decisions. How ML model outputs convey explanations to stakeholders is important, so these explanations must be in human (and technical domain related) understandable terms. Consequently, stakeholders can rapidly interpret, then trust predictions better, and will be able to act on them more effectively. The main contributions of this paper are: 1. introduce XAI into the PHM of industrial assets and provide a novel set of algorithms that translate the explanations produced by SHAP to text-based human-interpretable explanations; and 2. consider the context of these explanations as intended for application to prognostics of critical assets in industrial applications. The use of XAI will not only help in understanding how these ML models work, but also describe the most important features contributing to predicted degradation of the nuclear generation asset.",PHM Society European Conference,2022,10.36001/phme.2022.v7i1.3336,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
42099fd64416357c8aa13e048d65b15e33e55a63,https://www.semanticscholar.org/paper/42099fd64416357c8aa13e048d65b15e33e55a63,Trend analysis and forecasting air pollution in Rwanda,Air pollution is a major public health problem worldwide although the lack of data is a global issue for most low and middle income countries. Ambient air pollution in the form of ﬁne particulate matter (PM2.5) exceeds the World Health Organization guidelines in Rwanda with a daily average of around 42 . 6 µ g /m 3 . Monitoring and mitigation strategies require an expensive investment in equipment to collect pollution data. Low-cost sensor technology and machine learning methods have appeared as an alternative solution to get reliable information for decision making. This paper analyzes the trend of air pollution in Rwanda and proposes forecasting models suitable to data collected by a network of low-cost sensors deployed in Rwanda.,ArXiv,2022,10.48550/arXiv.2205.10024,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
45c6f3f13f3a66989d808541c2cdd7b2085b2f05,https://www.semanticscholar.org/paper/45c6f3f13f3a66989d808541c2cdd7b2085b2f05,Sequentially-reduced representation of artificial neural network to determine cardiovascular intrinsic frequencies,"Analysis of cardiovascular waveforms provides valuable clinical information about the state of health and disease. The intrinsic frequency (IF) method is a recently introduced framework that uses a single arterial pressure waveform to extract physiologically relevant information about the cardiovascular system. The clinical usefulness and physiological accuracy of the IF method have been well-established via several preclinical and clinical studies. However, the computational complexity of the current L2 optimization solver for IF calculations remains a bottleneck for practical deployment of the IF method in real-time settings. In this paper, we propose a machine learning (ML)-based methodology for determination of IF parameters from a single carotid waveform. We use a sequentially-reduced Feedforward Neural Network (FNN) model for mapping carotid waveforms to the output parameters of the IF method, thereby avoiding the non-convex L2 minimization problem arising from the conventional IF approach. Our methodology also includes procedures for data pre-processing, model training, and model evaluation. In our model development, we used both clinical and synthetic waveforms. Our clinical database is composed of carotid waveforms from two different sources: the Huntington Medical Research Institutes (HMRI) iPhone Heart Study and the Framingham Heart Study (FHS). In the HMRI and FHS clinical studies, various device platforms such as piezoelectric tonometry, optical tonometry (Vivio), and an iPhone camera were used to measure arterial waveforms. Our blind clinical test shows very strong correlations between IF parameters computed from the FNN-based method and those computed from the standard L2 optimization-based method (i.e., R≥0.93 and P-value ≤0.005 for each IF parameter). Our results also demonstrate that the performance of the FNN-based IF model introduced in this work is independent of measurement apparatus and of device sampling rate.",bioRxiv,2022,10.1101/2022.02.14.480311,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
18fd2634167b87af11a7277e8d3a90f4d7c0dc70,https://www.semanticscholar.org/paper/18fd2634167b87af11a7277e8d3a90f4d7c0dc70,Detection and Classification of Brain Tumor from MR Images Using an Improvised Image Analysis Algorithm,"Early detection of brain tumour and its classification are predominantly achieved by conventional methods of image processing and machine learning. Brain tumour, known for its rapid development in terms of size and effects over human health, has to be detected immediately from the onset for an effective diagnosis. Unless a treatment plan is defined to mitigate further growth, there are high chances of fatality. Detecting and classifying processes are an exigent task even for experienced radiologists. Segmentation and feature extraction are traditional image processing techniques used for the purpose. Nowadays, a computer-aided diagnosis system is merged with machine learning and deep learning strategies for distinguishing tumour cells. The proposed system is an investigation of classifying brain tumour in its early stages using enriched feature sets support vector machine classifiers for increasing the precision of accuracy. Dice coefficient was introduced, along with the said methods, to ensure classification accuracy. Enrichment of the features was achieved by area-based analysis with prospective growth metrics on a four quadrants designated on two-dimensional plane. Genetic algorithm with soft computing techniques improvised the classification accuracy. Two standard and open source data sets deployed the proposed model, which resulted in an accuracy of 98%, sensitivity of 92%, and the specificity of 98.1% as an average. The proposed model also consumed lesser time than the conventional standards with respect to detection and classification of brain tumours.",ECS Transactions,2022,10.1149/10701.4065ecst,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29710fde444f3afeb4c666c893478ae5ce4c4e5f,https://www.semanticscholar.org/paper/29710fde444f3afeb4c666c893478ae5ce4c4e5f,An Industrial-Grade Solution for Crop Disease Image Detection Tasks,"Crop leaf diseases can reflect the current health status of the crop, and the rapid and automatic detection of field diseases has become one of the difficulties in the process of industrialization of agriculture. In the widespread application of various machine learning techniques, recognition time consumption and accuracy remain the main challenges in moving agriculture toward industrialization. This article proposes a novel network architecture called YOLO V5-CAcT to identify crop diseases. The fast and efficient lightweight YOLO V5 is chosen as the base network. Repeated Augmentation, FocalLoss, and SmoothBCE strategies improve the model robustness and combat the positive and negative sample ratio imbalance problem. Early Stopping is used to improve the convergence of the model. We use two technical routes of model pruning, knowledge distillation and memory activation parameter compression ActNN for model training and identification under different hardware conditions. Finally, we use simplified operators with INT8 quantization for further optimization and deployment in the deep learning inference platform NCNN to form an industrial-grade solution. In addition, some samples from the Plant Village and AI Challenger datasets were applied to build our dataset. The average recognition accuracy of 94.24% was achieved in images of 59 crop disease categories for 10 crop species, with an average inference time of 1.563 ms per sample and model size of only 2 MB, reducing the model size by 88% and the inference time by 72% compared with the original model, with significant performance advantages. Therefore, this study can provide a solid theoretical basis for solving the common problems in current agricultural disease image detection. At the same time, the advantages in terms of accuracy and computational cost can meet the needs of agricultural industrialization.",Frontiers in Plant Science,2022,10.3389/fpls.2022.921057,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2152b40170ed648682aedd2fdc5bb92f58c9ae1a,https://www.semanticscholar.org/paper/2152b40170ed648682aedd2fdc5bb92f58c9ae1a,211 Using team science to support outbreak management in a large urban region during the COVID-19 pandemic,"OBJECTIVES/GOALS: To describe how the UCLA Clinical and Translational Science Institute (CTSI) assembled and deployed a science team in support of a local jurisdictions effort to manage and control COVID-19 outbreaks in one of the nations largest metropolitan regions, Los Angeles County (LAC). METHODS/STUDY POPULATION: During the COVID-19 pandemic (2020-21), building an efficient data infrastructure to support outbreak management became a priority for the local health department. In response, the UCLA CTSI assembled a science team with expertise across the translational continuum: epidemiology, laboratory and microbiology, machine learning, health policy, medicine and clinical care, and community engagement. The team partnered with a new LAC Data Science Team to foster a collaborative learning environment for scientists and public health personnel, employing improvement and implementation science to help mitigate COVID-19 outbreaks in sectors including healthcare, skilled nursing facilities, and K-12 education. The goal was a public health workforce that is prepared to problem-solve complex, evolving outbreaks. RESULTS/ANTICIPATED RESULTS: The science team created a learning environment with data modeling and visualization, problem-based learning, and active knowledge and skills acquisition. First, control charts and time series methods were used to visualize COVID-19 data and find signals for action. Second, a series of 16 Grand Rounds offered interactive sessions on problem-solving of outbreak challenges in different sectors. Third, a biweekly Public Health Digest provided fieldworkers with the latest scientific studies on COVID-19. All three elements guided and empowered the workforce to implement timelier, efficient outbreak mitigation strategies in the field. The partnered team also identified barriers to adoption of selected new data and management techniques, revealing areas for further skill-building and data-driven leadership. DISCUSSION/SIGNIFICANCE: The UCLA CTSI science team offered a backbone science infrastructure for helping public health and other sector agencies manage COVID-19 outbreaks and mitigation. It showed promise in bringing and translating science into public health practice. It revealed future priorities for CTSI innovation and scientific support of public agencies.",Journal of Clinical and Translational Science,2022,10.1017/cts.2022.113,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8a2e135c784ffe18136c3e5f0c11c7637e6ad6b5,https://www.semanticscholar.org/paper/8a2e135c784ffe18136c3e5f0c11c7637e6ad6b5,Evaluating StackGenVis with a Comparative User Study,"Stacked generalization (also called stacking) is an ensemble method in machine learning that deploys a metamodel to summarize the predictive results of heterogeneous base models organized into one or more layers. Despite being capable of producing high-performance results, building a stack of models can be a trial-and-error procedure. Thus, our previously developed visual analytics system, entitled StackGen Vis, was designed to monitor and control the entire stacking process visually. In this work, we present the results of a comparative user study we performed for evaluating the StackGen-Vis system. We divided the study participants into two groups to test the usability and effectiveness of StackGen Vis compared to Orange Visual Stacking (OVS) in an exploratory usage scenario using health-care data. The results indicate that StackGen Vis is significantly more powerful than OVS based on the qualitative feedback provided by the participants. However, the average completion time for all tasks was comparable between both tools.",2022 IEEE 15th Pacific Visualization Symposium (PacificVis),2022,10.1109/PacificVis53943.2022.00025,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7e9a68155b4d14fed1d126ac2f51ca969b1ea304,https://www.semanticscholar.org/paper/7e9a68155b4d14fed1d126ac2f51ca969b1ea304,Promoting the Importance of Recall Visits Among Dental Patients in India Using a Semi-Autonomous AI System,"In many developing countries like India, there is a widespread lack of general awareness about the importance of good oral health, which causes dental patients to neglect their oral hygiene, thus precipitating many long-term ailments. We developed an application that promotes the significance of regular dental checkups and oral health care by explaining to patients how these are intrinsic to overall health. Our application, in essence, extracts relevant health information from published scientific studies according to a patient's medical history and shares it with the patient at the discretion of the supervising dentist, thereby empowering patients to make more informed decisions. We present a detailed overview of our semi- autonomous machine learning-based solution, along with the complex challenges involved in the design, development, and real-world deployment of our application. Finally, we conducted a randomized parallel-group study in India with 224 dental patients over two years to assess the utility of our proposed solution. Results show our application improved the patient recall rate from 21.1% to 37.8% (p-value = 0.024).",dHealth,2022,10.3233/SHTI220352,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b443d19cde4c1217b2e0f8dbd88f5b950be25fb9,https://www.semanticscholar.org/paper/b443d19cde4c1217b2e0f8dbd88f5b950be25fb9,Random Forest of Epidemiological Models for Influenza Forecasting,"Forecasting the hospitalizations caused by the Influenza virus is vital for public health planning so that hospitals can be better prepared for an influx of patients. Many forecasting methods have been used in real-time during the Influenza seasons and submitted to the CDC for public communication. The forecasting models range from mechanistic models, and auto-regression models to machine learning models. We hypothesize that we can improve forecasting by using multiple mechanistic models to produce potential trajectories and use machine learning to learn how to combine those trajectories into an improved forecast. We propose a Tree Ensemble model design that utilizes the individual predictors of our baseline model SIkJalpha to improve its performance. Each predictor is generated by changing a set of hyper-parameters. We compare our prospective forecasts deployed for the FluSight challenge (2022) to all the other submitted approaches. Our approach is fully automated and does not require any manual tuning. We demonstrate that our Random Forest-based approach is able to improve upon the forecasts of the individual predictors in terms of mean absolute error, coverage, and weighted interval score. Our method outperforms all other models in terms of the mean absolute error and the weighted interval score based on the mean across all weekly submissions in the current season (2022). Explainability of the Random Forest (through analysis of the trees) enables us to gain insights into how it improves upon the individual predictors.",ArXiv,2022,10.48550/arXiv.2206.08967,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ba3d0d3981758b0bab9a0f1fc03dae6af08250d0,https://www.semanticscholar.org/paper/ba3d0d3981758b0bab9a0f1fc03dae6af08250d0,Data-Centric Epidemic Forecasting: A Survey,"The COVID-19 pandemic has brought forth the importance of epidemic forecasting for decision makers in multiple domains, ranging from public health to the economy as a whole. While forecasting epidemic progression is frequently conceptualized as being analogous to weather forecasting, however it has some key differences and remains a non-trivial task. The spread of diseases is subject to multiple confounding factors spanning human behavior, pathogen dynamics, weather and environmental conditions. Research interest has been fueled by the increased availability of rich data sources capturing previously unobservable facets and also due to initiatives from government public health and funding agencies. This has resulted, in particular, in a spate of work on 'data-centered' solutions which have shown potential in enhancing our forecasting capabilities by leveraging non-traditional data sources as well as recent innovations in AI and machine learning. This survey delves into various data-driven methodological and practical advancements and introduces a conceptual framework to navigate through them. First, we enumerate the large number of epidemiological datasets and novel data streams that are relevant to epidemic forecasting, capturing various factors like symptomatic online surveys, retail and commerce, mobility, genomics data and more. Next, we discuss methods and modeling paradigms focusing on the recent data-driven statistical and deep-learning based methods as well as on the novel class of hybrid models that combine domain knowledge of mechanistic models with the effectiveness and flexibility of statistical approaches. We also discuss experiences and challenges that arise in real-world deployment of these forecasting systems including decision-making informed by forecasts. Finally, we highlight some challenges and open problems found across the forecasting pipeline.",,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b019630f8a7daeaa545dab3d478a4334004be304,https://www.semanticscholar.org/paper/b019630f8a7daeaa545dab3d478a4334004be304,Interpretability and Optimisation of Convolutional Neural Networks Based on Sinc-Convolution.,"Interpretability often seeks domain-specific facts, which is understandable to human, from deep-learning (DL) or other machine-learning (ML) models of black-box nature. This is particularly important to establish transparency in ML model's inner-working and decision-making, so that a certain level of trust is achieved when a model is deployed in a sensitive and mission-critical context, such as health-care. Model-level transparency can be achieved when its components are transparent and are capable of explaining reason of a decision, for a given input, which can be linked to domain-knowledge. This study used convolutional neural network (CNN), with sinc-convolution as its constrained first-layer, to explore if such a model's decision-making can be explained, for a given task, by observing the sinc-convolution's sinc-kernels. These kernels work like band-pass filters, having only two parameters per kernel - lower and upper cutoff frequencies, and optimised through back-propagation. The optimised frequency-bands of sinc-kernels may provide domain-specific insights for a given task. For a given input instance, the effects of sinc-kernels was visualised by means of explanation vector, which may help to identify comparatively significant frequency-bands, that may provide domain-specific interpretation, for the given task. In addition, a CNN model was further optimised by considering the identified subset of prominent sinc frequency-bands as the constrained first-layer, which yielded comparable or better performance, as compared to its all sinc-bands counterpart, as well as, a classical CNN. A minimal CNN structure, achieved through such an optimisation process, may help design task-specific interpretable models. To the best of our knowledge, the idea of sinc-convolution layer's task-specific significant sinc-kernel-based network optimisation is the first of its kind. Additionally, the idea of explanation-vector-based joint time-frequency representation to analyse time-series signals is rare in the literature. The above concept was validated for two tasks, ECG beat-classification (five-class classification task), and R-peak localisation (sample-wise segmentation task).",IEEE journal of biomedical and health informatics,2022,10.1109/JBHI.2022.3185290,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bff8a2d5ed940c76e1ca683111dacea356ab2388,https://www.semanticscholar.org/paper/bff8a2d5ed940c76e1ca683111dacea356ab2388,Securing Healthcare Data With Blockchain,"This chapter shows that blockchain has a lot of potential for revolutionizing the traditional healthcare industry. When attempting to completely integrate blockchain technology with existing EHR systems, however, a number of research and operational hurdles remain. The authors evaluated and discussed some of these issues in this chapter. After that, they discovered a variety of possible research topics, such as IoT, big data, machine learning, and edge computing. They offer a methodology for implementing blockchain technology in the healthcare industry for electronic health records (EHR). The goal of the proposed structure is to first integrate blockchain technology for EHR and then to enable safe storage of electronic data for users of the framework by setting access controls. They hope that this review will help us gain a better understanding of the development and deployment of future generation EHR systems that will benefit humankind.",Advances in Healthcare Information Systems and Administration,2022,10.4018/978-1-7998-9606-7.ch007,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1dd053ae6202ffe17593b965996bd90a90ed7c97,https://www.semanticscholar.org/paper/1dd053ae6202ffe17593b965996bd90a90ed7c97,When Personalization Harms: Reconsidering the Use of Group Attributes in Prediction,"The standard approach to personalization in machine learning consists of training a model with group attributes like sex, age group, and blood type. In this work, we show that this approach to personalization fails to improve performance for all groups who provide personal data. We discuss how this eﬀect inﬂicts harm in applications where models assign predictions on the basis of group membership. We propose collective preference guarantees to ensure the fair use of group attributes in prediction. We characterize how common approaches to personalization violate fair use due to failures in model development and deployment. We conduct a comprehensive empirical study of personalization in clinical prediction models. Our results highlight the prevalence of fair use violations, demonstrate actionable interventions to mitigate harm, and underscore the need to measure the gains of personalization for all groups who provide personal data. Credentialed Health Data License. The heart dataset is hosted on the UCI ML Repository under an Open Data license. The apnea and saps datasets must be requested from the authors of the papers listed above [57, 77]. We minimally process each dataset to impute the values of missing points (using mean value imputation), and repair class imbalances across intersectional groups (to eliminate “trivial"" fair use violations that occur due to class imbalance).",ArXiv,2022,10.48550/arXiv.2206.02058,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
426f10e7dbe3eaa4514a0496233ab4b7f2ef67b0,https://www.semanticscholar.org/paper/426f10e7dbe3eaa4514a0496233ab4b7f2ef67b0,A Formal Model for the FAIR4Health Information Architecture,"In the EU project FAIR4Health, a ETL pipeline for the FAIRification of structured health data as well as an agent-based, distributed query platform for the analysis of research hypotheses and the training of machine learning models were developed. The system has been successfully tested in two clinical use cases with patient data from five university hospitals. Currently, the solution is also being considered for use in other hospitals. However, configuring the system and deploying it in the local IT architecture is non-trivial and meets with understandable concerns about security. This paper presents a model for describing the information architecture based on a formal approach, the 3LGM metamodel. The model was evaluated by the developers. As a result, the clear separation of tasks and the software components that implement them as well as the rich description of interactions via interfaces were positively emphasized.",ICIMTH,2022,10.3233/SHTI220761,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
61179674701d00b25f8e72f6ff00e4cbbaae0f46,https://www.semanticscholar.org/paper/61179674701d00b25f8e72f6ff00e4cbbaae0f46,LSTM-Autoencoder based Anomaly Detection for Indoor Air Quality Time Series Data,"—Anomaly detection for indoor air quality (IAQ) data has become an important area of research as the quality of air is closely related to human health and well-being. However, traditional statistics and shallow machine learning-based approaches in anomaly detection in the IAQ area could not detect anomalies involving the observation of correlations across several data points (i.e., often referred to as long-term dependences). We propose a hybrid deep learning model that combines LSTM with Autoencoder for anomaly detection tasks in IAQ to address this issue. In our approach, the LSTM network is comprised of multiple LSTM cells that work with each other to learn the long-term dependences of the data in a time-series sequence. Autoencoder identiﬁes the optimal threshold based on the reconstruction loss rates evaluated on every data across all time-series sequences. Our experimental results, based on the Dunedin CO 2 time-series dataset obtained through a real-world deployment of the schools in New Zealand, demonstrate a very high and robust accuracy rate (99.50%) that outperforms other similar models.",ArXiv,2022,10.48550/arXiv.2204.06701,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
45f06d3a16bfaa197f8f4c8f137f40b06d729f5e,https://www.semanticscholar.org/paper/45f06d3a16bfaa197f8f4c8f137f40b06d729f5e,Multi-class classification and modeling of the hospitalization status of COVID-19 patients,"In recent times, the unprecedented surge in the Coronavirus disease 2019 (COVID-19) due to the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has led to several attempts at understanding and containing the outbreak of the pandemic as well as to ultimately eradicate it. Steps taken so far include encouraging the wearing of face masks and shields, municipality restrictions such as work-from-home orders, the development of vaccines by health research institutions among others. It is widely believed that the main mode of transmission of the virus is from human to human. In this paper, we present the multi-class classification and modeling of the hospitalization status of COVID-19 patients by using both machine learning and compartmental mathematical models focusing on critical factors like hospital stay-days (SDs) and admission type based on severity of illness. The classification of hospitalization status of COVID-19 patients is necessary in order to know priority cases and give them prompt attention. Two key machine learning algorithms-the decision tree and random forest, are deployed in our analyses. The Levenberg–Marquardt (L-M) algorithm was used for parameter estimation for the mathematical model. From our results, it is easy to identify high risk patients in order to optimize treatment plans that would lower cost of treatments, reduce the chances of others getting infected and assist logistics teams to optimally allocate hospital resources. Hospital administrations can also be supported in deciding the number of staff and visitors per patient per day in a facility.",2022 IEEE Nigeria 4th International Conference on Disruptive Technologies for Sustainable Development (NIGERCON),2022,10.1109/nigercon54645.2022.9803121,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
536c4246b3467c9b2084be8e3705d2d7646eec27,https://www.semanticscholar.org/paper/536c4246b3467c9b2084be8e3705d2d7646eec27,A Hybrid Method for Prediction of Ash Fouling on Heat Transfer Surfaces,"Soot blowing optimization is a key, but challenging question in the health management of coal-fired power plant boiler. The monitoring and prediction of ash fouling for heat transfer surfaces is an important way to solve this problem. This study provides a hybrid data-driven model based on advanced machine-learning techniques for ash fouling prediction. First, the cleanliness factor is utilized to represent the level of ash fouling, which is the original data from the distributed control system. The wavelet threshold denoising algorithm is employed as the data preprocessing approach. Based on the empirical mode decomposition (EMD), the denoised cleanliness factor data is decoupled into a series of intrinsic mode functions (IMFs) and a residual component. Second, the support vector regression (SVR) model is used to fit the residual, and the Gaussian process regression (GPR) model is applied to estimate the IMFs. The cleanliness factor data of ash accumulation on the heat transfer surface of diverse devices are deployed to appraise the performance of the proposed SVR + GPR model in comparison with the sole SVR, sole GPR, SVR + EDM and GPR + EDM models. The illustrative results prove that the hybrid SVR + GPR model is superior to other models and can obtain satisfactory effects both in one-step- and the multistep-ahead cleanliness factor predictions.",Energies,2022,10.3390/en15134658,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a3bf65da38f8e2ff1269dc851f0757da3f4acec2,https://www.semanticscholar.org/paper/a3bf65da38f8e2ff1269dc851f0757da3f4acec2,Mechanics Informed Neutron Noise Monitoring to Perform Remote Condition Assessment for Reactor Vessel Internals,"
 Use of neutron noise analysis in pressurized water reactors to detect and diagnose degradation represents the practice of proactive structural health monitoring for reactor vessel internals. Recent enhancements to this remote condition monitoring and diagnostic computational framework quantify the sensitivity of the structural dynamics to different degradation scenarios. This methodology leverages benchmarked computational structural mechanics models and machine learning methods to enhance interpretability of neutron noise measurement results. The novelty of the methodology lies not in the particular technologies and algorithms but in our amalgamation into a holistic computational framework for structural health monitoring. Recent experience revealed successful deployment of this methodology to proactively diagnose different degradation scenarios, thus enabling prognostic asset management for reactor structures.",ASCE-ASME J Risk and Uncert in Engrg Sys Part B Mech Engrg,2022,10.1115/1.4054444,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4861af53198fe2d7cd84aceba16d5d5d33f58910,https://www.semanticscholar.org/paper/4861af53198fe2d7cd84aceba16d5d5d33f58910,Technology Literacy in Undergraduate Medical Education: Review and Survey of the US Medical School Innovation and Technology Programs,"Background Modern innovations, like machine learning, genomics, and digital health, are being integrated into medical practice at a rapid pace. Physicians in training receive little exposure to the implications, drawbacks, and methodologies of upcoming technologies prior to their deployment. As a result, there is an increasing need for the incorporation of innovation and technology (I&T) training, starting in medical school. Objective We aimed to identify and describe curricular and extracurricular opportunities for innovation in medical technology in US undergraduate medical education to highlight challenges and develop insights for future directions of program development. Methods A review of publicly available I&T program information on the official websites of US allopathic medical schools was conducted in June 2020. Programs were categorized by structure and implementation. The geographic distribution of these categories across US regions was analyzed. A survey was administered to school-affiliated student organizations with a focus on I&T and publicly available contact information. The data collected included the founding year, thematic focus, target audience, activities offered, and participant turnout rate. Results A total of 103 I&T opportunities at 69 distinct Liaison Committee on Medical Education–accredited medical schools were identified and characterized into the following six categories: (1) integrative 4-year curricula, (2) facilitated doctor of medicine/master of science dual degree programs in a related field, (3) interdisciplinary collaborations, (4) areas of concentration, (5) preclinical electives, and (6) student-run clubs. The presence of interdisciplinary collaboration is significantly associated with the presence of student-led initiatives (P=.001). “Starting and running a business in healthcare” and “medical devices” were the most popular thematic focuses of student-led I&T groups, representing 87% (13/15) and 80% (12/15) of respondents, respectively. “Career pathways exploration for students” was the only type of activity that was significantly associated with a high event turnout rate of >26 students per event (P=.03). Conclusions Existing school-led and student-driven opportunities in medical I&T indicate growing national interest and reflect challenges in implementation. The greater visibility of opportunities, collaboration among schools, and development of a centralized network can be considered to better prepare students for the changing landscape of medical practice.",JMIR medical education,2022,10.2196/32183,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6d2acdf479ef7568bc4dc02eb576b987042790f1,https://www.semanticscholar.org/paper/6d2acdf479ef7568bc4dc02eb576b987042790f1,14-LB: Clinical Utility of KidneyIntelX on Patients with Early-Stage Diabetic Kidney Disease—A Real-World Evidence Study,"Introduction: KidneyIntelX is a multiplex immunoassay of 3 plasma biomarkers with 7 clinical variables combined using machine-learning to generate a risk score for progressive decline in kidney function over 5 years in individuals with early-stage diabetic kidney disease (DKD) .
 Methods: A Population Health defined Mount Sinai approved care pathway for DKD patients informed by the KidneyIntelX test was introduced into the Mount Sinai Health System in New York, NY as part of a Real World Evidence (RWE) study (NCT04802395) . Decision impact of medication management (anti-hypertensives, SGLT2 inhibitors/GLP1 agonists) and specialist referral was tracked. An interim analysis was performed for 1) Assessing comparability between RWE and a published clinical validation cohort based on KidneyIntelX risk score distribution; 2) Determining if necessary EHR clinical fields were captured; 3) Identifying early evidence of KidneyIntelX impact on provider decision-making.
 Results: Between Mar-Nov 2021, 1,112 patients had KidneyIntelX test results, with post-test follow up to 36 weeks. The risk breakdown of RWE population was similar to the clinical validation cohort [High 14% vs. 17%, intermediate 40% vs. 37% and low risk 46% vs. 46%]. EHR record review for care changes confirmed ability to meet study objectives. Compared to patients scored low risk, there were changes in anti-hypertensives (OR 3.0; 95% CI 1.6-5.6) , initiation of SGLT2i/GLP-1a (OR 6.4; 95% CI 2.9-14) and increased referrals to nephrologists, endocrinologists, or dieticians (OR 2.8;95% CI 1.7-4.7) in patients scored as high-risk (Figure) .
 Conclusions: KidneyIntelX was successfully deployed in a health care system in a comparable population to the validation cohort with high data capture fidelity. Application of guideline-based
 therapies and specialist referral increased in the proportion to reported risk level by 3-6 and >2-fold, respectively.
 
 
 J. Tokita: None. M. J. Donovan: Employee; Renalytix. R. Fields: None.
",Diabetes,2022,10.2337/db22-14-lb,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
377fa875ca4f7b1f62cd5693542cd19025c5aab9,https://www.semanticscholar.org/paper/377fa875ca4f7b1f62cd5693542cd19025c5aab9,Demographic and socioeconomic factors predict maternal postpartum rehospitalization: a retrospective nuMoM2b dataset study,"The advent of artificial intelligence/machine learning (AI/ML) in medicine has opened opportunities for harnessing the power of ML to predict patient outcomes based on diverse data contained in the electronic medical records (EMR). Taken by themselves singular features represented by such diverse data are often not clearly predictive, but combined in an ML modeling framework such so-called weak learners have the power to yield highly predictive models of health outcomes. We hypothesized that sociodemographic and basic, easily obtainable health characteristics of pregnant mothers strongly predict the risk of rehospitalization. Using the nuMoM2b dataset from NICHD and reproducible, open access AI/ML techniques we tested and validated this hypothesis. Among a large (n=10,038) and geographically diverse cohort of nulliparous women with singleton gestations, the present findings show that while some of these characteristics highlight the known disparities in health outcomes (race/ethnicity), most of them are modifiable through social policies and health counseling. These include access to and support during education, comprehensive health insurance, alleviating coming out of poverty, smoking, and unhealthy lifestyle habits. Across the four ML models deployed, the results are mutually reinforcing yielding a clear cohesive picture. This solution can be used to develop a prospective risk prediction for this important health outcome in pregnant mothers. The strengths of the presented solution are its focus on preventable maternal morbidities and risk factors, demonstration of the impact on adversely affected populations, and reproducible step-by-step executable, documented open-access code with relatively low computational requirements. This enables easy adoption and further development on this and other similar datasets to study the contributions and predictive power of various factors to maternal morbidities.",medRxiv,2022,10.1101/2022.02.23.22271437,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
30e8e8131c39d723d620cc81f2eb526e94b5d086,https://www.semanticscholar.org/paper/30e8e8131c39d723d620cc81f2eb526e94b5d086,"Artificial intelligence in pulmonary medicine: computer vision, predictive model and COVID-19","Artificial intelligence (AI) is transforming healthcare delivery. The digital revolution in medicine and healthcare information is prompting a staggering growth of data intertwined with elements from many digital sources such as genomics, medical imaging and electronic health records. Such massive growth has sparked the development of an increasing number of AI-based applications that can be deployed in clinical practice. Pulmonary specialists who are familiar with the principles of AI and its applications will be empowered and prepared to seize future practice and research opportunities. The goal of this review is to provide pulmonary specialists and other readers with information pertinent to the use of AI in pulmonary medicine. First, we describe the concept of AI and some of the requisites of machine learning and deep learning. Next, we review some of the literature relevant to the use of computer vision in medical imaging, predictive modelling with machine learning, and the use of AI for battling the novel severe acute respiratory syndrome-coronavirus-2 pandemic. We close our review with a discussion of limitations and challenges pertaining to the further incorporation of AI into clinical pulmonary practice. Artificial intelligence (AI) is changing the landscape in medicine. AI-based applications will empower pulmonary specialists to seize modern practice and research opportunities. Data-driven precision medicine is already here. https://bit.ly/324tl2m",European Respiratory Review,2020,10.1183/16000617.0181-2020,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17575f8bde8a04ad9b4c9e59d3f3723280a9a61e,https://www.semanticscholar.org/paper/17575f8bde8a04ad9b4c9e59d3f3723280a9a61e,Diagnosis of Liver Disease by Using Least Squares Support Vector Machine Approach,"A healthy liver leads to healthy life. In India, as well as in other parts of the world, liver disease is one of the principle areas of concern in medicine. For this study, diagnosis of liver disease is performed by deploying classification methods include linear discriminant analysis LDA, quadratic discriminant analysis QDA, feed-forward neural network FFNN and support vector machine SVM based approaches. Experimental results concluded that SVM based approaches outperformed all other classification methods in terms of diagnostic accuracy rates. Furthermore, least squares support vector machine LSSVM with gaussian radial basis kernel function based machine learning approach had emerged as the as the best predictive model by reducing inefficiencies caused by false diagnosis. LSSVM also performed better than linear SVM, polynomial SVM, quadratic SVM and multilayer perceptron SVM despite the uneven variance in attribute values in the health examination data.",Int. J. Heal. Inf. Syst. Informatics,2016,10.4018/IJHISI.2016040104,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b65d267aa30ff9d1d8aa8ce0e9e47a288b77eb66,https://www.semanticscholar.org/paper/b65d267aa30ff9d1d8aa8ce0e9e47a288b77eb66,Technology integrated health management for dementia.,"Pioneering advances have been made in Internet of Things technologies (IoT) in healthcare. This article describes the development and testing of a bespoke IoT system for dementia care. Technology integrated health management (TIHM) for dementia is part of the NHS England National Test Bed Programme and has involved trailing the deployment of network enabled devices combined with artificial intelligence to improve outcomes for people with dementia and their carers. TIHM uses machine learning and complex algorithms to detect and predict early signs of ill health. The premise is if changes in a person's health or routine can be identified early on, support can be targeted at the point of need to prevent the development of more serious complications.",British journal of community nursing,2018,10.12968/bjcn.2018.23.10.502,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5adff71bbb61935cff69818d75cb6c416b4cff4a,https://www.semanticscholar.org/paper/5adff71bbb61935cff69818d75cb6c416b4cff4a,Social Bots for Online Public Health Interventions,"According to the Center for Disease Control and Prevention, hundreds of thousands initiate smoking each year, and millions live with smoking-related diseases in the United States. Many tobacco users discuss their opinions, habits and preferences on social media. This work conceptualizes a framework for targeted health interventions to inform tobacco users about the consequences of tobacco use. We designed a Twitter bot named Notobot (short for No-Tobacco Bot) that leverages machine learning to identify users posting pro-tobacco tweets and select individualized interventions to curb their tobacco use. We searched the Twitter feed for tobacco-related keywords and phrases, and trained a convolutional neural network using over 4,000 tweets manually labeled as either pro-tobacco or not pro-tobacco. This model achieved a 90% accuracy rate on the training set and 74% on test data. Users posting protobacco tweets were matched with former smokers with similar interests who posted anti-tobacco tweets. Algorithmic matching, leveraging the power of peer influence, allows for the systematic delivery of personalized interventions based on real anti-tobacco tweets from former smokers. Experimental evaluation suggested that our system would perform well if deployed.",2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),2018,10.1109/ASONAM.2018.8508382,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9fa15c73bc02a6d13c8fbe217becc8cfd08212a0,https://www.semanticscholar.org/paper/9fa15c73bc02a6d13c8fbe217becc8cfd08212a0,Can Predictive Modeling Tools Identify Patients at High Risk of Prolonged Opioid Use After ACL Reconstruction?,"BACKGROUND
Machine-learning methods such as the Bayesian belief network, random forest, gradient boosting machine, and decision trees have been used to develop decision-support tools in other clinical settings. Opioid abuse is a problem among civilians and military service members, and it is difficult to anticipate which patients are at risk for prolonged opioid use.


QUESTIONS/PURPOSES
(1) To build a cross-validated model that predicts risk of prolonged opioid use after a specific orthopaedic procedure (ACL reconstruction), (2) To describe the relationships between prognostic and outcome variables, and (3) To determine the clinical utility of a predictive model using a decision curve analysis (as measured by our predictive system's ability to effectively identify high-risk patients and allow for preventative measures to be taken to ensure a successful procedure process).


METHODS
We used the Military Analysis and Reporting Tool (M2) to search the Military Health System Data Repository for all patients undergoing arthroscopically assisted ACL reconstruction (Current Procedure Terminology code 29888) from January 2012 through December 2015 with a minimum of 90 days postoperative follow-up. In total, 10,919 patients met the inclusion criteria, most of whom were young men on active duty. We obtained complete opioid prescription filling histories from the Military Health System Data Repository's pharmacy records. We extracted data including patient demographics, military characteristics, and pharmacy data. A total of 3.3% of the data was missing. To curate and impute all missing variables, we used a random forest algorithm. We shuffled and split the data into 80% training and 20% hold-out sets, balanced by outcome variable (Outcome90Days). Next, the training set was further split into training and validation sets. Each model was built on the training data set, tuned with the validation set as applicable, and finally tested on the separate hold-out dataset. We chose four predictive models to develop, at the end choosing the best-fit model for implementation. Logistic regression, random forest, Bayesian belief network, and gradient boosting machine models were the four chosen models based on type of analysis (classification). Each were trained to estimate the likelihood of prolonged opioid use, defined as any opioid prescription filled more than 90 days after anterior cruciate reconstruction. After this, we tested the models on our holdout set and performed an area under the curve analysis concordance statistic, calculated the Brier score, and performed a decision curve analysis for validation. Then, we chose the method that produced the most suitable analysis results and, consequently, predictive power across the three calculations. Based on the calculations, the gradient boosting machine model was selected for future implementation. We systematically selected features and tuned the gradient boosting machine to produce a working predictive model. We performed area under the curve, Brier, and decision curve analysis calculations for the final model to test its viability and gain an understanding of whether it is possible to predict prolonged opioid use.


RESULTS
Four predictive models were successfully developed using gradient boosting machine, logistic regression, Bayesian belief network, and random forest methods. After applying the Boruta algorithm for feature selection based on a 100-tree random forest algorithm, features were narrowed to a final seven features. The most influential features with a positive association with prolonged opioid use are preoperative morphine equivalents (yes), particular pharmacy ordering sites locations, shorter deployment time, and younger age. Those observed to have a negative association with prolonged opioid use are particular pharmacy ordering sites locations, preoperative morphine equivalents (no), longer deployment, race (American Indian or Alaskan native) and rank (junior enlisted).On internal validation, the models showed accuracy for predicting prolonged opioid use with AUC greater than our benchmark cutoff 0.70; random forest were 0.76 (95% confidence interval 0.73 to 0.79), 0.76 (95% CI 0.73 to 0.78), 0.73 (95% CI 0.71 to 0.76), and 0.72 (95% CI 0.69 to 0.75), respectively. Although the results from logistic regression and gradient boosting machines were very similar, only one model can be used in implementation. Based on our calculation of the Brier score, area under the curve, and decision curve analysis, we chose the gradient boosting machine as the final model. After selecting features and tuning the chosen gradient boosting machine, we saw an incremental improvement in our implementation model; the final model is accurate, with a Brier score of 0.10 (95% CI 0.09 to 0.11) and area under the curve of 0.77 (95% CI 0.75 to 0.80). It also shows the best clinical utility in a decision curve analysis.


CONCLUSIONS
These scores support our claim that it is possible to predict which patients are at risk of prolonged opioid use, as seen by the appropriate range of hold-out analysis calculations. Current opioid guidelines recommend preoperative identification of at-risk patients, but available tools for this purpose are crude, largely focusing on identifying the presence (but not relative contributions) of various risk factors and screening for depression. The power of this model is that it will permit the development of a true clinical decision-support tool, which risk-stratifies individual patients with a single numerical score that is easily understandable to both patient and surgeon. Probabilistic models provide insight into how clinical factors are conditionally related. Not only will this gradient boosting machine be used to help understand factors contributing to opiate misuse after ACL reconstruction, but also it will allow orthopaedic surgeons to identify at-risk patients before surgery and offer increased support and monitoring to prevent opioid abuse and dependency.


LEVEL OF EVIDENCE
Level III, therapeutic study.",Clinical orthopaedics and related research,2020,10.1097/CORR.0000000000001251,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8e4a3c33371899b05ccc7b59914f9ce0b983308e,https://www.semanticscholar.org/paper/8e4a3c33371899b05ccc7b59914f9ce0b983308e,Sensor and Component Fault Detection and Diagnosis for Hydraulic Machinery Integrating LSTM Autoencoder Detector and Diagnostic Classifiers,"Anomaly occurrences in hydraulic machinery might lead to massive system shut down, jeopardizing the safety of the machinery and its surrounding human operator(s) and environment, and the severe economic implications following the faults and their associated damage. Hydraulics are mostly placed in ruthless environments, where they are consistently vulnerable to many faults. Hence, not only are the machines and their components prone to anomalies, but also the sensors attached to them, which monitor and report their health and behavioral changes. In this work, a comprehensive applicational analysis of anomalies in hydraulic systems extracted from a hydraulic test rig was thoroughly achieved. First, we provided a combination of a new architecture of LSTM autoencoders and supervised machine and deep learning methodologies, to perform two separate stages of fault detection and diagnosis. The two phases were condensed by—the detection phase using the LSTM autoencoder. Followed by the fault diagnosis phase represented by the classification schema. The previously mentioned framework was applied to both component and sensor faults in hydraulic systems, deployed in the form of two in-depth applicational experiments. Moreover, a thorough literature review of related work from the past decade, for autoencoders related fault detection and diagnosis in hydraulic systems, was successfully conducted in this study.",Sensors,2020,10.3390/s21020433,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
472c758372469c8278256a0161ef8206adcb26d3,https://www.semanticscholar.org/paper/472c758372469c8278256a0161ef8206adcb26d3,An Assistive Bot for Healthcare Using Deep Learning: Conversation-as-a-Service,,Advances in Intelligent Systems and Computing,2018,10.1007/978-981-13-1708-8_10,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fb79b5f6a557d1c434aa2c00b8395e171e464813,https://www.semanticscholar.org/paper/fb79b5f6a557d1c434aa2c00b8395e171e464813,Deep Detector Health Management under Adversarial Campaigns,"Machine learning models are vulnerable to adversarial inputs that induce seemingly unjustifiable errors. As automated classifiers are increasingly used in industrial control systems and machinery, these adversarial errors could grow to be a serious problem. Despite numerous studies over the past few years, the field of adversarial ML is still considered alchemy, with no practical unbroken defenses demonstrated to date, leaving PHM practitioners with few meaningful ways of addressing the problem. We introduce turbidity detection as a practical superset of the adversarial input detection problem, coping with adversarial campaigns rather than statistically invisible one-offs. This perspective is coupled with ROC-theoretic design guidance that prescribes an inexpensive domain adaptation layer at the output of a deep learning model during an attack campaign. The result aims to approximate the Bayes optimal mitigation that ameliorates the detection model's degraded health. A proactively reactive type of prognostics is achieved via Monte Carlo simulation of various adversarial campaign scenarios, by sampling from the model's own turbidity distribution to quickly deploy the correct mitigation during a real-world campaign.",ArXiv,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b4376c5f5b536c29090b81a72c50d6aa312ddae7,https://www.semanticscholar.org/paper/b4376c5f5b536c29090b81a72c50d6aa312ddae7,Miniaturized Pervasive Sensors for Indoor Health Monitoring in Smart Cities,"Sensors and electronics technologies are pivotal in several fields of science and engineering, especially in automation, industry and environment monitoring. Over the years, there have been continuous changes and advancements in design and miniaturization of sensors with the growth of their application areas. Challenges have arisen in the deployment, fabrication and calibration of modern sensors. Therefore, although the usage of sensors has greatly helped improving the quality of life, especially through their employment in many IoT (Internet of Things) applications, some threats and safety issues still remain unaddressed. In this paper, a brief review focusing on pervasive sensors used for health and indoor environment monitoring is given. Examples of technology advancements in air, water and radioactivity are discussed. This bird’s eye view suggests that solid-state pervasive sensors have become essential parts of all emerging applications related to monitoring of health and safety. Miniaturization, in combination with gamification approaches and machine learning techniques for processing large amounts of captured data, can successfully address and solve many issues of massive deployment. The development paradigm of Smart Cities should include both indoor and outdoor scenarios.",Smart Cities,2021,10.3390/SMARTCITIES4010008,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
31c38daebd364df81d54208a3961f1b2ad78f962,https://www.semanticscholar.org/paper/31c38daebd364df81d54208a3961f1b2ad78f962,Empowering Healthcare IoT Systems with Hierarchical Edge-Based Deep Learning,"Remote health monitoring is a powerful tool to provide preventive care and early intervention for populations-at-risk. Such monitoring systems are becoming available nowadays due to recent advancements in Internet-of-Things (IoT) paradigms, enabling ubiquitous monitoring. These systems require a high level of quality in attributes such as availability and accuracy due to patients critical conditions in the monitoring. Deep learning methods are very promising in such health applications to obtain a satisfactory performance, where a considerable amount of data is available. These methods are perfectly positioned in the cloud servers in a centralized cloud-based IoT system. However, the response time and availability of these systems highly depend on the quality of Internet connection. On the other hand, smart gateway devices are unable to implement deep learning methods (such as training models) due to their limited computational capacities. In our previous work, we proposed a hierarchical computing architecture (HiCH), where both edge and cloud computing resources were efficiently exploited, allocating heavy tasks of a conventional machine learning method to the cloud servers and outsourcing the hypothesis function to the edge. Due to this local decision making, the availability of the system was highly improved. In this paper, we investigate the feasibility of deploying the Convolutional Neural Network (CNN) based classification model as an example of deep learning methods in this architecture. Therefore, the system benefits from the features of the HiCH and the CNN, ensuring a high-level availability and accuracy. We demonstrate a real-time health monitoring for a case study on ECG classifications and evaluate the performance of the system in terms of response time and accuracy.","2018 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)",2018,10.1145/3278576.3278597,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c562416a533c8b1e331e126c5b8e9900b18069e8,https://www.semanticscholar.org/paper/c562416a533c8b1e331e126c5b8e9900b18069e8,Cerebral venous thrombosis post BNT162b2 mRNA SARS‐CoV‐2 vaccination: A black swan event,"Summary COVID-19 has already affected the world with this deadly virus, resulting in over 3.5 lakh deaths. The behavior of this virus is extraordinarily peculiar and mutates frequently. So, the scientific community faces the problems to analyze and forecast the virus's growth and transmission capability. The combined effort of powerful Artificial intelligence and Image processing techniques to predict the initial pattern of COVID-19 disease identifies the most affected areas in each country through social networking information and predicts drug-protein interactions for making new drugs vaccines. However, AI-empowered X-Ray and computed tomography image acquisition and segmentation techniques help us identify and diagnose the COVID-19 affected patients with minimal contact. In this chapter, our primary motivation is to sum up the essential roles of some AI-driven techniques (Machine learning, Deep learning, etc.) and AI-empowered imaging techniques to analyze, predict, and diagnose against COVID-19 disease. An essential set of open challenges and future research issues on AI-empowered procedures for handling COVID-19 are also discussed in this chapter. Summary This paper mainly deals with the design of Machine Learning model for the analysis of transmission dynamics of Covid 19. The entire globe is affected because of Corona virus. Ventilator dependent, Severe Acute respiratory and quarantine care ICU patients frequently face difficulties for their most basic human interactions, namely communication due to either respiratory illness, language problem or intubated. ICU patients have serious implications with respect to physical and psychological due to non communication problems. Researchers have developed different types of services like Speech language Pathologist so that Augmentative and alternative communication assistance can be given to all health professionals and caretakers. A probabilistic model is designed to analyse the new cases and death cases. Using machine learning approach Regression model is designed and future predications are displayed. The adequacy of the model is discussed along with the residuals of new cased and death cases. PCF and APCAF are obtained. This paper mainly deals with a probabilistic model to analyse and predict the new cases and deaths of covid 19. A new transformation of analyzing stationarity is carried out and based on this forecasting is executed. Summary This research express an impression of automated decision-making techniques that have been suggested for scrutiny of data from IoT based healthcare systems. IoT data analytics plays a vital role in this modern era since data from connected devices reveal meaningful results with better insights for the future. The chapter involves the design of a decision-making system that collects data from IoT based healthcare systems, preprocess and analyzes data, and generates detailed information reports for better diagnosis. Data preprocessing methods such as data cleaning, munging, normalization, reduction, and removing noisy data are applied. The blend of IoT data with analytics technique results to be beneficial in healthcare systems. The collected IoT information like pulse rate, temperature, oxygen level and heart rate from connected devices can be used to analyze the need and severity in the preliminary stage itself using appropriate machine learning techniques. Multi Criteria Decision Making (MCDM) techniques such as SMART, WPM, and TOPSIS are also applied for conclusion production procedure to generate detailed informative diagnostic reports. Being healthcare data, the overall objective is to aid business organizations with better decision making processes through data analytics thereby deploying the right IoT strategy. The result of the next-generation expert systems can utilize the results for further analysis in diagnosis and treatment. Summary The proposed work deals with the design and development of touch and native voice-assisted prototype to enable the intuitive communication & interaction between health professionals and patients who are affected with Severe Acute Respiratory Infection (SARI), Ventilator-dependent and admitted in Quarantine care. It also ensures the development of the multilingual capability to communicate effectively in most speaking ten Indian languages, so that the patients will be relieved from pains etc., as their queries are being addressed by health professionals. In this prototype, touch based gesture patterns can be effectively used as an interactive module and helps the doctors to monitor and answer to the queries of ICU patients regularly by updating it to the caretakers such that the patients are at ease to express their emotions or pains. The proposed prototype will be made available and accessible in an open software repository. As per the existing methods patients express their needs through non-verbal communication methods and they could be missed out or misinterpreted resulting in symptoms that are poorly understood and the clinicians overestimate their ability to understand their communication feelings. These situations are eradicated by employing the use of ?Touch Voice of SARI? Application. Hence this can be considered as an assistive communication tool which replaces the nonverbal communication to a meaningful communication for ventilator patients and healthcare professionals.",American journal of hematology,2021,10.1002/ajh.26272,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
269c7d883b3af927e21680e59dfbec269c4190ac,https://www.semanticscholar.org/paper/269c7d883b3af927e21680e59dfbec269c4190ac,Robotic Coral Reef Health Assessment Using Automated Image Analysis,"This paper presents a system capable of autonomous surveillance and analysis of coral reef ecosystems using natural lighting. We describe our strategy to safely and effectively deploy a small marine robot to inspect a reef using its digital cameras. Image analysis using a (RBF‐SVM) radial basis function‐support vector machines in combination with (LBP) local binary pattern, Gabor and Hue descriptors developed in this work are able to analyze the resulting image data automatically and reliably by learning from the annotations of expert marine biologists. Our primary evaluation is performed on a novel coral data set that we collected during a series of robotic ocean deployments, the MRL Coral Identification Challenge. We have also applied our algorithms to a data set of coral imagery previously published by other researchers. Our algorithms recognize coral images in our own challenging data with 88.9% accuracy, while being sufficiently efficient to run online on our vehicle. This demonstrates the feasibility of such a system for practical use for the preservation of this crucial ecological resource.",J. Field Robotics,2017,10.1002/rob.21698,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
61890eb3bea4c813e0df2fa4c2e3f5259700b2e0,https://www.semanticscholar.org/paper/61890eb3bea4c813e0df2fa4c2e3f5259700b2e0,Automatic cough classification for tuberculosis screening in a real-world environment,"Objective. The automatic discrimination between the coughing sounds produced by patients with tuberculosis (TB) and those produced by patients with other lung ailments. Approach. We present experiments based on a dataset of 1358 forced cough recordings obtained in a developing-world clinic from 16 patients with confirmed active pulmonary TB and 35 patients suffering from respiratory conditions suggestive of TB but confirmed to be TB negative. Using nested cross-validation, we have trained and evaluated five machine learning classifiers: logistic regression (LR), support vector machines, k-nearest neighbour, multilayer perceptrons and convolutional neural networks. Main Results. Although classification is possible in all cases, the best performance is achieved using LR. In combination with feature selection by sequential forward selection, our best LR system achieves an area under the ROC curve (AUC) of 0.94 using 23 features selected from a set of 78 high-resolution mel-frequency cepstral coefficients. This system achieves a sensitivity of 93% at a specificity of 95% and thus exceeds the 90% sensitivity at 70% specificity specification considered by the World Health Organisation (WHO) as a minimal requirement for a community-based TB triage test. Significance. The automatic classification of cough audio sounds, when applied to symptomatic patients requiring investigation for TB, can meet the WHO triage specifications for the identification of patients who should undergo expensive molecular downstream testing. This makes it a promising and viable means of low cost, easily deployable frontline screening for TB, which can benefit especially developing countries with a heavy TB burden.",Physiological measurement,2021,10.1088/1361-6579/ac2fb8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5e318590185f409494710510da425748eb6a3a51,https://www.semanticscholar.org/paper/5e318590185f409494710510da425748eb6a3a51,"AI Case Studies: Potential for Human Health, Space Exploration and Colonisation and a Proposed Superimposition of the Kubler-Ross Change Curve on the Hype Cycle","Abstract The development and deployment of artificial intelligence (AI) is and will profoundly reshape human society, the culture and the composition of civilisations which make up human kind. All technological triggers tend to drive a hype curve which over time is realised by an output which is often unexpected, taking both pessimistic and optimistic perspectives and actions of drivers, contributors and enablers on a journey where the ultimate destination may be unclear. In this paper we hypothesise that this journey is not dissimilar to the personal journey described by the Kubler-Ross change curve and illustrate this by commentary on the potential of AI for drug discovery, development and healthcare and as an enabler for deep space exploration and colonisation. Recent advances in the call for regulation to ensure development of safety measures associated with machine-based learning are presented which, together with regulation of the rapidly emerging digital after-life industry, should provide a platform for realising the full potential benefit of AI for the human species.",Studia Humana,2019,10.2478/sh-2019-0001,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cfd603c170228215e0066de6a1a3b7f7b69f2b4d,https://www.semanticscholar.org/paper/cfd603c170228215e0066de6a1a3b7f7b69f2b4d,Twitter-Based Detection of Illegal Online Sale of Prescription Opioid,"Objectives To deploy a methodology accurately identifying tweets marketing the illegal online sale of controlled substances. Methods We first collected tweets from the Twitter public application program interface stream filtered for prescription opioid keywords. We then used unsupervised machine learning (specifically, topic modeling) to identify topics associated with illegal online marketing and sales. Finally, we conducted Web forensic analyses to characterize different types of online vendors. We analyzed 619 937 tweets containing the keywords codeine, Percocet, fentanyl, Vicodin, Oxycontin, oxycodone, and hydrocodone over a 5-month period from June to November 2015. Results A total of 1778 tweets (< 1%) were identified as marketing the sale of controlled substances online; 90% had imbedded hyperlinks, but only 46 were “live” at the time of the evaluation. Seven distinct URLs linked to Web sites marketing or illegally selling controlled substances online. Conclusions Our methodology can identify illegal online sale of prescription opioids from large volumes of tweets. Our results indicate that controlled substances are trafficked online via different strategies and vendors. Public Health Implications Our methodology can be used to identify illegal online sellers in criminal violation of the Ryan Haight Online Pharmacy Consumer Protection Act.",American journal of public health,2017,10.2105/AJPH.2017.303994,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ffdf00dbc32891fe6f106c88cb68761665da4c70,https://www.semanticscholar.org/paper/ffdf00dbc32891fe6f106c88cb68761665da4c70,The livestock farming digital transformation: implementation of new and emerging technologies using artificial intelligence,"Abstract Livestock welfare assessment helps monitor animal health status to maintain productivity, identify injuries and stress, and avoid deterioration. It has also become an important marketing strategy since it increases consumer pressure for a more humane transformation in animal treatment. Common visual welfare practices by professionals and veterinarians may be subjective and cost-prohibitive, requiring trained personnel. Recent advances in remote sensing, computer vision, and artificial intelligence (AI) have helped developing new and emerging technologies for livestock biometrics to extract key physiological parameters associated with animal welfare. This review discusses the livestock farming digital transformation by describing (i) biometric techniques for health and welfare assessment, (ii) livestock identification for traceability and (iii) machine and deep learning application in livestock to address complex problems. This review also includes a critical assessment of these topics and research done so far, proposing future steps for the deployment of AI models in commercial farms. Most studies focused on model development without applications or deployment for the industry. Furthermore, reported biometric methods, accuracy, and machine learning approaches presented some inconsistencies that hinder validation. Therefore, it is required to develop more efficient, non-contact and reliable methods based on AI to assess livestock health, welfare, and productivity.",Animal Health Research Reviews,2022,10.1017/S1466252321000177,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
53ac5031930a7b4b0af494d3e3761dff8537d471,https://www.semanticscholar.org/paper/53ac5031930a7b4b0af494d3e3761dff8537d471,Wireless on Walls: Revolutionizing the future of health care,"Following the standardization and deployment of the 5G network, researchers have shifted their focus to beyond 5G (B5G) communication. Existing technologies have brought forth a plethora of applications that could not have been imagined in the past years. B5G will enable us to rethink the capability it will offer in various sectors, including agriculture, search and rescue, and, more specifically, in the delivery of health-care services. Unobtrusive and noninvasive measurements using radio-frequency (RF) sensing, monitoring, and the control of wearable medical devices are the areas that would potentially benefit from B5G. Applications such as RF sensing, device charging, and remote patient monitoring will be a key challenge in using millimeter-wave (mm-wave) communication. The mm-waves experience multipath-induced fading, where the rate of attenuation is larger as compared to microwaves. Eventually, mm-wave communication systems would require range extenders and guided surfaces. A proposed solution is the use of intelligent reflective surfaces, which will have the ability to manipulate electromagnetic (EM) signals. These intelligent surfaces mounted and/or coated on walls, also known as intelligent walls (IWs), are planar and active surfaces, which will be a key element in B5G and 6G communication. These intelligent walls, equipped with a machine learning (ML) algorithm and computation power, would have the ability to manipulate EM waves and act as gateways in the heterogeneous network environment. The article presents the application and vision of intelligent walls for next-generation health care in the era of B5G.",IEEE Antennas and Propagation Magazine,2021,10.1109/map.2020.3036063,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
92079950bb4c636c26cf39f1d9d774d30e8140a9,https://www.semanticscholar.org/paper/92079950bb4c636c26cf39f1d9d774d30e8140a9,A Hybrid Optimized LSTM Models for Human Activity Recognition with IOT Devices,"With the advent of Internet of things(IoT),HA (HA) recognition has contributed the more application in health care in terms of diagnosis and Clinical process. These devices must be aware of human movements to provide better aid in the clinical applications as well as user’s daily activity.Also , In addition to machine and deep learning algorithms, HA recognition systems has significantly improved in terms of high accurate recognition. However, the most of the existing models designed needs improvisation in terms of accuracy and computational overhead. In this research paper, we proposed a BAT optimized Long Short term Memory (BAT-LSTM) for an effective recognition of human activities using real time IoT systems. The data are collected by implanting the Internet of things) devices invasively. Then, proposed BAT-LSTM is deployed to extract the temporal features which are then used for classification to HA. Nearly 10,0000 dataset were collected and used for evaluating the proposed model. For the validation of proposed framework, accuracy, precision, recall, specificity and F1-score parameters are chosen and comparison is done with the other state-of-art deep learning models. The finding shows the proposed model outperforms the other learning models and finds its suitability for the HA recognition.","International Journal of Advanced Research in Science, Communication and Technology",2021,10.48175/ijarsct-2326,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
846a11c06f855916b84afd9e8d373489fff41847,https://www.semanticscholar.org/paper/846a11c06f855916b84afd9e8d373489fff41847,An improvement of visualized images from vibration for plastic gear early failure detection using convolutional neural network,"Recently, data-driven machine health monitoring has become more popular due to the wide-spread deployment of lowcost sensors and deep learning algorithms’ achievements. The detection of failures of machines can be determined based on failure classification results using deep learning architectures. On this tendency, we constructed a plastic gear failure detection structure using a convolutional neural network. In this study, raw vibration data was converted to frequencydomain data. Amplitudes of frequencies in the monitored frequency band were transferred into images, which then were labeled as crack or non-crack by a high-speed camera. Although deep learning architectures have great potential to automatically learn from complex features of input data, the high-amplitude frequencies reflecting the main vibration causes such as gear meshing frequency and its harmonics or shaft frequency affect the accuracy of learning. Besides, the low-amplitude frequencies in a low-frequency band, which are sensitive to gear failures, show efficiency in early failure signs of the plastic gear. Thus, this paper proposed an image visualization and labeling method by focusing on lowamplitude frequency features in the low-frequency band and lessening high-amplitude frequency features. The results show that the proposed system learning from new visualized images can detect plastic gear’s early failure situation before the initial crack happened.",Smart Structures and Materials + Nondestructive Evaluation and Health Monitoring,2021,10.1117/12.2582637,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7b536d12f03f6e3277b29ea244e066bfcb123e8f,https://www.semanticscholar.org/paper/7b536d12f03f6e3277b29ea244e066bfcb123e8f,Cable Health Monitoring in Distribution Networks using Power Line Communications,"Power Line Communication (PLC) harnesses the existing infrastructure of power lines for data transmission. As one application, PLC is being used for monitoring and control in distribution networks. In this paper, we propose an autonomous technique that exploits the communication channel estimated inside legacy PLC modems to determine the health of distribution cables. In particular, we consider paper insulated lead covered (PILC) cables widely used in low and medium voltage distribution networks that are most susceptible to thermal degradations. Measurement campaigns have shown that these thermal degradations cause dielectric property changes in PILC cable insulations, which also result in changes in PLC channel conditions. However, through channel characterization of healthy and degraded cables, we demonstrate that the estimated channel frequency responses are not sufficiently distinctive for manual diagnosis. We therefore propose a machine-learning based technique that not only achieves our set target, but is also able to estimate the cable health under varying load conditions. Simulation results show that our proposed technique accurately estimates thermal degradation severities in PILC cables. We thus believe that PLC based cable health monitoring can be used as an autonomous remote diagnostics method that can be integrated into a smart-grid concept and has the promise of being more cost-effective than deploying personnel and/or dedicated equipment.","2018 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)",2018,10.1109/SmartGridComm.2018.8587458,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1be1a4766c70093b040cf137413091ec3fb50526,https://www.semanticscholar.org/paper/1be1a4766c70093b040cf137413091ec3fb50526,Actitracker: A Smartphone-Based Activity Recognition System for Improving Health and Well-Being,"Actitracker is a smartphone-based activity-monitoring service to help people ensure they receive sufficient activity to maintain proper health. This free service allowed people to set personal activity goals and monitor their progress toward these goals. Actitracker uses machine learning methods to recognize a user's activities. It initially employs a ""universal"" model generated from labeled activity data from a panel of users, but will automatically shift to a much more accurate personalized model once a user completes a simple training phase. Detailed activity reports and statistics are maintained and provided to the user. Actitracker is a research-based system that began in 2011, before fitness trackers like Fitbit were popular, and was deployed for public use from 2012 until 2015, during which period it had 1,000 registered users. This paper describes the Actitracker system, its use of machine learning, and user experiences. While activity recognition has now entered the mainstream, this paper provides insights into applied activity recognition, something that commercial companies rarely share.",2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA),2016,10.1109/DSAA.2016.89,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d8f1b0dc4720e76cab2bb21f756341b466b4dbd0,https://www.semanticscholar.org/paper/d8f1b0dc4720e76cab2bb21f756341b466b4dbd0,Gait-based Gender Classification Using Smartphone Accelerometer Sensor,"People gender and activities recognition are becoming a hot topic in our daily applications through gait information. The very well-known applications are safety-health, security, entertainment and billing. Numerous data mining and machine learning algorithms have been proposed for such issue. Equally, many technologies could be used to observe the people activities to identify their gender and activities. However, the existing solutions and applications suffer from privacy and cost to deploy the solution and their obtained accuracy. For example, when the CCTV camera or Kinect sensors technology are used to identify people, such technologies will violate the privacy since most of the people do not want to take their pictures or videos during their daily activities. Therefore, to tackle such issue, this paper presents a new scheme to identify the gender of the people via onboard Smartphone sensors including accelerometer sensor. Such a scheme requires little interaction with the people; individuals would simply have to hold his/her smartphone and walk normally. Four different data mining techniques and machine learning algorithms are used to identify people gender including: Decision Tree (DT), Support Vector Machine (SVM), k-Nearest Neighbor (k-NN) and Deep learning algorithm (recurrent-neural-network long-short-term-memory ‘RNN-LSTM’). Further, a set of experiments are conducted via Android-based smartphones (to read smartphone accelerometer sensor) and MATALB-2018a packages used to perform the validity of the scheme. The obtained results from the experiments show that the accuracy of the gender identification is about 94.11% via deep learning algorithm (RNN-LSTM) and is around 83.75% by using DT algorithm.",2019 5th International Conference on Frontiers of Signal Processing (ICFSP),2019,10.1109/icfsp48124.2019.8938033,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
47be4ffa42e52704d614d314b6cb76110ef5a650,https://www.semanticscholar.org/paper/47be4ffa42e52704d614d314b6cb76110ef5a650,Training and Profiling a Pediatric Emotion Recognition Classifier on Mobile Devices,"Implementing automated emotion recognition on mobile devices could provide an accessible diagnostic and therapeutic tool for those who struggle to recognize emotion, including children with developmental behavioral conditions such as autism. Although recent advances have been made in building more accurate emotion classifiers, existing models are too computationally expensive to be deployed on mobile devices. In this study, we optimized and profiled various machine learning models designed for inference on edge devices and were able to match previous state of the art results for emotion recognition on children. Our best model, a MobileNet-V2 network pre-trained on ImageNet, achieved 65.11% balanced accuracy and 64.19% F1-score on CAFE, while achieving a 45-millisecond inference latency on a Motorola Moto G6 phone. This balanced accuracy is only 1.79% less than the current state of the art for CAFE, which used a model that contains 26.62x more parameters and was unable to run on the Moto G6, even when fully optimized. This work validates that with specialized design and optimization techniques, machine learning models can become lightweight enough for deployment on mobile devices and still achieve high accuracies on difficult image classification tasks. Keywords—edge computing, autism spectrum disorder, mobile health, computer vision",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d34f4d5b745f49f422f90c2d49103fcc234e5ff7,https://www.semanticscholar.org/paper/d34f4d5b745f49f422f90c2d49103fcc234e5ff7,Deploying an Artificial Intelligence System for COVID-19 Testing at the Greek Border,"On July 1st, 2020, members of the European Union gradually lifted earlier COVID-19 restrictions on non-essential travel. In response, we designed and deployed “EVA” – a novel, self-learning artificial intelligence system – across all Greek borders to identify asymptomatic travelers infected with SARS-CoV-2 based on demographic characteristics and results from previously tested travelers. EVA allocates Greece’s limited testing resources to (i) limit the importation of new cases and (ii) provide real-time estimates of COVID-19 prevalence to inform border policies. 
 
Counterfactual analysis shows that our system identified on average 1.85x as many asymptomatic, infected travelers as random surveillance testing, and up to 2-4x as many during peak travel. Moreover, for most countries, EVA identified atypically high prevalence 9-days earlier than machine learning systems based on publicly reported data. By adaptively adjusting border policies 9-days earlier, EVA prevented additional infected travelers from arriving. 
 
Finally, using EVA’s unique cross-country, large-scale dataset on prevalence in asymptomatic populations, we show that commonly used public data on cases/deaths/testing have limited predictive value for the prevalence among asymptomatic travelers, and furthermore exhibit strong country-specific idiosyncrasies. As herd immunity is still likely more than a year away [1], and travel protocols for the summer of 2021 are still being discussed, our insights raise serious concerns about internationally proposed border control policies [2] that are both country-agnostic and solely based on public data. Instead, our work paves the way for leveraging AI and real-time data for public health goals, such as border control during a pandemic.",,2021,10.2139/SSRN.3789038,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
249685efbf5a8151f640c275066e5c8f9ce46547,https://www.semanticscholar.org/paper/249685efbf5a8151f640c275066e5c8f9ce46547,Artificial intelligence - The promise for an agricultural revolution in new era,"Agriculture is slowly becoming digital. The adoption of Artificial Intelligence (AI) and Machine Learning (ML) both in terms of agricultural products and in-field farming techniques are increasing. Artificial Intelligence in agriculture is emerging in three major areas, namely agricultural robotics, soil and crop monitoring and predictive analytics. The use of sensors and soil sampling techniques are increasing day by day which helps in gathering of data. In turn, this data is stored in farm management system which is better processed and analysed. Thus, the data available along with other related data paves a way to successfully deploy AI in agriculture. AI in agriculture is emergingin cognitive computing and it has all the scope to become the most disruptive technology in agriculture services as it is able to understand, learn and respond to different situations (based on learning) to increase efficiency. The areas where the use of cognitive solutions can benefit agriculture are growth driven by IOT, image-based insight generation, identification of optimal mix for agronomic products, health monitoring of crops and automation techniques in irrigation and enabling farmers. In addition, the drone based solutions have significant impact in terms of productivity gains, coping with adverse weather conditions, yield management and precision farming.The emergence of new age technologies like Artificial Intelligence (AI), Cloud Machine Learning, Satellite Imagery and advanced analytics are creating an ecosystem for smart farming. Fusion of all this technology is enabling farmers achieve higher average yield and better price control.",AGRICULTURE UPDATE,2020,10.15740/has/au/15.4/435-437,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64d3f534c2cfa83110f82d092b266167d450c95d,https://www.semanticscholar.org/paper/64d3f534c2cfa83110f82d092b266167d450c95d,Biomedical and health informatics approaches remain essential for addressing the COVID-19 pandemic,"As this March issue of the Journal of the American Medical Informatics Association (JAMIA) is published, we have experienced a year of sheltering-in-place, wearing masks, frequent handwashing, and COVID-19 testing. For some of us, this year also included COVID-19 infection and loss of family, friends, and colleagues— and more recently, COVID-19 vaccination. I accepted JAMIA’s first COVID-related paper on March 19, 2020 less than 24 hours after its submission, and the accepted version was available online within days. To date, JAMIA has received almost 400 COVIDrelated submissions and published 69 contributions in issues since June 2020. The March issue includes 7 papers and correspondence related to COVID-19 including a call from World Health Organization authors to strengthen data in response to COVID-19 and beyond, a report on virtual care expansion in the Veterans Health Administration, and correspondence about telemedicine, privacy, and information security in the age of COVID-19. In this editorial, I highlight 5 papers that reflect the breadth of biomedical and health informatics approaches to addressing the COVID-19 pandemic. Haendel and colleagues provide an overview of the rationale, design, infrastructure, and deployment of the National COVID Cohort Collaborative (N3C). N3C (covid.cd2h.org), an open science community focused on analyzing individual-level data from many centers, was developed by the Clinical and Translational Award Program, the National Center for Translational Sciences, and the scientific community to enable rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and subsequently reduce the immediate and long-term consequences of COVID-19. To overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data, N3C developed (a) legal agreements and governance for organizations and researchers; (b) data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; (c) a data quality assurance and harmonization pipeline to create a single harmonized dataset; (d) a secure data enclave with data, machine learning, and statistical analytics tools; (e) dissemination mechanisms; and (f) a synthetic data pilot to democratize data access. There are 3 datasets for analysis: synthetic, deidentified, and limited. The Attribution and Publication Policy encompasses all N3C contributions as reflected in the author contribution statement for this paper. Analyses posted within the N3C enclave leverage the contributor attribution model to track the transitive credit of all upstream contributors. The N3C infrastructure is designed to be scalable and extensible to other topics. Sun and colleagues designed COVID-19 Trial Finder, an opensource semantic search engine, to facilitate patient-centered search of COVID-19 trials. It is powered by a machine-readable dataset for all COVID-19 trials in the United States. COVID-19 Trial Finder also includes a web-based visualization of the geographic distribution of COVID-19 trials. The initial search is by location and radius distance from trial sites; this is refined through a set of dynamically generated medical questions to assess patient eligibility for nearby COVID-19 trials. They assessed the precision of COVID-19 Trial Finder for COVID19 using 20 case reports from LitCOVID. Overall precision across the 20 cases was 79.76%, although it varied widely across cases. The major factor contributing to imprecision was the inability to generate relevant questions in some instances which prevented filtering out irrelevant trials. The system (https://covidtrialx.dbmi.columbia.edu) and its source code (https://github.com/WengLab-InformaticsResearch/COVID19-TrialFinder) are accessible online. Hassandoust, Akhaghpour, and Johnson examine individual privacy concerns and intention to adopt contact tracing mobile applications through a situational privacy calculus model. Using structural equation modeling and a national sample (N1⁄4853) of survey",J. Am. Medical Informatics Assoc.,2021,10.1093/jamia/ocab007,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f39b6e464a445439e1bf3fe5d0fa40009da3944e,https://www.semanticscholar.org/paper/f39b6e464a445439e1bf3fe5d0fa40009da3944e,An Internet-of-Things Solution to Assist Independent Living and Social Connectedness in Elderly,"Social isolation has been identified as a major risk in elderly people living alone because of their association with cognitive decline, depression, and other mental health-related issues. Ambient Assisted Living (AAL) is identified as a key technology to facilitate independent living and maintain social connnectedness between elderly, their families, and caregivers. AAL combines Internet of Things, Smart Homes, and machine learning to produce a smart solution that encourages independent, safe, and socially active life for elderly people within their own home. In this article, we propose, develop, implement, and validate a novel Internet-of-Things-based solution that uses passive (i.e., non-obstructive methods) sensing for real-time monitoring of elderly in their homes. The significance of the proposed solution is in the use of machine learning and statistical models to automatically build a personalised model by learning the normal behavioural pattern for the person from deployed sensors in the house. It then uses this model to detect significant changes in the behavioural pattern, should they occur, that could be a consequence of possible health deterioration. We evaluate the performance of the proposed solution via real-world in-home trials installed in six elderly people’s home for a period from 1.5 to 4 months. A discussion and analysis of the in-home trial outcomes and feedback from elderly who participated in the trials conclude the article.",ACM Trans. Soc. Comput.,2019,10.1145/3363563,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a89157d830d7c2a57d383c014bcc032a9c77745,https://www.semanticscholar.org/paper/3a89157d830d7c2a57d383c014bcc032a9c77745,Trust Issues: Uncertainty Estimation Does Not Enable Reliable OOD Detection On Medical Tabular Data,"When deploying machine learning models in high-stakes real-world environments such as health care, it is crucial to accurately assess the uncertainty concerning a model's prediction on abnormal inputs. However, there is a scarcity of literature analyzing this problem on medical data, especially on mixed-type tabular data such as Electronic Health Records. We close this gap by presenting a series of tests including a large variety of contemporary uncertainty estimation techniques, in order to determine whether they are able to identify out-of-distribution (OOD) patients. In contrast to previous work, we design tests on realistic and clinically relevant OOD groups, and run experiments on real-world medical data. We find that almost all techniques fail to achieve convincing results, partly disagreeing with earlier findings.",ML4H@NeurIPS,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2849cebd934da48df0baa44dd74fda0fce473b3a,https://www.semanticscholar.org/paper/2849cebd934da48df0baa44dd74fda0fce473b3a,EHR-Independent Predictive Decision Support Architecture Based on OMOP,"Background  The increasing availability of molecular and clinical data of cancer patients combined with novel machine learning techniques has the potential to enhance clinical decision support, example, for assessing a patient's relapse risk. While these prediction models often produce promising results, a deployment in clinical settings is rarely pursued. Objectives  In this study, we demonstrate how prediction tools can be integrated generically into a clinical setting and provide an exemplary use case for predicting relapse risk in melanoma patients. Methods  To make the decision support architecture independent of the electronic health record (EHR) and transferable to different hospital environments, it was based on the widely used Observational Medical Outcomes Partnership (OMOP) common data model (CDM) rather than on a proprietary EHR data structure. The usability of our exemplary implementation was evaluated by means of conducting user interviews including the thinking-aloud protocol and the system usability scale (SUS) questionnaire. Results  An extract-transform-load process was developed to extract relevant clinical and molecular data from their original sources and map them to OMOP. Further, the OMOP WebAPI was adapted to retrieve all data for a single patient and transfer them into the decision support Web application for enabling physicians to easily consult the prediction service including monitoring of transferred data. The evaluation of the application resulted in a SUS score of 86.7. Conclusion  This work proposes an EHR-independent means of integrating prediction models for deployment in clinical settings, utilizing the OMOP CDM. The usability evaluation revealed that the application is generally suitable for routine use while also illustrating small aspects for improvement.",Appl. Clin. Inform.,2020,10.1055/s-0040-1710393,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f2607e52bf3f6badba25d69ce4b04688cfe22513,https://www.semanticscholar.org/paper/f2607e52bf3f6badba25d69ce4b04688cfe22513,Artificial intelligence for diabetic retinopathy screening: a review,,Eye,2019,10.1038/s41433-019-0566-0,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d38e744492478dfc3d5bd6eab7923b3979157f33,https://www.semanticscholar.org/paper/d38e744492478dfc3d5bd6eab7923b3979157f33,"Validation of Artificial Intelligence to Support the Automatic Coding of Patient Adverse Drug Reaction Reports, Using Nationwide Pharmacovigilance Data",,Drug Safety,2022,10.1007/s40264-022-01153-8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7fb365d6a956c0dc1d992dd3ba97704683e6cd65,https://www.semanticscholar.org/paper/7fb365d6a956c0dc1d992dd3ba97704683e6cd65,Deep Learning Algorithms for Detection of Lymph Node Metastases From Breast Cancer: Helping Artificial Intelligence Be Seen.,"Artificial intelligence (AI), the theory and development of computer systems able to perform tasks that normally require human intelligence, is creeping into almost every facet of modern life. Familiar examples include computer chess games, speech recognition, intelligent routing in content delivery networks, and autonomous driving cars. In the financial sector, AI is routinely used for fraud detection, algorithmic trading, and chatbots (ie, computer programs that appear to conduct conversations via auditory or textual methods, such as with online virtual assistants). Health care has been slower to adopt AI but the pace of implementation is accelerating at an impressive rate. In 2014, the acquisition of AI startups in health care was about $600 million; in 2021, it is anticipated to be $6.6 billion or a 40% compound annual growth rate.1 One reason health care is ripe for AI is “big data”: the health care industry has rich data sets that are ideal for AI given the requirement for large test sets of data with which the computer can “learn.” Most computer modeling enhancements in health care, particularly in the image analysis field, have focused on feature engineering, essentially asking a computer to evaluate explicit features specified by experts. This permits the algorithms to detect abnormalities or predict specified lesions. In contrast, deep learning is a form of AI that includes machine learning techniques that perform iterative optimization strategies that are based on pixel-by-pixel evaluation of the data from images.2 The promise of AI in health care is the delivery of improved quality and safety of care and the potential to democratize expertise. For example, in a study by Esteva et al,3 the authors compared the ability of a deep convolutional neural network (CNN) to discriminate the most common skin cancers including malignant melanoma. They compared and demonstrated at least equivalence in the performance of their algorithm against 21 board-certified dermatologists in evaluating biopsy-proven clinical images. In this example, AI was used to discriminate whether skin lesions were malignant. The authors suggested that mobile devices, like smartphones, could be deployed with similar algorithms, permitting potentially low-cost universal access to vital diagnostic care anywhere in the world. In another study, Gulshan et al4 applied a deep CNN approach to a test set of more than 128 000 retinal fundus images from adult patients with diabetes to identify referable diabetic retinopathy. The algorithm developed had very high sensitivity and specificity for detecting referable diabetic retinopathy and macular edema.4 This study established a clear path toward use of AI not to replace physicians, but rather to perform simple, cost-effective, and widely available examinations and analyses that could help identify at-risk patients who require referral for specialty care while reassuring other patients that potential retinal manifestations of their diabetes are not present or are stable. Radiology, having converted to digital images more than 25 years ago, is well-positioned to deploy AI for diagnostics. Several studies have shown considerable opportunity to support radiologists in evaluating a variety of scan types including mammography for breast lesions, computed tomographic scans for pulmonary nodules and infections, and magnetic resonance images for brain tumors including the molecular classification of brain tumors.5-9 In contrast to radiology, pathology has been late to adopt digital imaging and thus computer-assisted diagnostic technologies. In part, this is the result of practical and financial obstacles. With conversion to digital images, radiology eliminated film, chemicals, developers, and storage of the films. Radiology departments also solved problems related to loss of films and transport of films to where they are needed, for example, in operating rooms, emergency departments, and intensive care units. Unforeseen at the time, although anticipated by some, was the inherent value within these images for greater learning using computers to improve the quality, safety, and efficiency of radiologists. Many, if not most, of the practical benefits realized by radiology would not be achieved with pathology digitization. An anatomic pathology workflow that includes digital pathology will not reduce or remove the need to produce and ultimately store glass slides of pathology specimens. Instead of any reductions, digital pathology will require additional workflows, personnel, equipment, and importantly storage of data (it is estimated that digital pathology images are at least 10 times larger files than radiology images), all on top of an already financially and operationally stressed health care system. Certainly, the adoption of digital pathology will bring some advantages, particularly in areas such as rapid teleconsultations with experts and in quality and safety. Nonetheless, Author Video Interview and JAMA Report Video",JAMA,2017,10.1001/jama.2017.14580,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6b55f3092449e71b5e88bac1323f13e2bddce639,https://www.semanticscholar.org/paper/6b55f3092449e71b5e88bac1323f13e2bddce639,Telemedicine in the ICU: Innovation in the Critical Care Process,"Tele-ICU is a technology-based model designed to deliver effective critical care in the intensive care unit (ICU). The tele-ICU system has been developed to address the increasing demand for intensive care services and the shortage of intensivists. A finite number of intensivists from remote locations provide real-time services to multiple ICUs and assist in the treatment of critically ill patients. Risk prediction algorithms, smart alarm systems, and machine learning tools augment conventional coverage and can potentially improve the quality of care. Tele-ICU is associated with substantial improvements in mortality, reduced hospital and ICU length of stay, and decreased health care costs. Although multiple studies show improved outcomes following the implementation of tele-ICU, results are not consistent. Several factors, including the heterogeneity of tele-ICU infrastructure deployed in different facilities and the reluctance of health care workers to accept tele-ICU, could be associated with these varied results. Considerably high installation and ongoing operational costs might also be limiting the widespread utilization of this innovative service. While we believe that the implementation of tele-ICU offers potential advantages and makes critical care delivery more efficient, further research on the impact of this technology in critical care settings is warranted.",Journal of intensive care medicine,2020,10.1177/0885066620968518,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e56b457e93a7b4e85da3d6568b8cbcb9ca1163dc,https://www.semanticscholar.org/paper/e56b457e93a7b4e85da3d6568b8cbcb9ca1163dc,"Assessment of the Feasibility of automated, real-time clinical decision support in the emergency department using electronic health record data",,BMC Emergency Medicine,2018,10.1186/s12873-018-0170-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
315acb4dece97c44e54e5ada981f68ed4e780d90,https://www.semanticscholar.org/paper/315acb4dece97c44e54e5ada981f68ed4e780d90,Digital Transformation in Smart Farm and Forest Operations Needs Human-Centered AI: Challenges and Future Directions,"The main impetus for the global efforts toward the current digital transformation in almost all areas of our daily lives is due to the great successes of artificial intelligence (AI), and in particular, the workhorse of AI, statistical machine learning (ML). The intelligent analysis, modeling, and management of agricultural and forest ecosystems, and of the use and protection of soils, already play important roles in securing our planet for future generations and will become irreplaceable in the future. Technical solutions must encompass the entire agricultural and forestry value chain. The process of digital transformation is supported by cyber-physical systems enabled by advances in ML, the availability of big data and increasing computing power. For certain tasks, algorithms today achieve performances that exceed human levels. The challenge is to use multimodal information fusion, i.e., to integrate data from different sources (sensor data, images, *omics), and explain to an expert why a certain result was achieved. However, ML models often react to even small changes, and disturbances can have dramatic effects on their results. Therefore, the use of AI in areas that matter to human life (agriculture, forestry, climate, health, etc.) has led to an increased need for trustworthy AI with two main components: explainability and robustness. One step toward making AI more robust is to leverage expert knowledge. For example, a farmer/forester in the loop can often bring in experience and conceptual understanding to the AI pipeline—no AI can do this. Consequently, human-centered AI (HCAI) is a combination of “artificial intelligence” and “natural intelligence” to empower, amplify, and augment human performance, rather than replace people. To achieve practical success of HCAI in agriculture and forestry, this article identifies three important frontier research areas: (1) intelligent information fusion; (2) robotics and embodied intelligence; and (3) augmentation, explanation, and verification for trusted decision support. This goal will also require an agile, human-centered design approach for three generations (G). G1: Enabling easily realizable applications through immediate deployment of existing technology. G2: Medium-term modification of existing technology. G3: Advanced adaptation and evolution beyond state-of-the-art.",Sensors,2022,10.3390/s22083043,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6ea59f72f3239e524b7fb5d09eaf2fc9638cb018,https://www.semanticscholar.org/paper/6ea59f72f3239e524b7fb5d09eaf2fc9638cb018,Ai Technology Achieving General Purpose Ai That Can,"Artificial IntelligenceArtificial Intelligence in Cyber Security: Impact and ImplicationsTechnological Progress, Artificial Intelligence, and Inclusive GrowthEnergy Research AbstractsCan Artificial Intelligence ImproveHandbook of Pharmaceutical Granulation TechnologyArtificial Intelligence for BusinessArtificial Intelligence in EducationThe Democratization of Artificial IntelligenceAdvances in Artificial Intelligence, Software and Systems EngineeringFinancing Our FutureProceedings of the Future Technologies Conference (FTC) 2021, Volume 1Artificial IntelligenceNew Technologies in Dermatological Science and PracticeArtificial IntelligenceGame Theory and Machine Learning for Cyber SecurityRegulatory Aspects of Artificial Intelligence on BlockchainConcise Encyclopedia of Software EngineeringEuropean Artificial Intelligence (AI) Leadership, the Path for an Integrated VisionAI In The Age Of Cyber-DisorderReadings in Artificial Intelligence and DatabasesHuman decisionsConstitution 3.0Artificial Intelligence and IoT-Based Technologies for Sustainable Farming and Smart AgricultureArtificial Intelligence and Deep Learning for Decision MakersThe Regional Economics of Technological TransformationsArchitects of IntelligenceArtificial IntelligenceArtificial Intelligence and Integrated Intelligent Information SystemsECIAIR 2019 European Conference on the Impact of Artificial Intelligence and Robotics Intelligence UnboundHow to Achieve Inclusive GrowthArtificial Intelligence for Business OptimizationArtificial Intelligence in SocietyThe Myth of Artificial IntelligenceThe Digital Innovation RaceAI-First HealthcareProject Management Best Practices: Achieving Global ExcellenceConnected WorldBiotechnology: Concepts, Methodologies, Tools, and Applications The interaction of database and AI technologies is crucial to such applications as data mining, active databases, and knowledge-based expert systems. This volume collects the primary readings on the interactions, actual and potential, between these two fields. The editors have chosen articles to balance significant early research and the best and most comprehensive articles from the 1980s. An in-depth introduction discusses basic research motivations, giving a survey of the history, concepts, and terminology of the interaction. Major themes, approaches and results, open issues and future directions are all discussed, including the results of a major survey conducted by the editors of current work in industry and research labs. Thirteen sections follow, each with a short introduction. Topics examined include semantic data models with emphasis on conceptual modeling techniques for databases and information systems and the integration of data model concepts in high-level data languages, definition and maintenance of integrity constraints in databases and knowledge bases, natural language front ends, object-oriented database management systems, implementation issues such as concurrency control and error recovery, and representation of time and knowledge incompleteness from the viewpoints of databases, logic programming, and AI.The artificial intelligence (AI) landscape has evolved significantly from 1950 when Alan Turing first posed the question of whether machines can think. Today, AI is transforming societies and economies. It promises to generate productivity gains, improve well-being and help address global challenges, such as climate change, resource scarcity and health crises.As technology continues to saturate modern society, agriculture has started to adopt digital computing and data-driven innovations. This emergence of “smart” farming has led to various advancements in the field, including autonomous equipment and the collection of climate, livestock, and plant data. As connectivity and data management continue to revolutionize the farming industry, empirical research is a necessity for understanding these technological developments. Artificial Intelligence and IoT-Based Technologies for Sustainable Farming and Smart Agriculture provides emerging research exploring the theoretical and practical aspects of critical technological solutions within the farming industry. Featuring coverage on a broad range of topics such as crop monitoring, precision livestock farming, and agronomic data processing, this book is ideally designed for farmers, agriculturalists, product managers, farm holders, manufacturers, equipment suppliers, industrialists, governmental professionals, researchers, academicians, and students seeking current research on technological applications within agriculture and farming.This book constitutes the refereed proceedings of the Second International Conference, SLAAI-ICAI 2018, held in Moratuwa, Sri Lanka, in December 2018. The 32 revised full papers presented were carefully reviewed and selected from numerous submissions. The papers are organized in the following topical sections: ?intelligence systems; neural networks; game theory; ontology engineering; natural language processing; agent based system; signal and image processing.After a long time of neglect, Artificial Intelligence is once again at the center of most of our political, economic, and socio-cultural debates. Recent advances in the field of Artifical Neural Networks have led to a renaissance of dystopian and utopian speculations on an AI-rendered future. Algorithmic technologies are deployed for identifying potential terrorists through vast surveillance networks, for producing sentencing guidelines and recidivism risk profiles in criminal justice systems, for demographic and psychographic targeting of bodies for advertising or propaganda, and more generally for automating the analysis of language, text, and images. Against this background, the aim of this book is to discuss the heterogenous conditions, implications, and effects of modern AI and Internet technologies in terms of their political dimension: What does it mean to critically investigate efforts of net politics in the age of machine learning algorithms?Intelligence Unbound explores the prospects, promises, and potential dangers of machine intelligence and uploaded minds in a collection of stateof-the-art essays from internationally recognized philosophers, AI researchers, science fiction authors, and theorists. Compelling and intellectually sophisticated exploration of the latest thinking on Artificial Intelligence and machine minds Features contributions from an international cast of philosophers, Artificial Intelligence researchers, science fiction authors, and more Offers current, diverse perspectives on machine intelligence and uploaded minds, emerging topics of tremendous interest Illuminates the nature and ethics of tomorrow’s machine minds—and of the convergence of humans and machines—to consider the pros and cons of a variety of intriguing possibilities Considers classic philosophical puzzles as well as the latest topics debated by scholars Covers a wide range of viewpoints and arguments regarding the prospects of uploading and machine intelligence, including proponents and skeptics, pros and consCompanies that don't use AI to their advantage will soon be left behind. Artificial intelligence and machine learning will drive a massive reshaping of the economy and society. What should you and your company be doing right now to ensure that your business is poised for success? These articles by AI experts and consultants will help you understand today's essential thinking on what AI is capable of now, how to adopt it in your organization, and how the technology is likely to evolve in the near future. Artificial Intelligence: The Insights You Need from Harvard Business Review will help you spearhead important conversations, get going on the right AI initiatives for your company, and capitalize on the opportunity of the machine intelligence revolution. Catch up on current topics and deepen your",,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2c7e46ef2cc83d7cd0343f8e807cff590eca5a9f,https://www.semanticscholar.org/paper/2c7e46ef2cc83d7cd0343f8e807cff590eca5a9f,Construction and Application of an Intelligent Response System for COVID-19 Voice Consultation in China: A Retrospective Study,"Background: The outbreak of novel coronavirus disease 2019 (COVID-19) has led to tremendous individuals visit medical institutions for healthcare services. Public gatherings and close contact in clinics and emergency departments may increase the exposure and cross-infection of COVID-19. Objectives: The purpose of this study was to develop and deploy an intelligent response system for COVID-19 voice consultation, to provide suggestions of response measures based on actual information of users, and screen COVID-19 suspected cases. Methods: Based on the requirements analysis of business, user, and function, the physical architecture, system architecture, and core algorithms are designed and implemented. The system operation process is designed according to guidance documents of the National Health Commission and the actual experience of prevention, diagnosis and treatment of COVID-19. Both qualitative (system construction) and quantitative (system application) data from the real-world healthcare service of the system were retrospectively collected and analyzed. Results: The system realizes the functions, such as remote deployment and operations, fast operation procedure adjustment, and multi-dimensional statistical report capability. The performance of the machine-learning model used to develop the system is better than others, with the lowest Character Error Rate (CER) 8.13%. As of September 24, 2020, the system has received 12,264 times incoming calls and provided a total of 11,788 COVID-19-related consultation services for the public. Approximately 85.2% of the users are from Henan Province and followed by Beijing (2.5%). Of all the incoming calls, China Mobile contributes the largest proportion (66%), while China Unicom and China Telecom are accounted for 23% and 11%. For the time that users access the system, there is a peak period in the morning (08:00–10:00) and afternoon (14:00–16:00), respectively. Conclusions: The intelligent response system has achieved appreciable practical implementation effects. Our findings reveal that the provision of inquiry services through an intelligent voice consultation system may play a role in optimizing the allocation of healthcare resources, improving the efficiency of medical services, saving medical expenses, and protecting vulnerable groups.",Frontiers in Medicine,2021,10.3389/fmed.2021.781781,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
99d72202999460543e6b7c1a82fd171ee187cfcb,https://www.semanticscholar.org/paper/99d72202999460543e6b7c1a82fd171ee187cfcb,Biomedical and health informatics continue to contribute to COVID-19 pandemic solutions and beyond,"As I write this editorial in May of 2021, there are broad indications of reopening and decreasing COVID-19 pandemic restrictions in the US, while there are major pandemic hotspots globally. Like many others, I am hopeful that the lessons from the pandemic can be applied to major public health issues in the future. How transferrable are the theories, models, algorithms, and informatics-based solutions that we’ve developed? Through the years, we’ve certainly argued that this is a fundamental characteristic of informatics as a scientific field. I highlight 5 COVID-related studies in this issue, and I ask you to reflect, as I have done, on the key lessons for the future. In partnership with state and local public health agencies as well as health systems, Dixon et al describe the development and implementation of population-level dashboards that are deployed on top of a statewide health information exchange. Two dashboards collate information on individuals tested for and infected with COVID19. The primary dashboard enables authorized users working in public health agencies to monitor populations in detail. In contrast, a public version provides higher-level situational awareness to inform ongoing pandemic response efforts in communities. Over the span of 2 months, the dashboards were accessed by 74 317 distinct users, indicating substantial use. In terms of usefulness, the private dashboard enabled detection of a local community outbreak associated with a meat-packing plant. The authors call for continued investment in a statewide health information exchange as a critical component of public health infrastructure. Klann and co-authors describe the development and validation of a computable phenotype for COVID-19 severity by the Consortium for Clinical Characterization of COVID-19 by EHR (4CE). 4CE is an international collaboration that is addressing COVID-19 through federated analyses of electronic health record (EHR) data. They developed an EHR-based severity phenotype, consisting of 6 code classes using patient hospitalization data, and validated the phenotype in twelve 4CE international sites against the outcomes of intensive care unit admission and/or death. The full 4CE severity phenotype developed by experts had a pooled sensitivity of 0.73 and specificity 0.83 for the combined outcome of intensive care unit admission and/or death; however, the sensitivity of individual code categories for acuity had high variability. The authors also conducted a pilot in 1 site in which they compared selected predictors of severity between a machine learning approach and the 4CE phenotype with mean areas under the curve reported as 0.956 (95% confidence interval, 0.952–0.959) and 0.903 (95% confidence interval, 0.886– 0.921), respectively. The authors suggest that the severity phenotype comprising 6 code classes was resilient to coding variability across institutions, but they raised the concern that machine learning approaches may overfit hospital-specific orders. These findings contribute to the literature about generic vs institution-specific approaches. Malden, Heeney, Bates, and Sheikh conducted a qualitative study to develop an in-depth understanding of how hospitals with a long history of health information technology (HIT) use responded to the COVID-19 pandemic from an HIT perspective. Informed by a topic guide, they interviewed 44 healthcare professionals with a background in informatics from 6 hospitals internationally via videoconference. They applied thematic analysis to develop a coding framework and identify emerging themes. This resulted in 3 themes and 6 subthemes. Key findings included (a) HIT was employed to manage time and resources during a surge in patient numbers through fast-tracked governance procedures and the creation of real-time bed capacity tracking within EHRs; (b) improving the integration of different hospital systems was important across sites; (c) use of hard-stop alerts and order sets was perceived as effective in helping to respond to potential medication shortages and select available drug treat-",J. Am. Medical Informatics Assoc.,2021,10.1093/jamia/ocab130,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6f6169151f17a392481b4f8c597555a532b0e81a,https://www.semanticscholar.org/paper/6f6169151f17a392481b4f8c597555a532b0e81a,Social media monitoring of mental health during disasters: A scoping review of methods and applications,"BackgroundDifficulties in deploying mental health assessments during disasters have resulted in emerging research examining the use of social media as a population mental health monitoring tool. This review synthesises this literature, with particular focus on research methods and applications.MethodsThe field of social media monitoring of mental health during disasters was rapidly mapped using a scoping review methodology. Six interdisciplinary research databases were searched for relevant articles, with data extracted on the articles’ applications and data collection and analysis methods. Articles were then synthesised via narrative review.ResultsForty-seven papers were identified. Three application themes emerged, including: (i) estimating mental health burden; (ii) planning or evaluating interventions and policies, and (iii) knowledge discovery, where theories of human behaviour and mental health were evaluated. Applications across 30 mental health issues were identified, with mental health typically assessed using established linguistic dictionaries. Features extracted from social media data included linguistic, psycholinguistic, behavioural, and demographic features. Analytic techniques involved machine learning, statistical modelling, and qualitative analyses.ConclusionsThe application of social media monitoring has considerable potential for measuring the mental health impact on populations during disasters. As an emerging field, opportunities for further work were identified to improve mental health assessment methods, examine specific mental health conditions, and trial tools in real-world settings. Platforms integrated with such techniques may offer significant benefits for monitoring mental health in contexts where formal assessments are difficult to deploy, and may potentially be harnessed to monitor the impact of response efforts and intervention delivery.",,2021,10.31234/OSF.IO/YKZ2N,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a9a8102602d23954e0e8dd457209e5ef9e4b052,https://www.semanticscholar.org/paper/2a9a8102602d23954e0e8dd457209e5ef9e4b052,Deployment of a Free-Text Analytics Platform at a UK National Health Service Research Hospital: CogStack at University College London Hospitals,"As more healthcare organisations transition to using electronic health record (EHR) systems it is important for these organisations to maximise the secondary use of their data to support service improvement and clinical research. These organisations will find it challenging to have systems which can mine information from the unstructured data fields in the record (clinical notes, letters etc) and more practically have such systems interact with all of the hospitals data systems (legacy and current). To tackle this problem at University College London Hospitals, we have deployed an enhanced version of the CogStack platform; an information retrieval platform with natural language processing capabilities which we have configured to process the hospital’s existing and legacy records. The platform has improved data ingestion capabilities as well as better tools for natural language processing. To date we have processed over 18 million records and the insights produced from CogStack have informed a number of clinical research use cases at the hospitals. Section 1: Introduction 4 Epic Systems Corporation 3 University College London Hospitals NHS Foundation Trust, Clinical Research Informatics Unit 2 King’s College London 1 University College London, Institute of Health Informatics Over the past twenty years we have seen an increased uptake of electronic health records (EHR) within healthcare organisations with much of this being attributable to national efforts in having healthcare organisations transition to using full EHR systems [1] [2]. These EHRs represent a rich data asset but there remains a challenge in secondary use of the data for improving clinical care through activities such as service improvement and clinical research. In many cases the EHRs have simply replicated the paper system that they replaced and have not taken full advantage of the opportunities presented in having the health records in this new electronic format. Whilst functional systems to address these gaps are emerging many of the tools and data analytic approaches used on EHR data are limited to structured data, such as coded diagnoses and numeric clinical measurements, despite almost 80% of information being recorded as unstructured free text [10] (such as clinical notes, imaging reports and transfer of care documents). An additional difficulty is that a hospital’s record is typically distributed across numerous disconnected data systems which presents a challenge in data harmonisation. Working with EHRs thus presents a challenge firstly in harmonising and accessing the hospitals entire record from both existing and legacy data systems and secondly having tools and techniques available to mine and extract data from within these records; especially the unstructured free text. Manual analysis of unstructured text is time-consuming, so there has been much interest in developing automated methods for extracting accurate structured information from the text. Interpreting free text is a major analytic challenge; clinical text is written in a variety of styles by numerous authors, and may have mis-spellings, negations and information which does not relate to the patient. There has been intense interest in developing natural language processing techniques to interpret clinical text. Early methods used a rule-based approach, but more modern algorithms incorporate machine learning techniques, enabling the algorithms to ‘learn’ as more data is analysed. The CogStack platform [6] was developed to address these exact problems. The platform can be described as an information retrieval (IR) system designed to interface with a hospital’s EHR system. It was initially developed with an emphasis on ingestion and harmonisation of records from multiple data systems within a healthcare organisation. Whilst certain off the shelf natural language processing (NLP) tools were explored in the first iteration they were added as a proof of concept to demonstrate that the platform could potentially be configured to interact with such tools. In this paper we discuss the deployment of CogStack at University College London Hospital (UCLH) and the improvements introduced to the platform to ensure that platform scales to meet the growing research demands of the hospital. Our deployment has focused on addressing the following three key issues which need to be universally addressed at all research driven healthcare organisations. Multiple Data Systems: The EHRs of an organisation will typically be distributed across a number of different vendor systems, posing a challenge for the use of this information for clinical care and research. It is not uncommon for an organisation to have to maintain oversight over a myriad of data systems and vendors due to the fact that different clinical specialties will have different requirements of how data needs to be stored and managed. The resulting heterogeneity in data means that it is challenging for the organisation to find a common data model or even process through which the organisation's entire record can be harmonised. Methods and systems through which data is stored, collected and retrieved have been improving in order to tackle this challenge. Most notably many NHS trusts have opted to transition into using full scale EHR systems (e.g. Epic) each of which typically enforce their own data models. Some systems such as Epic go further in providing additional systems that allow data from third party data and legacy systems to be integrated with data collected via their own systems (Epic Clarity/Caboodle). Messaging standards (e.g. HL7 FHIR5 ), standardised terminologies (e.g SNOMED CT ) and standardised clinical information models (such as openEHR archetypes6) aim to improve interoperability between systems, but much more work is needed in this area. In order to maximise the benefit of patient data, it is essential that clinicians and researchers can access data in a way that is flexible, easily adaptable and independent of the organisation’s choice of current and previous EHR systems. Multiple Data Formats: A patient’s record may be distributed across both scanned documents (pdfs), text documents (.doc files) as well as data stored in relational databases. Legacy documents for example will likely be stored as files and attachments whereas data that has been generated using a modern EHR system will likely be stored in a more structured way; possibly in a relational database. An IR system would thus need to be able to ingest and interact with records from all the various data formats used by the organisation. The CogStack platform provides a distributed architecture for document processing, including PDF to text conversion, or optical character recognition that may be needed prior to analysis of the text itself. Unstructured Text: A final issue is that data within the EHR systems is recorded in both structured and unstructured fields. Some information is inherently unstructured in nature and needs to be recorded as free text (e.g. patient stories), but even where structured fields are available, clinicians may not use them and enter the information in free text instead. For example, a recent audit in our Trust found that patients admitted with suspected or confirmed COVID-19 had only 62.3% of their key diagnoses and comorbidities recorded in the structured problem list [11]. In order to support use of clinical data at scale and for multiple stakeholders, a successful IR system should provide mechanisms through which the clinical information within the unstructured free text notes can be made available. The CogStack platform provides a convenient user interface for searching free text and invoking information extraction algorithms, presenting the results in a way that is easy to visualise and harness for downstream research or for reintegration as structured data back into the EHR. 6 https://www.openehr.org/ 5 https://www.hl7.org/fhir/overview.html",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d67664ba9d82cd5c2f24c492da0b901d38f4c266,https://www.semanticscholar.org/paper/d67664ba9d82cd5c2f24c492da0b901d38f4c266,"Introduction to the Special Issue on the Wearable Technologies for Smart Health, Part 2","Wearable health-tracking consumer products are gaining popularity, including smart watches, fitness trackers, smart clothing, and head-mounted devices. These wearable devices promise new opportunities for the study of health-related behavior, for tracking of chronic conditions, and for innovative interventions in support of health and wellness. Next-generation wearable technologies have the potential to transform today’s hospitalcentered healthcare practices into proactive, individualized care. Although it seems new technologies enter the marketplace every week, there is still a great need for research on the development of sensors, sensor-data analytics, wearable interaction modalities, and more. In this special issue, we sought to assemble a set of articles addressing novel computational research related to any aspect of the design or use of wearables in medicine and health, including wearable hardware design, AI and data analytics algorithms, human-device interaction, security/privacy, and novel applications. Here, in Part 2 of a two-part collection of articles on this topic, we are pleased to share four articles about the use of wearables for skill assessment, activity recognition, mood recognition, and deep learning. In the first article, Generalized and Efficient Skill Assessment from IMU Data with Applications in Gymnastics and Medical Training, Khan et al. propose a new framework for skill assessment that generalizes across application domains and can be deployed for different near-real-time applications. The effectiveness and efficiency of the proposed approach is validated in gymnastics and surgical skill training of medical students. In the next article, Privacy-preserving IoT Framework for Activity Recognition in Personal Healthcare Monitoring, Jourdan et al. propose a framework that uses machine learning to recognize the user activity, in the context of personal healthcare monitoring, while limiting the risk of users’ re-identification from biometric patterns that characterize an individual. Their solution trades off privacy and utility with a slight decrease of utility (9% drop in accuracy) against a large increase of privacy. Next, the article Perception Clusters: Automated Mood Recognition using a Novel Cluster-driven Modelling System proposes a mood-recognition system that groups individuals in “perception clusters” based on their physiological signals. This method can provide inference results that are more accurate than generalized models, without the need for the extensive training data necessary to build personalized models. In this regard, the approach is a compromise between generalized and personalized models for automated mood recognition (AMR). Finally, in an article about the Ensemble Deep Learning on Wearables Using Small Datasets, Ngu et al. describe an in-depth experimental study of Ensemble Deep Learning techniques on small time-series datasets generated by wearable devices, which is motivated by the fact that there are no publicly available, large, annotated datasets that can be used for training for some healthcare applications, such as the real-time fall detection. The offline experimental results show that an ensemble of Recurrent Neural Network (RNN) models outperforms a single RNN model and achieves a significantly higher precision without reducing much of the recall after re-training with real-world user feedback.",ACM Trans. Comput. Heal.,2021,10.1145/3442350,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
31ffad336bfc4d460c13f900bc3e05e1131e6644,https://www.semanticscholar.org/paper/31ffad336bfc4d460c13f900bc3e05e1131e6644,Frugal development and deployment of an innovative mobile health platform for COVID-19 in Sri Lanka: the case of SelfShield app,"© Author(s) (or their employer(s)) 2021. No commercial reuse. See rights and permissions. Published by BMJ. INTRODUCTION During the early phases of the COVID19 pandemic, emerging technologies focused largely on strengthening the health system, supporting law enforcement authorities, and enabling researchers to model COVID19 outbreaks and resource requirements. When the health systems are burdened by the influx of patients with COVID19, it is neither practical nor rational to treat all patients with COVID19 in the hospital as many will either be asymptomatic or mildly symptomatic. Thus, home monitoring of patients has been practised in many countries. 3 Respiratory involvement was the first documented site of complications and still continues to be responsible for majority of the deaths. Therefore, in order to provide effective home care for patients with COVID19, we recognised the need for a frugal technology tool to monitor patients remotely including monitoring the breathing performance. Guided by the Commonwealth Centre for Digital Health (CWCDH), a voluntary group of medical doctors, health informaticians and software developers from Sri Lanka embarked on a mission to fulfil this need by developing a smart phonebased selfhealth checking tool. Named the SelfShield project, the system comprised a smart phone app, a dashboard for medical teams and machine learning algorithms capable of analysing breathing and voice signals. This report reflects on our early experience with the SelfShield system and we were guided by the following key objectives: 1. Identifying already validated bedside clinical tests that may be cost effectively transformed into a mobile platform. 2. Designing and developing a mobile app to capture subjective and objective COVID19related data in a userfriendly manner and a dashboard that can help medical professionals assist consenting users. 3. Developing machine learning algorithms capable of analysing sound signals to facilitate decision making related to COVID19. 4. Deploying the system as a COVID19 response tool with a focus on citizen empowerment.",BMJ Innovations,2021,10.1136/bmjinnov-2021-000836,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d3fb359bf5a2d15bea601cc80c1deaaf520a596b,https://www.semanticscholar.org/paper/d3fb359bf5a2d15bea601cc80c1deaaf520a596b,ML-Based Device-Agnostic Human Activity Detection with WiFi Sniffer Traffic,"Human Activity Detection plays a pivotal role in smoothly managing the health care for the elderly and those with chronic health conditions in smart home environments. Even though there are several technological advancements made in this area, solutions like smartwatches are costly to afford and the solutions that rely on sensors and cameras suffer from privacy concerns. While wireless channel state information-based approaches can address some of these limitations, these approaches either require special hardware to be deployed or modifications at the WiFi access point. In this paper, we propose to detect human activities in a device-agnostic manner by leveraging passively captured passively captured WiFi MAC-layer traffic with the help of a sniffer. In that way, elderly people and those who suffer from chronic health conditions do not need to put any sensors on their body. This approach is not only cost-effective, but it is also easy to deploy without requiring any changes at the WiFi access point or installing special sensors in the environment. We train and test six off-the-shelf machine learning models on 15+ hours worth of WiFi MAC-layer traffic collected in a home environment. We present a proof-of-concept system prototype that employs this approach. We are able to detect six activities - (a) Walking vs Sitting, (b) Sleeping vs Awake, and (c) Using Phone vs Not Using Phone in three different real-world scenarios. Our evaluation reveals that WiFi MAC-layer traffic has special signatures to detect human activities and we are able to achieve 92.49 % detection accuracy in the best case.",2022 14th International Conference on COMmunication Systems & NETworkS (COMSNETS),2022,10.1109/COMSNETS53615.2022.9668420,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
156c0631d57905e83d80950fafba915576774109,https://www.semanticscholar.org/paper/156c0631d57905e83d80950fafba915576774109,Combined automated screening for age-related macular degeneration and diabetic retinopathy in primary care settings,"Background: Age-related macular degeneration (AMD) and diabetic retinopathy (DR) are among the leading causes of blindness in the United States and other developed countries. Early detection is the key to prevention and effective treatment. We have built an artificial intelligence-based screening system which utilizes a cloud-based platform for combined large scale screening through primary care settings for early diagnosis of these diseases. Methods: iHealthScreen Inc., an independent medical software company, has developed automated AMD and DR screening systems utilizing a telemedicine platform based on deep machine learning techniques. For both diseases, we prospectively imaged both eyes of 340 unselected non-dilated subjects over 50 years of age. For DR specifically, 152 diabetic patients at New York Eye and Ear faculty retina practices, ophthalmic and primary care clinics in New York city with color fundus cameras. Following the initial review of the images, 308 images with other confounding conditions like high myopia and vascular occlusion, and poor quality were excluded, leaving 676 eligible images for AMD and DR evaluation. Three ophthalmologists evaluated each of the images, and after adjudication, the patients were determined referrable or non-referable for AMD DR. Concerning AMD, 172 were labeled referable (intermediate or late), and 504 were non-referable (no or early). Concurrently, regarding DR, 33 were referable (moderate or worse), and 643 were non-referable (none or mild). All images were uploaded to iHealthScreen’s telemedicine platform and analyzed by the automated systems for both diseases. The system performances are tested on per eye basis with sensitivity, specificity, accuracy, and kappa scores with respect to the professional graders. Results: In identifying referable DR, the system achieved a sensitivity of 97.0% and a specificity of 96.3%, and a kappa score of 0.70 on this prospective dataset. For AMD, the sensitivity was 86.6%, the specificity of 92.1%, and a kappa score of 0.76. Conclusions: The AMD and DR screening tools achieved excellent performance operating together to identify two retinal diseases prospectively in mixed datasets, demonstrating the feasibility of such tools in the early diagnosis of eye diseases. These early screening tools will help create an even more comprehensive system capable of being trained on other retinal pathologies, a goal within reach for public health deployment.",Annals of eye science,2021,10.21037/aes-20-114,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0661300551477d3ab320164c4f57a4bcd1b3f59e,https://www.semanticscholar.org/paper/0661300551477d3ab320164c4f57a4bcd1b3f59e,Social Media as a Catalyst for Policy Action and Social Change for Health and Well-Being: Viewpoint,"This viewpoint paper argues that policy interventions can benefit from the continued use of social media analytics, which can serve as an important complement to traditional social science data collection and analysis. Efforts to improve well-being should provide an opportunity to explore these areas more deeply, and encourage the efforts of those conducting national and local data collection on health to incorporate more of these emerging data sources. Social media remains a relatively untapped source of information to catalyze policy action and social change. However, the diversity of social media platforms and available analysis techniques provides multiple ways to offer insight for policy making and decision making. For instance, social media content can provide timely information about the impact of policy interventions. Social media location information can inform where to deploy resources or disseminate public messaging. Network analysis of social media connections can reveal underserved populations who may be disconnected from public services. Machine learning can help recognize important patterns for disease surveillance or to model population sentiment. To fully realize these potential policy uses, limitations to social media data will need to be overcome, including data reliability and validity, and potential privacy risks. Traditional data collection may not fully capture the upstream factors and systemic relationships that influence health and well-being. Policy actions and social change efforts, such as the Robert Wood Johnson Foundation’s effort to advance a culture of health, which are intended to drive change in a network of upstream health drivers, will need to incorporate a broad range of behavioral information, such as health attitudes or physical activity levels. Applying innovative techniques to emerging data has the potential to extract insight from unstructured data or fuse disparate sources of data, such as linking health attitudes that are expressed to health behaviors or broader health and well-being outcomes.",Journal of medical Internet research,2018,10.2196/jmir.8508,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
42a7db85a7413589b9f1d258d23072a3d045cedd,https://www.semanticscholar.org/paper/42a7db85a7413589b9f1d258d23072a3d045cedd,Predictive analytics for data driven decision support in health and care,"Abstract Due to an ever-increasing amount of data generated in healthcare each day, healthcare professionals are more and more challenged with information. Predictive models based on machine learning algorithms can help to quickly identify patterns in clinical data. Requirements for data driven decision support systems for health and care (DS4H) are similar in many ways to applications in other domains. However, there are also various challenges which are specific to health and care settings. The present paper describes a) healthcare specific requirements for DS4H and b) how they were addressed in our Predictive Analytics Toolset for Health and care (PATH). PATH supports the following process: objective definition, data cleaning and pre-processing, feature engineering, evaluation, result visualization, interpretation and validation and deployment. The current state of the toolset already allows the user to switch between the various involved levels, i. e. raw data (ECG), pre-processed data (averaged heartbeat), extracted features (QT time), built models (to classify the ECG into a certain rhythm abnormality class) and outcome evaluation (e. g. a false positive case) and to assess the relevance of a given feature in the currently evaluated model as a whole and for the individual decision. This allows us to gain insights as a basis for improvements in the various steps from raw data to decisions.",it Inf. Technol.,2018,10.1515/itit-2018-0004,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f298c610975987727b3005a4d3cfa26fcf7fbbce,https://www.semanticscholar.org/paper/f298c610975987727b3005a4d3cfa26fcf7fbbce,A Decade of Internet of Things: Analysis in the Light of Healthcare Applications,"Impressive growth in the number of wearable health monitoring devices has affected global health industry as they provide rapid and intricate details related to physical examinations, such as discomfort, heart rate, and blood glucose level, which enable doctors to efficiently diagnose sensitive heart troubles. The Internet of Medical Things (IoMT) is a phenomenon wherein computer networks and medical equipment are connected through the Internet to provide real-time interaction between physicians and patients. In this article, we present a comprehensive view of the IoMT and its related Machine Learning (ML)-based developed frameworks designed, or being utilized, in the last decade, i.e., from 2010 to 2019. The presented techniques are designed for monitoring limbs, controlling rural healthcare, identifying e-health applications, monitoring health through mobile apps, classifying heart sounds, detecting stress in drivers, monitoring cardiac diseases, making the decision to predict heart attacks, recognizing human activities, and classifying breast cancer. The aim is to provide a clear picture of the existing IoMT environment so that the analysis may pave the way for the diagnosis of critical disorders such as cancer, heart attack, and blood pressure among others. In the end, we also provide some unresolved challenges that are confronted in the deployment of the secure IoMT-based healthcare systems.",IEEE Access,2019,10.1109/ACCESS.2019.2927082,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7bd08fd8b9ff2909d1babef89b36eb2ad20be607,https://www.semanticscholar.org/paper/7bd08fd8b9ff2909d1babef89b36eb2ad20be607,Discovery of cardiac imaging biomarkers by training neural network models across diagnostic modalities,"Machines can be readily trained to automate medical image interpretation, with the primary goal of replicating human capabilities. Here, we propose an alternative role: using machine learning to discover pragmatic imaging-based biomarkers by interpreting one complex imaging modality via a second, more ubiquitous, lower-cost modality. We applied this strategy to train convolutional neural network models to estimate positron emission tomography (PET)-derived myocardial blood flow (MBF) at rest and with hyperemic stress, and their ratio, coronary flow reserve (CFR), using contemporaneous two-dimensional echocardiography videos as inputs. The resulting parameters, echoAI-restMBF, echoAI-stressMBF, and echoAI-CFR modestly approximated the original values. However, using echocardiograms of 5,393 (derivation) and 5,289 (external validation) patients, we show they sharply stratify individuals according to disease comorbidities and combined with baseline demographics, are strong predictors for heart failure hospitalization (C-statistic derivation: 0.79, 95% confidence interval 0.77-0.81; validation: 0.81, 0.79-0.82) and acute coronary syndrome (C-statistic derivation: 0.77, 0.73-0.80; validation: 0.75, 0.73-0.78). Using echocardiograms of 3,926 genotyped individuals, we estimate narrow-sense heritability of 9.2%, 20.4% and 6.5%, respectively for echoAI-restMBF, echoAI-stressMBF, and echoAI-CFR. MBF indices show inverse genetic correlation with impedance-derived body mass indices, such as fat-free body mass (e.g., {rho}=-0.43, q=0.05 for echoAI-restMBF) and resolve conflicting historical data regarding body mass index and CFR. In terms of diseases, genetic association with ischemic heart disease is seen most prominently for echoAI-stressMBF ({rho}=-0.37, q=2.4x10-03). We hypothesize that interpreting one imaging modality through another represents a type of ""information bottleneck"", capturing latent features of the original physiologic measurements that have relevance across tissues. Thus, we propose a broader potential role for machine learning algorithms in developing scalable biomarkers that are anchored in known physiology, representative of latent biological factors, and are readily deployable in population health applications.",medRxiv,2021,10.1101/2021.02.07.21251025,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5793116b8d0c9749afa91df50b10de5487880e0,https://www.semanticscholar.org/paper/a5793116b8d0c9749afa91df50b10de5487880e0,Spacecraft Informatics,"Spacecraft informatics is one of the most exciting and contemporary research topics in recent years. Many countries are deploying related technologies such as AI, robotics, machine learning, etc., in the deep-space explorations. Moreover, considering the high-complexity, high cost and high risk involved in spacecraft, advanced technologies in information modelling, simulation, optimisation and decision support methods are required to improve the effectiveness, efficiencies, reliabilities and safety of the space operations (Du et al. 2017; Rui et al. 2014). The emerging informatics approach offers the benefit to the area of spacecraft regarding in-orbit spacecraft, satellites, space-stations of any types in deep-space exploration missions from ground control, user payload, space weather and conditions, remote sensing and telemetry, and many more spaceflight missions and activities of designing, forecasting, planning and control. To contribute the present and future space exploration and spacecraft development, in this special issue, we have collected excellent papers of research in spacecraft informatics. Each paper underwent a double-blind peer review by independent, anonymous expert referees. After the reviewing processes, eight highquality papers were accepted and are published in this issue. The first paper is ‘Optimisation problems and resolution methods in satellite scheduling and spacecraft operation: a survey’ by Xhafa and Ip (2019). This paper aims to study the state of the art in the satellite scheduling regarding the spacecraft design, operation and satellite deployment system. With heuristics methods, the constraint features in satellite mission planning, including window accessibility and visibility requirements can be addressed for producing smalland low-cost satellites. The second paper, entitled ‘Moon image segmentation with a new mixture histogram model’ by Hsu et al. (2019) is related to an application of image processing technology in the spacecraft. This paper aims to develop a histogram mixture model with genetic algorithm for improving the effectiveness in segmenting the moon surface image. Instead of the manual parameters measurement, the parameters can be obtained by a genetic algorithm. The results show that the proposed algorithm improved the drawbacks of previous non-parametric methods for moon image segmentation. In the papers, entitled ‘Blockchain adoption for information sharing: risk decisionmaking in spacecraft supply chain’ by Zheng et al. (2019) and ‘A framework for rocket and satellite launch information management systems based on blockchain technology’ by Li, Wang, and Zhang (2019), they employed blockchain technology for information management and sharing in the spacecraft supply chain. The use of blockchain technology allows the stakeholders in the spacecraft to (i) reduce transaction cost and risks, and (ii) improve the reliability and traceability of the spacecraft information to enhance the overall effectiveness and efficiency of the supply chain. The paper ‘Health condition estimation of spacecraft key components using belief rule base’ by Tang et al. (2019) developed a semi-quantitative method to examine the ENTERPRISE INFORMATION SYSTEMS 2021, VOL. 15, NO. 8, 1019–1021 https://doi.org/10.1080/17517575.2021.1886331",Enterp. Inf. Syst.,2021,10.1080/17517575.2021.1886331,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ba510af77c248a4a3f02cad6fe6cb24f7b053474,https://www.semanticscholar.org/paper/ba510af77c248a4a3f02cad6fe6cb24f7b053474,Multi-lane LBP-Gabor Capsule Network with K-means Routing for Medical Image Analysis,"Medical images naturally occur in smaller quantities and are not balanced. Some medical domains such as radiomics involve the analysis of images to diagnose a patient’s condition. Often, images of sick inaccessible parts of the body are taken for analysis by experts. However, medical experts are scarce, and the manual analysis of the images is time-consuming, costly, and prone to errors. Machine learning has been adopted to automate this task, but it is tedious, time-consuming, and requires experienced annotators to extract features. Deep learning alleviates this problem, but the threat of overfitting on smaller datasets and the existence of the “black box” still lingers. This paper proposes a capsule network that uses Local Binary Pattern (LBP), Gabor layers, and K-Means routing in an attempt to alleviate these drawbacks. Experimental results show that the model produces state-of-the-art accuracy for the three datasets (KVASIR, COVID-19, and ROCT), does not overfit on smaller and imbalanced datasets, and has reduced complexity due to fewer parameters. Layer activation maps, a cluster of features, predictions, and reconstruction of the input images, show that our model is interpretable and has the credibility and trust required to gain the confidence of practitioners for deployment in critical areas such as health.",International Journal of Advanced Computer Science and Applications,2021,10.14569/ijacsa.2021.0121031,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9406f72d0c9231341b6fdf139bbb1bf6c0ddddec,https://www.semanticscholar.org/paper/9406f72d0c9231341b6fdf139bbb1bf6c0ddddec,An Intelligent Mobile-Enabled System for Diagnosing Parkinson Disease: Development and Validation of a Speech Impairment Detection System,"Background Parkinson disease (PD) is one of the most common neurological diseases. At present, because the exact cause is still unclear, accurate diagnosis and progression monitoring remain challenging. In recent years, exploring the relationship between PD and speech impairment has attracted widespread attention in the academic world. Most of the studies successfully validated the effectiveness of some vocal features. Moreover, the noninvasive nature of speech signal–based testing has pioneered a new way for telediagnosis and telemonitoring. In particular, there is an increasing demand for artificial intelligence–powered tools in the digital health era. Objective This study aimed to build a real-time speech signal analysis tool for PD diagnosis and severity assessment. Further, the underlying system should be flexible enough to integrate any machine learning or deep learning algorithm. Methods At its core, the system we built consists of two parts: (1) speech signal processing: both traditional and novel speech signal processing technologies have been employed for feature engineering, which can automatically extract a few linear and nonlinear dysphonia features, and (2) application of machine learning algorithms: some classical regression and classification algorithms from the machine learning field have been tested; we then chose the most efficient algorithms and relevant features. Results Experimental results showed that our system had an outstanding ability to both diagnose and assess severity of PD. By using both linear and nonlinear dysphonia features, the accuracy reached 88.74% and recall reached 97.03% in the diagnosis task. Meanwhile, mean absolute error was 3.7699 in the assessment task. The system has already been deployed within a mobile app called No Pa. Conclusions This study performed diagnosis and severity assessment of PD from the perspective of speech order detection. The efficiency and effectiveness of the algorithms indirectly validated the practicality of the system. In particular, the system reflects the necessity of a publicly accessible PD diagnosis and assessment system that can perform telediagnosis and telemonitoring of PD. This system can also optimize doctors’ decision-making processes regarding treatments.",JMIR medical informatics,2020,10.2196/18689,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98ae4b12ab518b5eb4d36e4ec40fca5d5167e3d3,https://www.semanticscholar.org/paper/98ae4b12ab518b5eb4d36e4ec40fca5d5167e3d3,A Comprehensive Review on the Emerging IoT-Cloud based Technologies for Smart Healthcare,"Internet of Things (IoT) has redefined the operation of next-generation technologies by offering an intelligent framework. Cloud and IoT based system has been widely used in numerous applications for providing automated solutions and services. One of the areas in which the IoT and cloud have been widely used in the healthcare industry. To strengthen the healthcare system many initiatives are undertaken using advanced technologies such as IoT and cloud. So in this paper, a comprehensive review of the different IoT health model that are available are presented. The paper focuses on the various deployment strategies for building a cloud and IoT based system for smart home and smart hospital environment for handling different health-related issues. The paper highlights the various benefits that the IoT offers and also presents the challenges that are most prevalent in realizing the full automation of the healthcare system. The paper also discusses the integration of machine learning techniques for processing health data in the cloud to provide quality healthcare and modernize the healthcare system.",2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS),2020,10.1109/ICACCS48705.2020.9074457,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d4e00ad29cff7695aded3c81af9397821250cf41,https://www.semanticscholar.org/paper/d4e00ad29cff7695aded3c81af9397821250cf41,PEM fuel cell prognostics under variable load: A data-driven ensemble with new incremental learning,"Proton Exchange Membrane Fuel cells (PEMFC) are one of the most promising fuel cell technologies, which qualify for variety of applications as power generation source. The Prognostics & Health Management of fuel cell is an emerging field, which is paving the way for large scale industrial deployment of PEMFC technology. More precisely, prognostics of PEMFC become a major area of focus nowadays that enables predicting the behavior of PEMFC to produce actionable information to extend its life span. This paper contributes the first application on data-driven prognostics of PEMFC stack under variable load for combined heat and power generation (μCHP). In brief, an ensemble structure of Summation Wavelet-Extreme Learning Machine models is proposed with a new incremental learning scheme, to achieve long-term predictions on stack state of health (SOH) and to give confidence for better decisions. The proposed prognostics model is validated on data from PEMFC stack used for a μCHP application under variable load profile for a complete year. A thorough comparison on SOH predictions results clearly shows the significance of proposed prognostics model, which can predict with few learning data for a long-term prognostics horizon around 650 hours with high accuracy and low uncertainty.","2016 International Conference on Control, Decision and Information Technologies (CoDIT)",2016,10.1109/CoDIT.2016.7593569,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7457b092e64ac63edef5a4f203ece6cc97996e41,https://www.semanticscholar.org/paper/7457b092e64ac63edef5a4f203ece6cc97996e41,An analytics approach to problems in health care,"Health care expenditures in the United States have been increasing at unsustainable rates for more than thirty years with no signs of abating. Decisions to accept or reject deceased-donor kidneys offered to patients on the kidney transplantation waitlist currently rely on physician experience and intuition. Scoring rules to determine which end-stage liver disease patients are in most dire need of immediate transplantation have been haphazardly designed and reactively modified in an attempt to decrease waitlist mortality and increase fairness for cancer patients. For each of the above problem settings, we propose a framework that takes realworld data as input and draws upon modern data analytics methods ranging from mixed integer linear optimization to predictive machine learning to yield actionable insights that can add a significant edge over current practice. We describe an approach that, given insurance claims data, leads conservatively to a 10% reduction in health care costs in a study involving a large private US employer. Using historical data for patients on the kidney waitlist and organ match runs, we build a model that achieves an out-of-sample AUC of 0.87 when predicting whether or not a patient will receive a kidney of a particular quality within three, six, or twelve months. Given historical data for patients on the liver waitlist, we create a unified model that is capable of averting an additional 25% of adverse events in simulation compared to current practice without disadvantaging cancer patients. Thesis Supervisor: Dimitris Bertsimas Title: Boeing Professor of Operations Research Co-director, Operations Research Center",,2017,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d0c70c5fd8799042f13dfed52f48fa1e6bd4e3a8,https://www.semanticscholar.org/paper/d0c70c5fd8799042f13dfed52f48fa1e6bd4e3a8,Towards Knowledge-Driven Symptom Monitoring & Trigger Detection of Primary Headache Disorders,"Headache disorders are experienced by many people around the world. In current clinical practice, the follow-up and diagnosis of headache disorder patients only happens intermittently, based on subjective data self-reported by the patient. The mBrain system tries to make this process more continuous, autonomous and objective by additionally collecting contextual and physiological data via a wearable, mobile app and machine learning algorithms. To support the monitoring of headache symptoms during attacks for headache classification and the detection of headache triggers, much knowledge and contextual data is available from heterogeneous sources, which can be consolidated with semantics. This paper presents a demonstrator of knowledge-driven services that perform these tasks using Semantic Web technologies. These services are deployed in a distributed cascading architecture that includes DIVIDE to derive and manage the RDF stream processing queries that perform the con-textually relevant filtering in an intelligent and efficient way. support systems ; • Ap-plied computing → Health care information systems ; • Computer systems organization → Distributed architectures.",,2022,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9b62db19ab0d212417f3b2f646d14df7422e1540,https://www.semanticscholar.org/paper/9b62db19ab0d212417f3b2f646d14df7422e1540,Advances in Prediction of Readmission Rates Using Long Term Short Term Memory Networks on Healthcare Insurance Data,"Background 30-day hospital readmission is a long-standing medical problem that affects patients’ morbidity and mortality and costs billions of dollars annually. Recently, machine learning models have been created to predict risk of inpatient readmission for patients with specific diseases, however no model exists to predict this risk across all patients. Methods We developed a bi-directional Long Short Term Memory (LSTM) Network that is able to use readily available insurance data (inpatient visits, outpatient visits, and drug prescriptions) to predict 30-day readmission for any admitted patient, regardless of reason. We compare model performance with and without inclusion of 30-days of historical data prior to the initial admission, and with 7, 14, or 21 days of additional information following discharge. Finally, we added an attention layer to the model to investigate what features were most responsible for prediction in three categories: diagnosis related group, primary diagnosis, and drug therapy class. The top performing model achieved an ROC AUC of 0.763 ± 0.011 when using historical, inpatient, and post-discharge data. The LSTM model significantly outperformed a baseline random forest classifier, indicating that understanding the sequence of events is important for model prediction. Incorporation of 30-days of historical data also significantly improved model performance compared to inpatient data alone, indicating that a patient’s clinical history prior to admission, including outpatient visits and pharmacy data is a strong contributor to re-admission. Our results demonstrate that a machine learning model is able to predict risk of inpatient readmission with reasonable accuracy for all patients using structured insurance billing data. Because billing data or equivalent surrogates can be extracted from sites, such a model could be deployed to identify patients at risk for readmission before they are discharged, or to assign more robust follow up (closer follow up, home health, mailed medications) to at-risk patients after discharge.",ArXiv,2022,10.48550/arXiv.2207.00066,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
58daedd87b3d2b3413f31f39d57660da64e3d410,https://www.semanticscholar.org/paper/58daedd87b3d2b3413f31f39d57660da64e3d410,Automated COVID-19 emergency response using modern technologies,"Almost all countries are struggling with a pandemic created by infection of the severe acute respiratory syndrome coronavirus-2 virus. Health professionals are overstretched and are estimating to treat millions of peoples infected by this virus. However, we see the gainful employment of new technologies to provide fewer human interaction benefits to prevent the transmission of this virus. Here, in this paper, the capabilities of new technologies such as unmanned aerial vehicles, data analysis, three-dimensional (3D) printing, machine learning, and artificial intelligence are used to develop a model to the limit of their autonomous functionalities. We have proposed an automated COVID-19 pandemic emergency response system using the above modern technologies. These technologies are used efficiently to supply essential items in the required location and minimize the need for transportation. Advanced digital technologies are used to observe the crowd in different cities. It can identify people who are not wearing masks in public places. Further, 3D printing technology is used to manufacture personal protective equipment for COVID-19, and drones are used to deliver these items in the required places. The integrated deployment of new technologies can help us to fight this virus in a better way. This model can help through intelligent population screening, improved medical help, timely notification, and suggestions about infection control. It uses an innovative platform supported through different software and machine learning techniques. Furthermore, doctors, analysts, governments, and researcher can take its advantage to analyze the level of infection by the virus.",,2020,10.4103/am.am_68_20,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ad1301752d55a2dbd855c979c0b0d15f3ce986cc,https://www.semanticscholar.org/paper/ad1301752d55a2dbd855c979c0b0d15f3ce986cc,Semantic ML for Manufacturing Monitoring at Bosch,"Motivation. Technological advances that come with Industry 4.0, in e.g. sensoring and communication, unlock unprecedented large volumes of manufacturing data. This opens new horizons for data-driven methods like Machine Learning (ML) in analysis of manufacturing processes for a wide range of industries. An important scenario here is monitoring of manufacturing processes, including e.g. analysing the quality of the manufactured products and predicting the health state of machines and equipment. Consider an example of welding quality monitoring at Bosch, where welding is performed with automated machines that connect pieces of metal together by pressing them and passing high current electricity through them. Development of ML approaches for welding quality monitoring used in Bosch follows an iterative workflow that includes data collection (Step 1), task negotiation (Step 2), data preparation (Step 3), ML model development (Step 4), result interpretation and model selection (Step 5), model deployment (Step 6).",SEMWEB,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
80c85bcde7bf4341873b2c2dd31b1f8c9864272b,https://www.semanticscholar.org/paper/80c85bcde7bf4341873b2c2dd31b1f8c9864272b,Importance of Fog Computing in Healthcare 4.0,,,2020,10.1007/978-3-030-46197-3_4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9de44f32c71c87084af2d52240dfe80c31fe0661,https://www.semanticscholar.org/paper/9de44f32c71c87084af2d52240dfe80c31fe0661,A Digital Platform for Remote Healthcare Monitoring,We describe a digital platform developed in collaboration with clinicians and user groups to provide remote healthcare monitoring and support in a dementia care application. The platform uses data from sensory devices that are deployed in participants’ homes and utilises a set machine learning and analytical algorithms to identify risks of adverse health conditions such as Urinary Tract Infections (UTIs) and hypertension in people with dementia. The platform includes a clinical interface that is used by a monitoring team to view alerts and notifications that are generated by the algorithms and to also browse the in-home activity and physiological data in a secure and privacy-aware system. The platform complies to the information governance requirements of the UK National Healthcare Service (NHS) and is registered as a class 1 medical device. The platform has been deployed and tested in over 150 homes.,WWW,2020,10.1145/3366424.3383541,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0de1229fe0da9816f0209f88eeacb04b29a35ca7,https://www.semanticscholar.org/paper/0de1229fe0da9816f0209f88eeacb04b29a35ca7,A Platform for Disease Intervention Planning,"The research and development of new tools and strategies for disease intervention planning requires resources, data, and computation spread across multiple institutions and individuals. Whether this is towards an objective such as drug discovery or informing intervention policy, it should be possible for these tools to be flexibly deployed to meet the decision support needs of the Global Health community. In this work we introduce a new platform to demonstrate the utility of a scalable computational infrastructure, blockchain based validation and machine learning (ML) algorithms, to assist in the generation of validated novel policies for malaria control. We have conducted preliminary tests in the generation of simulation-based evidence to guide policy level decision making. Specifically to assess the performance of; the scalable infrastructure under different simulation complexities and distributed compute; Hyperledger Fabric to provide validation of shared information within our application; and ML approaches to generate novel policy insights. Finally the components of the platform may be leveraged via a non-technical user or policy-maker through an Interactive Dashboard, bridging the gap between research and immediate needs in Disease Intervention Planning.",2020 IEEE International Conference on Healthcare Informatics (ICHI),2020,10.1109/ICHI48887.2020.9374384,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
abeb627334f43170b8c632d8702b22556a715e70,https://www.semanticscholar.org/paper/abeb627334f43170b8c632d8702b22556a715e70,Patient-Independent Schizophrenia Relapse Prediction Using Mobile Sensor Based Daily Behavioral Rhythm Changes,,MobiHealth,2021,10.1007/978-3-030-70569-5_2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6a892494188ed5474ab81b0b4d3d36adc6eecfa8,https://www.semanticscholar.org/paper/6a892494188ed5474ab81b0b4d3d36adc6eecfa8,Toward unsupervised Human Activity Recognition on Microcontroller Units,"Bringing artificial intelligence to embedded devices has become a central research topic in many scientific domains (environment, agriculture, sociology, health…). For Human Activity Recognition, Artificial Neural Networks (ANNs) have shown their capability to provide better performance compared to other machine learning methods. However, ANNs suffer from two major limitations. First, ANNs are often trained using supervised learning requiring labelled databases, which are often difficult to build in real applications. Then, those algorithms are usually very expensive in terms of computing power. For that reason, their integration into low-power microcontrollers has been so far only evaluated to a limited extent. In this paper, we propose to evaluate quantitatively and qualitatively the embedded implementation of different neural networks for human activity recognition. First, supervised learning approaches are presented, followed by an exploratory study of unsupervised learning approaches using Self-Organizing Maps. Finally, some aspects of embedded unsupervised online learning are investigated to improve classification results using subject-specific data over a more general training. Each neural network is tested on a Human Activity Recognition dataset acquired from a smartphone using accelerometer and gyroscope sensing information (UCI HAR) and deployed on the SparkFun Edge board. This board hosts a low-power ARM Cortex-M4F-based microcontroller.",2020 23rd Euromicro Conference on Digital System Design (DSD),2020,10.1109/DSD51259.2020.00090,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3bc00eb2fd3fbead609c48e649f65a3e32b01263,https://www.semanticscholar.org/paper/3bc00eb2fd3fbead609c48e649f65a3e32b01263,Ownership at Large: Open Problems and Challenges in Ownership Management,"Software-intensive organizations rely on large numbers of software assets of different types, e.g., source-code files, tables in the data warehouse, and software configurations. Who is the most suitable owner of a given asset changes over time, e.g., due to reorganization and individual function changes. New forms of automation can help suggest more suitable owners for any given asset at a given point in time. By such efforts on ownership health, accountability of ownership is increased. The problem of finding the most suitable owners for an asset is essentially a program comprehension problem: how do we automatically determine who would be best placed to understand, maintain, evolve (and thereby assume ownership of) a given asset. This paper introduces the Facebook Ownesty system, which uses a combination of ultra large scale data mining and machine learning and has been deployed at Facebook as part of the company's ownership management approach. Ownesty processes many millions of software assets (e.g., source-code files) and it takes into account workflow and organizational aspects. The paper sets out open problems and challenges on ownership for the research community with advances expected from the fields of software engineering, programming languages, and machine learning.",ICPC,2020,10.1145/3387904.3389293,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
20012245b4406f92d32ec05ff9d9dca00a462586,https://www.semanticscholar.org/paper/20012245b4406f92d32ec05ff9d9dca00a462586,The COVID-19 Pandemic Vulnerability Index (PVI) Dashboard: monitoring county level vulnerability,"While the COVID-19 pandemic presents a global challenge, the U.S. response places substantial responsibility for both decision-making and communication on local health authorities. To better support counties and municipalities, we integrated baseline data on relevant community vulnerabilities with dynamic data on local infection rates and interventions into a Pandemic Vulnerability Index (PVI). The PVI presents a visual synthesis of county-level vulnerability indicators that can be compared in a regional, state, or nationwide context. We describe use of the PVI, supporting epidemiological modeling and machine-learning forecasts, and deployment of an interactive, web Dashboard. The Dashboard facilitates decision-making and communication among government officials, scientists, community leaders, and the public to enable more effective and coordinated action to combat the pandemic. One Sentence Summary: The COVID-19 Pandemic Vulnerability Index Dashboard monitors multiple data streams to communicate county-level trends and vulnerabilities and support local decision-making to combat the pandemic. for use under a CC0 license. This article is a US Government work. It is not subject to copyright under 17 USC 105 and is also made available (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 13, 2020. ; https://doi.org/10.1101/2020.08.10.20169649 doi: medRxiv preprint NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice. 2 Defeating the COVID-19 pandemic requires well-informed, data-driven decisions at all levels of government, from federal and state agencies to county health departments. Numerous datasets are being collected in response to the pandemic, enabling the development of predictive models and interactive monitoring applications[1, 2]. However, this multitude of data streams—from disease incidence to personal mobility and comorbidities—is overwhelming to navigate, difficult to integrate, and challenging to communicate. Synthesizing these disparate data is crucial for decision-makers, particularly at the state and local levels, to prioritize resources efficiently, identify and address key vulnerabilities, and evaluate and implement effective interventions. To address this situation, we developed a COVID-19 Pandemic Vulnerability Index (PVI) Dashboard (https://covid19pvi.niehs.nih.gov/) for interactive monitoring that features a countylevel Scorecard to visualize key vulnerability drivers, historical trend data, and quantitative predictions to support decision making at a local level (Figure 1). We assembled U.S. countyand state-level datasets into 12 key indicators across four major domains: current infection rates (infection prevalence, rate of increase), baseline population concentration (daytime density/traffic, residential density), current interventions (social distancing, testing rates), and health and environmental vulnerabilities (susceptible populations, air pollution, age distribution, comorbidities, health disparities, and hospital beds). These 12 indicators (some of which combine multiple datasets) are integrated at the county level into an overall PVI score, employing methods previously used for geospatial prioritization and profiling[3, 4]. The individual data streams comprising these indicators measure either wellestablished, general vulnerability factors for public health disasters or emerging factors relevant to the COVID-19 pandemic[5]. Details of PVI score formulation and rationale are described in the Supplement, along with links to all source data. The software used to generate PVI scores and profiles from these data is freely available at https://toxpi.org. To empower additional modeling efforts, the complete time series of all daily PVI scores and data are available at https://github.com/COVID19PVI/data. In developing the PVI, we performed rigorous statistical modeling of the underlying data to augment confidence in responsive actions, enable quantitative analysis and monitoring, and provide short-term predictions of cases and deaths. Our modeling efforts directly address the discussion in [6], by contextualizing factors such as racial differences with corrections for socioeconomic factors, health resource allocation, and co-morbidities, plus highlighting placebased risks and resource deficits that might explain spatial distributions. Specifically, three types of modeling efforts were performed and are regularly updated. First, epidemiological modeling on cumulative caseand death-related outcomes provides insights into the epidemiology of the pandemic. Second, dynamic time-dependent modeling provides similar outcome estimates as national-level models, but with county-level resolution. Finally, a Bayesian machine learning approach provides data-driven, short-term forecasts. The results of these modeling efforts are summarized below, with detailed methods and full results included in the Supplement. With respect to factors affecting COVID-19 related mortality, we find that the proportion of Black residents and the PM2.5 index of small-particulate air pollution are the most significant predictors among those included, reinforcing conclusions from previous reports[7]. An increase of one percentage point of Black residents is associated with a 3.3% increase in the COVID-19 death rate. The effect of a 1 g/m3 increase in PM2.5 is associated with an approximately 16% increase in the COVID-19 death rate, a value at the high end of a previously reported confidence interval from a report in late April 2020[7] when deaths had reached 38% of the current total. for use under a CC0 license. This article is a US Government work. It is not subject to copyright under 17 USC 105 and is also made available (which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity. The copyright holder for this preprint this version posted August 13, 2020. ; https://doi.org/10.1101/2020.08.10.20169649 doi: medRxiv preprint",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d27454c2f2fc851d552da405318d7db0dcd37627,https://www.semanticscholar.org/paper/d27454c2f2fc851d552da405318d7db0dcd37627,Managing COVID-19 Global Pandemic With High-Tech Consumer Wearables: A Comprehensive Review,"The novel corona virus (COVID-19) created a havoc all around the globe without any prediction of its eradication. All the previous methods seemed to fail and exceptional considerations are now required to be deployed in order to deal with this pandemic. The aim of this retrospective study is to highlight the new solutions to manage and deal with the pandemic. This study discusses different e-health wearable devices that help in early diagnosis of COVID-19 symptoms and also presents an overview of some artificial intelligence and machine learning techniques applied on CT-scan or Chest X-ray images to refine the correct diagnosis of patients. Finally, this work addresses the importance of smart chat-bots that provides assistance to the people suffering from stress and anxiety during quarantine. These chat-bots can offer psychological therapies in isolation and can be very useful.",2020 12th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT),2020,10.1109/ICUMT51630.2020.9222428,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
63750e108273992df88c35ad476960c19b27a014,https://www.semanticscholar.org/paper/63750e108273992df88c35ad476960c19b27a014,Wide and Deep Learning for Recommendation System,"Low Birth Weight is the major problem for the new born. Low birth weight is a term used to describe babies who are born weighing less than 5 pounds, 8 ounces (2,500 grams). Low-birth weight babies are more likely than babies with normal weight to have health problems as a newborn. Almost 40 percent of the new born suffer from underweight. Predicting birth weight before the birth of the baby is the best way to help the baby get special care as early as possible. It helps us to arrange for doctors and special facilities before the baby is born. There are several factors that affect the birth weight. Through past studies, it has been observed that the factors which affect the child birth range from biological characteristics like the baby's sex, race, age of mother and father, weight gained by the mother during pregnancy to behavioral characteristics like smoking and drinking habits of the mother, the education and living conditions of the parents. This project focuses on developing a web application that predicts baby weight taking baby’s gender, plurality, gestation weeks and mothers age as inputs. Machine learning is one of the domains that plays important role in medical industry. Many machine learning models have been developed to predict diseases at the early stage. In this project wide and deep neural network model is developed using TensorFlow library in Google cloud environment. Wide and Deep Neural Network combines wide linear model and deep neural network. It provides both memorization and generalization. Pre-processing and training is done in the distributed environment using cloud Dataflow and Cloud ML Engine. The model is then deployed as REST API.A web application is developed to invoke the API with the user inputs and show the predicted baby weight to the users. It is scalable and provides high performance.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a8b9340af9e44dd9032d9ec942149a9686702f61,https://www.semanticscholar.org/paper/a8b9340af9e44dd9032d9ec942149a9686702f61,Learning Disease representations from Discharge Summaries,"One of the most important goals in healthcare is health promotion, disease prevention and identification of the associated risks.[1] The typical problems is that even after decades of epidemiological research, it has proven to be very difficult to identify diseases and its risk factors. Now a days most of the health data is stored electronically, for example as Electronic Health Records (EHR). Disease registries and similar database of information provides a wealth of information that can be used to identify and track the diseases since its onset and enable faster remedy.[2] This paper presents an artificial intelligence approach to disease identification. Also there has been a growing demand for ease of access to healthcare, and this necessitates the development of healthcare technology with Human Computer Interaction(HCI) design in mind. HCI usage can help both patients and healthcare providers as well.[3] So we also propose a Human Computer Interaction component that can answer patientś question and help improve the quality of healthcare services provided to an individual. We make use of Natural Language Processing, Machine Learning and Big Data technologies to provide a feasible deployable solution.",2019 International Conference on Intelligent Computing and Remote Sensing (ICICRS),2019,10.1109/ICICRS46726.2019.9555851,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
297bb55cd7355b11e1630e75515d65eb3d8a4542,https://www.semanticscholar.org/paper/297bb55cd7355b11e1630e75515d65eb3d8a4542,Wavelet Based Real-Time Planetary Gearbox Health Monitoring Under Non-Stationary Operation,,Experimental Techniques,2021,10.1007/s40799-021-00518-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
354c445d8fe45a1bdcc862dd2cdfce4289acfc4f,https://www.semanticscholar.org/paper/354c445d8fe45a1bdcc862dd2cdfce4289acfc4f,"Privacy, Health, and Race Equity in the Digital Age","Privacy is a basic and foundational human good meriting moral and legal protection (Allen 2011). Privacy isn’t, however, everything (Allen 2003). Other goods and values matter, too (Solove 2003; Marmor 2015). Bioethicists are rethinking privacy and confidentiality as health-related policy imperatives in light of the common good and digital life (Austin 2003). In the 1990s, the era of the Human Genome Project, prevailing bioethical perspectives emphasized the importance of privacy and confidentiality in clinical, research and health administrative settings (Dhir and Aggarwal 1998; Allen 1999; Goldman, Schwartz, and Tang 2000). Many debated whether genetic information required exceptional levels of concealment (Gostin and Hodge 1999). It was also the era when the Health Insurance Portability and Accountability Act (HIPAA) was enacted (Allen 2021). By the early 2000s, regulators had implemented HIPAA’s Privacy and Security Rules, and the Genetic Information Nondiscrimination Act was enacted (Allen 2021). Today, a shift from privacy enthusiasm to skepticism can be discerned, with applications of artificial intelligence and machine learning at a historic apex. Older ideals promoting generous health data privacy clashes with newer ideals promoting generous health data sharing (Romoser 2018). Cautious critics of neuroscience applications harken back to older ideals of the privacy of mental states and the brain (Farahany 2023). The federal government’s marketing of the “All of Us Project” reflects the newer ideal and attendant priorities (Denny et al. 2019). Among the pressures on the older ideals of health privacy is the concern that socially useful, even lifesaving, technological innovations could be thwarted by “individualistic” privacy impediments. The philosophic worry that an individualistic interpretation of privacy works mischief in the world is not new to the digital age. Philosophers have long argued, including in the face of feminist and progressive critiques (Allen 1988), that although the concept of privacy can be deployed for anti-social purposes, privacy is not an inherently anti-social value. On the contrary, privacy functions to empower individuals to be more fit for the varied social roles and responsibilities comprising everyday lives in our inevitably social world. Indeed, “opportunities for individual forms of personal privacy make persons more fit for social participation and contribution to the pool of resources and assets available to all” (Allen 1988, 51). Dignity, self-determination and well-being require opportunities for privacy and private choices, rendering privacy an aspect of the collective good. Put differently, privacy is socially and politically embedded (Mokrosinska 2018). When both data privacy and data disclosure commend themselves, nuanced and context-specific accommodation (“balancing”) are required (Francis 2008; Miedema 2020), not eschewals of privacy based on its alleged “individualism.” It’s time to move beyond pitting individual privacies against collective goods. Bioethicists on the cutting edge are turning to equity issues raised by the privacy protection project. As fundamental as it is, the problem of how a world clamoring for big data honors privacy interests traditionally enshrined in moral and legal rights is but one meriting the attention of bioethicists in the digital age. Another fundamental contemporary concern worthy of emphasize is how marginalized and racialized populations fare in efforts to regulate privacy (Goodwin 2020). Do regulations proposed and enacted on the state and federal level protect the interests of all members of the collective equally well? Do underlying structures of racism, prejudice, and privilege, along with differences in compliance and enforcement mean that some people’s privacy is better protected than others’? (Allen 2015) The privacy of African Americans is not consistently well-protected, whether in the name of individuals or the collective. The new ethos of data sharing is",The American journal of bioethics : AJOB,2022,10.1080/15265161.2022.2076405,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e431045587c1bfea964c46d57de5a027419522a8,https://www.semanticscholar.org/paper/e431045587c1bfea964c46d57de5a027419522a8,COVID-19 Vaccination and Public Health Countermeasures on Variants of Concern in Canada: Evidence From a Spatial Hierarchical Cluster Analysis,"Background There is mounting evidence that the third wave of COVID-19 incidence is declining, yet variants of concern (VOCs) continue to present public health challenges in Canada. The emergence of VOCs has sparked debate on how to effectively control their impacts on the Canadian population. Objective Provincial and territorial governments have implemented a wide range of policy measures to protect residents against community transmission of COVID-19, but research examining the specific impact of policy countermeasures on the VOCs in Canada is needed. Our study objective was to identify provinces with disproportionate prevalence of VOCs relative to COVID-19 mitigation efforts in provinces and territories in Canada. Methods We analyzed publicly available provincial- and territorial-level data on the prevalence of VOCs in relation to mitigating factors, summarized in 3 measures: (1) strength of public health countermeasures (stringency index), (2) the extent to which people moved about outside their homes (mobility index), and (3) the proportion of the provincial or territorial population that was fully vaccinated (vaccine uptake). Using spatial agglomerative hierarchical cluster analysis (unsupervised machine learning), provinces and territories were grouped into clusters by stringency index, mobility index, and full vaccine uptake. The Kruskal-Wallis test was used to compare the prevalence of VOCs (Alpha, or B.1.1.7; Beta, or B.1.351; Gamma, or P.1; and Delta, or B.1.617.2 variants) across the clusters. Results We identified 3 clusters of vaccine uptake and countermeasures. Cluster 1 consisted of the 3 Canadian territories and was characterized by a higher degree of vaccine deployment and fewer countermeasures. Cluster 2 (located in Central Canada and the Atlantic region) was typified by lower levels of vaccine deployment and moderate countermeasures. The third cluster, which consisted of provinces in the Pacific region, Central Canada, and the Prairies, exhibited moderate vaccine deployment but stronger countermeasures. The overall and variant-specific prevalences were significantly different across the clusters. Conclusions This “up to the point” analysis found that implementation of COVID-19 public health measures, including the mass vaccination of populations, is key to controlling VOC prevalence rates in Canada. As of June 15, 2021, the third wave of COVID-19 in Canada is declining, and those provinces and territories that had implemented more comprehensive public health measures showed lower VOC prevalence. Public health authorities and governments need to continue to communicate the importance of sociobehavioural preventive measures, even as populations in Canada continue to receive their primary and booster doses of vaccines.",JMIR public health and surveillance,2021,10.2196/31968,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f1bc43932beb14a00cd47feac4e40951601dd7a9,https://www.semanticscholar.org/paper/f1bc43932beb14a00cd47feac4e40951601dd7a9,Key challenges for delivering clinical impact with artificial intelligence,,BMC Medicine,2019,10.1186/s12916-019-1426-2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
37f0982783150372f7bd910b605e2ee58fb22284,https://www.semanticscholar.org/paper/37f0982783150372f7bd910b605e2ee58fb22284,Smarter micro-targeting to improve global health outcomes: scaling cluster segmentation on novel types of data for precision public health,"In global health, optimized interventions that rely on voluntary uptake should account for decision-making heterogeneity within the target population. This is a major challenge: to efficiently use scarce resources, the right people should be targeted with the right intervention at the right time. This entails segmenting the population of interest based on the differences that underlie their decision-making, prioritizing which segments to target, and then developing segment-specific intervention strategies. Effective global health interventions at scale require large financial and human resource investments, and both are limited in resource-poor settings. Therefore, scaling segmentation approaches to optimize intervention development and deployment is a key challenge and requires collaboration at the intersection of global health and machine learning experts. Here, we demonstrate how the collection of novel types of data coupled with the application of unsupervised classification algorithms can help micro-target interventions on the ground to drive health outcomes. Highlighting a case study on Voluntary Medical Male Circumcision in Africa, we discuss lessons learned and innovations in future programs, especially how mobile approaches to data collection and analytics can be streamlined to make segmentation a scalable approach across global health.",,2018,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a9e77ef57fe90ecd9d390711c4113f987bcd6ea4,https://www.semanticscholar.org/paper/a9e77ef57fe90ecd9d390711c4113f987bcd6ea4,Exploring Collective Behavior of Internet of Robotic Things for Indoor Plant Health Monitoring,"In this paper, we present an innovative way of sensing the health of indoor plants and performing actions using social media messaging service as a cost-saving exercise. For this, we explore the use of Internet of Robotic Things (IoRT), the incorporation of robotics aspect into wider IoT environment to transform the present landscape into the fully automated world. The dynamic nature of health of plants is inferred intelligently by the employed machine learning models which take the input readings of the sensors attached to the robotic arm of an autonomous mobile robot. Ericsson’s APPIoT platform is used for storing and analyzing the sensor data in a cloud background for setting newer thresholds. The actuation efforts are shared to a closed community through social media messaging platform like WhatsApp. The community members who received the intimation are expected to take necessary actions immediately. The system has been tested in an indoor environment of the Ericsson office in Chennai where the different types of plant pots are deployed on different floors. By exploring the collective behavior in our system proved to be a cost-efficient way of maintaining the health of the indoor plants.",2018 IEEE International Conference on Internet of Things and Intelligence System (IOTAIS),2018,10.1109/IOTAIS.2018.8600865,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
88d30284ffcea288943c7b2500601ffc5310f1c4,https://www.semanticscholar.org/paper/88d30284ffcea288943c7b2500601ffc5310f1c4,Unsupervised Domain Adaptation based Remaining Useful Life Prediction of Rolling Element Bearings,"With the rise of Artificial Intelligence (AI), machine learning techniques are now conquering the research field of Prognostics and Health Management (PHM). Classic deployable prognostic models manipulate large amount of machinery historical data to map the degradation process based on inherent features. Nowadays one of the major challenges in prognostics research is the data deficit problem when historical data is not available or accessible, in enough quantity and variety. In the frames of Transfer Learning, the domain adaptation technique aims to build a model with strong generalization ability which can be transferred to datasets with different distributions. In this paper, a Domain Adversarial Neural Network (DANN) model is combined with a Bidirectional Long Short- Term Memory (Bi-LSTM) neural network for the estimation of the Remaining Useful Life (RUL) of rolling element bearings. The unsupervised domain adaptation is fulfilled using a labelled bearing degradation dataset as the source domain data and an unlabelled dataset captured under different operation conditions as the target domain data for the Bi-LSTM DANN. The proposed method achieves promising results, applied on real bearing vibration data captured on run-to-failure tests, with high prediction accuracy of the bearing RUL compared to un-adapted methods.",,2020,10.36001/PHME.2020.V5I1.1208,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9ba08aa482be43eba490fd1e74dbf15381d48147,https://www.semanticscholar.org/paper/9ba08aa482be43eba490fd1e74dbf15381d48147,Combating Hard or Soft Disasters with Privacy-Preserving Federated Mobile Buses-and-Drones based Networks,"It is foreseeable the popularity of the mobile edge computing enabled infrastructure for wireless networks in the incoming fifth generation (5G) and future sixth generation (6G) wireless networks. Especially after a ‘hard’ disaster such as earthquakes or a ‘soft’ disaster such as COVID-19 pandemic, the existing telecommunication infrastructure, including wired and wireless networks, is often seriously compromised or with infectious disease risks and should-not-close-contact, thus cannot guarantee regular coverage and reliable communications services. These temporarily-missing communications capabilities are crucial to rescuers, health-carers, or affected or infected citizens as the responders need to effectively coordinate and communicate to minimize the loss of lives and property, where the 5G/6G mobile edge network helps. On the other hand, the federated machine learning (FML) methods have been newly developed to address the privacy leakage problems of the traditional machine learning held normally by one centralized organization, associated with the high risks of a single point of hacking. After detailing current state-of-the-art both in privacy-preserving, federated learning, and mobile edge communications networks for ‘hard’ and ‘soft’ disasters, we consider the main challenges that need to be faced. We envision a privacy-preserving federated learning enabled buses-and-drones based mobile edge infrastructure (ppFL-AidLife) for disaster or pandemic emergency communications. The ppFL-AidLife system aims at a rapidly deployable resilient network capable of supporting flexible, privacy-preserving and low-latency communications to serve large-scale disaster situations by utilizing the existing public transport networks, associated with drones to maximally extend their radio coverage to those hard-to-reach disasters or should-not-close-contact pandemic zones.",2020 IEEE 21st International Conference on Information Reuse and Integration for Data Science (IRI),2020,10.1109/IRI49571.2020.00013,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f67d60c60b396599cadcce80a6955377fabdb697,https://www.semanticscholar.org/paper/f67d60c60b396599cadcce80a6955377fabdb697,Simulation-driven Deep Classification of Bearing Faults from Raw Vibration Data,"The industry is moving towards maintenance strategies that consider component health, which require extensive collection and analysis of data. Condition monitoring methods that require manual feature extraction and analysis, become infeasible on an industrial scale. Machine learning algorithms can be used to automatically detect and classify faults, however, obtaining sufficient data for training is required for deep learning and other data-driven classification approaches. Data from healthy machine operation is generally available in abundance, while data from representative faultand operating conditions is limited. This limits both development and deployment of deep learning-based CM systems on an industrial scale. This paper addresses both the challenges of automated analysis and lack of training data. A deep learning classifier architecture utilizing 1-dimensional dilated convolutions is proposed. Dilation of the convolution kernel allows for analysis of raw vibration signals while simultaneously maintaining the receptive field of the classifier enough to capture temporal patterns. The proposed method performs classification in time domain on signal segments of 1 second or shorter. With knowledge of the bearing specification, artificial vibration signals with similar characteristics as an actual bearing fault can be created. In this work, generated fault signals are combined with healthy operational data to obtain training data for a deep classifier. Parameters of the vibration Martin Hemmer et al. This is an open-access article distributed under the terms of the Creative Commons Attribution 3.0 United States License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. model is chosen as distributions rather than fixed values. By using a range parameters in the vibration model, the classifier learns to recognize temporal features from the training data that generalize to unseen data. The effectiveness of the proposed method is demonstrated by training classifiers on generated data and testing on real signals from faulty bearings at both low and high speed. One dataset containing seeded faults and three run-to-failure tests are used for the demonstration.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6e9582ec17a74e19cafbad763fab24fe0b380854,https://www.semanticscholar.org/paper/6e9582ec17a74e19cafbad763fab24fe0b380854,Exploration of Multi-output Gaussian Process Regression for Residual Storage Life Prediction in Lithium Ion Battery,"The shift from conventional war to troubled peace has seen the reduction of full-scale deployment of military equipment for operations. Conversely, the increased occurrences of natural disasters and epidemics necessitate the provision of contingency equipment, to readily surge for responsive support. Long term storage presents a more cost-effective approach to own, maintain and operate such military or civil equipment. Recent developments in artificial intelligence and machine learning have fueled interest in equipment prognosis and proactive predictive maintenance to enable prognostics and health management (PHM). However, this is not prevalent in the domain for equipment under long term storage. This could be attributed to slower, and possibly different degradation modes, coupled with lack of large data sets for prognosis in the storage scenario. In this paper, we explore the use of multi-output Gaussian Process (MOGP) regression, on lithium ion battery units in storage, under various state-of-charge and temperature conditions, and discuss empirical effects of training data selection and test data parameters on the accuracy of the residual storage life (RSL) prediction. This will pave way for the development of RSL prediction methods for equipment fleet under storage, considering the scenario of limited or no knowhow of the degradation model.",2020 Prognostics and Health Management Conference (PHM-Besançon),2020,10.1109/PHM-Besancon49106.2020.00051,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e176fa38286bb89a707d7c7d49ccf38d2364bb8e,https://www.semanticscholar.org/paper/e176fa38286bb89a707d7c7d49ccf38d2364bb8e,Computer-Based PTSD Assessment in VR Exposure Therapy,,HCI,2020,10.1007/978-3-030-59990-4_32,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2adb579bcd01c49d974ca0c50319d215fbf37cce,https://www.semanticscholar.org/paper/2adb579bcd01c49d974ca0c50319d215fbf37cce,Scalable Healthcare Assessment for Diabetic Patients Using Deep Learning on Multiple GPUs,"The large-scale parallel computation that became available on the new generation of graphics processing units (GPUs) and on cloud-based services can be exploited for use in healthcare data analysis. Furthermore, computation workstations suited for deep learning are usually equipped with multiple GPUs allowing for workload distribution among multiple GPUs for larger datasets while exploiting parallelism in each GPU. In this paper, we utilize distributed and parallel computation techniques to efficiently analyze healthcare data using deep learning techniques. We demonstrate the scalability and computational benefits of this approach with a case study of longitudinal assessment of approximately 150 000 type 2 diabetic patients. Type 2 diabetes mellitus (T2DM) is the fourth case of mortality worldwide with rising prevalence. T2DM leads to adverse events such as acute myocardial infarction, major amputations, and avoidable hospitalizations. This paper aims to establish a relation between laboratory and medical assessment variables with the occurrence of the aforementioned adverse events and its prediction using machine learning techniques. We use a raw database provided by Basque Health Service, Spain, to conduct this study. This database contains 150 156 patients diagnosed with T2DM, from whom 321 laboratory and medical assessment variables recorded over four years are available. Predictions of adverse events on T2DM patients using both classical machine learning and deep learning techniques were performed and evaluated using accuracy, precision, recall and F1-score as metrics. The best performance for the prediction of acute myocardial infarction is obtained by linear discriminant analysis (LDA) and support vector machines (SVM) both balanced and weight models with an accuracy of 97%; hospital admission for avoidable causes best performance is obtained by LDA balanced and SVMs balanced both with an accuracy of 92%. For the prediction of the incidence of at least one adverse event, the model with the best performance is the recurrent neural network trained with a balanced dataset with an accuracy of 94.6%. The ability to perform and compare these experiments was possible through the use of a workstation with multi-GPUs. This setup allows for scalability to larger datasets. Such models are also cloud ready and can be deployed on similar architectures hosted on AWS for even larger datasets.",IEEE Transactions on Industrial Informatics,2019,10.1109/TII.2019.2919168,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
02ee08087aaecb5dbf4cfcad68ea3af96162b574,https://www.semanticscholar.org/paper/02ee08087aaecb5dbf4cfcad68ea3af96162b574,Methodological guide to deploy Functional Analysis into CODAC Systems for the Tritium Processing in ITER,"The present document is focused on the a nalysis of the ITER - TBM‘s Proto - CODAC system. ITER is considered to be the first nuclear fusion reactor to be energetically feasible for a sustained period of time with a rated fusion power of 500 MW. ITER Project involves 35 countries with a total est imated budget of some 15.000 M€; being the first of its kind from the point of view of international collaboration, engineering and supply sources; where every country participate with the best of its possibilities. The hearth of the fusion reactor is a giant Tokamak (6.2 m plasma major radius) with a se ries of ancillary buildings and facilities that might complete the whole p roject. The operation of ITER is scheduled to operate along the next 50 years , after completion of the facilities construction and commissioning of the plant, considering first to b e operated in D - D and further in a D - T modes. In this sense, the activity that supports the development of the present work was stated to be necessary to consider a tritium balance for the self - sufficient reaction and operation of the whole. Tritium is a v ery scarce element being its global sto cks to the present date of 2016 of some 20 kg, being produced mainly collected from the operation of Candu reactors in Canada [Raeder, 1986] . Also the operation of the ITER reactor might produce Tritium at a rate that might b e able to support the fusion reaction indefinitely on a time basis. Because of the tritium balance it is difficult to state due to its highly permeation throughout confinement of first walls and joint materials . Not to mention its high ly dangerous potential to human health, according to radiologic al properties . This is why it is necessary to establish predictive tools that might indicate the concentration and inventory across the facility, including emissions to the environment. In this sense, ITER Instrumentation and Control systems for Control and Data Acquisition (DACS) mainly constitute the layers between the users (Control Room) and the field Instrumentation (sensors and actuators). This is nam ed as ITER CODAC, which is the primary global system analyzed in the present document. The control philosophy it is stated to be predictive and from the author‘s point of view must include the comparison between field measurement and advanced modeling, including machine learning utility system that might be deployed in computational base.",,2018,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c26fc9a1ccc05d8e1a025a8866a14f29ef595b8c,https://www.semanticscholar.org/paper/c26fc9a1ccc05d8e1a025a8866a14f29ef595b8c,Artificial Intelligence for Social Good,"The Computing Community Consortium (CCC), along with the White House Office of Science and Technology Policy (OSTP), and the Association for the Advancement of Artificial Intelligence (AAAI), co-sponsored a public workshop on Artificial Intelligence for Social Good on June 7th, 2016 in Washington, DC. This was one of five workshops that OSTP co-sponsored and held around the country to spur public dialogue on artificial intelligence, machine learning, and to identify challenges and opportunities related to AI. In the AI for Social Good workshop, the successful deployments and the potential use of AI in various topics that are essential for social good were discussed, including but not limited to urban computing, health, environmental sustainability, and public welfare. This report highlights each of these as well as a number of crosscutting issues.",ArXiv,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
187e3237bb4db7c3ccb5e4d4e40db5fe9e85d56e,https://www.semanticscholar.org/paper/187e3237bb4db7c3ccb5e4d4e40db5fe9e85d56e,Automated and flexible identification of complex disease: building a model for systemic lupus erythematosus using noisy labeling,"Accurate and efficient identification of complex chronic conditions in the electronic health record (EHR) is an important but challenging task that has historically relied on tedious clinician review and oversimplification of the disease. Here we adapt methods that allow for automated ""noisy labeling"" of positive and negative controls to create a ""silver standard"" for machine learning to automate identification of systemic lupus erythematosus (SLE). Our final model, which includes both structured data as well as text processing of clinical notes, outperformed all existing algorithms for SLE (AUC 0.97). In addition, we demonstrate how the probabilistic outputs of this model can be adapted to various clinical needs, selecting high thresholds when specificity is the priority and lower thresholds when a more inclusive patient population is desired. Deploying a similar methodology to other complex diseases has the potential to dramatically simplify the landscape of population identification in the EHR.


MeSH terms
Electronic Health Records, Machine Learning, Lupus Erythematosus, Phenotype, Algorithms.",J. Am. Medical Informatics Assoc.,2018,10.1093/jamia/ocy154,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
07245c674c83fb52bef694ddcafff46c0eb6384a,https://www.semanticscholar.org/paper/07245c674c83fb52bef694ddcafff46c0eb6384a,Cable Diagnostics With Power Line Modems for Smart Grid Monitoring,"Remote monitoring of electrical cable conditions is an essential characteristic of the next-generation smart grid, which features the ability to consistently surveil and control the grid infrastructure. In this paper, we propose a technique that harnesses power line modems (PLMs) for monitoring cable health. We envisage that all or most of these PLMs have already been deployed for data communication purposes and focus on the distribution grid or neighborhood area networks in the smart grid. For such a setting, we propose a machine learning (ML)-based framework for automatic cable diagnostics by continuously monitoring the cable status to identify, assess, and locate possible degradations. As part of our technique, we also synthesize the state-of-the-art reflectometry methods within the PLMs to extract beneficial features for the effective performance of our proposed ML solution. The simulation results demonstrate the effectiveness of our solution under different aging conditions and varying load configurations. Finally, we reflect on our proposed diagnostics method by evaluating its robustness and comparing it with existing alternatives.",IEEE Access,2018,10.1109/ACCESS.2019.2914580,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d88d30188455aa6cb4c26c3670f03fd27bef53b3,https://www.semanticscholar.org/paper/d88d30188455aa6cb4c26c3670f03fd27bef53b3,The interplay between artificial intelligence and fog radio access networks,"The interplay between artificial intelligence (AI) and fog radio access networks (F-RANs) is investigated in this work from two perspectives: how F-RANs enable hierarchical AI to be deployed in wireless networks and how AI makes F-RANs smarter to better serve mobile devices. Due to the heterogeneity of processing capability, the cloud, fog, and device layers in F-RANs provide hierarchical intelligence via centralized, distributed, and federated learning. In addition, cross-layer learning is also introduced to further reduce the demand for the memory size of the mobile devices. On the other hand, AI provides F-RANs with technologies and methods to deal with massive data and make smarter decisions. Specifically, machine learning tools such as deep neural networks are introduced for data processing, while reinforcement learning (RL) algorithms are adopted for network optimization and decisions. Then, two examples of AI-based applications in F-RANs, i.e., health monitoring and intelligent transportation systems, are presented, followed by a case study of an RL-based caching application in the presence of spatio-temporal unknown content popularity to showcase the potential of applying AI to F-RANs.",China Communications,2020,10.23919/JCC.2020.08.001,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6c21b7c307cacd50e0942a18d7ebf2f0fc5e1b3b,https://www.semanticscholar.org/paper/6c21b7c307cacd50e0942a18d7ebf2f0fc5e1b3b,Portable hardware & software technologies for addressing ophthalmic health disparities: A systematic review,"Vision impairment continues to be a major global problem, as the WHO estimates 2.2 billion people struggling with vision loss or blindness. One billion of these cases, however, can be prevented by expanding diagnostic capabilities. Direct global healthcare costs associated with these conditions totaled $255 billion in 2010, with a rapid upward projection to $294 billion in 2020. Accordingly, WHO proposed 2030 targets to enhance integration and patient-centered vision care by expanding refractive error and cataract worldwide coverage. Due to the limitations in cost and portability of adapted vision screening models, there is a clear need for new, more accessible vision testing tools in vision care. This comparative, systematic review highlights the need for new ophthalmic equipment and approaches while looking at existing and emerging technologies that could expand the capacity for disease identification and access to diagnostic tools. Specifically, the review focuses on portable hardware- and software-centered strategies that can be deployed in remote locations for detection of ophthalmic conditions and refractive error. Advancements in portable hardware, automated software screening tools, and big data-centric analytics, including machine learning, may provide an avenue for improving ophthalmic healthcare.",Digital health,2022,10.1177/20552076221090042,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
53d67ee0ca4447b89d1c56fe6b563ea25acd1bb8,https://www.semanticscholar.org/paper/53d67ee0ca4447b89d1c56fe6b563ea25acd1bb8,COVI White Paper-Version 1.1,"The SARS-CoV-2 (Covid-19) pandemic has resulted in significant strain on health care and public health institutions around the world. Contact tracing is an essential tool for public health officials and local communities to change the course of the Covid-19 pandemic. Standard manual contact tracing of people infected with Covid-19, while the current gold standard, has significant challenges that limit the ability of public health authorities to minimize community infections. Personalized peer-to-peer contact tracing through the use of mobile applications has the potential to shift the paradigm of Covid-19 community spread. Although some countries have deployed centralized tracking systems through either GPS or Bluetooth, more privacy-protecting decentralized systems offer much of the same benefit without concentrating data in the hands of a state authority or in for-profit corporations. Additionally, machine learning methods can be used to circumvent some of the limitations of standard digital tracing by incorporating many clues (including medical conditions, self-reported symptoms, and numerous encounters with people at different risk levels, for different durations and distances) and their uncertainty into a more graded and precise estimation of infection and contagion risk. The estimated risk can be used to provide early risk awareness, personalized recommendations and relevant information to the user and connect them to health services. Finally, the non-identifying data about these risks can inform detailed epidemiological models trained jointly with the machine learning predictor, and these models can provide statistical evidence for the interaction and importance of different factors involved in the transmission of the disease. They can also be used to monitor, evaluate and optimize different health policy and confinement/deconfinement scenarios according to medical and economic productivity indicators. However, such a strategy based on mobile apps and machine learning should proactively mitigate potential ethical and privacy risks, which could have substantial impacts on society (not only impacts on health but also impacts such as stigmatization and abuse of personal data). Here, we present an overview of the rationale, design, ethical considerations and privacy strategy of ‘COVI,’ a Covid-19 public peer-to-peer contact tracing and risk awareness mobile application developed in Canada. Addendum 2020-07-14: The government of Canada has declined to endorse COVI and will be promoting a different app for decentralized contact tracing. In the interest of preventing fragmentation of the app landscape, COVI will therefore not be deployed to end users. We are currently still in the process of finalizing the project, and plan to release our code and models for academic consumption and to make them accessible to other States should they wish to deploy an app based on or inspired by said code and models. University of Ottawa, Mila, Université de Montréal, The Alan Turing Institute, University of Oxford, University of Pennsylvania, McGill University, Borden Ladner Gervais LLP, The Decision Lab, HEC Montréal, Max Planck Institute, Libéo, University of Toronto. Corresponding author general: richard.janda@mcgill.ca Corresponding author for public health: abhinav.sharma@mcgill.ca Corresponding author for privacy: ywyu@math.toronto.edu Corresponding author for machine learning: yoshua.bengio@mila.quebec Corresponding author for user perspective: brooke@thedecisionlab.com Corresponding author for technical implementation: jean-francois.rousseau@libeo.com 1 ar X iv :2 00 5. 08 50 2v 2 [ cs .C R ] 2 7 Ju l 2 02 0",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5a3d9d779ac08f128db6656c0b106c676c425698,https://www.semanticscholar.org/paper/5a3d9d779ac08f128db6656c0b106c676c425698,Towards Social Enterprise with Internet of Office Desks,,HCC,2020,10.1007/978-3-030-62803-1_29,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
53f16cd9c64248aea915c56390815f1652ea7da9,https://www.semanticscholar.org/paper/53f16cd9c64248aea915c56390815f1652ea7da9,Toward Smart Urban Development Through Intelligent Edge Analytics,,Integration of WSN and IoT for Smart Cities,2020,10.1007/978-3-030-38516-3_8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7ec15731613ac0dc5d09125d325e7970a5a6a1ea,https://www.semanticscholar.org/paper/7ec15731613ac0dc5d09125d325e7970a5a6a1ea,Communications for IoT: Connectivity and Networking,"The Internet of Things (IoT) is revolutionizing many industries by enabling machines to directly work with each other without human intervention, and communication and networking technologies are fundamental to enabling it. IoT systems are also creating a significant amount of new data which can now be processed to analyze and learn from using novel machine-learning techniques. However, the requirements for communications can vary significantly depending on the target applications, and they can range from ultra-low power for enabling a vast deployment of sensors with multi-year battery life to ultra-reliable low latency communications (URLLC) for smart factories and remote robot control. 5G, as an example, is expected to deliver a number of enhancements to support massive IoT deployments as well as URLLC capabilities for new verticals such as Smart Cities, Industrial IoT, E-Health, Public Safety, and Autonomous Vehicles (V2V, V2X). The purpose of this Special Issue is to provide researchers and practitioners working on Connectivity and Networking technologies for IoT systems a means to share experiences and disseminate successful applications of IoT technologies and identify recent trends and opportunities poised to revolutionize the IoT industry.",IEEE Internet of Things Magazine,2020,10.1109/MIOT.2020.9063399,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
000559ddec47a6e2f1b06829d1b1c2f73270b55f,https://www.semanticscholar.org/paper/000559ddec47a6e2f1b06829d1b1c2f73270b55f,Introduction to the Special Section on Big Data and Artificial Intelligence for Network Technologies,"The papers in this special section examines the deployment of Big Data and artificial intelligence for network technologies. The eneration of huge amounts of data, called big data, is creating the need for efficient tools to manage those data. Artificial intelligence (AI) has become the powerful tool in dealing with big data with recent breakthroughs at multiple fronts in machine learning, including deep learning. Meanwhile, information networks are becoming larger and more complicated, generating a huge amount of runtime statistics data such as traffic load, resource usages. The emerging big data and AI technologies may include a bunch of new requirements, applications and scenarios such as e-health, Intelligent Transportation Systems (ITS), Industrial Internet of Things (IIoT), and smart cities in the term of computing networks. The big data and AI driven network technologies also provide an unprecedented patient to discover new features, to characterize user demands and system capabilities in network resource assignment, security and privacy, system architecture, modeling and applications, which needs more explorations. The focus of this special section is to address the big data and artificial intelligence for network technologies. We appreciate contributions to this special section and the valuable and extensive efforts of the reviewers. The topics of this special section range from big data and AI algorithms, models, architecture for networks and systems to network architecture,",IEEE Trans. Netw. Sci. Eng.,2020,10.1109/tnse.2020.2968206,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
43f1a2d83868c882a32cf148950e1ee00eb81977,https://www.semanticscholar.org/paper/43f1a2d83868c882a32cf148950e1ee00eb81977,YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart Camera Applications,"Deep Learning-based object detectors can enhance the capabilities of smart camera systems in a wide spectrum of machine vision applications including video surveillance, autonomous driving, robots and drones, smart factory, and health monitoring. Pedestrian detection plays a key role in all these applications and deep learning can be used to construct accurate state-of-the-art detectors. However, such complex paradigms do not scale easily and are not traditionally implemented in resource-constrained smart cameras for on-device processing which offers significant advantages in situations when real-time monitoring and robustness are vital. Efficient neural networks can not only enable mobile applications and on-device experiences but can also be a key enabler of privacy and security allowing a user to gain the benefits of neural networks without needing to send their data to the server to be evaluated. This work addresses the challenge of achieving a good trade-off between accuracy and speed for efficient deployment of deep-learning-based pedestrian detection in smart camera applications. A computationally efficient architecture is introduced based on separable convolutions and proposes integrating dense connections across layers and multi-scale feature fusion to improve representational capacity while decreasing the number of parameters and operations. In particular, the contributions of this work are the following: 1) An efficient backbone combining multi-scale feature operations, 2) a more elaborate loss function for improved localization, 3) an anchor-less approach for detection, The proposed approach called YOLOpeds is evaluated using the PETS2009 surveillance dataset on 320x320 images. Overall, YOLOpeds provides real-time sustained operation of over 30 frames per second with detection rates in the range of 86% outperforming existing deep learning models.",IET Comput. Vis.,2020,10.1049/iet-cvi.2019.0897,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
517e2923dc6967a43efc03008989231fc546eb55,https://www.semanticscholar.org/paper/517e2923dc6967a43efc03008989231fc546eb55,Icebreaker: Element-wise Active Information Acquisition with Bayesian Deep Latent Gaussian Model,"In this paper we introduce the ice-start problem, i.e., the challenge of deploying machine learning models when only little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative for the real-world machine learning applications. For instance, in the health-care domain, when training an AI system for predicting patient metrics from lab tests, obtaining every single measurement comes with a high cost. Active learning, where only the label is associated with a cost does not apply to such problem, because performing all possible lab tests to acquire a new training datum would be costly, as well as unnecessary due to redundancy. We propose Icebreaker, a principled framework to approach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method. Our proposed method combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM's ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than the previous VAE (Variational autoencoder) based models, when the data set size is small, using both machine learning benchmarks and real-world recommender systems and health-care applications. Moreover, based on BELGAM, Icebreaker further improves the performance and demonstrate the ability to use minimum amount of the training data to obtain the highest test time performance.",ArXiv,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
76f154dd671b214bdfa9957b715abf67ec674565,https://www.semanticscholar.org/paper/76f154dd671b214bdfa9957b715abf67ec674565,"Best Practices for Noise-Based Augmentation to Improve the Performance of Emotion Recognition ""In the Wild""","Emotion recognition as a key component of high-stake downstream applications has been shown to be effective, such as classroom engagement or mental health assessments. These systems are generally trained on small datasets collected in single laboratory environments, and hence falter when tested on data that has different noise characteristics. Multiple noise-based data augmentation approaches have been proposed to counteract this challenge in other speech domains. But, unlike speech recognition and speaker verification, in emotion recognition, noise-based data augmentation may change the underlying label of the original emotional sample. In this work, we generate realistic noisy samples of a well known emotion dataset (IEMOCAP) using multiple categories of environmental and synthetic noise. We evaluate how both human and machine emotion perception changes when noise is introduced. We find that some commonly used augmentation techniques for emotion recognition significantly change human perception, which may lead to unreliable evaluation metrics such as evaluating efficiency of adversarial attack. We also find that the trained state-of-the-art emotion recognition models fail to classify unseen noiseaugmented samples, even when trained on noise augmented datasets. This finding demonstrates the brittleness of these systems in realworld conditions. We propose a set of recommendations for noise-based augmentation of emotion datasets and for how to deploy these emotion recognition systems “in the wild”.",ArXiv,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fd9e632b6e9d761909847439bd3598b6f880af7b,https://www.semanticscholar.org/paper/fd9e632b6e9d761909847439bd3598b6f880af7b,Augmented Intelligence: Enhancing the Roles of Health Actuaries and Health Economists for Population Health Management.,"Achieving desired population health and business outcomes requires new levels of productivity, efficiency, and risk minimization. Machine learning (ML), cognitive computing, natural language processing, and other augmented intelligence (AI) tools are increasingly applied to health care initiatives. AI applies to a plethora of artificial intelligence technologies and tools currently used in health care. AI implies any kind of modeling that supplements humans, augmenting human intelligence, not replacing it. Health care decision makers are embracing AI, thereby leveraging information from multiple sources to enable improved individual and population outcomes. ML, for example, applies algorithms and decision-making tools to enormous amounts of clinical data from electronic health records, pharmaceutical databases, and unstructured text data. AI analytics are in predictive risk assessment, clinical decision support, home health monitoring, finance, and resource allocation. These applications are integral to population health management (PHM), Accountable Care Organizations (ACOs), Medicare Advantage, and public health initiatives. A recent hospital survey suggests a promising future for AI that is particularly relevant to PHM. The survey found that, of 7 applications, AI is likely to have the greatest initial impact on population health (24%), clinical decision support (20%), and patient diagnostic tools (20%), followed by precision medicine (14%), and hospital/physician workflow (8%). A variety of AI applications are being tested for health care. But growth and promise can only be met if the additional information is accessible and useful to CEOs and key policy makers. Clinical informatics underlies efforts to improve quality of care and PHM. Considerable work is being done by data scientists, such as Google/Sanofi’s joint venture, Onduo, that will collect and monitor real-time data on people with diabetes. This initiative, like many others, will fail unless there is a way to interpret the data, identify opportunities for intervention, and deliver the information in real time to clinicians and patients. Results are likely to be suboptimal if complex health care AI applications rely only on data scientists. Even with excellent abilities, most data scientists lack industry knowledge and the particular skills of health actuaries (HAs) and health economists (HEs), such as risk analysis and behavioral economics. HA and HE expertise is vital to maximizing value from the use of AI. These players guide health care business decisions, policy making and operations improvements, creating useful outputs for pricing, coverage decisions, business advances, and policy making by applying sophisticated statistical modeling and analytic tools. Although there is overlap between the abilities of actuaries and economists (Table 1), they bring distinct and essential skill sets to an analytic team. AI has been called the world’s most valuable resource as it allows users to extract increasing, ongoing actionable insights and value from myriad sources and uses of data. HAs and HEs can leverage AI to provide expanded and more specific guidance to payers, providers, suppliers, programs, and health systems. For example, AI-enhanced HA expertise helps ACOs to assess and pinpoint risk under capitated contracts. HEs can incorporate the HA evaluation and other AI-enabled analytics to recommend the optimal deployment of care management resources to achieve contracted clinical and financial outcomes. Blending PHM and AI-driven precision medicine could yield a new health care services paradigm. The shift to value-based care has increased the risk borne by providers significantly and increases pressure to identify and manage risk and evaluate outcomes. Innovative use of AI may help identify short-term clinical goals, reduce risk to increase savings, or serve as a return on investment indicator. Opportunities to enhance PHM exist with predictive modeling for identifying high-risk patients. AI tools aid prediction and help identify patients with multiple chronic conditions who are moving across disease states/trajectories that are often associated with increased resource use and cost. Gaps exist. Predictive modeling is hampered by missing pieces – what works and how it works – and gaps in comprehensive information. The common practice of segmenting populations by specific conditions (eg, diabetes) is highly inefficient because most people have multiple chronic conditions. Although HAs use predictive modeling",Population health management,2018,10.1089/pop.2017.0146,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bd19383a9d52a5fdf7c896a21fbfeba7a7c2d0f9,https://www.semanticscholar.org/paper/bd19383a9d52a5fdf7c896a21fbfeba7a7c2d0f9,Harnessing AI for health equity in oncology research and practice.,"67 Background: Recent advances in artificial intelligence (AI) carry underexplored practical and ethical implications for the practice of clinical oncology. As oncologic applications of AI proliferate, a framework for guiding their ethical implementations and equitable distribution will be crucial. Methods: We reviewed the current landscape of AI applications in oncology research and clinical practice by reviewing the current body of evidence in PubMed and Medline. Key ethical challenges and opportunities to address health equity are critically evaluated and highlighted. Ethical implications for patients, clinicians and society at large are delineated, with particular focus on the impact and ramifications of AI with respect to healthcare disparities and equity of oncology care delivery. Results: Growing concerns that AI may widen disparities in oncologic care by virtue of lack of affordability, inconsistent accessibility and biased machine-learning models are addressed. Although there is potential for AI to widen disparities in oncology care, using foresight in application, AI has the potential to (1) democratize access to specialized clinical knowledge, (2) improve the accuracy of predicting cancer susceptibility, recurrence and mortality, (3) prevent diagnostic errors in under-resourced settings, (4) minimize unintended bias and (5) enable access to tailored therapeutic options including clinical trials if appropriately deployed. Separately, AI can be harnessed to identify areas of underserved needs and optimize systems of health-information sharing and reimbursements as blockchain technology converges with AI. As AI advances it will have a larger presence in oncology research and clinical practice. Conclusions: A strategic framework integrating ethical standards and emphasizing equitable implementation can help ensure that the potential of AI to address disparities in oncology are maximally captured and its perils averted. Further work is being done on exploring these challenges and will be submitted as a manuscript.",Journal of Clinical Oncology,2018,10.1200/JCO.2018.36.30_SUPPL.67,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6af4abe9f3360b2817db4a655e1d3486754ba6b0,https://www.semanticscholar.org/paper/6af4abe9f3360b2817db4a655e1d3486754ba6b0,Large-scale learning for media understanding,,EURASIP J. Image Video Process.,2015,10.1186/S13640-015-0080-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
69f91edaf5abc963a9b9b121d1f8bc851333e133,https://www.semanticscholar.org/paper/69f91edaf5abc963a9b9b121d1f8bc851333e133,Active Learning in the Era of Big Data,"Active learning methods automatically adapt data collection by selecting the most informative samples in order to accelerate machine learning. Because of this, real-world testing and comparing active learning algorithms requires collecting new datasets (adaptively), rather than simply applying algorithms to benchmark datasets, as is the norm in (passive) machine learning research. To facilitate the development, testing and deployment of active learning for real applications, we have built an open-source software system for large-scale active learning research and experimentation. The system, called NEXT, provides a unique platform for realworld, reproducible active learning research. This paper details the challenges of building the system and demonstrates its capabilities with several experiments. The results show how experimentation can help expose strengths and weaknesses of active learning algorithms, in sometimes unexpected and enlightening ways.",,2015,10.2172/1225849,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cb3b88a6fa9f278273ec33864e4534feca891d90,https://www.semanticscholar.org/paper/cb3b88a6fa9f278273ec33864e4534feca891d90,A Unified Cloud-Native Architecture For Heterogeneous Data Aggregation And Computation,"Improving healthcare depends on collecting and analyzing different types of health related data such as Electronic Health Records (EHR), Patient Generated Health Data (PGHD), prescription and medication data and medical image data. Even though different solutions in terms of storage and processing have been designed and developed but each solution is usually designed for a specific type of data. Storing, processing, and analyzing all types of data using a single solution necessarily doesn't result in best performance and quality of analysis. To acquire the better quality, each types of data requires its own type of storage, data processing and machine learning solutions which cannot be integrated as a unified system in some cases. In order to have a unified system that serves all types of data we propose a modular cloud native architecture with autonomous modules in terms of control, deployment and management for each types of data.",BCB,2020,10.1145/3388440.3414911,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a21fc370a7e0854d456c921d6a061a84c82ffee,https://www.semanticscholar.org/paper/2a21fc370a7e0854d456c921d6a061a84c82ffee,Letter from the Special Issue Editor,"As Artificial Intelligence (AI) and Machine Learning (ML) are increasingly being used to make consequential decisions that may critically impact individuals and many aspects of our society such as criminal justice, health care, education, and employment, there is a growing recognition that AI systems may perpetuate or, worse, exacerbate the unfairness of existing social systems. To tackle this problem, there has been a sharp recent focus on fair AI/ML research in the Machine Learning community. These efforts tend to focus on how to engineer fair AI models by (a) defining appropriate metrics of fairness and (b) designing new algorithms to mitigate bias and ensure fairness. It however frequently overlooks the messy, complex and ever changing contexts in which these systems are deployed. As AI fairness is a complex socio-technical issue which cannot be addressed by a purely technical solution, designing fair AI systems requires close collaboration across multiple disciplines to deeply integrate the social, historical, legal, and technical context and concerns in the design process. In this special issue on Interdisciplinary Perspectives on Fairness and Artificial Intelligence Systems, leading researchers from engineering, social science and humanities present their work on ethical considerations in developing fair AI systems specifically, and responsible socio-technical systems in general. We sought highquality contributions that integrate ideas from more than one field across the disciplines of technology, social science and the humanities. These papers will provide readers deep insights into the nature and complexity of AI biases, their manifestations in developing practical socio-technical systems and typical mitigation strategies. They also identify opportunities for the AI community to engage with the experts from the humanities. Safiya U. Noble and Sarah T. Roberts from UCLA seek to expand the conversations about socio-technical systems beyond individual, moral and ethical concerns. They believe that the field of “ethical AI” must contend with how it affects and is affected by power structures that encode systems of sexism, racism, and class. They advocate the need for independent research institutes, such as the UCLA Center for Critical Internet Inquiry (C2i2) to promote investigations into the politics, economics, and impacts of technological systems. Jennifer Keating from the University of Pittsburgh discusses the importance of incorporating ethical standards and responsible design features into the development of new technologies. Covid contact tracing was used as a case study to illustrate how rapidly developed tools can have unintended consequences if they are not carefully designed/monitored. She advocates that technologists should collaborate with experts from the humanities to integrate deeper cultural concerns and social/political context into technology development. Lisa Singh and her co-authors from Georgetown University overview the challenges associated with using social media data and the ethical considerations they create. They frame the ethical dilemmas within the context of data privacy and algorithmic fairness and show how and when different ethical concerns arise. Sebastian Schelter from University of Amsterdam and Julia Stoyanovich from NYU present a discussion on technical bias that arises in the data processing pipeline. A number of potential sources of bias during the preprocessing, model development and deployment phases of the ML development lifecycle are identified, with illustrative examples. They show how software support can help avoid these technical bias issues. The broader point of the work is to shed light on the challenge of bias introduced due to data engineering decisions, and to promote an emerging research direction on developing solutions to mitigate it. James Foulds and Shimei Pan from UMBC aim to shed light on whether parity-based metrics are valid measures of AI fairness. They consider the arguments both for and against parity-based fairness definitions and provide a set of guidelines on their use in different contexts. Finally, Jared Sylvester and Edward Raff from Booz Allen Hamilton argue that good-faith efforts toward implementing fairness in practical ML applications should be encouraged, even when the fairness interventions may not result from completely resolving thorny philosophical debates, as this represents progress over the (likely unfair) status quo. This viewpoint is discussed in several contexts: choosing the right fairness metric, solving trolley problems for self-driving cars, and selecting hyper-parameters for fair learning algorithms. James Foulds and Shimei Pan University of Maryland, Baltimore County",IEEE Data Eng. Bull.,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7c2dfedcd85dd55d9cd243df12d3c841b4a1393f,https://www.semanticscholar.org/paper/7c2dfedcd85dd55d9cd243df12d3c841b4a1393f,An Intelligent Mobile-Enabled System for Diagnosing Parkinson Disease: Development and Validation of a Speech Impairment Detection System (Preprint),"
 BACKGROUND
 Parkinson disease (PD) is one of the most common neurological diseases. At present, because the exact cause is still unclear, accurate diagnosis and progression monitoring remain challenging. In recent years, exploring the relationship between PD and speech impairment has attracted widespread attention in the academic world. Most of the studies successfully validated the effectiveness of some vocal features. Moreover, the noninvasive nature of speech signal–based testing has pioneered a new way for telediagnosis and telemonitoring. In particular, there is an increasing demand for artificial intelligence–powered tools in the digital health era.
 
 
 OBJECTIVE
 This study aimed to build a real-time speech signal analysis tool for PD diagnosis and severity assessment. Further, the underlying system should be flexible enough to integrate any machine learning or deep learning algorithm.
 
 
 METHODS
 At its core, the system we built consists of two parts: (1) speech signal processing: both traditional and novel speech signal processing technologies have been employed for feature engineering, which can automatically extract a few linear and nonlinear dysphonia features, and (2) application of machine learning algorithms: some classical regression and classification algorithms from the machine learning field have been tested; we then chose the most efficient algorithms and relevant features.
 
 
 RESULTS
 Experimental results showed that our system had an outstanding ability to both diagnose and assess severity of PD. By using both linear and nonlinear dysphonia features, the accuracy reached 88.74% and recall reached 97.03% in the diagnosis task. Meanwhile, mean absolute error was 3.7699 in the assessment task. The system has already been deployed within a mobile app called No Pa.
 
 
 CONCLUSIONS
 This study performed diagnosis and severity assessment of PD from the perspective of speech order detection. The efficiency and effectiveness of the algorithms indirectly validated the practicality of the system. In particular, the system reflects the necessity of a publicly accessible PD diagnosis and assessment system that can perform telediagnosis and telemonitoring of PD. This system can also optimize doctors’ decision-making processes regarding treatments.
",,2020,10.2196/preprints.18689,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
102eb2f5689f8df20fb82b39afd504c4136ee54b,https://www.semanticscholar.org/paper/102eb2f5689f8df20fb82b39afd504c4136ee54b,Ownership at Large50,"Software-intensive organizations rely on large numbers of software assets of different types, e.g., source-code files, tables in the data warehouse, and software configurations. Who is the most suitable owner of a given asset changes over time, e.g., due to reorganization and individual function changes. New forms of automation can help suggest more suitable owners for any given asset at a given point in time. By such efforts on ownership health, accountability of ownership is increased. The problem of finding the most suitable owners for an asset is essentially a program comprehension problem: how do we automatically determine who would be best placed to understand, maintain, evolve (and thereby assume ownership of) a given asset. This paper introduces the Facebook Ownesty system, which uses a combination of ultra large scale data mining and machine learning and has been deployed at Facebook as part of the company’s ownership management approach. Ownesty processes many millions of software assets (e.g., source-code files) and it takes into account workflow and organizational aspects. The paper sets out open problems and challenges on ownership for the research community with advances expected from the fields of software engineering, programming languages, and machine learning.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d052170e38fcc0ed6f08530ee1aeb0d34cbcbb4b,https://www.semanticscholar.org/paper/d052170e38fcc0ed6f08530ee1aeb0d34cbcbb4b,TOXIC GAS DETECTION AND ANALYSIS USING IOT,"Internet of Things (IoT) is the drifting concept introduced in the smart world. In this project, we have deployed IoT model hardware to get easy remote access through the internet. Industrial Internet of Things (IIoT) is a new concept that contributes to industrialization. In order to make the proposed device much smarter, various technologies such as Machine Learning (ML) and Statistic Data Analytics along with the IoT have been incorporated in this work. This device gathers real-time data and analyzes it appropriately, As it is known, the main element of self-driving philosophy using IoT is a smart machine that captures the data and needs human intervention. Also for better results, the communication of necessary information is a must. This work specifically focusses on safety concerns for the workers working in industrial areas. In this work, we provide a prediction of the value of toxic gases through continuous monitoring, to reduce industrial accidents. Since the intake of gases has an adverse effect on human health.  To achieve this ML regression algorithm is used. The work is carried out by the IoT cloud platform. The proposed prototype consists of UCD3138128 microcontroller, ESP 8266 (Wi-Fi protocol) and Gas sensor MQ-7.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64a02ab14f9e3c088af63512b4a60bc99aa6be9c,https://www.semanticscholar.org/paper/64a02ab14f9e3c088af63512b4a60bc99aa6be9c,Analytics and decision-making to inform public policy in response to diverse threats,,Environment Systems and Decisions,2020,10.1007/s10669-020-09791-y,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
889228f25ca31c2a869d74624a03769e4be6d9e7,https://www.semanticscholar.org/paper/889228f25ca31c2a869d74624a03769e4be6d9e7,Breast cancer classification using parametric free thresholding adjacency statistics based Fibonacci patterns,"According to the American cancer society, the average risk of women getting diagnosed with breast cancer during their life is 13%. The World Health Organization also reports that the number of cancer cases is projected to rise to 19.3 million by 2025. Recent research works point out that physicians can only diagnose cancer with 79% accuracy while machine learning procedures achieve 91% accuracy or more. The current challenges are early cancer detection and the efficient and accurate diagnosis of histopathology tissue samples. Several Deep Learning breast cancer classification models have been developed to assist medical practitioners. However, these methods are data hungry and require thousands of training image samples, often coupled with data augmentation to achieve satisfactory results with long training hours. In this paper, we propose a machine learning classification model by integrating the Parameter free Thresholding Adjacency Statistics (PFTAS) with Fibonacci-p patterns for breast cancer detection. Computer simulations on BreakHis cancer datasets in comparison to other machine learning and deep learning-based methods show that (i) the presented method helps eliminate dependence on large training data and data augmentation, (ii) robustness to noise and background stains, and (iii) lightweight model easy to train and deploy.",,2020,10.1117/12.2558613,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
77b87bda93a82f067fe035e39dd10b415633f3e5,https://www.semanticscholar.org/paper/77b87bda93a82f067fe035e39dd10b415633f3e5,Classifying strength exercises performed by wheelchair users using accelerometer data of wearables,"Inadequate physical activity increases the risk of various health problems. For wheelchair users, physical activity can be more challenging and daily goals are often not met. Wearables and e-platforms do not offer wheelchair users the same benefits as non-wheelchair users. With the help of accelerometer data obtained by multiple accelerometer devices, we studied human activity recognition (HAR) for strength exercises performed by 40 wheelchair users with a spinal cord injury (SCI) or lower limb amputation (LLA). The classification of seven strength exercise categories was done with supervised machine learning techniques including a recurrent neural network (RNN). To determine the performance of the classifier, we compared the performance between classifying strength exercises with daily activities. In addition, we tested our models to injury-specific subgroups to detect diversity between different types of wheelchair users. With these experiments, we concluded that creating a classification model for strength exercises in a free moving fitness environment is challenging. Wheelchair users tend to perform exercises with different execution forms, due to variation in physical limitations. Our model is not accurate enough for a reasonable adjustment to energy expenditure estimation with an accuracy score of 0.55. Improvement of the model within the field of strength exercises among wheelchair users is necessary before it can actually be deployed to wearables and e-platforms.",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
57e6482fbaa502e66679325acf7c9b197927edc9,https://www.semanticscholar.org/paper/57e6482fbaa502e66679325acf7c9b197927edc9,Baseline Modelling and Composite Representation of Unobtrusively (IoT) Sensed Behaviour Changes Related to Urban Physical Well-Being,,ICOST,2020,10.1007/978-3-030-51517-1_13,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
66200b4a38011ccd1a5092b67b32a42992413d7d,https://www.semanticscholar.org/paper/66200b4a38011ccd1a5092b67b32a42992413d7d,Learning from Clinical Judgments: Semi-Markov-Modulated Marked Hawkes Processes for Risk Prognosis,"Critically ill patients in regular wards are vulnerable to unanticipated adverse events which require prompt transfer to the intensive care unit (ICU). To allow for accurate prognosis of deteriorating patients, we develop a novel continuous-time probabilistic model for a monitored patient's temporal sequence of physiological data. Our model captures ""informatively sampled"" patient episodes: the clinicians' decisions on when to observe a hospitalized patient's vital signs and lab tests over time are represented by a marked Hawkes process, with intensity parameters that are modulated by the patient's latent clinical states, and with observable physiological data (mark process) modeled as a switching multi-task Gaussian process. In addition, our model captures ""informatively censored"" patient episodes by representing the patient's latent clinical states as an absorbing semi-Markov jump process. The model parameters are learned from offline patient episodes in the electronic health records via an EM-based algorithm. Experiments conducted on a cohort of patients admitted to a major medical center over a 3-year period show that risk prognosis based on our model significantly outperforms the currently deployed medical risk scores and other baseline machine learning algorithms.",ICML,2017,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5c0fbc6e7c5f62c5e117106b319ccf55703f9119,https://www.semanticscholar.org/paper/5c0fbc6e7c5f62c5e117106b319ccf55703f9119,Active learning for accurate analysis of streaming partial discharge data,"Partial discharge (PD) is a phenomenon of electric discharge typically caused by the damaged or aged insulation of high voltage equipment in power grids, such as transformers, switch gears, and cable terminals. In the context of Prognostic and Health Management (PHM), detection and monitoring of PD are important to ensure the reliability of electrical assets and to avoid catastrophic failures. Machine learning techniques have been successfully applied to discover features and patterns that correspond to different types of partial discharges [9], [11]. Recently, PD monitoring systems have being deployed for assessing the health condition of these equipments continuously so that the maintenance would require less human effort and fewer maintenance interruptions to the operation. However, such systems require labeled data to build data models for PD detection and classification. Labeled data is expensive to obtain since it requires domain expert's manual inputs. Minimizing the labeling cost is thus an important issue to solve. To the best of our knowledge, this issue has not been properly addressed in this domain. This paper proposes an active learning (AL) approach for accurate analysis of streaming PD data that aims to train an accurate PD classification model with minimum cost through selecting the most informative instances for the human experts to label. Experimental results show that our method is able to achieve the high classification accuracy of 86.9% with only a small labeling budget of 1 %.",2015 IEEE Conference on Prognostics and Health Management (PHM),2015,10.1109/ICPHM.2015.7245026,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
476d47e52eb28f286db022788acb554a585e45a6,https://www.semanticscholar.org/paper/476d47e52eb28f286db022788acb554a585e45a6,Privacy-Preserving Technology to Help Millions of People: Federated Prediction Model for Stroke Prevention,"prevention of stroke with its associated risk factors has been one of the public health priorities worldwide. Emerging artificial intelligence technology is being increasingly adopted to predict stroke. Because of privacy concerns, patient data are stored in distributed electronic health record (EHR) databases, voluminous clinical datasets, which prevent patient data from being aggregated and restrains AI technology to boost the accuracy of stroke prediction with centralized training data. In this work, our scientists and engineers propose a privacy-preserving scheme to predict the risk of stroke and deploy our federated prediction model on cloud servers. Our system of federated prediction model asynchronously supports any number of client connections and arbitrary local gradient iterations in each communication round. It adopts federated averaging during the model training process, without patient data being taken out of the hospitals during the whole process of model training and forecasting. With the privacy-preserving mechanism, our federated prediction model trains over all the healthcare data from hospitals in a certain city without actual data sharing among them. Therefore, it is not only secure but also more accurate than any single prediction model that trains over the data only from one single hospital. Especially for small hospitals with few confirmed stroke cases, our federated model boosts model performance by 10%~20% in several machine learning metrics. To help stroke experts comprehend the advantage of our prediction system more intuitively, we developed a mobile app that collects the key information of patients' statistics and demonstrates performance comparisons between the federated prediction model and the single prediction model during the federated training process.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17af969fdf80f2e8d426984a04aeae659bee1dc5,https://www.semanticscholar.org/paper/17af969fdf80f2e8d426984a04aeae659bee1dc5,Four equity considerations for the use of artificial intelligence in public health,"New technologies can either improve or worsen health inequities.1 Innovative technologies involving artificial intelligence are no exception, particularly where they are adopted and implemented in health systems. Indeed, determining whether and how artificial intelligence might contribute to reducing or exacerbating health inequities has been identified as a priority research area by several stakeholders and by numerous ethics and policy guidance documents.2–4 Understanding the connection between health inequities and artificial intelligence should be a priority when deploying these technologies in public health. Since public health activities typically target populations instead of individuals and require collective action instead of individual intervention,5 introducing artificial intelligence technologies to support these activities may influence (either positively or negatively, intentionally or unintentionally) health inequities more than in other areas. As such, identifying the distinctive equity considerations and dimensions that might emerge in the public health context is critical. However, doing so is not a straightforward task. First, we cannot simply look to past technological innovations to determine which health equity considerations or implications might arise with the use of artificial intelligence in public health because technological innovations and their diffusion in health systems each produce or interact with health inequities in novel ways.1 We may not be able to assume that the trends or pathways that create or prevent inequities will be the same when implementing artificial intelligence technologies as they are with other technological innovations. This limitation may be particularly challenging with artificial intelligence technologies given their use of big data and machine learning. Second, artificial intelligence represents a vast and sometimes contested area of study and application. Here we define artificial intelligence as a branch of computer science that explores the ability of computers to imitate aspects of intelligent human behaviour, such as problem-solving, reasoning and recognition.2 Technologies that are supported by artificial intelligence are therefore numerous, and include natural language processing, object recognition and reinforcement learning, among others. The ways in which these technologies might be deployed in public health are equally numerous, including digital disease surveillance, machine learning to predict incidences of noncommunicable diseases, and others. Finally, given that health inequities are often defined as differences in health that are unjust, even what should be counted as health inequities and what it means to achieve health equity may differ according to the nature of the new technology, how it is or has been integrated into health systems and our judgements about its interaction with the public’s health.6 As a result, before research or health system interventions in this area are developed or implemented, we should first seek to conceptually map the unique ways in which inequities might manifest when artificial intelligence is implemented or used in public health. Indeed, important work examining the unique equity dimensions associated with specific artificial intelligence technologies in this area has begun.7 Yet, we posit that there are general equity considerations and dimensions that can be identified and used as starting points for the reflection of equitable artificial intelligence in public health, and that it would be of benefit for the field to have these identified and enumerated. We will briefly describe four key equity considerations and dimensions and conclude by discussing how they can be used as starting points to further understand and enhance the equitable deployment of artificial intelligence in public health.",Bulletin of the World Health Organization,2020,10.2471/blt.19.237503,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
25adb47d872026fa084296fa5051539318de4cbf,https://www.semanticscholar.org/paper/25adb47d872026fa084296fa5051539318de4cbf,Artificial Intelligence in Ophthalmology: Evolutions in Asia.,"Artificial intelligence (AI) has been studied in ophthalmology since availability of digital information in ophthalmic care. The significant turning point was availability of commercial digital color fundus photography in the late 1990s, which caused digital screening for diabetic retinopathy (DR) to take off. Automated Retinal Disease Assessment software was then developed using machine learning to detect abnormal lesions in fundus to screen DR. The use of this version of AI had not been generalized because the specificity at 45% was not high enough, although the sensitivity reached 90%. The recent breakthrough in machine learning is the invent of deep learning, which accelerates its performance to be on par with experts. The first 2 breakthrough studies on deep learning for screening DR were conducted in Asia. The first represented collaboration of datasets between Asia and the United States for algorithms development, whereas the second represented algorithms developed in Asia but validated in different populations across the world. Both found accuracy for detecting referable DR of >95%. Diversity and variety are unique strengths of Asia for AI studies. There are many more studies of AI ongoing in Asia not only as prospective deployments in DR but in glaucoma, age-related macular degeneration, cataract, and systemic disease, such as Alzheimer's disease. Some Asian countries have laid out plans for digital health care system using AI as one of the puzzle pieces for solving blindness. More studies on AI and digital health are expected to come from Asia in this new decade.",Asia-Pacific journal of ophthalmology,2020,10.1097/01.APO.0000656980.41190.bf,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
256d9de117058607477769223fc410a7742968c8,https://www.semanticscholar.org/paper/256d9de117058607477769223fc410a7742968c8,Biomarkers and neuromodulation techniques in substance use disorders,,Bioelectronic medicine,2020,10.1186/s42234-020-0040-0,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
641076d8786511559cd31b96fc2c93426120ad47,https://www.semanticscholar.org/paper/641076d8786511559cd31b96fc2c93426120ad47,Multiaccuracy: Black-Box Post-Processing for Fairness in Classification,"Prediction systems are successfully deployed in applications ranging from disease diagnosis, to predicting credit worthiness, to image recognition. Even when the overall accuracy is high, these systems may exhibit systematic biases that harm specific subpopulations; such biases may arise inadvertently due to underrepresentation in the data used to train a machine-learning model, or as the result of intentional malicious discrimination. We develop a rigorous framework of *multiaccuracy* auditing and post-processing to ensure accurate predictions across *identifiable subgroups*. Our algorithm, MULTIACCURACY-BOOST, works in any setting where we have black-box access to a predictor and a relatively small set of labeled data for auditing; importantly, this black-box framework allows for improved fairness and accountability of predictions, even when the predictor is minimally transparent. We prove that MULTIACCURACY-BOOST converges efficiently and show that if the initial model is accurate on an identifiable subgroup, then the post-processed model will be also. We experimentally demonstrate the effectiveness of the approach to improve the accuracy among minority subgroups in diverse applications (image classification, finance, population health). Interestingly, MULTIACCURACY-BOOST can improve subpopulation accuracy (e.g. for ""black women"") even when the sensitive features (e.g. ""race"", ""gender"") are not given to the algorithm explicitly.",AIES,2018,10.1145/3306618.3314287,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
09a0cd6d18bc2f2ea6beae570bb95f7ebf5dd854,https://www.semanticscholar.org/paper/09a0cd6d18bc2f2ea6beae570bb95f7ebf5dd854,Measuring Depression Symptom Severity from Spoken Language and 3D Facial Expressions,"With more than 300 million people depressed worldwide, depression is a global problem. Due to access barriers such as social stigma, cost, and treatment availability, 60% of mentally-ill adults do not receive any mental health services. Effective and efficient diagnosis relies on detecting clinical symptoms of depression. Automatic detection of depressive symptoms would potentially improve diagnostic accuracy and availability, leading to faster intervention. In this work, we present a machine learning method for measuring the severity of depressive symptoms. Our multi-modal method uses 3D facial expressions and spoken language, commonly available from modern cell phones. It demonstrates an average error of 3.67 points (15.3% relative) on the clinically-validated Patient Health Questionnaire (PHQ) scale. For detecting major depressive disorder, our model demonstrates 83.3% sensitivity and 82.6% specificity. Overall, this paper shows how speech recognition, computer vision, and natural language processing can be combined to assist mental health patients and practitioners. This technology could be deployed to cell phones worldwide and facilitate low-cost universal access to mental health care.",ArXiv,2018,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4e959b639e9e7502ef280a804b4bdc0435613a97,https://www.semanticscholar.org/paper/4e959b639e9e7502ef280a804b4bdc0435613a97,A threat intelligence framework for protecting smart satellite-based healthcare networks,,Neural computing & applications,2021,10.1007/s00521-021-06441-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5c07c90b2c02e8af013d562f1d375440906047d,https://www.semanticscholar.org/paper/d5c07c90b2c02e8af013d562f1d375440906047d,Entity recognition from clinical texts via recurrent neural network,,BMC Medical Informatics and Decision Making,2017,10.1186/s12911-017-0468-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5145a690dc4e37a7e72aeaf5fda6f7e534f36ff9,https://www.semanticscholar.org/paper/5145a690dc4e37a7e72aeaf5fda6f7e534f36ff9,Smart-bot Technology: Conversational Agents Role in Maternal Healthcare Support,"There is a need for a system that respond to various queries in real-time, to advice and inform expectant mothers during their pregnancy. Several smart services have been deployed, bundled with health information systems, and other digital services. While such solutions better services in the healthcare settings, they may not be available to the masses in the rural. Besides they rarely dispense this information precisely and or accurately. A new digital ecosystem, represented by chatbots seem to offer promising solution by embodying the function of a virtual healthcare expert, who is always available to provide information in the required precision. Powered by AI and machine learning algorithms, chatbots are forecasted to bring forth accuracy, precision and availability of information when used. This paper discusses the need to develop chatbots to be integrated in smart phones; intended to provide support to to-be mothers during their journey in pregnancy.",2019 IST-Africa Week Conference (IST-Africa),2019,10.23919/ISTAFRICA.2019.8764817,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4a25026af3cc3c4be580f09469fd72e069f7551f,https://www.semanticscholar.org/paper/4a25026af3cc3c4be580f09469fd72e069f7551f,Artificial Intelligence and the Future of Work,"This article analyses how artificial intelligence (AI) can transform work, considering both the potential of this technology and its limits. The sectoral approach adopted, focusing on the health, transport and banking sectors, allows for a detailed analysis of both the opportunities and risks as well as the evolution of tasks, learning dynamics, and changes in working conditions and management practices. The analysis shows that the tasks making up jobs in these sectors cannot always be automated with AI and that in many cases AI-based devices are used in a way that is complimentary to the skills of human workers. For this reason, and irrespective of the impact of AI on the overall level of employment, the analysis shows that the deployment of AI depends on continuous learning and skills development. The article concludes by arguing that learning forms of work organization are best suited for fostering complementarity between the machine and the human.JEL classification: O31, O33, JE53, L63, L90, M15.",Revue d'économie industrielle,2020,10.4000/rei.8727,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ff818b0ca9904936f5473f8fa904c3b585d9438e,https://www.semanticscholar.org/paper/ff818b0ca9904936f5473f8fa904c3b585d9438e,Customization scenarios for de-identification of clinical notes,,BMC Medical Informatics and Decision Making,2020,10.1186/s12911-020-1026-2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
44895ec003ae7fa4675b25c1e5fede4cfcc7b3bd,https://www.semanticscholar.org/paper/44895ec003ae7fa4675b25c1e5fede4cfcc7b3bd,"Automated Clinical Coding: What, Why, and Where We Are?","Clinical coding is the task of transforming medical information in a patient’s health records into structured codes so that they can be used for statistical analysis. This is a cognitive and time-consuming task that follows a standard process in order to achieve a high level of consistency. Clinical coding could potentially be supported by an automated system to improve the efficiency and accuracy of the process. We introduce the idea of automated clinical coding and summarise its challenges from the perspective of Artificial Intelligence (AI) and Natural Language Processing (NLP), based on the literature, our project experience over the past two and half years (late 2019 early 2022), and discussions with clinical coding experts in Scotland and the UK. Our research reveals the gaps between the current deep learning-based approach applied to clinical coding and the need for explainability and consistency in real-world practice. Knowledge-based methods that represent and reason the standard, explainable process of a task may need to be incorporated into deep learning-based methods for clinical coding. Automated clinical coding is a promising task for AI, despite the technical and organisational challenges. Coders are needed to be involved in the development process. There is much to achieve to develop and deploy an AI-based automated system to support coding in the next five years and beyond. Figure 1. An example of clinical coding, manual and automated (linked with solid and dashed arrows, respectively), with ICD-9-CM codes from a clinical note in the MIMIC-III dataset [9] of ICU patients in 2001-2012 in a hospital in the US. Dashed arrows between clinical coders and the automated coding system suggest potential interactions between them, while this is yet to be considered in many clinical coding systems. Note that the format of data and clinical codes does not reflect the situation of other regions in the world for example, in the UK, where data may be less structured and there is no universal discharge summary available. 1 The icon of “Clinical Coders” was from Freepik in Flaticon, https://www.flaticon.com/free-icon/user_747376, under the Flaticon licence (attribution required). The icon of “Automated Coding System” was from https://iconlibrary.com/png/272370.html, under the Attribution 3.0 Unported (CC BY 3.0) licence. Introduction: what is (automated) clinical coding? Clinical coding is the task of transforming medical records, usually presented as free texts written by clinicians, into structured codes in a classification system like ICD-10 (International Classification of Diseases). For example, in Scotland, this means to apply a standard process to classify information about patients into appropriate diagnosis and procedure codes in ICD and OPCS, finally contributing to the Scottish Morbidity Records (SMR01) national dataset. The process of coding usually includes data abstraction or summarisation [1]. The purpose of clinical coding is to provide consistent and comparable clinical information across units of care and over time. The resulting national data are used to support areas, such as health improvement, inform healthcare planning and policy and add to the epidemiological understanding of a wide variety of conditions, so confidence in the data is essential. Also, codes are used for billing purposes in the US. For introductory slides about clinical coding in the UK provided by NHS Digital, see Clinical coding for non coders. Clinical coding is a non-trivial task for humans. An expert clinical coder is expected to decipher a large number of documents about a patient’s episode of care, and to select the most accurate codes from a large classification system (or an ontology), according to the contexts in the various documents and the regularly updated coding guidelines. For example, coding in the US adopts the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM), which has around 68,000 codes. There is a standard process for manual coding to ensure data consistency: textual analysis, summarisation, and clearly defined steps to classification into codes (or the four steps of analyse, locate, assign, and verify as suggested by the NHS digital in the coding standard of 2021 [2, p.11]). The process minimises the risk of introducing variations caused by artefacts (potentially leading to wrong decision making), thus collecting and analysing data and applying the standard is important. There are regularly updated guidelines and standards for coding (e.g., in Public Health Scotland). Usually, it can take months and longer to train an expert clinical coder in the NHS (National Health Service) in the UK. Automated clinical coding is the idea that clinical coding may be automated by computers using AI technologies [3]. It is a branch of computer-assisted coding (CAC) [4]. In recent years, AI has been considered as a promising approach to transforming healthcare by intelligently processing the increasing amount of data with machine learning and NLP techniques [5]. Automated clinical coding is a potential AI application to facilitate the administration and management of clinical records in the hospital and medical research. There has been a surge of articles for automated clinical coding with deep learning (as the current mainstream approach of AI) for the last few years, as reviewed in [6-8]. However, while there is some progress for automated clinical coding, the task is far from solved. For the last two years and more, we have been working on the task and discussing with practitioners of clinical coding and clinicians from Scotland and the UK. We illustrate the manual and automated clinical coding process, and their potential interactions, in Figure 1. In this paper, we aim to summarise the technical challenges of clinical coding, mainly related to deep learning, and propose directions for future research in this area. Why do we need automated clinical coding? There are some major reasons that automated clinical coding can be helpful. First, manual coding is time-consuming. A clinical coder in NHS Scotland usually codes about 60 cases a day (equivalent to 7-8min for each case) and an NHS coding department of around 25 to 30 coders usually codes over 20,000 cases per month. Even so, there is a backlog of cases to be coded, which can take several months or more (e.g., over a year [10]). Second, manual coding may be prone to errors. This may be due to incompleteness in a patient’s data, subjectivity in choosing the diagnosis codes, lack of coding expertise, or data entry errors [1]. The average accuracy of coding in the UK was around 83% with a large variance among studies (50-98%) [11]. In Scotland, the accuracy of coding is very high (e.g. in 2019-2020, achieved 92.5% for 3-digit code accuracy and 88.8% for 4-digit code accuracy of main conditions), yet still not perfect and under-coding occurs (for around 20% of the common conditions). On the other hand, computer-assisted coding could improve the accuracy, quality, and efficiency of manual coding, according to a recent, qualitative literature 2 https://www.ndc.scot.nhs.uk/National-Datasets/data.asp?SubID=5 3 https://www.aapc.com/medical-coding/medical-coding.aspx 4 https://hscic.kahootz.com/gf2.ti/f/762498/30719205.1/PPSX/-/Coding_for_non_coders_automaticnew.ppsx 5 https://www.isdscotland.org/Products-and-services/Terminology-services/Clinical-coding-guidelines/ 6 https://beta.isdscotland.org/media/7465/assessment-of-smr01-data-scotland-report-2019-v1.pdf review [4]. We believe that with recent AI technologies (for example, NLP), automated coding has the potential to better support clinical coders. We mostly focus on the case that AI directly contributes to clinical codes. Why is automated coding a complex problem to solve? While humans can achieve high accuracy in clinical coding, the standard procedure, text analysis, text summarisation, and classification into codes, poses immense challenges for computer-based systems. This requires Natural Language Understanding (NLU), one of the classical but largely unsolved areas of AI [12-13], and the linking of natural language to knowledge representations like the ICD-10 classification system. Also, this clinical task poses more specific challenges compared to common NLU tasks. From our experience, these relate mainly to the following difficulties: 1. Clinical documents are variously structured, notational, lengthy, and incomplete. Clinical coding requires the understanding of texts in clinical documents, which is usually different from other types of documents like publications or texts from social media. They have variable document structures, they can be lengthy (on average around 1500 words [14] in only the discharge summaries in a US intensive care dataset, MIMIC-III [9]), and use variable abbreviations (e.g., “a [xx] y/o M w/ Hep C, HTN, CKD, a/w HTN emergency” in a discharge summary in MIMICIII) and terse symbols (e.g., the use of “?” to denote uncertainty and “+” to denote a positive test). Coding also requires the understanding of the entirety of a patient’s records, which includes multiple types of documents (e.g. discharge summaries, radiology reports, pathology reports, etc.). These documents are not always in a structured format and are sometimes incomplete or missing. 2. Classification systems used for coding are complex and dynamic. The ICD-10-CM system has around 68,000 codes in a large hierarchy. The ICD-11 system (started in Jan 2022, but yet to be used in practice at the time of writing) introduces significant changes in chapter structure, diagnostic categories, diagnostic criteria, etc. [15] Besides, classification standards are updated regularly (e.g. usually every few months in Public Health Scotland). Automated clinical coding needs to work with dynamic and complex classification systems. 3. The social-technical issues with automated clinical coding systems ",ArXiv,2022,10.48550/arXiv.2203.11092,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ce7218f09a6b91eb06122133068234b8702fa384,https://www.semanticscholar.org/paper/ce7218f09a6b91eb06122133068234b8702fa384,Artificial Intelligence Predictive Analytics in the Management of Outpatient MRI Appointment No-Shows.,"OBJECTIVE. Outpatient appointment no-shows are a common problem. Artificial intelligence predictive analytics can potentially facilitate targeted interventions to improve efficiency. We describe a quality improvement project that uses machine learning techniques to predict and reduce outpatient MRI appointment no-shows. MATERIALS AND METHODS. Anonymized records from 32,957 outpatient MRI appointments between 2016 and 2018 were acquired for model training and validation along with a holdout test set of 1080 records from January 2019. The overall no-show rate was 17.4%. A predictive model developed with XGBoost, a decision tree-based ensemble machine learning algorithm that uses a gradient boosting framework, was deployed after various machine learning algorithms were evaluated. The simple intervention measure of using telephone call reminders for patients with the top 25% highest risk of an appointment no-show as predicted by the model was implemented over 6 months. RESULTS. The ROC AUC for the predictive model was 0.746 with an optimized F1 score of 0.708; at this threshold, the precision and recall were 0.606 and 0.852, respectively. The AUC for the holdout test set was 0.738 with an optimized F1 score of 0.721; at this threshold, the precision and recall were 0.605 and 0.893, respectively. The no-show rate 6 months after deployment of the predictive model was 15.9% compared with 19.3% in the preceding 12-month preintervention period, corresponding to a 17.2% improvement from the baseline no-show rate (p < 0.0001). The no-show rates of contactable and noncontactable patients in the group at high risk of appointment no-shows as predicted by the model were 17.5% and 40.3%, respectively (p < 0.0001). CONCLUSION. Machine learning predictive analytics perform moderately well in predicting complex problems involving human behavior using a modest amount of data with basic feature engineering, and they can be incorporated into routine workflow to improve health care delivery.",AJR. American journal of roentgenology,2020,10.2214/ajr.19.22594,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3426cafb917eb04e9c79e911ddf598f5487b2e81,https://www.semanticscholar.org/paper/3426cafb917eb04e9c79e911ddf598f5487b2e81,Predicting Days in Hospital using Health Insurance Claims,"Health insurance costs across the world have increased alarmingly in recent years. A major cause of this increase is payment errors made by the insurance companies while processing claims. These errors often result in extra administrative effort to re-process (or rework) the claim which accounts for up to 30% of the administrative staff in a typical health insurer. We describe a system that helps reduce these errors using machine learning techniques by predicting claims that will need to be reworked, generating explanations to help the auditors correct these claims, and experiment with feature selection, concept drift, and active learning to collect feedback from the auditors to improve over time. We describe our framework, problem formulation, evaluation metrics, and experimental results on claims data from a large US health insurer. We show that our system results in an order of magnitude better precision (hit rate) over existing approaches which is accurate enough to potentially result in over $15-25 million in savings for a typical insurer. We also describe interesting research problems in this domain as well as design choices made to make the system easily deployable across health insurance companies.",,2016,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bb4ac7e4239569e2a59e7e7dbb6f0d1bfa8ce4ca,https://www.semanticscholar.org/paper/bb4ac7e4239569e2a59e7e7dbb6f0d1bfa8ce4ca,APPLAUSE: Automatic Prediction of PLAcental health via U-net Segmentation and statistical Evaluation,"Purpose: Artificial-intelligence population-based automated quantification of placental maturation and health from a rapid functional Magnetic Resonance scan. The placenta plays a crucial role for any successful human pregnancy. Deviations from the normal dynamic maturation throughout gestation are closely linked to major pregnancy complications. Antenatal assessment in-vivo using T2* relaxometry has shown great promise to inform management and possible interventions but clinical translation is hampered by time consuming manual segmentation and analysis techniques based on comparison against normative curves over gestation. Methods: This study proposes a fully automatic pipeline to predict the biological age and health of the placenta based on a rapid (sub-30 second) T2* scan in two steps: Automatic segmentation using a U-Net and a Gaussian Process regression model to characterize placental maturation and health. These are trained and evaluated on 110 3T MRI placental data sets including 20 high-risk pregnancies diagnosed with pre-eclampsia and/or fetal growth restriction. Results: Automatic segmentation achieves comparable performance to human experts (mean DICE coefficients automatic-manual 0.76, Pearson Correlation Coefficient 0.986 for mean T2* within the masks). The placental health prediction achieves an excellent ability to differentiate early cases of placental insufficiency before 32 weeks. High abnormality scores correlate with low birth weight, premature birth and histopathological findings. Retrospective application on a different cohort imaged at 1.5T illustrates the ability for direct clinical translation. Conclusion: The presented automatic pipeline facilitates a fast, robust and reliable prediction of placental maturation. It yields human-interpretable and verifiable intermediate results and quantifies uncertainties on the cohort-level and for individual predictions. The proposed machine-learning pipeline runs in close to real-time and, deployed in clinical settings, has the potential to become a cornerstone of diagnosis and intervention of placental insufficiency.",medRxiv,2020,10.1101/2020.09.22.20199521,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
514e6d865f9e43550a9442d8608fd3787c3df39e,https://www.semanticscholar.org/paper/514e6d865f9e43550a9442d8608fd3787c3df39e,Remote health monitoring: Predicting outcome success based on contextual features for cardiovascular disease,"Current studies have produced a plethora of remote health monitoring (RHM) systems designed to enhance the care of patients with chronic diseases. Many RHM systems are designed to improve patient risk factors for cardiovascular disease, including physiological parameters such as body mass index (BMI) and waist circumference, and lipid profiles such as low density lipoprotein (LDL) and high density lipoprotein (HDL). There are several patient characteristics that could be determining factors for a patient's RHM outcome success, but these characteristics have been largely unidentified. In this paper, we analyze results from an RHM system deployed in a six month Women's Heart Health study of 90 patients, and apply advanced feature selection and machine learning algorithms to identify patients' key baseline contextual features and build effective prediction models that help determine RHM outcome success. We introduce Wanda-CVD, a smartphone-based RHM system designed to help participants with cardiovascular disease risk factors by motivating participants through wireless coaching using feedback and prompts as social support. We analyze key contextual features that secure positive patient outcomes in both physiological parameters and lipid profiles. Results from the Women's Heart Health study show that health threat of heart disease, quality of life, family history, stress factors, social support, and anxiety at baseline all help predict patient RHM outcome success.",2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society,2014,10.1109/EMBC.2014.6943953,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cd820dec2a922b8287e8b1b3119d2b39313f6df1,https://www.semanticscholar.org/paper/cd820dec2a922b8287e8b1b3119d2b39313f6df1,A Wireless Mobile Sensor Platform for Structural Health Monitoring,"Modern system identification (SID) procedures rely on fixed sensor networks for data collection. Ideally, sensors are fixed at locations and contain profitable structural responses, however, such sensing areas are often limited by the accessibility of the structure and environmental hazards. Not only are fixed sensor placements limited, the data contains restricted spatial information. Mobile sensors simultaneously record data in time while moving in space, so that few sensors collect data containing dense, less-restricted spatial information, providing a more cost-effective solution than a dense array of static sensors. Mobile sensor data contain fundamentally different attributes than fixed sensor data. Such data can be classified as dynamic sensor network (DSN) data, which inherently include spatial discontinuities whenever sensors change position. Despite this challenge, such data can be processed for identification using an iterative machine learning technique Structural Identification using Expectation Maximization (STRIDE). Furthermore, the preservation of spatial information in mobile sensor networks has been quantified throughout simulations: given the same number of sensors, a mobile sensor network produces superior spatial information when compared to a static sensor network. In this paper, ambient vibrations of a simple beam test-bed are measured by a wireless mobile sensor network which includes four parallel lines of motor-driven belts that tow an array of sensor carts along the span of the beam. Feedback between the step motor and a computer was established to achieve a precise spatial grid for the mobile sensors. Modal identification results are presented, documenting the accuracy and feasibility of a realworld mobile sensor network for SID.",,2015,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
88b4a63f544b2d9fcc797dde768a813458c1dcce,https://www.semanticscholar.org/paper/88b4a63f544b2d9fcc797dde768a813458c1dcce,Improving Regulatory Effectiveness Through Better Targeting: Evidence from OSHA,"We study how a regulator can best allocate its limited inspection resources. We direct our analysis to a US Occupational Safety and Health Administration (OSHA) inspection program that targeted dangerous establishments and allocated some inspections via random assignment. We find that inspections reduced serious injuries by an average of 9% over the following five years. We use new machine learning methods to estimate the effects of counterfactual targeting rules OSHA could have deployed. OSHA could have averted over twice as many injuries if its inspections had targeted the establishments where we predict inspections would avert the most injuries. The agency could have averted nearly as many additional injuries by targeting the establishments predicted to have the most injuries. Both of these targeting regimes would have generated over $1 billion in social value over the decade we examine. Our results demonstrate the promise, and limitations, of using machine learning to improve resource allocation. JEL Classifications: I18; L51; J38; J8",SSRN Electronic Journal,2019,10.2139/ssrn.3443052,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10bbc5556fe6b79b18bb986af5e601b7ac7ab114,https://www.semanticscholar.org/paper/10bbc5556fe6b79b18bb986af5e601b7ac7ab114,LTF: A Label Transformation Framework for Correcting Target Shift,"Distribution shift is a major obstacle to the deployment of current deep learning models on realworld problems. Let Y be the target (label) and X the predictors (features). We focus on one type of distribution shift, target shift, where the marginal distribution of the target variable PY changes but the conditional distribution PX|Y does not. Existing methods estimate the density ratio between the sourceand target-domain label distributions by density matching. However, these methods are either computationally infeasible for large-scale data or restricted to shift correction for discrete labels. In this paper, we propose an end-to-end Label Transformation Framework (LTF) for correcting target shift, which implicitly models the shift of PY and the conditional distribution PX|Y using neural networks. Thanks to the flexibility of deep networks, our framework can handle continuous, discrete, and even multidimensional labels in a unified way and is scalable to large data. Moreover, for high dimensional X , such as images, we find that the redundant information in X severely degrades the estimation accuracy. To remedy this issue, we propose to match the distribution implied by our generative model and the target-domain distribution in a low-dimensional feature space that discards information irrelevant to Y . Both theoretical and empirical studies demonstrate the superiority of our method over previous approaches. UBTECH Sydney AI Centre, School of Computer Science, Faculty of Engineering, The University of Sydney, Darlington, NSW 2008, Australia School of Mathematics and Statistics, The University of Melbourne Department of Philosophy, Carnegie Mellon University. Correspondence to: Jiaxian Guo <jguo5934@uni.sydney.edu.au>. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).",,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c17a6cdf91b8a72faf59a66237ec1b40540a1894,https://www.semanticscholar.org/paper/c17a6cdf91b8a72faf59a66237ec1b40540a1894,NEW STATISTICAL LEARNING METHODS FOR PERSONALIZED MEDICAL DECISION MAKING,"Xuan Zhou: New Statistical Learning Methods for Personalized Medical Decision Making (Under the direction of Donglin Zeng and Yuanjia Wang) This research focuses on developing new and computationally efficient statistical learning methods for multicategory classification and personalized medical decision making. Motivated by the challenge of multicategory classification problems, and the computational efficiency and theoretical properties of support vector machines (SVM), a novel learning algorithm is proposed. The method is then adapted to estimating multicategory individualized treatment rules by connecting with outcome weighted learning (Zhao et al., 2012). At last, an application to Electronic Health Record data is explored. The proposed algorithm, forward-backward SVM (FB-SVM) is based on a sequential binary classification algorithm and relies on support vector machines for each binary classification and utilizes only feasible data in each step. Therefore, the method guarantees convergence and entails light computational burden. More importantly, we prove the theoretical property of Fisher consistency of the classification rule derived from the FB-SVM, which is not guaranteed by existing algorithms. We also obtain the risk bound for the predicted misclassification rate. We conduct extensive simulation and application studies, using popular benchmarking data and data from a newly completed realworld study, to demonstrate that the proposed method has superior performance, in terms of low misclassification rates and significantly improved computational speed when compared to existing methods. Furthermore, we generalize the proposed FB-SVM with outcome weighted learning to estimate optimal individualized treatment rule (ITR) with multiple options of treatment, namely sequential outcome-weighted learning (SOM). Specifically, we solve a multicategory treatment selection problem via sequential weighted support vector machines. Theoretically, we show that the resulting ITR is Fisher consistent. We demonstrate the performance of proposed method with extensive simulations.",,2018,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8d5f6d1a600d9e1ecef890954478268db41cc3d8,https://www.semanticscholar.org/paper/8d5f6d1a600d9e1ecef890954478268db41cc3d8,Measuring Use of Evidence Based Psychotherapy for Posttraumatic Stress Disorder in a Large National Healthcare System,,Administration and Policy in Mental Health and Mental Health Services Research,2018,10.1007/s10488-018-0850-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a20ed3521bd0041a22cf4dacd90b6f675751f27,https://www.semanticscholar.org/paper/3a20ed3521bd0041a22cf4dacd90b6f675751f27,"6G Wireless Communication: Its Vision, Viability, Application, Requirement, Technologies, Encounters and Research","The fast development of multiband ultrafast seamless network and super reliable data transmission system to support heavy traffic applications such as artificial intelligence, machine learning, deep learning, augmented reality, virtual reality, 3D media, Internet of Things, Enterprise Internet of Thing and the Internet of Nano-things that involves with the real time transfer of data, voice and video in terabytes per second (Tb/s), the current cellular network (5G Network is insufficient to meet the growth of usage of triple play services in fraction of time). To meet the expectation of heavy data users is a big challenge in today's generation. To handle the situation of drastic demand of data, the sixth generation of mobile technology (6G) should be deeply studied along with its potential in terms of bandwidth, low latency, channel capacity, channel modeling techniques, loss propagation models, energy spectrum efficiency, faster network connectivity and data security. In this paper the vision in terms intelligent computing and wireless massive connectivity, feasibility, requirement in terms of modifying the existing 5G network, technologies in terms of artificial intelligence, 3D networking, SM-MIMO and optical computing, challenges after deployment, research to promote good health for 6G and application of 6G in the field of industry, automation sector, health, and transport has been studied and presented.","2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)",2020,10.1109/ICCCNT49239.2020.9225680,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4ded2b6f2d90c4a9bb098199fca8fa0fef27c258,https://www.semanticscholar.org/paper/4ded2b6f2d90c4a9bb098199fca8fa0fef27c258,SensoryGANs: An Effective Generative Adversarial Framework for Sensor-based Human Activity Recognition,"This study focuses on improving the performance of human activity recognition when a small number of sensor data are available under some special practical scenarios and resource-limited environments, such as some high-risk projects, anomaly monitoring and actual tactical scenarios. The Human Activity Recognition (HAR) based on wearable sensors is an attractive research topic in machine learning and ubiquitous computing over the last few decades, and has extremely practicality in health surveillance, medical assistance, personalized services, etc. However, with the limitation of sensor sampling rate, sustainability, deployment, and other restricted conditions, it is difficult to collect enough and resultful sensor data anywhere, anytime. Therefore, the HAR based on wearable sensors always faces the challenges of the low-data regime under some practical scenarios, which leads to a low accuracy of activity recognition and needs to be solved urgently. Currently, the Generative Adversarial Networks (GANs) provide a powerful method for training resultful generative models that could generate very convincing verisimilar images. The framework of GANs and its variants shed many lights on improving the performance of HAR. In this paper, we propose a new generative adversarial networks framework called SensoryGANs that can effectively generate available sensor data used for HAR. To the best of our knowledge, SensoryGANs is the first unbroken generative adversarial networks applied in generating sensor data in the HAR research field. Firstly, we tried exploring and devising three activity-special GANs models for three human daily activities. Secondly, these specific models are trained with the guidance of unbroken vanilla GANs. Thirdly, the trained generators from adversarial optimization process are used to generate synthetic sensor data. Finally, the synthetic sensor data from SensoryGANs are used to enrich the original authentic sensor datasets, which can improve the performance of target activity recognition model. Meanwhile, we propose three visual evaluation methods for assessing synthetic sensor data produced by the trained generators in SensoryGANs models. Experimental results show that SensoryGANs models have the capability of capturing the implicit distribution of real sensor data of human activity, and then the synthetic sensor data generated by SensoryGANs models Have a potential for improving human activity recognition.",2018 International Joint Conference on Neural Networks (IJCNN),2018,10.1109/IJCNN.2018.8489106,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dc81be6bdf58ab9f17dfe5dbb513910a5bbf326e,https://www.semanticscholar.org/paper/dc81be6bdf58ab9f17dfe5dbb513910a5bbf326e,Deploying nEmesis: Preventing Foodborne Illness by Data Mining Social Media,"Foodborne illness afflicts 48 million people annually in the U.S. alone. Over 128,000 are hospitalized and 3,000 die from the infection. While preventable with proper food safety practices, the traditional restaurant inspection process has limited impact given the predictability and low frequency of inspections, and the dynamic nature of the kitchen environment. Despite this reality, the inspection process has remained largely unchanged for decades. We apply machine learning to Twitter data and develop a system that automatically detects venues likely to pose a public health hazard. Health professionals subsequently inspect individual flagged venues in a double blind experiment spanning the entire Las Vegas metropolitan area over three months. By contrast, previous research in this domain has been limited to indirect correlative validation using only aggregate statistics. We show that adaptive inspection process is 63% more effective at identifying problematic venues than the current state of the art. The live deployment shows that if every inspection in Las Vegas became adaptive, we can prevent over 9,000 cases of foodborne illness and 557 hospitalizations annually. Additionally, adaptive inspections result in unexpected benefits, including the identification of venues lacking permits, contagious kitchen staff, and fewer customer complaints filed with the Las Vegas health department.",AI Mag.,2016,10.1609/aimag.v38i1.2711,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a80063fbcccbf74a97faa2ac2a04950e32cb36ce,https://www.semanticscholar.org/paper/a80063fbcccbf74a97faa2ac2a04950e32cb36ce,Pattern analysis: predicting COVID-19 pandemic in India using AutoML,"Purpose: Since December 2019, global attention has been drawn to the rapid spread of COVID-19 Corona was discovered in India on 30 January 2020 To date, in India, 178,014 disease cases were reported with 14,011 deaths by the Indian Government In the meantime, with an increasing spread speed, the COVID-19 epidemic occurred in other countries The survival rate for COVID-19 patients who suffer from a critical illness is efficiently and precisely predicted as more fatal cases can be affected in advanced cases However, over 400 laboratories and clinically relevant survival rates of all present critically ill COVID-19 patients are estimated manually The manual diagnosis inevitably results in high misdiagnosis and missed diagnosis owing to a lack of experience and prior knowledge The chapter presents an option for developing a machine-based prognostic model that exactly predicts the survival of individual severe patients with clinical data from different sources such as Kaggle data gov and World Health Organization with greater than 95% accuracy The data set and attributes are shown in detail The reasonableness of such a mere three elements may depend, respectively, on their representativeness in the indices of tissue injury, immunity and inflammation The purpose of this paper is to provide detailed study from the diagnostic aspect of COVID-19, the work updates the cost-effective and prompt criticality classification and prediction of survival before the targeted intervention and diagnosis, in particular the triage of the vast COVID-19 explosive epidemic Design/methodology/approach: Automated machine learning (ML) provides resources and platforms to render ML available to non-ML experts, to boost efficiency in ML and to accelerate research in machine learning H2O AutoML is used to generate the results (Dulhare et al , 2020) ML has achieved major milestones in recent years, and it is on which an increasing range of disciplines depend But this performance is crucially dependent on specialists in human ML to perform the following tasks: preprocess the info and clean it;choose and create the appropriate apps;choose a family that fits the pattern;optimize hyperparameters for layout;and models of computer learning post processes Review of the findings collected is important Findings: These days, the concept of automated ML techniques is being used in every field and domain, for example, in the stock market, education institutions, medical field, etc ML tools play an important role in harnessing the massive amount of data In this paper, the data set relatively holds a huge amount of data, and appropriate analysis and prediction are necessary to track as the numbers of COVID cases are increasing day by day This prediction of COVID-19 will be able to track the cases particularly in India and might help researchers in the future to develop vaccines Researchers across the world are testing different medications to cure COVID;however, it is still being tested in various labs This paper highlights and deploys the concept of AutoML to analyze the data and to find the best algorithm to predict the disease Appropriate tables, figures and explanations are provided Originality/value: As the difficulty of such activities frequently goes beyond non-ML-experts, the exponential growth of ML implementations has generated a market for off-the-shelf ML solutions that can be used quickly and without experience We name the resulting work field which is oriented toward the radical automation of AutoML machine learning The third class is that of the individuals who have illnesses such as diabetes, high BP, asthma, malignant growth, cardiovascular sickness and so forth As their safe frameworks have been undermined effectively because of a common ailment, these individuals become obvious objectives Diseases experienced by the third classification of individuals can be lethal (Shinde et al , 2020) Examining information is fundamental in having the option to comprehend the spread and treatment adequacy The world needs a ot more individuals investigating the information The understanding from worldwide data on the spread of the infection and its conduct will be key in limiting the harm The main contributions of this study are as follows: predicting COVID-19 pandemic in India using AutoML;analyzing the data set predicting the patterns of the virus;and comparative analysis of predictive algorithms The organization of the paper is as follows, Sections I and II describe the introduction and the related work in the field of analyzing the COVID pandemic Section III describes the workflow/framework for AutoML using the components with respect to the data set used to analyze the patterns of COVID-19 patients © 2020, Emerald Publishing Limited",,2020,10.1108/wje-09-2020-0450,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d11edc8f267ff0c59999d9ed40c9604360272d16,https://www.semanticscholar.org/paper/d11edc8f267ff0c59999d9ed40c9604360272d16,Toward Automatic Risk Assessment to Support Suicide Prevention.,"BACKGROUND
Suicide has been considered an important public health issue for years and is one of the main causes of death worldwide. Despite prevention strategies being applied, the rate of suicide has not changed substantially over the past decades. Suicide risk has proven extremely difficult to assess for medical specialists, and traditional methodologies deployed have been ineffective. Advances in machine learning make it possible to attempt to predict suicide with the analysis of relevant data aiming to inform clinical practice.


AIMS
We aimed to (a) test our artificial intelligence based, referral-centric methodology in the context of the National Health Service (NHS), (b) determine whether statistically relevant results can be derived from data related to previous suicides, and (c) develop ideas for various exploitation strategies.


METHOD
The analysis used data of patients who died by suicide in the period 2013-2016 including both structured data and free-text medical notes, necessitating the deployment of state-of-the-art machine learning and text mining methods.


LIMITATIONS
Sample size is a limiting factor for this study, along with the absence of non-suicide cases. Specific analytical solutions were adopted for addressing both issues.


RESULTS AND CONCLUSION
The results of this pilot study indicate that machine learning shows promise for predicting within a specified period which people are most at risk of taking their own life at the time of referral to a mental health service.",Crisis,2019,10.1027/0227-5910/a000561,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
44495cfe83fbe0a9cc8c047f323fb0c25921eba1,https://www.semanticscholar.org/paper/44495cfe83fbe0a9cc8c047f323fb0c25921eba1,Efficient k-NN Implementation for Real-Time Detection of Cough Events in Smartphones,"The potential  of telemedicine in respiratory health care has not been completely unveiled in part due to the inexistence of reliable objective measurements of symptoms such as cough. Currently available cough detectors are uncomfortable and expensive at a time when generic smartphones can perform this task. However, two major challenges preclude smartphone-based cough detectors from effective deployment namely, the need to deal with noisy environments and computational cost. This paper focuses on the latter, since complex machine learning algorithms are too slow for real-time use and kill the battery in a few hours unless specific actions are taken. In this paper, we present a robust and efficient implementation of a smartphone-based cough detector. The audio signal acquired from the device's microphone is processed by computing local Hu moments as a robust feature set in the presence of background noise. We previously demonstrated that pairing Hu moments and a standard k-NN classifier achieved accurate cough detection at the expense of computation time. To speed-up k-NN search, many tree structures have been proposed. Our cough detector uses an improved vantage point (vp)-tree with optimized construction methods and a distance function that results in faster searches. We achieve 18× speed-up over classic vp-trees, and 560× over standard implementations of k-NN in state-of-the-art machine learning libraries, with classification accuracies over 93%, enabling real-time performance on low-end smartphones.",IEEE Journal of Biomedical and Health Informatics,2018,10.1109/JBHI.2017.2768162,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
71a978ce9878a26ba6e87b551f2bb7c987e47ebc,https://www.semanticscholar.org/paper/71a978ce9878a26ba6e87b551f2bb7c987e47ebc,Data Visualization for Air Quality Analysis on Bigdata Platform,"With the advances of industry, air pollution is increasingly becoming serious, and most of governments in the world has deployed many devices to monitor daily air quality. Monitoring and forecasting of air quality has also become an important issue to improve the quality of people's lives. As far as we know, bad air quality does not only affect the health of the respiratory tract, it may but also even cause mental illness. Many researchers have investigated different approaches to work on air quality forecast, and the visualization of forecasting becomes important. In this paper, we present an architecture for visualizing forecasted air quality on a big data platform. We implemented an ETL (Extract-Transform-Load) based framework in the platform, which includes computing nodes and storage nodes. Computational nodes are used for data collection and for air quality forecasting over the next 1 to 8 hours through machine learning and deep learning. Storage nodes are used to retrieve, analyze, and preprocess of collected data. We use the RESTful Web Service as an API, and finally we use the browser to get the data by predefined API and to present the forecasted and monitored results with Google Map API and D3 JavaScript library. It reveals that the visualization on big data framework can work well for air quality analysis.",2019 International Conference on System Science and Engineering (ICSSE),2019,10.1109/ICSSE.2019.8823437,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c028e162c9da97417c7ecd769f9ed8bdc1c89b00,https://www.semanticscholar.org/paper/c028e162c9da97417c7ecd769f9ed8bdc1c89b00,Evaluating and improving the reliability of gas-phase sensor system calibrations across new locations for ambient measurements and personal exposure monitoring,"Abstract. Advances in ambient environmental monitoring technologies are enabling concerned communities and citizens to collect data to better understand their local environment and potential exposures. These mobile, low-cost tools make it possible to collect data with increased temporal and spatial resolution, providing data on a large scale with unprecedented levels of detail. This type of data has the potential to empower people to make personal decisions about their exposure and support the development of local strategies for reducing pollution and improving health outcomes. However, calibration of these low-cost instruments has been a challenge. Often, a sensor package is calibrated via field calibration. This involves colocating the sensor package with a high-quality reference instrument for an extended period and then applying machine learning or other model fitting technique such as multiple linear regression to develop a calibration model for converting raw sensor signals to pollutant concentrations. Although this method helps to correct for the effects of ambient conditions (e.g., temperature) and cross sensitivities with nontarget pollutants, there is a growing body of evidence that calibration models can overfit to a given location or set of environmental conditions on account of the incidental correlation between pollutant levels and environmental conditions, including diurnal cycles. As a result, a sensor package trained at a field site may provide less reliable data when moved, or transferred, to a different location. This is a potential concern for applications seeking to perform monitoring away from regulatory monitoring sites, such as personal mobile monitoring or high-resolution monitoring of a neighborhood. We performed experiments confirming that transferability is indeed a problem and show that it can be improved by collecting data from multiple regulatory sites and building a calibration model that leverages data from a more diverse data set. We deployed three sensor packages to each of three sites with reference monitors (nine packages total) and then rotated the sensor packages through the sites over time. Two sites were in San Diego, CA, with a third outside of Bakersfield, CA, offering varying environmental conditions, general air quality composition, and pollutant concentrations. When compared to prior single-site calibration, the multisite approach exhibits better model transferability for a range of modeling approaches. Our experiments also reveal that random forest is especially prone to overfitting and confirm prior results that transfer is a significant source of both bias and standard error. Linear regression, on the other hand, although it exhibits relatively high error, does not degrade much in transfer. Bias dominated in our experiments, suggesting that transferability might be easily increased by detecting and correcting for bias. Also, given that many monitoring applications involve the deployment of many sensor packages based on the same sensing technology, there is an opportunity to leverage the availability of multiple sensors at multiple sites during calibration to lower the cost of training and better tolerate transfer. We contribute a new neural network architecture model termed split-NN that splits the model into two stages, in which the first stage corrects for sensor-to-sensor variation and the second stage uses the combined data of all the sensors to build a model for a single sensor package. The split-NN modeling approach outperforms multiple linear regression, traditional two- and four-layer neural networks, and random forest models. Depending on the training configuration, compared to random forest the split-NN method reduced error 0 %–11 % for NO2 and 6 %–13 % for O3.
",Atmospheric Measurement Techniques,2019,10.5194/AMT-12-4211-2019,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
052f46718b15976d1f228b27f3fdc80edbbb51aa,https://www.semanticscholar.org/paper/052f46718b15976d1f228b27f3fdc80edbbb51aa,PHM Technology for Memory Anomalies in Cloud Computing for IaaS,"The IaaS (Infrastructure as a Service) is one of the most popular services from todays cloud service providers, where the virtual machines (VM) are rented by users who can deploy any program they want in the VMs to make their own websites or use as their remote desktops. However, this poses a major challenge for cloud IaaS providers who cannot control the software programs that users develop, install or download on their rented VMs. Those programs may not be well developed with various bugs or even downloaded/installed together with virus, which often make damages to the VMs or infect the cloud platform. To keep the health of a cloud IaaS platform, it is very important to implement the PHM (Prognostics and Health Management) technology for detecting those software problems and self-healing them in an intelligent and timely way. This paper realized a novel PHM technology inspired by biological autonomic nervous system to deal with the memory anomalies of those programs running on the cloud IaaS platform. We first present an innovative autonomic computing technology called Bionic Autonomic Nervous System (BANS) to endow the cloud system with distinctive capabilities of perception, detection, reflection, and learning. Then, we propose a BANS-based Prognostics and Health Management (BPHM) technology to enable the cloud system self-dealing with various memory anomalies. AI-based failure prognostics, immediate self-healing, self-learning ability and self-improvement functions are implemented. Experimental results illustrate that the designed BPHM can automatically and intelligently deal with complex memory anomalies in a real cloud system for IaaS, to keep the system much more reliable and healthier.","2020 IEEE 20th International Conference on Software Quality, Reliability and Security (QRS)",2020,10.1109/QRS51102.2020.00018,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e8169b1388d57c147ab778a25f17bc51500fcba9,https://www.semanticscholar.org/paper/e8169b1388d57c147ab778a25f17bc51500fcba9,Monitoring algal blooms using active learning camera sensor networks,"The frequent occurrence of toxin-producing algal blooms is a serious concern for the ecological status of inland water and for human and animal health. In this paper, camera sensor networks are used to monitor algal blooms in lake for the first time. A distributed machine learning based algal blooms recognition DMLAR algorithm is proposed and implemented on embedded sensor nodes. DMLAR accurately recognises algal blooms and estimates their amounts in real-time based on the pictures of water surface. The machine learning model used by DMLAR is constructed by designing an active learning task, which is accomplished by collaborative embedded sensor nodes in a distributed manner. Extensive field experiments with large dataset are performed on the system deployed in lake since May 2010. Experiment results show that DMLAR outperforms two widely used methods both in terms of estimation accuracy and execution time, using nearly the same memory and energy.",Int. J. Sens. Networks,2015,10.1504/IJSNET.2015.071633,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a6c7b3c141f6c604e08fee902fa268665b8a4221,https://www.semanticscholar.org/paper/a6c7b3c141f6c604e08fee902fa268665b8a4221,Simple linear classifiers via discrete optimization: learning certifiably optimal scoring systems for decision-making and risk assessment,"Scoring systems are linear classification models that let users make quick predictions by adding, subtracting, and multiplying a few small numbers. These models are widely used in applications where humans have traditionally made decisions because they are easy to understand and validate. In spite of extensive deployment, many scoring systems are still built using ad hoc approaches that combine statistical techniques, heuristics, and expert judgement. Such approaches impose steep trade-offs with performance, making it difficult for practitioners to build scoring systems that will be used and accepted. In this dissertation, we present two new machine learning methods to learn scoring systems from data: Supersparse Linear Integer Models (SLIM) for decision-making applications; and Risk-calibrated Supersparse Linear Integer Models (RiskSLIM) for risk assessment applications. Both SLIM and RiskSLIM solve discrete optimization problems to learn scoring systems that are fully optimized for feature selection, small integer coefficients, and operational constraints. We formulate these problems as integer programming problems and develop specialized algorithms to recover certifiably optimal solutions with an integer programming solver. We illustrate the benefits of this approach by building scoring systems for realworld problems such as recidivism prediction, sleep apnea screening, ICU seizure prediction, and adult ADHD diagnosis. Our results show that a discrete optimization approach can learn simple models that perform well in comparison to the state-ofthe-art, but that are far easier to customize, understand, and validate. Thesis Supervisor: Cynthia Rudin Title: Associate Professor of Computer Science Duke University",,2017,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17005a1bd4189707f17d8bef9a0909c9399f7171,https://www.semanticscholar.org/paper/17005a1bd4189707f17d8bef9a0909c9399f7171,The Plant Pathology 2020 challenge dataset to classify foliar disease of apples,"Apple orchards in the U.S. are under constant threat from a large number of pathogens and insects. Appropriate and timely deployment of disease management depends on early disease detection. Incorrect and delayed diagnosis can result in either excessive or inadequate use of chemicals, with increased production costs, environmental, and health impacts. We have manually captured 3,651 high-quality, real-life symptom images of multiple apple foliar diseases, with variable illumination, angles, surfaces, and noise. A subset, expert-annotated to create a pilot dataset for apple scab, cedar apple rust, and healthy leaves, was made available to the Kaggle community for 'Plant Pathology Challenge'; part of the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2020 (Computer Vision and Pattern Recognition). We also trained an off-the-shelf convolutional neural network (CNN) on this data for disease classification and achieved 97% accuracy on a held-out test set. This dataset will contribute towards development and deployment of machine learning-based automated plant disease classification algorithms to ultimately realize fast and accurate disease detection. We will continue to add images to the pilot dataset for a larger, more comprehensive expert-annotated dataset for future Kaggle competitions and to explore more advanced methods for disease classification and quantification.",ArXiv,2020,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ad3ff2bc45526b4e6158072d4840147bd59051b,https://www.semanticscholar.org/paper/2ad3ff2bc45526b4e6158072d4840147bd59051b,Beginnings of Artificial Intelligence in Medicine (AIM): Computational Artifice Assisting Scientific Inquiry and Clinical Art – with Reflections on Present AIM Challenges,"Summary Background : The rise of biomedical expert heuristic knowledge-based approaches for computational modeling and problem solving, for scientific inquiry and medical decision-making, and for consultation in the 1970’s led to a major change in the paradigm that affected all of artificial intelligence (AI) research. Since then, AI has evolved, surviving several “winters”, as it has oscillated between relying on expensive and hard-to-validate knowledge-based approaches, and the alternative of using machine learning methods for inferring classification rules from labelled datasets. In the past couple of decades, we are seeing a gradual but progressive intertwining of the two. Objectives : To give an overview of early directions in AI in medicine and threads of some subsequent developments motivated by the very different goals of scientific inquiry for biomedical research, and for computational modeling of clinical reasoning and more general healthcare problem solving from the perspective of today’s “AI-Deep Learning Boom”. To show how, from the beginning, AI was central to Biomedical and Health Informatics (BMHI), as a field investigating how to understand intelligent thinking in dealing professionally with the practice for healthcare, developing mathematical models, technology, and software tools to aid human experts in biomedicine, despite many previous bouts of “exuberant optimism” about the methodologies deployed. Methods : An overview and commentary on some of the early research and publications in AI in biomedicine, emphasizing the different approaches to the modeling of problems involved in clinical practice in contrast to those of biomedical science. A concluding reflection of a few current challenges and pitfalls of AI in some biomedical applications. Conclusion : While biomedical knowledge-based systems played a critical role in influencing AI in its early days, 50 years later they have taken a back seat behind “Deep Learning” which promises to discover knowledge structures for inference and prediction, both in science and for clinical decision-support. Early work on AI for medical consultation turned out to be more useful for explanation and teaching than for clinical practice, as had been originally intended. Today, despite the many reported successes of deep learning, fundamental scientific challenges arise in drawing on models of brain science, cognition, and language, if AI is to augment and complement rather than replace human judgment and expertise in biomedicine while also incorporating these advances for translational medicine. Understanding clinical phenotypes and how they relate to precision and personalization of care requires not only scientific inquiry, but also humanistic models of treatment that respond to patient and practitioner narrative exchanges, since it is the stories and insights of human experts which encourage what Norbert Weiner termed the ethical “human use of human beings”, so central to adherence to the Hippocratic Oath",Yearbook of medical informatics,2019,10.1055/s-0039-1677895,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ac16cdc3f9791ec40c4e54c7cbbe35a90bf37bba,https://www.semanticscholar.org/paper/ac16cdc3f9791ec40c4e54c7cbbe35a90bf37bba,A prediction model of military combat and training exposures on VA service-connected disability: a CENC study,"ABSTRACT Background: Research has shown that number of and blast-related Traumatic Brain Injuries (TBI) are associated with higher levels of service-connected disability (SCD) among US veterans. This study builds and tests a prediction model of SCD based on combat and training exposures experienced during active military service. Methods: Based on 492 US service member and veteran data collected at four Department of Veterans Affairs (VA) sites, traditional and Machine Learning algorithms were used to identify a best set of predictors and model type for predicting %SCD ≥50, the cut-point that allows for veteran access to 0% co-pay for VA health-care services. Results: The final model of predicting %SCD ≥50 in veterans revealed that the best blast/injury exposure-related predictors while deployed or non-deployed were: 1) number of controlled detonations experienced, 2) total number of blast exposures (including controlled and uncontrolled), and 3) the total number of uncontrolled blast and impact exposures. Conclusions and Relevance: We found that the highest blast/injury exposure predictor of %SCD ≥50 was number of controlled detonations, followed by total blasts, controlled or uncontrolled, and occurring in deployment or non-deployment settings. Further research confirming repetitive controlled blast exposure as a mechanism of chronic brain insult should be considered.",Brain injury,2019,10.1080/02699052.2019.1655793,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f13f661d21e06cea9e60e4f670db173a1c80ee3d,https://www.semanticscholar.org/paper/f13f661d21e06cea9e60e4f670db173a1c80ee3d,Bridging the gap: Using reservoir ecology and human serosurveys to estimate Lassa virus incidence in West Africa,"Forecasting how the risk of pathogen spillover changes over space is essential for the effective deployment of interventions such as human or wildlife vaccination. However, due to the sporadic nature of spillover events and limited availability of data, developing and validating robust predictions is challenging. Recent efforts to overcome this obstacle have capitalized on machine learning to predict spillover risk. Past approaches combine infection data from both humans and reservoir to train models that assess risk across broad geographical regions. In doing so, these models blend data sources that separately describe pathogen risk posed by the reservoir and the realized rate of spillover into the human population. We develop a novel approach that models as separate stages: 1) the contributions of spillover risk from the reservoir and pathogen distribution, and 2) the resulting incidence of pathogen in the human population. Our methodology allows for a rigorous assessment of whether forecasts of spillover risk can reliably predict the realized spillover rate into humans, as measured by seroprevalence. In addition to providing a rigorous cross-validation of risk predictions, this methodology could shed light on human habits that modulate or amplify the resultant spillover. We apply our method to Lassa virus, a zoonotic pathogen that poses a high threat of emergence in West Africa. The resulting framework is the first forecast to quantify the extent to which predictions of spillover risk from the reservoir explain regional variation in human seroprevalence. We use predictions generated by the model to revise existing estimates for the annual number of new human Lassa infections. Our model predicts that between 935,200 – 3,928,000 humans are infected by Lassa virus each year, an estimate that exceeds current conventional wisdom. Author Summary The 2019 emergence of SARS-2 coronavirus is a grim reminder of the threat animal-borne pathogens pose to human health. Even prior to SARS-2, the spillover of so-called zoonotic pathogens was a persistent problem, with pathogens such as Ebola and Lassa regularly but unpredictably causing outbreaks. Machine-learning models that can anticipate when and where animal-to-human virus transmission is most likely to occur could help guide surveillance effort, as well as preemptive countermeasures to pandemics, like information campaigns or vaccination programs. We develop a novel machine learning framework that uses data-sets describing the distribution of a virus within its host and the range of its animal host, along with human immunity data, to infer rates of animal-to-human transmission across a focal region. By training the model on data from the animal host, our framework allows rigorous validation of spillover predictions on human data. We apply our framework to Lassa fever, a viral disease of West Africa that is spread to humans by rodents, and update estimates of symptomatic and asymptomatic Lassa virus infections in humans. Our results suggest that Nigeria is most at risk for the emergence of new strains of Lassa virus, and therefore should be prioritized for outbreak-surveillance.",bioRxiv,2020,10.1101/2020.03.05.979658,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
08cf11d2dc72b5eb8cb2f4e27d1c2f76a7c47219,https://www.semanticscholar.org/paper/08cf11d2dc72b5eb8cb2f4e27d1c2f76a7c47219,Applying an Intelligent Personal Agent on a Smart Home Using a Novel Dialogue Generator,,AIAI,2020,10.1007/978-3-030-49186-4_32,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6a2a534a9d01b76ecb5caba20032022a904cb50d,https://www.semanticscholar.org/paper/6a2a534a9d01b76ecb5caba20032022a904cb50d,COSMIC Semantic Segmentation Framework,"Deep space missions such as the Mars Reconnaissance Orbiter collect more data than can be sent back to Earth due to limited communications bandwidth. Machine learning algorithms can be deployed on board orbiters to prioritize the downlink of scientifically interesting images, such as those including fresh impact craters, recurring slope lineae, or dust devils. However, basic machine learning research is necessary to boost realworld performance, and numerous possible convolutional neural network architectures must be evaluated in terms of accuracy and compute requirements. A framework is designed to reduce redundant development, to standardize the algorithm testing process, and to allow developers to focus on the implementation details of novel machine learning algorithms. Three convolutional neural network implementations are included with the framework, pending use in future research. 1Content-based Onboard Summarization to Monitor Infrequent Change 2CL #18-465",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
459960be65dd04317dd325af5b7cbb883d822ee4,https://www.semanticscholar.org/paper/459960be65dd04317dd325af5b7cbb883d822ee4,The Meme Quiz: A Facial Expression Game Combining Human Agency and Machine Involvement,"We describe a game with a purpose called The Meme Quiz in which a human player mimics popular Internet memes, and the system guesses which expression the player imitated. The purpose of the game is to collect a useful dataset of in-the-wild facial expressions. The game was deployed with 198 players contributing 2,860 labeled images. In contrast to many data-gathering games that use interaction between humans to define the mechanics and verify the data, our game has an online machine learning system at its core. As more people play and make faces, The Meme Quiz gathers more data and makes better guesses over time. One main advantage of this setup is the ability to monitor the usefulness of the data as it is collected and to watch for improvement, instead of waiting until the end of the game to process the data. Our contributions are 1) the design and deployment of a game for collecting diverse, real-world facial expression data and 2) an exploration of the design space of datagathering games along two axes: human agency and machine involvement, including advantages of building a game around an interactive domain-specific technical system. Keywords games with a purpose, facial expression recognition, crowdsourcing, computer vision, machine learning 1. INTRODUCTION Facial expression recognition is an important part of affective computing. Typically, only the six basic expressions of joy, sadness, fear, anger, surprise, and disgust are used in affective computing – a small set of facial expressions by all accounts. We are interested in extending the capabilities of automated expression recognition and in collecting a new dataset of facial expressions that includes many new expressions. To do so, we take advantage of the broad set of facial expressions that appear in Internet memes. (a) Not Bad Obama (b) Not Impressed McKayla Figure 1: Example Internet Memes portraying several different emotions. Do these emotions have obvious names, or is the picture itself a more concise way of conveying the emotion? Reaction images [1], known by the shorthand MRW (“My Reaction When”), are a type of meme that portray an emotion in response to something said or experienced. “Not Bad Obama” and “Not Impressed McKayla”, shown in Figure 1, are two recognizable media images that have been elevated to meme status. MRW memes can also include non-human faces, such as “Grumpy Cat” in Figure 6(c). These reaction images may have value beyond entertainment; Figure 2 shows a MRW meme known as“Success Kid”annotated with a story about a user’s breakthrough using reaction memes to convey emotional state to a therapist. Communicative expression-related memes would be useful to affective computing, where a primary goal is to assist people who struggle with reading or communicating emotions in their everyday lives. Although reaction memes themselves are popular on the Internet, there is no data source of everyday people portraying these same facial expressions. Anticipating that imitating memes would not only generate useful data but also be amusing and compelling, we set out to build a game to crowdsource photos of people imitating meme facial expressions. Since our end goal is to use the collected dataset to train an automated system to recognize these new expressions, we decided to build the training and teaching of this system into the game. In this paper we present The Meme Quiz, a game we developed where the player is asked to act out a meme expression and the system guesses which meme the player is imitating. Over time as the game collects more data, the system improves and is able to guess expressions correctly. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Proceedings of the 10th International Conference on the Foundations of Digital Games (FDG 2015), June 22-25, 2015, Pacific Grove, CA, USA. ISBN 978-0-9913982-4-9. Copyright held by author(s). Figure 2: A “My reaction when” meme depicting a story about using MRW memes to convey emotional state to a therapist. We designed our game such that it does not require the expression recognition technology to work perfectly; the fun of the game comes from the fact that the system occasionally makes mistakes. In fact, our system can start learning immediately and does not need to be bootstrapped with initial data. In the middle of deployment, we were able to adapt the game by adding new memes to impersonate, and we were able to monitor the health of the data over time to make sure the system was in fact learning these novel facial expressions. Because our game uses online machine learning as its core mechanic, it is different from other crowdsourced data generation games. In the rest of this paper, we explore the space of crowdsourced data-generation games along two dimensions of human agency and machine involvement, and describe how The Meme Quiz fits as a game with high agency for both the human and the computer. Our contributions are 1) the design and deployment of a game for collecting diverse facial expression data and 2) an exploration of the design space of data-gathering games along two axes: human agency and machine involvement, including advantages of building a game around an interactive domain-specific technical system. 2. RELATED WORK This section focuses on background work related to facial expressions and crowdsourcing of these expressions. Games with a purpose are highly relevant, and we discuss many games in Section 3 on our proposed design space for datagathering games. Name Subjects Photos per Subject Expressions CK+ 127 4 videos 6 Multi PIE 337 2,225 photos 6 MMI 90 20 videos+photos 6+AUs AM-FED 242 1 videos 2 Table 1: Comparison of facial expression datasets There are a number of existing facial expression datasets, such as CK+ [15], CMU Multi-PIE [7], and MMI [18], which have been laboriously captured and annotated with emotion and Action Unit (AU) labels from the Facial Action Coding System (FACS). These datasets have fueled facial expression recognition research for over a decade and Table 1 shows a comparison of these datasets. These standard datasets are often collected in controlled lab environments with, at most, a few hundred subjects. In practical applications, face trackers must work on a wide variety of facial appearances and in many different lighting conditions, and on more than six expressions. Bigger datasets are necessary, as well as datasets captured in the real world in realistic situations, such using a webcam or a front-facing camera on a mobile phone. Our game captures faces in realistic capture conditions, and includes many more expressions. The AM-FED [16] dataset was also captured “in the wild” by recording subjects’ faces as they watched Super Bowl advertisements on their own computers. As an incentive for allowing their reactions be recorded, subjects were shown a chart of their smile activity compared to others, which is an interesting integration of computer vision back into the user experience. The expressions captured in AM-FED are spontaneous (or as spontaneous as they can be when the subjects are aware they are being recorded), but the videos were chosen to elicit joy only, so the dataset does not span a wide range of emotions, or even very extreme emotions. While our own dataset is posed, it includes the basic expressions as well as many more, captured in real world environments. Capturing spontaneous expressions is difficult, as it requires subjecting users to unpleasant stimuli designed to elicit emotions such as disgust, fear, or pain, and different people might not be sensitive to the same stimuli. Recently, Li et. al. [14] and Yan et. al. [26] have compiled datasets of spontaneous micro-expressions using videos chosen to elicit emotions including joy, surprise, and disgust and encouraging subjects to try to hide their emotions. Zhang et. al. [27] have also captured a 3D dataset of spontaneous expressions by engaging lab subjects in different activities, such as playing an embarrassing game or experiencing an unpleasant smell. We believe acting out expressions is more fun for the participant than being subjected to unpleasant stimuli. New datasets of labeled examples of facial expressions that span a wide variety of people, capture conditions, and emotions are critical to the future of automated expression recognition and affective computing. Especially compared to bringing subjects to act out expressions in-person, online crowdsourcing has the potential to recruit many more subjects and collect far more data. The Meme Quiz is one of many possible ways to realize mechanics and incentives of crowdsourcing facial data. 3. DESIGN SPACE OF DATA-GATHERING GAMES AND SYSTEMS Before we describe our game, we want to define the design space of games with a purpose (GWAPs), specifically those used for gathering data, and position The Meme Quiz within that space. Games with a purpose, such as the ESP Game [25], were first introduced to produce large, labeled datasets to be used as training data for computer vision and machine learning tasks. Since then, games including BeFaced [22] and Motion Chain [20] have been developed to generate new data. We will call these games data-gathering games, with datageneration games as a subset. Paid crowdsourcing through micro-task platforms like Mechanical Turk are also a common way to gather and generate data. Not all games with a purpose are data-gathering games; some like Foldit [2], Phylo [9], and EteRNA [13] are about solving puzzles and understanding the human process of finding optimal solutions, rather than simply collecting a dataset. The Meme Quiz is ultimately about collecting a dataset, but also understanding the system’s learning process. In order to understand what makes ou",FDG,2015,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1de1fb5a0530c5c144c8a78fb653c8c7bc58c108,https://www.semanticscholar.org/paper/1de1fb5a0530c5c144c8a78fb653c8c7bc58c108,Sensor-based human activity recognition: Overcoming issues in a real world setting,"The rapid growing of the population age in industrialized societies calls for advanced tools to continuous monitor the activities of people. The goals of those tools are usually to support active and healthy ageing, and to early detect possible health issues to enable a long and independent life. Recent advancements in sensor miniaturization and wireless communications have paved the way to unobtrusive activity recognition systems. Hence, many pervasive health care systems have been proposed which monitor activities through unobtrusive sensors and by machine learning or artificial intelligence methods. Unfortunately, while those systems are effective in controlled environments, their actual effectiveness out of the lab is still limited due to different shortcomings of existing approaches. 
 
In this work, we explore such systems and aim to overcome existing limitations and shortcomings. Focusing on physical movements and crucial activities, our goal is to develop robust activity recognition methods based on external and wearable sensors that generate high quality results in a real world setting. Under laboratory conditions, existing research already showed that wearable sensors are suitable to recognize physical activities while external sensors are promising for activities that are more complex. Consequently, we investigate problems that emerge when coming out of the lab. This includes the position handling of wearable devices, the need of large expensive labeled datasets, the requirement to recognize activities in almost real-time, the necessity to adapt deployed systems online to changes in behavior of the user, the variability of executing an activity, and to use data and models across people. As a result, we present feasible solutions for these problems and provide useful insights for implementing corresponding techniques. Further, we introduce approaches and novel methods for both external and wearable sensors where we also clarify limitations and capabilities of the respective sensor types. Thus, we investigate both types separately to clarify their contribution and application use in respect of recognizing different types of activities in a real world scenario. 
 
Overall, our comprehensive experiments and discussions show on the one hand the feasibility of physical activity recognition but also recognizing complex activities in a real world scenario. Comparing our techniques and results with existing works and state-of-the-art techniques also provides evidence concerning the reliability and quality of the proposed techniques. On the other hand, we also identify promising research directions and highlight that combining external and wearable sensors seem to be the next step to go beyond activity recognition. In other words, our results and discussions also show that combining external and wearable sensors would compensate weaknesses of the individual sensors in respect of certain activity types and scenarios. Therefore, by addressing the outlined problems, we pave the way for a hybrid approach. Along with our presented solutions, we conclude our work with a high-level multi-tier activity recognition architecture showing that aspects like physical activity, (emotional) condition, used objects, and environmental features are critical for reliable recognizing complex activities.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a55c8a2f8cab01a78a640fa46af3ca6e66f7360c,https://www.semanticscholar.org/paper/a55c8a2f8cab01a78a640fa46af3ca6e66f7360c,Towards Predicting Risky Behavior Among Veterans with PTSD by Analyzing Gesture Patterns,"Risky behavior including violence and aggression, self-injury, anger outburst, domestic violence along with self-injury, sexual abuse, rule-breaking, use of drugs and alcohol, suicide, etc. are alarming issues among US military veterans who return from combat zone deployment in Iraq and Afghanistan. Veterans are exposed to trauma in war zones which affect most of them with post-traumatic stress disorder (PTSD) or other mental health problems to some degree. Studies have shown that veterans have much higher rates of PTSD than civilians and are more likely to engage in risky behavior. One of the forms of displaying and engaging in risky behaviors is through gestures. We collaborated with veterans and social scientists to find the list of 13 gestures that are often used by veterans engaged in risky behaviors. In this research work, we have collected accelerometer data from subjects performing the gestures mentioned above and have tried to detect them using machine learning techniques. This paper describes identifying gesture clusters from the accelerometer coordinate data and development of a predictive model that can classify the gestures resulting in the prediction of risky behaviors among the veterans who suffer from PTSD.",2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC),2019,10.1109/COMPSAC.2019.00104,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a75b6768778e0609dd91dc663b7a6a4b879edec,https://www.semanticscholar.org/paper/2a75b6768778e0609dd91dc663b7a6a4b879edec,Transforming Underwriting in the Life Insurance Industry,"Life insurance provides trillions of dollars of financial security for hundreds of millions of individuals and families worldwide. Life insurance companies must accurately assess individual-level mortality risk to simultaneously maintain financial strength and price their products competitively. The traditional underwriting process used to assess this risk is based on manually examining an applicant’s health, behavioral, and financial profile. The existence of large historical data sets provides an unprecedented opportunity for artificial intelligence and machine learning to transform underwriting in the life insurance industry. We present an overview of how a rich application data set and survival modeling were combined to develop a life score that has been deployed in an algorithmic underwriting system at MassMutual, an American mutual life insurance company serving millions of clients. Through a novel evaluation framework, we show that the life score outperforms traditional underwriting by 6% on the basis of claims. We describe how engagement with actuaries, medical doctors, underwriters, and reinsurers was paramount to building an algorithmic underwriting system with a predictive model at its core. Finally, we provide details of the deployed system and highlight its value, which includes saving millions of dollars in operational efficiency while driving the decisions behind tens of billions of dollars of benefits.",AAAI,2019,10.1609/aaai.v33i01.33019373,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
90d295f62b7bf7974e368fabe79c3711222b57f8,https://www.semanticscholar.org/paper/90d295f62b7bf7974e368fabe79c3711222b57f8,"Social Media for Mental Health: Data, Methods, and Findings",,,2020,10.1007/978-3-030-41251-7_8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
577f6634925377849fc0b8e9c55e9f85af31e907,https://www.semanticscholar.org/paper/577f6634925377849fc0b8e9c55e9f85af31e907,Sana.PCHR: Patient-Controlled Electronic Health Records for Refugees,,Leveraging Data Science for Global Health,2020,10.1007/978-3-030-47994-7_27,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
24e307bd97e7f7f00895484cc6719789e43a9a71,https://www.semanticscholar.org/paper/24e307bd97e7f7f00895484cc6719789e43a9a71,Bangladesh’s digital health journey: reflections on a decade of quiet revolution,"Bangladesh has made remarkable progress in digital health in recent years. Through one of the world’s largest deployments to date of the open-source District Health Information Software 2 (DHIS2), the country now has a national public sector health data warehouse. Information from previously fragmented data systems is now unified in a common data repository, enabling data exchange for health information systems and decision-making. Work is ongoing to create lifetime electronic health records for all citizens that can be transferred between health facilities. Extensive customization of open-source software has laid the foundations for a national digital networking system. Initiatives have focused on producing digital solutions to aid priorities such as strengthening the health system as a whole as well as supporting specific technical interventions, for example improving the civil registration and vital statistics system. Digital solutions have also supported the Bangladesh health workforce strategy through a set of registries that electronically captures and maintains human resource information for the entire public health sector, including monitoring staff attendance through the use of low-cost biometric fingerprint time-attendance machines. Citizens are encouraged to engage in shaping health services via a web-based complaints and suggestions system, and a new system to raise health awareness via public digital displays has started in Dhaka. Strong support at the highest political level has been critical to the success of efforts to introduce these innovations. The endeavour has also generated a cadre of enthusiastic eHealth proponents, who are focused on further strengthening and expanding the existing systems and on harnessing the vast amount of information amassed at the central data repository through big data analysis, artificial intelligence and machine learning.",WHO South-East Asia journal of public health,2019,10.4103/2224-3151.264849,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c5e003bc482e498f6a0677c82840edbc52856bc1,https://www.semanticscholar.org/paper/c5e003bc482e498f6a0677c82840edbc52856bc1,Recollections of John Fox: One of the founders of medical AI,"John Fox, who died in 2021, was a productive, far sighted cognitive and AI scientist best known for his work on the Oxford System of Medicine, the Proforma guideline modelling language and the OpenClinical computable knowledge publishing model. The Oxford System of Medicine (OSM) was a pioneering primary care decision support tool developed in the late 1980s in collaboration with Oxford University Press, supported by three British GPs (Mike O'Neill, Andrzej Glowinski and Peter Pritchard). This 5-year project explored how to develop a large scale, maintainable knowledge base with many thousands of declarative facts and a handful of generic rules that operated over them. OSM was initially developed using PROPS-2, a Prolog-based inference engine developed in the late 1980's by Saki Hajnal and other members of John's team at the Imperial Cancer Research Fund (ICRF—now merged into Cancer Research UK) in London. PROPS-2 was a well-supported expert system toolkit with a user manual and user group that was widely disseminated and used for prototyping many knowledgebased systems in the early years of medical AI, such as ACORN. The OSM provided a starting point for the development of John's ideas on symbolic decision procedures for autonomous agents (including human agency) that were taken forward by members of his Advanced Computation Laboratory at ICRF. Colin Gordon was the academic lead for the sequence of EU projects that took the OSM decision model and applied it to the clinical decisions involved in managing cancer treatments, which evolved into a framework for representing clinical guidelines. John worked with Paul Krause, Simon Parsons and others at the ACL to develop the foundational models for the logical assessment of arguments for and against different courses of action. This was early work in a strand that has now grown into a significant international body of academic research on argumentation. His ideas diverged from the mainstream data-driven approaches that have gained so much prominence in the last three decades, but anticipated concerns about interpretability and safety which are increasingly at the forefront of thinking about AI. One outcome of this research was the development of PROFORMA, a language for modelling computable guidelines based on a rigorous logic-based argumentation approach. It is a symbolic decision and planning language which provides an expressive formalism for modelling professional expertise and deploying ‘human friendly’ decision services and other cognitive agents, forming part of Fox's CREDO framework. Graphical programming tools allow the user to capture most of the logical structures found in practice guidelines in executable form, and PROFORMA has been tested in many clinical areas with 16 published studies (some of which are randomised trials) showing clinical benefit. The PROFORMA toolkit and language are complemented by a novel open publishing model that starts by developing a PROFORMA ‘publet’ (computable guideline fragment), documenting it and placing the results on the OpenClinical website for open peer review and revision. OpenClinical is a not-for-profit community interest company founded in 2003, aimed at improving patient care by promoting a new publication model for innovative AI and knowledge engineering techniques. It provides incubator and trialling services for machine executable models of clinical decision-making and workflow management using the OpenClinical platform, and is closely aligned with our current interest in Mobilising Computable Biomedical Knowledge, MCBK. OpenClinical has recently been spun-in to Oxford University Innovation's portfolio of not-for-profit companies—see www. openclinical.net. There are currently over 50 publets available for anyone to use on the site, including a recent COVID management guideline described in Learning Health Systems journal. John Fox also founded a learned journal in 1984, the Knowledge Engineering Review, and was editor for 12 years. This journal started with thin glossy paper and few subscribers but later gained the support of Cambridge University Press, has become widely read and cited and is now in its 36th volume. John was also influential in the formation of the British Computer Society Expert System group and the European Society for AI in Medicine in the 1980s and trained many PhDs and post docs, some of whom (such as Enrico Coiera and Paul Taylor) are now leading the discipline. John described himself as “Researcher in the scientific foundations, practical technologies and deployment of AI and cognitive systems for the real world.” After a PhD in psychology in Cambridge where he was supervised by Donald Broadbent FRS, he spent 2 years as a postdoc in the USA working at CMU with AI founders Allen Newell and Herb Simon and then at Cornell before returning to a post with the Medical Research Council in Sheffield. I first met John in 1985 soon after he had set up the Advanced Computation Lab and was advertising for two doctors to join him for the OSM project. In 1981, he had persuaded Sir Walter Bodmer FRS, then Director of ICRF, to remove his programming group from the computational support unit for ICRF scientists to become a new research unit, the Advanced Computation Lab (ACL). Spurred on by a series of quinquennial reviews carried out by distinguished international scientists, John built up the ACL over 25 years to become a Received: 22 February 2022 Accepted: 28 February 2022",Learning Health Systems,2022,10.1002/lrh2.10308,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
224a657b91aef3ab723e8f3c4c25c7de773f0d8f,https://www.semanticscholar.org/paper/224a657b91aef3ab723e8f3c4c25c7de773f0d8f,New Directions in Artifi cial Intelligence for Public Health Surveillance,"contamination of the food or water supply), and other patterns relevant to the health of populations (such as obesity, drug abuse, mental health, or malnutrition). This surveillance takes place at the local, state, national, and global scales, and often requires coordination of multiple entities (for example, hospitals, pharmacies, and local, state, and federal public health organizations) to achieve a timely, focused, and effective response to emerging health events. In this work, we focus on the role that AI and machine learning methods can play in assisting public health through the early, automatic detection of emerging outbreaks and other health-relevant patterns. The last decade has seen major advances in analytical methods for outbreak detection, including (but not limited to) analysis of spatial and temporal data,1 integration of multiple data streams,2 Bayesian methods to model and differentiate between multiple event types,3,4 more realistic outbreak simulations,5 and improved metrics to evaluate detection performance.6 Deployed systems have incorporated many such methods, monitoring a variety of public health data sources such as Emergency Department visits and over-the-counter medication sales7 and enabling more timely and accurate identifi cation of disease outbreaks in practice. While most existing surveillance systems rely heavily on basic statistical methods such as time series analysis together with the expert knowledge of public health practitioners, we believe that the disease surveillance fi eld is entering a major paradigm shift due to a dramatic increase in the number, quantity, and complexity of available data sources. Current disease surveillance systems are relying more and more on massive quantities of data from nontraditional sources, ranging from Internet search queries and user-generated Web content, to detailed electronic medical records, to continuous data streams from sensor networks, cellular telephones, and other locationaware devices. This shift toward analysis of data at the societal scale will require a corresponding shift in the methodologies employed in practical disease surveillance systems, incorporating techniques from AI, machine learning, and data mining to make sense of the massive quantity of data, to detect relevant patterns, and to assist public health decision making. Practitioners will increasingly rely on tools and systems that use advanced statistical methods to accurately distinguish relevant from irrelevant patterns, scalable algorithms to process the massive quantities of complex, high-dimensional data, and machine learning approaches to continually improve system performance from user feedback. Thus we believe that the next decade of disease surveillance research will require us to address three main challenges:",,2012,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
70f55179d6b854448fddb9fc2205d3cab8c13693,https://www.semanticscholar.org/paper/70f55179d6b854448fddb9fc2205d3cab8c13693,Persona Traits Identification based on Myers-Briggs Type Indicator(MBTI) - A Text Classification Approach,"Personality is a very important part of our lifestyle. It determines how we live, speak, react, and indicates our preferences, and even affects our mental health. Personality analysis is an intuitive ability of humans, carried out every day with multiple people, and for innumerable reasons. Personality profiling, specifically, has several real-life use cases, such as mental health screening tests, screening during human resource interviews, recommendations to writers about the interplay between personalities that people enjoy reading about and friend suggestions. This work presents the analysis of text written by a person such as an essay, tweet, or blog post and creates a personality profile of the person. The main considerations of the work are the type of data gathered, text preprocessing methods, and the machine learning techniques used to estimate personality scores. Various machine learning models and feature vector combinations have been compared, and deployment of solutions have been described. Accuracies up to 88% were achieved using the methods detailed in this work.","2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)",2018,10.1109/ICACCI.2018.8554828,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
307a2fa0c8e77f91ff1c0f7b2471c030078464ad,https://www.semanticscholar.org/paper/307a2fa0c8e77f91ff1c0f7b2471c030078464ad,Exergames in motor skill learning.,"IntroductionExergaming, by joining physical activity with Natural User Interfaces and Gesture Recognition technology, addresses the fundamental questions of perception and phenomenology in a digital context, with awareness that embodied actions within a digital media interface are ""fluid and functional crossings between virtual and physical realms."" (Hansen 2006)""Natural User Interface is the next metaphysical paradigm shiftin man machine interaction (MMI) also known as human computer interaction (HCI). Beginning with the Command Line Interface (CLI) and followed by the Graphical User Interface (GUI), we are now in the midst of discovering the next phase of a more organic interfaces which are based on more traditional human interaction paradigms such as touch, vision, speech and most importantly creativity."" (NUIGroup 2009)The Natural User Interfaces include input and output based on touch, voice, movements and move towards an efficient use of the senses in the interaction with machines.The origin of term ""exergame"" is uncertain: as noted Sinclair, earliest citation of ""exergame"", according to Wordspy website, is by RajuNudhar on the Toronto Star in 2004.In a bid to unite jocks with nerds in a way never seen before, Toronto-based Nexfit has introduced Canada's first exer-gaming bike. ...At its most basic, the product is an exercise bike that hooks up to a personal computer. The bike serves as a giant joystick. You use the handlebars as the controller, and above the right hand grip are the traditional joystick controls with a trigger button. For racing games, the pedals of the bike serve as the accelerator. There are also ""force feedback"" simulators so the rumble effect you get on a console's controller is emulated by the entire bike.RajuNudhar, ""In hot pursuit of the Holodeck,"" The Toronto Star, April 20, 2004Sinclair also noted as ""exergames are also referred to using the following terms; Activity promoting video games (Lanningham-Foster, Jensen et al.); interactive video games (Hoysniemi, 2006; Luke,2005), and exertion interfaces (Mueller, Agamanolis et al. 2003 2003, Yang, Smith et al. 2008).""(Sinclair 2011)In a study on the definition of exergames, Oh and Yang(Oh and Yang 2010) have proposed a classification of terms with which exergames are referred in scientific studies, distinguishing between health-related contexts and non health-related contexts. These terms are: Exergame, Exertainment, Dance simulation video game , Interactive video game, Activity promoting video game, Active video game, Physical gaming, Kinaesthetic of video gaming, Physical activity-change games.Given this state of the art, we agree with Yang (Yang, Smith et al. 2008), in affirming that this area of study ""is still in its infancy"".The definition of exergame used herein was provided by Bogost:""Exergaming is the combination of exercise and video games"" (Bogost 2007)It should be emphasized, however, as exergames involve the whole body of the player in the human-machine interaction process, making use of special devices such as MicrosoftKinect, the Nintendo Wiimote and BalanceBoard, just to mention the most well-known. (Di Tore and Raiola 2012)MethodsThis paper presents an excursus of the literature on exergames and summarizes the state of the art of research in this field, in an effort to identify the theoretical and didactic foundations of exergames design, in order to see if there are exergames that are attributable to a specific theoretical framework within Physical Education or that are specifically oriented to teaching or rehabilitation.This work intends to provide a preliminary analysis of the scientific literature on the subject of exergames, in order to verify whether there are scientific works in which have been studied and presented exergames specifically designed for educational purposes or rehabilitation purposes.ResultsSince the first deployment, exergames have received, in science, a positive reception, by virtue of two factors:involvement in the field of gaming the entire body of the player is a powerful tool in the longstanding battle against sedentary lifestyle (Chamberlin and Gallagher 2008);the level of user involvement, already high in traditional videogames, with exergames becomes even more valuable due to the NUIs (Baranowski, Buday et al. …",,2012,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a4ebc7ccc186da22b491e0c0f8883ff8888ef5b4,https://www.semanticscholar.org/paper/a4ebc7ccc186da22b491e0c0f8883ff8888ef5b4,A Multi-Disciplinary Framework for Continuous Biomedical Monitoring Using Low-Power Passive RFID-Based Wireless Wearable Sensors,"We have applied passive Radio Frequency Identification (RFID), typically used for inventory management, to implement a novel knit fabric strain gauge assembly using conductive thread. As the fabric antenna is stretched, the strength of the received signal varies, yielding potential for wearable, wireless, powerless smart-garment devices based on small and inexpensive passive RFID technology. Knit fabric sensors and other RFID biosensors can enable comfortable, continuous monitoring of biofeedback, but requires an integrated framework consisting of antenna modeling and fabrication, signal processing and machine learning on the noisy wireless signal, secure HIPAA- compliant data storage, visualization and human factors, and integration with existing medical devices and electronic health records (EHR) systems. We present a multidisciplinary, end-to-end framework to study, model, develop, and deploy RFID-based biosensors.",2016 IEEE International Conference on Smart Computing (SMARTCOMP),2016,10.1109/SMARTCOMP.2016.7501674,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1d4f1c75bc27f1f1b524cf25fc7307bb0de35271,https://www.semanticscholar.org/paper/1d4f1c75bc27f1f1b524cf25fc7307bb0de35271,A learning-based approach to exploiting sensing diversity in performance critical sensor networks,"Wireless sensor networks for human health monitoring, military surveillance, and disaster warning all have stringent accuracy requirements for detecting and classifying events while maximizing system lifetime. To meet high accuracy requirements and maximize system lifetime, we must address sensing diversity: sensing capability differences among both heterogeneous and homogeneous sensors in a specific deployment. Existing approaches either ignore sensing diversity entirely and assume all sensors have similar capabilities or attempt to overcome sensing diversity through calibration. Instead, we use machine learning to take advantage of sensing differences among heterogeneous sensors to provide high accuracy and energy savings for performance critical applications. 
In this dissertation, we provide five major contributions that exploit the nuances of specific sensor deployments to increase application performance. First, we demonstrate that by using machine learning for event detection, we can explore the sensing capability of a specific deployment and use only the most capable sensors to meet user accuracy requirements. Second, we expand our diversity exploiting approach to detect multiple events using a distributed manner. Third, we address sensing diversity in body sensor networks, providing a practical, user friendly solution for activity recognition. Fourth, we further increase accuracy and energy savings in body sensor networks by sharing sensing resources among neighboring body sensor networks. Lastly, we provide a learning-based approach for forwarding event detection decisions to data sinks in an environment with mobile sensor nodes.",,2012,10.21220/S2-CFQE-GA24,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ea7a38b28dadc4d57d7d2d9c0af998543a0564f5,https://www.semanticscholar.org/paper/ea7a38b28dadc4d57d7d2d9c0af998543a0564f5,Adaptive Thermal Sensor Array Placement for Human Segmentation and Occupancy Estimation,"Thermal sensor array (TSA) offers privacy-preserving, low-cost, and non-invasive features, which makes it suitable for various indoor applications such as anomaly detection, health monitoring, home security, and monitoring energy efficiency applications. Previous approaches to human-centred applications using the TSA usually relied on the use of a fixed sensor location to make the human-sensor distance and the human presence shape fixed. However, placing this sensor in different locations and new indoor environments can pose a significant challenge. In this paper, a novel framework based on a deep convolutional encoder-decoder network is proposed to address this challenge in real-life deployment. The framework presents a semantic segmentation of the human presence and estimates the occupancy in indoor-environment. It is also capable to segment the human presence and counts the number of people from different sensor locations, indoor environments, and human to sensor distance. Furthermore, the impact of the distance on the human presence using the TSA is investigated. The framework is evaluated to estimate the occupancy in different sensor locations, the number of occupants, environments, and human distance with classification and regression machine learning approaches. This paper shows that the classification approach using the adaptive boosting algorithm is an accurate approach which has achieves an accuracy of 98.43% and 100% from vertical and overhead sensor locations respectively.",IEEE Sensors Journal,2020,10.1109/JSEN.2020.3020401,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
194a032180c6a863a89fe349d11edf745e03ebee,https://www.semanticscholar.org/paper/194a032180c6a863a89fe349d11edf745e03ebee,Internet of Things (IoT) Based Indoor Air Quality Sensing and Predictive Analytic—A COVID-19 Perspective,"Indoor air quality typically encompasses the ambient conditions inside buildings and public facilities that may affect both the mental and respiratory health of an individual. Until the COVID-19 outbreak, indoor air quality monitoring was not a focus area for public facilities such as shopping complexes, hospitals, banks, restaurants, educational institutes, and so forth. However, the rapid spread of this virus and its consequent detrimental impacts have brought indoor air quality into the spotlight. In contrast to outdoor air, indoor air is recycled constantly causing it to trap and build up pollutants, which may facilitate the transmission of virus. There are several monitoring solutions which are available commercially, a typical system monitors the air quality using gas and particle sensors. These sensor readings are compared against well known thresholds, subsequently generating alarms when thresholds are violated. However, these systems do not predict the quality of air for future instances, which holds paramount importance for taking timely preemptive actions, especially for COVID-19 actual and potential patients as well as people suffering from acute pulmonary disorders and other health problems. In this regard, we have proposed an indoor air quality monitoring and prediction solution based on the latest Internet of Things (IoT) sensors and machine learning capabilities, providing a platform to measure numerous indoor contaminants. For this purpose, an IoT node consisting of several sensors for 8 pollutants including NH3, CO, NO2, CH4, CO2, PM 2.5 along with the ambient temperature & air humidity is developed. For proof of concept and research purposes, the IoT node is deployed inside a research lab to acquire indoor air data. The proposed system has the capability of reporting the air conditions in real-time to a web portal and mobile app through GSM/WiFi technology and generates alerts after detecting anomalies in the air quality. In order to classify the indoor air quality, several machine learning algorithms have been applied to the recorded data, where the Neural Network (NN) model outperformed all others with an accuracy of 99.1%. For predicting the concentration of each air pollutant and thereafter predicting the overall quality of an indoor environment, Long and Short Term Memory (LSTM) model is applied. This model has shown promising results for predicting the air pollutants’ concentration as well as the overall air quality with an accuracy of 99.37%, precision of 99%, recall of 98%, and F1-score of 99%. The proposed solution offers several advantages including remote monitoring, ease of scalability, real-time status of ambient conditions, and portable hardware, and so forth.",Electronics,2021,10.3390/ELECTRONICS10020184,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cf9509120c92d85bf1d1be9779c26c35950a7ec1,https://www.semanticscholar.org/paper/cf9509120c92d85bf1d1be9779c26c35950a7ec1,"Identifying Unproven Cancer Treatments on the Health Web: Addressing Accuracy, Generalizability and Scalability","Building machine learning models that identify unproven cancer treatments on the Health Web is a promising approach for dealing with the dissemination of false and dangerous information to vulnerable health consumers. Aside from the obvious requirement of accuracy, two issues are of practical importance in deploying these models in real world applications. (a) Generalizability: The models must generalize to all treatments (not just the ones used in the training of the models). (b) Scalability: The models can be applied efficiently to billions of documents on the Health Web. First, we provide methods and related empirical data demonstrating strong accuracy and generalizability. Second, by combining the MapReduce distributed architecture and high dimensionality compression via Markov Boundary feature selection, we show how to scale the application of the models to WWW-scale corpora. The present work provides evidence that (a) a very small subset of unproven cancer treatments is sufficient to build a model to identify unproven treatments on the web; (b) unproven treatments use distinct language to market their claims and this language is learnable; (c) through distributed parallelization and state of the art feature selection, it is possible to prepare the corpora and build and apply models with large scalability.",MedInfo,2013,10.3233/978-1-61499-289-9-667,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
32b84733c0f9898bab54c69a2de5534d2ed1b120,https://www.semanticscholar.org/paper/32b84733c0f9898bab54c69a2de5534d2ed1b120,Intelligent Techniques for Data Science,,Springer International Publishing,2016,10.1007/978-3-319-29206-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
be88e4783329a7dd5298c797ce7b946e93271359,https://www.semanticscholar.org/paper/be88e4783329a7dd5298c797ce7b946e93271359,Hindsight Analysis of the Chicago Food Inspection Forecasting Model,"The Chicago Department of Public Health (CDPH) conducts routine food inspections of over 15,000 food establishments to ensure the health and safety of their patrons. In 2015, CDPH deployed a machine learning model to schedule inspections of establishments based on their likelihood to commit critical food code violations. The City of Chicago released the training data and source code for the model, allowing anyone to examine the model. We provide the first independent analysis of the model, the data, the predictor variables, the performance metrics, and the underlying assumptions. We present a summary of our findings, share lessons learned, and make recommendations to address some of the issues our analysis unearthed.",ArXiv,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a65a08a09f4fbdad03bf2e02316b252c9221c71c,https://www.semanticscholar.org/paper/a65a08a09f4fbdad03bf2e02316b252c9221c71c,Adversarial Campaign Mitigation via ROC-Centric Prognostics,"Machine learning models are vulnerable to adversarial inputs that induce seemingly unjustifiable errors. As automated classifiers are increasingly used in industrial control systems and machinery, these adversarial errors could grow to be a serious problem. Despite numerous studies over the past few years, the field of adversarial ML is still considered alchemy, with no practical unbroken defenses demonstrated to date, leaving PHM practitioners with few meaningful ways of addressing the problem. We introduce “turbidity detection” as a practical superset of the adversarial input detection problem, coping with adversarial campaigns rather than statistically invisible one-offs. This perspective is coupled with ROC-theoretic design guidance that prescribes an inexpensive domain adaptation layer at the output of a deep learning model during an attack campaign. The result aims to approximate the Bayes optimal mitigation that ameliorates the detection model’s degraded health. A proactively reactive type of prognostics is achieved via Monte Carlo simulation of various adversarial campaign scenarios, by sampling from the model’s own turbidity distribution to quickly deploy the correct mitigation during a real-world campaign.",Annual Conference of the PHM Society,2019,10.36001/PHMCONF.2019.V11I1.865,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0add834925a8dce93832fdb3856bfaa0e4a2987a,https://www.semanticscholar.org/paper/0add834925a8dce93832fdb3856bfaa0e4a2987a,Part Name Normalization,"Parts information plays a key role in prognostics and health management. However, expressions of parts often have a wide range of variations, spawned by typos, ad hoc abbreviations, acronyms, and incomplete names. Normalization of such terms is crucial for many applications. Part names post a major challenge also because they tend to be in the form of multi-word terms. In this paper, we propose a novel normalization method UNAMER (Unification and Normalization Analysis, Misspelling Evaluation and Recognition). It is a general method for identifying term variants, including multi-word term variants, and normalizing them under a canonical name. UNAMER does not rely on a predefined set of canonical terms, which is often hard to obtain. Given a term, UNAMER first identifies candidate variants by exploiting contextual information. It then uses a supervised machine learning model, trained using easy-to-generate examples, that leverages both contextual and lexical features to predict actual variants from the candidates. UNAMER further extends its capability to normalize multi-word parts, such as part names like ‘lt pnl’, ‘letf pnl’ and ‘lft panal’ for ‘left panel’ using a specialized linguistically motivated term alignment approach. UNAMER has been deployed in practical applications to normalize part names in the aerospace domain. We will use examples from these real-life applications to demonstrate and illustrate results from UNAMER.",2019 IEEE International Conference on Prognostics and Health Management (ICPHM),2019,10.1109/ICPHM.2019.8819386,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
be764d06da50ebe9f4da5fa2289ee734409d6027,https://www.semanticscholar.org/paper/be764d06da50ebe9f4da5fa2289ee734409d6027,Is Regular Re-Training of a Predictive Delirium Model Necessary After Deployment in Routine Care?,"Adoption of electronic medical records in hospitals generates a large amount of data. Health care professionals can easily lose their sight on the important insights of the patients' clinical and medical history. Although machine learning algorithms have already proved their significance in healthcare research, remains a challenge translation and dissemination of fully automated prediction algorithms from research to decision support at the point of care. In this paper, we address the effect of changes in the characteristics of data over time on the performance of deployed models for the use case of predicting delirium in hospitalised patients. We have analysed the stability of models trained with subsets of data from one single year (2012, 2013...2016, respectively), and tested the models with data from 2017. Our results show that in the case of delirium prediction, the models were stable over time, indicating that re-training the models is not necessary e.g. once per year might be more than sufficient.",dHealth,2019,10.3233/978-1-61499-971-3-186,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
126ef846184ae1bb59a11e345f414b8cdda180c0,https://www.semanticscholar.org/paper/126ef846184ae1bb59a11e345f414b8cdda180c0,IOT BASED WEED DETECTION USING IMAGE PROCESSING AND CNN,"Farming is the source of income for more than half of the Indian population. One of the serious issues in agriculture is the control of weeds growing among the plantation crops. At present weeds are being removed manually by farmers wherever possible, or weed killers/herbicides are being sprayed all over the field to keep them under control. This technique is very inefficient because chemicals are being sprayed on plantation crops also, which leads to, polluting the environment and health problems in humans. To avoid these consequences, a smart weed control system should be deployed. This paper focuses on detecting the weeds in the crop using convolutional neural network ,Image processing and IOT. CNN model is first trained by giving large images of weed and crop. This trained CNN model is deployed onto Raspberry pi. Images from camera is sent to raspberry pi based Machine learning system. Raspberry-pi performs Image segmentation, by dividing the image into small segments. The Segmentation Algorithm used is Watershed Segmentation Algorithm. Each segment is passed onto Trained CNN model for classifying as weed or crop. If it is weed, the area is marked in the original image as weed. In this manner all the weed segments are marked and the marked image can be sent to farmers through Email. The system was trained using 250 images of weed and crop and has given an Average Accuracy of 85% ,Average False ratio of 7%,Average False Acceptance ratio of 2.6%. Keywords—Convolutional Neural Network, watershed segmentation Algorithm, Raspberry Pi",International Journal of Engineering Applied Sciences and Technology,2019,10.33564/ijeast.2019.v04i03.089,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aef4f9a704832d654d776b79797b1219e8473377,https://www.semanticscholar.org/paper/aef4f9a704832d654d776b79797b1219e8473377,Resource Central: Understanding and Predicting Workloads for Improved Resource Management in Large Cloud Platforms,"Cloud research to date has lacked data on the characteristics of the production virtual machine (VM) workloads of large cloud providers. A thorough understanding of these characteristics can inform the providers' resource management systems, e.g. VM scheduler, power manager, server health manager. In this paper, we first introduce an extensive characterization of Microsoft Azure's VM workload, including distributions of the VMs' lifetime, deployment size, and resource consumption. We then show that certain VM behaviors are fairly consistent over multiple lifetimes, i.e. history is an accurate predictor of future behavior. Based on this observation, we next introduce Resource Central (RC), a system that collects VM telemetry, learns these behaviors offline, and provides predictions online to various resource managers via a general client-side library. As an example of RC's online use, we modify Azure's VM scheduler to leverage predictions in oversubscribing servers (with oversubscribable VM types), while retaining high VM performance. Using real VM traces, we then show that the prediction-informed schedules increase utilization and prevent physical resource exhaustion. We conclude that providers can exploit their workloads' characteristics and machine learning to improve resource management substantially.",SOSP,2017,10.1145/3132747.3132772,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8d37fc1a144ab3db6510b6a6a52a76107335f6cd,https://www.semanticscholar.org/paper/8d37fc1a144ab3db6510b6a6a52a76107335f6cd,Practical Intrusion Detection of Emerging Threats,"The Internet of Things (IoT), in combination with advancements in Big Data, communications and networked systems, offers a positive impact across a range of sectors including health, energy, manufacturing and transport. By virtue of current business models adopted by manufacturers and ICT operators, IoT devices are deployed over various networked infrastructures with minimal security, opening up a range of new attack vectors. Conventional rule-based intrusion detection mechanisms used by network management solutions rely on pre-defined attack signatures and hence are unable to identify new attacks. In parallel, anomaly detection solutions tend to suffer from high false positive rates due to the limited statistical validation of ground truth data, which is used for profiling normal network behaviour. In this work we go beyond current solutions and leverage the coupling of anomaly detection and Cyber Threat Intelligence (CTI) with parallel processing for the profiling and detection of emerging cyber attacks. We demonstrate the design, implementation, and evaluation of Citrus: a novel intrusion detection framework which is adept at tackling emerging threats through the collection and labelling of live attack data by utilising diverse Internet vantage points in order to detect and classify malicious behaviour using graph-based metrics as well as a range of machine learning (ML) algorithms. Citrus considers the importance of ground truth data validation and its flexible software architecture enables both the real-time and offline profiling, detection and classification of emerging cyber-attacks under optimal computational costs. Thus, establishing it as a viable and practical solution for next generation network defence and resilience strategies.",IEEE Transactions on Network and Service Management,2022,10.1109/tnsm.2021.3091517,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
93f3402bcc717208a1473899a793870476d3bf21,https://www.semanticscholar.org/paper/93f3402bcc717208a1473899a793870476d3bf21,Cost-Effectiveness Analysis of a Procalcitonin-Guided Decision Algorithm for Antibiotic Stewardship Using Real-World U.S. Hospital Data,"Abstract Medical decision-making is revolutionizing with the introduction of artificial intelligence and machine learning. Yet, traditional algorithms using biomarkers to optimize drug treatment continue to be important and necessary. In this context, early diagnosis and rational antimicrobial therapy of sepsis and lower respiratory tract infections (LRTI) are vital to prevent morbidity and mortality. In this study we report an original cost-effectiveness analysis (CEA) of using a procalcitonin (PCT)-based decision algorithm to guide antibiotic prescription for hospitalized sepsis and LRTI patients versus standard care. We conducted a CEA using a decision-tree model before and after the implementation of PCT-guided antibiotic stewardship (ABS) using real-world U.S. hospital-specific data. The CEA included societal and hospital perspectives with the time horizon covering the length of hospital stay. The main outcomes were average total costs per patient, and numbers of patients with Clostridium difficile and antibiotic resistance (ABR) infections. We found that health care with the PCT decision algorithm for hospitalized sepsis and LRTI patients resulted in shorter length of stay, reduced antibiotic use, fewer mechanical ventilation days, and lower numbers of patients with C. difficile and ABR infections. The PCT-guided health care resulted in cost savings of $25,611 (49% reduction from standard care) for sepsis and $3630 (23% reduction) for LRTI, on average per patient. In conclusion, the PCT decision algorithm for ABS in sepsis and LRTI might offer cost savings in comparison with standard care in a U.S. hospital context. To the best of our knowledge, this is the first health economic analysis on PCT implementation using U.S. real-world data. We suggest that future CEA studies in other U.S. and worldwide settings are warranted in the current age when PCT and other decision algorithms are increasingly deployed in precision therapeutics and evidence-based medicine.",Omics : a journal of integrative biology,2019,10.1089/omi.2019.0113,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d925bf5a4141296fbd36d4984e81d70886e09dbc,https://www.semanticscholar.org/paper/d925bf5a4141296fbd36d4984e81d70886e09dbc,Fine-Scale Air Pollution Models for Epidemiologic Research: Insights From Approaches Developed in the Multi-ethnic Study of Atherosclerosis and Air Pollution (MESA Air).,,Current environmental health reports,2021,10.1007/s40572-021-00310-y,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b70f7a33388d14738e392264f798357a4a957fcc,https://www.semanticscholar.org/paper/b70f7a33388d14738e392264f798357a4a957fcc,Industrial Agents and Distributed Agent-Based Learning,"Today sensor data processing and information mining become more and more complex concerning the amount of sensor data to be processed, the data dimension, the data quality, and the relationship between derived information and input data. This is the case especially in large-scale sensing and measuring processes embedded in Cloud environments. Measuring uncertainties, calibration errors, and unreliability of sensors have a significant impact on the derivation quality of suitable information. In the technical and industrial context the raising complexity and distribution of data processing is a special issue. Commonly, information is derived from raw input data by using some kind of mathematical model and functions, but often being incomplete or unknown. If reasoning of statements is primarily desired, Machine Learning can be an alternative. Traditionally, sensor data is acquired and delivered to and processed by a central processing unit. In this paper, the deployment of distributed Machine Learning using mobile Agents forming self-organizing and self-adaptive systems (self-X) is discussed and posing the benefit for the enhancement of the sensor and data processing in technical and industrial systems. This also addresses the quality of the computed statements, e.g., an accurate prediction of run-time parameters like mechanical loads or health conditions, the efficiency, and the reliability in the presence of partial system failures",ECSA 2016,2016,10.3390/CASA-3-S2004,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
05fe0a3ae371dc1e2b0f90ee29cb73063c6c43bf,https://www.semanticscholar.org/paper/05fe0a3ae371dc1e2b0f90ee29cb73063c6c43bf,"Internet of Things (IoT) for Next-Generation Smart Systems: A Review of Current Challenges, Future Trends and Prospects for Emerging 5G-IoT Scenarios","The Internet of Things (IoT)-centric concepts like augmented reality, high-resolution video streaming, self-driven cars, smart environment, e-health care, etc. have a ubiquitous presence now. These applications require higher data-rates, large bandwidth, increased capacity, low latency and high throughput. In light of these emerging concepts, IoT has revolutionized the world by providing seamless connectivity between heterogeneous networks (HetNets). The eventual aim of IoT is to introduce the plug and play technology providing the end-user, ease of operation, remotely access control and configurability. This paper presents the IoT technology from a bird’s eye view covering its statistical/architectural trends, use cases, challenges and future prospects. The paper also presents a detailed and extensive overview of the emerging 5G-IoT scenario. Fifth Generation (5G) cellular networks provide key enabling technologies for ubiquitous deployment of the IoT technology. These include carrier aggregation, multiple-input multiple-output (MIMO), massive-MIMO (M-MIMO), coordinated multipoint processing (CoMP), device-to-device (D2D) communications, centralized radio access network (CRAN), software-defined wireless sensor networking (SD-WSN), network function virtualization (NFV) and cognitive radios (CRs). This paper presents an exhaustive review for these key enabling technologies and also discusses the new emerging use cases of 5G-IoT driven by the advances in artificial intelligence, machine and deep learning, ongoing 5G initiatives, quality of service (QoS) requirements in 5G and its standardization issues. Finally, the paper discusses challenges in the implementation of 5G-IoT due to high data-rates requiring both cloud-based platforms and IoT devices based edge computing.",IEEE Access,2020,10.1109/ACCESS.2020.2970118,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
44935233e13bff2fca0e85c076dd4ea24986d045,https://www.semanticscholar.org/paper/44935233e13bff2fca0e85c076dd4ea24986d045,Ensemble Based Real-Time Adaptive Classification System for Intelligent Sensing Machine Diagnostics,"The deployment of a sensor node to manage a group of sensors and collate their readings for system health monitoring is gaining popularity within the manufacturing industry. Such a sensor node is able to perform real-time configurations of the individual sensors that are attached to it. Sensors are capable of acquiring data at different sampling frequencies based on the sensing requirements. The different sampling rates affect power consumption, sensor lifespan, and the resultant network bandwidth usage due to the data transfer incurred. These settings also have an immediate impact on the accuracy of the diagnostics and prognostics models that are employed for system health monitoring. In this paper, we propose a novel adaptive classification system architecture for system health monitoring that is well suited to accommodate and take advantage of the variable sampling rate of sensors. As such, our proposed system is able to yield a more effective health monitoring system by reducing the power consumption of the sensors, extending the sensors' lifespan, as well as reducing the resultant network traffic and data logging requirements. We also propose an ensemble based learning method to integrate multiple existing classifiers with different feature representations, which can achieve significantly better, stable results compared with the individual state-of-the-art techniques, especially in the scenario when we have very limited training data. This result is extremely important in many real-world applications because it is often impractical, if not impossible, to hand-label large amounts of training data.",IEEE Transactions on Reliability,2012,10.1109/TR.2012.2194352,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
43b3c43b14509cc7027ff3a146c54f6957d8698a,https://www.semanticscholar.org/paper/43b3c43b14509cc7027ff3a146c54f6957d8698a,Identification of Snails and Schistosoma of Medical Importance via Convolutional Neural Networks: A Proof-of-Concept Application for Human Schistosomiasis,"In recent decades, computer vision has proven remarkably effective in addressing diverse issues in public health, from determining the diagnosis, prognosis, and treatment of diseases in humans to predicting infectious disease outbreaks. Here, we investigate whether convolutional neural networks (CNNs) can also demonstrate effectiveness in classifying the environmental stages of parasites of public health importance and their invertebrate hosts. We used schistosomiasis as a reference model. Schistosomiasis is a debilitating parasitic disease transmitted to humans via snail intermediate hosts. The parasite affects more than 200 million people in tropical and subtropical regions. We trained our CNN, a feed-forward neural network, on a limited dataset of 5,500 images of snails and 5,100 images of cercariae obtained from schistosomiasis transmission sites in the Senegal River Basin, a region in western Africa that is hyper-endemic for the disease. The image set included both images of two snail genera that are relevant to schistosomiasis transmission – that is, Bulinus spp. and Biomphalaria pfeifferi – as well as snail images that are non-component hosts for human schistosomiasis. Cercariae shed from Bi. pfeifferi and Bulinus spp. snails were classified into 11 categories, of which only two, S. haematobium and S. mansoni, are major etiological agents of human schistosomiasis. The algorithms, trained on 80% of the snail and parasite dataset, achieved 99% and 91% accuracy for snail and parasite classification, respectively, when used on the hold-out validation dataset – a performance comparable to that of experienced parasitologists. The promising results of this proof-of-concept study suggests that this CNN model, and potentially similar replicable models, have the potential to support the classification of snails and parasite of medical importance. In remote field settings where machine learning algorithms can be deployed on cost-effective and widely used mobile devices, such as smartphones, these models can be a valuable complement to laboratory identification by trained technicians. Future efforts must be dedicated to increasing dataset sizes for model training and validation, as well as testing these algorithms in diverse transmission settings and geographies.",Frontiers in Public Health,2021,10.3389/fpubh.2021.642895,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
52181d427d942a5a1c2b51e7e3ae78c4f87d784b,https://www.semanticscholar.org/paper/52181d427d942a5a1c2b51e7e3ae78c4f87d784b,Gaussian Markov Random Fields for Localizing Reinforcing Bars in Concrete Infrastructure,"Sensor technologies play a significant role in monitoring the health conditions of urban sewer assets. Currently, the concrete sewer systems are undergoing corrosion due to bacterial activities on the concrete surfaces. Therefore, water utilities use predictive models to estimate the corrosion by using observations such as relative humidity or surface moisture conditions. Surface moisture conditions can be estimated by electrical resistivity based moisture sensing. However, the measurements of such sensors are influenced by the proximal presence of reinforcing bars. To mitigate such effects, the moisture sensor needs to be optimally oriented on the concrete surface. This paper focuses on developing a machine learning model for localizing the reinforcing bars inside the concrete through non-invasive measurements. This work utilizes a resistivity meter that works based on the Wenner technique to obtain electrical measurements on the concrete sample by taking measurements at different angles. Then, the measured data is fed to a Gaussian Markov Random Fields based spatial prediction model. The spatial prediction outcome of the proposed model demonstrated the feasibility of localizing the reinforcing bars with reasonable accuracy for the measurements taken at different angles. This information is vital for decision-making while deploying the moisture sensors in sewer systems.",Proceedings of the 35th International Symposium on Automation and Robotics in Construction (ISARC),2018,10.22260/ISARC2018/0146,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
812fcbe5aa03a0f9907b1c3c15b133ca9fac764b,https://www.semanticscholar.org/paper/812fcbe5aa03a0f9907b1c3c15b133ca9fac764b,Data mining to predict and prevent errors in health insurance claims processing,"Health insurance costs across the world have increased alarmingly in recent years. A major cause of this increase are payment errors made by the insurance companies while processing claims. These errors often result in extra administrative effort to re-process (or rework) the claim which accounts for up to 30% of the administrative staff in a typical health insurer. We describe a system that helps reduce these errors using machine learning techniques by predicting claims that will need to be reworked, generating explanations to help the auditors correct these claims, and experiment with feature selection, concept drift, and active learning to collect feedback from the auditors to improve over time. We describe our framework, problem formulation, evaluation metrics, and experimental results on claims data from a large US health insurer. We show that our system results in an order of magnitude better precision (hit rate) over existing approaches which is accurate enough to potentially result in over $15-25 million in savings for a typical insurer. We also describe interesting research problems in this domain as well as design choices made to make the system easily deployable across health insurance companies.",KDD,2010,10.1145/1835804.1835816,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
176d31f73bc65e07dc6e650b75404c31666dcdbb,https://www.semanticscholar.org/paper/176d31f73bc65e07dc6e650b75404c31666dcdbb,Design of a Spark Big Data Framework for PM2.5 Air Pollution Forecasting,"In recent years, with rapid economic development, air pollution has become extremely serious, causing many negative effects on health, environment and medical costs. PM2.5 is one of the main components of air pollution. Therefore, it is necessary to know the PM2.5 air quality in advance for health. Many studies on air quality are based on the government’s official air quality monitoring stations, which cannot be widely deployed due to high cost constraints. Furthermore, the update frequency of government monitoring stations is once an hour, and it is hard to capture short-term PM2.5 concentration peaks with little warning. Nevertheless, dealing with short-term data with many stations, the volume of data is huge and is calculated, analyzed and predicted in a complex way. This alleviates the high computational requirements of the original predictor, thus making Spark suitable for the considered problem. This study proposes a PM2.5 instant prediction architecture based on the Spark big data framework to handle the huge data from the LASS community. The Spark big data framework proposed in this study is divided into three modules. It collects real time PM2.5 data and performs ensemble learning through three machine learning algorithms (Linear Regression, Random Forest, Gradient Boosting Decision Tree) to predict the PM2.5 concentration value in the next 30 to 180 min with accompanying visualization graph. The experimental results show that our proposed Spark big data ensemble prediction model in next 30-min prediction has the best performance (R2 up to 0.96), and the ensemble model has better performance than any single machine learning model. Taiwan has been suffering from a situation of relatively poor air pollution quality for a long time. Air pollutant monitoring data from LASS community can provide a wide broader monitoring, however the data is large and difficult to integrate or analyze. The proposed Spark big data framework system can provide short-term PM2.5 forecasts and help the decision-maker to take proper action immediately.",International journal of environmental research and public health,2021,10.3390/ijerph18137087,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d751a13fb4de5cd9a9ee2405174e1b2ada01846d,https://www.semanticscholar.org/paper/d751a13fb4de5cd9a9ee2405174e1b2ada01846d,Data portability for activities of daily living and fall detection in different environments using radar micro-doppler,,Neural Comput. Appl.,2022,10.1007/s00521-022-06886-2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2762e0dc0e3f54eb28634803d7ea4d3de7c7421f,https://www.semanticscholar.org/paper/2762e0dc0e3f54eb28634803d7ea4d3de7c7421f,Computational decision support system in healthcare: a review and analysis,"A decision support system (DSS) may help to synchronize comprehensive computational aspects of computational problems like knowledge discovery, processing, and pattern visualization. It provides an effective channel for decision making by churning huge datasets. Primarily, DSS has been deployed in domains like business process management, health informatics, and even for managing smart devices. Numerous algorithms have been proposed to augment the efficacy of DSS and are undergoing refinement. Most recently, DSS has been trialed in the healthcare industry because there is a need for an intelligent decision support system. It may be helpful in the process of automation along with the solution generation and evaluation. In this paper, broad analysis and discussion on the applicability and suitability of the methods related to DSS and algorithms have been discussed along with the role of information and communications technology (ICT). It also includes problem-based discussion and suggested solutions along with different cases in the healthcare system. It covers the data analysis with the domain intelligence impact along with the information processing for knowledge extraction and discovery. It also covers some of the clinical decision aspects for understanding the impact of other correlated medical resource systems. The methodological and computational analysis includes data preprocessing, knowledge extraction, interpretation, decision-making model, and the influencing factors in the performance analysis. The main data mining methods considered here for the DSS system in case of healthcare informatics discussion were association rule mining, clustering, classification and optimization algorithms. The machine learning aspects covered here in three ways supervised, semi-supervised, and unsupervised for the decision analysis based on the healthcare system. Finally, based on the methodological and computational applicability different decision-making scenarios have been discussed and analyzed for the analysis of the combination and nature of applicability. Our study and analysis provide an analytical and computational perspective in terms of the health care system, influencing parameters, their applicability, a methodological perspective, decision-making process, traditional methods, and the challenges along with the suggested measures for the future. It's also helpful in the process of maintaining the internal and external aspects which is more reliable in performance aspects of DSS.",,2021,10.19101/IJATEE.2020.762142,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59c08c29d97488c4199b146644606fdc8f8c3894,https://www.semanticscholar.org/paper/59c08c29d97488c4199b146644606fdc8f8c3894,Identifying and Mapping Groups of Protected Area Visitors by Environmental Awareness,"Protected areas worldwide receive billions of visitors annually. The positive impact of nature on health and wellbeing, in addition to providing opportunities for cultural activities such as recreation and aesthetic appreciation, is well documented. Management to reduce negative impacts to biodiversity and conservation aims whilst providing amenities and access to visitors is important. Understanding environmental awareness of visitors and their on-site spatial patterns can assist in making effective management decisions within often constrained resources. However, there is a lack of strategies for site-specific identification and predictive mapping of visitors by environmental awareness. Here, we demonstrate a method to map on-site visitation by latent groups of visitors based on their environmental awareness of on-site issues. On-site surveys and participatory mapping were used to collect data on environmental awareness on bird nesting and spatial visitation patterns in an upland moor in northern England. Latent class analysis (LCA), a structural equation model, was used to discover underlying groups of environmental awareness, with random forest (RF) modelling, a machine learning technique, using a range of on-site predictors (bioclimatic, land cover, elevation, viewshed, and proximity to paths and freshwater) to predict and map visitation across the site by each group. Visitors were segmented into ‘aware’ and ‘ambiguous’ groups and their potential spatial visitation patterns mapped. Our results demonstrate the ability to uncover groups of users by environmental awareness and map their potential visitation across a site using a variety of on-site predictors. Spatial understanding of the movement patterns of differently environmentally aware groups of visitors can assist in efficient targeting of conservation education endeavours (i.e., signage, positioning of staff, monitoring programmes, etc.), therefore maximising their efficacy. Furthermore, we anticipate this method will be of importance to environmental managers and educators when deploying limited resources.",Land,2021,10.3390/LAND10060560,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
86a39663fa2f9160a7a434ee37d4a5ad55410946,https://www.semanticscholar.org/paper/86a39663fa2f9160a7a434ee37d4a5ad55410946,Artificial intelligence in pathology and laboratory medicine,"Increased healthcare demand has placed pressure on laboratory medicine to improve turnover and optimise efficiency using digitalisation, automation and artificial intelligence (AI). This will bring new challenges for the clinical laboratory. Laboratorians need to understand the utility of AI, its limitations and implementation. The management of big data requires ready access and accurate and contextual analysis. AI uses complex algorithms and data from medical and laboratory data to mimic human analysis and this requires accurate and reliable data. The role of AI in laboratory medicine is rapidly expanding owing to recognition of its potential to improve detection, laboratory workflows, decision support and reduce costs and increase efficiency. In this thematic issue on AI, we have attempted to present an overview of the uses of AI in laboratory medicine and advances in the digitalisation of pathology. Rakha et al from the University of Nottingham and Google Health provide an erudite overview of current and future applications of AI in pathology. The applications of AI in pathology range from prognostic/predictive applications to workflow and diagnostic applications to education as well as to the integration of other investigative data derived from genomics and radiology. It is clear that the trend of rapid deployment of AI will continue, but they highlight the gap between the translation process of discovery to clinical application, which they attribute to the fact that research and the clinical environment are often widely separated. The articles in this issue go to some length to highlight the areas of current and future applications in pathology. One area where digitalisation has progressed rapidly is in whole slide imaging. This allows slides to be transferred between locations. The value of digital neuropathology is illustrated in the paper in this issue by Williams and coauthors at the University of Leeds. This has also progressed towards the use of AI for interpretation of digital slides. There will be increased application of AI algorithms in the digital diagnostic workflow according to Stathonikos et al. The increased adoption of digital pathology allows the use of AI algorithms to facilitate automatic triaging and quality control along with assisted reading of whole slide images. There will be increased utilisation of diagnostic, prognostic and predictive algorithms based on AIdrive image analysis. Evans and coauthors describe the provision of highquality and costeffective histopathology to underserviced, remote areas, for example, in rural Canada, has been enabled by the application of digital pathology. Whole slide imaging has also found use in distant teaching as shown by that between the University of Toronto and the University of the West Indies. Immunohistochemistry is a technique that plays a crucial role in histopathology and traditionally the sections have been quantified visually by pathologists. This takes time and is subjective. Computer analysis offers the opportunity of standardised, quantifiable and highly reproducible scoring. The publication on ovarian cancer by Gentles et al illustrates this point elegantly and proves that automated scoring is reliable and superior to manual scoring and offers the reproducibility needed for highthroughput diagnostic applications. It is clear that cancer diagnosis will be one of the major growth areas for AI applications as with cancer being the leading cause of death and the most important obstacle to increased life expectancy. Deeplearning platforms for H&E analysis of slide are more sensitive to variations that escape the human eye and can offer improved fine tuning of disease prediction and prognostication and advancement of the goals of personalised and precision medicine. The review by Fitzgerald and coauthors examines how improved therapeutic stratification can be achieved in breast and prostate cancer using biomarkers and AI algorithms. They conclude that AI and machine learning will enhance precision oncology and ease the burden of pathologists and improve the capacity for reviewing high priority cases as well improve the quality and precision of diagnosis for patients. Bone marrow slide analysis will also benefit from machine learning and Baranova et al illustrate this with an open source learning tool for plasma cells. The quantitation of bone marrow plasma cell percentage is an important component of the diagnostic criteria for multiple myeloma. Using an open source digital pathology tool, QuPath, CD138positive bone marrow plasma cells were quantified. This was found to improve the speed and accuracy of cell counting. Big data analysis is a domain where the power of AI comes to the fore. This is particularly evident in chemical pathology where Punchoo et al provide a detailed overview of the applications of machine learning in the chemical pathology laboratory. Machine learning can be applied to diverse chemical pathology laboratory processes including clinical decision support, detection of errors, analysis of gels and discovery of biomarkers. Machine learning analysis offers the promise of rapid and standardised interpretation for digitised gel images in serum protein electrophoresis. The future is certainly bright and laboratorians and clinicians will need to be educated in the principles of machine learning in the framework of the appropriate regulatory and ethical frameworks.",Journal of Clinical Pathology,2021,10.1136/jclinpath-2021-207682,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7b63a396f39d22b0b47e5f7030c972f1280dba94,https://www.semanticscholar.org/paper/7b63a396f39d22b0b47e5f7030c972f1280dba94,"Fog-to-Cloud Computing for Animal Farming: Towards Low-Cost Technologies, Data Exchange and Animal Welfare","Coordinated fog-to-cloud computing systems are expected to expedite the evolution of cloud-based smart farming, towards openness and data sharing, while making farming economically sustainable for smaller farms. We demonstrate a fog-to-cloud enabled animal farming system that not only deploys low-cost technology for data collection and sharing, but also uniquely considers animal welfare and quality-of-life. On an practical example of a multi-master replication of SQL Server databases between Microsoft Azure Cloud and multiple fog nodes on the farm, we show that fog-based systems can help improve performance, scale to higher amounts of database entries, pre-process data with aid of machine learning, while providing reliability of the system in an easy-to-use fashion. Considerations of animal welfare, cloud-based data analysis, fog-enabled farming along with mobile applications are envisioned as common place for future farmers and consumers alike, and are in line with a recent trends connecting animal welfare, human health and the environment.",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29abfa0a99680b36d5832331098ca035354f0b42,https://www.semanticscholar.org/paper/29abfa0a99680b36d5832331098ca035354f0b42,Identifying Military Veterans in a Clinical Research Database using Natural Language Processing,"BackgroundThere is a lack of quantitative evidence concerning United Kingdom veterans who access secondary mental health care. This is mainly due to a person’s veteran status not being routinely collected when they enter the health care system. 
Main AimThe study aimed to develop an NLP approach for identifying veterans accessing secondary mental health care services using National Health Service electronic health records. 
MethodsVeterans were identified using the South London and Maudsley Biomedical Research Centre (SLaM) case register – a database holding secondary mental health care electronic records for the South London and Maudsley National Health Service Trust of 300,000 patients. We developed two methods. An NLP and machine learning tool were developed to automatically evaluate personal history statements written by clinicians. 
ResultsThis study showed that it was possible to identify veterans using the NLP and machine learning approach on a sub-set of 4,200 patients. The automatic machine learning method was able to identify 270 veterans representing an accuracy of 97.2%. It is estimated to take between 6 to 16 minutes to manually search patient history statements whereas the automatic machine learning method took only one minute to run. 
ConclusionWe have shown that it is possible to identify veterans using NLP combined with machine learning. This work contributes towards the development of a more comprehensive picture of veterans who are accessing secondary mental health care services in the UK. It represents a first step in identifying veterans from one dataset and we hope that future research can inform the possibility of deploying the methods nationally. Despite our success in the current work, the tools are tailored to the SLaM dataset and future work is needed to develop a more agnostic framework. 
FundingForces in Mind Trust",International Journal of Population Data Science,2019,10.23889/ijpds.v4i3.1162,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
febafe7171e459a5fbd5b286cb4433af3f3441c6,https://www.semanticscholar.org/paper/febafe7171e459a5fbd5b286cb4433af3f3441c6,Thoughts on Edge Intelligence,"Machine learning methods have exploded in the past half-dozen years. Machine learning is being applied to a huge range of problems across the spectrum of applications. Initial results relied on server-oriented computations. But many applications will require deploying aspects of machine learning throughout the network hierarchy. Several factors motivate the development of Edge Intelligence architectures and algorithms: network bandwidth, power consumption, latency, privacy, etc. This talk will start the motivation for edge intelligence with several examples from manufacturing and health care and outline some important problems for VLSI systems.",ACM Great Lakes Symposium on VLSI,2019,10.1145/3299874.3322802,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a417267ce843dae3587d5567dacf165451445fc,https://www.semanticscholar.org/paper/3a417267ce843dae3587d5567dacf165451445fc,CAPACITIVE SENSORS FOR SAFETY APPLICATIONS,Indoor human localization is widely used nowadays for majority of the applications. Tag less human localization can really be helpful in the field of health care. Some Machine learning algorithms can fruitfully detect sensor data variability and noises caused by the deployment-specific conditions of environment. We present a system in which we make use of experimental data from a capacitive sensor-based indoor human localization system to detect unauthorized intrusion and abnormal entries that can be further monitored using the GSM modules. Machine learning algorithms like the Weka Collections can be used for human indoor localization for the purpose of exactly identifying the person's location inside a room and further prevent him or her entering furthermore using a shock generator.,,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
76519b32542a93d949c903c14c7cdf8e81f40e24,https://www.semanticscholar.org/paper/76519b32542a93d949c903c14c7cdf8e81f40e24,Session 1 : Intelligent Transportation and Urban Planning,"Activities of Daily Living (ADLs), or a person’s routine activities of selfcare, are important factors influencing the feasibility of home health care or aging in place for many individuals. Automated, sensor-based recognition of such activities affords home stay, greater independence and privacy, and improved quality of life to individuals who would require stay in a supervised or medical facility. This paper describes a data-driven framework for the design and deployment of such an automated system for activity recognition using simple, unobtrusive, and privacy-friendly binary sensors. It presents the results of an experimental study, with both numerical and qualitative observations, of this framework on a publicly available real dataset. Machine Learning on Cataracts Classification Using SqueezeNet Author(s): Xingzhi Qian, Evan W. Patton, Justin Swaney, Qian Xing, Tingying(Helen) Zeng Abstract: Cataracts is a serious eye disease, affecting over 20 million people worldwide. It is the clouding of the lens, which blocks the light to go through the lens and project on the retina. As a result, the nerve cannot transfer the whole image to the brain, leading to blindness. A vast majority of cataracts patients are people who are over 50 years old. To classify different areas of cataracts in lens, we use supervised training of convolutional neural network to train 420 images of cataracts on the lens taken from slit-lamps. The experiment can make the future of classifying cataracts more easily and ophthalmologists can apply operations to different categories of cataracts within a shorter time to cure patients with cataracts. For those people in the countryside, even not so experienced doctors can take the photo of lens and use the program to classify cataracts correctly. A Study on Multidimensional Medical Data Processing Based on Random Forest Author(s): Lifeng Zhang, Hongyan Cui, Roy E.Welsch Abstract: In the field of medical research, when researchers use physical examination indicators to diagnose diseases, it is often difficult to make decisions because of the large number of data dimensions. It is also tough to make effective decisions on whether or not to be ill according to relatively important attributes. Under such circumstances, this paper proposes a feature extraction method based on random forest, which extracts features from multidimensional data. With validation of the UCI diabetic retinopathy data, we designed a method to calculate the impact score of multi-dimensional attributes to the presence or absence of disease. Then, by selecting two groups of data with higher impact score and lower impact score. Last, we used neural network algorithm to make comparative verification. The experimental results show that the high-impact score data calculated by the random forest has certain advantages over the lowscore data in disease diagnosis, both on the accuracy of the diagnosis model and the diagnosis. We choose to use this method to select fewer features with higher scores to diagnose diseases, and also achieve good results. Plant Disease Identification Using Convolutional Neural Networks Author(s): Kevin Zeng Qi, Justin Mark Swaney, Evan W. Patton Abstract: Plant diseases are a major threat to food security for public health. The goal of this research is to develop an effective system that can detect these diseases before they become widespread. We combat this by innovatively training a convolutional neural network to detect and identify diseases from the RGB images of plant leaves. The architecture of the network is based on the Alexnet architecture. The dataset consisted of corn, tomato and apple leaf images. The results were to be very promising with a 92.22% accuracy when trained and tested on the specific labels of each disease and species. First-Aid system desig Author(s): Haoran Ma, Yang Liu, Yajuan Fang, Berthold K.P.Horn Abstract: For the new upgrade of an existing first-aid system, the method of combining mobile device with Internet is adopted to realize the real-time feedback of patients' location information, query the corresponding first-aid methods and call nearby resources, so as to shorten the time of first-aid for patients and save their lives. Session 3a: Intelligent Communities Time: 8:00am-10:30am, October 24th Location: W20-306 Chair(s): Gilly Leshed UniWifi, A Smart Network System Author(s): Harry Zhou, Bruce Wang Abstract: As people become more and more reliant on wifi to complete day to day tasks, individuals also become increasingly restricted to their homes or places that provide it. We propose an Intelligent Network System that could provide constant wifi connection to the masses so that anyone could roam anywhere within an urban area and remain connected to the internet. Our concept revolves around using the contemporary ‘mesh zone’ technology. In phase one, we believe that by having small yet powerful routers installed everywhere, mesh zones that be created to effectively cover areas small and large. In phase two, the potential of having routers moved to the skies becomes probable when combined with high performance drones. The goal is global connectivity. We envision for a future where every device around the globe is connected to one or many central network databases. This is important because all internet traffic could be monitored and therefore greatly eliminating most if not all potential intrusions to civilian safety all around the globe. There are three checkpoints that we would like to accomplish. First, to test the connectivity range of a mesh router with a commercial drone. Then to successfully build our own beta prototype flyer. And at last, to test our beta flyers with multiple mesh routers to complete a working mesh zone. Wifi routers today are not being used to their full potential as they ironically work independently to connect collective devices to the web. By implementing mesh, one could connect to secure and fast connection while having mobility freedom. One could truly stay connected anywhere and everywhere. CoDAS, a Method for Envisioning Larger-Scaled Computational Artifacts Connecting Communities Author(s): Carlos Araujo de Aguiar, Gilly Leshed, Alexander Bernard, John McKenzie, Camille Andrews, Keith Evan Green Abstract: Information Technologies are increasingly embedded into artifacts of the physical world—furniture, rooms, buildings, and urban infrastructure—making communities around-the-globe more connected and, arguably, more intelligent. However, such larger-scaled, social computing artifacts arrive with critical concerns of cost, material choice, design requirements, fabrication means, robust and safe use, power, and resistance to vandalism and the elements. Given the complexity of realizing larger-scaled, computational artifacts, conventional design methods prove inadequate and potentially costly and dangerous if researchers move too quickly to full-scale prototyping. In this paper, we present CoDAS, a hybrid methodological approach that combines elements of well-known HCI methods to effectively develop larger-scale social computing artifacts. A survey of Multi-controllers Consistency on SDN Author(s): Tao Yu, Yang Hong, Hongyan Cui, Hongxiang Jiang Abstract: Software-Defined Network (SDN) is developing rapidly for its benefit of programmability. However, new challenges also appear. One of them is while we are applying distributed controllers in SDN networks, we must consider the consistency problem. In SDN networks, especially in a multi-controller architecture, it is a great challenge to maintain a global view consistency of the networks among all controllers, which is also key to issue flow regulations. Lacking of consistency in packets, flows, and networks level may result in serious errors. Besides, consistency problem also exists in data plane. How to keep all switches executing a same set of rules to avoid errors is often discussed. In this paper we’ll conclude the different situations of consistency problems and provide the related research solutions. The methods in the paper not only regard to consistency of control plane, but also data plane. At last, we also introduced the two methods to evaluate the performance of consistency, those are strong consistency and final consistency. Anonymous network communication based on SDN Author(s): Taiyu Wong, Hongyan Cui, Yuepeng Shen, Wenqi Lin, Tao Yu Abstract: As more and more personal information is used in network services, network anonymity has received more and more attention. Attackers could endanger the victims’ privacy by attacking or eavesdropping nodes during the networks routing. For example, attackers could retrieve the IP and MAC address of victims from network traffics, and use it to correlate the network behavior to individuals. The emerging Software Defined Network (SDN) technique provides a pretty flexible platform that can control the whole network by software programming, which propose a new solution to realize the network anonymity problem. In this paper, we propose a solution based on SDN to anonymize both MAC and IP addresses of network traffics in order to mitigate the privacy threats, and programing it. Furthermore, we test the anonymity function on our SDN Testbed. Our solution supports two working modes: a two-way anonymous mode which anonymizes the IP and MAC addresses of all data packets, and an one-way anonymous mode which anonymizes MAC and IP addresses of senders. Friendly Acoustic Technology Enhance Neighborhood and Friendship Author(s): Zhang Xiangdong, Kuang Zheng, Yang Jun Abstract: It is estimated that there are currently 80 million to 100 million square dance crowds in China. Due to noise pollution, there are often quarrels and conflicts between the square dance crowd and their neighbors. Even in order to compete for the venue, there will be disputes between different square dance teams. The directional sound product based on local sound field control technolog",,2019,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
907badca5cb6ce2aa0d4ba36029d9540e72bd4ab,https://www.semanticscholar.org/paper/907badca5cb6ce2aa0d4ba36029d9540e72bd4ab,Non-contact modal parameters identification using a K-cluster algorithm,"Non-contact structural health monitoring is a promising field for assessing civil structures, such as bridges. Not having to access the structure avoids different issues: the closure of the structure, the use of special equipment to access it, and others. This study uses digital image processing, machine learning, and parallel computing to detect the vibration of a flexible structure. If a structure is too stiff, a reinforced concrete short-span bridge or a multi-story building, it is hard to identify its natural frequencies without some sort of target panel or target feature. Instead, if the structure is flexible, it is possible to identify its displacement and its natural frequencies, but it is a challenge with high computational cost. This study presents an unsupervised machine-learning algorithm to identify a structure, its displacement, and its natural frequencies. The algorithm was deployed on a simple supported beam using a commercially available camera and an inexpensive GPU.",Smart Structures and Materials + Nondestructive Evaluation and Health Monitoring,2019,10.1117/12.2514443,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
486937398769701f921bbbfc18efeb284f93b63c,https://www.semanticscholar.org/paper/486937398769701f921bbbfc18efeb284f93b63c,"Camera-based, mobile disease surveillance using Convolutional Neural Networks","ObjectiveAutomated syndromic surveillance using mobile devices is an emerging public health focus that has a high potential for enhanced disease tracking and prevention in areas with poor infrastructure. Pacific Northwest National Laboratory sought to develop an Android mobile application for syndromic biosurveillance that would i) use the phone camera to take images of human faces to detect individuals that are sick through a machine learning (ML) model and ii) collect image data to increase training data available for ML models. The initial prototype use case is for screening and tracking the health of soldiers for use by the Department of Defense’s Disease Threat Reduction Agency.IntroductionInfectious diseases present with multifarious factors requiring several efforts to detect, prevent, and break the chain of transmission. Recently, machine learning has shown to be promising for automated surveillance leading to rapid and early interventions, and extraction of phenotypic features of human faces [3, 5]. In addition, mobile devices have become a promising tool to provide on-the-ground surveillance, especially in remote areas and geolocation mapping [4].Pacific Northwest National Laboratory (PNNL) combines machine learning with mobile technology to provide a groundbreaking prototype of disease surveillance without the need for internet, just a camera. In this android application, VisionDx, a machine learning algorithm analyses human face images and within milliseconds notifies the user with confidence level whether or not the person is sick. VisionDx comes with two modes, photo and video, and additional features of history, map, and statistics. This application is the first of its kind and provides a new way to think about the future of syndromic surveillance.MethodsData. Human healthy (n = 1096) and non-healthy (n = 1269) facial images met the criteria for training the Machine Learning model after preprocessing them. The healthy images were obtained from the Chicago face database [6] and California Institute of Technology [2]. There are no known collections of disease facial images. Using open source image collection/curation services, images were identified by a variety of keywords, including specific infectious diseases. The criteria for image inclusion was 1. a frontal face was identified using OpenCV library [1], and 2. the image contained signs of disease through visual inspection (e.g., abnormal color, texture, swelling).Model. To identify a sick face from a healthy one, we used transfer machine learning and experimented with various pretrained Convolutional Neural Networks (CNN) from Google for mobile and embedded vision applications. Using MobileNet, we trained the final model with our data and deployed it to our prototype mobile app. Google Mobile Vision API and TensorFlow mobile were used to detect human faces and run predictions in the mobile app.Mobile Application. The Android app was built using Android Studio to provide an easily navigable interface that connects every action between tabbed features. The app features (i.e., Map, Camera, History, and Statistics) are in tab view format. The custom-made camera is the main feature of the app, and it contains face detection capability. A real-time health status detection function gives a level of confidence based the algorithm results found on detected faces in the camera image.ResultsPNNL's prototype Android application, VisionDx, was built with user-friendly tab views and functions to take camera images of human faces and classify them as sick or healthy through an inbuilt ML model. The major functions of the app are the camera, map, history, and statistics pages. The camera tab has a custom-made camera with face detection algorithm and classification model of sick or healthy. The camera has image or video mode and results of the algorithm are updated in milliseconds. The Statistics view provides a simple pie chart on sick/healthy images based on user selected time and location. The Map shows pins representing all labeled images stored, and the History displays all the labeled images. Clicking on an image in either view shows the image with metadata, i.e., model confidence levels, geolocation, and datetime.The CNN model prediction accuracy has ~98% validation accuracy and ~96% test accuracy. High model performance shows the possibility that deep learning could be a powerful tool to detect sickness. However, given the limited dataset, this high accuracy also means the model is most likely overfit to the data. The training set is limited: a. the number of training images is small compared to the variability in facial expressions and skin coloring, and b. the sick images only contained overt clinical signs. If trained on a larger, diverse set of data, this prototype app could prove extremely useful in surveillance efforts of individual to large groups of people in remote areas, e.g., to identify individuals in need of medical attention or get an overview of population health. In effort to improve the model, VisionDx was developed as a data collection tool to build a more comprehensive dataset. Within the tool, users can override the model prediction, i.e., false positive or false negative, with a simple toggle button. Lastly, the app was built to protect privacy so that other phone aps can't access the images unless shared by a user.ConclusionsDeveloped at PNNL for the Defense Threat Reduction Agency, VisionDx is a novel, camera-based mobile application for real-time biosurveillance and early warning in the field without internet dependency. The prototype mobile app takes pictures of faces and analyzes them using a state-of-the-art machine learning model to give two confidence levels of likelihood of being sick and healthy. With further development of a labeled dataset, such as by using the app as a data collection too, the results of the algorithm will quickly improve leading to a ground-breaking approach to public health surveillance.References1. Bradski G. (n.d.) The OpenCV Library. Retrieved Sept 30, 2018 at http://www.drdobbs.com/open-source/the-opencv-library/1844043192. Computational Vision: Archive. (1999). Retrieved Sept 22, 2018 at http://www.vision.caltech.edu/html-files/archive.html3. Ferry Q, Steinberg J, Webber C, et al (2014). Diagnostically relevant facial gestalt information from ordinary photos. ELife, 3, e02020.4. Fornace KM, Surendra H, Abidin TR, et al (2018). Use of mobile technology-based participatory mapping approaches to geolocate health facility attendees for disease surveillance in low resource settings. International Journal of Health Geographics, 17(1), 21. https://doi.org/10.1186/s12942-018-0141-05. Lopez DM, de Mello FL, G Dias, CM, et al (2017). Evaluating the Surveillance System for Spotted Fever in Brazil Using Machine-Learning Techniques. Frontiers in Public Health, 5. https://doi.org/10.3389/fpubh.2017.003236. Ma DS, Correll J, Wittenbrink B. (2015) The Chicago face database: A free stimulus set of faces and norming data. Behavior Research Methods, 47(4), 1122–1135. https://doi.org/10.3758/s13428-014-0532-5 ",Online Journal of Public Health Informatics,2019,10.5210/ojphi.v11i1.9849,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59b9ebadfd2b801b64722d786f62224db8ccc089,https://www.semanticscholar.org/paper/59b9ebadfd2b801b64722d786f62224db8ccc089,Risk Stratification and Prognosis Using Predictive Modelling and Big Data Approaches,,Health Informatics,2019,10.1007/978-3-030-18626-5_7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
893f8b5782df115c60137dd339dbdd4509f51454,https://www.semanticscholar.org/paper/893f8b5782df115c60137dd339dbdd4509f51454,Ultra High-Dimensional Nonlinear Feature Selection for Big Biological Data,"Machine learning methods are used to discover complex nonlinear relationships in biological and medical data. However, sophisticated learning models are computationally unfeasible for data with millions of features. Here, we introduce the first feature selection method for nonlinear learning problems that can scale up to large, ultra-high dimensional biological data. More specifically, we scale up the novel Hilbert-Schmidt Independence Criterion Lasso (HSIC Lasso) to handle millions of features with tens of thousand samples. The proposed method is guaranteed to find an optimal subset of maximally predictive features with minimal redundancy, yielding higher predictive power and improved interpretability. Its effectiveness is demonstrated through applications to classify phenotypes based on module expression in human prostate cancer patients and to detect enzymes among protein structures. We achieve high accuracy with as few as 20 out of one million features—a dimensionality reduction of 99.998 percent. Our algorithm can be implemented on commodity cloud computing platforms. The dramatic reduction of features may lead to the ubiquitous deployment of sophisticated prediction models in mobile health care applications.",IEEE Transactions on Knowledge and Data Engineering,2016,10.1109/TKDE.2018.2789451,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e3f567f023a2d2480b0283a6bac0601503b1bc22,https://www.semanticscholar.org/paper/e3f567f023a2d2480b0283a6bac0601503b1bc22,Learning Predictive Analytics with R,"Get to grips with key data visualization and predictive analytic skills using RAbout This BookAcquire predictive analytic skills using various tools of RMake predictions about future events by discovering valuable information from data using RComprehensible guidelines that focus on predictive model design with real-world dataWho This Book Is ForIf you are a statistician, chief information officer, data scientist, ML engineer, ML practitioner, quantitative analyst, and student of machine learning, this is the book for you. You should have basic knowledge of the use of R. Readers without previous experience of programming in R will also be able to use the tools in the book.What You Will LearnCustomize R by installing and loading new packagesExplore the structure of data using clustering algorithmsTurn unstructured text into ordered data, and acquire knowledge from the dataClassify your observations using Naive Bayes, k-NN, and decision treesReduce the dimensionality of your data using principal component analysisDiscover association rules using AprioriUnderstand how statistical distributions can help retrieve information from data using correlations, linear regression, and multilevel regressionUse PMML to deploy the models generated in RIn DetailR is statistical software that is used for data analysis. There are two main types of learning from data: unsupervised learning, where the structure of data is extracted automatically; and supervised learning, where a labeled part of the data is used to learn the relationship or scores in a target attribute. As important information is often hidden in a lot of data, R helps to extract that information with its many standard and cutting-edge statistical functions.This book is packed with easy-to-follow guidelines that explain the workings of the many key data mining tools of R, which are used to discover knowledge from your data.You will learn how to perform key predictive analytics tasks using R, such as train and test predictive models for classification and regression tasks, score new data sets and so on. All chapters will guide you in acquiring the skills in a practical way. Most chapters also include a theoretical introduction that will sharpen your understanding of the subject matter and invite you to go further.The book familiarizes you with the most common data mining tools of R, such as k-means, hierarchical regression, linear regression, association rules, principal component analysis, multilevel modeling, k-NN, Naive Bayes, decision trees, and text mining. It also provides a description of visualization techniques using the basic visualization tools of R as well as lattice for visualizing patterns in data organized in groups. This book is invaluable for anyone fascinated by the data mining opportunities offered by GNU R and its packages.Style and approachThis is a practical book, which analyzes compelling data about life, health, and death with the help of tutorials. It offers you a useful way of interpreting the data that's specific to this book, but that can also be applied to any other data.",,2015,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
00dcfbe542c80d259c0a530e5f42e9705fb9080b,https://www.semanticscholar.org/paper/00dcfbe542c80d259c0a530e5f42e9705fb9080b,What to know before forecasting the flu,"Accurate and timely influenza (flu) forecasting has gained significant traction in recent times. If done well, such forecasting can aid in deploying effective public health measures. Unlike other statistical or machine learning problems, however, flu forecasting brings unique challenges and considerations stemming from the nature of the surveillance apparatus and the end utility of forecasts. This article presents a set of considerations for flu forecasters to take into account prior to applying forecasting algorithms.",PLoS Comput. Biol.,2018,10.1371/journal.pcbi.1005964,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fba4eac6b1f9259ad524bb70fb144c34f9794a36,https://www.semanticscholar.org/paper/fba4eac6b1f9259ad524bb70fb144c34f9794a36,The Promise for Reducing Healthcare Cost with Predictive Model: An Analysis with Quantized Evaluation Metric on Readmission,"Quality of care data has gained transparency captured through various measurements and reporting. Readmission measure is especially related to unfavorable patient outcomes that directly bends the curve of healthcare cost. Under the Hospital Readmission Reduction Program, payments to hospitals were reduced for those with excessive 30-day rehospitalization rates. These penalties have intensified efforts from hospital stakeholders to implement strategies to reduce readmission rates. One of the key strategies is the deployment of predictive analytics stratified by patient population. The recent research in readmission model is focused on making its prediction more accurate. As cost-saving improvements through artificial intelligent-based health solutions are expected, the broad economic impact of such digital tool remains unknown. Meanwhile, reducing readmission rate is associated with increased operating expenses due to targeted interventions. The increase in operating margin can surpass native readmission cost. In this paper, we propose a quantized evaluation metric to provide a methodological mean in assessing whether a predictive model represents cost-effective way of delivering healthcare. Herein, we evaluate the impact machine learning has had on transitional care and readmission with proposed metric. The final model was estimated to produce net healthcare savings at over $1 million given a 50% rate of successfully preventing a readmission.",Journal of healthcare engineering,2021,10.1155/2021/9208138,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cf1ea98787d70340d621ab7f62b1565de12feac9,https://www.semanticscholar.org/paper/cf1ea98787d70340d621ab7f62b1565de12feac9,Li-ion Battery Aging with Hybrid Physics-Informed Neural Networks and Fleet-wide Data,"Lithium-ion batteries are commonly used to power electric unmanned aircraft vehicles (UAVs).Therefore, the ability to model both the state of charge as well as battery health is very important for reliable and affordable operation of UAV fleets.Even though models based on first principles are accurate and trustworthy, the complex electro-chemistry that governs battery discharge and aging makes it hard to build and use such models for in-time monitoring of battery conditions.Moreover, the careful tuning or estimation of high-fidelity model parameters hampers the straightforward deployment in the field.Alternatively, reduced order models have the advantage of capturing the overall behavior of battery discharge. 
Reduced-order principle-based models are built by carefully simplifying the physics/chemistry such that computational cost is dramatically reduced while the overall behavior of the system is still captured.These simplifications also lead to a number of parameters to be estimated based on data as well as residual discrepancy (model-form uncertainty).This approach can lead to a number of parameters to be estimated based on data as well as residual model-form uncertainty; a property shared with machine learning models. The latter are solely built on the basis of data, and can still capture unexpected nonlinearities.The drawback is that traditional machine learning tends to require large number of data points hard to retrieve in many scientific and engineering fields like, for example, the field of battery discharge and degradation prediction. 
In this paper, we will present a hybrid modeling approach for tracking and forecasting battery aging based on ``as-used'' conditions.Our approach directly implements a reduced-order model based on Nerst and Butler-Volmer equations within a deep neural network framework.While most of the input-output relationship is captured by reduced-order models, the data-driven kernels reduce the gap between predictions and observations.The hybrid model estimates the overall battery discharge, and a multilayer perceptron models the battery internal voltage.Battery aging is characterized by time-dependent internal resistance and the amount of available Li-ions.We address the difficult issue of building and updating the aging model by reducing the need for reference discharge cycles.This is beneficial to operators, since it reduces the need of taking the batteries out of commission.We compensate for lack of reference discharge cycles by using a probabilistic model that leverages previously available fleet-wide information. 
We validate our approach using data publicly available through the NASA Prognostics Center of Excellence website.Results showed that our hybrid battery prognosis model can be successfully calibrated, even with a limited number of observations.Moreover, the model can help optimizing battery operation by offering long-term forecast of battery capacity.",Annual Conference of the PHM Society,2021,10.36001/phmconf.2021.v13i1.2998,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ed7a57c1565e394ed576650d02a7b88c2d92c677,https://www.semanticscholar.org/paper/ed7a57c1565e394ed576650d02a7b88c2d92c677,CairoDep: Detecting Depression in Arabic Posts Using BERT Transformers,"Early detection and intervention of mental illness can significantly improve the chances of successful treatment and cure. With the wide adoption and use of social media platforms, the posts of someone give a window to his or her mind that can help detect mental health issues. Numerous researches were done to identify mental health conditions from posts in English language. Very few were done for Arabic language using traditional natural language processing (NLP) models. In this novel research, we use the latest NLP models, namely Bidirectional Encoded from Representations Transformers (BERT), for detecting depression in Arabic social media posts. We built CairoDep, a set of models and a benchmark dataset for this purpose. First, we built CairoDep v1.0 dataset, a labeled dataset of 7000 posts including 3400 normal (non-depressed) posts and 3600 depressed posts. Our dataset was collected from multiple sources, specifically crowdsourcing, Arabic mental health forums and pages, readily available datasets and translation from English datasets. Second, we further trained two pre-trained BERT transformers for Arabic language to detect depression from Arabic posts in Modern Standard Arabic (MSA) and dialectic Arabic, namely ARABERT and MARBERT. We further trained and evaluated them on the dataset using 80%-20% split. We achieved accuracy, precision, recall and F1-Score values of 96.93%, 96.92%, 96.93% and 96.92% for ARABERT and of 96.07%, 96.11%, 96.04% and 96.07% for MARBERT respectively. These results are quite superior to the results reported in the literature for depression detection using lexicon analysis or traditional machine learning techniques. They open the door for deploying NLP transformers to develop mental health AI-powered applications and platforms for Arabic speakers. We developed these models as part of iHayaNow, an AI-based mental health helpline and a holistic platform for Arabic speakers that is under research and development.",2021 Tenth International Conference on Intelligent Computing and Information Systems (ICICIS),2021,10.1109/ICICIS52592.2021.9694178,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0d14e1189b011091c708e01568055d9a146a8ba6,https://www.semanticscholar.org/paper/0d14e1189b011091c708e01568055d9a146a8ba6,Intelligent systems and computational methods in medical and healthcare solutions with their challenges during COVID-19 pandemic,"This special issue of the Journal of Intelligent Systems focuses on recent advances and improvements in intelligent systems and computational methods in medical and healthcare solutions with their challenges during COVID - 19 pandemic. Although intelligent systems and arti ﬁ cial intelligence ( AI ) and their appli cations are now the hottest research areas, in recent years, there have been more and more AI applica tions in the medical ﬁ eld. AI technology is promoting the development of the medical and health indus -tries. In the medical domain, AI techniques can be used to develop clinical decision support systems to help with medical diagnostics. AI technologies can also be deployed in various medical devices, trackers, and information systems. A huge amount of patient data are recorded in the electronic medical record database, including diagnosis, medical history, medications, and lab results. Through the process of extraction, transformation, and loading, researchers can generate a patient dataset worthy of analysis by AI techniques. In addition to the data analysis using structure data, AI techniques are now used for medical image recognition, medical text and semantic recognition, and molecular biological testing. The analysis results can be used as a reference for the evaluation of patients by the medical team. Recently, AI, internet - of - things, big data analytics, machine learning, deep learning, Fog Computing, cloud com -puting, and block chain technologies have been intelligently applied with various applications in net -working, Medical diagnosis and Healthcare Systems, shipping to build e ﬃ cient, sustainable systems, and Intelligent Solutions to Medical and Healthcare Systems. This special issue focuses on advanced techniques in signal processing, analysis, modelling, and classi ﬁ cation, applied to a variety of medical diagnostic problems. Biomedical data play a fundamental role in many ﬁ elds of research and clinical practice. Very often the complexity of these data and their large volume makes it necessary to develop advanced analysis techniques and systems. Furthermore, the introduction of new techniques and methodologies for diagnostic purposes, especially in the ﬁ eld of medical imaging, requires new signal processing and machine learning methods. The recent progress in In the ﬁ rst paper under this category, Manal Mostafa Ali proposed an e ﬀ ective Arabic Sentiment Analysis about Online Learning to Mitigate Covid - 19. Di ﬀ erent classi ﬁ cation algorithms including Naïve Bayes ( NB ) , Multinomial Naïve Bayes ( MNB ) , K Nearest Neighbor ( KNN ) , Logistic Regression ( LR ) , and Support Vector Machine ( SVM ) were examined. The experiments reveal that the proposed model performs well in analyzing the perception of people about coronavirus with a maximum accuracy of about 89.6% using SVM classi ﬁ er. paper, a Void - hole Aware and Reliable Data Forwarding Strategy for Underwater Wireless Sensor Networks. This article proposes a void - holes aware and reliable data forwarding strategy ( VHARD - FS ) in a proactive mode to control data packet delivery from CH nodes to the sink in underwater wireless sensor networks ( UWSNs ) . In the proposed strategy, each CH node is aware of its neighbor ’ s performance ranking index to conduct a reliable packet transmission to the sink via the most energy - e ﬃ cient route. Extensive simulation results indicate that the VHARD - FS outperforms existing routing approaches while comparing energy e ﬃ ciency and network throughput. This study helps to e ﬀ ec tively alleviate the resource limitations associated with UWSNs by extending network life and increasing service availability even in a harsh underwater environment. proposed an Identi ﬁ cation of E ﬃ cient COVID - 19 Diagnostic Test Through Arti ﬁ cial Neural Networks Approach – Substantiated by and They arti ANN to acquire the COVID 19 The analyzed by using Learning, and probabilistic were applied The results indicated Gold for Real - Time and Heterogeneous Data Sources. This paper proposes a general Multiple Coordinative Data Fusion Modules ( MCDFM ) framework for real - time and heterogeneous data sources. They develop the MCDFM framework to adapt various DF application domains requiring macro and micro perspectives of the observed problems. This framework consists of preprocessing, ﬁ l -tering, and decision as key DF processing phases. These three phases integrate speci ﬁ c purpose algorithms or methods such as data cleaning and windowing methods for preprocessing, extended Kalman ﬁ lter ( EKF ) for ﬁ ltering, fuzzy logic for local decision, and software agents for coordinative decision. These methods perform tasks that assist in achieving local and coordinative decisions for each node in the network of the framework application domain. They illustrate and discuss the proposed framework in detail by taking a stretch of road intersections controlled by a tra ﬃ c light controller ( TLC ) as a case study. The case study provides a clearer view of the way the proposed framework solves tra ﬃ c congestion as a domain problem. They identify the tra ﬃ c features that include the average vehicle count, average vehicle speed ( km/h ) , average density ( % ) , interval ( s ) , and timestamp. The framework uses these features to identify three congestion periods, which are the non - peak period with a congestion degree of 0.178 and a variance of 0.061, a medium peak period with a congestion degree of 0.588 and a variance of 0.0593, and a peak period with a congestion degree of 0.796 and a variance of 0.0296.",Journal of Intelligent Systems,2021,10.1515/jisys-2021-0171,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4a263d8913f928ba96597592019e56a94614ea82,https://www.semanticscholar.org/paper/4a263d8913f928ba96597592019e56a94614ea82,HybridFaceMaskNet: A Novel Face-Mask Detection Framework Using Hybrid Approach,"
 Coronavirus disease 2019 (covid-19 ) is a contiguous disease which is caused by severe acute respiratory syndrome coronavirus2(SARAS-2) started from Wuhan, china, and spread all over the world within a few months in 2019. Government of all countries had to apply lockdown to decrease the number of aﬀected patient as mortality rate of many countries became very high at that time. In the awake of 2nd wave of COVID 19 WHO has made mandatory to use mask in largely crowded areas, health centers, communities and in diﬀerent places to prevent spread of virus. Many countries have invented the vacancies but it will ﬁrstly available for corona front line warriors only, not for general people, So, people have to wear mask when they are going out from home. But In recent days it can be followed that people are reluctant to wear mask when they are entering in oﬃces, departmental stores or local shops where, gathering might happen anytime. This could lead to spread of COVID-19 among the communities. With the help of computer-vision, people who are not wearing mask can be detected by generating an alarm signal. To achieve this challenging task, a face mask detector ‘HybridFaceMaskNet’ is proposed, which is a combination of classical Machine Learning and deep learning algorithm. ‘HybridFaceMaskNet’ can achieve state-of-art accuracy on public faces. The real challenges are the low-quality images, diﬀerent distances of people from camera and dynamic lighting on the faces at daylight or in artiﬁcial light.This problem can be overcome by using diﬀerent noise removal techniques. HybridFaceMaskNet is trained with three diﬀerent classiﬁcation of images ‘proper-mask’, ‘incorrect-mask’ and ‘no-mask’ which are collected from real life images and some synthetic data , to generate alarm for diﬀerent scenario .This HybridFaceMaskNet is trained on Google Colab and is compared with diﬀerent existing face mask detector model. There is a possibility of deploy the model in IOT devices as it is light weight compare to other existing models.",,2021,10.21203/RS.3.RS-476241/V1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
081477fc7873583fe2da9a961ebc9ea04f21fd69,https://www.semanticscholar.org/paper/081477fc7873583fe2da9a961ebc9ea04f21fd69,Comparison of binary classifiers for data-driven prognosis of jet engines health,"A reliable prognosis is crucial to manage asset health and predict maintenance needs of large civil jet engines, which in turn contribute to enhanced aircraft airworthiness, longer time on wing and optimized lifecycle costs. With the accumulation of large amount of data over the last decade, one can relate the number of components serviced during a maintenance visit to the history of parameters inside and outside the engine (temperatures, pressure, shaft rotation speeds, vibration levels, etc.). While established statistical models had been developed for small samples, more recent computer-intensive statistical techniques from the field of Machine Learning (ML) can handle more complex datasets. In particular, binary classifiers constitute an attractive option to predict the probability of servicing the components of a given jet engine at the next maintenance visit. This paper demonstrates the validity of such data-driven methods on an industrial case study involving failures of thousands of compressor blades in aeronautical turbomachines. The prediction accuracy obtained with the ML techniques presents a significant improvement over the state-of-the-art. Moreover, the performance of six binary classifiers with different characteristics logistic regression, support vector machines, classification trees, random forests, gradient boosted trees and neural networks was compared according to four qualitative and quantitative criteria. Results show that there is no clear winner, although ensemble models based on trees (random forests and boosted trees) offer a good overall compromise while neural networks offer the best absolute performance. In the industrial world, the business objectives, the environment in which the models are deployed and the users’ skills should dictate the choice of the most adequate statistical technique.",,2014,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98167c045aee227671960d6c8da22f135602f5b9,https://www.semanticscholar.org/paper/98167c045aee227671960d6c8da22f135602f5b9,A hardware-friendly algorithm for scalable training and deployment of dimensionality reduction models on FPGA,"With ever-increasing application of machine learning models in various domains such as image classification, speech recognition and synthesis, and health care, designing efficient hardware for these models has gained a lot of popularity. While the majority of researches in this area focus on efficient deployment of machine learning models (a.k.a inference), this work concentrates on challenges of training these models in hardware. In particular, this paper presents a high-performance, scalable, reconfigurable solution for both training and deployment of different dimensionality reduction models in hardware by introducing a hardware-friendly algorithm. Compared to state-of-the-art implementations, our proposed algorithm and its hardware realization decrease resource consumption by 50% without any degradation in accuracy.",2018 19th International Symposium on Quality Electronic Design (ISQED),2018,10.1109/ISQED.2018.8357319,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
806a9c5f7e9d1ab38d6a0df1506b6a1cea2df5f4,https://www.semanticscholar.org/paper/806a9c5f7e9d1ab38d6a0df1506b6a1cea2df5f4,Mobility Patterns of Doctors Using Electronic Health Records on iPads,"Before Electronic Health Records (EHRs) were available on touch-panel tablets, doctors were confined to accessing the records on their hospital's computer stations, in their offices or at nurse stations. We deployed Dr. Pad, a mobile EHR application on the iPad, to resident doctors at the Taipei Veterans General Hospital in Taipei, Taiwan. We are able to extract direct usage and motion data from a large-scale in-the-wild use of a mobile EHR by 179 resident doctors over 4 weeks. Using machine-learning techniques, we can predict the doctors' mobile behaviors while using Dr. Pad, which were previously unobserved and mainly self-reported. Our data revealed trends in the doctors' use of the mobile EHR, which supported claims by doctors on their usage habits, our observations of their work routines, and even showed that the doctors used Dr. Pad more frequently than we had expected.",BCB,2013,10.1145/2506583.2512366,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
93421cef562eda8f4546bdba692e45a3e95692e8,https://www.semanticscholar.org/paper/93421cef562eda8f4546bdba692e45a3e95692e8,Hybrid Fault Prognostics for Nuclear Applications: Addressing Rotating Plant Model Uncertainty,"Nuclear plant operators are required to understand the uncertainties associated with the deployment of prognostics toolsin order to justify their inclusion in operational decision making processes and satisfy regulatory requirements. Operationaluncertainty can cause underlying prognostics models to underperform on assets that are subject to evolving impactsof age, manufacturing tolerances, operating conditions, and operating environment effects, of which may be capturedthrough a condition monitoring (CM) system that itself may be degraded. Sources of uncertainty in the data acquisitionpipeline can impact the health of CM data used to estimate the remaining useful life (RUL) of assets. These uncertaintiescan disguise or misrepresent developing faults, where (for example) the fault identification is not achieved until it hasprogressed to an unmanageable state. This leaves little flexibility for the operator’s maintenance decisions and generallyundermines model confidence. 
One method to quantify and account for operational uncertainty is calibrated hybrid models, employing physics, knowledgeor data driven methods to improve model accuracy and robustness. Hybrid models allow known physical relations tooffset full reliance on potentially untrustworthy data, whilst reducing the need for an abundance of representative historicaldata to reliably identify the monitored asset’s underlying behavioural trends. Calibration of the model then ensuresthe model is updated and representative of the real monitored asset by accounting for differences between the physics orknowledge model and CM data. 
In this paper, an open-source bearing knowledge informed machine learning (ML) model and CM datasets are utilizedin an illustrative bearing prognostic application. The uncertainty incurred by the decisions made at key stages in thedevelopment of the model’s data acquisition and processing pipeline are assessed and demonstrated by the resultant impacton RUL prediction performance. It was shown that design decisions could result in multiple valid pipeline designswhich generated different predicted RUL trajectories, increasing the uncertainty in the model output.",PHM Society European Conference,2022,10.36001/phme.2022.v7i1.3321,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6abb1ba25738b3ce50c50496a7c862758f7814d0,https://www.semanticscholar.org/paper/6abb1ba25738b3ce50c50496a7c862758f7814d0,A forecasting tool for predicting asthma related emergency department visits and hospitalizations using heterogeneous data sources,"New Zealand (NZ) is one of the countries with the highest prevalence and mortality rate due to asthma. Organisation for Economic Co-operation and Development (OECD) statistics [3] indicate NZ has one of the highest hospital admission rates for asthma of OECD countries. According to recent records [1], on average 77 New Zealanders each year lost their battle to asthma. Furthermore, the cost burden of asthma to the NZ economy has not improved over the years [2]. Not much work has been accomplished in the direction of population health forecasting for asthma in NZ. The aim of this study is to develop a prediction model for anticipating asthma-related hospitalisations in Auckland, NZ while exploiting diverse heterogeneous data sources. These sources accounts for triggers that exacerbate asthma conditions like meteorological and air quality factors plus the social media resource accessed through Google search trends. The research work is divided into two parts; in the first phase I analysed the relationship between trigger parameters and asthma using the Pearson Correlation Coefficient. Subsequently, in part two a comparative examination has been conducted based upon the prediction models developed using different machine learning techniques on the continuous data of 1097 days. The experimental evaluation shows that the best forecasting tool could predict asthma-related hospitalisation with an accuracy of 78.87% while the precision and recall for the model were 79.80% and 78.87%. The outcome achieved from implementing such a model would be beneficial for public health surveillance, thereby helping in more efficient and timely healthcare resource deployment. ",Rangahau Aranga: AUT Graduate Review,2022,10.24135/rangahau-aranga.v1i1.31,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8d5c421161aa107d1a91d1d35381f2cbd2b88d24,https://www.semanticscholar.org/paper/8d5c421161aa107d1a91d1d35381f2cbd2b88d24,A comprehensive survey on secure software‐defined network for the Internet of Things,"The Internet of Things (IoT) is the network of smart devices, sensors, and machines that continuously monitored the surrounding environment and execute meaningful decisions on the data or information it receives. The Internet‐enabled devices could facilitate computer‐mediated strategies for various tasks, for example, smart health care, managing the cities or smart factories, smart manufacturing, automating the home and business, etc. IoT commonly uses Internet technology for establishing communication among devices, thus inherits all the security threats that are currently affecting Internet users along with other security threats that are specific to IoTs due to resources constrained nature of the smart devices and sensors. The greater footprint, the distributed nature of the network and the existence of a huge number of IoT devices has also attracted criminals, fraudsters, and attackers to utilize this medium for spreading malicious content or making devices unavailable for legitimate use. It is imperative to ensure that the Confidentiality, Integrity, Security, and Privacy of information and users should remain intact while using these devices and thus they require an effective security system. Software‐defined Networks (SDN) and Network Function are the way to control and configure devices from a centralized location and have been proven to offer scalability and versatility to their deployed ecosystems. In this paper, we systematically review the adoption of SDN and Network Function Virtualization (NFV) for securing the IoT network from emerging threats. To this extent, we provide a comprehensive survey on security solutions based on SDN, Blockchain, NFV, and SDN/NFV proposed for the security of the IoT network. We have also identified open challenges in this domain which includes lack of standardization, low cost, and effective machine learning systems for identifying malicious traffic and handling great attack surface and different attack vectors. The deployed technologies exhibit positive strides in their usage for the provision of security in IoT environments offering security enhancements, scalability, and versatility.",Trans. Emerg. Telecommun. Technol.,2021,10.1002/ett.4391,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e1036088d1820f7aa5a029cb92e4a642849473d8,https://www.semanticscholar.org/paper/e1036088d1820f7aa5a029cb92e4a642849473d8,Internet of things–Enabled technologies as an intervention for childhood obesity: A systematic review,"Childhood obesity is one of the most serious public health challenges of the 21st century, with consequences lasting into adulthood. Internet of Things (IoT)-enabled devices have been studied and deployed for monitoring and tracking diet and physical activity of children and adolescents as well as a means of providing remote, ongoing support to children and their families. This review aimed to identify and understand current advances in the feasibility, system designs, and effectiveness of IoT-enabled devices to support weight management in children. We searched Medline, PubMed, Web of Science, Scopus, ProQuest Central and the IEEE Xplore Digital Library for studies published after 2010 using a combination of keywords and subject headings related to health activity tracking, weight management, youth and Internet of Things. The screening process and risk of bias assessment were conducted in accordance with a previously published protocol. Quantitative analysis was conducted for IoT-architecture related findings and qualitative analysis was conducted for effectiveness-related measures. Twenty-three full studies are included in this systematic review. The most used devices were smartphone/mobile apps (78.3%) and physical activity data (65.2%) from accelerometers (56.5%) were the most commonly tracked data. Only one study embarked on machine learning and deep learning methods in the service layer. Adherence to IoT-based approaches was low but game-based IoT solutions have shown better effectiveness and could play a pivotal role in childhood obesity interventions. Researcher-reported effectiveness measures vary greatly amongst studies, highlighting the importance for improved development and use of standardised digital health evaluation frameworks.",PLOS Digital Health,2022,10.1371/journal.pdig.0000024,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
edc4085e7e8e2e206e9ca7fb46e77a523c081828,https://www.semanticscholar.org/paper/edc4085e7e8e2e206e9ca7fb46e77a523c081828,Fuzzy association rule mining for recognising daily activities using Kinect sensors and a single power meter,,J. Ambient Intell. Humaniz. Comput.,2018,10.1007/s12652-017-0571-8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
290021c63e2f9ec2399221a57903e1d9b4c51ae0,https://www.semanticscholar.org/paper/290021c63e2f9ec2399221a57903e1d9b4c51ae0,Non-Dominated Sorting Genetic Algorithm-II-Induced Neural-Supported Prediction of Water Quality with Stability Analysis,"Water is one of the most important necessities for human survival. In municipal corporation areas, water quality affects a large part of the population. Good quality water supply is an imperative parameter that influences individuals’ health. Automated accurate water quality determination becomes an urgent necessity. Detecting the drinking water quality can prevent such scenarios prior to the critical stage. Recent research works have achieved reasonable success in predicting the water quality by deploying several machine learning-based techniques and utilising different aspects to analyse water quality. The accuracy levels of already proposed models are to be improved, keeping in mind the sensitivity of the problem domain. In the current work, Non-dominated Sorting Genetic Algorithm-II (NN-NSGA-II) was employed to train the artificial neural network (ANN) to improve its performance over its traditional counterparts. The proposed model gradually minimises two different objective functions, namely the root mean square error (RMSE) and Maximum Error (ME) in order to find the optimal weight vector for the ANN. The proposed model was compared with another two well-established models namely ANN trained with Genetic Algorithm (NN-GA) and ANN trained with Particle Swarm Optimisation (NN-PSO) in terms of accuracy, precision, recall, [Formula: see text]-Measure, Matthews correlation coefficient (MCC) and Fowlkes–Mallows (FM) index. Furthermore, a data perturbation-based stability analysis is proposed to test the stability of the proposed method. The simulation results established superior accuracy of NN-NSGA-II over the other models.",J. Inf. Knowl. Manag.,2018,10.1142/S0219649218500168,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,https://www.semanticscholar.org/paper/8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,Multi Uav Cooperative Surveillance With Spatio Temporal,"Deep Learning for Unmanned SystemsMultiple Heterogeneous Unmanned Aerial VehiclesAdvanced Mobile RoboticsSafe Robot Navigation Among Moving and Steady ObstaclesComputer Safety, Reliability, and SecurityAdvances in Swarm IntelligenceHolonic and Multi-Agent Systems for ManufacturingAdvances in Artificial Intelligence and Applied Cognitive ComputingUnmanned Aircraft SystemsIntelligent Computing Theories and ApplicationAutonomous Airborne Wireless NetworksAd Hoc NetworksEnabling Blockchain Technology for Secure Networking and CommunicationsUAV Sensors for Environmental MonitoringUnmanned Aerial Vehicles: Breakthroughs in Research and PracticeComputational Collective IntelligenceTime-Critical Cooperative Control of Autonomous Air VehiclesAdvances in Cooperative Control and OptimizationCooperative Robots and Sensor Networks 2015Artificial Intelligence and SecurityPRICAI 2016: Trends in Artificial IntelligenceClosing the Gap Between Research and Field Applications for Multi-UAV Cooperative MissionsMulti-rotor Platform Based UAV SystemsProceedings of the Future Technologies Conference (FTC) 2020, Volume 1Unmanned Aerial SystemsAdvanced Distributed Consensus for Multiagent SystemsCooperative Control of MultiAgent SystemsMulti-UAV Planning and Task AllocationMobile Internet SecurityCooperative Control of Multiple Unmanned Aerial Vehicles with Application to Forest Fire Detection and FightingMulti UAV Systems with Motion and Communication ConstraintsIntelligent Autonomy of UAVsIntelligent and Fuzzy Techniques in Big Data Analytics and Decision MakingIntelligent Autonomy of UAVsUAV Cooperative Decision and ControlCooperative Localization and NavigationAdvances in Guidance, Navigation and ControlMachine Learning and Intelligent CommunicationsUnmanned Aerial VehiclesThe Cognitive Approach in Cloud Computing and Internet of Things Technologies for Surveillance Tracking Systems Ad hoc networks, which include a variety of autonomous networks for specific purposes, promise a broad range of civilian, commercial, and military applications. These networks were originally envisioned as collections of autonomous mobile or stationary nodes that dynamically auto-configure themselves into a wireless network without relying on any existing network infrastructure or centralized administration. With the significant advances in the last decade, the concept of ad hoc networks now covers an even broader scope, referring to the many types of autonomous wireless networks designed and deployed for a specific task or function, such as wireless sensor networks, vehicular networks, home networks, and so on. In contrast to the traditional wireless networking paradigm, such networks are all characterized by sporadic connections, highly error-prone communications, distributed autonomous operation, and fragile multi-hop relay paths. The new wireless networking paradigm necessitates reexamination of many established concepts and protocols, and calls for developing a new understanding of fundamental problems such as interference, mobility, connectivity, capacity, and security, among others. While it is essential to advance theoretical research on fundamental and practical research on efficient policies, algorithms and protocols, it is also critical to develop useful applications, experimental prototypes, and real-world deployments to achieve an immediate impact on society for the success of this wireless networking paradigm.A comprehensive review of the state of the art in the control of multi-agent systems theory and applications The superiority of multi-agent systems over single agents for the control of unmanned air, water and ground vehicles has been clearly demonstrated in a wide range of application areas. Their large-scale spatial distribution, robustness, high scalability and low cost enable multi-agent systems to achieve tasks that could not successfully be performed by even the most sophisticated single agent systems. Cooperative Control of Multi-Agent Systems: Theory and Applications provides a wide-ranging review of the latest developments in the cooperative control of multi-agent systems theory and applications. The applications described are mainly in the areas of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Throughout, the authors link basic theory to multi-agent cooperative control practice — illustrated within the context of highly-realistic scenarios of high-level missions — without losing site of the mathematical background needed to provide performance guarantees under general working conditions. Many of the problems and solutions considered involve combinations of both types of vehicles. Topics explored include target assignment, target tracking, consensus, stochastic game theory-based framework, event-triggered control, topology design and identification, coordination under uncertainty and coverage control. Establishes a bridge between fundamental cooperative control theory and specific problems of interest in a wide range of applications areas Includes example applications from the fields of space exploration, radiation shielding, site clearance, tracking/classification, surveillance, search-and-rescue and more Features detailed presentations of specific algorithms and application frameworks with relevant commercial and military applications Provides a comprehensive look at the latest developments in this rapidly evolving field, while offering informed speculation on future directions for collective control systems The use of multi-agent system technologies in both everyday commercial use and national defense is certain to increase tremendously in the years ahead, making this book a valuable resource for researchers, engineers, and applied mathematicians working in systems and controls, as well as advanced undergraduates and graduate students interested in those areas.Time-Critical Cooperative Control of Autonomous Air Vehicles presents, in an easy-to-read style, the latest research conducted in the industry, while also introducing a set of novel ideas that illuminate a new approach to problem-solving. The book is virtually self-contained, giving the reader a complete, integrated presentation of the different concepts, mathematical tools, and control solutions needed to tackle and solve a number of problems concerning time-critical cooperative control of UAVs. By including case studies of fixed-wing and multirotor UAVs, the book effectively broadens the scope of application of the methodologies developed. This theoretical presentation is complemented with the results of flight tests with real UAVs, and is an ideal reference for researchers and practitioners from academia, research labs, commercial companies, government workers, and those in the international aerospace industry. Addresses important topics related to time-critical cooperative control of UAVs Describes solutions to the problems rooted in solid dynamical systems theory Applies the solutions developed to fixed-wing and multirotor UAVs Includes the results of field tests with both classes of UAVsThis book provides the state-of-the-art intelligent methods and techniques for solving realworld problems along with a vision of the future research. The fifth 2020 Future Technologies Conference was organized virtually and received a total of 590 submissions from academic pioneering researchers, scientists, industrial engineers, and students from all over the world. The submitted papers covered a wide range of important topics including but not limited to computing, electronics, artificial intelligence, robotics, security and communications and their applications to the real world. After a double-blind peer review process, 210 submissions (including 6 poster papers) have been selected to be included in these proceedings. One of the meaningful and valuable dimensions of this conference is the way it brings together a large group of technology geniuses in one venue to not only present breakthrough research in future technologies, but also to promote discussions and debate of relevant issues, challenges, opportunities and research findings. The authors hope that readers find the book interesting, exciting and inspiringAdvanced Distributed Consensus for Multiagent Systems contributes to the further development of advanced distributed consensus methods for different classes of multiagent methods. The book expands the field of coordinated multiagent dynamic systems, including discussions on swarms, multi-vehicle and swarm robotics. In addition, it addresses advanced distributed methods for the important topic of multiagent systems, with a goal of providing a high-level treatment of consensus to different versions while preserving systematic analysis of the material and providing an accounting to math development in a unified way. This book is suitable for graduate courses in electrical, mechanical and computer science departments. Consensus control in multiagent systems is becoming increasingly popular among researchers due to its applicability in analyzing and designing coordination behaviors among agents in multiagent frameworks. Multiagent systems have been a fascinating subject amongst researchers as their practical applications span multiple fields ranging from robotics, control theory, systems biology, evolutionary biology, power systems, social and political systems to mention a few. Gathers together the theoretical preliminaries and fundamental issues related to multiagent systems and controls Provides coherent results on adopting a multiagent framework for critically examining problems in smart microgrid systems Presents advanced analysis of multiagent systems under cyberphysical attacks and develops resilient control strategies to guarantee safe operationComplete with online files and updates, this cutting-edge text looks at the next generation of unmanned flying machines. Aerial robots can be considered as an evolution of the Unmanned Aerial Vehicl",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c404631799f6601e6ac021602383ef0b5da686d8,https://www.semanticscholar.org/paper/c404631799f6601e6ac021602383ef0b5da686d8,"Society for Technology in Anesthesia STA Virtual Annual Meeting Syllabus January 15 , 2021 7 : 00 am-4 : 30","Full Abstract Title Presenting Author Institution C L IN IC A L A P P L IC A T IO N S 1 A Novel Device That May Lower the Incidence of Injectable Medication Errors Tariq Chaudhry, MD Tufts Medical Center 2 Design and Implementation of a Voice-Based Controller for the Solar 8000 Monitor Christopher Connor, MD, PhD Brigham and Women's Hospital 3 Pre-Deployment Assessment of NETCCN COVID-19 Tele Critical Care Technologies in a Laboratory Environment David Arney, PhD Massachusetts General Hospital 4 Intraoperative Arterial Pressure Waveforms Shows Temporal Structure Complexity Correlated with Acuity of Liver Transplant by Pulse Wave Manifold Learning Analysis Shen-Chih Wang, MD, PhD Taipei Veterans General Hospital 5 Resurrecting a 'Shocking' Dinosaur: Updating the Original Mechanomyography Gold Standard for 2020 Kelly Michaelsen, MD, PhD University of Washington 6* Analgesic Monitoring Indices in Response to Noxious Stimuli of Laparoscopic Cystectomy Surgery and Their Time Optimization Yu-Ting Lin, MD, PhD Taipei Veterans General Hospital 7 Approximating the Interand Intra-Patient PK/PD of PropofolInduced Burst Suppression Jason Huang, BS University of Utah 8 Comparison of Near-Infrared Spectroscopy-Derived Cerebral and Somatic Oxygenation Indices During Pediatric Scoliosis Surgery Michael Wood, PhD University of British Columbia A D V A N C E M E N T S IN T E C H N O L O G Y 9** Measuring the Performance of Multi-Pump Infusion Systems with Spectrophotometry David Arney, PhD Massachusetts General Hospital/Harvard University 10 Preliminary Experience With a New High-Speed Flow Sensor for Investigating and Improving Syringe Pump Flow Performance Robert Butterfield, BSE RDB Consulting 11 Detecting Abnormalities on Displays of Patient Information Sydney Fleishman Vanderbilt University 12 A Framework for Evaluating Healthcare Machine Learning Models: Application and Analysis Using Hospital Readmission Eilon Gabel, MD University of California, Los Angeles 13 Improved Sedation Capnography And Enhanced Patient Safety For Sedation Anesthesia Michael Jach, MD 14*** Reduction of Preoperative Anxiety Using Virtual Reality vs Midazolam: A Randomized Controlled Trial Anthony Koo, MD Sanjana Khanna, BS Phoenix Children's Hospital 15 Leveraging the Human Digital Twin for Perioperative Monitoring of Pediatric PatientsAn Early Case Study Hannah Yates, BS Johns Hopkins B IG D A T A & D A T A B A SE R E SE A R C H 16 Modeling the Cost Savings of Continuous Pulse Oximetry and Capnography Monitoring of United States Hospital Ward Patients Receiving Opioids Ashish Khanna, MD, FCCP, FCCM Wake Forest School of Medicine 17 Defining Gender and Race/Ethnicity-Specific Laboratory Reference Ranges and its Impact on Predicting Post-Operative Acute Kidney Injury and Mortality Outcomes Andrew Lee, MS University of California, Los Angeles 18 Machine Learning Approaches to Predict Intraoperative Transfusion Matthew Zapf, MD Vanderbilt University 19 Simulation Study to Evaluate Fidelity of Continuous Pulse Oximetry Recording in the Electronic Health Record Diane Dao, MD Children's Hospital of Philadelphia/University of Pennsylvania Abstract Table of",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
75fccf9eda7cf9c961efd3e9d42ba73ed37ab2e9,https://www.semanticscholar.org/paper/75fccf9eda7cf9c961efd3e9d42ba73ed37ab2e9,Tutorial: Edge Computing for Mobile Internet of Things,"Internet of things (IoT) has emerged as the enabling technology for smart applications in different domains, such as transportation, health-care, industry, smart homes and buildings, and education (e.g., [1-5]). IoT applications rely on the deployment of resourceconstrained devices that collect data from the environment it is immersed and control events of interest through actuators. One of the daunting challenges in many IoT applications is the need for the real-time processing of a large amount of produced data. Such processing is often impractical to be performed at the IoT devices, due to their resource-constrained nature and the incurred energy cost. In this regard, IoT data is often offloaded to be processed on distant powerful cloud servers, which return to IoT devices as the result of the heavy computations. This approach is well-suited for computation-intensive tasks in IoT applications. However, the process of task offloading to cloud servers incurs additional delays for the IoT application, in addition to the network overhead. Therefore, edge computing has been proposed to provide computation, communication, and storage resources closer to IoT devices. The general idea is to place resources in the proximity of IoT devices that will demand them. Thus, the latency involved in the IoT application is reduced since computation-intensive tasks are processed on edge devices rather than on distant cloud servers. One of the critical challenges in edge-aided IoT applications is that edge devices have limited resource capabilities when compared to cloud servers. In this regard, edge devices' resources must be managed and allocated in an efficient way, aimed at providing resources to IoT applications with guaranteed quality of service (QoS). This tutorial will motivate and explore the challenges, design principles, and goals of edge computing for IoT applications. It presents the building blocks for the design of optimization models for IoT task offloading to edge nodes. By doing so, it discusses the communication challenges between IoT and edge devices and highlights the different mathematical formulations commonly used in the literature to model IoT to edge communication. Furthermore, this tutorial discusses optimization-based and machine learning (ML)-based solutions for tackling the task offloading decision problem. Besides, this tutorial presents recent advancements in resource management solutions aimed at efficient resource allocation at edge devices. Finally, this tutorial shall conclude with a discussion of research opportunities and challenges in the edge-assisted Internet of things.",DIVANet,2021,10.1145/3479243.3494705,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
05956c3c3b62c07e6726f7ef8a4b340ddcbe3f97,https://www.semanticscholar.org/paper/05956c3c3b62c07e6726f7ef8a4b340ddcbe3f97,Senior Design Instructors for 2021-2022 Contact Information,"In this project, we are creating a health equity dashboard for Connecticut. Our goal is the bring different data sources together and display to the users to show what types of programs or services should be provided in the different places in Connecticut. In order to accomplish this, we will be using Connecticut’s Census data along with datasets from Centers for Medicare & Medicaid Services. We hope our webpage will be informative of the services we should provide in the various towns and counties of Connecticut. The CT National Guard Cyber Range 2021 Project focuses on working with the ongoing project that was developed last year. This year, the goal was to move the cyber range to the cloud for remote access. Currently, the cyber range simulates two blue team scenarios: a ransomware attack and a vulnerable Active Directory access page. As cyber attacks–more specifically ransomware attacks–are rising in use, this cyber security project holds real world, practical applications. With this year’s team, each scenario is now remotely deployable, allowing CTNG trainees to practice National Guard battle plans from wherever. The project uses Amazon Web Services for cloud compute virtual machines, with Terraform for automating virtual machine deployment. Furthermore, practice scenarios are now easily addable due to the abstraction that was made possible through virtualization. The current scenarios are built with a variety of technologies, from Powershell scripts and Active Directory on Windows to Apache on Linux, but a wider variety is possible with ability to build and add any scenarios desired. Making the ongoing project more easily modifiable and adaptable allows the CTNG and any further teams to build quicker. This is essential as cyber security is now more important than ever, and any solutions in the field must be able to evolve quickly. and deprecated. Additional steps towards were taken by updating the protocol that certain tasks utilize from communicating with a SOAP to utilizing REST commands. by other the so-called Condition-Based Maintenance (CBM) where the maintenance is only conducted when it is really needed other than scheduled so that the maintenance cost is reduced and engine time-on-wing is extended; Doing the maintenance at the right place allows the needed facility and part inventory are in place to support the maintenance (for commercial airlines, this is usually the hubs). As an engine OEM, Pratt & Whitney is committed to provide dependable jet engine health management. The key to support doing the right maintenance at the right time and the right place is to identify a failure accurately and reliably at an early stage so that there will be ample time for the aircraft to get to the right place for maintenance. For most engine components, a failure is a state of the component that a fault is progressed to. By definition, a fault is a physical imperfection or impairment that is responsible for failure while a failure is a state of inability to perform a normal function. As shown in the P-F curve in Figure 1, the earlier a fault is detected, the less cost to repair would incur. It is well-known that the earlier a fault is detected, the more likely the detection is a false alarm. Excessive false alarms would defeat the propose of doing the right maintenance. Also, some of the fault may lead to safety critical failures, in which case, the recall rate of the detection has to be 100%. Overall, the goal for this project is to implement a machine learning algorithm which can accurately identify and diagnose engine faults. Battery powered IoT devices are a common tool in today’s jobsite. However, the downtime required to charge or replace dead batteries is costly at a large scale, so it is in a company’s best interest to optimize the battery life of their IoT devices. It is not uncommon to produce a noticeable decrease in the battery life of a device after even the slightest of updates to its firmware. Therefore, it is valuable to have the ability to run constant checks to ensure a device’s expected battery life stays within a tight range. Our project will provide companies and technology developers an easy means of testing firmware changes before finalizing device updates in order to catch these power-draining bugs. We have partnered with Triax Technologies to develop an open-source continuous integration (CI) testing platform for analyzing the change in power consumption of a device following any update. Our goal is to simplify the user experience by creating a modular and highly-configurable framework that allows developers to use the CI platform and power profiler of their choosing and have complete control of all aspects of the testing. The output to the user includes graphical interpretations of the analysis and readable results that can be sent via email or added as a comment on a pull request. The project is focused on creating and implementing two features on The Whelen Engineering Company’s web-based application: the Whelen Cloud Platform (WCP). WCP provides a real-time vehicle tracking service to emergency services with an interactive map that displays the locations and status of all vehicles. Our job was to implement two features for the the Live Map designed to be useful for coordinating fire fighting services during an emergency. While these features were originally specific to fire trucks, we designed them in such a way that they could be useful for any organization that Whelen provides services for, whether it be law enforcement, emergency medical services, or even the Department of Transportation. that A cyber range is a virtual environment in which users can simulate cyber attacks, test cybersecurity technology, host competitions, etc. In order to address the current limitations of cyber ranges, our team proposes that a domain specific language (DSL) should be used for cyber range development. A DSL within a cyber range would allow for customization of cyber range scenarios and standardization of scenario development. Our team will create a prototype of a DSL that could be implemented within a cyber range using Xtext, and write an NSF proposal supporting the use of DSLs in a cyber range. Our project also addresses the lack of accessibility with current cyber ranges. We suggest a hybrid licensing model, as well as more cost effective platforms to run our cyber range on (Raspberry Pi, existing cyber ranges, etc.). The team has created a prototype Google Chrome extension to adapt website content to be more accessible. The tool adjusts color schemes, font size, font family, and line and letter spacing to benefit users diagnosed with dyslexia and minor visual impairments. The resulting software will allow users to have equal opportunity to access and digest information online. The goal of our project is primarily about implementing three post-quantum signature verification algorithms to be run on the Xilinx ZCU102 development board and running performance tests on said algorithms. We seek to use the performance metrics in order to determine which algorithm has the best trade off between speed and security, especially in the context where the ARM processor must be reset and the boot time minimized. Our project develops software for a specific vibro-tactile biofeedback system. This system is designed to help firefighters navigate smoke filled buildings. Our vibro-tactile biofeedback system uses patterns of vibration felt on the body to provide new ways of perceiving direction. UWB radio based positioning system is used to determine the ranging values and location of a mobile unit. These systems are integrated together to create a prototype device that can be used to blind-navigate around an indoor environment. For this project, Sonalysts would like to have the students design and develop an AR application that interacts with static exhibits. Our project is an augmented reality mobile application that is able to render animated 3D holograms in real-time and geospatially anchor them on physical objects and/or tags in the real world. It is capable of image recognition, object detection, geolocation mapping, marker recognition, and it can support an augmented reality view that contains spatial awareness and AR sessions. In addition to this, our application is able to render animated 3D object models, retrieve and fetch them from a cloud database in real-time, contain a secure user authentication and authorization service, and should have a friendly and interactive user interface. When climate disasters occur and damage properties, insurance companies are expected to pay for losses covered by a client’s policy. The issue, however, is that many of these policies are determined by historical data. This historical data determines how much an insurance company is expected to pay if a claim is made and under what circumstances a claim is valid. This past data is rapidly becoming more and more dissimilar to what is happening today due to changes in the frequency and severity of climate disasters. It is vital that better solutions are developed in order to reflect the current circumstances. It is for these reasons that the project Climate Risk Strategy Analyzer (CRISTAL) was created. The purpose of CRISTAL is to act as a tool for broker agencies to evaluate their clients current insurance policies and determine what further coverage may be needed when the current climate situation is taken into consideration. By combining a climate risk analysis and a coverage gap analysis, CRISTAL will provide users with predictive and prescriptive analyses. Such analyses will include possible climate events that can affect a client’s business, automated recommendations related to their policies, and advisories about potential financial changes. In order to achieve this goal, our aim Students will provide a virtual reality experience where a remote user in a VR headset can peripherals can control a telepresence robot to",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0a382216eaa782e1832447c73594d98a0f1782d1,https://www.semanticscholar.org/paper/0a382216eaa782e1832447c73594d98a0f1782d1,The journal of knowledge engineering special issue on WorldCist'19—Seventh World Conference on Information Systems and Technologies,"The constant growth of technology leads to the development of expert systems that serve to support critical decision-making and have applications in many areas, such as healthcare, business, chemistry, financial decision-making, and engineering. These systems are computer programs derived from a computer science research branch called Artificial Intelligence (AI) and use human knowledge intensively in problem-solving. These programs combine expert knowledge and use the knowledge necessary to solve problems (Kidd, 2012). In this special issue, we present a range of papers covering some of the subareas of expert systems such as intelligent and decision support systems, ethics, computers, and security, health informatics, simulations, and big-data analytics. This special issue comprises six research papers. All manuscripts are extended versions of selected papers from WorldCIST'19 - 7th World Conference on Information Systems and Technologies, held in at La Toja Island, Galicia, Spain, April 2019. The WorldCIST conference have become a global forum for researchers and practitioners to present and discuss the most recent innovations, trends, results, experiences, and con-cerns in the several perspectives of Information Systems and Technologies, as well as computer science in general. The six selected papers in this special section include a Virtual Programming Lab (VPL), a model's predictions, a novel information systems architecture for the agri-food sector, various approaches for detection of malware, an intelligent system to assess, in real-time, potential HRV indices, that can predict HRQoL in lymphoma patients throughout chemotherapy treatment, as well as an expert system comprising a self-aware framework for resource-efficient and accurate data transmission within a low-power lossy sensor network (LLN) deployed for indoor monitoring. Cardoso et al. (2020) present the VPL, a Moodle plugin that allows students to submit their code and get prompt feedback without the teacher's intervention. To test this concept, an experiment was performed with several classes of beginner programming students, in two editions of Algorithms and Programming course unit of the degree in Informatics Engineering lectured at the Informatics Engineering Department at the School of Engineering, Polytechnic Institute of Porto. on sig-natures and are error-prone. Traditional machine learning techniques are based on static, dynamic, and hybrid analysis; however, for large scale Android malware analysis, these approaches are not feasible. Deep neural architectures can analyze large scale static details of the applications, but static analysis techniques can ignore many malicious behaviours of applications. The study contributes to the documentation of various constructing a 6LoWPAN network in the Contiki Cooja simulator. MCDM is applied to generate an adaptive objective function for the IPv6 routing protocol for the LLN (RPL) and to aid in ranking the nodes to select the best available neighbouring node, while the data accuracy is ensured by the cluster head through data corre-lation among its associated members. The network performance is assessed by analyzing the packet delivery rate, throughput and energy con-sumption against varying sensors and by comparing our proposed MCDM-RPL with a standard RPL and a fuzzy-based RPL, where the results show that our framework is found to be better with gains of 13%, 25% and 13%, respectively.",Expert Syst. J. Knowl. Eng.,2021,10.1111/exsy.12711,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cff6f87ddb7e31465fdf763f882093e0885519a6,https://www.semanticscholar.org/paper/cff6f87ddb7e31465fdf763f882093e0885519a6,A REVIEW ON USE OF AUTOMATION IN SYSTEMATIC REVIEWS FOR SCIENTIFIC EVIDENCE GENERATION Short title: An Overview of Automation in Systematic Reviews,"Background: Systematic reviews are primarily literature reviews performed using systematic methods. A well-conducted review enables clinicians and policy-makers to stay updated in their respective fields of interest, and make informed decisions. Once fully automated, it will enable researchers to conduct systematic reviews efficiently, produce high-quality evidence, and contribute more to the field of evidence-based medicine. Mathematical models based on results from swiftly conducted systematic reviews may predict the future incidence or outbreak scenarios for diseases, which are public health problems. Main text: This paper presents an exhaustive literature review on the common methods that can be deployed for automating sub-processes with in a systematic review, their scope, current use, and limitations. A comprehensive search in PubMed and Google Scholar to identify articles or reviews describing use of existing automation tools within the systematic review process was performed. The main methods discussed include machine learning or artificial intelligence, text-mining, and text classification. Current gaps as well as opportunities to improve the quality of a systematic review and the overall evidence generation process are also reviewed. Conclusions: Several technologies like Automatic Term Recognition (ATR), text-mining, text identification, as well as machine learning have already been incorporated to the general process of systematic reviews and so are common tools like Abstrackr, DistillerSR, and RobotAnalyst. The use of automatic classifiers, supervised classification algorithms, and natural language processing has been seen for search of pertinent literature. Harmonization of the existing tools is imperative for further development and quality evidence generation.",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6926800b286ceef6a94ac3d6f941b41760a88193,https://www.semanticscholar.org/paper/6926800b286ceef6a94ac3d6f941b41760a88193,Persuasive Factors and Weakness for Security Vulnerabilities in BIG IOT Data in Healthcare Solution,"In the present scenario, public health is a global challenge. In view of COVID-19 pandemic, interventions of emerging technologies hasbeen highly increased and post-pandemica big technological shift is expected for providing information and communication Technology-enabled solutions to healthcare as well a meeting other social challenges. Internet of Things or IoT and Big data are the technologies prominently being used in healthcare applications. In smart city visualization to provide ubiquitous computing environment, urge of smart, small but powerful sensor devices or IoT technology-enabled healthcare solutions deployments done over open networked infrastructure and underlying architecture. Such highly dynamic and heterogeneous environment with rapid digital transformation enforcing trusted security resource-restrictions and performance implication. In this paper, firstly, we explore the existing security, privacy and authentication weakness in reference to IoT or IoMT and big data enabled healthcare applications. Secondly, scaling the low to high security risks done based on the major weaknesses. In this work primarily we focus on most challenging attacks like Denial of Services (DoS), Man in the middle and dynamic intrusions. In winding-up machine learning based intelligent adaptive approach proposed for underlying deficiencies and insufficiencies in IoT enabled Healthcare application security. The key driving forces for the imprecision of trust and security with emerging Big IoT also presented as future scope.",Journal of Physics: Conference Series,2021,10.1088/1742-6596/2007/1/012046,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
15c80b95dfae8d64a796c5694f37eb95576f7ca6,https://www.semanticscholar.org/paper/15c80b95dfae8d64a796c5694f37eb95576f7ca6,"A Highly Scalable, Modular Test Bench Architecture for Large-Scale DC Power Cycling of SiC MOSFETs: Towards Data Enabled Reliability","Silicon carbide (SiC) power MOSFETs have superior conduction, switching and thermal properties compared to silicon (Si) MOSFETs and IGBTs [1]. However, unlike Si devices, whose reliability is well understood from decades of research and field data, SiC device technology is relatively nascent and has only recently started witnessing wide scale deployment. This reliability challenge can possibly be addressed through two complementary solutions as shown in Figure 1: 1) developing a large accelerated aging dataset of SiC devices under various conditions to understand their long term reliability and guide future device development, 2) using on-board, in-system prognostics and device health monitoring techniques to predict imminent device failures well ahead of time, thus ensuring reliable system operation [2]. In both cases, the large-scale reliability testing of SiC MOSFETs is needed. Generally, remaining useful lifetime (RUL) estimation methods for power devices use an empirical model obtained from fitting accelerated aging data [3]-[7], [9], [10]. Consequently, the accuracy of RUL models is directly related to the size and variety of available accelerated aging dataset. Moreover, large datasets are crucial in enabling machine learning (ML) and artificial intelligence (AI) based reliability models.",IEEE Power Electronics Magazine,2021,10.1109/MPEL.2020.3047668,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
42c9527670182855ec693b469e58925e84998e29,https://www.semanticscholar.org/paper/42c9527670182855ec693b469e58925e84998e29,"""How Robotics are Revolutionizing Rehabilitation""","Capitalizing on the new understanding of brain plasticity, we introduced a paradigm shift in clinical practice in 1989 when we initiated the development of the MIT-Manus robot for neuro-rehabilitation and deployed it into the clinic. Since then we collected evidence to support the potential of enhancing and augmenting recovery following a stroke, first during the sub-acute and then the chronic phase. Our efforts and that of others led to the endorsements starting in 2010 from the American Heart Association, the American Stroke Association, and the Veterans Administration for the use of rehabilitation robots for the Upper Extremity, but not yet for the Lower Extremity. AHA recommendations were the same in the 2016 revision. Furthermore, it was demonstrated in the VA system that upper extremity robotic therapy has an economic advantage over manual therapy. More recently we completed a pragmatic study RATULS under the auspices of the National Health Service of the United Kingdom and its NIHR Health Technology Assessment Programme, which enrolled 770 stroke patients. Thus, we have developed novel robotic treatment and evaluation tools and have managed to collect the experimental evidence that demonstrates the unequivocal therapeutic benefits stemming from robot-aided rehabilitation for the upper extremity as well as present shortcomings. This talk will present an overview of our past rehabilitation robotics efforts and more recent efforts addressing the identified shortcomings. ""Novel Biomarkers: Robotics and Machine Learning "" Hermano Igo Krebs, PhD Abstract: In stroke, we demonstrated that robotic devices promoted upper extremity motor recovery. Those studies raised new questions focused on patients who were mildly or completely resistant to therapy, i.e., patients who did not improve, and prompted the hypothesis In stroke, we demonstrated that robotic devices promoted upper extremity motor recovery. Those studies raised new questions focused on patients who were mildly or completely resistant to therapy, i.e., patients who did not improve, and prompted the hypothesis that we could predict who are the responders, quasi-responders, and non-responders to behavioral therapy. There have been other attempts to create biomarkers to predict outcomes employing clinical scales such as the Fugl-Meyer assessment, the neurologic sensory exam, functional impairment scales, neurophysiology and neuro-imaging analysis; but these attempts have had mixed results and these measures are seldom used in practice to optimize therapy. To understand the variability of recovery, we examined the data collected with the robotic group on a recently completed studies. We investigated the potential for building a more sensitive biomarker, composed of robotic measurements collected during evaluation and training, to analyze the performance of patients recovering from stroke and to predict who will respond to movement-based treatment and who will not. We hypothesize that kinematic and kinetic measurements can predict the response to behavioral therapy in stroke and also determine how to optimize care for a particular patient. Here we will discuss our attempts to employ both linear and non-linear approaches and ascertain the correlation levels between our robot-based biomarker and clinical scales. We will discuss robot biomarker effect-size and compare it to clinical scales to determine whether there are some noticeable efficiencies in using the robotassay instead of the clinical scales. We will also present our efforts in developing an expert algorithm that employs data collected during the baseline assessment and during two consecutive training sessions in order to predict patient outcomes as well as to determine patterns of improvement in stroke patients so as to build an alternative machine learning predictor of outcomes. ""Starting a Venture Company"" Hermano Igo Krebs, PhD Abstract: “Imagine being present at the birth of a new industry. . . trends are now starting to converge and I can envision a future in which robotics devices will become a nearly ubiquitous part of our day-to-day lives. Technologies such as distributed computing, voice and visual recognition, and wireless broadband connectively will open the door to a new generation of autonomous devices that enable computers to perform tasks in the physical world on our behalf. We may be on the verge of a new era, when the PC will get up off the desktop and allow us to see, hear, touch and manipulate objects in places where we are not physically present.” Bill Gates Disruptive technology is a term coined to characterize an innovation that disrupts an existing market or way of doing things and creates a new value network. The concept was first described at Harvard Business School by Clayton M. Christensen, who described the concept in 1996 as: ""Generally, disruptive innovations were technologically straightforward, consisting of off-theshelf components put together in a product architecture that was often simpler than prior approaches. They offered less of what customers in established markets wanted and so could rarely be initially employed there. They offered a different package of attributes valued only in emerging markets remote from, and unimportant to, the mainstream."" Eventually with improvement, borrowing from Malcolm Gladwell, the moment of critical mass, the threshold, the boiling point is reached and the old practices and existing value network is abandoned in favor of the new one. Here I will discuss my experience as an entrepreneur and whether rehabilitation robotics has achieved its “tipping point.” “Imagine being present at the birth of a new industry. . . trends are now starting to converge and I can envision a future in which robotics devices will become a nearly ubiquitous part of our day-to-day lives. Technologies such as distributed computing, voice and visual recognition, and wireless broadband connectively will open the door to a new generation of autonomous devices that enable computers to perform tasks in the physical world on our behalf. We may be on the verge of a new era, when the PC will get up off the desktop and allow us to see, hear, touch and manipulate objects in places where we are not physically present.” Bill Gates Disruptive technology is a term coined to characterize an innovation that disrupts an existing market or way of doing things and creates a new value network. The concept was first described at Harvard Business School by Clayton M. Christensen, who described the concept in 1996 as: ""Generally, disruptive innovations were technologically straightforward, consisting of off-theshelf components put together in a product architecture that was often simpler than prior approaches. They offered less of what customers in established markets wanted and so could rarely be initially employed there. They offered a different package of attributes valued only in emerging markets remote from, and unimportant to, the mainstream."" Eventually with improvement, borrowing from Malcolm Gladwell, the moment of critical mass, the threshold, the boiling point is reached and the old practices and existing value network is abandoned in favor of the new one. Here I will discuss my experience as an entrepreneur and whether rehabilitation robotics has achieved its “tipping point.”",,2021,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cfe050eb8eac90d75bb106f091c949ccea3273db,https://www.semanticscholar.org/paper/cfe050eb8eac90d75bb106f091c949ccea3273db,Challenges facing AI and Big data for Resource-poor Healthcare System,"During the last decade, major advancements in the health-care system have developed by offering numerous benefits to the patients throughout the world but resource-poor countries are not benefited through the best practices of health-care due to the lack of educated health-care providers, infrastructure, financial and technical issues, etc. Health-care systems in resource-poor countries face many challenges including increased healthcare cost, patient safety, overtreatment and failure to adopt best practices for health-care. In such countries, massive data generate from various resources including medical imaging, patient record, pharmaceutical reports, and medical devices. The exponential growth in medical data and advancement in health-care technologies focus data analysts to come up with innovative solutions for improving health-care practices in poor countries. Big data analytics provide tools to collect manage and analyze structured and unstructured medical data to find useful insights. Complexity and volume of medical data also show that, Artificial intelligence (AI) has the ability to approximate conclusions without direct human input, which can be applied in the health-care system of resource-poor countries and is now being utilized to further develop health services in high-income countries. Numerous investigations show that, AI performs better than humans in certain health-care undertakings such as diagnosis of cancer, tumor, heart diseases, radiology, etc. Popular AI techniques include machine learning methods such as neural network, support vector machine, and deep learning for structured data as well as natural language processing for unstructured data. There is a variety of hurdles around the use of big data and AI in health-care includes regulation, permission, transparency, and accountability. Also, the collection of data from an individual-a prerequisite for big data analytics is a technical and ethical issue. There are a lot of challenges for AI and big data in health-care but efforts need to be made before these techniques can be deployed in ethical and safe way. In this chapter, we discuss the challenges that AI and big data techniques face in resource-poor health care system and how it can be used to improve health outcomes in resource-poor countries.",2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC),2021,10.1109/ICESC51422.2021.9532955,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2d09486b87995ba315ff1d8b7f9c60a0b7dfef7b,https://www.semanticscholar.org/paper/2d09486b87995ba315ff1d8b7f9c60a0b7dfef7b,A Distillation Approach to Data Efficient Individual Treatment Effect Estimation,"The potential for using machine learning algorithms as a tool for suggesting optimal interventions has fueled significant interest in developing methods for estimating heterogeneous or individual treatment effects (ITEs) from observational data. While several methods for estimating ITEs have been recently suggested, these methods assume no constraints on the availability of data at the time of deployment or test time. This assumption is unrealistic in settings where data acquisition is a significant part of the analysis pipeline, meaning data about a test case has to be collected in order to predict the ITE. In this work, we present Data Efficient Individual Treatment Effect Estimation (DEITEE), a method which exploits the idea that adjusting for confounding, and hence collecting information about confounders, is not necessary at test time. DEITEE allows the development of rich models that exploit all variables at train time but identifies a minimal set of variables required to estimate the ITE at test time. Using 77 semi-synthetic datasets with varying data generating processes, we show that DEITEE achieves significant reductions in the number of variables required at test time with little to no loss in accuracy. Using real data, we demonstrate the utility of our approach in helping soon-to-be mothers make planning and lifestyle decisions that will impact newborn health.",AAAI,2019,10.1609/AAAI.V33I01.33014544,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aa30901b02e9923851d507e1f2726bcf9ef1b068,https://www.semanticscholar.org/paper/aa30901b02e9923851d507e1f2726bcf9ef1b068,OccuSpace: Towards a Robust Occupancy Prediction System for Activity Based Workplace,"Workplace occupancy detection is becoming increasingly important in large Activity Based Work (ABW) environments as it helps building and office management understand the utilisation and potential benefits of shared workplace. However, existing sensor-based technologies detect workstation occupancy in indoor spaces require extensive installation of hardware and maintenance incurring ongoing costs. Moreover, accuracy can depend on the specific seating styles of workers since the sensors are usually placed under the table or overhead. In this research, we provide a robust system called OccuSpace to predict occupancy of different atomic zones in large ABW environments. Unlike fixed sensors, OccuSpace uses statistical features engineered from Received Signal Strength Indicator (RSSI) of Bluetooth card beacons carried by workers while they are within the ABW environment. These features are used to train state-of-the-art machine learning algorithms for prediction task. We setup the experiment by deploying our system in a realworld open office environment. The experimental results show that OccuSpace is able to achieve a high accuracy for workplace occupancy prediction.",2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),2019,10.1109/PERCOMW.2019.8730762,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
577fc6f7caadf3b4039eef127ae07b9c774b512e,https://www.semanticscholar.org/paper/577fc6f7caadf3b4039eef127ae07b9c774b512e,Smartphone-Based Self-Testing of COVID-19 Using Breathing Sounds.,"Telemedicine could be a key to control the world-wide disruptive and spreading novel coronavirus disease (COVID-19) pandemic. The COVID-19 virus directly targets the lungs, leading to pneumonia-like symptoms and shortness of breath with life-threatening consequences. Despite the fact that self-quarantine and social distancing are indispensable during the pandemic, the procedure for testing COVID-19 contraction is conventionally available through nasal swabs, saliva test kits, and blood work at healthcare settings. Therefore, devising personalized self-testing kits for COVID-19 virus and other similar viruses is heavily admired. Many e-health initiatives have been made possible by the advent of smartphones with embedded software, hardware, high-performance computing, and connectivity capabilities. A careful review of breathing sounds and their implications in identifying breathing complications suggests that the breathing sounds of COVID-19 contracted users may reveal certain acoustic signal patterns, which is worth investigating. To this end, acquiring respiratory data solely from breathing sounds fed to the smartphone's microphone strikes as a very appealing resolution. The acquired breathing sounds can be analyzed using advanced signal processing and analysis in tandem with new deep/machine learning and pattern recognition techniques to separate the breathing phases, estimate the lung volume, oxygenation, and to further classify the breathing data input into healthy or unhealthy cases. The ideas presented have the potential to be deployed as self-test breathing monitoring apps for the ongoing global COVID-19 pandemic, where users can check their breathing sound pattern frequently through the app.",Telemedicine journal and e-health : the official journal of the American Telemedicine Association,2020,10.1089/tmj.2020.0114,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
243057879b1168bbb0e7f356b6cf1609b756d5e7,https://www.semanticscholar.org/paper/243057879b1168bbb0e7f356b6cf1609b756d5e7,Highly Secured Implantable Medical Devices,"This work is targeting a solid security improvement in the wireless communication between existing and possibly future implantable medical devices (IMDs) and Programmer Monitor Device (PMD). A public medical server acting as a trusted Authority is introduced. A dedicated Pacemaker Proxy Device (PPD) is proposed to serve as a security mediator between PMD and IMD taking care of all medical security, liability and responsibility issues. The key idea is based on embedding low-complexity and resilient digital physical identities based on a new concept in the system devices to prohibit physical substitution/cloning attacks. A biometric identity extracted from the patient's ECG (electrocardiogram) is supporting the security system by adding rather hard-to-clone patient personal health profile. A machine learning algorithm is deployed to extract such biometric identity (key). The initial results of the proposed approach showed practical accuracy in extracting the biometric identity approaching 95%. The whole resulting system ensures solid, resilient and high level of protection for future smart medical environment.",2018 International Conference on Innovations in Information Technology (IIT),2018,10.1109/INNOVATIONS.2018.8605968,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fe216b5fa0bc9bb27fad6a3da1b846c4ab6afda6,https://www.semanticscholar.org/paper/fe216b5fa0bc9bb27fad6a3da1b846c4ab6afda6,Data-Driven Resiliency Solutions for Boards and Systems,"Data analytics and real-time monitoring can be used to ensure that boards and systems operate as intended. This paper first describes how machine learning, statistical techniques, and information-theoretic analysis can be used to close the gap between working silicon and a working system. Next, it describes how time-series analysis can be used to analyze health status and detect anomalies in complex core router systems. Traditional techniques fail to identify abnormal or suspect patterns when the monitored data involves temporal measurements and exhibits significantly different statistical characteristics for its constituent features. This paper thus not only describes a feature-categorization-based hybrid method and a changepoint-based method to detect anomalies in time-varying features with different statistical characteristics, but also proposes a symbol-based health analyzer to obtain a full picture of the health status of monitored core routers. A comprehensive set of experimental results is presented for data collected during 30 days of field operation from over 20 core routers deployed by customers of a major telecom company.",2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID),2018,10.1109/VLSID.2018.70,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c1e79df58927e7f428bddcfd66cd146c445ba33c,https://www.semanticscholar.org/paper/c1e79df58927e7f428bddcfd66cd146c445ba33c,Neural Network with Confidence Kernel for Robust Vibration Frequency Prediction,"Image-based measurement has received increasing attention as it can substantially reduce the cost of labor, measurement equipment, and installation process. Instead of using optical flow, pattern, or marker tracking to extract a displacement signal, in this study, a novel noncontact machine learning-based system was proposed to directly predict vibration frequency with high accuracy and good reliability by using image sequences acquired from a single camera. The performance of the proposed method was demonstrated through experiments conducted in a laboratory and under real-field conditions and compared with those obtained using a contacted sensor. The vibration frequency prediction results of the proposed method are compared with industry-level vibration sensor results in the frequency domain, demonstrating that the proposed method could predict the target-object-vibration frequency as accurately as an industry-level vibration sensor, even under uncontrollable real-field conditions with no additional enhancement or extra signal processing techniques. However, only the principal vibration frequency of a measurement target is predicted, and the measurement range is limited by the trained model. Nonetheless, if these limitations are resolved, this method can potentially be used in real engineering applications in mechanical or civil structural health monitoring thanks to the simple deployment and concise pipeline of this method.",J. Sensors,2019,10.1155/2019/6573513,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e16659119daa56ed7f41c253789734857af65ee4,https://www.semanticscholar.org/paper/e16659119daa56ed7f41c253789734857af65ee4,An Overview of Audio Event Detection Methods from Feature Extraction to Classification,"ABSTRACT Audio streams, such as news broadcasting, meeting rooms, and special video comprise sound from an extensive variety of sources. The detection of audio events including speech, coughing, gunshots, etc. leads to intelligent audio event detection (AED). With substantial attention geared to AED for various types of applications, such as security, speech recognition, speaker recognition, home care, and health monitoring, scientists are now more motivated to perform extensive research on AED. The deployment of AED is actually a more complicated task when going beyond exclusively highlighting audio events in terms of feature extraction and classification in order to select the best features with high detection accuracy. To date, a wide range of different detection systems based on intelligent techniques have been utilized to create machine learning-based audio event detection schemes. Nevertheless, the preview study does not encompass any state-of-the-art reviews of the proficiency and significances of such methods for resolving audio event detection matters. The major contribution of this work entails reviewing and categorizing existing AED schemes into preprocessing, feature extraction, and classification methods. The importance of the algorithms and methodologies and their proficiency and restriction are additionally analyzed in this study. This research is expanded by critically comparing audio detection methods and algorithms according to accuracy and false alarms using different types of datasets.",Appl. Artif. Intell.,2017,10.1080/08839514.2018.1430469,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3669f95b0a3224c62d4ddfcebc174dee613e07fc,https://www.semanticscholar.org/paper/3669f95b0a3224c62d4ddfcebc174dee613e07fc,Topic Model for Identifying Suicidal Ideation in Chinese Microblog,"Suicide is one of major public health problems worldwide. Traditionally, suicidal ideation is assessed by surveys or interviews, which lacks of a real-time assessment of personal mental state. Online social networks, with large amount of user-generated data, offer opportunities to gain insights of suicide assessment and prevention. In this paper, we explore potentiality to identify and monitor suicide expressed in microblog on social networks. First, we identify users who have committed suicide and collect millions of microblogs from social networks. Second, we build suicide psychological lexicon by psychological standards and word embedding technique. Third, by leveraging both language styles and online behaviors, we employ Topic Model and other machine learning algorithms to identify suicidal ideation. Our approach achieves the best results on topic-500, yielding F1 − measure of 80.0%, Precision of 87.1%, Recall of 73.9%, and Accuracy of 93.2%. Furthermore, a prototype system for monitoring suicidal ideation on several social networks is deployed.",PACLIC,2015,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c3d16c06f489128bd2c3ee91f2bf1b6fbeef0055,https://www.semanticscholar.org/paper/c3d16c06f489128bd2c3ee91f2bf1b6fbeef0055,Physiological and Behavior Monitoring Systems for Smart Healthcare Environments: A Review,"Healthcare optimization has become increasingly important in the current era, where numerous challenges are posed by population ageing phenomena and the demand for higher quality of the healthcare services. The implementation of Internet of Things (IoT) in the healthcare ecosystem has been one of the best solutions to address these challenges and therefore to prevent and diagnose possible health impairments in people. The remote monitoring of environmental parameters and how they can cause or mediate any disease, and the monitoring of human daily activities and physiological parameters are among the vast applications of IoT in healthcare, which has brought extensive attention of academia and industry. Assisted and smart tailored environments are possible with the implementation of such technologies that bring personal healthcare to any individual, while living in their preferred environments. In this paper we address several requirements for the development of such environments, namely the deployment of physiological signs monitoring systems, daily activity recognition techniques, as well as indoor air quality monitoring solutions. The machine learning methods that are most used in the literature for activity recognition and body motion analysis are also referred. Furthermore, the importance of physical and cognitive training of the elderly population through the implementation of exergames and immersive environments is also addressed.",Sensors,2020,10.3390/s20082186,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6160e79c5fadf2bcfa30008f1cbd95a1f39c1b5d,https://www.semanticscholar.org/paper/6160e79c5fadf2bcfa30008f1cbd95a1f39c1b5d,Harvesting Randomness to Optimize Distributed Systems,"We view randomization through the lens of statistical machine learning: as a powerful resource for offline optimization. Cloud systems make randomized decisions all the time (e.g., in load balancing), yet this randomness is rarely used for optimization after-the-fact. By casting system decisions in the framework of reinforcement learning, we show how to collect data from existing systems, without modifying them, to evaluate new policies, without deploying them. Our methodology, called harvesting randomness, has the potential to accurately estimate a policy's performance without the risk or cost of deploying it on live traffic. We quantify this optimization power and apply it to a real machine health scenario in Azure Compute. We also apply it to two prototyped scenarios, for load balancing (Nginx) and caching (Redis), with much less success, and use them to identify the systems and machine learning challenges to achieving our goal. Our long-term agenda is to harvest the randomness in distributed systems to develop non-invasive and efficient techniques for optimizing them. Like CPU cycles and bandwidth, we view randomness as a valuable resource being wasted by the cloud, and we seek to remedy this.",HotNets,2017,10.1145/3152434.3152435,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
adbc8aa0ad677ec0b81955425fb888b4e2743a3a,https://www.semanticscholar.org/paper/adbc8aa0ad677ec0b81955425fb888b4e2743a3a,An hybrid platform for remote health monitoring: From concept to deployment,"This paper presents experimental results from a platform consisting of multiple wearable body area networks (BAN) connected to a wireless mesh network. The proposed platform collects, processes and wirelessly transmits medical data from multiple wearable BAN to a medical control center (MCC) through a solar-powered and multi-hop mesh network. This proof-of-concept platform encompasses several innovations. In the BAN, a dynamic TDMA MAC layer has been implemented over a 802.15.4 physical layer as well as 2 lightweight protocols. To reduce the number of packet sent by sensors and the size of packet sent by the gateway, a similarity-based filter and a polynomial interpolation technique respectively are used. In the solar-powered mesh network, a machine learning algorithm has been implemented to predict battery depletion and ensure continuity of service.","2015 7th International Conference on New Technologies, Mobility and Security (NTMS)",2015,10.1109/NTMS.2015.7266472,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
41c339ea5b64dd923c064d63142e88501b260236,https://www.semanticscholar.org/paper/41c339ea5b64dd923c064d63142e88501b260236,Editorial: The Real Technology Revolution: Technology Justice,,Development,2019,10.1057/s41301-019-00230-3,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fca58eb8f934a5715dd3b2f4622ae41ab3974a2a,https://www.semanticscholar.org/paper/fca58eb8f934a5715dd3b2f4622ae41ab3974a2a,Utilization and Monetization of Healthcare Data in Developing Countries,"Abstract In developing countries with fledgling healthcare systems, the efficient deployment of scarce resources is paramount. Comprehensive community health data and machine learning techniques can optimize the allocation of resources to areas, epidemics, or populations most in need of medical aid or services. However, reliable data collection in low-resource settings is challenging due to a wide range of contextual, business-related, communication, and technological factors. Community health workers (CHWs) are trusted community members who deliver basic health education and services to their friends and neighbors. While an increasing number of programs leverage CHWs for last mile data collection, a fundamental challenge to such programs is the lack of tangible incentives for the CHWs. This article describes potential applications of health data in developing countries and reviews the challenges to reliable data collection. Four practical CHW-centric business models that provide incentive and accountability structures to facilitate data collection are presented. Creating and strengthening the data collection infrastructure is a prerequisite for big data scientists, machine learning experts, and public health administrators to ultimately elevate and transform healthcare systems in resource-poor settings.",Big Data,2015,10.1089/big.2014.0053,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f3829f50a1e34db72ad6eb4adefa82897498a3e3,https://www.semanticscholar.org/paper/f3829f50a1e34db72ad6eb4adefa82897498a3e3,"Big Data Driven Clinical Informatics & Surveillance (BDD_CIS) – A Multimodal Database Focused Clinical, Community, and Multi-Omics Surveillance Plan for COVID-19: A study Protocol (Preprint)","
 BACKGROUND
 The Coronavirus Disease 2019 (COVID-19) caused by the severe acute respiratory syndrome coronavirus (SARS-CoV-2) remains a serious global pandemic. Currently, all age groups are at risk for infection but the elderly and persons with underlying health conditions are at higher risk of severe complications. In the United States (US), the pandemic curve is rapidly changing with over 6,786,352 cases and 199,024 deaths reported. South Carolina (SC) as of 9/21/2020 reported 138,624 cases and 3,212 deaths across the state.
 
 
 OBJECTIVE
 The growing availability of COVID-19 data provides a basis for deploying Big Data science to leverage multitudinal and multimodal data sources for incremental learning. Doing this requires the acquisition and collation of multiple data sources at the individual and county level.
 
 
 METHODS
 The population for the comprehensive database comes from statewide COVID-19 testing surveillance data (March 2020- till present) for all SC COVID-19 patients (N≈140,000). This project will 1) connect multiple partner data sources for prediction and intelligence gathering, 2) build a REDCap database that links de-identified multitudinal and multimodal data sources useful for machine learning and deep learning algorithms to enable further studies. Additional data will include hospital based COVID-19 patient registries, Health Sciences South Carolina (HSSC) data, data from the office of Revenue and Fiscal Affairs (RFA), and Area Health Resource Files (AHRF).
 
 
 RESULTS
 The project was funded as of June 2020 by the National Institutes for Health.
 
 
 CONCLUSIONS
 The development of such a linked and integrated database will allow for the identification of important predictors of short- and long-term clinical outcomes for SC COVID-19 patients using data science.
",,2020,10.2196/preprints.24504,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8e19fe99b4a90c0dd59c44a3dafaf993becf6eaa,https://www.semanticscholar.org/paper/8e19fe99b4a90c0dd59c44a3dafaf993becf6eaa,Physical analytics to model health behaviors,"Mobile phones are a pervasive platform for opportunistic sensing of social and health related behaviors. In this talk, I discuss how sensor data from mobile phones can be used to model and predict health outcomes. The talk starts with a review of research at the MIT Media Lab, and then transitions into how Ginger.io has built a commercial platform to collect, annotate, analyze and drive healthcare interventions at scale, deployed with major US hospital systems and healthcare providers. The Ginger.io three-part platform -- patient app, behavioral analytics engine, and provider dashboard -- applies this technology to give care providers a window into their patients' health between office visits. Our mobile app uses smartphone sensors to passively collect information about a patient's daily patterns. Using this data, our machine learning models are able to detect at-risk patients significantly better than the standard of care. Any concerning changes in behavior are communicated to the provider through our simple, action-oriented web dashboard. Ginger.io is part of the care solutions at institutions such as Kaiser Permanente, Novant Health, UCSF, Duke Medical and Cincinnati Children's.",WPA@MobiSys,2014,10.1145/2611264.2611272,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
58341b9f2e5ed86f94366943eb36362d13808d4b,https://www.semanticscholar.org/paper/58341b9f2e5ed86f94366943eb36362d13808d4b,IMPACT: a generic tool for modelling and simulating public health policy.,"BACKGROUND
Populations are under-served by local health policies and management of resources. This partly reflects a lack of realistically complex models to enable appraisal of a wide range of potential options. Rising computing power coupled with advances in machine learning and healthcare information now enables such models to be constructed and executed. However, such models are not generally accessible to public health practitioners who often lack the requisite technical knowledge or skills.


OBJECTIVES
To design and develop a system for creating, executing and analysing the results of simulated public health and healthcare policy interventions, in ways that are accessible and usable by modellers and policy-makers.


METHODS
The system requirements were captured and analysed in parallel with the statistical method development for the simulation engine. From the resulting software requirement specification the system architecture was designed, implemented and tested. A model for Coronary Heart Disease (CHD) was created and validated against empirical data.


RESULTS
The system was successfully used to create and validate the CHD model. The initial validation results show concordance between the simulation results and the empirical data.


CONCLUSIONS
We have demonstrated the ability to connect health policy-modellers and policy-makers in a unified system, thereby making population health models easier to share, maintain, reuse and deploy.",Methods of information in medicine,2011,10.3414/ME11-02-0006,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fceac94e2d512fd772466d33faa670e926edb7f9,https://www.semanticscholar.org/paper/fceac94e2d512fd772466d33faa670e926edb7f9,iHear Food: Eating Detection Using Commodity Bluetooth Headsets,"Monitoring a person's dietary behavior has many health applications (e.g. weight management). Existing approaches for automatic eating detection using wearable sensors often require custom hardware that may not be practical as their usability and energy efficiency have not been validated. In this paper, we propose to use off-the-shelf Bluetooth headsets to unobtrusively monitor and detect users' eating episodes by analyzing the chewing sound. The challenges of using commodity acoustic hardware include the limited sampling rate that reduces feature fidelity and the impact of environment noise in real-world settings. Our experimental results show that the traditional kernel-based approach using Support Vector Machine (SVM) could achieve 94-95% classification accuracy in lab settings, though the detection performance quickly degraded to 65-76% for in-the-field testing. We then propose a novel Deep Learning based classification technique that drastically improved detection accuracy to 77-94% despite the existence of ambient noise. To the best of our knowledge, this is the first study to use Bluetooth headsets to detect eating episodes and to use Deep Learning to significantly increase classification performance in this context. We believe that the adoption of readily available and low-cost consumer devices provides a foundation for practical deployment of automated dietary monitoring applications.","2016 IEEE First International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)",2016,10.1109/CHASE.2016.14,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
56a57b99b100694f74fa38b9a18b9269d6c9f937,https://www.semanticscholar.org/paper/56a57b99b100694f74fa38b9a18b9269d6c9f937,Classifying IoT Devices in Smart Environments Using Network Traffic Characteristics,"The Internet of Things (IoT) is being hailed as the next wave revolutionizing our society, and smart homes, enterprises, and cities are increasingly being equipped with a plethora of IoT devices. Yet, operators of such smart environments may not even be fully aware of their IoT assets, let alone whether each IoT device is functioning properly safe from cyber-attacks. In this paper, we address this challenge by developing a robust framework for IoT device classification using traffic characteristics obtained at the network level. Our contributions are fourfold. First, we instrument a smart environment with 28 different IoT devices spanning cameras, lights, plugs, motion sensors, appliances, and health-monitors. We collect and synthesize traffic traces from this infrastructure for a period of six months, a subset of which we release as open data for the community to use. Second, we present insights into the underlying network traffic characteristics using statistical attributes such as activity cycles, port numbers, signalling patterns, and cipher suites. Third, we develop a multi-stage machine learning based classification algorithm and demonstrate its ability to identify specific IoT devices with over 99 percent accuracy based on their network activity. Finally, we discuss the trade-offs between cost, speed, and performance involved in deploying the classification framework in real-time. Our study paves the way for operators of smart environments to monitor their IoT assets for presence, functionality, and cyber-security without requiring any specialized devices or protocols.",IEEE Transactions on Mobile Computing,2019,10.1109/TMC.2018.2866249,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1d0df3fad5821f7c03437c15b49c9d9931367b16,https://www.semanticscholar.org/paper/1d0df3fad5821f7c03437c15b49c9d9931367b16,e-Labs and the Stock of Health Method for Simulating Health Policies,"Regional outcomes of national health policies are difficult to forecast. This is partly due to a lack of realistically complex models that can be used to appraise policy options and partly a lack of accessible and adaptable tools that can be used to simulate the consequences of policy decisions. These barriers might be overcome by exploiting the commoditization of massively parallel computing architectures, advances in machine learning, and the increased availability of large-scale linked healthcare data. This paper presents a novel modelling methodology, The Stock of Health, for harnessing emerging data and computational resources to simulate health policy, with application initially to coronary heart disease. We detail the use of multi-core graphical processing architectures to facilitate a micro-simulation approach. The simulation tools have been deployed through the IMPACT Framework. We explore how this framework can be extended to support the sharing and reuse of policy models and simulations based on the digital publishing concept of e-Lab.",MedInfo,2013,10.3233/978-1-61499-289-9-288,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f0181da3c6618177bce90173afdd6eb352f4e22e,https://www.semanticscholar.org/paper/f0181da3c6618177bce90173afdd6eb352f4e22e,Guest Editorial: Computer Vision for Animal Biometrics,"Biometric Computer Vision that detects, tracks, identifies, describes, and classifies animal life from captured image and video data, is an emerging subject in machine vision. It is an exciting moment for this field of study. For the first time a myriad of realworld systems and applications are becoming integrated into the practice of the biological sciences. Indeed, Computer Vision systems have also started to assist work in a variety of allied scientific areas including field ecology, agricultural research, animal welfare, conservation, public health and the behavioural sciences. This Special Issue brings together a selection of eight timely papers in this field, submitted by researchers of institutions from across four continents. The works presented here include the analysis of animals ranging from insects and fish, to birds and mammals, but also life during embryonic development. The presented papers showcase some of the current diversity in this research domain: methods span the whole spectrum from traditional feature-based approaches to Deep Learning solutions. Psota et al. in their paper “Tracking of group-housed pigs using multi-ellipsoid expectation maximization” describe a system that utilises depth images accurately to estimate the position and orientation of individual pigs in a group-housed environment over significant periods of time. By applying expectation maximization as a policy for ellipse fitting, their method is able to exploit consistent shape and fixed target numbers to aid tracking. Practical results demonstrate that the system can track 15 group-housed pigs for an average of 19.7 minutes between failure events. Xie et al. in their paper “A novel open snake model based on global guidance field for embryo vessel location” present a framework for blood vessel region extraction and accurate snakebased localisation in imagery of animal embryos. Their open snake model utilises a global guidance field and is initialised by a deformation template. Experimental results on a specific embryo vessel database demonstrate that the proposed algorithm can robustly locate the embryo's blood vessels and obtain orientations of the vessel branches. Comparisons with traditional methods illustrate the effectiveness and competitiveness of their proposed model. Bakkay et al. in their paper “Automatic detection of individual and touching insects from trap images by combining contour-based and region-based segmentation” introduce a method for the detection of insects from camera trap images in difficult conditions by employing an innovative region merging algorithm and an adaptive k-means clustering approach, operating on the object contour's convex hull. Quantitative evaluations show that the proposed method can detect insects with higher accuracy than most widely used approaches. Eerola et al. in their paper “Automatic individual identification of Saimaa ringed seals” describe a method for the automatic image-based individual identification of endangered Saimaa ringed seals (Phoca hispida saimensis) that exploits the species’ permanent and individually unique visual pelage patterns. The proposed framework performs segmentation of the seals from the background, as well as post-processing and classification steps required for identification. Two existing individual identification methods are compared to the presented work using a challenging data set of Saimaa ringed seal images. The results show that the proposed segmentation and post-processing steps are effective and can provide increased identification performance against a generic baseline. Akkaya et al. in their paper “Mouse face tracking using a convolutional neural network” present a convolutional neural network (CNN) tracker called MFTN for following a mouse's face in video footage. Notably, in the proposed architecture, target information is extracted from a combination of lowand high-level features by a particular sub-network to achieve a more robust and accurate tracker. Experiments show that the particular MFTN/c tracker achieved an accuracy of 0.8, a robustness of 0.67, and a throughput of 213 fps on the GPU-powered testing workstation. Beyan et al. in their paper “Extracting statistically significant behaviour from noisy fish tracking data” describe an approach to the cleaning of a large and noisy visual tracking dataset to allow for the extraction of statistically sound results from the underlying image data. In particular, the paper presents an analysis of a dataset of 3.6 million underwater trajectories of a species of fish, which are also labelled with the water temperature at the time of acquisition. By a combination of data binning and robust estimation methods, the authors demonstrate reliable evidence for an increase in fish speed as water temperature increases. Several statistical tests applied to the data confirm that results are statistically significant. Ardo et al. in their paper “A CNN-based cow interaction watchdog” introduce an automated video analysis system for the processing of cow footage that can select or discard recorded video material based on user-defined criteria commonly required in behavioural research to reduce the amount of time experts have to spend on watching video. A CNN architecture is proposed and then evaluated in a pilot study. It is shown that 38% (50% with additional filter parameters) of the recordings in the test dataset could be correctly and successfully removed, while only losing 1% (4%) of the potentially interesting video frames. Finally, Silla Junior et al. in their paper “Bird and whale identification using sound images” describe a novel approach for the automated identification of birds and whales from calls. The visual features of audio used are constructed from different spectrograms and from harmonic and percussion images. These images are then divided into sub-windows from which sets of texture descriptors are extracted for classification. The experiments reported in this paper use a dataset of bird vocalizations targeted for species recognition and a dataset of right whale calls targeted for whale detection, as well as three well-known benchmarks for music genre classification. The authors demonstrate that the fusion of different texture features, as well as texture and audio features together can enhance performance. As is clear from the above content, this Special Issue highlights the great breadth of research in Visual Animal Biometrics today, and the even greater potential for this area of Computer Vision in the future. One may argue that the field is indeed on its way to realising another facet of Jim Gray's 4th scientific paradigm, ever more intricately binding together biological research questions with Computer Vision engineering. In any case, we hope that readers will find the papers put forward here inspiring and informative; and we would like to extend our sincere thanks to all authors and reviewers of the works before us.",IET Comput. Vis.,2018,10.1049/iet-cvi.2018.0019,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
66bdd08a19520bf87766dc64266e728277538394,https://www.semanticscholar.org/paper/66bdd08a19520bf87766dc64266e728277538394,Reverse innovation experiences from the RAFT e-learning and telemedicine network.,"Available infrastructure, resources, and provided services in low-and middle-income countries differ significantly from high-income countries. In healthcare for example, the uneven distribution of health professionals and lack of human resources are real barriers to equitable access to quality health care and services in most developing countries and particularly in Sub-Saharan Africa. As available resources are lower and infrastructure is les developed many services and tools that have been developed for a high-income context cannot be used or are not sustainably affordable in a low-income environment, which led to the development of tools and services that are affordable and appropriate for this context. This ranges from concepts of blended learning, over tools for distance education and diagnostic to hardware like affordable and robust ultrasound machines and services like mobile payment. Many of these solutions and tools also have a great potential to be utilized in a different context and some of them have been deployed in high-income countries.",World hospitals and health services : the official journal of the International Hospital Federation,2016,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2cc3338709ea9c14ff422025ae4a8ad09f9598ba,https://www.semanticscholar.org/paper/2cc3338709ea9c14ff422025ae4a8ad09f9598ba,Explainable AI: from black box to glass box,,Journal of the Academy of Marketing Science,2019,10.1007/s11747-019-00710-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e2b611deaa8d324356289ee75cc70c373b71ef69,https://www.semanticscholar.org/paper/e2b611deaa8d324356289ee75cc70c373b71ef69,Failure Prediction Based on Anomaly Detection for Complex Core Routers,"Data-driven prognostic health management is essential to ensure high reliability and rapid error recovery in commercial core router systems. The effectiveness of prognostic health management depends on whether failures can be accurately predicted with sufficient lead time. This paper describes how time-series analysis and machine-learning techniques can be used to detect anomalies and predict failures in complex core router systems. First both a feature-categorization-based hybrid method and a changepoint-based method have been developed to detect anomalies in time-varying features with different statistical characteristics. Next, a SVM-based failure predictor is developed to predict both categories and lead time of system failures from collected anomalies. A comprehensive set of experimental results is presented for data collected during 30 days of field operation from over 20 core routers deployed by customers of a major telecom company.",2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD),2018.0,10.1145/3240765.3243476,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f675b8153e6d4bf93de5bcbb8748b1344558003b,https://www.semanticscholar.org/paper/f675b8153e6d4bf93de5bcbb8748b1344558003b,A Fuzzy Rule Based Approach to Predict Risk Level of Heart Disease,"Health care domain systems globally face lots of difficulties because of the high amount of risk factors of heart diseases in peoples (WHO, 2013). To reduce risk, improved knowledge based expert systems played an important role and has a contribution towards the development of the healthcare system for cardiovascular disease. To make use of benefits of knowledge based system, it is necessary for health organizations and users; must need to know the fuzzy rule based expert system’s integrity, efficiency, and deployments, which are the open challenges of current fuzzy logic based medical systems. In our proposed system, we have designed a fuzzy rule based expert system and also by using data mining technique we have reduced the total number of attributes. Our system mainly focuses on cardiovascular disease diagnosis, and the dataset taken from UCI (Machine Learning Repository). We explored in the existing work. The majority of the researcher’s experimentation was made on 14 attributes out of 76. While, in our system we took advantage of 6 attributes for system design. In the preliminary stage UCI, data participated in suggested system that will get outcomes. The performance of the system matched with Neural Network and J48 Decision Tree Algorithm.",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
103d9a658947ea8a56b6597b33e20a2b58ae1845,https://www.semanticscholar.org/paper/103d9a658947ea8a56b6597b33e20a2b58ae1845,New Directions in Artifi cial Intelligence for Public Health Surveillance,"contamination of the food or water supply), and other patterns relevant to the health of populations (such as obesity, drug abuse, mental health, or malnutrition). This surveillance takes place at the local, state, national, and global scales, and often requires coordination of multiple entities (for example, hospitals, pharmacies, and local, state, and federal public health organizations) to achieve a timely, focused, and effective response to emerging health events. In this work, we focus on the role that artifi cial intelligence and machine learning methods can play in assisting public health through the early, automatic detection of emerging outbreaks and other health-relevant patterns. The last decade has seen major advances in analytical methods for outbreak detection, including (but not limited to) analysis of spatial and temporal data,1 integration of multiple data streams,2 Bayesian methods to model and differentiate between multiple event types,3,4 more realistic outbreak simulations,5 and improved metrics to evaluate detection performance.6 Deployed systems have incorporated many such methods, monitoring a variety of public health data sources such as Emergency Department visits and over-the-counter medication sales7 and enabling more timely and accurate identifi cation of disease outbreaks in practice. While most existing surveillance systems rely heavily on basic statistical methods such as time series analysistogether with the expert knowledge of public health practitioners, we believe that the disease surveillance fi eld is entering a major paradigm shift due to a dramatic increase in the number, quantity, and complexity of available data sources. Current disease surveillance systems are relying more and more on massive quantities of data from nontraditional sources, ranging from Internet search queries and user-generated Web content, to detailed electronic medical records, to continuous data streams from sensor networks, cellular telephones, and other locationaware devices. This shifttoward analysis of data at the societal scale will require a corresponding shift in the methodologies employed in practical disease surveillance systems, incorporating techniques from artifi cial intelligence, machine learning, and data mining to make sense of the massive quantity of data, to detect relevant patterns, and to assist public health decision making. Practitioners will increasingly rely ontools and systems that use advanced statistical methods toaccurately distinguish relevant from irrelevant patterns, scalable algorithms to process the massive quantities of complex, high-dimensional data, and machine learning approaches to continually improve system performance from user feedback. Thus we believe that the next decade of disease surveillance research will require us to address three main challenges:",,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
40f45033b18670b32698b050e93621d9f2044ec9,https://www.semanticscholar.org/paper/40f45033b18670b32698b050e93621d9f2044ec9,Business opportunities in 5G mobile technology,"The question of how actors perceive business opportunities has puzzled both researchers and practitioners for decades. In the era of artificial intelligence, machine learning, and the Internet of things, many actors of the technology-intensive industries question how to use new technology to create value, and how to monetize new service concepts. In this paper, we focus on the next mobile communications technology, 5G, as one of the potential value-creators for the future that holds business opportunities for its utilizers and deployers. The concept of business opportunities is strongly associated with research on entrepreneurship (cf. Carlsson et al., 2003). Entrepreneurial opportunities consist of a set of ideas, beliefs, and actions that enable the introduction of goods, services, raw materials, and organizing methods in the absence of current markets for them (Sarasvathy et al., 2003). The research stream of entrepreneurial opportunities (cf. Alvarez & Barney, 2007, 2010; Dimov, 2007, 2011; Eckhardt & Shane, 2003) can offer new insights into the development of opportunities in high technologyintensive fields, and especially as regards the development of 5G. Strategies for opportunity identification, exploitation, and value creation are vital in the 5G era, as non-ICT traditional business sectors begin to deploy wireless technologies (e.g., factories, automotive, etc.). Researchers expect that 5G will change the business models and business ecosystems; it will also better address the evolving needs of customers (cf. Kliks et al., 2018). Unlike already existing mobile communications systems, 5G allows integration of vertical industries, e.g., energy, media, health, factories, and the automotive industry (5G-PPP, 2016). Thus, specialized companies will be able to provide services and establish positions in the value chains and actor networks. This is a major transformation compared to an environment dominated by bilateral relationships between mobile operators and their customers...",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
20edb0b91ab6ac22573d5eb96ebe4b2cb23b2678,https://www.semanticscholar.org/paper/20edb0b91ab6ac22573d5eb96ebe4b2cb23b2678,Review of techniques for predicting hard drive failure with SMART attributes,"Hard drive failure prediction is still a relevant problem today. A number of statistical and machine learning techniques were proposed to improve failure forecasting accuracy after SMART was introduced. SMART is a diagnostics tool that aims at providing forehand failure warnings. Failure prediction methods can be viewed as a part of reliability analysis - the field that was studied intensively for decades. However, in some situations available techniques cannot be applied due to a simple reason - information at hand is not always sufficient for reliable prediction. SMART's goal is to provide meaningful information that can signify problems with the health condition of a hard drive and failure prediction techniques can leverage this data to provide timely and reliable warnings. To find the best failure forecasting algorithm and evaluate the possibility of its widespread deployment, we review existing datasets with SMART attributes, methods for feature selection for hard drive failure prediction.",,2018.0,10.1504/IJMISSP.2018.10014099,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d636a8fb42da7e15c04baca6b21b1060f0ed8b64,https://www.semanticscholar.org/paper/d636a8fb42da7e15c04baca6b21b1060f0ed8b64,Towards Automatic Suicide Risk Assessment,"Background: Suicide has been considered as an important public health issue for years, and is one of the main causes of death worldwide. Despite prevention strategies being applied, the rate of suicide has not changed substantially over the past decades. Suicide risk has proven extremely difficult to assess for medical specialists, and traditional methodologies deployed have been ineffective. Advances in machine learning make it possible to attempt to predict suicide with the analysis of relevant data aiming to inform clinical practice. Aims: (a) test our artificial intelligence based, referral-centric methodology in the context of the NHS, (b) determine whether statistically relevant results can be derived from data related to previous suicides, and (c) develop ideas for various exploitation strategies. Method: The analysis used data of patients who died by suicide in the period 2013-2016 including both structured data and free-text medical notes, necessitating the deployment of state of the art machine learning and text mining methods. Results and Conclusions: The results of this pilot study indicate that machine learning shows promise to predict within a specified period which people are most at risk of taking their own life at the time of referral to a mental health service.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
87c754b52dcf133d115ec804db0d54bfca3cab69,https://www.semanticscholar.org/paper/87c754b52dcf133d115ec804db0d54bfca3cab69,Towards application of non-invasive environmental sensors for risks and activity detection,"One of the main goals of Ambient Assisted Living (AAL) is to provide supportive environment for the elderly or disabled. Such environments are not feasible without correctly identifying states and activities of the persons receiving the care. They rely on the interaction and processing of data originating from many components and objects in the surrounding. In order to collect the data, various sensors are used to monitor the environment, as well as the person's health parameters. One of the main concerns in AAL is preservation of user's privacy. In this paper we address that by proposing a non-intrusive approach for data collection and identification of daily activity and risks. We describe the wiring of such system based on cheap non-intrusive sensors, deployment in a real environment, the protocols for data fusion and processing, and explain how machine learning could be employed for detecting risks and activities. The main contribution of this paper is development of non-intrusive sensor kits that can be easily deployed in real-life environments and are capable of collecting data that can reliable detect activities and risk.",2016 IEEE 12th International Conference on Intelligent Computer Communication and Processing (ICCP),2016.0,10.1109/ICCP.2016.7737117,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
67c56f76efd9111593df16854106b7917dc8f3db,https://www.semanticscholar.org/paper/67c56f76efd9111593df16854106b7917dc8f3db,Toward the Use of Operational Cycle Data for Capacity Estimation,"For the development, simulation and validation of data-driven battery aging models, a critical aspect is having access to large amounts of reliable aging data. Although normal operation of battery packs can be simulated in the lab to generate aging data, a variety of other non-operational profiles are typically needed, requiring many hours of testing, often at conditions different than normal operational conditions observed when the battery pack is deployed in its intended application. Moreover, application of prolonged and multiple capacity tests can be detrimental to the health of the battery. In view of these concerns, this article continues a line of research into capacity fade estimation approaches that require less data and time for the data generation process; in particular, an approach using rule based machine learning for Li-ion battery packs is proposed. Using data generated in the laboratory, aging behavior is characterized by measurable features and a supervised learning approach in order to estimate capacity fade using real-time operational data toward the goal of eliminating the need for specific capacity tests. The experimental results presented in this article focus on proof of concept and are part of a comprehensive study into general capacity estimation and capacity fade estimation in battery packs.",2018 IEEE Conference on Control Technology and Applications (CCTA),2018.0,10.1109/CCTA.2018.8511573,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1b985858ef2a888268bac0d6d07c3947254cbf2e,https://www.semanticscholar.org/paper/1b985858ef2a888268bac0d6d07c3947254cbf2e,How Big Data Analytics Can Help Future Regulatory Issues in Carbon Capture and Sequestration CCS Projects,"
 In this age of data, there is a significant need for tracking and prediction of non-compliance of rules & regulations in various industries including the oil & gas sector. In this paper, we will be reviewing some of the anticipated regulatory issues in commercial implementations of carbon capture & sequestration (CCS) and discuss how machine learning and big data analytics can diminish future non-compliance incidents.
 With the rising awareness of advanced data-driven technologies such as ""Big Data Analytics"" and ""Machine Learning"", a contemporary approach to regulation and compliance is developing. This emerging approach, called ""Algorithmic Regulation"", defines an alternative framework for systematic collection of data (real-time or near real-time) and continuous generation of knowledge through intelligent computational algorithms in order to regulate a domain of activities.
 In this study, we will look at some of the major data management challenges in the pilot CCS operations with regards to rules and regulations. We will then discuss how an algorithmic regulatory framework can help in conducting CCS operations in a manner that are compliant with environmental, safety and health policies and regulations.
 Field operators collect a lot of data which needs to be formatted and modelled in a fashion acceptable to understand the operator's compliance with regulation. Generally, such compliance qualification criteria are verified using human intellect and basic querying software. In other industries, the idea of converting rules & regulations in a format understandable by machines is gaining momentum and great strides have been taken. The technological progresses made possible by data-driven analytical techniques can create a paradigm shift in the way rules and regulations are designed and implemented. Large-scale deployment of CCS projects is bound to bring with it a number of regulatory issues, making it a necessity to proactively explore and address the anticipated issues. These technologies can equip regulated entities as well as regulators with advanced tools for managing complexity in CCS projects. These improved solutions will help companies to better meet the regulatory data collection, reporting and governance requirements in large scale CCS operations.
 This paper looks into advanced data management and modeling techniques like ""algorithmic regulations"" to increase compliance in carbon capture and sequestration projects. The concept of handling rules and regulations in the form of big data will change the outlook and compliance management will become increasingly more agile and responsive.","Day 3 Thu, April 25, 2019",2019.0,10.2118/195284-MS,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
002be03a6c1f589e707fb85f6cdb43b76375429e,https://www.semanticscholar.org/paper/002be03a6c1f589e707fb85f6cdb43b76375429e,Detecting Irregular Patterns in IoT Streaming Data for Fall Detection,"Detecting patterns in real time streaming data has been an interesting and challenging data analytics problem. With the proliferation of a variety of sensor devices, real-time analytics of data from the Internet of Things (IoT) to learn regular and irregular patterns has become an important machine learning problem to enable predictive analytics for automated notification and decision support. In this work, we address the problem of learning an irregular human activity pattern, fall, from streaming IoT data from wearable sensors. We present a deep neural network model for detecting fall based on accelerometer data giving 98.75 percent accuracy using an online physical activity monitoring dataset called “MobiAct”, which was published by Vavoulas et al. The initial model was developed using IBM Watson studio and then later transferred and deployed on IBM Cloud with the streaming analytics service supported by IBM Streams for monitoring real-time IoT data. We also present the systems architecture of the real-time fall detection framework that we intend to use with Mbientlab's wearable health monitoring sensors for real time patient monitoring at retirement homes or rehabilitation clinics.","2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)",2018.0,10.1109/IEMCON.2018.8614822,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5f60ca811d837377f09239392d677e08fff7b10,https://www.semanticscholar.org/paper/d5f60ca811d837377f09239392d677e08fff7b10,Development of a HIPAA-compliant environment for translational research data and analytics,"High-performance computing centers (HPC) traditionally have far less restrictive privacy management policies than those encountered in healthcare. We show how an HPC can be re-engineered to accommodate clinical data while retaining its utility in computationally intensive tasks such as data mining, machine learning, and statistics. We also discuss deploying protected virtual machines. A critical planning step was to engage the university's information security operations and the information security and privacy office. Access to the environment requires a double authentication mechanism. The first level of authentication requires access to the university's virtual private network and the second requires that the users be listed in the HPC network information service directory. The physical hardware resides in a data center with controlled room access. All employees of the HPC and its users take the university's local Health Insurance Portability and Accountability Act training series. In the first 3 years, researcher count has increased from 6 to 58.",J. Am. Medical Informatics Assoc.,2014.0,10.1136/amiajnl-2013-001769,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6fdeb8b00e46438e0691e02b1f22cb66197d9439,https://www.semanticscholar.org/paper/6fdeb8b00e46438e0691e02b1f22cb66197d9439,Discussions of a Preliminary Hand Hygiene Compliance Monitoring Application-as-a-service,"Hospital Acquired Infections (HAIs) are a global concern as they impose significant economic consequences on the healthcare systems. In the U.S. alone, HAIs have cost hospitals an estimated $9.8 billion a year. An effective measure to reduce the spread of HAIs is for Health Care Workers (HCWs) to comply with recommended hand hygiene (HH) guidelines. Unfortunately, HH guideline compliance is currently poor, forcing hospitals to implement controls. The current standard for monitoring compliance is overt direct observation of hand sanitation of HCWs by trained observers, which can be time-consuming, costly, biased, and sporadic. Our research describes a hand hygiene compliance monitoring app, Hygiene Police (HyPo), that can be deployed as a service to alleviate the manual effort, reduce errors, and improve existing compliance monitoring practice. HyPo exploits machine learning analyses of handwashing compliance data from a 30-bed intensive care unit to predict future compliance characteristics. Based on the results, HyPo then provides HWCs with timely feedback and augments the current monitoring approach to improve compliance.",HEALTHINF,2017.0,10.5220/0006293705370544,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59652d606dfdcdd5ce551549340d75fb6d9fa88a,https://www.semanticscholar.org/paper/59652d606dfdcdd5ce551549340d75fb6d9fa88a,A non-parametric control chart for high frequency multivariate data,"Support Vector Data Description (SVDD) is a machine learning technique used for single class classification and outlier detection. A SVDD based K-chart was first introduced by Sun and Tsung [4]. K-chart provides an attractive alternative to the traditional control charts such as the Hotelling's T2 charts when the distribution of the underlying multivariate data is either non-normal or is unknown. But there are challenges when the K-chart is deployed in practice. The K-chart requires calculating the kernel distance of each new observation but there are no guidelines on how to interpret the kernel distance plot and draw inferences about shifts in process mean or changes in process variation. This limits the application of K-charts in big-data applications such as equipment health monitoring, where observations are generated at a very high frequency. In this scenario, the analyst using the K-chart is inundated with kernel distance results at a very high frequency, generally without any recourse for detecting presence of any assignable causes of variation. We propose a new SVDD based control chart, called a kT chart, which addresses the challenges encountered when using a K-chart for big-data applications. The kT charts can be used to track simultaneously process variation and central tendency.",2017 Annual Reliability and Maintainability Symposium (RAMS),2016.0,10.1109/RAM.2017.7889786,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
812746384a31d814efef4d64b63fbe6c1f4f2e0b,https://www.semanticscholar.org/paper/812746384a31d814efef4d64b63fbe6c1f4f2e0b,Construction and Application of a Medical-Grade Wireless Monitoring System for Physiological Signals at General Wards,,Journal of Medical Systems,2020.0,10.1007/s10916-020-01653-z,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
46a8aa4e2609363a3dc870586e26c436829d3938,https://www.semanticscholar.org/paper/46a8aa4e2609363a3dc870586e26c436829d3938,Cloud based patient prioritization as service in public health care,"This paper proposes and evaluates the performance of a Cyber-healthcare system which is aimed at providing patient prioritization over the cloud as a public health service for the rural and urban communities of the developing world. The underlying cloud-based Internet-of-Things (IoT-Cloud) infrastructure is aimed to be implemented in the city of Lubumbashi in the republic Democratic Republic of the Congo (DRC) with the objective of setting up a community health care network around a mesh of health kiosks. We propose a deployment model for the proposed Cyber-healthcare system, and describe a patient prioritization process as part of its situation awareness component. The results obtained from an experimental prototype reveal the field readiness of the off-the-shelf bio-sensor technology used by the system, the performance achieved when using a solar powered subsystem, the relative communication capabilities provided by its protocols and the network engineering feasibility of the planned community health care network. The relative efficiency of using supervised machine learning compared to unsupervised machine learning when performing patient prioritization, is also revealed through two popular algorithms: Multivariate linear regression (MLR) and K-means clustering (KMC).",2016 ITU Kaleidoscope: ICTs for a Sustainable World (ITU WT),2016.0,10.1109/ITU-WT.2016.7805709,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
92593aaf4bcfeffbb4e06d5c8c9a7d3bca29b22f,https://www.semanticscholar.org/paper/92593aaf4bcfeffbb4e06d5c8c9a7d3bca29b22f,Development of mass spectrometry-based targeted assay for direct detection of novel SARS-CoV-2 coronavirus from clinical specimens,"The COVID-19 pandemic caused by severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) has overwhelmed health systems worldwide and highlighted limitations of diagnostic testing. Several types of diagnostics including RT-PCR-based assays, antigen detection by lateral flow assays and antibody-based assays have been developed and deployed in a short time. However, many of these assays are lacking in sensitivity and/or specificity. Here, we describe an immunoaffinity purification followed by high resolution mass spectrometry-based targeted assay capable of detecting viral antigen in nasopharyngeal swab samples of SARS-CoV-2 infected individuals. Based on our discovery experiments using purified virus, recombinant viral protein and nasopharyngeal swab samples from COVID-19 positive patients, nucleocapsid protein was selected as a target antigen. We then developed an automated antibody capture-based workflow coupled to targeted high-field asymmetric ion mobility spectrometry (FAIMS) - parallel reaction monitoring (PRM) assays on an Orbitrap Exploris 480 mass spectrometer. An ensemble machine learning-based model for determining COVID-19 positive samples was created using fragment ion intensities in the PRM data. This resulted in 97.8% sensitivity and 100% specificity with RT-PCR-based molecular testing as the gold standard. Our results demonstrate that direct detection of infectious agents from clinical samples by mass spectrometry-based assays have potential to be deployed as diagnostic assays in clinical laboratories.",medRxiv,2020.0,10.1101/2020.08.05.20168948,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e6d9121158ae0377ef1dcb6c62f391ce0c112bd2,https://www.semanticscholar.org/paper/e6d9121158ae0377ef1dcb6c62f391ce0c112bd2,Predictive Analysis for the Arbovirus-Dengue using SVM Classification,"Data mining in biology and medicine is a core component of biomedical informatics, and one of the first intensive applications of computer science to this field. Today’s biomedical data mining appears more multifaceted with advances in knowledge discovery in databases as well as machine learning approaches. This paper explores the application of machine learning techniqueSVM for the identification of one of the Arboviral disease – Dengue. This paper reports novel biological discovery through nontrivial data mining process by using existing computational techniques. The goal of the system is to support the collection, and retrieval of public health documents, data, learning objects, and tools. We have deployed this generic infrastructure to facilitate data integration and knowledge sharing in the domain of dengue, which is one of the most prevalent viral diseases. This paper proposed an effort to apply the svm classification with the Radial basis function to classify the viral data and the model exhibits highly precise prediction rate.",,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b07507fb07f9913de77bd9f95a52d01bf4704cc8,https://www.semanticscholar.org/paper/b07507fb07f9913de77bd9f95a52d01bf4704cc8,Preventive healthcare policies in the US: solutions for disease management using Big Data Analytics,,Journal of Big Data,2020.0,10.1186/s40537-020-00315-8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f5df9b8e0184f29de62f7f1bee1e29212a5c3ef4,https://www.semanticscholar.org/paper/f5df9b8e0184f29de62f7f1bee1e29212a5c3ef4,An Autonomous Model Construction Mechanism in Dynamic Sensor Networks,"Internet-of-Things (IoT) plays a critical role in many intelligent scenarios, such as home automation, health care, connected vehicles and so on. Taking into account of several practical concerns like privacy, latency and battery issues, embedding machine learning algorithms in IoT devices is a potentially effective solution. Due to the fact that IoT devices are deployed in highly dynamic environment, reconstruction capability for model which can make the devices adapt to changes of the environment is imperative. In this paper, we design a novel autonomous model training mechanism based on curriculum learning which can deduce a set of labels to rebuild a new model adapting to dynamic environment. In particular, the label learning adopts a three-step strategy, including (1) curriculum generation, (2) curriculum refinement, and (3) curriculum teaching. In the first step, we design a reliability evaluation mechanism to pick out a high-quality set with higher reliability over the original curriculum. In the second step, based on confusion matrix and label propagation, we adjust the labels of the curriculum to accomplish the curriculum refinement. In the third step, the labels of the low-quality set will be adjusted based on the refined curriculum. Then an accurate training set can be obtained, based on which a new model can be built. Extensive experiments on three datasets demonstrate the efficiency of our approach compared to the state-of-the-art methods.","2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)",2018.0,10.1109/SmartWorld.2018.00285,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
12ffb762cb3684c0de366b0be2dd5dbc6df80945,https://www.semanticscholar.org/paper/12ffb762cb3684c0de366b0be2dd5dbc6df80945,Intitute for Statistics Master Thesis with the title : Imputation and Prediction of HIV using NHS Survey Data from Nigeria,"The human immunodeficiency virus (HIV) is one of the biggest pandemic of our time. As there exists a therapy that can suppress the viral load, it is important to identify as many HIV positive people as possible since the majority does not know about their condition. To gather information, national health services (NHS) conduct surveys which include a voluntary HIV test. It would be desirable to be able to predict the result of that test for people who did not attend it. To achieve this, first multiple imputation is used to accommodate the missing data in co-variables. Then, machine learning methods are applied. Five models are deployed to construct classifiers. The models are a logistic regression model, a mixed effects logistic regression model, random forests, boosted trees and naive Bayes. Additionally, sampling techniques are used to accommodate the highly imbalanced data of the HIV test result. With none of the techniques was it possible to construct a satisfactory classifier. All classifiers predicted all missing test results as negative. Though it is possible to classify some cases as positive, this comes at a high cost of many false predicted positive test results.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a2e2f36f2cf5e87745a2d3a31cadf73cdea0d261,https://www.semanticscholar.org/paper/a2e2f36f2cf5e87745a2d3a31cadf73cdea0d261,Improving accuracy of long-term prognostics of PEMFC stack to estimate remaining useful life,"Proton Exchange Membrane Fuel cells (PEMFC) are energy systems that facilitate electrochemical reactions to create electrical energy from chemical energy of hydrogen. PEMFC are promising source of renewable energy that can operate on low temperature and have the advantages of high power density and low pollutant emissions. However, PEMFC technology is still in the developing phase, and its large-scale industrial deployment requires increasing the life span of fuel cells and decreasing their exploitation costs. In this context, Prognostics and Health Management of fuel cells is an emerging field, which aims at identifying degradation at early stages and estimating the Remaining Useful Life (RUL) for life cycle management. Indeed, due to prognostics capability, the accurate estimates of RUL enables safe operation of the equipment and timely decisions to prolong its life span. This paper contributes data-driven prognostics of PEMFC by an ensemble of constraint based Summation Wavelet-Extreme Learning Machine (SW-ELM) algorithm to improve accuracy and robustness of long-term prognostics. The SW-ELM is used for ensemble modeling due to its enhanced applicability for real applications as compared to conventional data-driven algorithms. The proposed prognostics model is validated on run-to-failure data of PEMFC stack, which had the life span of 1750 hours. The results confirm capability of the prognostics model to achieve accurate RUL estimates.",2015 IEEE International Conference on Industrial Technology (ICIT),2015.0,10.1109/ICIT.2015.7125235,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e6cec9b4b33e1cee607b5954848a160de05f5e17,https://www.semanticscholar.org/paper/e6cec9b4b33e1cee607b5954848a160de05f5e17,AUTOMATIC RECOGNITION OF VIRTUAL REALITY SICKNESS BASED ON PHYSIOLOGICAL SIGNALS,"Virtual Reality (VR) sickness seems one of the main limitations to the large-scale adoption of VR technologies. This disturbance seems to induce physiological changes that affect the sympathetic and parasympathetic activities of the users. Thereby, it seems relevant to measure users’ physiological data in order to prevent and reduce VR sickness. This paper presents the results of an initial real-life experiment of VR sickness detection based on physiological data. The electrodermal, cardiac and subjective data of 27 participants was recorded during VR sessions. Machine Learning algorithms were trained and the best model (Gradient Boosting) explained 48% of the VR sickness variance. These results demonstrate the opportunity to develop an automatic and continuous tool to detect the appearance of VR sickness based on physiological signals. This tool will prove very valuable to the VR industry. INTRODUCTION Virtual Reality (VR) appears as a major technological breakthrough and a main business opportunity for the entertainment industry. The VR market is expected to expand exponentially with worldwide revenues for the AR/VR growing to more than $162 billion in 2020 [1]. However, one main limitation to its large-scale adoption is VR sickness especially because of health, ethical, legal and acceptability aspects. VR sickness is a common problem that could affect up to 60% of adult users [2]. The necessity to better detect and prevent the appearance of VR sickness is at the origin of this research cooperation between b<>com and Editorial user research lab, Ubisoft Paris aiming at the development of an automatic VR sickness detection tool. VIRTUAL REALITY SICKNESS: CAUSES AND SYMPTOMS Previous research proposed several hypotheses to explain VR Sickness. The most common theory is the sensory conflict theory [3]. According to this theory, VR sickness is the result of conflicts and inconsistency between the different sensorial information sent to the brain when the user evolves in the virtual world. In VR, the most common conflict is a discrepancy between the motion information coming from the vestibular system and the motion information coming from the visual system. Indeed, this information comes from two separate systems: the vestibular system located in the inner ear and the visual system [4]. This discrepancy will be detected by the brain and will induce, in sensitive participants, the symptoms of VR sickness. VR sickness is a complex phenomenon and while motion cues play a primary role, multiple factors are known to contribute to the appearance of the sickness. Three main categories of factors can be identified: 1) The factors related to the characteristics of the stimuli: the spatial frequency [5], the reactivity of the system [6], the wideness of the Field Of View (FOV) [7], etc. 2) The factors related to the predispositions of the users: gender [8], age [9], the predisposition to suffer from migraine attack [10], etc. 3) The users’ past experiences [11], according to the sensory conflict theory. In fact VR sickness appears only when a present set of vestibular and visual information is not congruent with what is expected from previous experiences [12]. The complex nature of VR sickness is not limited to its different causes, but it is reflected in its symptomatology as well. While the most evident and detrimental symptom of VR sickness is the nausea, the complete symptomatology of VR sickness includes other elements like general discomfort, headache, disorientation and eye strain. The intensity as well as the duration of the symptoms are quite variable. They depend on the characteristic of the stimulus and the user predisposition to VR sickness. In the majority of cases, the symptoms disappear some minutes after the end of the stimulation. Nevertheless, there are documented cases when the symptoms were still present 6 hours after the VR experience [13]. THE ASSESSMENT OF VIRTUAL REALITY SICKNESS The traditional way to evaluate VR sickness is based on subjective questionnaires. Various questionnaires have been previously developed to assess a sickness level. The most popular is probably the “Simulator Sickness Questionnaire” (SSQ) proposed by Kennedy in 1993 [14]. It is constituted of 16 questions to evaluate 3 categories of symptoms: nausea related symptoms, oculomotor symptoms and disorientation symptoms. While still widely used for the simplicity of its deployment and analysis, the SSQ has several limitations. Indeed, this measure is global, gathered a posteriori, intrusive and punctual. These limitations make the SSQ (and any other questionnaire) inadequate to be integrated in an automatic tool to evaluate VR sickness. Another method was proposed by Keshavarz and collaborators [15] which consists in requesting the participants to verbally give their evaluation of sickness level on a scale ranging from 0 to 20, with zero representing no discomfort and twenty representing barely supportable sickness. This approach seems to be a very good alternative to the SSQ since very strong correlation (r = .79) between verbal rating and SSQ scores were reported in this study. Nevertheless, this method is cognitively disruptive for the user experience in a context of VR-video games. To be effective and valuable for the VR industry, the assessment method must ideally be continuous, automatic and real time. Considering these constraints, physiological data related to the perceived VR sickness was used in this paper. The physiological measures of VR sickness The physiological response associated to VR sickness is due to the connections between the vestibular and the autonomic nervous system. The conflicting inputs from visual, vestibular and somatosensory afferents induce a vestibular autonomic response. This response involves both the sympathetic and the parasympathetic systems and affects for instance the heart rate variability and the skin conductance [16]. Various researches support the hypothesis of a measurable VR sickness by physiological response. For instance, Gavgani and collaborators [17] underline a correlation between phasic skin conductance activity and the reported nausea ratings. While Dennison [18] found relations between subscale scores of the SSQ and bradygastric power, breathing rate, pulse amplitude and blinking. Moreover, Ohyama and collaborators [19] investigated the cardiac responses associated to VR sickness. But, cardiac responses didn’t statically correlate with the user subjective evaluation. These findings suggest the existence of a relation between the physiological responses and VR sickness. Nevertheless, such relation seems too complex to be exploited using classical analyses. To handle such complex data, Machine Learning approach has spread in recent years to go beyond the limits of classical statistical approaches. Nam and collaborators [20] use such method to detect nausea in VR using various bio-signals (EEG, ECG, PPG, SCL, EOG, SKT). Results seem promising as they are able to partially detect nausea in real time [20]. Automatic recognition of VR sickness: the Machine Learning approach To automatically detect VR sickness using physiological data, the use of Machine Learning algorithms seem relevant. In this approach, physiological and declared VR sickness are mapped using Machine Learning algorithms. In others words, the training of Machine Learning algorithms, using the supervised techniques [21], aims to infer the function between the input data (i.e., physiological data) and the output data (i.e., subjective labels). Indeed, Machine Learning algorithms have the ability to learn without being explicitly programmed [22]. After training, the models should be able to automatically recognize in real time, for any new user, the VR sickness related to the physiological data without requesting a subjective response. Physiological signals and subjective VR sickness level were collected to investigate the possibility of detecting VR sickness automatically. A large and relevant labeled dataset (i.e., physiological data labeled with subjective evaluation of VR sickness) to train models is fundamental to obtain an efficient system of VR sickness detection. So, Editorial user research lab, Ubisoft Paris and b<>com decided to cooperate with the intent to collect and analyze consistent amounts of physiological data of test users viewing VR content. Contrary to previous studies [19], [20] the aim of the current paper is to develop and evaluate a new solution more adapted to the industrial context than previous approaches based on invasive and/or expensive sensors (e.g., EEG or eye tracking). METHOD 27 participants (22 men and 5 women average age: 25.93 years; standard deviation: 4.39) were recruited by Ubisoft. Participants were requested to test three VR game prototypes during 30 minutes. The prototypes were interactive games currently under development and they implied a relevant amount of camera’s movements. The first game was a space simulation using a third-person point of view. The second was an arcade car racing game (in first-person and third-person point of view) and the third was a space firstperson shooter. To increase the probability of VR sickness we didn’t implement in these prototypes any of the typical countermeasures (i.e. Reduction of the peripheral vision) applied in the gaming industry to prevent VR sickness. The participants were informed that they were free to stop the experiment at any time. In order to induce various levels of VR sickness, the game’s levels tested by the participants were designed to increase progressively the VR sickness induction. VR content was presented using the “Oculus Rift” ® or “HTC Vive” 2 ® devices. Measures Two types of measures were collected: the physiological data and subjective data of the users’ sickness. The physiological data was collected using the “Shimmer GSR+”®. This sensor measures the electrodermal activity (EDA) and the Blood Pulse Volume (B",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
74fd6de3651cb68b270d87f358e1acfe90a810d6,https://www.semanticscholar.org/paper/74fd6de3651cb68b270d87f358e1acfe90a810d6,"The Catlin Seaview Survey – kilometre‐scale seascape assessment, and monitoring of coral reef ecosystems","Marine ecosystems provide critically important goods and services to society, and hence their accelerated degradation underpins an urgent need to take rapid, ambitious and informed decisions regarding their conservation and management. 
The capacity, however, to generate the detailed field data required to inform conservation planning at appropriate scales is limited by time and resource consuming methods for collecting and analysing field data at the large scales required. 
The ‘Catlin Seaview Survey’, described here, introduces a novel framework for large-scale monitoring of coral reefs using high-definition underwater imagery collected using customized underwater vehicles in combination with computer vision and machine learning. This enables quantitative and geo-referenced outputs of coral reef features such as habitat types, benthic composition, and structural complexity (rugosity) to be generated across multiple kilometre-scale transects with a spatial resolution ranging from 2 to 6 m2. 
The novel application of technology described here has enormous potential to contribute to our understanding of coral reefs and associated impacts by underpinning management decisions with kilometre-scale measurements of reef health. 
Imagery datasets from an initial survey of 500 km of seascape are freely available through an online tool called the Catlin Global Reef Record. Outputs from the image analysis using the technologies described here will be updated on the online repository as work progresses on each dataset. 
Case studies illustrate the utility of outputs as well as their potential to link to information from remote sensing. The potential implications of the innovative technologies on marine resource management and conservation are also discussed, along with the accuracy and efficiency of the methodologies deployed. 
 
 
Copyright © 2014 John Wiley & Sons, Ltd.",,2014.0,10.1002/AQC.2505,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
afaf5aa4eb9f8709869cbc05c964e7eab413a785,https://www.semanticscholar.org/paper/afaf5aa4eb9f8709869cbc05c964e7eab413a785,Autonomous diagnostics and prognostics through competitive learning driven HMM-based clustering,A prerequisite to effective wide-spread deployment of condition-based maintenance (CBM) practices is effective diagnostics and prognostics. This paper presents a novel method for employing HMMs for autonomous diagnostics as well as prognostics. The diagnostics module exploits competitive learning to achieve HMM-based clustering. The prognostics module builds upon the diagnostics module to compute joint distributions for health-state transition times. The proposed methods were validated on a physical test bed; a drilling machine.,"Proceedings of the International Joint Conference on Neural Networks, 2003.",2003.0,10.1109/IJCNN.2003.1223951,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dda04ae60de9b137150a8f844ac9b2bedd49091d,https://www.semanticscholar.org/paper/dda04ae60de9b137150a8f844ac9b2bedd49091d,Near Cloud: Low-cost Low-Power Cloud Implementation for Rural Area Connectivity and Data Processing,"Information and communication technologies (ICTs) has enabled growth in developed countries and urban cities through improvements in communication systems, devices and applications. In rural areas, especially in developing countries, ICT penetration is not as high, often due to lack of available infrastructure and funding. With the increasing availability of Internet-of-Things (IoT) devices, low-cost large-scale deployments have become possible even in rural areas. We design, develop and implement, Near Cloud, a cloud-less platform that allows users and IoT devices to communicate and share information. This is built on top of a wireless mesh network (WMN) of low-cost, low-power IoT devices and deployed in areas where there is little to no Internet connectivity. To inject ICT and help bridge the digital divide in rural areas, Near Cloud provides functionalities such as web servers on nodes, accessibility to all users via Wi-Fi, and various data processing including image processing and machine learning. We will show applicability of Near Cloud in improving rural education, health care facilities, disaster response and agriculture.",2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC),2018.0,10.1109/COMPSAC.2018.10307,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a1186207dd9e25b67c89067f0913bb0847d791f,https://www.semanticscholar.org/paper/2a1186207dd9e25b67c89067f0913bb0847d791f,Real-time Topic Models for Crisis Counseling,"The proliferation of text-based crisis counseling platforms in recent months has opened an exciting opportunity for applied machine learning to (1) provide practical assistance for human counselors who provide emotional and practical support and (2) analyze counselor-caller interactions to build a landscape of the distribution of mental health issues experienced by callers on an unprecedented scale. We present Fathom, a natural language interface powered by topic models to help crisis counselors on Crisis Text Line, a new 911-like crisis hotline that takes calls via text messaging. We apply a mixed-initiative labeled LDA model to analyze counselor-caller conversations and use them to power real-time visualizations aimed at mitigating counselor cognitive load. We discuss three key aspects of crisis counseling and why topic models are suitable for mining this phenomenon. We propose new variants of topic models inspired by the practical constraints posed by their real-time deployment.",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
687dddcceb3b5fdb4bc91ece69f19f7f913b43f8,https://www.semanticscholar.org/paper/687dddcceb3b5fdb4bc91ece69f19f7f913b43f8,Pilot study on strategies in sensor placement for robust hand/wrist gesture classification based on movement related changes in forearm volume,"Force Myography (FMG) is novel method of tracking functional motor activity using volumetric changes associated with muscle function. With comparable accuracy and multiple advantages over traditional methods of functional motor activity tracking, FMG has made leaps and bounds in terms of applications in human-machine interfaces and healthcare devices. As a field that is rapidly gaining popularity in health innovation, the aim of this paper is to contribute to our understanding of the nature FMG methods and establish it as a robust and reliable technique. The main point of exploration for this study is the impact of sensor placement and spatial coverage on FMG methods. Five participants were invited to perform a series of isolated wrist motions and hand gestures while wearing custom built FMG devices. Linear Discriminant Analysis (LDA) machine learning models were developed using 80% of the data for training and 20% for testing. Overall, the accuracy of the LDA models ranged from 75% to 100% across all subjects and dimensions of FMG data. The model accuracy improved when increasing the spatial coverage from 1 FMG band to 2, but it did not increase further with additions. The results also showed that the improved accuracy offered by a large spatial coverage of FMG data can be approximated by lower spatial coverage if sensors were place in an optimal location. This location was indicated to be midway between the wrist and the collective muscle bellies of intrinsic forearm muscles. The knowledge generated from this work aims serve as a guide towards the development of portable FMG based technology for widespread deployment in the general population. The hope is that the long-term benefits of continued FMG research will address issues in healthcare associated with disparities in access to medical technologies.",2016 IEEE Healthcare Innovation Point-Of-Care Technologies Conference (HI-POCT),2016.0,10.1109/HIC.2016.7797693,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8daef234828a5b33f5a058b83f8884ec2fe53802,https://www.semanticscholar.org/paper/8daef234828a5b33f5a058b83f8884ec2fe53802,PANDA: Facilitating Usable AI Development,"Recent advances in artificial intelligence (AI) and machine learning have created a general perception that AI could be used to solve complex problems, and in some situations over-hyped as a tool that can be so easily used. Unfortunately, the barrier to realization of mass adoption of AI on various business domains is too high because most domain experts have no background in AI. Developing AI applications involves multiple phases, namely data preparation, application modeling, and product deployment. The effort of AI research has been spent mostly on new AI models (in the model training stage) to improve the performance of benchmark tasks such as image recognition. Many other factors such as usability, efficiency and security of AI have not been well addressed, and therefore form a barrier to democratizing AI. Further, for many real world applications such as healthcare and autonomous driving, learning via huge amounts of possibility exploration is not feasible since humans are involved. In many complex applications such as healthcare, subject matter experts (e.g. Clinicians) are the ones who appreciate the importance of features that affect health, and their knowledge together with existing knowledge bases are critical to the end results. In this paper, we take a new perspective on developing AI solutions, and present a solution for making AI usable. We hope that this resolution will enable all subject matter experts (eg. Clinicians) to exploit AI like data scientists.",ArXiv,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6b77b4235bd455cf6df68cfa4fe4e2aa9401d06c,https://www.semanticscholar.org/paper/6b77b4235bd455cf6df68cfa4fe4e2aa9401d06c,Ethics in artificial intelligence: introduction to the special issue,,Ethics and Information Technology,2018.0,10.1007/s10676-018-9450-z,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
470e5e3200a8d2253242c32e641ed3a9e37817a8,https://www.semanticscholar.org/paper/470e5e3200a8d2253242c32e641ed3a9e37817a8,A Data Mining Framework for Activity Recognition in Smart Environments,"Recent years have witnessed the emergence of Smart Environments technology for assisting people with their daily routines and for remote health monitoring. A lot of work has been done in the past few years on Activity Recognition and the technology is not just at the stage of experimentation in the labs, but is ready to be deployed on a larger scale. In this paper, we design a data-mining framework to extract the useful features from sensor data collected in the smart home environment and select the most important features based on two different feature selection criterions, then utilize several machine learning techniques to recognize the activities. To validate these algorithms, we use real sensor data collected from volunteers living in our smart apartment test bed. We compare the performance between alternative learning algorithms and analyze the prediction results of two different group experiments performed in the smart home.",2010 Sixth International Conference on Intelligent Environments,2010.0,10.1109/IE.2010.22,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8ea6ebd950bdec182f4ad034d81cb6c2f96db383,https://www.semanticscholar.org/paper/8ea6ebd950bdec182f4ad034d81cb6c2f96db383,Revolutionizing Future Healthcare using Wireless on the Walls (WoW),"Following the standardization and deployment of fifth generation (5G) network, researchers have shifted their focus to beyond 5G communication. Existing technologies have brought forth a plethora of applications that could not have been imagined in the past years. Beyond 5G will enable us to rethink the capability, it will offer in various sectors including agriculture, search and rescue and more specifically in the delivery of health care services. Unobtrusive and non-invasive measurements using radio frequency (RF) sensing, monitoring and control of wearable medical devices are the areas that would potentially benefit from beyond 5G. Applications such as RF sensing, device charging and remote patient monitoring will be a key challenge using millimetre (mmWave) communication. The mmWaves experience multi-path induced fading, where the rate of attenuation is larger as compared to the microwaves. Eventually, mmWave communication systems would require range extenders and guided surfaces. A proposed solution is the use of intelligent reflective surfaces, which will have the ability to manipulate electromagnetic (EM) signals. These intelligent surfaces mounted and/or coated on walls aka - Intelligent Walls are planar and active surfaces, which will be a key element in beyond 5G and 6G communication. These intelligent walls equipped with machine learning algorithm and computation power would have the ability to manipulate EM waves and act as gateways in the heterogeneous network environment. The article presents the application and vision of intelligent walls for next-generation healthcare in the era of beyond 5G.",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f3646a4cc35ed517ebe7662840b2738e2820139f,https://www.semanticscholar.org/paper/f3646a4cc35ed517ebe7662840b2738e2820139f,ASSESS MS: supporting the clinical assessment of Multiple Sclerosis using Kinect,"We present an early prototype of the ASSESS MS system, developed to help health professionals more accurately monitor the progression of Multiple Sclerosis (MS). Specifically, the system aims to detect and quantify changes in motor dysfunction more objectively and accurately than human assessors. We focus on key interaction design decisions needed to deploy a machine-learning based system in a real clinical context.",PervasiveHealth,2014.0,10.4108/ICST.PERVASIVEHEALTH.2014.255429,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1c31d738fb1abac291cff3b67067b00c88740ff6,https://www.semanticscholar.org/paper/1c31d738fb1abac291cff3b67067b00c88740ff6,Autonomous diagnostics and prognostics in machining processes through competitive learning-driven HMM-based clustering,"A prerequisite to widespread deployment of condition-based maintenance (CBM) systems in industry is autonomous yet effective diagnostics and prognostics algorithms. The concept of ‘autonomy’ in the context of diagnostics and prognostics is usually based on unsupervised clustering techniques. This paper employs an unsupervised competitive learning algorithm to perform hidden Markov model (HMM) based clustering of multivariate temporal observation sequences derived from sensor signal(s). This method improves autonomy of the diagnostic engine over the more traditional classifier based diagnostics models. Classifier models, such as the model presented by Baruah and Chinnam [Baruah, P. and Chinnam, R.B., 2005. HMM for diagnostics and prognostics in machining processes. International Journal of Production Research, 43 (6), 1275–1293] employ ‘labelled’ feature vectors for supervised model building and subsequent health-state classification during condition monitoring. Improving the autonomy of the diagnostics model also improves the autonomy of the prognostics module that often builds upon information extracted through the diagnostics module. We have validated the proposed methods on a physical test-bed that involved monitoring drill-bits on a CNC machine outfitted with thrust-force and torque sensors. Experimental results demonstrate the ability of this method to estimate on-line the remaining-useful-life of a drill-bit with significant accuracy.",,2009.0,10.1080/00207540802232930,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c6f2f23b95cc8d441c5a9d63270f9bb3cee4edeb,https://www.semanticscholar.org/paper/c6f2f23b95cc8d441c5a9d63270f9bb3cee4edeb,The Role of Technology in Health Care Innovation: A Commentary,"Information and communication technologies offer the opportunity for tremendous innovation in healthcare. Technology-based therapeutic and care coordination systems, that embrace web-, mobile-, sensing-, computing, and bioinformatics technologies, offer considerable promise for enabling entirely new models of healthcare both within and outside of formal systems of care and offer the opportunity to have a large public health impact. 
 
In a recent article, Linda Rosenberg highlights three primary changes she sees evolving within U.S. healthcare policy and practice, including increasing: (1) consumer engagement in their own care management, (2) integration of physical care and mental healthcare within care settings, and (3) data-driven care that measures outcomes and is responsive to performance metrics (Rosenberg, 2012). 
 
We propose that technology can play a key role in all three of these evolutions, plus more. First, technology affords a new model for enabling consumers to play a central role in selecting and helping to define the course of their own healthcare. A wide array of tools exist to monitor and capture real-time data about individuals’ behavioral and physiological states (e.g., via user input into mobile applications, wearable sensors and/or smartphone sensors). Additionally, there has been an explosion of research and development activities leading to the creation of self-directed tools that provide on-demand, educational or therapeutic support anytime/anywhere to help individuals manage their own health behavior. These tools may also provide individuals with the option to engage an extended support network in their own healthcare management (e.g., by sharing their health behavior data with family and friends to both empower and support them; by participating in virtual supportive communities, etc.). Further, decision support tools are increasingly being developed to help individuals better understand, access, and make choices about treatment. 
 
Second, although integration of behavioral healthcare into care settings that have largely managed physical health holds great promise for increasing coordination, quality, and impact of care, this evolution also creates a scenario in which already overburdened clinicians may not feel like they have the expertise, time, or resources to effectively address the behavioral health (e.g., substance use, mental health) needs of their clients. Technology offers tremendous opportunity to facilitate integrated care. Technology-based care systems, grounded in science-based approaches to promote health behavior, offer the potential to concurrently address an array of chronic illnesses and behavioral health issues in a manner that is optimally responsive to each patient’s needs. In this way, technology may reduce disease-specific, siloed care and offer countless opportunities for tailoring behavioral monitoring and intervention delivery for each individual and in response to changing health behavior trajectories over time. 
 
Third, embracing technology as part of the fundamental infrastructure for healthcare delivery allows for detailed data capture that can enable a careful examination of outcomes, including at the patient, provider, organizational and system levels. In some cases, this may optimally occur when electronic health records containing data captured within the care setting are integrated with data captured via other electronic media used by patients to monitor their health behavior outside of care settings. And, in other cases, detailed data capture can help individuals identify meaningful patterns in their own behavioral health. 
 
A growing body of research has demonstrated the acceptability, effectiveness, and cost-effectiveness of technology-based therapeutic tools (e.g., Marsch & Ben-Zeev, 2012). The widespread reach and ‘just-in-time’ therapeutic support they provide may help to prevent escalation of symptoms and promote sustained support for health behavior. Additionally, given the ubiquity of technology, including rapidly growing access to the Internet and smartphones among diverse communities, an approach to healthcare that embraces technology may play a key role in reducing healthcare disparities. 
 
Technology may increase our ability to pursue the World Health Organization’s definition of health, which embraces complete mental, physical and social well-being and not merely the absence of disease and infirmity (WHO, 1948). We may not get all the way there, but we may get closer than ever before. Unlike traditional medical care, which is simply a periodic visitor in the lives of people, technology can be there every minute of every day. It can measure, analyze, and intervene at any time and do so in virtually all aspects of life (many of which are outside the traditional purview of healthcare but which affect wellbeing). Technology in cars can prevent one from turning left into an oncoming truck. It can be used to measure gait to determine whether a person’s balance or cognitive well-being has deteriorated. It can offer games to relax, information to guide, or warnings to prepare individuals when weather becomes dangerous. Technology can relieve loneliness and isolation, speed productivity, and drive and park a car. All these things are not dreams; they are operational right now. Of course, the use of technology must be tailored to the needs and assets of individuals, families, and communities and be under their control. But, if offered in this way, technology allows for the potential to touch virtually every part of life that affects wellbeing. 
 
In order to fully realize this potential, however, a number of key challenges need to be tackled. First, although a large number of technology-based therapeutic tools have been developed, a unified, coordinated, and scalable technology-based system has not yet been fully developed. In order for this approach to have a large impact on population health, an understanding of the optimal combination of tools to include in a technology-based care delivery system is needed. Additionally, an understanding of the best model for integrating and deploying such a system, in a manner that brings value to all relevant stakeholders, is critical. 
 
Relatedly, the cultural divide between healthcare specialists and technology specialists needs to be bridged. A number of groups have already launched initiatives to facilitate coordinated efforts among a diverse group of health specialists and technologists, but an ongoing and focused dialogue is needed to achieve the end goal product. 
 
Additionally, current reimbursement models are not yet structured to accommodate many technology-based therapeutic tools in their payer models. The way in which these reimbursement models are structured over time will undoubtedly have a substantive impact on the adoption and sustained use of this approach. 
 
There are reasons to be both excited and cautious about this evolution. Although technology targeting behavioral health can offer valuable tools to behavioral health specialists, it will likely also force a transition in care delivery models. As mentioned above, there are already hundreds of research articles demonstrating that technology-based behavioral interventions, such as those targeting depression, anxiety disorders and substance use disorders, can be as effective as clinicians who treat these disorders. With increasing consumer access and demand for technology-based therapeutic tools, behavioral health specialists will need to embrace this evolution and evolve along with it. Professionals will need to view technology as a powerful partner in improving quality and productivity of behavioral healthcare. 
 
We recognize that there will be resistance by some to this change. But we see evidence of similar trends in virtually every labor-intensive profession, including our own. Faculty members at universities are finding they need to adjust to the prospect that hundreds of thousands of people can (for many topics) learn as effectively from computers as they can in a classroom. Researchers are finding that, by leveraging technology, mega research studies can be conducted in much less time, include more diverse participant representation, and address many more research questions than ever before. Statisticians may find that data mining and machine learning, along with massive volumes of data, can change the need for inferential statistics. 
 
In many ways, it is difficult to envision an evolution in healthcare, including the realization of the goals of the Affordable Care Act of 2010, without centrally embracing technology as a key part of a new model of healthcare. This is an exciting time of tremendous opportunity to transform healthcare delivery models. And, this is a time to seek out new horizons. We have the opportunity to broaden our goals and models of care to help people really understand the complex issues of our time and make decisions that are in their best interests and can help them meet their goals. Although much work is still needed, we look forward to the launch of innovative service delivery models at a population level that leverage the numerous, effective, technology-based tools we have available to optimize the reach, impact, and cost-effectiveness of healthcare.",Journal of dual diagnosis,2013.0,10.1080/15504263.2012.750105,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
35bcf5f8dfbdfbe72f60ca4218fdc3798224a940,https://www.semanticscholar.org/paper/35bcf5f8dfbdfbe72f60ca4218fdc3798224a940,Lynx: Automatic Elderly Behavior Prediction in Home Telecare,"This paper introduces Lynx, an intelligent system for personal safety at home environments, oriented to elderly people living independently, which encompasses a decision support machine for automatic home risk prevention, tested in real-life environments to respond to real time situations. The automatic system described in this paper prevents such risks by an advanced analytic methods supported by an expert knowledge system. It is minimally intrusive, using plug-and-play sensors and machine learning algorithms to learn the elder's daily activity taking into account even his health records. If the system detects that something unusual happens (in a wide sense) or if something is wrong relative to the user's health habits or medical recommendations, it sends at real-time alarm to the family, care center, or medical agents, without human intervention. The system feeds on information from sensors deployed in the home and knowledge of subject physical activities, which can be collected by mobile applications and enriched by personalized health information from clinical reports encoded in the system. The system usability and reliability have been tested in real-life conditions, with an accuracy larger than 81%.",BioMed research international,2015.0,10.1155/2015/201939,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
78c5da1bbf4e9a4acde195eab8d1a647329d69e6,https://www.semanticscholar.org/paper/78c5da1bbf4e9a4acde195eab8d1a647329d69e6,Pathological Test Type and Chemical Detection Using Deep Neural Networks: A Case Study Using ELISA and LFA Assays,"Purpose The gradual increase in geriatric issues and global imbalance of the ratio between patients and healthcare professionals has created a demand for intelligent systems with the least error-prone diagnosis results to be used by less medically trained persons and save clinical time. This paper aims at investigating the development of an image-based colourimetric analysis. The purpose of recognising such tests is to support wider users to begin a colourimetric test to be used at homecare settings, telepathology, etc. Design/methodology/approach The concept of an automatic colourimetric assay detection is delivered by utilising two cases. Training Deep Learning (DL) models on thousands of images of these tests using transfer learning, this paper i) classifies the type of the assay, and ii) classifies the colourimetric results. Findings This paper demonstrated that the assay type can be recognised using DL techniques with 100% accuracy within a fraction of a second. Some of the advantages of the pre-trained model over the calibration-based approach are robustness, readiness and suitability to deploy for similar applications within a shorter period of time. Originality/value To the best of our knowledge, this is the first attempt to provide Colourimetric Assay Type Classification (CATC) using DL. Humans are capable to learn thousands of visual classifications in their life. Object recognition may be a trivial task for humans, due to photometric and geometric variabilities along with the high degree of intra-class variabilities it can be a challenging task for machines. However, transforming visual knowledge into machines, as proposed, can support non-experts to better manage their health and reduce some of the burdens on experts.",Journal of Enterprise Information Management,2020.0,10.1108/jeim-01-2020-0038,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8bb097a893ca75a032dbb3c823acad04c0634286,https://www.semanticscholar.org/paper/8bb097a893ca75a032dbb3c823acad04c0634286,Beyond Mobile Apps: A Survey of Technologies for Mental Well-being,"Mental health problems are on the rise globally and strain national health systems worldwide. Mental disorders are closely associated with fear of stigma, structural barriers such as financial burden, and lack of available services and resources which often prohibit the delivery of frequent clinical advice and monitoring. Technologies for mental well-being exhibit a range of attractive properties which facilitate the delivery of state of the art clinical monitoring. This review article provides an overview of traditional techniques followed by their technological alternatives, sensing devices, behaviour changing tools, and feedback interfaces. The challenges presented by these technologies are then discussed with data collection, privacy and battery life being some of the key issues which need to be carefully considered for the successful deployment of mental health tool-kits. Finally, the opportunities this growing research area presents are discussed including the use of portable tangible interfaces combining sensing and feedback technologies. Capitalising on the captured data these ubiquitous devices offer, state of the art machine learning algorithms can lead to the develop",ArXiv,2019.0,10.1109/taffc.2020.3015018,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
289f59b8dd4dd50d65c21f57106df8e454096998,https://www.semanticscholar.org/paper/289f59b8dd4dd50d65c21f57106df8e454096998,Fish Freshness Estimation though analysis of Multispectral Images with Convolutional Neural Networks,"Quantification of food quality is a critical process for ensuring public health. Fish correspond to a particularly challenging case due to its high perishable nature as food. Existing approaches require laboratory testing, a laborious and timeconsuming process. In this paper, we propose a novel approach for evaluating fish freshness by exploiting the information encoded in the spectral profile acquired by a snapshot spectral camera. To extract the relevant information, we employ state-ofthe-art Convolutional Neural Networks and treat the problem as an instance of multi-class classification, where each class corresponds to a two-day period since harvesting. Experimental evaluation on individuals from the Sparidae (Boops sp.) family demonstrates that the proposed approach constitutes a valid methodology, offering both accuracy as well as effortless application. Introduction Fish are the most vulnerable foods since changes in fish fleshness are very rapid due to bacterial, enzymatic and oxidative causes. Fish spoilage is influenced by several factors such as the type of fish, the way of extinction and the method of preservation. Freshness, in addition to the quality value it offers to fish as a food, has a significant impact on its commercial value as a marketable commodity. European legislation categorizes fish into four categories based on their quality value as food, namely Excellent, Category A, Category B and Inadmissible. In the first category, the catches are classified immediately after their catch and in the latter category unsuitable for human consumption [1]. The traditional approach for estimating the freshness of a dietary product is using human senses like appearance, odor, flavor and texture [2]. Human senses however exhibit a very high degree of subjectivity and therefore are questioned in cases of a dispute. To address this issue, numerous laboratory evaluation processes have been developed. In this work, we describe an approach for estimating fish freshness by analyzing the spectral profile obtained from multispectral imagery using state-of-the-art machine learning methods and particularly, Convolutional Neural Networks (CNNs). The proposed approach offers a number of significant benefits compared to existing approaches including the extremely fast evaluation, the ability to perform in-situ estimation, and the non-discrictive nature of the method. The novelties of this work include: • The use of a state-of-the-art CNN for the automated extraction of appropriate spatio-spectral features; • Use of multispectral information for a snapshot spectral camera; • The creation of a new dataset which is made publicly available; • The demonstration of fish freshness estimation system using optical information. The objective of this paper is the demonstration of the capabilities of state-of-the-art deep learning architectures and more specifically Convolutional Neural Networks (CNN) in analyzing multispectral images for estimating the freshness of fish. By fish freshness, we mean the estimation of the apparent days since harvest, which may not coincide with the actual number of days in cases of problematic storage conditions. The targeted scenario involves a compact and portable system which will consist of a snapshot spectral imaging system and a mini-pc system like the NVIDIA Jetson, while the interfacing with the user will be achieved though transmission of the processed images to his/her smartphone, as shown in Figure 1. Figure 1. Overview of the system. State-of-the-art Degradation in fish quality is due to the posthumous enzyme activity which leads to the breakdown of cell membranes which in turn leads to the exponential increase in the bacterial load, causing the sever degradation of the skin. Currently, different types of instruments are available for the quantification of fish freshness which exploit the alteration of different physiological parameters. Different approaches that have been presented in the liturate include methods based on enzyme biosensors, electrochemical biosensors, colorimetric sensor, electronic tongue, and different types of spectroscopy[3]. Multispectral imaging, a particular case of spectroscopy is among the most prominent solutions for this problem due to the numerous benefits such method offer including the in-situ and real-time estimation. In this work, we employ Snapshot Spectral Imaging technologies which in addition to the general benefits of spectroscopy, do not require scaning the item over a conveyor belt. This techology has been recently employed for classifying generic objects [6], as well for food quality monitoring including detecting plant desease [7] and red-meat classification [8]. Method The proposed system currently consists of a snapshot spectral imaging camera and a data processing pipeline based on machine learning for estimating the elapsed time between harvesting and imaging. Specifically, observations are acquired over the visible-near IR range (400-1000nm) using a snapshot spectral camera from Photon Focus (MV1-D2048x1088-HS02-96G2), equipped with an IMEC sensors acquiring snapshot spectral imagery of 2048× 1088 pixels at 42fps. Unlike traditional linescan approaches, is able to acquire the entire spectral profile of a scene from a single image (exposure). This capability makes snapshot spectral cameras ideal for the deployment in realtime environments, removing the need for specialized platforms like conveyor platforms. The quantum efficiency of each band is shown in Figure 2. Figure 2. Quantum efficiency associated with each spectral band. An example of the appearance of fish individuals at two different wavelength on day 1 and day 4 is shown in Figure 3. In this example, one can observe that regions around the tail and around the eye appear to change appearance with the passing of time, an observation which is consistent with the known sensory tests. Figure 3. Examples of fish imaged at 608 and 815nm on the first and forth",,2020.0,10.2352/issn.2470-1173.2020.12.fais-171,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cdebf1de7b2ccb852b203708f9dc2e584a2abb0c,https://www.semanticscholar.org/paper/cdebf1de7b2ccb852b203708f9dc2e584a2abb0c,Comparing Human-Robot Proxemics between Virtual Reality and the Real World,"Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of Human-Robot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other. Comparing Human-Robot Proxemics between Virtual Reality and the Real World Rui Li KTH Royal Institute of Technology Stockholm, Sweden Rui3@kth.se ABSTRACT Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other.Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI). To fully deploy the potential of VR and benefit HRI studies, we need to establish the basic understanding of the relationship between the physical, real-world interaction (Live) and VR. This study compared Live and VR HRI with a focus on proxemics, as proxemics preference can reflect comprehensive human intuition, making it suitable to be used to compare Live and VR. To evaluate the influence of different modalities in VR, virtual scenes with different visual familiarity and spatial sound were compared as well. Lab experiments were conducted with a physical Pepper robot and its virtual copy. In both Live and VR, proxemics preferences, the perception of the robot (competence and discomfort) and the feeling of presence were measured and compared. Results suggest that proxemic preferences do not remain consistent in Live and in VR, which could be influenced by the perception of the robot. Therefore, when conducting HRI experiments in VR, the perceptions of the robot need be compared before the experiments. Results also indicate freedom within VR HRI as different VR settings are consistent with each other. INTRODUCTION Virtual Reality (VR) is gaining more and more popularity as a research tool in the field of HumanRobot Interaction (HRI) [1][2][3][4]. VR has been used to test teleoperation and collect demonstration data to train machine learning algorithms, which showcased the effectiveness of learning visuomotor skills using data collected by consumer-grade devices [1]. VR teleoperation systems were proposed to crowdsource robotic demonstrations at scale [2]. A VR simulation framework was also proposed to replace the physical robot, as VR can enable high level abstraction in embodiment and multimodal interaction [3]. VR has also been used as a rapid prototyping tool to design in-vehicle interactions and interfaces for self-driving cars, which showed the evocation to genuine responses from test participants [4]. Compared to other HRI experiment methods, VR as an emerging interactive media provides unique advantages. VR HRI has the potential of having higher immersion and fidelity than picture based HRI, video-based HRI and simulated HRI. In situations where the perception of the robot is challenging, compared to on-screen viewing, VR display showed significant improvement on collaborative tasks [5]. When comparing VR HRI to the physical, realworld interaction (Live HRI), there is a trade-off between the two. VR experiences still cannot replace physical experiences due to system limitation, and limited interaction modalities etc. [6]. For example, system limitations such as limited field of view and low display resolution could reduce immersion and presence of the VR experience, resulting in different behaviors from Live experiments. Limited interaction modalities, such as the absence of touch, means that the participant could not feel the robot or even go through the robot, which could potentially break the entire interaction. Figure 1: Photograph of the Live experiment setting However, with the help of the distribution of consumer-grade VR devices and online crowdsourcing platforms, VR HRI has the potential to gain massive data for training robotic behavior and studying HRI related issues. Data collection through VR can also reduce noise and improve the data quality [1], which help to ease data processing and algorithm training. Furthermore, VR HRI experiments can test concepts and interactions without physical robots, making it more resource efficient and less expensive than Live HRI. Less hardware also means that the experiment will be less cumbersome to set up, easier to be reproduced and to ensure experiment quality. In this study, HRI Proxemics (the preferred personal space between a human and a robot) was compared to give a better justification and more basic understanding of the relationship between Live and VR. Proxemics preferences rely on lower level intuition [7], therefore, reflect the differences in the perceptions between Live and VR better. Compared to other HRI subject such as conversational (audio) or gaze behavior (visual), which are more modality dependent, proxemics can give a comprehensive understanding of the human responses. In addition, variations of modalities in VR can greatly influence human perception. For example, a higher visual familiarity of the physical environment in VR can decrease the effect of distance distortion [8]. Auditory inputs play another important role in VR, the addition of spatial sound can increase the sense of presence in VR and provide sound localization [9]. Thus, this work also compares VR settings with variance in modalities to evaluate the impacts of visual familiarity and spatial sound on VR HRI experiments. A 2 x 3 mixed design experiment was conducted to evaluate the differences between Live and VR HRI, as well as the influence of visual familiarity and spatial sound in VR. For the Live HRI, the pepper robot from Softbank Robotics was used (Figure 1). In the VR HRI, a 3D model of the same robot was used. To measure visual familiarity, the VR scene was created in Blender based on a 3D scan of the physical lab. The spatial sound was created by enabling the movement of the physical robot, due to the difficulties of engineering spatial sound. The interaction was implemented in Unity. As an objective measurement for proxemics preference, the minimum comfort distance (MCD) was measured. In addition, for the psychological perception of the experience, the feeling of presence was measured with the SUS questionnaire. For the perception of the robot, two relevant factors, competence and discomfort was measured with the ROSAS questionnaire.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
53c7ba5e970f1fa628d6edda01b3e12751d0a85d,https://www.semanticscholar.org/paper/53c7ba5e970f1fa628d6edda01b3e12751d0a85d,Improving the Accuracy and Transparency of Underwriting with AI to Transform the Life Insurance Industry,"Life insurance provides trillions of dollars of financial security for hundreds of millions of individuals and fami­lies worldwide. To simultaneously offer affordable products while managing this financial ecosystem, life-insurance companies use an underwriting process to assess the mortality risk posed by individual applicants. Traditional underwriting is largely based on examining an applicant’s health and behavioral profile. This manual process is incompatible with expectations of a rapid customer experience through digital capabilities. Fortunately, the availability of large historical data sets and the emergence of new data sources provide an unprecedented opportunity for artificial intelligence to transform under­writing in the life-insurance industry with standard measures of mortality risk. We combined one of the largest application data sets in the industry with a responsible artificial intelligence framework to develop a mortality model and life score. We describe how the life score serves as the primary risk-driving engine of deployed algorithmic underwriting systems and demonstrate its high level of accuracy, yielding a nine-percent reduction in claims within the healthiest pool of applicants. Additionally, we argue that, by embracing transparency, the industry can build consumer trust and respond to a dynamic regulatory environment focused on algorithmic decision-making. We present a consumer-facing tool that uses a state-of-the-art method for interpretable machine learning to offer transparency into the life score.",AI Mag.,2020.0,10.1609/aimag.v41i3.5320,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ca87844781b6e424aa88391b733f5ef5a4485a53,https://www.semanticscholar.org/paper/ca87844781b6e424aa88391b733f5ef5a4485a53,Human centered AI design for clinical monitoring and data management,"
 
 
 In clinical settings, significant resources are spent on data collection and monitoring patients' health parameters to improve decision-making and provide better care. With increased digitization, the healthcare sector is shifting towards implementing digital technologies for data management and in administration. New technologies offer better treatment opportunities and streamline clinical workflow, but the complexity can cause ineffectiveness, frustration, and errors. To address this, we believe digital solutions alone are not sufficient. Therefore, we take a human-centred design approach for AI development, and apply systems engineering methods to identify system leverage points. We demonstrate how automation enables monitoring clinical parameters, using existing non-intrusive sensor technology, resulting in more resources toward patient care. Furthermore, we provide a framework on digitization of clinical data for integration with data management.
 
 
 
 Activities of Daily Living (ADLs) are essential parameters, necessary for evaluating patients in mental health wards. Ideally logging the parameters should take place at hourly intervals; however, time constraints and lack of resources restrict the nursing staff to consolidating the overall impression during the day, relying on what they recall. Using design methods, sensors (e.g. infrared, proximity, pressure) are used to automate the acquisition of data for machine learning that correspond to the ADLs, considering privacy and other medical requirements.
 
 
 
 We present a concept of a room with sensors that can be deployed in clinical settings. Sensor data log ADLs, and provide machine learning data. A theoretical framework demonstrates how collected data can be used in electronic/medical health records.
 
 
 
 Data acquisition of the ADLs with automation enable variable specificity and sensitivity on-demand. It further facilitates interoperability and provides data for machine learning.
 
 
 
 Our research demonstrates automated data acquisition techniques for clinical monitoring. Human centered AI design approach enables on-demand analysis of ADLs for mental health treatment.
",European Journal of Public Health,2020.0,10.1093/eurpub/ckaa165.225,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ff29ea3641c45e90157a04bd47ed6d497ccac14,https://www.semanticscholar.org/paper/2ff29ea3641c45e90157a04bd47ed6d497ccac14,Implementation of Data Mining from Social Media for Improved Public Health Care,"To improve public health care outcomes with reduced cost, this research proposed a framework which focuses on the positive and negative symptoms of illnesses and the side effects of treatments. However, previous studies have been limited as they neither identified influential users nor discussed how to model forms of relationships that affect network dynamics and determine the accurate ranking of certain end user’s feedbacks. In this research, a two-step analysis framework is proposed as the system. In the first level, the system utilized exploratory analysis and clustered users and their useful feedbacks through self-organizing maps (SOM). In the second level, the system developed three lists of negative and positive feedbacks and treatment symptoms caused by implanting the SOM that considered accurate ranking by calculating the frequency of each term of interests. The feasibility of the proposed solution is confirmed as performance evaluations of the system in terms of computational costs. The results showed that these solutions are reasonable computational costs relative to memory and processor usage. Keywords—Data mining; social media; medical data; end user feedbacks; positive terms; negative terms; symptoms I. RESEARCH MOTIVATIONS AND BACKGROUND Data mining from social media recently gained the attention of many important businesses and industries. Data mining is empowered by the recent advances in big data analysis as well as the network modeling of social media forums and websites, which are integrated to achieve knowledge discovery solutions and to extract useful information from various fields [1]. The health care industry is one of the most important fields that can be significantly enhanced by modern data mining techniques that allow the discovery of certain trend patterns as a product of the social media feedbacks generated dynamically from the experiences and opinions of end users [2]. These techniques can be applied to drug feedbacks in social media which can help manufacturers continuously enhance their products at reducedcosts. Successful data mining from social media can result in numerous benefits for business owners and manufacturers [3]; however, a number of challenges should be addressed first to reach the acceptable level and wide deployment of this new technology [4]. In addition, classical data mining techniques and algorithms should be empowered with an intelligent pattern recognition tool to predict and visualize the common trends of the data in general. Moreover, it should weigh certain descriptions or feedbacks based on their frequency and eliminate some neutral words as a filtration technique in the preprocessing stage. Different online forums contain feedbacks that should be network-modelled for a more convenient analysis. All these challenges are the main inspirations that motivated this research. The main contributions of this work can be considered as developing a feasible text data-mining solution that can partition different users with certain ID by modeling their existence in different web forums. Furthermore, the accurate clustering of negative and positive feedbacks and the visualization of the overall positive or negative feedback trends in a reasonable computational cost solution is another benefit from this research. The basic concepts are explained in this section as a background of the research field and the proposed solutions. First, the processes of data collection and mining are considered challenging tasks given a large number of networks studied, and this requires a complex representation of the social network structure. The complexity of such structure is derived from network density and levels of the parents and nodes clustering social media contents. Network clustering involves complex, big, and parallel data processing to cover the analysis of each networks’ nodes representing certain user communities. A part of the network usually as small as the sample size is used for data collection. Future Technologies Conference (FTC) 2017 29-30 November 2017| Vancouver, Canada 235 | P a g e Traditionally, structuring and modelling social networks can extract useful information as topic trends and the trends of opinions and the linguistics properties play an effective role in this study. At the beginning, certain word filtration techniques are used to remove unwanted words, such as stop and stemming words [5]. The concept of the self-organizing map (SOM) is utilized in particular research fields; in the simplest terms, SOM is a predefined wordlist used to correlate with the large data from the social networks under the tests to extract positive and negative words [6]. Importantly, certain algorithms are used to determine the frequency of certain positive or negative words, so that weighing the word (in another meaning its effectiveness among other words) can be determined. Finally, simple statistical tools are used to identify a positive or negative trend and the most common words describing the symptoms of drug use. Similar solutions in the literature on disease surveillance for the case of Influenza-related community who share fluposting online is utilized through the technique text and structural data mining of web and social media (WSM) [7] [8]. In the critical analysis of the SOM and WSM techniques in the literature [9], [10], it can be concluded that SOM techniques have more advantages in terms of the capability of investigating the positive and negative feedbacks of treatments. This advantage can be achieved by mapping large dimensional information onto a low dimensional space. II. METHODOLOGIES OF THE PROPOSED SYSTEM A two-step framework is proposed as an investigatory analysis to evaluate the correlations between user posts and positive/negative words under a drug name. The correlation is obtained by using SOM. Using a network-based approach, the system enabled users and their posts to find the possible partition using complete linkages. The two processes involved with inter-social dynamic maps for reviewing SOM results are described below:  The correlation between user and judgment.  The partition between users and their posts. Regarded as an unsupervised technique, Self-OrganizingMap (SOM) is used to explore the survey dataset based on the artificial neural network. The representation of the SOM data is in multidimensional data such as two or three dimension. Based on the data compression of the vector quantization technique, the SOM process is used to reduce the dimensionality of sectors. The information is stored as a topological relationship within the training sets in a network. Therefore, large data sets are visualized with high dimensionality using SOM. The competitive learning approach of SOM has one neuron unconnected to the input and output layers for each training phase. Although the connection between the neurons is absent, communication exists between each phase through a neighborhood function. The proposed SOM approach is used to summarize and visualize the profiles of individual patients. This visualization process helps determine domain experts. The two perspectives involved in the process of accurately obtaining results are computational and scientific perspectives [11]. By using SOM in the computational perspective, feasibility is examined by extracting useful information from questionnaires. In the scientific perspective, the different types of patient diseases such as type-I diabetes are collected to understand the responses in the diabetes survey and suggest about domain experts to clinicians. By contrast, clinicians are required to take a survey about their patients. The mean, skewness, variance, and frequency are the traditional descriptive statistical methods, but it provides simplified conclusions. Thus, data are analyzed based on statistical machine learning tools with black box by clinicians. The SOM algorithm is used for mining correlations and clustering similar responses within the surveys. If the dimension is higher for clustered responses, then the data is visualized in a two-dimensional grid to reduce data complexity. Complexity is reduced by revealing more meaningful relationships and by understanding the dependencies among the survey responses. Previously, SOM is used to visually explore data areas such as health, lifestyle, nutrition, financial, gene expression, marine safety, and linguistics. Recently, SOM is utilized to explore questionnaire-based loneliness survey data. The present research also focuses on improving data interpretation by revealing possible associations between the tendency of item nonresponse and the background variables of participants. The flaw conclusion is obtained by item nonresponse which is related to the background variables of respondents, such as age and gender nonresponses. Considering the undetected non-causative relationships between independent and dependent variables, the nonresponse factors affected patient satisfaction. In the present study, item nonresponse does not refer to participants who fail to return the survey, but to the ones who choose not to respond to all questions. In the proposed approach, the issues involved in this research are included for data analysis. Large surveys have demonstrated that although respondents and non-respondents in patient satisfaction surveys may differ according to several demographic and clinical characteristics, the differences in satisfaction between them tend to be relatively small and non-respondents do not constitute a homogenous group. Many highly sophisticated statistical methods are used as a standard technique to handle the problem of missing responses. In the existing link method, the idea that missing data are not just a statistical nuisance but also contain valuable information as such is tested simply by including the number of item nonresponses per respondent as an explanatory variable in the models. The expected predictors of pati",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
59e10d1d4cd454635914cfd0ac5160a318fd0473,https://www.semanticscholar.org/paper/59e10d1d4cd454635914cfd0ac5160a318fd0473,UB09 Session 9,"In the domain of Wireless Sensor Networks (WSN), providing an effective security solution to protect the motes and their communications is challenging. Due to the hard constraints on performance, storage and energy consumption, normal network-security related techniques cannot be applied. Focusing on the ""Intrusion Detection"" problem, we propose a realworld application of our WSN Intrusion Detection System (WIDS). WIDS exploits the Weak Process Models to classify potential security issues in the WSN and to notify the operators when an attack tentative is detected. In this demonstration, we show how our IDS works, how it detects some basic attacks and how the IDS can evolve to fullfil the needs of secure WSN deployments. Download Paper (PDF) UB09.2 RESCUE: EDA TOOLSET FOR INTERDEPENDENT ASPECTS OF RELIABILITY, SECURITY AND QUALITY IN NANOELECTRONIC SYSTEMS DESIGN Authors: Cemil Cem Gürsoy1, Guilherme Cardoso Medeiros2, Junchao Chen3, Nevin George4, Josie Esteban Rodriguez Condia5, Thomas Lange6, Aleksa Damljanovic5, Raphael Segabinazzi Ferreira4, Aneesh Balakrishnan6, Xinhui Anna Lai1, Shayesteh Masoumian7, Dmytro Petryk3, Troya Cagil Koylu2, Felipe Augusto da Silva8, Ahmet Cagri Bagbaba8 and Maksim Jenihhin1 1Tallinn University of Technology, EE; 2Delft University of Technology, NL; 3IHP, DE; 4BTU Cottbus-Senftenberg, DE; 5Politecnico di Torino, IT; 6IROC Technologies, FR; 7Intrinsic ID B.V., NL; 8Cadence Design Systems GmbH, DE Abstract The demonstrator will introduce an EDA toolset developed by a team of PhD students in the H2020-MSCA-ITN RESCUE project. The recent trends for the computing systems include machine intelligence in the era of IoT, complex safety-critical applications, extreme miniaturization of technologies and intensive interaction with the physical world. These trends set tough requirements on mutually dependent extra-functional design aspects. RESCUE is focused on the key challenges for reliability (functional safety, ageing, soft errors), security (tamper-resistance, PUF technology, intelligent security) and quality (novel fault models, functional test, FMEA/FMECA, verification/debug) and related EDA methodologies. The objective of the interdisciplinary cross-sectoral team from Tallinn UT, TU Delft, BTU Cottbus, POLITO, IHP, IROC, Intrinsic-ID, Cadence and Bosch is to develop in collaboration a holistic EDA toolset for modelling, assessment and enhancement of these extra-functional design aspects. Download Paper (PDF)The demonstrator will introduce an EDA toolset developed by a team of PhD students in the H2020-MSCA-ITN RESCUE project. The recent trends for the computing systems include machine intelligence in the era of IoT, complex safety-critical applications, extreme miniaturization of technologies and intensive interaction with the physical world. These trends set tough requirements on mutually dependent extra-functional design aspects. RESCUE is focused on the key challenges for reliability (functional safety, ageing, soft errors), security (tamper-resistance, PUF technology, intelligent security) and quality (novel fault models, functional test, FMEA/FMECA, verification/debug) and related EDA methodologies. The objective of the interdisciplinary cross-sectoral team from Tallinn UT, TU Delft, BTU Cottbus, POLITO, IHP, IROC, Intrinsic-ID, Cadence and Bosch is to develop in collaboration a holistic EDA toolset for modelling, assessment and enhancement of these extra-functional design aspects. Download Paper (PDF) UB09.3 ASAM: AUTOMATIC SYNTHESIS OF ALGORITHMS ON MULTI CHIP/FPGA WITH COMMUNICATION CONSTRAINTS Authors: Amir Masoud Gharehbaghi, Tomohiro Maruoka, Yukio Miyasaka, Akihiro Goda, Amir Masoud Gharehbaghi and Masahiro Fujita, The University of Tokyo, JP Abstract Mapping of large systems/computations on multiple chips/multiple cores needs sophisticated compilation methods. In this demonstration, we present our compiler tools for multi-chip and multi-core systems that considers communication architecture and the related constraints for optimal mapping. Specifically, we demonstrate compilation methods for multi-chip connected with ring topology, and multi-core connected with mesh topology, assuming fine-grained reconfigurable cores, as well as generalization techniques for large problems size as convolutional neural networks. We will demonstrate our mappings methods starting from data-flow graphs (DFGs) and equations, specifically with applications to convolutional neural networks (CNNs) for convolution layers as well as fully connected layers. Download Paper (PDF) UB09.4 HEPSYCODE-MC: ELECTRONIC SYSTEM-LEVEL METHODOLOGY FOR HW/SW CO-DESIGN OF MIXED-CRITICALITY EMBEDDED SYSTEMS Authors: Luigi Pomante1, Vittoriano Muttillo1, Marco Santic1 and Emilio Incerto2 1Università degli Studi dell'Aquila DEWS, IT; 2IMT Lucca, IT Abstract Heterogeneous parallel architectures have been recently exploited for a wide range of embedded application domains. Embedded systems based on such kind of architectures can include different processor cores, memories, dedicated ICs and a set of connections among them. Moreover, especially in automotive and aerospace application domains, they are even more subjected to mixed-criticality constraints. So, this demo addresses the problem of the ESL HW/SW co-design of mixed-criticality embedded systems that exploit hypervisor (HPV) technologies. In particular, it shows an enhanced CSP/SystemC-based design space exploration step, in the context of an existing HW/SW co-design flow that, given the system specification is able to (semi)automatically propose to the designer: a custom heterogeneous parallel HPV-based architecture; an HW/SW partitioning of the application; a mapping of the partitioned entities onto the proposed architecture. Download Paper (PDF)Heterogeneous parallel architectures have been recently exploited for a wide range of embedded application domains. Embedded systems based on such kind of architectures can include different processor cores, memories, dedicated ICs and a set of connections among them. Moreover, especially in automotive and aerospace application domains, they are even more subjected to mixed-criticality constraints. So, this demo addresses the problem of the ESL HW/SW co-design of mixed-criticality embedded systems that exploit hypervisor (HPV) technologies. In particular, it shows an enhanced CSP/SystemC-based design space exploration step, in the context of an existing HW/SW co-design flow that, given the system specification is able to (semi)automatically propose to the designer: a custom heterogeneous parallel HPV-based architecture; an HW/SW partitioning of the application; a mapping of the partitioned entities onto the proposed architecture. Download Paper (PDF) UB09.5 CS: CRAZYSQUARE Authors: Federica Caruso1, Federica Caruso1, Tania Di Mascio1, Alessandro D'Errico1, Marco Pennese2, Luigi Pomante1, Claudia Rinaldi1 and Marco Santic1 1University of L'Aquila, IT; 2Ministry of Education, IT Abstract CrazySquare (CS) is an adaptive learning system, developed as a serious game for music education, specifically indicated for young teenager approaching music for the first time. CS is based on recent educative directions which consist of using a more direct approach to sound instead of the musical notation alone. It has been inspired by a paper-based procedure that is currently used in an Italian middle school. CS represents a support for such teachers who prefer involving their students in a playful dimension of learning rhythmic notation and pitch, and, at the same time, teaching playing a musical instrument. To reach such goals in a cost-effective way, CS fully exploits all the recent advances in the EDA domain. In fact, it is based on a framework composed of mobile applications that will be integrated with augmented reality HW/SW tools to provide virtual/augmented musical instruments. The proposed demo will show the main features of the current CS framework implementation. Download Paper (PDF)CrazySquare (CS) is an adaptive learning system, developed as a serious game for music education, specifically indicated for young teenager approaching music for the first time. CS is based on recent educative directions which consist of using a more direct approach to sound instead of the musical notation alone. It has been inspired by a paper-based procedure that is currently used in an Italian middle school. CS represents a support for such teachers who prefer involving their students in a playful dimension of learning rhythmic notation and pitch, and, at the same time, teaching playing a musical instrument. To reach such goals in a cost-effective way, CS fully exploits all the recent advances in the EDA domain. In fact, it is based on a framework composed of mobile applications that will be integrated with augmented reality HW/SW tools to provide virtual/augmented musical instruments. The proposed demo will show the main features of the current CS framework implementation. Download Paper (PDF) UB09.6 LABSMILING: A SAAS FRAMEWORK, COMPOSED OF A NUMBER OF REMOTELY ACCESSIBLE TESTBEDS AND RELATED SW TOOLS, FOR ANALYSIS, DESIGN AND MANAGEMENT OF LOW DATA-RATE WIRELESS PERSONAL AREA NETWORKS BASED ON IEEE 802.15.4 Authors: Carlo Centofanti, Luigi Pomante, Marco Santic and Walter Tiberti, University of L'Aquila, IT Abstract Low data-rate wireless personal area networks (LR-WPANs) are constantly increasing their presence in the fields of IoT, wearable, home automation, health monitoring. The development, deployment and testing of SW based on IEEE 802.15.4 standard (and derivations, e.g. 15.4e), require the exploitation of a testbed as the network grows in complexity and heterogeneity. This demo shows LabSmiling: a SaaS framework which connects testbeds deployed in a real-world-environment and the related SW tools that make available a meaningful (but still scalable) number of physical devices (sensor nodes) to developers. It provides a comforta",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c91a36fd2d8930f5ebe84e2512689ec8e70b362c,https://www.semanticscholar.org/paper/c91a36fd2d8930f5ebe84e2512689ec8e70b362c,Robust and Adaptive Signal Segmentation for Structural Monitoring Using Autonomous Agents,"Monitoring of mechanical structures is a Big Data challenge and includes Structural Health Monitoring (SHM) and Non-destructive Testing (NDT). The sensor data produced by common measuring techniques, e.g., guided wave propagation analysis, is characterized by a high dimensionality in the temporal and spatial domain. There are off- and on-line methods applied at maintenance- or run-time, respectively. On-line methods (SHM) usually are constrained by low-resource processing platforms, sensor noise, unreliability, and real-time operation requiring advanced and efficient sensor data processing. Commonly, structural monitoring is a task that maps high-dimensional input data on low-dimensional output data (information, which is feature extraction), e.g., in the simplest case a Boolean output variable “Damaged”. Machine Learning (ML), e.g., supervised learning, can be used to derive such a mapping function. But ML quality and performance depends strongly on the input data size. Therefore, adaptive and reliable input data reduction (that is feature selection) is required at the first layer of an automatic structural monitoring system. Assuming some kind of two-dimensional sensor data (or n-dimensional data in general), image segmentation can be used to identify Regions of Interest (ROI), e.g., of wave propagation fields. Wave propagation in materials underlie reflections that must be distinguished, especially in hybrid materials (e.g., combining metal and fibre-plastic composites) there are complex wave propagation fields. The image segmentation is one of the most crucial parts of image processing. Major difficulties in image segmentation are noise and the differing homogeneity (fuzziness and signal gradients) of regions, complicating the definition of suitable threshold conditions for the edge detection or region splitting/clustering. Many traditional image segmentation algorithms are constrained by this issue. Artificial Intelligence can aid to overcome this limitation by using autonomous agents as an adaptive and self-organizing software architecture, presented in this work. Using a collection of co-operating agents decomposes a large and complex problem in smaller and simpler problems with a Divide-and-Conquer approach. Related to the image segmentation scenario, agents are working mostly autonomous (de-coupled) on dynamically bounded data from different regions of a signal or an image (i.e., distributed with simulated mobility), adapted to the locality, being reliable and less sensitive to noisy sensor data. In this work, self-organizing agents perform segmentation. They are evaluated with measured high-dimensional data from piezo-electric acusto-ultrasonic sensors recording the wave propagation in plate-like structures. Commonly, SHM deploys only a small set of sensors and actuators at static positions delivering only a few temporal resolved sensor signals (1D), whereas NDT methods additionally can use spatial scanning to create images of wave signals (2D). Both one-dimensional temporal and two-dimensional spatial segmentation are considered to find characteristic ROI.",ECSA 2017,2017.0,10.3390/ECSA-4-04917,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ad98dbc77d5ae0e8a78b06ffd9616416d515f1dc,https://www.semanticscholar.org/paper/ad98dbc77d5ae0e8a78b06ffd9616416d515f1dc,Hardware And Embedded Algorithms For Real Time Variable Rate Fertiliser Applications,"Efficient use of fertilisers, in particular the use of Nitrogen (N), is one of the rate-limiting factors in meeting global food production requirements. While N is a key driver in increasing crop yields, overuse can also lead to negative environmental and health impacts. It has been suggested that Variable Rate Fertiliser (VRF) techniques may help to reduce excessive N applications. VRF seeks to spatially vary fertiliser input based on estimated crop requirements, however a major challenge in the operational deployment of VRF systems is the automated processing of large amounts of sensor data in real-time. Machine learning (ML) techniques have shown promise in their ability to process these large, high-velocity data streams, and to produce accurate predictions. This paper will use a simulation testing methodology on real hardware to compare two existing ML algorithms and a prototype implementation of a newly developed algorithm for their applicability to VRF application.",,2017.0,10.5281/ZENODO.895528,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0c758a42c3cb294373870564f42a0e7372fa296e,https://www.semanticscholar.org/paper/0c758a42c3cb294373870564f42a0e7372fa296e,Prediction of Bike Sharing Demand,"Bike sharing systems have been gaining prominence all over the world with more than 500 successful systems being deployed in major cities like New York, Washington, London. With an increasing awareness of the harms of fossil based mean of transportation, problems of traffic congestion in cities and increasing health consciousness in urban areas, citizens are adopting bike sharing systems with zest. Even developing countries like India are adopting the trend with a bike sharing system in the pipeline for Karnataka. This paper tackles the problem of predicting the number of bikes which will be rented at any given hour in a given city, henceforth referred to as the problem of ‘Bike Sharing Demand’. In this vein, this paper investigates the efficacy of standard machine learning techniques namely SVM, Regression, Random Forests, Boosting by implementing and analyzing their performance with respect to each other. This paper also presents two novel methods, Linear Combination and Discriminating Linear Combination, for the ‘Bike Sharing Demand’ problem which supersede the aforementioned techniques as good estimates in the real world.",,2017.0,10.13005/OJCST/10.01.30,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
878a8b46c70cbb53728d9c039532a14efb0f1b41,https://www.semanticscholar.org/paper/878a8b46c70cbb53728d9c039532a14efb0f1b41,Using big data analytics to improve HIV medical care utilisation in South Carolina: A study protocol,"Introduction Linkage and retention in HIV medical care remains problematic in the USA. Extensive health utilisation data collection through electronic health records (EHR) and claims data represent new opportunities for scientific discovery. Big data science (BDS) is a powerful tool for investigating HIV care utilisation patterns. The South Carolina (SC) office of Revenue and Fiscal Affairs (RFA) data warehouse captures individual-level longitudinal health utilisation data for persons living with HIV (PLWH). The data warehouse includes EHR, claims and data from private institutions, housing, prisons, mental health, Medicare, Medicaid, State Health Plan and the department of health and human services. The purpose of this study is to describe the process for creating a comprehensive database of all SC PLWH, and plans for using BDS to explore, identify, characterise and explain new predictors of missed opportunities for HIV medical care utilisation. Methods and analysis This project will create person-level profiles guided by the Gelberg-Andersen Behavioral Model and describe new patterns of HIV care utilisation. The population for the comprehensive database comes from statewide HIV surveillance data (2005–2016) for all SC PLWH (N≈18000). Surveillance data are available from the state health department’s enhanced HIV/AIDS Reporting System (e-HARS). Additional data pulls for the e-HARS population will include Ryan White HIV/AIDS Program Service Reports, Health Sciences SC data and Area Health Resource Files. These data will be linked to the RFA data and serve as sources for traditional and vulnerable domain Gelberg-Anderson Behavioral Model variables. The project will use BDS techniques such as machine learning to identify new predictors of HIV care utilisation behaviour among PLWH, and ‘missed opportunities’ for re-engaging them back into care. Ethics and dissemination The study team applied for data from different sources and submitted individual Institutional Review Board (IRB) applications to the University of South Carolina (USC) IRB and other local authorities/agencies/state departments. This study was approved by the USC IRB (#Pro00068124) in 2017. To protect the identity of the persons living with HIV (PLWH), researchers will only receive linked deidentified data from the RFA. Study findings will be disseminated at local community forums, community advisory group meetings, meetings with our state agencies, local partners and other key stakeholders (including PLWH, policy-makers and healthcare providers), presentations at academic conferences and through publication in peer-reviewed articles. Data security and patient confidentiality are the bedrock of this study. Extensive data agreements ensuring data security and patient confidentiality for the deidentified linked data have been established and are stringently adhered to. The RFA is authorised to collect and merge data from these different sources and to ensure the privacy of all PLWH. The legislatively mandated SC data oversight council reviewed the proposed process stringently before approving it. Researchers will get only the encrypted deidentified dataset to prevent any breach of privacy in the data transfer, management and analysis processes. In addition, established secure data governance rules, data encryption and encrypted predictive techniques will be deployed. In addition to the data anonymisation as a part of privacy-preserving analytics, encryption schemes that protect running prediction algorithms on encrypted data will also be deployed. Best practices and lessons learnt about the complex processes involved in negotiating and navigating multiple data sharing agreements between different entities are being documented for dissemination.",BMJ Open,2019.0,10.1136/bmjopen-2018-027688,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
25ae1b3b715812f28cf89944b4ecd4227cac00e2,https://www.semanticscholar.org/paper/25ae1b3b715812f28cf89944b4ecd4227cac00e2,Wearable Devices and IoT,,A Handbook of Internet of Things in Biomedical and Cyber Physical System,2019.0,10.1007/978-3-030-23983-1_10,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
32f97b529171cd8c527f8ca883f90e1fbc5795d9,https://www.semanticscholar.org/paper/32f97b529171cd8c527f8ca883f90e1fbc5795d9,IEEE Access Special Section Editorial: Health Informatics for the Developing World,"We live in a world with growing disparity in the quality of life available to people in the developed and developing countries. Healthcare in the developing world is fraught with numerous problems such as the lack of health infrastructure, and human resources, which results in very limited health coverage. The field of health informatics has made great strides in recent years towards improving public health systems in the developing world by augmenting them with state-of-the-art information and communication technologies (ICT). Through real-world deployment of these technologies, there is real hope that the health industry in the developing world will progress from its current, largely dysfunctional state to one that is more effective, personalized, and cost effective. Health informatics can usher a new era of personalized health analytics, with the potential to transform healthcare in the developing world. In conjunction with mHealth and eHealth, many other important health informatics trends—such as artificial intelligence (AI), machine learning (ML), big data, crowdsourcing, cloud computing—are also emerging. Exponentially growing heterogeneous data, with the help of big data analytics, has the potential to provide descriptive, predictive, and prescriptive health insights as well as enable new applications such as telemedicine and remote diagnostics and surgery. Such systems could enhance the overall process of monitoring, diagnosis, and prognosis of diseases.",IEEE Access,2017.0,10.1109/ACCESS.2017.2783118,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ba93bb6065630d409452cf37915319e4fb7c5202,https://www.semanticscholar.org/paper/ba93bb6065630d409452cf37915319e4fb7c5202,A KLD-LSSVM based computational method applied for feature ranking and classification of primary biliary cirrhosis stages,"Medical datasets having variety of features can increase the complexity of decision process. Prioritising these features with respect to medical sickness is a prime task for effective assessment of patients' health. In this study, a two-step computational method based on Kullback-Leibler divergence (KLD) method and least squares support vector machine (LSSVM) is presented as an integrated model and a LSSVM-based approach is projected as an individual model. KLD was employed to rank the features and radial basis kernel function-based LSSVM approach was deployed to classify primary biliary cirrhosis (PBC) stages. Performance of several machine-learning algorithms, individually as well as in integration with KLD, was evaluated on a real-life biomedical PBC dataset. Simulation results indicated that proposed LSSVM and KLD-LSSVM-based frameworks had shown robustness to the noisy data and had outperformed other individual and integrated methods, respectively. It is concluded that the proposed methodologies can be productively applied to real-life health examination datasets containing a variety of features and multiple decision classes.",Int. J. Comput. Biol. Drug Des.,2017.0,10.1504/IJCBDD.2017.10003743,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
429e0d68b9a41d530107037e6a4f0c758f7c2e77,https://www.semanticscholar.org/paper/429e0d68b9a41d530107037e6a4f0c758f7c2e77,Data-Driven Approaches for Developing Clinical Practice Guidelines,"This chapter discusses clinical practice guidelines (CPGs) and their incorporation into healthcare IT (HIT) applications. CPGs provide guidance on treatment options based on evidence. This chapter provides a brief background on challenges in CPG development and adherence, and offers examples of data-driven approaches to improve usability of CPGs and their applications in HIT. A focus is given to clinical pathways, which translate CPG recommendations into actionable plans for patient management in community practices. Approaches for developing data-driven clinical pathways from electronic health record data are presented, including statistical, process mining, and machine learning algorithms. Further, efforts on using CPGs for decision support through visual analytics, and deployments of CPGs into mobile applications are described. Data-driven approaches can facilitate incorporation of practicebased evidence into CPG development after validation by clinical experts, potentially bridging the gap between available CPGs and changing clinical needs and workflow management.",,2017.0,10.4018/978-1-5225-0920-2.CH003,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
62d22864d0be1fd2329d248e10f54c360b999167,https://www.semanticscholar.org/paper/62d22864d0be1fd2329d248e10f54c360b999167,Composite Activity Recognition in Smart Homes Using Markov Logic Network,"Smart environments have progressed and evolved into a significant research area with development of sensor technology, wireless communication and machine learning strategies. Ambient Intelligence incorporated into smart environment assists in resolving many social related applications to facilitate the future society. The initiative of modeling Activity of Daily Living (ADL) and Ambient Assisted Living (AAL) in smart homes have helped in the deployment of applications to various domains like elderly care, health care etc. Activity recognition is the task involved in reasoning within smart homes with the aim of recognizing the ongoing activity of the occupant. Constructing an activity model is essential to carry out recognition and is achieved through various machine learning and artificial intelligence techniques. Data driven approach constructs activity model through statistical machine learning mechanisms while knowledge driven approach constructs activity model through knowledge representation and modeling strategies. Uncertainty and temporal data are better handled by data driven approach while re-usability and context based analysis is handled better by knowledge driven approach of activity modeling. To combine the features of data driven and knowledge driven approaches, a hybrid activity modeling technique is required. The proposed system performs activity modeling via Markov Logic Network, a machine learning strategy that combines probabilistic reasoning and logical reasoning with a single framework. Activities in a smart home are categorized as simple and composite activities, wherein composite activities are defined as related simple activities within a given time interval. The proposed system models both simple and composite activity using soft and hard rules of MLN. Experiments carried over the proposed system shows the effectiveness of the proposed work for recognizing simple and composite activity.",2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and Its Associated Workshops (UIC-ATC-ScalCom),2014.0,10.1109/UIC-ATC-ScalCom.2014.98,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
677e7b93c4bb987ca5de6a7defad0e4751894ff5,https://www.semanticscholar.org/paper/677e7b93c4bb987ca5de6a7defad0e4751894ff5,How to Make Decisions ( Optimally ),"Distributed systems are constantly faced with difficult decisions to make, such as in scheduling, caching, and traffic routing, to name a few. In most of these scenarios, the optimal decision is unknown and depends heavily on context. How can a system designer know if they have deployed the best decision-making policy, or if a different policy would perform better? As a community, we have developed a few methodologies for answering this question, some of them offline (e.g., simulation, trace-driven modeling) and some of them online (e.g., A/B testing). Neither approach is satisfactory: the offline methods suffer from bias and rely heavily on domain knowledge; the online methods are costly and difficult to deploy. What system designers ideally seek is the ability to ask “what if” questions about a policy without ever deploying it, which is called counterfactual evaluation. In this talk, I will show how reinforcement learning and causal inference can be synthesized to counterfactually evaluate a distributed system. We will apply this methodology to infrastructure systems in Azure, and face fundamental challenges and opportunities along the way. This talk will serve as an introduction to reinforcement learning and the counterfactual way of thinking, which I hope will interest and inspire the OPODIS community. I will start by introducing reinforcement learning (RL) as the right framework for modeling decisions in a distributed system. In RL, an agent learns by interacting with its environment: i.e., making decisions and receiving feedback for them. This is a stark contrast to traditional (supervised) learning, where the correct answer, or “label”, is known. Since an RL agent does not know the correct answer, it must constantly explore its world by randomizing some of its decisions. Now it turns out that this randomization, if used correctly, can give us a special superpower: the ability to evaluate policies that have never been deployed. As magical as this may sound, we can use statistics to show that this evaluation is indeed correct. Unfortunately, applying this methodology to distributed systems is far from straightforward. Systems are complex, stateful amalgamations of components that navigate large decision spaces. We will need to wear both an RL hat and a systems hat to address these challenges. On the other hand, systems also present exciting opportunities. Many systems already use randomization in their decisions, e.g., to distribute data or work over replicas, or to manage resource contention. Sometimes, a conservative decision can implicitly yield feedback for other decisions: for example, when waiting for a timeout to expire, we automatically get feedback for what would have happened if we waited for any shorter amount of time. I will show how we can harvest this randomness and implicit feedback to achieve more effective counterfactual evaluation. We will apply all of the above ideas to two production infrastructure systems in Azure: a machine health monitor that decides when to reboot unresponsive machines, and a geo-distributed edge proxy that chooses the TCP configuration of each proxy machine. In both cases, we are able to counterfactually evaluate arbitrary policies with estimates that match the ground truth. Production environments raise interesting constraints and challenges, some of which are preventing us from scaling up our methodology. I will describe a possible path forward, and invite others in the community to contemplate these problems as well. 2012 ACM Subject Classification Computing methodologies → Reinforcement learning, Software and its engineering → Software organization and properties",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
75045755003c9fc14e5539e6a5be4621a93ab178,https://www.semanticscholar.org/paper/75045755003c9fc14e5539e6a5be4621a93ab178,Computational and Bioinformatics Techniques for Immunology,"Computational immunology and immunological bioinformatics are well-established and rapidly evolving research fields. Whereas the former aims to develop mathematical and/or computational methods to study the dynamics of cellular and molecular entities during the immune response [1–4], the latter targets proposing methods to analyze large genomic and proteomic immunological-related datasets and derive (i.e., predict) new knowledge mainly by statistical inference and machine learning algorithms. 
 
Since immunology provides key information about basic mechanisms in a number of related diseases, it represents the most critical target for medical intervention. Therefore an advance in either computational or bioinformatics immunology research field has the potential to pave the way for improvement of human health through better patient-specific diagnostics and optimized immune treatment. 
 
In this special issue, we take an interest from mathematicians, bioinformaticians, computational scientists, and engineers together with experimental immunologists, to present and discuss latest developments in different subareas ranging from modeling and simulation to machine learning predictions and their application to basic and clinical immunology. 
 
Of the possible directions for development in immune-informatics special interest is raising for models focusing on innate-adaptive immune response activation, immune senescence, and multiscale and multiorgan models of immune-related diseases and for models accounting for cell trafficking in lymph nodes and/or in the lymphatic mesh as in “Modeling biology spanning different scales: an open challenge” by F. Castiglione et al. 
 
Exploring the connections between classical mathematical modeling (at different scales) and bioinformatics predictions of omic scope along with specific aspects of the immune system in combination with concepts and methods like computer simulations, mathematics and statistics for the discovery, design, and optimization of drugs, vaccines, and other immunotherapies represents a hot topic in computational biology and systems medicine [5, 6]. 
 
The review from F. Castiglione et al. calls attention to the importance of the different time-space scale involved in biological phenomena and in particular in the immune system. It dissects the problem and discusses various techniques that have been developed in scientific areas other than computational biology. 
 
In their paper S. Jarrah et al. illustrate a simple ODE model to investigate the role of the immune response in muscle degeneration and regeneration in the mdx mouse model of Duchenne muscular dystrophy. Their model suggests that the immune response contributes substantially to the muscle degeneration and regeneration processes and predicts in a certain parameter range a permanent immune activation damaging muscle fibers. 
 
In the paper contributed by T. Clancy and E. Hovig, the authors propose a new method to integrate expression profiles and protein-protein interaction (PPI) data. Bioinformatics techniques are used to study differential protein interaction mechanisms across the entire immune cell lineages and the transcriptional activators and modules and are analyzed in the context of exemplars obtained by clustering the PPI network. The results illustrate that the integration of protein interaction networks with the most comprehensive database of gene expression profiles of the immune cells can be used to generate hypotheses into the underlying mechanisms governing the differentiation and the differential functional activity across the immune cell lineage. 
 
The development of mathematical models of the immune response allows a better understanding of the multifaceted mechanisms of the defense system. In this scenario, as already introduced in the review from F. Castiglione et al., multiscale approaches play a fundamental role. B. de M. Quintela et al. propose a scheme for coupling distinct models of different scales and aspects of the immune system describing a new model that deals with the inflammation processes. These processes are simulated coupling and ordinary differential equations that are used as a model for the systemic response. The dynamics of various immune cells is shown in the presence of an antigen. 
 
There is a controversy about the relationship between HLA-A2 and Alzheimer's disease. HLA supposedly plays a modifier effect on the risk that depends on genetic loadings. Garcia and Murillo present an in silico method to evaluate this relationship and to reveal genes associated with both the HLA-A2 and Alzheimer's disease. They used experimental knowledge of protein-protein interactions to evaluate the top ranked genes shared by both concepts, previously found through text mining. 
 
With the vast amount of immunological data available, immunology research is entering the big data era. These data vary in granularity, quality, and complexity and are stored in various formats, including publications, technical reports, and databases. In the paper contributed by G. L. Zhang et al., it is clearly stated that the present challenge is to make the transition from data to actionable knowledge and wisdom and bridge the gap between knowledge and application. In their work, the authors present a knowledge-based approach based on a framework called KB-builder that facilitates data mining by enabling fast development and deployment of web-accessible immunological data knowledge warehouses. This technique speeds up rational vaccine design by providing accurate and well-annotated data coupled with tailored computational analysis tools and workflows. 
 
Hepatitis C virus and HIV are rapidly mutating viruses. They have adopted evolutionary strategies that allow escape from the host immune response via genomic mutations. Recent advances in high-throughput sequencing are reshaping the field of immune-virology of viral infections, as these allow fast and cheap generation of genomic data. P. Leung et al. propose a pipeline that allows visualization and statistical analysis of viral mutations that are associated with immune escape. Using next generation sequencing data from longitudinal analysis of HCV viral genomes during a single HCV infection, along with antigen specific T-cell responses detected from the same subject, the authors prove the applicability of these tools in the context of primary HCV infection. The proposed pipeline is a freely accessible collection of tools (see the paper for details). 
 
M. Kenn et al. point the attention on the dynamic variations in the distances between pairs of atoms that are used for clustering subdomains of biomolecules. They draw on a well-known target function for clustering and first show mathematically that the assignment of atoms to clusters has to be crisp, not fuzzy, as hitherto assumed, proving that this method reduces the computational load of clustering drastically, demonstrating results for several biomolecules relevant in immunoinformatics. 
 
In the paper by R. Ribarics et al., molecular dynamics is presented as a valuable tool for the investigation of functional elements in biomolecules. They used several spline models to approximate the overall shape of MHC α-helices. The authors applied this technique to a series of MD simulations of alloreactive MHC molecules that allowed them to capture the dynamics of MHC α-helices' steric configurations. In the paper, they discuss the variability of spline models underlying the geometric analysis with varying polynomial degrees of the splines. 
 
HIV represents a widespread viral infection without cure. Drug treatment has transformed HIV disease into a treatable long-term infection. However, the appearance of mutations within the viral genome reduces the susceptibility of HIV to drugs. In the paper contributed by M. Haering et al., the authors discuss predictions derived from a mathematical model of HIV dynamics. Their results indicate that early therapy initiation (within 2 years after infection) is critical to delay AIDS progression. 
 
 
Francesco Pappalardo 
 
Vladimir Brusic 
 
Filippo Castiglione 
 
Christian Schonbach",BioMed research international,2014.0,10.1155/2014/263189,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ef5898e237584f1efb140bdaf7ad82c200b226dc,https://www.semanticscholar.org/paper/ef5898e237584f1efb140bdaf7ad82c200b226dc,Mobile Sensing and Support for People With Depression: A Pilot Trial in the Wild,"Background Depression is a burdensome, recurring mental health disorder with high prevalence. Even in developed countries, patients have to wait for several months to receive treatment. In many parts of the world there is only one mental health professional for over 200 people. Smartphones are ubiquitous and have a large complement of sensors that can potentially be useful in monitoring behavioral patterns that might be indicative of depressive symptoms and providing context-sensitive intervention support. Objective The objective of this study is 2-fold, first to explore the detection of daily-life behavior based on sensor information to identify subjects with a clinically meaningful depression level, second to explore the potential of context sensitive intervention delivery to provide in-situ support for people with depressive symptoms. Methods A total of 126 adults (age 20-57) were recruited to use the smartphone app Mobile Sensing and Support (MOSS), collecting context-sensitive sensor information and providing just-in-time interventions derived from cognitive behavior therapy. Real-time learning-systems were deployed to adapt to each subject’s preferences to optimize recommendations with respect to time, location, and personal preference. Biweekly, participants were asked to complete a self-reported depression survey (PHQ-9) to track symptom progression. Wilcoxon tests were conducted to compare scores before and after intervention. Correlation analysis was used to test the relationship between adherence and change in PHQ-9. One hundred twenty features were constructed based on smartphone usage and sensors including accelerometer, Wifi, and global positioning systems (GPS). Machine-learning models used these features to infer behavior and context for PHQ-9 level prediction and tailored intervention delivery. Results A total of 36 subjects used MOSS for ≥2 weeks. For subjects with clinical depression (PHQ-9≥11) at baseline and adherence ≥8 weeks (n=12), a significant drop in PHQ-9 was observed (P=.01). This group showed a negative trend between adherence and change in PHQ-9 scores (rho=−.498, P=.099). Binary classification performance for biweekly PHQ-9 samples (n=143), with a cutoff of PHQ-9≥11, based on Random Forest and Support Vector Machine leave-one-out cross validation resulted in 60.1% and 59.1% accuracy, respectively. Conclusions Proxies for social and physical behavior derived from smartphone sensor data was successfully deployed to deliver context-sensitive and personalized interventions to people with depressive symptoms. Subjects who used the app for an extended period of time showed significant reduction in self-reported symptom severity. Nonlinear classification models trained on features extracted from smartphone sensor data including Wifi, accelerometer, GPS, and phone use, demonstrated a proof of concept for the detection of depression superior to random classification. While findings of effectiveness must be reproduced in a RCT to proof causation, they pave the way for a new generation of digital health interventions leveraging smartphone sensors to provide context sensitive information for in-situ support and unobtrusive monitoring of critical mental health states.",JMIR mHealth and uHealth,2016.0,10.2196/mhealth.5960,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d91b1b996678425418321d9de5b251778eb506d7,https://www.semanticscholar.org/paper/d91b1b996678425418321d9de5b251778eb506d7,Knowledge engineering with semantic web technologies for decision support systems based on psychological models of expertise,"Machines that provide decision support have traditionally used either a representation of human expertise or used mathematical algorithms. Each approach has its own limitations. This study helps to combine both types of decision support system for a single system. However, the focus is on how the machines can formalise and manipulate the human representation of expertise rather than on data processing or machine learning algorithms. It will be based on a system that represents human expertise in a psychological format. The particular decision support system for testing the approach is based on a psychological model of classification that is called the Galatean model of classification. The simple classification problems only require one XML structure to represent each class and the objects to be assigned to it. However, when the classification system is implemented as a decision support system within more complex realworld domains, there may be many variations of the class specification for different types of object to be assigned to the class in different circumstances and by different types of user making the classification decision. All these XML structures will be related to each other in formal ways, based on the original class specification, but managing their relationships and evolution becomes very difficult when the specifications for the XML variants are text-based documents. For dealing with these complexities a knowledge representation needs to be in a format that can be easily understood by human users as well as supporting ongoing knowledge engineering, including evolution and consistency of knowledge. The aim is to explore how semantic web technologies can be employed to help the knowledge engineering process for decision support systems based on human expertise, but deployed in complex domains with variable circumstances. The research evaluated OWL as a suitable vehicle for representing psychological expertise. The task was to see how well it can provide a machine formalism for the knowledge without losing its psychological validity or transparency: that is, the ability of end users to understand the knowledge representation intuitively despite its OWL format. The OWL Galatea model is designed in this study to help in automatic knowledge maintenance, reducing the replication of knowledge with variant uncertainties and support in knowledge engineering processes. The OWL-based approaches used in this model also aid in the adaptive knowledge management. An adaptive assessment questionnaire is an example of it, which is dynamically derived using the users age as the seed for creating the alternative questionnaires. The credibility of the OWL Galatea model is tested by applying it on two extremely different assessment domains (i.e. GRiST and ADVANCE). The conclusions are that OWLbased specifications provide the complementary structures for managing complex knowledge based on human expertise without impeding the end users’ understanding of the knowledgebase. The generic classification model is applicable to many domains and the accompanying OWL specification facilitates its implementations.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3f9d9414a3077ee1630c65a9258ec3728ed5e778,https://www.semanticscholar.org/paper/3f9d9414a3077ee1630c65a9258ec3728ed5e778,Statistical Communications in Infectious Diseases,"Background: Human immunodeficiency virus (HIV) viral failure occurs when antiretroviral therapy fails to suppress and sustain a person’s viral load count below 1,000 copies of viral ribonucleic acid per milliliter. For those newly diagnosed with HIV and living in a setting where healthcare resources are limited, such as a lowand middle-income country, the World Health Organization recommends viral load monitoring six months after initiation of antiretroviral treatment and yearly thereafter. Deviations from this schedule are made in cases where viral failure occurs or at the discretion of the clinician. Failure to detect viral failure in a timely fashion can lead to delayed administration of essential interventions. Clinical prediction models based on information available in the patient medical record are increasingly being developed and deployed for decision support in clinical medicine and public health. This raises the possibility that prediction models can be used to detect potential for viral failure in advance of viral measurements, particularly when those measurements occur infrequently. Objective: Our goal is to use electronic health record data from a large HIV care program in Kenya to characterize and compare the predictive accuracy of several statistical machine learning methods for predicting viral failure at the first and second measurements following initiation of antiretroviral therapy. Predictive accuracy is measured in terms of sensitivity, specificity and area under the receiver-operator characteristic curve. Methods: We trained and cross-validated 10 statistical machine learningmodels and algorithms on data from over 10,000 patients in the Academic Model Providing Access to Healthcare care program in western Kenya. These included parametric, non-parametric, ensemble, and Bayesian methods. The input variables included 50 items from the clinical record, hand picked in consultation with clinician experts. Predictive accuracy measures were calculated using 10-fold cross validation. Results: Viral load failure rate is about 20% in this patient cohort at both the first and second measurements. Ensemble techniques generally outperformed other methods. For predicting viral failure at the first follow up measure, specificity was over 90% for these methods, but sensitivity was typically in the 50–60% range. Predictive accuracy was greater for the second follow upmeasure, with sensitivities over 80%. Super Learner, gradient boosting and Bayesian additive regression trees consistently outperformed other methods. For a viral *Corresponding author: Joseph W. Hogan, Brown University, Providence, Rhode Island, USA; and Academic Model Providing Access to Healthcare (AMPATH), Eldoret, Kenya, E-mail: jwh@brown.edu. https://orcid.org/0000-0001-7959-7361 Allan Kimaina, Moi University, Eldoret, Kenya; Brown University, Providence, RI, USA; and Academic Model Providing Access to Healthcare (AMPATH), Eldoret, Kenya JonathanDick, IndianaUniversity, Indianapolis, IN, USA; AcademicModel Providing Access to Healthcare (AMPATH), Eldoret, Kenya Allison DeLong, Stavroula A. Chrysanthopoulou and Rami Kantor, Brown University, Providence, RI, USA Statistical Communications in Infectious Diseases 2020; 12(s1): 20190017",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
58dc374e2669cd54638605c336334c9aff818095,https://www.semanticscholar.org/paper/58dc374e2669cd54638605c336334c9aff818095,Selected Papers from the Eleventh ITU Kaleidoscope Academic Conference,"This special section contains two updated papers, originally presented at the eleventh International Telecommunication Union’s (ITU) Kaleidoscope academic conference. The title of the conference was “ICT for Health: Networks, Standards and Innovation,” and took place in the United States, specifi cally in Atlanta, Georgia from 4-6 December 2019. The host was the Georgia Tech Research Institute with the collaboration of the World Health Organization (WHO). There were nearly 100 participants: 70 physically at the venue coming from 16 countries and over 30 on the web. The proceedings are available on the ITU website at https://www.itu.int/pub/T-PROC-KALEI-2018, and from the IEEE Xplore Digital Library. Pictorial highlights from the conference are available at https://www.fl ickr.com/photos/ itupictures/with/49237161532/. The topic of the next conference is “Industry-Driven Digital Transformation.” It was originally scheduled for 7-9 September 2020 in Hanoi, Viet Nam, in conjunction with the ITU Digital World 2020. However, due to the Covid-19 pandemic, it is now an online conference from 7–11 December 2020 running four hours per day to accommodate the various time zones. To access the conference, check its main page at https://www.itu.int/en/ITU-T/academia/kaleidoscope/2020. The ITU Kaleidoscope series of academic conferences started in 2008 to provide an interdisciplinary forum for the discussion of Information and Communication Technologies (ICTs) relevant to future telecommunication standards. Participants typically include researchers, academics, students, engineers, policymakers, regulators as well as futurists. The fi rst article in this issue deals with Machine Learning (ML) and Artifi cial Intelligence (AI) in medicine. The main challenge is that, because of the wide variety of patients and clinical conditions, ML/AI models must produce results that practitioners can rely on even when the algorithms process previously unseen data. Another diffi culty is that these algorithms are black boxes because their exact workings are unknown. Some bioethicists have suggested that applying trust to AI is a corruption of language that can corrupt thought because it is “a category error, mistakenly assuming that AI belongs to a category of things that can be trusted” [1]. This is why international cooperation is indispensable because it allows substantial synergies in the selection of the training and test data sets as well as the validation of the software, from both engineering and clinical viewpoints. This invited article from the Fraunhofer Heinrich Hertz Institute and the Technische Universität Berlin, titled “Toward Global Validation Standards for Health AI,” covers these aspects. The authors, Markus A. Wenzel and Thomas Wiegand, present an overview of the work being carried out under the joint auspices of the ITU-T and WHO to address the use of machine learning and artifi cial intelligence in healthcare, and highlight what has been achieved in terms of guidelines. On the regulatory side, they mention the contributions of the National Health Service in the UK and the International Medical Device Regulators Forum. On the standardization side, they list activities by a variety of organizations such as the U.S. National Institute of Standards and Technology (NIST), the Chinese Electronics Standards Institute, the European Union High-Level Expert Group on AI, the German Deutsches Institut für Normung (DIN), the IEEE, and the International Organization for Standardization (ISO). The second article, “Converged Internet of Lights Network for Telecommunication, Positioning, Illumination and Medical Therapy,” is a joint contribution from several Chinese and British universities and research institutions. The authors are Jian Song, Xiaofei Wang, Jintao Wang, Hongming Zhang, Changyong Pan, Yue Zhang, and John Cosmas. They focus on the spectrum of the visible light from 380nm to 850nm, which is nearly one thousand times broader than the Radio Frequency (RF) spectrum. This is because Light Emitting Diodes (LEDs) can be deployed to modulate visible light for Visible Light Communication (VLC). Accordingly, lighting systems can be designed to combine information services using a network of LEDs integrated with sensors. This would constitute what the authors call the Internet of Lights (IoL). IoL, however, can have both positive and negative impact on human beings (as well as other animals), because of its eff ect on the circadian rhythms and hence body functions. On the positive side, it can be used as a non-intrusive intervention therapy to alleviate degenerative neurological diseases such as SeLecTeD Papers froM The ELeVenTh ITU KaLeiDoscope AcaDeMic Conference",IEEE Commun. Stand. Mag.,2020.0,10.1109/MCOMSTD.2020.9204601,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
590c72f28a55f4525b758ca366e03f3cd85a408f,https://www.semanticscholar.org/paper/590c72f28a55f4525b758ca366e03f3cd85a408f,"Drones Move From ""Nice To Have"" to Strategic Resources for Projects","While drones have been used on oil and gas facilities for video inspections and other tasks, they have been operated by an on-site pilot or one positioned on a bobbing workboat adjacent to an offshore platform. Now a proof-of-concept study conducted by TechnipFMC has tested the feasibility of a global drone system with drones operated remotely by pilots based anywhere in the world. The study is the subject of a paper (OTC 30241) presented at the Offshore Technology Conference Asia in Kuala Lumpur in November.
 Construction supervision and health, safety, and environmental (HSE) monitoring were the main drivers of the study. The construction supervision application is part of a larger digitalization ambition to monitor and manage construction activities with data generated from the drone ultimately feeding an internal software dedicated to this business process. Potential HSE applications include crisis management, human safety, evacuation assistance, hazardous-area identification, traffic control, carbon-footprint reduction, and environmental surveys.
 One of the study’s main objectives was to move from traditional unmanned autonomous vehicles (UAV) to resident systems and to investigate the possibilities they could offer. Aerial views have been used extensively to reduce personnel exposure in specific situations such as difficult access or potentially dangerous inspection areas like active flares, confined spaces, or high structures. In these cases, the drones are controlled by an on-site pilot who is either within their line of sight or a short distance away.
 Combining AUV technology with embedded and associated intelligence from the internet of things (IoT), artificial intelligence (AI), and cloud and edge computing should enable drones to fly safely in complex and dynamic environments, resulting in integrated, resident systems that are permanently deployed at construction sites and available 24/7 without the need for an on-site certified pilot. Implementing these technologies will make data accessible and available in real time to people working on the project worldwide and it will also generate new work processes for project management and execution.
 Flight and Operations Testing
 According to the paper’s primary author, Nicolas Tcherniguin, manager of offshore business and technology with TechnipFMC, digital tools such as image recognition, machine learning, and simulation of digital twins based on the drone’s flight have been tested. Remaining bottlenecks have been identified, and some have been addressed while others will require additional efforts. AI development will offer additional features, especially if they can be integrated with other ground monitoring devices.",,2020.0,10.2118/1220-0029-JPT,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9327d45e34bfb88631d3c14e3b07d260a21f34e5,https://www.semanticscholar.org/paper/9327d45e34bfb88631d3c14e3b07d260a21f34e5,Microsoft Word-Beyond Mobile Apps A Survey of Technologies for Mental Well-being.docx,"Mental health problems are on the rise globally and strain national health systems worldwide. Mental disorders are closely associated with fear of stigma, structural barriers such as financial burden, and lack of available services and resources which often prohibit the delivery of frequent clinical advice and monitoring. Technologies for mental well-being exhibit a range of attractive properties, which facilitate the delivery of state-of-the-art clinical monitoring. This review article provides an overview of traditional techniques followed by their technological alternatives, sensing devices, behaviour changing tools, and feedback interfaces. The challenges presented by these technologies are then discussed with data collection, privacy, and battery life being some of the key issues which need to be carefully considered for the successful deployment of mental health toolkits. Finally, the opportunities this growing research area presents are discussed including the use of portable tangible interfaces combining sensing and feedback technologies. Capitalising on the data these ubiquitous devices can record, state of the art machine learning algorithms can lead to the development of robust clinical decision support tools towards diagnosis and improvement of mental well-being delivery in real-time.",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3af91b1be29551c1cf19866f47e7035b7e139343,https://www.semanticscholar.org/paper/3af91b1be29551c1cf19866f47e7035b7e139343,Objective Image Quality Assessment: Facing The Real-World Challenges,"There has been a growing interest in recent years in the development of objective image quality assessment (IQA) models, whose roles are not only to monitor image quality degradations and benchmark image processing systems, but also to optimize various image and video processing algorithms and systems. While the past achievement is worth celebrating, a number of major challenges remain when we apply existing IQA models in realworld applications. These include obvious ones such as the challenges to largely reduce the complexity of existing IQA algorithms and to make them easy-to-use and easy-to-understand. There are also challenges regarding the applicability of existing IQA models in many real-world problems where image quality needs to be evaluated and compared across dimensionality, across viewing environment, and across the form of representations − specific examples include quality assessment for image resizing, color-togray image conversion, multi-exposure image fusion, image retargeting, and high dynamic range image tone mapping. Here we will first elaborate these challenges, and then concentrate on a specific one, namely the generalization challenge, which we believe is a more fundamental issue in the development, validation and application of IQA models. Specifically, the challenge is about the generalization capability of existing IQA models, which achieve superior quality prediction performance in lab testing environment using a limited number of subject-rated test images, but the performance may not extend to the real-world where we are working with images of a much greater diversity in terms of content and complexity. We will discuss some principle ideas and related work that might help us meet the challenges in the future. Introduction Over the past decades, a growing number of researchers and engineers in the image processing community have started to realize the importance of image/video quality assessment (IQA/VQA) [40, 29, 4]. This is not surprising because no matter what image/video processing problems we are working on, the same issues repeatedly come up − How should we evaluate the images generated from our algorithms/systems? How do we know our algorithm/system is creating an improvement between the input and output images, and by how much? How can we know one algorithm/system performs better than another, and by how much? What should be the quality criterion for which the design of our algorithms/systems should be optimized? Since the human eyes are the ultimate receivers in most image processing applications, human subjective visual testing would be a reliable solution. However, with the exponential increase of the volume of image/video data being generated daily, it becomes impossible to address these quality issues in a timely manner by subjective visual testing, which is slow, cumbersome and expensive. Instead, only trusted objective IQA models may potentially meet these needs. In academia, objective IQA has been a hot research topic, especially in the past 15 years [35, 4, 29]. First, the commonly used numerical disotrtion/quality measures in the past − the mean squared error (MSE) and the peak signal-to-noise ratio (PSNR) − have been shown to correlate poorly with perceived image quality [28, 30]. Second, a large number of perceptually more meaningful IQA models have been proposed, including full-reference (where a perfect quality reference image is available when evaluating a distorted image) [35, 4, 29], no-reference (where the reference image is not accessible) [34, 24, 31], and reduced-reference (where only partial information about the reference image is available) models [39, 36, 31, 29]. Third, several design principles have been discovered and repeatedly demonstrated to be useful in the design and improvement of IQA models. These include psychophysical and physiological visibility models [35, 4], the structural similarity (SSIM) approaches [28, 32, 33, 20, 49], the natural scene statistics (NSS) and information theoretic approaches [36, 39, 21, 31], the visual saliency based approaches [50], and the machine learning based approaches [6]. Fourth, a number of subject-rated image quality databases have been created and made publicly available [22, 7, 8, 17, 16, 47]. They provide a common benchmark platform for the evaluation and comparison of IQA models, among which several algorithms have achieved high correlations with the subjective mean opinion scores (MOSs) of the test images [23, 38, 33, 49]. In the video delivery industry, perceptual objective IQA methods such as the SSIM algorithm have been incorporated into many practical hardware and software systems to monitor image/video quality degradations and to test/compare image/video encoders and transcoders [27, 25, 26]. The wide use of SSIM has resulted in a Primetime Engineering Emmy Award given by the Academy of Television Arts and Sciences [1]. The remarkable development and successful deployment of modern IQA methods are definitely worth celebrating. Nevertheless, this does not necessarily mean that the existing IQA models have already met the real-world challenges. Otherwise, they should have made a much stronger impact and become a gamechanging factor in the industry. Using the video delivery industry as an example, even now most practitioners are still equating bitrate with quality in the practical design of video delivery architectures. However, using the same bitrate to encode different video content could result in dramatically different visual quality. Clearly, the perceptual quality of the video itself, which is presumably the ultimate evaluation criterion of the whole video delivery system, has not been placed at the driver’s seat. While it is understandable that quality degradation is inevitable at many stages in the video delivery chain due to practical constraints, the real concern here is that there is no existing protocol to monitor and control such quality degradation. As a result, various tricks have been used to manipulate the video content and network resources are allocated in suboptimal ways, leaving the creative intent of the content producers unprotected. While it is certain that the industry needs to be better informed about the great potentials of making the best use of IQA/VQA models, we believe that an equally important aspect that slows down the process is that the existing IQA/VQA models still do not meet many real-world challenges. In the following sections, we will elaborate some of these challenges and then focus on a specific one, namely the generalization challenge. We wish our discussions on some fundamental ideas could provide some useful insights for the future development of IQA models that may meet these real-world challenges. The Real-World Challenges Here we make a list of real-world challenges, many of which are described in more details through examples of practical scenarios. 1. It is highly desirable to reduce the complexity of the IQA/VQA algorithms so that they can be computed in realtime or in an even faster speed. This is especially useful in time-sensitive applications such as live broadcasting and videoconferencing. Many existing models are far from meeting this challenge. 2. It is essential to make the IQA/VQA scores easy-to-use and easy-to-understand. For example, the raw SSIM score does not have an explicit perceptual meaning, making it difficult to determine what level of SSIM index can warrant an excellent video quality and how much improvement in the SSIM index is sufficient to create visible quality improvement. Mapping the raw scores into a perceptually linear domain that is easily linked to human expressions about image quality is desirable. 3. The same video stream shown on different display devices could result in very different perceptual quality. For example, a strongly compressed video that exhibits very annoying artifacts on a large TV could appear to have fine quality when viewed on the screen of a smartphone. The quality may also change significantly when the video is watched on the same TV but at two different viewing distances, one at the default distance and the other at a very close distance. However, existing IQA/VQA models give the same score based on the video stream only, completely ignorant of the viewing device and viewing condition. 4. In a video-on-demand application, a high-quality highresolution (e.g., 4K) source video may be encoded into multiple video streams of different resolutions (e.g., 1080p, 720p, 360p, 240p, etc.) and different bit rates, aiming for satisfying a variety of user needs. In order to measure the quality of the encoded videos, most existing VQA models cannot be computed because the source (reference) and test videos have different spatial resolutions. 5. An image or video may need to be displayed on a screen that has a spatial resolution higher than that of the image resolution. As a result, spatial interpolation is performed. Again, most existing VQA models are not applicable because the reference and test images have different spatial resolutions. 6. An image or video of imperfect quality (e.g., being compressed at an earlier stage) is received and then transcoded to multiple images or videos with different bitrates and resolutions. Most existing IQA/VQA models are not applicable not only because they do not allow for cross-resolution quality assessment, but also because they assume the original reference image/video to have perfect quality, which is not the case here. How to carry out “degraded reference” IQA/VQA is a major challenge. 7. A high dynamic range (HDR) image (e.g., the pixels are in 10 or more bit depths) is tone mapped to a standard dynamic range (SDR) image (8 bits per pixel) in order to be visualized on an SDR display. There is certainly information loss that we would like to capture. However, most existing IQA models do not apply because they cannot compare images/videos with different dynamic ranges.",IQSP,2016.0,10.2352/ISSN.2470-1173.2016.13.IQSP-205,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3516e17605a0e18918f898a2283c4e94a70d4e72,https://www.semanticscholar.org/paper/3516e17605a0e18918f898a2283c4e94a70d4e72,Opportunities and Challenges in Association and Episode Discovery from Electronic Health Records,"83 guidance; machine understanding of human behavior, emotional, and physiological states; and the need to respond appropriately to unintended stimuli. Numerous machine perception , cognition, and communication challenges also remain such as image-guided intervention, speech and language understanding, two-hand-like manipulative dexterity, and learning systems that adapt to an individual's long-term change of state. Solutions likely lie at the intersection of new and ongoing research in computer science, materials, psychology, and neuroscience. The societal pressure to mitigate the healthcare crisis presents an unprecedented opportunity for computing , information science, and engineering. Whereas the pursuit of understanding the pathogenesis of disease will be accelerated with new algorithms and increasingly powerful computation and data architec-tures, we look to other computation-enabled means to provide additional avenues to the pursuit of quality of life. Multidisciplinary approaches are required to engineer a privacy-maintaining information infrastructure with secure, real-time access to unprecedented amounts of heterogeneous health, medical, and treatment data. New generations of algorithms must be developed to utilize the resulting global resource of population-based evidence for assisted discovery, knowledge creation, and even individual point-of-care decisions. Ana-lytics based on modeling phenomena ranging from the physiology of humans to their social interactions are required to optimize therapies ranging from molecular medicine to be-havioral interventions. Such advances in human-centered computing in combination with standardization and commercialization of unobtrusive sensing and robotics will trigger a disruptive change in health-care and wellbeing by empowering individuals to more directly participate. Finally, partnerships among academic , industrial, and governmental bodies are required to enable these computer science innovations and realize their deployment in order to help transform healthcare. Will Barkis is a AAAS science and technology policy fellow at the American Association for the Advancement of Science. Contact him at wbarkis@gmail.com. As healthcare practices, both small and large, move from traditional paper-based patient charts to electronic health records (EHRs), new opportunities are emerging for secondary uses of data captured as part of routine care. Such opportunities include not only traditional research meth-odologies involving relatively small cohorts of selected patients, but also large-scale data mining analyses encompassing hundreds of thousands or even millions of patients at once. Performing these nontraditional analyses has required novel computational approaches, sometimes borrowing from techniques originally developed in other elds such as genomics and network theory. Additionally, to interpret such large volumes of data in a meaningful",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
19b373bf77a2975761d880c1bae30f636a324551,https://www.semanticscholar.org/paper/19b373bf77a2975761d880c1bae30f636a324551,Model ... Training data Test data at day 1 Test data at day 100 Model Model Model Model ... Cloud ... Hospital 1 Hospital 2 Hospital n,"Recent advances in artificial intelligence (AI) and machine learning have created a general perception that AI could be used to solve complex problems, and in some situations over-hyped as a tool that can be so easily used. Unfortunately, the barrier to realization of mass adoption of AI on various business domains is too high because most domain experts have no background in AI. Developing AI applications involves multiple phases, namely data preparation, application modeling, and product deployment. The effort of AI research has been spent mostly on new AI models (in the model training stage) to improve the performance of benchmark tasks such as image recognition. Many other factors such as usability, efficiency and security of AI have not been well addressed, and therefore form a barrier to democratizing AI. Further, for many real world applications such as healthcare and autonomous driving, learning via huge amounts of possibility exploration is not feasible since humans are involved. In many complex applications such as healthcare, subject matter experts (e.g. Clinicians) are the ones who appreciate the importance of features that affect health, and their knowledge together with existing knowledge bases are critical to the end results. In this paper, we take a new perspective on developing AI solutions, and present a solution for making AI usable. We hope that this resolution will enable all subject matter experts (eg. Clinicians) to exploit AI like data scientists.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0dd6b27fc633e0a892ae0e69e16462f59ee57eea,https://www.semanticscholar.org/paper/0dd6b27fc633e0a892ae0e69e16462f59ee57eea,DIGITAL CAMPAIGN TRACKING WITH RESPECT TO APPLICATION INFRASTRUCTURE,"Digital campaigns are often derailed from their goals due to amiss or often miscalculated aspects of the impact of the campaign on application infrastructure. To mitigate this problem, an approach is described herein which unifies these otherwise disjoint domains of digital marketing and application monitoring analytics. A solution is provided whereby a user may perform capacity planning for upcoming campaigns and perform real time correlation on campaign and infrastructure Key Performance Indicators (KPIs), thus maximizing revenue and optimizing infrastructure cost. Through machine learning algorithms which are running on top of correlated data from both the domains, a plethora of actionable and valuable insights may be unraveled. DETAILED DESCRIPTION In today’s age of technology, companies drive engagement, conversions, traffic, and revenue by running many digital marketing campaigns. The success of these campaigns is of utmost importance to the firm as it ties in with the overarching goals of the organization. Although multiple factors can contribute to the derailment of a campaign from its goals, one oft-ignored factor is how these campaigns affect the infrastructure health of the application. These campaigns usually introduce a spike in application usage and reveal application infrastructure to be under-provisioned. To mitigate the adverse effect of the campaign to an application, firms currently deploy an ad-hoc process. This approach involves capturing key data points of user traffic from campaigns and key performance metrics from an Application Performance Manager 2 Mathur et al.: DIGITAL CAMPAIGN TRACKING WITH RESPECT TO APPLICATION INFRASTRUCT Published by Technical Disclosure Commons, 2018 Copyright 2018 Cisco Systems, Inc. 2 5609 (APM), and attempting to correlate the two. This is limited because the whole process is usually manual, accounts for a limited historical data set, is non-adaptive to continuous changes in campaign strategy or application infrastructure, and is mostly pivoted on prior human experience. Figure 1 below provides examples illustrating these problems.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
505195a1db461b083ee30141923b1610ec2cb8ee,https://www.semanticscholar.org/paper/505195a1db461b083ee30141923b1610ec2cb8ee,Artificial intelligence and the dreaded 's.,"Numerous industries are being disrupted by growth in new technologies, especially information technologies, and healthcare is no exception. Advances in robotics, wireless sensor networks, 5D printing, and cloud technologies are reshaping countless industries. I am intrigued by the increasing importance of automation, machine learning, and artifi cial intelligence (AI) in healthcare. Let us explore three questions together: • Where are common applications of AI and automation in healthcare? • What implications for physician assistants (PAs) arise from increased automation and AI in caring for patients? • Did AI bring back the ’s that causes any self-respecting PA to cringe? I nearly panicked recently when I caught sight of the following two headlines from online articles about new healthcare technologies, which might lead a person to think the PAs of the future are not people at all. At the very least, I was ready to e-mail the AAPA communications team to combat those pesky apostrophes. The articles actually detailed advances in automation and AI within healthcare. Bright.MD raises another $8M for “virtual physician’s assistant” SmartExam (www.mobihealthnews.com/content/ brightmd-raises-another-8m-virtual-physicians-assistantsmartexam) Healthcare Chatbots: The Physician’s Assistant of the Future? (http://blog.kantarhealth.com/blog/brian-mondry/ 2016/11/28/healthcare-chatbots-the-physician’s-assistantof-the-future) Next, let us sort out AI and automation. According to Merriam Webster, artifi cial intelligence is the capability of a machine to imitate intelligent human behavior. Automation, on the other hand, is the automatically controlled operation of an apparatus, process, or system by mechanical or electronic devices that take the place of human labor. COMMON APPLICATIONS A widely adopted automation in healthcare is appointment reminder software that automatically reminds patients of their upcoming scheduled appointments, with options to customize the message and/or time it is delivered for patient preference. Similarly, missed appointment notifi cation systems can alert a PA to a potentially worrisome pattern of missed appointments for a patient identifi ed as high-risk. Robotics, commonly deployed in areas such as pharmacy and surgery, are automations proven to increase effi ciency and safety. According to CB Insights, about 86% of healthcare provider organizations, life science companies, and healthcare technology vendors are using AI technology. The most common applications seem to fall into one of ten categories: managing medical records and other data; doing repetitive jobs such as analyzing tests, interpreting radiologic studies, and data entry; helping design treatment plans; digital consultation (such as the Babylon app); virtual nurses (such as the Molly app), medication management (such as the AiCure app); drug development; precision medicine; health monitoring; and healthcare system analysis.1 Numerous tech giants are investing heavily in AI applications for healthcare as well, such as Microsoft’s Healthcare NExT initiative and Google’s Deepmind Health.",JAAPA : official journal of the American Academy of Physician Assistants,2018.0,10.1097/01.JAA.0000530302.23280.25,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3f3f00fc84c5ea2f6fba2dea24d139dfcc2278bb,https://www.semanticscholar.org/paper/3f3f00fc84c5ea2f6fba2dea24d139dfcc2278bb,Visual Model Interpretation for Epidemiological Cohort Studies,"Epidemiological cohort studies investigate the cause and development of diseases in human populations. Conventional analyses are challenged by recently increasing study sizes, which is why the incorporation of machine learning gains popularity. State-of-the-art classifiers are however often hard to interpret – an important requirement in medical applications. This thesis addresses the gap between predictive power and interpretability in the context of cohort study analysis. Main contribution is the development of an interactive visual interface for the interpretation and comparison of probabilistic classifiers. It supports the analysis of important features at both global and individual level, computation of partial dependence, and iterative construction of meaningful feature groups. To analyse the longitudinal influence of features, the user can modify the feature set by removing a feature or replacing its value by a previous examination record. The developed visual interface is evaluated in two case studies in order to test its effectiveness for the generation and validation of research hypotheses. The case studies include a realworld epidemiological cohort study and synthetic data. The results indicate the interface’s usefulness for epidemiological research, but also reveal necessary further work for the deployment into a productive environment.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0567b8ddbc6d517c70d7fd032f55710cec0fb92e,https://www.semanticscholar.org/paper/0567b8ddbc6d517c70d7fd032f55710cec0fb92e,Integrated satellite‐terrestrial networks in future wireless systems,"This special issue is devoted to capture the latest advances in scientific, industrial, regulatory, and standardisation analyses in satellite communications (SatCom), with particular emphasis on future integrated satellite‐terrestrial networks. During the last years, an unprecedented and ever increasing demand for broadband high‐speed, heterogeneous, ultrareliable, secure, and low latency communications has been motivating and leading the definition of new standards and technologies for wireless communications, known as 5G. In particular, from the network point of view, several diverse trends can be identified, as, eg, the evolution towards smarter devices, the sharp increase in the number of connected wearable and machine‐to‐machine (M2M) devices, or the intensification of augmented reality (AR), and virtual reality (VR) services. The vision provided by ITU for IMT‐2020 systems back in 2015 highlighted a set of technical requirements for future systems, as, for instance: (a) up to a hundred‐fold increase in user experienced data rate; (b) a 10‐fold decrease in latency; and (c) a hundred times increase in network efficiency. These challenging requirements come along with other key drivers as the emergence of Internet of things (IoT), ie, billions of objects connected to the Internet, which is the enabler for smart cities, or the need to ensure network reliability, robustness, and availability, as well as cybersecurity. The key role that 5G systems will play in the worldwide economic and societal processes to support next generation vertical services, aiming at a seamlessly connected society, is thus leading the massive scientific and industrial interest in 5G communications. Future (5G and beyond) wireless communications will bring together not only people but also things, data, applications, smart cities, and transportation in a smart, integrated, and seamless networked society, impacting the well‐known 5G vertical markets, ie, Internet of things, Industry 4.0, automotive and transportation sectors, e‐Health, and factories of the future. In this context, the integration of satellite and terrestrial networks can be a cornerstone to the realisation of the foreseen heterogeneous global system to enhance the end user experience. Due to their inherently large footprint, satellites can efficiently complement and extend dense terrestrial networks, both in densely populated areas and in rural zones, as well as provide reliable Mission Critical services. In the past, there has been a loose interaction between the satellite and terrestrial communities, which have developed almost independently from each other, and this led to a difficult a posteriori integration between the two systems to provide seamless services. Thanks to the initiation of the new 5G communication standards, and learning from past experience, the satellite and terrestrial communities are now working together to realize a fully fledged satellite‐terrestrial architecture based on the 5G ecosystem. This is reflected, in particular, in the framework of 3GPP standardisation, in which a new study item on non‐terrestrial networks (NTN) has recently been approved and initiated. NTN systems are expected to support 5G services in isolated or remote areas that cannot be served, or are underserved, by terrestrial networks, to reinforce the 5G service reliability and continuity for M2M and IoT and to enable 5G network scalability. During recent 3GPP RAN meetings, phase one studies for NTN have been concentrated on the definition of several scenarios, which can be categorized based on the type of satellite payload, ie, transparent or regenerative. In particular, on the one hand, when geostationary earth orbit (GEO) or low earth orbit (LEO) transparent satellites are deployed, the satellite operates as a radio frequency repeater providing backhaul connection towards the next generation NodeB (gNB) located at the system gateway (GW); in this case, the satellite is thus operating as the radio unit (RU), while the overall remote radio unit (RRU) is completed by the baseband unit (BU) at the GW. On the other hand, when a regenerative payload is considered, functional split concepts can be applied to SatCom; in particular, the gNB protocol stack can be split at different layers to be implemented onboard the satellite, operating as the distributed unit of the gNB (gNB‐DU), while the remaining upper layers are implemented at the GW in the centralized unit (gNB‐CU). The possibility to implement multiple gateways is also being assessed, which requires a high degree of coordination and advanced mobility management functions in order to ensure proper coordination at all protocol layers. Multiconnectivity between the satellite and terrestrial networks is also foreseen, in line with the discussion reported above. The integration of satellite and terrestrial networks, and in particular the impact that satellite typical impairments might have on the 5G air interface and protocols, poses the need to address key aspects related to waveforms, signalling, and resource allocation with respect to the physical layer (PHY), as well as possible modifications to the upper layer procedures, due to the large delays, and new business cases to build commercially viable solutions for manufacturers and operators. When LEO satellites are considered, it is worth noticing that, in order to ensure a global service coverage, a mega‐constellation of satellites is required. This is one of the emerging challenges in the SatCom business, and it is based on the concept that hundreds of low orbit, and possibly",Int. J. Satell. Commun. Netw.,2018.0,10.1002/sat.1292,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5cde71cc3a4884d54d4c730851889ca44c3d490,https://www.semanticscholar.org/paper/d5cde71cc3a4884d54d4c730851889ca44c3d490,Vibration-based structural health monitoring using large sensor networks,"Recent advances in hardware and instrumentation technology have allowed the possibility of deploying very large sensor arrays on structures. Exploiting the huge amount of data that can result in order to perform vibration-based structural health monitoring (SHM) is not a trivial task and requires research into a number of specific problems. In terms of pressing problems of interest, this paper discusses: the design and optimisation of appropriate sensor networks, efficient data reduction techniques, efficient and automated feature extraction methods, reliable methods to deal with environmental and operational variability, efficient training of machine learning techniques and multi-scale approaches for dealing with very local damage. The paper is a result of the ESF-S3T Eurocores project ""Smart Sensing For Structural Health Monitoring"" (S3HM) in which a consortium of academic partners from across Europe are attempting to address issues in the design of automated vibration-based SHM systems for structures.",,2010.0,10.12989/SSS.2010.6.3.335,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1b2198523b79be5ed653bb24b1944ba023ac5b7f,https://www.semanticscholar.org/paper/1b2198523b79be5ed653bb24b1944ba023ac5b7f,"Mitigating noise and traffic congestion through measuring, mapping, and reducing noise pollution","Noise is a ubiquitous and omnipresent urban pollutant with serious health issues. This so-called “forgotten pollutant” includes all types of sounds including vehicular noise, barking dogs, music, and human sounds. Mechanical noise, and especially traffic sound, is especially “annoying” as it manifests in a plethora of ways that can be constant, intermittent, or impulsive. We have approached noise mitigation efforts via notions of “you can’t fix what you can’t measure,” “seeing is believing,” machine-aided soundscape listening, and unusually cost-effective, robust, scalable sensor network designs for dense, spatiotemporal soundmaps creation. In this paper we report on updates—Citygram’s recent partnership with IBM and its “Horizon” edge compute system, plug-and-sense sensor network hardware/software, visualizations, machine learning and sensor scaling/deployment strategies—applicable towards capturing road, rail, aircraft, and other types of urban noise agents to improve understanding of urban livability a...",,2017.0,10.1121/1.4988389,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
afe1c47d0c01ae20d807036f3fbb4df6cc1e4f72,https://www.semanticscholar.org/paper/afe1c47d0c01ae20d807036f3fbb4df6cc1e4f72,Ecological momentary interventions for depression and anxiety,"Ecological momentary interventions (EMIs) are becoming more popular and more powerful resources for the treatment and prevention of depression and anxiety due to advances in technological capacity and analytic sophistication. Previous work has demonstrated that EMIs can be effective at reducing symptoms of depression and anxiety as well as related outcomes of stress and at increasing positive psychological functioning. In this review, we highlight the differences between EMIs and other forms of treatment due to the nature of EMIs to be deeply integrated into the fabric of people's day‐to‐day lives. EMIs require unique considerations in their design, deployment, and evaluation. Furthermore, given that EMIs have been advanced by changes in technologies and that the use of behavioral intervention technologies for mental health has been increasing, we discuss how technologies and analytics might usher in a new era of EMIs. Future EMIs might reduce user burden and increase intervention personalization and sophistication by leveraging digital sensors and advances in natural language processing and machine learning. Thus, although current EMIs are effective, the EMIs of the future might be more engaging, responsive, and adaptable to different people and different contexts.",Depression and anxiety,2017.0,10.1002/da.22649,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5d9ad70e93bd93a1d942cd96ffd538ae3c964cf6,https://www.semanticscholar.org/paper/5d9ad70e93bd93a1d942cd96ffd538ae3c964cf6,A Distributed Sensor Network for Waste Water Management Plant Protection,,Sensors,2016.0,10.1007/978-3-319-55077-0_39,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
56909f565bcff87f0387b8d3e4ab4376515a7aee,https://www.semanticscholar.org/paper/56909f565bcff87f0387b8d3e4ab4376515a7aee,Sensor data analysis and information extraction for structural health monitoring,"Recently, advances in sensing techniques, internet technologies, and wireless communications are increasingly facilitating and allowing practical deployment of large and dense sensor networks for structural health monitoring. Thus, it is vital to develop efficient techniques to process and analyze the massive amount of sensor data in order to extract essential information on the monitored structures. The efforts in this dissertation are mainly dedicated to this direction, including studies on structural damage identification and traffic pattern recognition. In these studies, traditional analysis tools for structural engineering (e.g., finite element (FE) based simulation) are utilized, and the potential of machine learning techniques is extensively explored. 
Using different strategies, three structural damage identification approaches (referred to as approach A, B, and C, respectively) are developed in this dissertation. Both approaches A and B adopt decentralized analysis frameworks, which define substructures in the monitored system according to the sensor spatial distribution. Within approach A, each substructure is represented by a dynamic model, and the system properties are periodically identified based on sensor measurements for monitoring purposes. Herein, approach A is applied to seismic downhole data to monitor changes in soil layer properties. As for approach B, a neural network is developed for each substructure to predict the dynamic response at a selected sensor location from measurements of neighboring sensors. Thus, the dynamic characteristics of the substructure are represented by the network, and changes in the statistical distribution of network prediction error are evaluated and utilized as a damage indicator. Three applications of approach B are presented, two based on experimental data and one of bridge pier damage identification based on simulation data. Approach C adopts a statistical pattern recognition paradigm. Within this framework, a range of damage patterns of interest is provided by numerical simulation, the Principal Components Analysis (PCA) technique is employed for feature extraction, and a neural network is developed for damage pattern identification. Herein, approach C is also applied to the bridge pier damage identification problem. Finally, the combination of neural networks and PCA is also employed to develop a strain-based vehicle classification approach, based on a unique strain-video dataset.",,2006.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
18d1f54f339d556f5a1f8984fe9eb22ab52be9cf,https://www.semanticscholar.org/paper/18d1f54f339d556f5a1f8984fe9eb22ab52be9cf,Activity recognition in the home setting using simple and ubiquitous sensors,"In this work, a system for recognizing activities in the home setting that uses a set of small and simple state-change sensors, machine learning algorithms, and electronic experience sampling is introduced. The sensors are designed to be “tape on and forget” devices that can be quickly and ubiquitously installed in home environments. The proposed sensing system presents an alternative to sensors that are sometimes perceived as invasive, such as cameras and microphones. Since temporal information is an important component of activities, a new algorithm for recognizing activities that extends the naive Bayes classifier to incorporate low-order temporal relationships was created. Unlike prior work, the system was deployed in multiple residential environments with non-researcher occupants. Preliminary results show that it is possible to recognize activities of interest to medical professionals such as toileting, bathing, and grooming with detection accuracies ranging from 25% to 89% depending on the evaluation criteria used. Although these preliminary results were based on small datasets collected over a two-week period of time, techniques have been developed that could be applied in future studies and at special facilities to study human behavior such as the MIT Placelab. The system can be easily retrofitted in existing home environments with no major modifications or damage and can be used to enable IT and health researchers to study behavior in the home. Activity recognition is increasingly applied not only in home-based proactive and preventive healthcare applications, but also in learning environments, security systems, and a variety of human-computer interfaces.",,2003.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5c3cffd4545666e09c5b5192186284037693eccc,https://www.semanticscholar.org/paper/5c3cffd4545666e09c5b5192186284037693eccc,The application of data mining and cloud computing techniques in data-driven models for structural health monitoring,"Recently, data-driven models for Structural Health Monitoring (SHM) have been of great interest among many researchers. In data-driven models, the sensed data are processed to determine the structural performance and evaluate the damages of an instrumented structure without necessitating the mathematical modeling of the structure. A framework of data-driven models for online assessment of the condition of a structure has been developed here. The developed framework is intended for automated evaluation of the monitoring data and structural performance by the Internet technology and resources. The main challenges in developing such framework include: (a) utilizing the sensor measurements to estimate and localize the induced damage in a structure by means of signal processing and data mining techniques, and (b) optimizing the computing and storage resources with the aid of cloud services. The main focus in this paper is to demonstrate the efficiency of the proposed framework for real-time damage detection of a multi-story shear-building structure in two damage scenarios (change in mass and stiffness) in various locations. Several features are extracted from the sensed data by signal processing techniques and statistical methods. Machine learning algorithms are deployed to select damage-sensitive features as well as classifying the data to trace the anomaly in the response of the structure. Here, the cloud computing resources from Amazon Web Services (AWS) have been used to implement the proposed framework.",SPIE Smart Structures and Materials + Nondestructive Evaluation and Health Monitoring,2016.0,10.1117/12.2218707,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
024b93294970bd610e212bb004e2bd143c65058f,https://www.semanticscholar.org/paper/024b93294970bd610e212bb004e2bd143c65058f,Composite Activity Recognition in Smart Homes Using Markov Logic Network,"Smart environments have progressed and evolved into a significant research area with development of sensor technology, wireless communication and machine learning strategies. Ambient Intelligence incorporated into smart environment assists in resolving many social related applications to facilitate the future society. The initiative of modeling Activity of Daily Living (ADL) and Ambient Assisted Living (AAL) in smart homes have helped in the deployment of applications to various domains like elderly care, health care etc. Activity recognition is the task involved in reasoning within smart homes with the aim of recognizing the ongoing activity of the occupant. Constructing an activity model is essential to carry out recognition and is achieved through various machine learning and artificial intelligence techniques. Data driven approach constructs activity model through statistical machine learning mechanisms while knowledge driven approach constructs activity model through knowledge representation and modeling strategies. Uncertainty and temporal data are better handled by data driven approach while re-usability and context based analysis is handled better by knowledge driven approach of activity modeling. To combine the features of data driven and knowledge driven approaches, a hybrid activity modeling technique is required. The proposed system performs activity modeling via Markov Logic Network, a machine learning strategy that combines probabilistic reasoning and logical reasoning with a single framework. Activities in a smart home are categorized as simple and composite activities, wherein composite activities are defined as related simple activities within a given time interval. The proposed system models both simple and composite activity using soft and hard rules of MLN. Experiments carried over the proposed system shows the effectiveness of the proposed work for recognizing simple and composite activity.",2014 IEEE 11th Intl Conf on Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on Autonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on Scalable Computing and Communications and Its Associated Workshops,2014.0,10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.31,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ba48a39ffff2a1d45f7ac6614a3f5137e028d60,https://www.semanticscholar.org/paper/2ba48a39ffff2a1d45f7ac6614a3f5137e028d60,IEEE Access Special Session Editorial: Big Data Services and Computational Intelligence for Industrial Systems,"The pervasive nature of big data technologies as witnessed in industry services and everyday life has given rise to an emergent, data-focused economy stemming from many aspects of industrial applications. The richness and vastness of these services are creating unprecedented research opportunities in a number of industrial fields including public health, urban studies, economics, finance, social science, and geography. We are moving towards the era of Big Data Services , which are deployed in a multi-scale complex distributed architecture. These services can be formed a high-level computational intelligence based on emerging analytical techniques such as big data analytics and web analytics. In this context, computational intelligence employs software tools from advanced analytics disciplines such as data mining, predictive analytics, and machine learning. At the same time, it becomes increasingly important to anticipate technical and practical challenges and to identify best practices learned through experience. This special session has included nine papers, and a brief summary about each paper is presented as follows.",IEEE Access,2015.0,10.1109/ACCESS.2016.2516178,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
015474f1d1f4c8d0c0c0f314dc9d56aeacad1c88,https://www.semanticscholar.org/paper/015474f1d1f4c8d0c0c0f314dc9d56aeacad1c88,Non-intrusive sleep pattern recognition with ubiquitous sensing in elderly assistive environment,,Frontiers of Computer Science,2015.0,10.1007/s11704-015-4404-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4885c17120a3d74d62b4e2cf9636d2e26bc2bae6,https://www.semanticscholar.org/paper/4885c17120a3d74d62b4e2cf9636d2e26bc2bae6,Behavioral Context Recognition In the Wild,"The ability to automatically recognize a person's behavioral context (including where they are, what they are doing, who they are with, etc.) is greatly beneficial in health monitoring, aging care, personal assistants, smart homes, customized entertainment, and many other domains. For all of these different applications to succeed on a larger scale, the context-recognition component must be unobtrusive and work smoothly, without making people adjust their behavior. It is important for research to validate context-recognition systems in the real world - under the same conditions in which such applications will eventually be deployed. In this thesis, I promote context recognition in-the-wild, capturing people's authentic behavior in their natural environments using natural, everyday devices.In Chapter 1, I introduce the field of behavioral context recognition, and describe three parts of research in the field: defining the problem (what are the inputs and what are the outputs), collecting data, and artificial intelligence (AI) / machine learning (ML) methods.In Chapter 2, I present the problem of behavioral context recognition and the challenges of addressing behavior in-the-wild. I introduce the ExtraSensory Dataset, which was collected from 60 participants in-the-wild, and is publicly available at http://extrasensory.ucsd.edu. I describe simple machine learning methods and demonstrate that smartphones and smartwatches can be used to successfully recognize diverse contexts in regular life (e.g., walking, sleeping, at school, on a bus, cooking, shower, phone in pocket).In Chapter 3, I specifically address machine learning solutions that facilitate training classifiers with irregular data from the wild - highly unbalanced, with occasions of missing labels or sensors, and potentially collected in phases addressing different sets of labels.In Chapter 4, I address the challenge of collecting labeled data in-the-wild and describe our self-reporting solution - the ExtraSensory App. I analyze the collected data and subjective feedback from the participants to gain insights about user-interface design to engage users to contribute labels about their own behavior. A revised version of the app, with improvements based on this dissertation, is publicly available at http://extrasensory.ucsd.edu/ExtraSensoryApp.In Chapter 5, I discuss the progress this work makes in the field of behavioral context recognition, and suggest directions for future improvements.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8f2a47cd8a04aa7985d36c1106b01f35290be30f,https://www.semanticscholar.org/paper/8f2a47cd8a04aa7985d36c1106b01f35290be30f,Development of 80- and 100- Mile Work Day Cycles Representative of Commercial Pickup and Delivery Operation,"When developing and designing new technology for integrated vehicle systems deployment, standard cycles have long existed for chassis dynamometer testing and tuning of the powertrain. However, to this day with recent developments and advancements in plug-in hybrid and battery electric vehicle technology, no true “work day” cycles exist with which to tune and measure energy storage control and thermal management systems. To address these issues and in support of development of a range-extended pickup and delivery Class 6 commercial vehicle, researchers at the National Renewable Energy Laboratory in collaboration with Cummins analyzed 78,000 days of operational data captured from more than 260 vehicles operating across the United States to characterize the typical daily performance requirements associated with Class 6 commercial pickup and delivery operation. In total, over 2.5 million miles of realworld vehicle operation were condensed into a pair of duty cycles, an 80-mile cycle and a 100-mile cycle representative of the daily operation of U.S. class 3-6 commercial pickup and delivery trucks. Using novel machine learning clustering methods combined with mileage-based weighting, these composite representative cycles correspond to 90th and 95th percentiles for daily vehicle miles traveled by the vehicles observed. In addition to including vehicle speed vs time drive cycles, in an effort to better represent the environmental factors encountered by pickup and delivery vehicles operating across the United States, a nationally representative grade profile and key status information were also appended to the speed vs. time profiles to produce a “work day” cycle that captures the effects of vehicle dynamics, geography, and driver behavior which can be used for future design, development, and validation of technology. Introduction Under DOE-FOA-0001349 FY15 Award for Mediumand Heavy-Duty Vehicle Powertrain Electrification, Cummins and PACCAR jointly proposed the development of a range-extending plug-in hybrid electric Class 6 pickup and delivery truck. The goal of this project is to demonstrate an electrified vehicle that would deliver a minimum of 50% reduction in fuel consumption across a range of representative drive cycles. In addition to achieving the 50% fuel reduction target, the vehicle also needs to demonstrate as good or better drivability and performance while still meeting emissions requirements when compared to existing conventionally fueled baseline vehicles. Most existing duty cycles used to test conventional internal combustion powered vehicles are of a limited time duration. For example, the Hybrid Truck Utility Forum Class 6 Pickup and Delivery cycle is slightly more than one hour. When testing a system using only fuel as its energy source, this is acceptable; a onehour duty cycle can be used to represent the vehicle operation for the entire work day (e.g., fuel consumption in the middle of the day is very similar to fuel consumption at the end of the day). However, with plug-in electric vehicles, the system (battery characteristics and thermal management systems) may operate differently throughout the work day (especially near the end of the day). For example, the available battery energy may be completely spent prior to the completion of the route. A short duty cycle cannot simply be extrapolated. Evaluating the vehicle over the entire work day also provides the ability to interject appropriate stops that are typical of the Class 6-7 pickup and delivery application. These stops can range from several minutes to much longer and can have significant thermal effect on the vehicle and powertrain systems. These stops may also have a large impact on overall duty cycle mileage (and other duty cycle characteristics such as average speed) as the stops may account for roughly half of the work day. As part of the research and development team, the National Renewable Energy Laboratory (NREL) was been NREL/CP-5400-70943. Posted with permission. Presented at WCX 18: SAE World Congress Experience, 10-12 April 2018, Detroit, Michigan.",,2018.0,10.4271/2018-01-1192,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6e76b0d359fd8a6a373ce96fd5458deec5252d9a,https://www.semanticscholar.org/paper/6e76b0d359fd8a6a373ce96fd5458deec5252d9a,An Engineering Toolbox to Build Situation Aware Ambient Assisted Living Systems,"Due to increasing anticipated average life and health expenditure ambient assisted living (AAL) systems attract the attention of researchers. To successfully build and deploy AAL systems knowledge from different fields of computer science is needed: pervasive computing to gain the raw data, machine learning and pattern recognition to interpret these data and HCI knowledge to allow implicit interaction with the system.In this paper we propose a reference architecture for building AAL systems. Based on this reference architecture we introduce a toolbox that simplifies the development of AAL systems. The toolbox consists of a meta-model for pipeline systems, a low-level context model, high-level context ontologies, customizable components and tool support.","2008 Third International Conference on Broadband Communications, Information Technology & Biomedical Applications",2008.0,10.1109/BROADCOM.2008.36,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
55e79bb5ba46c7240f699c296e449b43d7b1463b,https://www.semanticscholar.org/paper/55e79bb5ba46c7240f699c296e449b43d7b1463b,Snorkel: A System for Lightweight Extraction,"We describe a vision and an initial prototype system for extracting structured data from unstructured or dark input sources–such as text, embedded tables, and images– called Snorkel, in which users write traditional extraction scripts which are automatically enhanced by machine learning techniques. The key technical idea is to view the user’s actions with standard tools as implicitly defining a statistical model. For example, to extract mentions of supplierpurchaser relations in SEC filings, a user of Snorkel might write several scripts that reference lists of company names, known supplier-purchaser relations, or specific textual patterns. Snorkel is able to automatically assess each script’s reliability for the task, combine their outputs together in a statistically sound way, and use the combined signals to train a machine learning model with automatically generated features to perform the task more accurately and broadly. Compared to current machine learning approaches, Snorkel is our attempt to make an end-run around two major pain points: hand-labeling training data and feature engineering. More broadly, Snorkel is a first step toward our vision of a new generation of data systems that are observational: systems that observe users working with standard tools, and use machine learning techniques “behind the scenes” to improve performance. In preliminary hacakathons, non-expert users from the biomedical domain have quickly neared or exceeded competition benchmarks, and Snorkel is now in use by a handful of technology companies, government organizations, and scientists. Lightweight Macroscopic Analysis Snorkel is intended for tasks in which users’ time and technical skills are limited, and the output schema is unknown or rapidly changing. Typically, dark data systems are deployed only in large corporations and government agencies due to their expense and high technical barrier to entry. Moreover, they are only deployed in situations in which a fixed, high-value schema is known in advance. In many scenarios, however, users may only have on the order of a week to write high-quality extractors with new and evolving schemas—for example, researchers looking for new types of anomalous drug interactions in electronic health records, or financial analysts examining newly released earning reports. Snorkel empowers users to quickly write programs that are radically more ro-",CIDR,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2f470cfddc970e8d134aacfa42600f0c399eed48,https://www.semanticscholar.org/paper/2f470cfddc970e8d134aacfa42600f0c399eed48,Evaluating Intrusion Detection Systems for Energy Diversion Attacks,"The widespread deployment of smart meters and ICT technologies is enabling continuous collection of high resolution data about consumption behavior and health of grid infrastructure. This has also spurred innovations in technological solutions using analytics/machine learning methods that aim to improve efficiency of grid operations, implement targeted demand management programs, and reduce distribution losses. One one hand, the technological innovations can potentially lead large-scale adoption of analytics driven tools for predictive maintenance and anomaly detection systems in electricity industry. On the other hand, private profit-maximizing firms (distribution utilities) need accurate assessment of the value of these tools to justify investment in collection and processing of significant amount of data and buy/implement analytics tools that exploit this data to provide actionable information (e.g. prediction of component failures, alerts regarding fraudulent customer behavior, etc.) In this thesis, the focus on the value assessment of intrusion/fraud detection systems, and study the tradeoff faced by distribution utilities in terms of gain from fraud investigations (and deterrence of fraudulent customer) versus cost of investigation and false alarms triggered due to probabilistic nature of IDS. Our main contribution is a Bayesian inspection game framework, which models the interactions between a profit-maximizing distribution utility and a population of strategic customers. In our framework, a fraction of customers are fraudulent they consume same average quantity of electricity but report less by strategically manipulating their consumption data. We consider two sources of information incompleteness: first, the distribution utility does not know the identity of fraudulent customers but only knows the fraction of these consumers, and second, the distribution utility does not know the actual theft level but only knows its distribution. We first consider situation in which only the first source of information incompleteness is present, i.e., the distribution utility has complete information about the actual theft level. We present two simultaneous game models, which have same assumption 3 about customer preferences and fraud, but differ in the way in which the distribution utility operates the IDS. In the first model, the distribution utility probabilistically chooses to use IDS with a default (fixed) configuration. In the second model, the distribution utility can configure/tune the IDS to achieve an optimal operating point (i.e. combination of detection probability and false alarm rate). Throughout, we assume that the theft level is greater than cost of attack. Our results show that for, the game with default IDS configuration, the distribution utility does not use the IDS in equilibrium if the fraction of fraudulent customers is less than a critical fraction. Also the distribution utility realizes a positive “value of IDS” only if one or both have the following conditions hold: (a) the ratio of detection probability and false alarm probability is greater than a critical ratio, (b) the fraction of fraudulent customers is greater than the critical fraction. For the tunable IDS game, we show that the distribution utility always uses an optimal configuration with non-zero false alarm probability. Furthermore, the distribution utility does not tune the false alarm probability when the fraction of fraudulent customers is greater than a critical fraction. In contrast to the game with fixed IDS, in the game of tunable IDS, the distribution utility realizes a positive value from IDS, and the value increases in fraction of fraudulent customers. Next, we consider the situation in which both sources of information incompleteness are present. Specifically, we present a sequential game in which the distribution utility first chooses the optimal configuration of the IDS based on its knowledge of theft level distribution (Stage 1), and then optimally uses the configured IDS in a simultaneous interaction with the customers (Stage 2). This sequential game naturally enables estimation of the “value of information” about theft level, which represents the additional monetary benefit the distribution utility can obtain if the exact value of average theft level is available in choosing optimal IDS configuration in Stage 1. Our results suggest that the optimal configuration under lack of full information on theft level lies between the optimal configurations corresponding to the high and low theft levels. Interestingly enough, our analysis also suggests that for certain technical (yet realistic) conditions on the ROC curve that characterizes achievable detection probability and false alarm probability configurations, the value of information about certain combination of theft levels can attain negligibly small values. Thesis Supervisor: Saurabh Amin Title: Robert N. Noyce Career Development Assistant Professor",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0ced62d2a76a2f8e1eac1869688e2b06a265a187,https://www.semanticscholar.org/paper/0ced62d2a76a2f8e1eac1869688e2b06a265a187,Predictive models for identifying risk of readmission after index hospitalization for heart failure: A systematic review,"Aims: Readmission rates for patients with heart failure have consistently remained high over the past two decades. As more electronic data, computing power, and newer statistical techniques become available, data-driven care could be achieved by creating predictive models for adverse outcomes such as readmissions. We therefore aimed to review models for predicting risk of readmission for patients admitted for heart failure. We also aimed to analyze and possibly group the predictors used across the models. Methods: Major electronic databases were searched to identify studies that examined correlation between readmission for heart failure and risk factors using multivariate models. We rigorously followed the review process using PRISMA methodology and other established criteria for quality assessment of the studies. Results: We did a detailed review of 334 papers and found 25 multivariate predictive models built using data from either health system or trials. A majority of models was built using multiple logistic regression followed by Cox proportional hazards regression. Some newer studies ventured into non-parametric and machine learning methods. Overall predictive accuracy with C-statistics ranged from 0.59 to 0.84. We examined significant predictors across the studies using clinical, administrative, and psychosocial groups. Conclusions: Complex disease management and correspondingly increasing costs for heart failure are driving innovations in building risk prediction models for readmission. Large volumes of diverse electronic data and new statistical methods have improved the predictive power of the models over the past two decades. More work is needed for calibration, external validation, and deployment of such models for clinical use.",European journal of cardiovascular nursing : journal of the Working Group on Cardiovascular Nursing of the European Society of Cardiology,2018.0,10.1177/1474515118799059,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
667d1da01344286cf6f0f8104d1d6ddc2a61eb31,https://www.semanticscholar.org/paper/667d1da01344286cf6f0f8104d1d6ddc2a61eb31,Handbook of sustainable engineering,,,2013.0,10.1007/978-1-4020-8939-8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dbf22e7605dad93903c5c21e15d5b05b3ace7b02,https://www.semanticscholar.org/paper/dbf22e7605dad93903c5c21e15d5b05b3ace7b02,Cohort profile: the Prospective Research In Stress-Related Military Operations (PRISMO) study in the Dutch Armed Forces,"Purpose The Prospective Research in Stress-Related Military Operations (PRISMO) study was initiated to gain a better understanding of the long-term impact of military deployment on mental health, and to map the different biological and psychological factors that contribute to the development of stress-related mental health symptoms. Participants The PRISMO cohort consists of a convenience sample of Dutch military personnel deployed to Afghanistan between 2005 and 2008. Baseline data collection resulted in the recruitment of 1032 military men and women. Combat troops as well as non-combat support troops were recruited to increase the representativeness of the sample to the population as a whole. Findings to date The prevalence of various mental health symptoms increases after deployment in PRISMO cohort members, but symptom progression over time appears to be specific for various mental health symptoms. For post-traumatic stress disorder, we found a short-term symptom increase within 6 months after deployment (8.2%), and a long-term symptom increase at 5 years after deployment (12.9%). Several biological vulnerability factors associated with the development of stress-related conditions after deployment were identified, including predeployment glucocorticoid receptor sensitivity and predeployment testosterone level. Thus far, 34 publications have resulted from the cohort. Future plans Various analyses are planned that will include the prevalence of mental health symptoms at 10 years postdeployment, as well as trajectory analyses that capture the longitudinal development of symptoms. Furthermore, we will use a machine learning approach to develop predictive and network models for several mental health symptoms, incorporating biological, psychological and social factors.",BMJ Open,2019.0,10.1136/bmjopen-2018-026670,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
baed8fa1c5f9d696fd41c8034afd91fbc61975ce,https://www.semanticscholar.org/paper/baed8fa1c5f9d696fd41c8034afd91fbc61975ce,Exploring Support Vector Machines and Random Forests for the Prognostic Study of an Arboviral Disease,"The need for rapid access to information in order to support critical decisions in public health cannot be disputed; however, development of such systems requires an understanding of the actual informational requirements of the practitioners. This paper explores the application of machine learning techniques for the detection of one of the Arboviral disease – Dengue. This paper reports original biological discovery through nontrivial data mining process by using accessible computational techniques. The goal of the system is to prop up the assortment, and recovery of public health documents, data, learning objects, and tools. We have deployed this standard infrastructure to facilitate data integration and knowledge sharing in the domain of dengue, which is one of the most prevalent Arboviral diseases. The proposed novel technique exhibits highly precise prediction rate (with total Mean Squared Error 0.06665807).",,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
70ae8b1c61273fc83209036fd919b9eef930be96,https://www.semanticscholar.org/paper/70ae8b1c61273fc83209036fd919b9eef930be96,Knowledge from Mechanical Behaviour Data ahmed hosny Submitted to the Graduate School of Design for the partial fulfillment of the requirements for the degree of Master in Design Studies in Technology,"This research aims to record, quantify and study material behavior within a data analytics framework. It does so while harnessing the power of the so-called ""big data"" in physical environments using both analytical and experimental methods. Current structural health monitoring systems are one-off applications that are non-scalable and only act as alert mechanisms. The focus is thus on a material-data interface that is scalable, developed for mass produced objects and is to be utilized during deployment stages. Daily sensor-embedded objects are placed online and hence have their deformation data logged onto the cloud. Data mining is then used to extract useful insights as well as predict future trends. By selectively reducing the degrees of strain measurement within objects and coupling that with machine learning, the research showcases relatively good accuracy in predicting displacements and loads acting on objects. The aggregation of such data over time allows for new design iteration workflows or data-informed design, aids in developing user-object interaction models and allows for a better understanding of challenging load cases that are difficult to model such as fatigue. A foundation for the Internet of Materials is thus proposed bridging sensor technologies, machine learning and the Internet of Things.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cce600d54ef32b3f6312b9166da097e0f9eded8a,https://www.semanticscholar.org/paper/cce600d54ef32b3f6312b9166da097e0f9eded8a,Designing a Visual Analytics System for Industry-Scale Deep Neural Network Models,"The complexity of industry-scale deep learning models and datasets pose unique design, visualization, and system challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have designed, developed, and deployed ACTIVIS, a visual analytics system for interpreting industry-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both instanceand subset-level. ACTIVIS has been deployed on Facebook’s machine learning platform. This article is a summary for the VAST’17 paper (TVCG track) ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models [2]. 1 DESIGNING FOR INDUSTRY-SCALE MODELS Despite the increasing interest in developing visualization tools for deep learning interpretation [5–7], the complexity of large-scale models and datasets used in industry pose unique design challenges that are inadequately addressed by existing work. For example, while most existing visualization tools target image datasets, deep learning tasks in industry often involve different types of data, including text and numerical data. Furthermore, in designing tools for realworld deployment, it is a high priority that the tools be flexible and scalable, adapting to the wide variety of models and datasets used. These observations motivate us to design and develop ACTIVIS [2], a visual analytics system for deep neural network models, now deployed on Facebook’s machine learning platform. Since the ACTIVIS project started in April 2016, we have conducted participatory design sessions with over 15 Facebook engineers, researchers, and data scientists across multiple teams to learn about their visual analytics needs. We identified six key design challenges — for data, model, and analytics — that have not been adequately addressed by existing deep learning visualization tools. The challenges include the need to support: (1) diverse input data sources, (2) high data volume, (3) complex model architecture, (4) a great variety of models, (5) diverse subset definitions for analytics, and (6) both instanceand subset-level analyses. These challenges shape the main design goals of ACTIVIS. 2 ACTIVIS CONTRIBUTIONS ACTIVIS’s main contributions include: • A novel visual representation that unifies instanceand subsetlevel inspections of neuron activation, facilitating comparison of activation patterns for multiple instances. *e-mail: kahng@gatech.edu †e-mail: mortimer@fb.com ‡e-mail: adityakalro@fb.com §e-mail: polo@gatech.edu • An interface that tightly integrates an overview of graph-structured complex models and local inspection of neuron activations, allowing users to explore the model at different levels of abstraction. • A deployed system scaling to large datasets and models. • Case studies with Facebook engineers and data scientists that highlight how ACTIVIS helps them with their work. ACTIVIS’s multiple coordinated views help users get a high-level overview of the model from which the user can drill down to perform localized inspection of activations. ACTIVIS visualizes how neurons are activated by user-specified instances or instance subsets, to help users understand how a model derives its predictions. The subsets can be flexibly defined using data attributes, features, or output results, enabling model inspection from multiple angles. While many existing deep learning visualization tools support instancelevel exploration [6, 7], ACTIVIS is the first tool that simultaneously supports instanceand subset-level exploration. Both exploration strategies are common and effective, and they offer complementary analytics benefits. Instance-based analysis instructs how individual instances contribute to a model’s accuracy, but it is tedious to inspect many instances one by one. Subset-based analysis leverages input features or instance subsets to help reveal relationships between data attributes and machine learning algorithms’ outputs [3]. It is especially beneficial when dealing with huge datasets in industry, which may consist of millions or billions of data points. By exploring instance subsets and enabling their comparison with individual instances, users can learn how them models respond to many different slices of the data. We refer our readers to the longer version of our ACTIVIS [2] VAST’17 paper published in IEEE Transactions on Visualization and Computer Graphics.",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
881da38df5ad2b71dcc500bf5041c6cec562b14f,https://www.semanticscholar.org/paper/881da38df5ad2b71dcc500bf5041c6cec562b14f,THE ROLE OF MULTIMODAL IN THE LEARNING SENSORIMOTOR INVOLVEMENT OF COGNITIVE SKILLS,"The existence and extent of effects of small-scale haptic involvement on recall performance in an explicit memory task were investigated in two related experiments involving a total of 40 subjects. The memory task was structured in such a way that it abstracts two of the fundamental activities encountered when interacting with realworld equipment through physical control interfaces: 1) the identification of the state of the system to be acted on; and 2) the recall of the series of actions which are to be taken when the system is in that state. Furthermore, the experiments were designed as training experiments. Haptic sensorimotor involvement is evaluated as an aid to training -it is used during practice and not used during performance. Results from Memory Experiment 1 show (i.e., Ho: p < 0.01 for 5 minute, 30 minute, and 24 hour examinations) that experimental group subjects performed approximately 2.5 times better when they trained with both visual stimuli (i.e., a keypad graphic) and haptic involvement than when they trained without these visual and haptic stimuli. Memory Experiment 2 shows (i.e., Ho: p < 0.05 for 5 and 30 minute examinations) that experimental group subjects performed approximately 1.5 times better when they trained with the keypad graphic and haptic interaction than when they trained with the keypad graphic only. These results were obtained even though the design of the experiments was such that independent variables affected the training of only the action part of sequences (i.e., the training of the sequence label was not affected by the independent variables) and experimental group examinations required recall of sequences memorized under two different conditions. The results of the two memory experiments suggest that: 1) small-scale haptic involvement can act as a training aid for a purely cognitive task; and 2) small-scale haptic involvement can compliment visual stimuli as an aid to training in a purely cognitive task. Thesis Supervisor : Nathaniel I. Durlach Title: Senior Scientist, Department of Electrical Engineering and Computer 1.0 Introduction The increased commercial availability of interface and computational devices supporting the development of multimodal, spatially-oriented, interactive human/machine interfaces has contributed to a burgeoning interest in the field of human/computer interaction (Biocca, 1992). Devices such as binocular stereoscopic helmet mounted displays, binaural stereophonic spatialization devices, haptic interaction devices, and unobtrusive position/orientation sensors are enabling the creation of human/machine interfaces for interaction with telerobots and computational models of a form and type which were previously found only in specialized research and military efforts (e.g., Freund, 1986; Shaker and Wise, 1988; Tachi, Arai, and Maeda, 1989; Aviles, Hughes, Everett, et. al., 1990). In their most extreme manifestations, systems utilizing these technologies are attempting to remove the boundaries associated with devices mediating interaction between humans and remote task environments (physical and computer generated) and, in some sense, project the human into these remote or virtual environments. Virtual environment (VE) systems in particular are experiencing a high degree of interest from the military, commercial, and private sectors. Current and foreseen application domains for VE systems include: (1) design, manufacturing, and marketing; (2) medicine and health care; (3) entertainment; and (4) training (Durlach and Mavor, 1995). This discussion will focus on research issues associated with using VE systems and technology for training. From a training perspective, some key features of virtual environments are that they are: 1) interactive and adaptive; 2) reconfigurable in software; 3) multimodal; and 4) can generate supernormal situations (Durlach, Pew, Aviles, DiZio, and Zeltzer, 1992). These features allow VE-based training systems to be developed which can be precisely tailored to specific tasks and individuals. In many ways, however, VE-based training systems may be viewed as natural outgrowths of previous simulation-based training systems (e.g., flight trainers). In some form, all four aforementioned key VE features apply to these ""classical"" trainers. In what ways, therefore, are VE-based systems unique? First of all, in contrast to classical simulation systems, VE-based systems can be highly reconfigurable for BOTH the far-field (i.e., objects and interactions out of reach) and the near-field (i.e., objects and interactions within reach). Classical flight simulators, for example, only reconfigure the scenery and environment outside of the airplane (i.e., the far-field) and do not easily allow flexibility in the airplane display and control layout (i.e., the near-field). In contrast, a VE-based training system can simulate a variety of nearand far-field configurations while utilizing the same human/machine interface devices. The second key characteristic of VE-based training systems is the potential for allowing multimodal (i.e., visual, auditory, and haptic) interactions. Unlike classical computer-based simulation systems, near-field simulations can be generated which may seen, felt, and heard in a spatially-oriented manner. Virtual environment systems, therefore, are unique in that they can generate reconfigurable multimodal sensorimotor near-field interactions. A large and growing percentage of the tasks encountered in military, commercial, and private enterprises, however, are predominantly cognitive in nature. For example, many of these tasks require mainly that the human operator control and monitor a system through the use of a control panel. Although the main interaction with such control panels is through the sensorimotor system, the requirement to know what controls to operate and when to operate them is largely a cognitive task. One viewpoint is that, given the aforementioned trends, training for manipulative skills is unimportant. Strong proponents of this view argue that the majority of IMPORTANT skills, independent of frequency of occurrence, are largely cognitive in nature (Welford, 1976). By extension, it is argued that, since sensorimotor skills are not the main skills which must be trained, sensorimotor involvement in VE-based training systems is not required or is of secondary importance. In other words, it is assumed that sensorimotor involvement is not needed for the training of cognitive skills. In the research described in this thesis, these assumptions were tested and the effect of multimodal sensorimotor involvement in the training of predominantly cognitive tasks was examined in a task which requires subjects to: 1) identify a discrete system state, and 2) identify a series of discrete actions which must be taken in response to that state. Training effectiveness is measured and compared between 1) ""classical"" textbased training methods and 2) training methods which provide visual stimuli and which require haptic sensorimotor involvement. 2.0 Background Intellectual or cognitive skills ""link perception and action and are concerned with translating perceptual input into a skilled response by using appropriate decisions."" Colley and Beach, 1989, p. 2 From a training research viewpoint, VE-based systems are interesting only to the extent that training efficiency, skill performance, or skill retention are influenced and/or psychophysical insight may be gained. From a practical viewpoint, issues of cost (e.g., training system cost, time/cost required to train to a certain level of proficiency, and resource use costs), safety (i.e., limiting trainee exposure to threatening situations), portability (i.e., ability to effect training at a variety of sites) and reconfigurability (i.e., ability to use the same system to train a variety of skills) are of import. Lower training effectiveness measures may be tolerable in certain situations if the system's practical factors evaluate positively for a given training system. Nonetheless, a crucial factor in the evaluation of any training methodology or system is its training effectiveness. To date, however, research relevant to assessing the quantitative impact of multimodal sensorimotor involvement in the training of predominantly cognitive tasks has been minimal. Current models that are directed towards the learning of cognitive skills often fail to consider the possible effects of sensorimotor involvement in the learning of these cognitive skills (e.g., Anderson 1990, Posner, 1989; Preece, Rogers, Sharp, Benyon, Holland, and Carey, 1994; Benyon and Murray, 1993; Frederiksen and White, 1993; Roberts, 1993). Most relevant research has occurred in the use of subject performed tasks (SPTs) and experimenter performed tasks (EPTs) in event/action recall memory experiments (e.g., Cohen, 1981; Cohen, Peterson, and Mantini-Atkinson, 1987; Koriat, Ben-Zur, and Nussbaum, 1990; McAndrews and Milner, 1991). These experiments, however, explore the effects of multimodal sensorimotor involvement on the recall of tasks which are inherently sensorimotor in nature. To the knowledge of the author, principled examination of the impact of multimodal sensorimotor involvement on the training of predominantly cognitive skills is non-existent. Why pursue work in this area? First of all, insight into the role of multimodal sensorimotor involvement in training will have strong implications for the practical design of VE-based training systems (e.g., assessing if the added complexity and cost of haptic and auditory components is worthwhile for a given training task). Second, experimental results may aid in extending current cognitive training theory to encompass sensorimotor involvement. The question still remains, however, as to what evidence or plausible mechanisms exist which indicate that multimodal sensorimotor involvement may have an effect on the training of cognitive tasks? Changes in training perform",,2008.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2027e2b74bfe625c881209702446f3ac74517fbc,https://www.semanticscholar.org/paper/2027e2b74bfe625c881209702446f3ac74517fbc,Long-term performance assessment of the Telegraph Road Bridge using a permanent wireless monitoring system and automated statistical process control analytics,"Abstract The purpose of this study is to advance wireless sensing technology for permanent installation in operational highway bridges for long-term automated health assessment. The work advances the design of a solar-powered wireless sensor network architecture that can be permanently deployed in harsh winter climates where limited solar energy and cold temperatures are normal operational conditions. To demonstrate the performance of the solar-powered wireless sensor network, it is installed on the multi-steel girder bridge carrying northbound I-275 traffic over Telegraph Road (Monroe, Michigan) in 2011; a unique design feature of the bridge is the use of pin and hanger connections to support the bridge main span. A dense network of strain gauges, accelerometers and thermometers are installed to acquire bridge responses of interest to the bridge manager including responses that would be affected by long-term bridge deterioration. The wireless monitoring system collects sensor data on a daily schedule and communicates the data to the Internet where it is stored in a curated data repository. Bridge response data in the repository are autonomously processed to extract truck load events using machine learning, compensate for environmental variations using nonlinear regression and to quantitatively assess anomalous bridge performance using statistical process control.",,2017.0,10.1080/15732479.2016.1171883,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c6cdde9134f6373311dbfd805ac84a69647ec7c3,https://www.semanticscholar.org/paper/c6cdde9134f6373311dbfd805ac84a69647ec7c3,Smart Monitoring: An Intelligent System to Facilitate Health Care across an Ageing Population,"In the UK, the number of people living with self-limiting conditions, such as Dementia, Parkinson’s disease and depression, is increasing. The resulting strain on national healthcare resources means that providing 24-hour monitoring for patients is a challenge. As this problem escalates, caring for an ageing population will become more demanding over the next decade. Our research directly proposes an alternative and cost effective method for supporting independent living that offers enhancements for Early Intervention Practices (EIP). In the UK, a national roll out of smart meters is underway, which enable detailed around-the-clock monitoring of energy usage. This granular data captures detailed habits and routines through the users’ interactions with electrical devices. Our approach utilises this valuable data to provide an innovative remote patient monitoring system. The system interfaces directly with a patient’s smart meter, enabling it to distinguish reliably between subtle changes in energy usage in real-time. The data collected can be used to identify any behavioural anomalies in a patient’s habit or routine, using a machine learning approach. Our system utilises trained models, which are deployed as web services using cloud infrastructures, to provide a comprehensive monitoring service. The research outlined in this paper demonstrates that it is possible to classify successfully both normal and abnormal behaviours using the Bayes Point Machine binary classifier.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
efb247294b66ec334f81f9f53f4baf00e54ccc40,https://www.semanticscholar.org/paper/efb247294b66ec334f81f9f53f4baf00e54ccc40,Digital Transformation in Healthcare – South Africa Context,"Digital transformation is growing at a slow rate in medical schemes or healthcare compared to other industries such as banking and insurance. The healthcare sector needs to embrace the digital transformation and adopt and optimize on use of technology, otherwise, the sector will be left behind. Other sectors have taken advantage of technology, for example in the retail sector, nowadays people shop online, bank, and do travel bookings online. The logistic business has also embraced digital transformation in that most activities are now done through devices at the convenience of one’s office or home. The recent HPCSA conference included topics such as Telemedicine’s where several digital transformation and innovations in the health sector were also presented. What was evident in the discussions was that progress in accelerating digital transformation is pounded by a slow pace of regulation and other relevant guidelines. The topics discussed clearly revealed that the health sector is still far behind compared to other countries. For example, there is a gap in the adoption of digitally enabled tools for diagnosing, providing treatment, and better management of chronic conditions and other conditions. Electronic medical records are still not a part of routine care both from the supply and the funders side except a handful of players. On the funders side, you do find several medical schemes that invest in technology, for example, there are schemes that are already implementing digital application forms for smooth onboarding of new members. This is with the aim of going digital and reduces paper application forms. Similarly, with the submission of claims of which more than 98% are submitted in electronic form has transformed significantly. Strategies such as digital marketing are typically used to reach the target market and communicate more effectively with members. Several schemes have invested a lot in product development such as mobile apps, developing communication channels through online and social media platforms. Social media platforms provide an opportunity for brand repositioning, it also provides an opportunity to reach a new target market and access to a larger pool potential client base. Social media platforms could also be used as a tool to improve service to clients, create convenience, provide instant interaction with clients. However, very few medical schemes optimize on these platforms, particularly small to medium schemes. There is still a need to measure value add of digital transformation to members, chiefly where the quality of care is concerned. *Address correspondence to this author at the General Manager Research and Monitoring, Council for Medical Schemes, South Africa; E-mail: m.willie@medicalschemes.com The Health Professions Council of South Africa is a statutory regulator of healthcare professions in South Africa. Medical schemes are non-profit organisation which are registered with the Registrar of Medical Schemes. Members belonging to a scheme make contributions and in return receive medical cover according to the rules of the scheme. A recent study conducted by Willie (2019) which was an unstructured survey on the use of medical scheme mobile app by members. The survey revealed than more than 75% of the respondents did not have the app installed. Some of the sentiments for not using the app were: • Lack of awareness about the app • The app is complex • No reason to use the app • Does not meet my needs Digital disruption has great potential in healthcare, the main areas of investments are certainly Big Data analytics and AI (Artificial Intelligence). Some of the big data analytics tools are useful for improving efficiencies where some of the tools can be automated, this potentially could yield better utilization of human resources and could potentially have huge cost savings. In the main, Big data and AI tools are used to profile clients, medical service providers and look at healthcare utilization patterns and trends. Some of the techniques such as predictive analytics are important in that they can be used not only to profile member but create a strategy to combat attrition. Insights from the data could be useful for data drive decision-making process that potentially save huge downstream cost for medical schemes. There is also great potential in investing in digital marketing and the optimal use of mobile apps. DIGITAL TRANSFORMATION INNITIATIVES IN THE PUBLIC SECTOR SOUTH AFRICA HEALTHCARE There are several innovations that must take place in the public sector in South Africa as far as digital 2 Global Journal of Immunology and Allergic Diseases, 2019, Vol. 7 Willie and Nkomo transformation is concerned, chiefly these are still at beta phases and their overall impact and outcomes are still to be realized. Furthermore, there are pockets of digital innovations in the public sector dating back to 2014, some are initiatives employed at provincial level whiles others are deployed at the national level. An integrated holistic approach at the national level could ascertain value add and impact in the sector. Box 1 below depicts the Department of Health’s (DoH) digital and eHealth developments and implementation from 2014. USE OF ARTIFICIAL INTELLIGENCE IN HEALTHCARE Artificial Intelligence (AI), Machine Learning (ML) and Big Data Analytics are some of the most talkedabout technologies in recent years. According to Bali, Garg, and Bali (2019), AI aims to mimic human cognitive functions, such as the ability to reason, discover meaning, generalize, or learn from experience. Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data (Jiang, 2017). Machine learning is the foundation of modern AI and is essentially an algorithm that allows computers to learn independently without following any explicit programming (Uzialko, 2019). The use of AI is already at advanced stages in other industries, the adoption in healthcare is growing at a steady rate, however, there is no doubt AI is certainly going to change the face of healthcare delivery. AI is being employed in a numerous setting, for example, Year Digital developments 2014 Aviro launched their innovative eHealth app. North West department of health outlines eHealth plans (RHIS) Cell – Life’s iDART hits the target. Tier. Net, the software application that monitors patients on HIV and TB treatment. The NDoH has issued a tender for a service provider to conduct an evaluation of the use of the Tier.Net NDoH sets out eHealth standards evaluation process 2015 The Mpumalanga DoH issues eHealth tender eHealth rollout high on Gauteng’s agenda Mobenzi has partnered with the Anova Health Institute to support the Limpopo (DoH) with the deployment of the Mobenzi mHealth technology emocha launches TB mHealth platform in South Africa NDoH is working with the CSIR to develop an eHealth system to accompany the rollout of NHI North West DoH announce eHealth pilot 2016 emocha Boosting MDR-TB linkage to care in South Africa emocha’s miLINC for MDR-TB mHealth platform was designed after the NDoH approached John Hopkins University The Human Research Science Council (HSRC) has announced the development of a new mHealth app aimed specifically at pregnant teens NDoH using eHealth to improve health facilities South Africa adopts WHO’s HIV ‘Test and Treat’ guidelines 2017 mHealth aiding in the diagnoses of burn injuries Generic and Biosimilar Medicine of Southern Africa has asked the South African government to accelerate the evaluation and registration of more affordable biosimilar medicines in South Africa. South African medical information-exchange company, Healthbridge, has announced their acquisition of Infosys software solutions’ healthcare division WHO and ITU to use eHealth to strengthen health services in Africa South Africa digital health accelerator attracts top eHealth startups 2018 The National Department of Health (NDoH) has identified IT and health information systems (HIS). The South African Medical Research Council (SAMRC) has partnered with Jembi Health systems NPC Philips and UJ renew MoU to empower healthcare professionals Digital health Cape Town have announced the commencement of their second accelerator programme A new mobile app, called ViaOpta Hello, has been unveiled to help hundreds of thousands of South African living with blindness and severe visual impairment 2019 a subsidiary of CompuGroup Medical SE has developed an e-scripting solution that is helping over 1,000 South African doctors ensure medication adherence among their patients. Aviro Health launches whatsapp channel to support HIV self-testing Box 1: Digital developments in the public sector. Digital Transformation in Healthcare – South Africa Context Global Journal of Immunology and Allergic Diseases, 2019, Vol. 7 3 funders, as well as administrators, use it to adjudicate and process of claims, hospital facilities for assessing bed occupancy. AI is also used to analyses unstructured data such as images, videos, physician notes to enable clinical decision making and information sharing. Other commentators such as Reddy (2018) argues that AI is more prevent in the area of medical diagnosis. AI systems can analyze huge volumes of data faster far more than humans, this improves efficiencies in identifying medical diagnoses than doctors. It should be noted that AI cannot completely replace the medical profession but could be used as a tool to optimize currently process and reach medical conclusions and decision-making factor, thus saving costs and improving quality of life. APPLICATIONS OF ARTIFICIAL INTELLIGENCE Artificial has the potential to change the healthcare industry in South Africa for the better, this is subject to optimal use in both the supply and demand side of the health care ecosystem. AI is deliver",Global Journal of Immunology and Allergic Diseases,2019.0,10.31907/2310-6980.2019.07.01,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
de54d22466f6078ea5295692c8cd3c686a316874,https://www.semanticscholar.org/paper/de54d22466f6078ea5295692c8cd3c686a316874,Introducing an All-mechanized Surgical Assistant for Use in Reconstructive Surgeries,"1 Copyright © 2019 The Authors. Published by Wolters Kluwer Health, Inc. on behalf of The American Society of Plastic Surgeons. This is an open access article distributed under the Creative Commons Attribution License 4.0 (CCBY), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Sir, T is currently a critical lack of surgeons in many advanced countries, including Japan. A geographic shortage of plastic surgeons is also sometimes considered to be a social problem.1,2 The key to solving this issue depends on proper and thoughtful deployment of surgical resources and on how smoothly the medical education system can provide residents with appropriate educational opportunities. During surgeries, surgical assistants often do nothing but simple tasks such as keeping the surgical field clear and simply follow top-down orders throughout the operation. Performance of these activities is a waste of talent and time for an assistant who has similar or higher skills than the senior surgeon. Alternatively, if the assistant is at the training level, he or she rarely gets effective learning opportunities due to standing in a position from which it is not possible to see the surgical field clearly. This situation provides young surgeons with nothing but a very poor view and position from which to have new surgical ideas. A totally automated operation could be one solution to these problems. Automated, unmanned hotels and retail services are becoming common. Machines and robots have already replaced people for helpful and essential assistance in daily life, and utilization of similar systems in the role of a surgical assistant is plausible. A good example is provided by the Octopus (MEDNOSBRO GmbH, Rudolfstetten, Switzerland), a device that serves as a versatile retractor system, and has 3 joints similar to those in a human upper limb, which allows precise all-direction maneuvers. In addition to this function, the system has flexible settings that allow a surgeon to place the machine in ideal positions to have a perfect view only by tightening or loosening a special screw attached to the device. A single surgeon can then complete an entire surgery using various tip parts of the retractor. Just like an assistant, the system plays a major role in the surgery, including facilitating a variety of flap elevations. Our surgical team has introduced the Octopus device into many kinds of reconstructive surgery, although mainly breast reconstruction, and we have shown that many plastic and reconstructive surgeries can be performed without an assistant. The device enables a single surgeon to complete the surgery alone, even in emergency situations, and never disturbs the surgeon’s work, loses focus, or becomes tired. The device makes it possible to reduce labor costs and to place sufficient talent in suitable positions, which releases assistants from unfruitful positions and consequently allows them to contribute much more in another field. If assistants are inexperienced residents, they can freely observe a surgery with a clear view that may not differ from the surgeon’s point of view, which allows acquisition of an understanding of a detailed procedure in an efficient way. There have been many beneficial results of device-assisted operations in various surgical fields,3–5 but relatively few in plastic and reconstructive surgery. However, this approach has great potential in this field, and we believe that this new surgical concept will spread quickly in the future.",Plastic and reconstructive surgery. Global open,2019.0,10.1097/GOX.0000000000002403,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
920b236f530422313ebccf5d43f7d3dd9103beba,https://www.semanticscholar.org/paper/920b236f530422313ebccf5d43f7d3dd9103beba,"International Conference on Computing and Artificial Intelligence ( ICCAI 2019 ) April 19-22 , 2019 Bali , Indonesia","Recently, deep learning (DL) plays important roles in many academic and industrial areas especially in computer vision and image recognition. Deep learning uses a neural network with deep structure to build a high-level feature space. It learns data-driven, highly representative, hierarchical image features, which have proven to be superior to conventional hand-crafted low-level features and mid-level features. In ILSVRC2015 (an Annual competition of image classification at large scale), higher recognition accuracy by deep learning than human has been achieved. Deep learning (DL) has also been applied to medical image analysis. Compared with DL-based natural image analysis, there are several challenges in DL-based medical image analysis due to their high dimensionality and limited number of labeled training samples. We proposed several deep learning techniques for medical image analysis including medical image segmentation, medical image detection and medical image recognition. In this keynote talk, I will talk about current progress and futures of medical image analysis with deep learning. ICCAI 2019 CONFERENCE ABSTRACT 12 Keynote Speaker IV Prof. Qijun Zhao Sichuan University, China Prof. Qijun Zhao is currently a professor in the College of Computer Science at Sichuan University. He obtained his B.Sc. and M.Sc. degrees in computer science both from Shanghai Jiao Tong University, and his Ph.D. degree in computer science from the Hong Kong Polytechnic University. He worked as a post-doc research fellow in the Pattern Recognition and Image Processing Lab at Michigan State University from 2010 to 2012. His recent research interests lie in 3D face modeling and recognition, with applications to forensics, intelligent video surveillance, mobile security, healthcare, and human-computer interactions. Dr. Zhao has published more than 60 papers in academic conferences and journals, including CVPR, ECCV, AAAI, ICB, IEEE Trans., and PR. He is the principal investigator for two projects funded by NSFC, one project funded by the National Key Research and Development Program of China, and many projects funded by companies. Dr. Zhao is a reviewer for many renowned field journals and conferences, such as IEEE TPAMI, IEEE TIFS, IJCV, PR, PRL, ICCV, CVPR, ECCV, and FG. He served as a program committee co-chair in organizing the 11th Chinese Conference on Biometric Recognition (CCBR 2016), the 2018 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), and the 2018 6th International Conference on Bioinformatics and Computational Biology (ICBCB 2018), and as a face recognition area co-chair for the 9th IEEE International Conference on Biometrics: Theory, Applications, and Systems (BTAS 2018). Topic: ""3D Face Reconstruction in Recognition Perspective"" Abstract—The face reveals a lot of information of humans, for example, identity, race, gender, age, emotion, intention, and health. 3D face models are thus widely studied in many disciplines. Yet, acquisition of 3D faces is still much more expensive and less convenient than acquisition of 2D face images, making it unaffordable to deploy 3D face technology in many real-world applications. Our research aims to reconstruct 3D face shapes from either single or multiple uncalibrated 2D face images from a perspective of identity recognition. This talk will introduce our recent progress along this direction. The methods we propose enable not only efficient generation of 3D face models when only 2D imaging devices are available, but also effective exploration of 3D face information for improving face recognition accuracy. We believe that 3D faces will play increasingly important roles in many applications with the rapid development of both 3D face acquisition techniques and 3D face modeling methods.The face reveals a lot of information of humans, for example, identity, race, gender, age, emotion, intention, and health. 3D face models are thus widely studied in many disciplines. Yet, acquisition of 3D faces is still much more expensive and less convenient than acquisition of 2D face images, making it unaffordable to deploy 3D face technology in many real-world applications. Our research aims to reconstruct 3D face shapes from either single or multiple uncalibrated 2D face images from a perspective of identity recognition. This talk will introduce our recent progress along this direction. The methods we propose enable not only efficient generation of 3D face models when only 2D imaging devices are available, but also effective exploration of 3D face information for improving face recognition accuracy. We believe that 3D faces will play increasingly important roles in many applications with the rapid development of both 3D face acquisition techniques and 3D face modeling methods. ICCAI 2019 CONFERENCE ABSTRACT 13 Keynote Speaker V Assoc. Prof. Ken‘ichi Morooka Kyushu University, Japan Assoc. Prof. Ken’ichi Morooka received his M.S. and Ph.D. degrees from Kyushu University, in 1997 and 2000, respectively. He was a visiting researcher with Institute of Systems & Information Technologies/KYUSHU. From 2000 to 2006, he was an associate professor in Graduate School of Science and Engineering, Tokyo Institute of Technology. He was an associate professor in Digital Medicine Initiative (2006-2010) and Department of Medical Sciences, Kyushu University (2010). Currently, he is an associate professor in Graduate School of Information Science and Electrical Engineering, Kyushu University. Also he was a visiting researcher, Illinois Institute of Technology, U.S. (2016). He has published more than 100 journal and conference articles. He has served as a member of organizing and program committees at numerous conferences, e.g. he has been program committes of MLMI 2018 and 2017, IFMIA 2017, CARS 2014 and EMBC 2013. His research interests cover computer-aided support system for therapy and surgery by image information processing and machine learning. Topic: ""Computer Aided System for Minimally Invasive Surgery Using Deep Learning"" Abstract—Recently, deep neural networks (DNNs) have been paid attention by various research fields including vision, audio and natural language. Of course, there are many DNN-based systems for therapy and diagnosis. Our research group has been doing research about computer-aided support systems for safe and accurate minimally invasive surgeries. Especially, to provide useful information for surgeons, our support systems use stereo endoscopic images, DNNs and 3D shapes and deformations of organs. I will present the fundamental techniques of our support system.Recently, deep neural networks (DNNs) have been paid attention by various research fields including vision, audio and natural language. Of course, there are many DNN-based systems for therapy and diagnosis. Our research group has been doing research about computer-aided support systems for safe and accurate minimally invasive surgeries. Especially, to provide useful information for surgeons, our support systems use stereo endoscopic images, DNNs and 3D shapes and deformations of organs. I will present the fundamental techniques of our support system. ICCAI 2019 CONFERENCE ABSTRACT 14 Invited Speaker Assoc. Prof. Sugiono Sugiono Brawijaya University, Indonesia Sugiono, Ph.D was born in Blitar, Indonesia, in 1978. He finished Bachelor degree in Mechanical Engineering Department at Brawijaya University in 2001, received Master Degree in Industrial Engineering at Sepuluh Nopember Institute of Technology, Surabaya in 2004, and graduated Ph.D. degree of Art, Design and Technology from University of Derby, UK, in 2012. Title of his thesis (PhD) is: Investigating an Intelligent Concept Design Tool for Automotive Car Body Design. His research interests lie in bioengineering ergonomics and intelligent product design. He worked as project analyser in investigating of fuel distribution for industry at PT. Surveyor Indonesia from 2001 to 2002. He also worked as purchasing vice leader at PT. Mitra Saruta (Textile) from 2004 to 2005. Currently, he is working as a lecturer at Department of Industrial Engineering, Brawijaya University start from 2005. He is a head of Work Design and Ergonomics Laboratory and head of Research Committee at Brawijaya University. He is an international reviewer of research, certificated by ISO 17024. He is also working as editor in chief of the Indonesian Journal of Disability Studies (IJDS). He is a senior member of Hong Kong Chemical, Biological and Environmental Engineering Society (HKCBEES), member of Indonesian Ergonomics Society (Perhimpunan Ergonomi Indonesia – PEI) and Member of International Association of Engineers (IAENG). Topic: ""The Importance of Open Innovation Concept to Improve Health and Safety Factors in Transportation"" Abstract—Controlling driver stress level is going to be popular research and put it a very important factor to reduce the risk of a road accident. Understanding the role of road complexity and information technology in transportation issues and their relationship with humans psychophysiological is a good challenge and profitable prospect for the future. Images from the Electrocardiograph (ECG) and Electroencephalography (EEG) are the important tools to identify the driver stress as part of a safety alert system. The Electrocardiograph (ECG) is to monitor every heart rate change and Electroencephalography (EEG) is to record brain signal change correlated with brain functions (thinking, visual, decision, etc.) from three different road types (city road, rural road, and motorway). In this speech, I will deliver a potential open innovation of health and safety factors in transportation (car, train) from the perspective of interaction among human, car, and environment.Controlling driver stress level is going to be popular research and put it a very important factor to reduce the risk of a road accident. Understanding the role of road complexity and information t",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fdeab769f14c7f0a89dce5a56eae3b59209af465,https://www.semanticscholar.org/paper/fdeab769f14c7f0a89dce5a56eae3b59209af465,Recognizing foods using deep neural networks under domain shift,"Obesity is one of the health problems in developed countries and it is a contributing factor for many diseases. Keeping the record of daily meal intake is an effective solution for tackling obesity and overweight. This can be done by developing apps that are able to automatically recommend a short list of most probable foods by analyzing the photo taken from food. Additionally, uncontrolled food intake could also lead to micronutrient deficiency which would shorten the life expectancy. One way to cope with vitamin deficiency and tackle obesity is to track our daily meals.
 Instead of using conventional dietary record methods, we can develop a system which is able to accurately estimate calorie intake of the user by analyzing images of foods. After finding the category of food, we can extract nutrition facts of the food and estimate its calorie. By tracking this information over time for a user, the system can recommend the user to change his or her habits or prepare a particular food.
 Recognizing foods from images possess some challenges. On the one hand, foods are highly deformable objects. This means that visual patterns of the same food in the same plate under the same ambient light can change significantly. On the other hand, occlusion of some ingredients by other ingredients makes recognition of food more difficult. Design of food and cooking style are other factors that make the food recognition harder. Furthermore, different seasoning and chopping might change the appearance of the same food. From the machine learning perspective, there are examples showing the intra-class variation problem in the task of food classification. Another challenge in food classification is the inter-class similarity. For instance, pasta with meat and pasta with vegetables visually may look similar. Misclassification of pasta with meat and pasta with vegetables causes miscalculation of their calories.
 There are powerful off-the-shelf machine learning models such as support vector machines and random forest that are able to learn complex decision boundaries. In order to use these models, we first need to extract a compact and informative feature vector. For this purpose, hand-crafted features such as color histogram, HOG, SIFT, LBP, Gabor filter or Bag of Features (BoF) could be extracted for an image. After extracting features, we train a classifier using one of the models that we mentioned above.
 Recent studies showed that the hand-crafted feature extraction methods are not adequately accurate for classifying foods. This is mainly due to the fact that different classes of food may overlap in the feature space. In other words, using the hand-crafted feature extraction methods, different classes of food might not be non-linearly separable (ie. two or more distinct classes might overlap) in the feature space. To train a model with a higher accuracy, we need a more powerful representation for images of food. Recently, Convolutional Neural Networks (ConvNets) have achieved impressive results on the ImageNet dataset. A ConvNet usually consists of several convolution layers and pooling layers that enables it to have more representation power than the hand-crafted approaches.
Given a dataset of adequate size and diversity, it is possible to find an architecture with an admissible accuracy on this dataset. Finding the network could be done manually by trying various architectures or it could be done using automatic architecture search algorithms. Although finding an architecture is still an interesting topic in this field, recent networks have been built by plugging several microarchitectures. It is also shown that different networks with considerably different architectures produce comparable results.
 In this thesis, we focus our attention on more demanding issues of neural networks which are important in developing practical applications. Specifically, we study knowledge adaptation, domain adaptation, active learning and knowledge distillation. Throughout the thesis, we will also study a few other topics and propose new techniques.
 Knowledge adaption is a technique to utilize the current knowledge of the network and adapt it to perform a new task. Knowledge adaptation is a branch of a broader topic called transfer learning. Given a pre-trained network, the common approach is to keep early layers of the network unchanged and finetune late layers of the network on the new task. This approach has been inspired by the fact that early layers of a network learn general features and late layers learn task-specific features.
 Picking layers to be trained and layers to be kept unchanged randomly might not be an accurate solution. Alternatively, we show how to use the Fisher Information Matrix to find which layers must be finetuned during knowledge adaptation. Then, we will propose a multi-task loss function to further improve the results.
 One of the issues in neural networks is that they do not inherently compute the uncertainty of the predictions. This is important in practical applications since we mainly want to report the prediction with high certainty. In other words, if the network is uncertain about the predicted class, we should not report it to the user.
 We will explain different techniques for computing the uncertainty of the prediction based on a single prediction. We will also show a technique called Monte Carlo dropout for estimating the uncertainty. Then, we will propose a method based on multi-crop evaluation for improving the results and approximating uncertainty, simultaneously.
 Whereas knowledge adaptation assumes that the pre-trained network is going to learn a different task using labeled data, unsupervised domain adaptation assumes that the network is going to perform the same task but the domain of source and target datasets are different. In addition, the target dataset is unlabeled. Domain adaptation is another branch of transfer learning and it studies how to reduce the divergence of two domains or how to learn an accurate mapping under domain shift. We will explain most commonly used techniques in this field, and we will propose a technique which is computationally more efficient than the state-of-the-art methods and it performs better in the task of food classification. Our method is a variant of self-training where we take into account uncertainty of prediction and use ensemble of predictions rather than a single prediction.
One way to exploit unlabeled data to improve the results is to use many unlabeled data. Previous results on semi-supervised learning have shown that the accuracy is improved by using unlabeled data together with labeled data. Another practical way to use unlabeled data is through a technique called active learning. Given the annotation budget, the major goal of active learning is to pick samples from a pool of unlabeled samples and ask a human to annotate them. The number of selected samples could not exceed the budget. The newly annotated samples are added to the dataset, and they are used to improving the network. The main question in active learning is how to pick samples that work better than random sampling. We will study various techniques for sample selection and perform a complete experiment on the task of food classification. We will show that informativeness measures work better than random selection.
The last part of our thesis deals with the problem of making our models compact. Our ultimate goal is to deploy the model on an embedded system or a smartphone with limited computational resources. Hence, it is essential to make our network as compact as possible in order to reduce the time to completion and use the resources efficiently. We will define a loss function to use labeled and unlabeled data for training a smaller network (mentee) by a bigger network (mentor). The first term in our loss function computes the cross-entropy between the normalized smoothed logits produced by the mentor and the normalized logits produced by the mentee. The second term in the loss function computed the mean square error of logits produced by the two networks on unlabeled images.
 Then, we will propose a new network architecture with lower complexity. Our network is composed of successive convolution layers followed by several fire-residual modules, expansion block and a classification layer. The first convolution layers are for reducing the spatial size of the input quickly. Then, the fire residual modules do complex transformations. Also, the expansion layer makes it possible to have rectangle shaped receptive fields. We simply use the softened logits as the ground truth data and use the cross-entropy to transfer the knowledge of the mentor to the mentee. Our experiments show that not only the mentee is able to imitate the mentor, it is also able to slightly improve the results.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c17da2168d6376b32e1599b0c2f6ad8b5a8e8651,https://www.semanticscholar.org/paper/c17da2168d6376b32e1599b0c2f6ad8b5a8e8651,Event Detection and Estimation Using Distributed Population Owned Sensors,"Author(s): Ibrahim, Ahmed Mokhtar Nagy | Advisor(s): Eltawil, Ahmed | Abstract: Smart phones are an indispensable tool in modern day-to-day life. Their widespread use has spawned numerous applications targeting diverse domains such as bio-medical, environment sensing and infrastructure monitoring. In such applications, the accuracy of the sensors at the core of the system is still questionable, since these devices are not originally designed for high accuracy sensing purposes. In this thesis, we investigate the accuracy limits of one of the commonly used sensors, namely, a smart phone accelerometer. As a use case, we focus on utilizing smart phone accelerometers in structural health monitoring (SHM). Using the already deployed network of distributed citizen-owned sensors is considered a cheap alternative to standalone sensors. These devices can capture floors vibration during disasters, and consequently compute the instantaneous displacement of each floor. Hence, damage indicators defined by government standards such as peak relative displacement can be estimated. In this work, we study the displacement estimation accuracy and propose a zero-velocity update (ZUPT) method for noise cancellation. Theoretical derivation and experimental validation are presented, and we discuss the impact of sensor error on the achieved building classification accuracy. Moreover, in spite of the presence of sensor error, SHM systems can be resilient by adopting machine learning. Several algorithms such as support vector machine (SVM), K-nearest neighbor (KNN) and convolutional neural network (CNN) are adopted and compared. Techniques for addressing noise levels are proposed and the results are compared to regular noise cancellation techniques such as filtering.Finally, since most previous work focused on modelling the sensor chip error itself, we study other sources of error such as sampling time uncertainty which is introduced by the device operating system (OS). That type of error can be considered a major contributor to the overall error, specially for sufficiently large signals. Hence, we propose a novel smart device accelerometer error model that includes the traditional additive noise as well as sampling time uncertainty errors. The model is validated experimentally using shake table experiments, and maximum likely-hood estimation (MLE) is used to estimate the model parameters. Moreover, we derive the Cramer-Rao lower bound (CRLB) of acceleration estimation based on the proposed model.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
07d1f21911f881ee23f512a9a58cd46a689eb3f2,https://www.semanticscholar.org/paper/07d1f21911f881ee23f512a9a58cd46a689eb3f2,2236. Stool-Derived Inflammatory Mediators Serve as Biomarkers of Severity in Clostridium difficile Infection,"Abstract Background Clostridium difficile infection (CDI) is a major public health concern and frequently results in severe disease, including death. Predicting subsequent complications early in the course can help optimize treatments and improve outcomes. However, models based on clinical criteria alone are not accurate and/or do not validate. We hypothesized that inflammatory mediators from the stool would be biomarkers for severity and complications. Methods Subjects were included after testing positive for toxigenic C. difficile by the clinical microbiology laboratory via enzyme immunoassay (EIA) for glutamate dehydrogenase and toxins A/B, with reflex to tcdB gene PCR for discordants. Stool was thawed on ice, diluted 1:1 with PBS and protease inhibitor, centrifuged, and the supernatant was analyzed by a custom antibody-linked bead array with 17 inflammatory mediators. Measurements were normalized and log-transformed. IDSA severity was defined by serum white blood cell count > 15000 cells/µL or creatinine 1.5-fold above baseline. Primary 30-day outcomes were all-cause mortality and attributable disease-related complications (DRC): ICU admission, colectomy, and/or death. Analyses included principal components, permutational multivariate ANOVA (PERMANOVA), and logistic regression ± L1 regularization and 5-fold cross validation. The area under the receiver operator characteristic curve (AuROC) was computed. Results We included 225 subjects, with 124 females (55.1%), average age 58.5 (±17), and more PCR+ than toxin EIA+ (170 vs. 55, respectively). IDSA severity, death, and DRCs occurred in 79 (35.1%), 14 (6.2%), and 12 (5.3%) subjects, respectively. PCA and PERMANOVA showed IDSA severity (P = 0.009) but not death or DRCs associated with the panel (figure). Several inflammatory mediators associated with IDSA severity and death (table). Machine learning models had AuROCs of 0.77 (IDSA severity), 0.84 (death), and 0.7 (DRCs). Conclusion We found that specific inflammatory mediators from the stool of patients with CDI associate with severity and complications. These results are promising, but need replication in a larger dataset and should be incorporated into models that include clinical covariates prior to deployment. Disclosures All authors: No reported disclosures.",Open Forum Infectious Diseases,2019.0,10.1093/ofid/ofz360.1914,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9267b0157df0790153466bd6b3670d70c8d7de0b,https://www.semanticscholar.org/paper/9267b0157df0790153466bd6b3670d70c8d7de0b,Resource allocation in future green wireless networks : applications and challenges,"Over the past few years, green radio communication has been an emerging topic since the footprint from the Information and Communication Technologies (ICT) is predicted to increase 7.3% annually and then exceed 14% of the global footprint by 2040. Moreover, the explosive progress of ICT, e.g., the fifth generation (5G) networks, has resulted in expectations of achieving 10-fold longer device battery lifetime, and 1000-fold higher global mobile data traffic over the fourth generation (4G) networks. Therefore, the demands for increasing the data rate and the lifetime while reducing the footprint in the next-generation wireless networks call for more efficient utilization of energy and other resources. To overcome this challenge, the concepts of small-cell, energy harvesting, and wireless information and power transfer networks can be evaluated as promising solutions for re-greening the world. 
 
In this dissertation, the technical contributions in terms of saving economical cost, protecting the environment, and guaranteeing human health are provided. More specifically, novel communication scenarios are proposed to minimize energy consumption and hence save economic costs. Further, energy harvesting (EH) techniques are applied to exploit available green resources in order to reduce carbon footprint and then protect the environment. In locations where implemented user devices might not harvest energy directly from natural resources, base stations could harvest-and-store green energy and then use such energy to power the devices wirelessly. However, wireless power transfer (WPT) techniques should be used in a wise manner to avoid electromagnetic pollution and then guarantee human health. To achieve all these aspects simultaneously, this thesis proposes promising schemes to optimally manage and allocate resources in future networks. 
 
Given this direction, in the first part, Chapter 2 mainly studies a transmission power minimization scheme for a two-tier heterogeneous network (HetNet) over frequency selective fading channels. In addition, the HetNet backhaul connection is unable to support a sufficient throughput for signaling an information exchange between two tiers. A novel idea is introduced in which the time reversal (TR) beamforming technique is used at a femtocell while zero-forcing-based beamforming is deployed at a macrocell. Thus, a downlink power minimizationscheme is proposed, and optimal closed-form solutions are provided. 
 
In the second part, Chapters 3, 4, and 5 concentrate on EH and wireless information and power transfer (WIPT) using RF signals. More specifically, Chapter 3 presents an overview of the recent progress in green radio communications and discusses potential technologies for some emerging topics on the platforms of EH and WPT. Chapter 4 develops a new integrated information and energy receiver architecture based on the direct use of alternating current (AC) for computation. It is shown that the proposed approach enhances not only the computational ability but also the energy efficiency over the conventional one. Furthermore, Chapter 5 proposes a novel resource allocation scheme in simultaneous wireless information and power transfer (SWIPT) networks where three crucial issues: power-efficient improvement, user-fairness guarantee, and non-ideal channel reciprocity effect mitigation, are jointly addressed. Hence, novel methods to derive optimal and suboptimal solutions are provided. 
 
In the third part, Chapters 6, 7, and 8 focus on simultaneous lightwave information and power transfer (SLIPT) for indoor applications, as a complementary technology to RF SWIPT. In this research, Chapter 6 investigates a hybrid RF/visible light communication (VLC) ultrasmall cell network where optical transmitters deliver information and power using the visible light, whereas an RF access point works as a complementary power transfer system. Thus, a novel resource allocation scheme exploiting RF and visible light for power transfer is devised. Chapter 7 proposes the use of lightwave power transfer to enable future sustainable Federated Learning (FL)-based wireless networks. FL is a new data privacy protection technique for training shared machine learning models in a distributed approach. However, the involvement of energy-constrained mobile devices in the construction of the shared learning models may significantly reduce their lifetime. The proposed approach can support the FL-based wireless network to overcome the issue of limited energy at mobile devices. Chapter 8 introduces a novel framework for collaborative RF and lightwave power transfer for wireless communication networks. The constraints on the transmission power set by safety regulations result in significant challenges to enhance the power transfer performance. Thus, the study of technologies complementary to conventional RF SWIPT is essential. To cope with this isue, this chapter proposes a novel collaborative RF and lightwave power transfer technology for next-generation wireless networks.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
593647de1b181a93357e041c07a5a931c2c02b7d,https://www.semanticscholar.org/paper/593647de1b181a93357e041c07a5a931c2c02b7d,An Antimicrobial Prescription Surveillance System that Learns from Experience,"Inappropriate prescribing of antimicrobials is a major clinical and health concern, as well as a financial burden, in hospitals worldwide. In this paper, we describe a deployed automated antimicrobial prescription surveillance system that has been assisting hospital pharmacists in identifying and reporting inappropriate antimicrobial prescriptions. One of the key characteristics of this system is its ability to learn new rules for detecting inappropriate prescriptions based on previous false alerts. The supervised learning algorithm combines instancebased learning and rule induction techniques. It exploits temporal abstraction to extract a meaningful time interval representation from raw clinical data, and applies nearest neighbor classification with a distance function on both temporal and non-temporal parameters. The learning capability is valuable both in configuring the system for initial deployment and improving its long term use. We give an overview of the application, point to lessons learned so far and provide insight into the machine learning capability.",AI Mag.,2013.0,10.1609/aimag.v35i1.2500,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f9c2c91673d675aafd68e8ed0e1107a83056f712,https://www.semanticscholar.org/paper/f9c2c91673d675aafd68e8ed0e1107a83056f712,Development of an heterogeneous wireless sensor network for instrumentation and analysis of beehives,"Honey bees have held a critical role in agriculture and nutrition from the dawn of human civilisation. The most crucial role of the bee is pollination; the value of pollination dependant crops is estimated at € 155 billion per year with honey bees identified as the most important pollinator insect. It is clear that honey bees are a vitally important part of the environment which cannot be allowed to fall into decline. The project outlined in this paper uses Wireless Sensor Network (WSN) technology to monitor a beehive colony and collect key information about activity/environment within a beehive as well as its surrounding area. This project uses low power WSN technologies, including novel sensing techniques, energy neutral operation, and multi-radio communications; together with cloud computing to monitor the behaviour within a beehive. The insights gained through this activity could reduce long term costs and improve the yield of beekeeping, as well as providing new scientific evidence for a range of honey bee health issues. WSN is an emerging modern technology, key to the novel concept of the Internet of Things (IoT). Comprised of embedded sensing, computing and wireless communication devices, they have found applications in nearly every aspect of daily life. Informed by biologists' hypotheses, this work used existing, commercially available WSN platforms together with custom built systems in an innovative application to monitor honey bee health and activity in order to better understand how to remotly monitor the health and behaviour of the bees. Heterogeneous sensors were deployed, monitoring the honey bees in the hive (temperature, CO2, pollutants etc.). Weather conditions throughout the deployment were recorded and a relationship between the hive conditions and external conditions was observed. A full solution is presented including a smart hive, communication, and data aggregation and visualisation tools. Future work will focus on improving the energy performance of the system, introducing a more specialised set of sensors, implementing a machine learning algorithm to extract meaning from the data without human supervision; and securing additional deployments of the system.",2015 IEEE International Instrumentation and Measurement Technology Conference (I2MTC) Proceedings,2015.0,10.1109/I2MTC.2015.7151292,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
92769374c37f4e0a2de5fe7f578d8a786389dd48,https://www.semanticscholar.org/paper/92769374c37f4e0a2de5fe7f578d8a786389dd48,for a Smart Home in a Box. Future,"This paper presents Vesta, a digital health platform composed of a smart home in a box for data collection and a machine learning based analytic system for deriving health indicators using activity recognition, sleep analysis and indoor localization. This system has been deployed in the homes of 40 patients undergoing a heart valve intervention in the United Kingdom (UK) as part of the EurValve project, measuring patients health and well-being before and after their operation. In this work a cohort of 20 patients are analyzed, and 2 patients are analyzed in detail as example case studies. A quantitative evaluation of the platform is provided using patient collected data, as well as a comparison using standardized Patient Reported Outcome Measures (PROMs) which are commonly used in hospitals, and a custom survey. It is shown how the ubiquitous in-home Vesta platform can increase clinical confidence in self-reported patient feedback. Demonstrating its suitability for digital health studies, Vesta provides deeper insight into the health, well-being and recovery of patients within their home.",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
df040ba4b648810e393d337ef05ded56e882802f,https://www.semanticscholar.org/paper/df040ba4b648810e393d337ef05ded56e882802f,hpcNMF: A high-performance toolbox for non-negative matrix factorization,"Non-negative matrix factorization (NMF) is a widely used machine learning algorithm for dimension reduction of large-scale data. It has found successful applications in a variety of fields such as computational biology, neuroscience, natural language processing, information retrieval, image processing and speech recognition. In bioinformatics, for example, it has been used to extract patterns and profiles from genomic and text-mining data as well as in protein sequence and structure analysis. While the scientific performance of NMF is very promising in dealing with high dimensional data sets and complex data structures, its computational cost is high and sometimes could be critical for delivering analysis results in a timely manner. In this paper, we describe a high-performance C++ toolbox for NMF, called hpcNMF, that is designed for use on desktop computers and distributed computer clusters. Algorithms based on different statistical models and cost functions as well as various metrics for model selection and evaluating goodness-of-fit are implemented in the toolbox. hpcNMF is platform independent and does not require the use of any special libraries. It is compatible with Windows, Linux and Mac operating systems; and message-passing interface is required for hpcNMF to be deployed on computer clusters to leverage the power of parallelized computing. We illustrate the utility of this toolbox using several real examples encompassing a broad range of applications. hpcNMF: A high-performance toolbox for non-negative matrix factorization Karthik Devarajan a,∗ aDepartment of Biostatistics & Bioinformatics, Fox Chase Cancer Center, Temple University Health System, Philadelphia, PA Guoli Wang b b3M Healthcare, Bethesda, MD Abstract Non-negative matrix factorization (NMF) is a widely used machine learning algorithm for dimension reduction of large-scale data. It has found successful applications in a variety of fields such as computational biology, neuroscience, natural language processing, information retrieval, image processing and speech recognition. In bioinformatics, for example, it has been used to extract patterns and profiles from genomic and text-mining data as well as in protein sequence and structure analysis. While the scientific performance of NMF is very promising in dealing with high dimensional data sets and complex data structures, its computational cost is high and sometimes could be critical for delivering analysis results in a timely manner. In this paper, we describe a high-performance C++ toolbox for NMF, called hpcNMF, that is designed for use on desktop computers and distributed computer clusters. Algorithms based on different statistical models and cost functions as well as various metrics for model selection and evaluating goodness-of-fit are implemented in the toolbox. hpcNMF is platform independent and does not require the use of any special libraries. It is compatible with Windows, Linux and Mac operating systems; and message-passing interface is required for hpcNMF to be deployed on computer clusters to leverage the power of parallelized computing. We illustrate the utility of this toolbox using several real examples encompassing a broad range of applications.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1089c3d2e5c1eb4fff1a91595d93ba635ee041bc,https://www.semanticscholar.org/paper/1089c3d2e5c1eb4fff1a91595d93ba635ee041bc,Rapidly Deployable Internet-of-Things Body Area Network Platform for Medical Devices,"Biomedical devices in the past provided limited capability for the data acquisition and presented the data in the form of user interface for a care provider to observe. Now, what is required for biomedical devices has fundamentally changed. Many devices must now support secure networking and include a network of sensors to enable machine learning-based sensor fusion for accurate inference of the subject’s state.This thesis introduces an Internet-of-Things (IoT) body area network (BAN) platform for medical devices that will provide rapid development capability with the assurance of security, networking, and the ability to host computationally intensive processes that are now required by medical devices. The BAN platform consists of seven wearable sensor nodes on the chest, wrists, upper legs, and ankles. Each sensor node includes sixteen general-purpose input/output (GPIO) pins, an analog-to-digital converter (ADC), two inter-integrated circuit (I2C) controllers, a serial peripheral interface (SPI), two universal asynchronous receiver transmitters (UART), and a universal serial bus (USB) on-the-go (OTG) to interface with sensors. The platform base model includes 9 degree-of-freedom inertial measurement unit (9DOF IMU) motion sensors, an electrocardiogram (ECG) sensor, a microphone, and a heart rate sensor. With its flexible interfaces, the platform is highly customizable and more sensors can be easily added.Each sensor node features an IoT computer-on-module called the Intel Edison. The device can connect to expansion boards for rapid development. Although it has two official expansion options, the BAN platform uses boards from a third party manufacturer due to their small size. Intel provides a library to access the external interfaces. The library is fully compatible only if the Arduino breakout is used. A C library that abstracts /sys/class/gpio interface was developed to access the GPIO. The ADC device used in the platform is an I2C device. A C library was developed that abstracts the I2C communication between the Intel Edison and the ADC to provide an intuitive application program interface (API). The UART interface is accessible via /dev/ttyMFD2. A Python package called PySerial is used to interface the serial port. These interfaces in addition to the Intel’s official breakouts and library enable many more applications.One of the most powerful features of the Intel Edison is its integrated WiFi module, enabling connection within the BAN and to the Internet. Since the BAN platform collects the user’s private health and activity data, the connection is secured by transport layer security (TLS). The networking among sensor nodes allows time synchronization with network time protocol (NTP) to have accurate sensor fusion.Powered by its Intel Atom dual-core processors, the BAN platform can host neural network-based classifiers to monitor users’ states. From experiments, the performance of the neural network hosted on the platform was found to be on par with that of neural network implemented in Matlab.The BAN platform was successfully distributed to freshmen, senior, and graduate IoT courses with exceptional assessment records. The IoT courses have shown that the students were able to rapidly develop fully functioning biomedical devices on the BAN platform.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a8f59ac02f845e7932528a28d013cbf25bdcf324,https://www.semanticscholar.org/paper/a8f59ac02f845e7932528a28d013cbf25bdcf324,"Advances in Data Analysis, Data Handling and Business Intelligence - Proceedings of the 32nd Annual Conference of the Gesellschaft für Klassifikation e.V., Joint Conference with the British Classification Society (BCS) and the Dutch/Flemish Classification Society (VOC), Helmut-Schmidt-University, Ha",,GfKl,2010.0,10.1007/978-3-642-01044-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98848b7aab22008c64760c81bfdf02df81410b25,https://www.semanticscholar.org/paper/98848b7aab22008c64760c81bfdf02df81410b25,Special section: Selected papers from the Fourth International Workshop on Recent Advances in Monte Carlo Techniques for Radiation Therapy,"Monte Carlo (MC) computational techniques are widely used for applications in radiation medicine and have traditionally covered the areas of radiation dosimetry, shielding, radiotherapy treatment planning, and radiological imaging. Moreover, they have contributed to the improvement and understanding of the link between physical parameters of radiation delivery and therapy success. Recently, MC methods are being integrated with other technologies used in radiation therapy, such as inverse optimization, deformable image registration, and machine learning techniques for outcomes studies, etc. The Fourth International Monte Carlo Workshop was held from 8–10 June, 2011 on the campus of McGill University, Montreal, Canada. The 2.5-day workshop was the fourth edition in a series that started at McGill University in 2001, proceedings of which have been published (Seuntjens and Mobit, 2002; Verhaegen and Seuntjens, 2005; Verhaegen and Seuntjens, 2008). These events have garnered interest across the world and were highly successful; parallel successful events have been organized by the European Workgroup on Monte Carlo treatment planning (Reynaerts, 2007; Spezi, 2010). The fourth edition of the workshop was co-organized by McGill University (Medical Physics) and Université Laval. In what turned out to be sunny and pleasant Canadian spring days, the status of MC techniques was examined as related to radiation medicine, but in a broader sense in terms of techniques and applicability compared to previous editions. Developers of MC technologies were brought together with users from clinical, industrial and academic backgrounds. The topics discussed at the workshop included code development, variance reduction, clinical implementation and evaluation, parallel processing, GPUs, planning and correlation studies, applications in adaptive radiation therapy, imaging and dosimetry as well as integration of MC techniques with non-MC related applications involving machine learning and radiation biology outcome modeling. The workshop was attended by 106 participants from nine countries. 43 oral presentations were given and the poster session contained 13 presentations discussed integrally in the workshop program. Selected papers from the workshop comprise the content of this special section and the papers were peer-reviewed in accordance with the typical high standards of Physics in Medicine and Biology (PMB). In broad strokes, representative papers from almost all sessions can be found in the section. The clinical impetus of accurate dose calculations in radiation therapy is often linked to specific applications, such as lung cancer radiation therapy: the need for accurate dose calculations in heterogeneous clinical treatment planning and delivery verification scenarios. Radiation medicine benefits from MC calculations for a variety of other applications that we will briefly discuss. To arrive at accurate dose calculations, one needs to examine the basics of underlying physics; models, implementations and geometric inputs play fundamental roles. MC codes used in radiation medicine applications frequently undergo changes and updates that affect their accuracy. In the first session, recent developments in stopping power models for Penelope, low energy photon cross-sections in EGSnrc, new algorithms and input geometries with Geant4 were presented. The paper by Sawkey et al (2012) discusses electron scattering algorithms in Geant4 and compares them to detailed experiments in other papers in this section. Source modeling plays a very important role in radiotherapy applications, whether the algorithm is MC-based or not. Beam modeling was introduced in an excellent plenary presentation by Kawrakow and accuracy of these models was further discussed by Faddegon. An upcoming radiation therapy application that requires accurate beam modeling is MERT (modulated electron beam radiation therapy), which represents the use of a large number of intensity and energy modulated radiation fields. In this section, Connell et al (2012) investigate the benefit of scattering foil-free beams for the application of MERT using experimental and MC techniques. Brachytherapy is an application that has been receiving increased 'MC attention' due to the importance of low energies of the radiation involved as well as successes of certain brachytherapy treatments in terms of local control (e.g., Vuong et al 2002). Detailed source modeling and approaches for fast treatment planning-type calculations are being developed to replace approximate methods currently used in clinical applications. Afsharpour et al (2012) discuss the development and performance of the ALGEBRA algorithm based on Geant4 and its interfacing to clinical TP stations through DICOM-RT. Computational acceleration has always been an important consideration for the more widespread deployment of MC techniques in different areas including radiation therapy. A computer architecture that received significant attention in recent years is the Graphics Processing Unit (GPU) technology in conjunction with MC and other modeling methods in radiation therapy. At the workshop Jiang presented a summary of the efforts by the San Diego group in this regard. Complementary to the role of GPUs and other hardware acceleration platforms, alternative grid-based solvers such as deterministic transport methods have made their entrée into the world of clinical treatment planning. In this context, Wareing discussed the background and strengths of the Acuros deterministic solver of the Boltzmann equation. One of the time consuming components in MC transport is ray tracing or the navigation and the handling of boundary crossing. Schümann et al (2012) discuss optimal techniques for voxel navigation through patient Cartesian grids in Geant4. The explicit simulation of time-dependencies with MC techniques, known as 4D MC, is of importance in a variety of studies including anatomical variations, source modulation as well as correlative outcome studies. 4D MC options have become part of the most radiation therapy-related packages including BEAMnrc/EGSnrc, Geant4 and Penelope. Shin et al (2012) study a modular framework for the simulation of time-dependent quantities in the Geant4 toolkit TOPAS. Another topic of significant interest is nuclear medicine and molecular imaging. Zaidi reviewed the role of MC techniques in positron emission tomography, which is very relevant to recent developments in imaging technologies, such as PET-MR. The efficacy of proton therapy and its potential in clinical treatment is affected by accurate knowledge of particle range uncertainties in tissues, which is influenced by fundamental as well as clinical issues. In this section, Paganetti (2012) presents a topical review of the role of MC in proton therapy and estimation of its range uncertainties. The application of radiation therapy to a patient provokes a response of a 'system' that depends not only on an accurate description of the manner in which energy is absorbed in the patient tissues but, more importantly, on radiation biological and clinical aspects, whereas the role of MC techniques is witnessing increased interest on this front. The workshop devoted a dedicated session to applications of MC in radiation biology and treatment outcomes, which has been reviewed in this section by El Naqa et al (2012) from macroscopic and microscopic perspectives. Incerti presented the progress of the Geant4-DNA track structure project whereas Lee et al (2012) discussed analytical modeling of radiation therapy lung late effects and local MC dose over time. Chow et al (2012) applied MC techniques to quantify dose enhancement effects by gold nanoparticles in electron beams. Significant discussions took place about suitable ways for dose-to-medium reporting for clinical applications such as brachytherapy and Gadolinium neutron capture therapy. The workshop concluded with two sessions involving dosimetry starting with the impact of tissue characterization from different imaging technologies on accuracy of dose calculations in a presentation by Verhaegen. Dosimetry involving absorbed dose detectors is an area in which MC techniques have a longstanding, established role. Bouchard (2012) discussed a formal cavity theory suitable for MC implementation and Kairn et al (2012) presented a comparison between gel dosimetry and MC dosimetry in a stereotactic application. The role of MC techniques as a radiation physics modeling approach in the optimization of efficacy and success of radiation therapy is expanding. We have witnessed its role in radiation therapy physics as an invaluable and accurate technique to understand basic measurement dosimetry. It has become the ultimate treatment planning dose calculation algorithm and it will play both a fundamental as well as a technical role in improving the understanding of a variety of effects and processes that are part of the patient system response to radiation therapy. This evolution will be fueled with the ever-improving computer hardware and algorithmic developments. There may be a day where one can contemplate in-silico clinical trials as a result of these developments. We would like to gratefully acknowledge the financial support from the Research Institute, the Department of Radiation Oncology and the Cancer Mission of the McGill University Health Centre, the Department of Oncology of McGill University, the Canadian Organization of Medical Physicists (COMP), Association Québequoise des physiciens médicaux (AQPMC) and the following corporate sponsors: Nucletron, BV (official sponsor of the day for 8 June, 2011); Varian Medical Systems (official sponsor of the day for 9 June, 2011) and Elekta/CMS Inc. (official sponsor of the day for 10 June, 2011). The workshop was also endorsed by the International Atomic Energy Agency. A final word of thanks goes out to all of those who contributed to the successful workshop: our local medi",Physics in medicine and biology,2012.0,10.1088/0031-9155/57/11/E01,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
34af4b500bc323d4ecf0897b8a3697f03650f1b1,https://www.semanticscholar.org/paper/34af4b500bc323d4ecf0897b8a3697f03650f1b1,Towards a Predictive Analytics-Based Intelligent Malaria Outbreak Warning System,"Malaria, as one of the most serious infectious diseases causing public health problems in the world, affects about two-thirds of the world population, with estimated resultant deaths close to a million annually. The effects of this disease are much more profound in third world countries, which have very limited medical resources. When an intense outbreak occurs, most of these countries cannot cope with the high number of patients due to the lack of medicine, equipment and hospital facilities. The prevention or reduction of the risk factor of this disease is very challenging, especially in third world countries, due to poverty and economic insatiability. Technology can offer alternative solutions by providing early detection mechanisms that help to control the spread of the disease and allow the management of treatment facilities in advance to ensure a more timely health service, which can save thousands of lives. In this study, we have deployed an intelligent malaria outbreak early warning system, which is a mobile application that predicts malaria outbreak based on climatic factors using machine learning algorithms. The system will help hospitals, healthcare providers, and health organizations take precautions in time and utilize their resources in case of emergency. To our best knowledge, the system developed in this paper is the first publicly available application. Since confounding effects of climatic factors have a greater influence on the incidence of malaria, we have also conducted extensive research on exploring a new ecosystem model for the assessment of hidden ecological factors and identified three confounding factors that significantly influence the malaria incidence. Additionally, we deploy a smart healthcare application; this paper also makes a significant contribution by identifying hidden ecological factors of malaria.",,2017.0,10.3390/APP7080836,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7aca23cb1ed35b1efe203a52bac8f889b27b189b,https://www.semanticscholar.org/paper/7aca23cb1ed35b1efe203a52bac8f889b27b189b,AC 2011-795: PROJECT-BASED SERVICE LEARNING AND STUDENT MOTIVATION,"We know from motivation theory that enhanced motivation in students is positively correlated with engagement and active learning, interest, and value. We know less about the types of instructional strategies and curricular interventions that work to enhance student motivation in a typical engineering course. Grounded in motivation theory, the purpose of this research is to evaluate how the context of project-based service-learning affects aspects of student motivation (particularly interest and engagement) in a required undergraduate Mechanical Engineering course. Our research aims to answer: 1) How does project-based service learning affect students’ motivation as compared to conventional (non-service) project-based learning? 2) Do students find the context of project-based service-learning more interesting and/or valuable than conventional project-based learning? 3) How does project-based service-learning affect student engagement in the course as compared to conventional project-based learning? The research, which began in 2009, is being completed over a three-year period. The students and activities in Component Design, an existing junior-level course, will serve as the research focus. Specifically, project-based service-learning curriculum will be implemented into a required design and build activity for Component Design students. Using a conventional design project as the control, how the context of project-based service learning affects aspects of student motivation will be studied. A mixed-methods assessment strategy will be employed: quantitative data from preand postproject surveys and shorter surveys administered during the semester will be combined with qualitative data from student interviews and focus groups. This paper will discuss the research design, theoretical framework, and the results of a pilot survey administered in February 2010. Introduction Part of the theoretical framework for this research includes project-based service-learning (PBSL). PBSL is a form of active learning where students work on projects that benefit a real community or client while obtaining a rich learning experience (Duffy, et al., 2009). Many engineering educators are embracing alternative instructional strategies like PBSL in an attempt to respond to major shifts in the engineering profession and practice. Today’s world is a global market and a place of rapid technological change. Newly graduated engineers often find themselves working in teams with people very different from themselves, where they must engage in more entrepreneurship and integrative thinking. Although PBSL opportunities are expanding at educational institutions nationwide, much of the findings on their impacts are anecdotal and qualitative. Some faculty have begun to assess PBSL programs and have found that PBSL does, in fact, cultivate stronger learning outcomes, entrepreneurship, cultural awareness, and community-mindedness. However, comprehensive and rigorous assessment methods have not yet been implemented (Bielefeldt, et al., 2008). Also, given that the number of students participating in PBSL activities may be small or unrepresentative of the undergraduate engineering student population at large, it is difficult to draw conclusions that can be generalized about this promising instructional strategy. One example of incorporating PBSL into engineering curriculum is the SLICE (Service-Learning Integrated throughout the College of Engineering) program at UMass Lowell, where all engineering students are exposed to service-learning in every semester (Duffy, et al., 2009). Extracurricular programs like Engineers Without Borders, Engineers for a Sustainable World, and Engineering World Health provide other opportunities for engineering students to participate in PBSL while providing a direct benefit to a target community – most often a developing or underdeveloped community outside the U.S. A drawback to these extracurricular programs is that participation is difficult for many engineering students and faculty. Barriers to participation include cost and time of travel, difficulty in operating and maintaining projects, and language and cultural differences that must be understood before any design work can begin. Because it is typically easier for students and faculty to become involved with local communities, implementing PBSL into existing university courses makes the benefits of this instructional strategy immediately accessible to a broader audience. We have our own communities in need within the U.S., so it makes sense to apply our resources to help communities close to home. In either case, the benefits of PBSL should be similar. One of the main differences between project-based service-learning and conventional projectbased learning is the addition of a community as a full partner. This added authenticity adds “real world complexity”, causing the project outcomes to be less defined initially (Bielefeldt, et al., 2008). This challenges students to “use their functional skills related to technology along with their critical thinking and interpersonal skills to gain an understanding of the problems they must solve in their projects” (Brescia, et al., 2009). The integration of technical skills to dynamic environments challenges students to immediately apply and make sense of what they have learned in the classroom. This process has shown to promote four areas of outcome, including personal efficacy, awareness of the surrounding environment, personal value identification, and a greater engagement with the learning content (Astin, et al., 2000). Now let’s turn to motivation theory – the second leg of the theoretical framework for this research. Motivation is a theoretical construct to explain the reason or reasons we engage in a particular behavior (Barkley, 2010). According to Brophy, students enter a “state” of motivation to learn when their engagement in a particular activity is guided by the intention of acquiring the knowledge or mastering the skill that the activity is designed to teach. Motivation, then, is so highly valued because it produces. Hence, it is of paramount concern to educators, who are constantly tasked with inducing students to learn, perform, and persist. Fortunately, educators need not resign themselves to the role of passive observers to students’ motivational patterns. In fact, educators can be active socialization agents capable of stimulating the general development of student motivation and its activation in particular situations (Brophy, 1987). What is the connection between PBSL and student motivation? That, in a nutshell, is the driving question behind this study. Assessing the impact of any new instructional strategy on student motivation is a worthwhile endeavor. According to self-determination theory, people at their best have an innate inclination toward mastery, spontaneous interest, exploration, and curiosity. This “intrinsic motivation”, which is a type of motivation characterized by doing an activity for the inherent satisfaction of the activity itself, seems to be part of human nature. However, intrinsic motivation requires supportive conditions to persist (Ryan and Deci, 2000). Other theories emphasize different (although related) conditions that support or thwart motivation. But, in general, supportive conditions can include a person’s feelings of autonomy, relatedness, and competence, accompanied by a sense of interest and value. Hence, we see that motivation is not a single construct; rather, it is a synthesis of many constructs. The table below presents several of these constructs and their relationship to the learning context of PBSL, where some of these motivation constructs seem to emerge naturally. Table 1: Connections between motivation and PBSL Constructs of Motivation Characteristics of PBSL Autonomy: characterized by choice, acknowledgement of feelings, and opportunities for self-direction. A sense that one’s actions are selfdetermined, or self-authored (Ryan and Deci, 2000). As opposed to more traditional engineering projects that often spell out the design challenge and much of the required solution (i.e. “design a spring-powered machine to launch a tennis ball 50 yards”), PBSL is inherently more open-ended due to the “realworld” context. That there may be a number of feasible solutions to a service-learning project gives students greater freedom to pursue a design solution that resonates with their skills and interests, hence directing their own learning. Relatedness: caring for and being cared for by others, Preliminary research carried out by the authors showed that most students felt somewhat a part of their university community but having a sense of belongingness , both with other individuals, and one’s own community (Deci and Ryan, 2002). very little a part of a greater community. PBSL can help students see that their engineering talent is an essential aspect to improving people’s quality of life in the greater community, hence enhancing feelings of relatedness. Competence: feeling effective in one’s interactions with the social environment and experiencing opportunities to exercise and express one’s capacities (Deci and Ryan, 2002). PBSL requires a breadth of skills, including non-technical engineering skills (i.e. the ability to work with a client, the ability to present ideas to a non-technical audience) that may not be emphasized in traditional engineering projects. This gives students with strong non-technical skills (those who may take the back seat in traditional engineering group projects) the opportunity to further develop and demonstrate their competence. At the same time, PBSL can be just as technical as traditional engineering projects to ensure students with stronger technical skills will also feel effective. Value: the belief that the learning task is relevant to satisfying personal goals (Vanasupa, et al., 2009). Engineering students, like any other subset of people, have",,2011.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
514ce8be29824781ca0e5489c680502b0f31242f,https://www.semanticscholar.org/paper/514ce8be29824781ca0e5489c680502b0f31242f,Real Prediction Machines,"Predicting the future is no longer about the mystical reading of natural and celestial phenomena. Today it is all about data. 
The Real Prediction Machine (RPM) is a domestic product that uses big and small data, in combination with machine learning and predictive modelling to make predictions about specific future events. 
 
Contemporary use of digital networked technology, such as personal computers and smart phones, is effectively feeding a live global human behaviour laboratory with data scientists experimenting on an (often) unknowing pool of billions. The futures that emerge from this research are as yet mostly unknown, but there are hints – as this data accumulates it can be analysed, mined and used in algorithms; patterns or trends invisible to the human observer can be identified; and seemingly random events become predictable. At this time prediction algorithms are predominantly being exploited by big industries such as banking, insurance and commerce, or examined in massive research projects such as the EU funded FuturICT project. They are, however, making surreptitious steps into our lives through tailored internet browsing and predictive shopping with occasional Kafkaesque consequences. 
RPMs exploits the potential of this technology motivated not by the interests of industry and research but by the more emotive and personal needs/desires of people – this has the purpose of communicating the transformative potential of big data in domestic life, and asking if the future possibilities described by the project are desirable. 
 
The concept 
When things fail they rarely do so instantaneously but through a gradual process of deterioration. Based on this observation, predictive analytics, through the deployment of sensors in pertinent places and contexts, can determine the when things begin to fail. Such techniques are increasingly used in the mechanical and structural world - to predict for example when a vehicle or bridge might be in need of pre-emptive maintenance. 
 
The RPMs use similar techniques but in the context of human everyday life to predict anything from health related events such as a heart attack to more emotive forecasts such as a domestic argument. 
 
Once the event has been chosen the necessary and available data streams, from local sensors to RSS feeds, determined they are fed into the prediction algorithm - the output of which controls the visual display on the prediction machine. This informs the viewer if the chosen event is approaching, receding or impending. 
 
The Real Prediction Machines was commissioned by the Crafts Council for the exhibition Crafting Narrative. This explored how contemporary designers and makers use objects as mediums to tell stories. 
 
Project developed in collaboration with Subramanian Ramamoorthy and Alan Murray. Engineering by Nick Williamson.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1bd64a7541e8d34f0d7782f0e786b2ffd78e55b7,https://www.semanticscholar.org/paper/1bd64a7541e8d34f0d7782f0e786b2ffd78e55b7,Interacting in various application domains,"eLearning and Education.- Arab Children's Reading Preference for Different Online Fonts.- Adaptation Decisions and Profiles Exchange among Open Learning Management Systems Based on Agent Negotiations and Machine Learning Techniques.- Accessing e-Learning Systems via Screen Reader: An Example.- Using Tablet PCs and Pen-Based Technologies to Support Engineering Education.- Optimal Affective Conditions for Subconscious Learning in a 3D Intelligent Tutoring System.- Computer-Based Learning to Improve Breast Cancer Detection Skills.- Virtual Classroom and Communicability: Empathy and Interaction for All.- Communicability for Virtual Learning: Evaluation.- Attention and Motivation in Hypermedia Systems.- A Web-Based, Interactive Annotation Editor for the eCampus Development Environment for SCORM Compliant E-Learning Modules.- An Innovative Way of Understanding Learning Processes: Eye Tracking.- A Set of Rules and Strategies for UNSAM Virtual Campus.- HCI Professional Involvement in k-12 Education: On Target or Missing the Mark?.- A Language Learning System Utilizing RFID Technology for Total Physical Response Activities.- Promoting Metacognition in Immersive Cultural Learning Environments.- The Application of the Flexilevel Approach for the Assessment of Computer Science Undergraduates.- Development of Ubiquitous On-Demand Study Support Environment for Nursing Students.- The Effects of Prior Knowledge on the Use of Adaptive Hypermedia Learning Systems.- Supporting Learners in Adaptive Learning Environments through the Enhancement of the Student Model.- The Concept of IMPRESSION: An Interactive Instruction System and Its Practice for Real-Time Distance Lessons between U.S. and Japan.- Improving Children's Writing Ability.- From Paper to Module - An Integrated Environment for Generating SCORM Compliant Moodle Courses Out of Text and Multimedia Elements.- Development of a Simulator of Abacus: Ancient Analog Calculator on a Mobile Phone as a Teaching Material.- A Proposal for a Framework for an e-Alumni Program Using SNS.- Supporting End-User Development of Personalized Mobile Learning Tools.- Didactic Models as Design Representations.- Interactive Learning Panels.- WebELS: A Content-Centered E-Learning Platform for Postgraduate Education in Engineering.- A Pen-Based Teaching System for Children and Its Usability Evaluation.- Development of a Visualised Sound Simulation Environment: An e-Approach to a Constructivist Way of Learning.- Games and Entertainment.- Causal Links of Presence.- Games Design Principles for Improving Social Web Applications.- A Multiple-Level 3D-LEGO Game in Augmented Reality for Improving Spatial Ability.- An Online Survey System on Computer Game Enjoyment and Personality.- Playability Testing of Web-Based Sport Games with Older Children and Teenagers.- Exploring the Elements and Design Criteria of Massively-Multiplayer Online Role-Playing Game (MMORPG) Interfaces.- Healthcare Game Design: Behavioral Modeling of Serious Gaming Design for Children with Chronic Diseases.- Analyzing Human Behaviors in an Interactive Art Installation.- The Effects of Quest Types and Gaming Motivations on Players' Knowledge Acquisitions in an Online Role-Playing Game Environment.- Self-movement Feeling Generation in Sports Watching with Screen Movement via Pan-Tilt Steerable Projector.- Design of Interactive Emotional Sound Edutainment System.- Understanding Online Game Addiction: Connection between Presence and Flow.- The Experience of Presence in 3D Web Environment: An Analysis of Korean Second Life.- Influence of Real-World Ten-Pin Bowling Experience on Performance during First-Time Nintendo Wii Bowling Practice.- Emotionally Adapted Games - An Example of a First Person Shooter.- DiamondTheater: A System for Reproducing Theater and Supporting Creative Activities.- Work, Collaboration and Business.- New Health Information Systems (HIS) Quality-in-Use Model Based on the GQM Approach and HCI Principles.- An Information Visualization Approach to Hospital Shifts Scheduling.- Designed to Fit: Challenges of Interaction Design for Clothes Fitting Room Technologies.- Usability for Poll Workers: A Voting System Usability Test Protocol.- CAD and Communicability: A System That Improves the Human-Computer Interaction.- A Novel Visualization Tool for Evaluating Medication Side-Effects in Multi-drug Regimens.- Design of a Web Intervention to Change Youth Smoking Habits.- Smart Makeup Mirror: Computer-Augmented Mirror to Aid Makeup Application.- Studying Reactive, Risky, Complex, Long-Spanning, and Collaborative Work: The Case of IT Service Delivery.- Human Computer Interaction in Virtual Standardized Patient Systems.- Towards Standardized Pen-Based Annotation of Breast Cancer Findings.- ImproV: A System for Improvisational Construction of Video Processing Flow.- E-Assessment: A Suitable Alternative for Measuring Competences?.- Green Advocate in E-Commerce.- Gesture-Based Sharing of Documents in Face-to-Face Meetings.- Developing, Deploying and Assessing Usage of a Movie Archive System among Students of Film Studies.- Using Activity Descriptions to Generate User Interfaces for ERP Software.- Developing a Nomenclature for EMR Errors.- Mapping for Multi-source Visualization: Scientific Information Retrieval Service (SIRS).- Client-Side Visualization of Internet Forums for Information Retrieval.- Social-Technical Tools for Collaborative Sensemaking and Sketching.- Developing Some User Interfaces of TV under Enormous Channels Environment.- Electronic Glassboard - Conception and Implementation of an Interactive Tele-presence Application.- A New Automatic Teller Machine (ATM) Proposal through the Analysis of ATMs of Three Banks.- Advanced Applications.- Designing Usable Bio-information Architectures.- Run-Time Adaptation of a Universal User Interface for Ambient Intelligent Production Environments.- Heuristic Evaluation of Mission-Critical Software Using a Large Team.- Interface Development for Early Notification Warning System: Full Windshield Head-Up Display Case Study.- Reflections on the Interdisciplinary Collaborative Design of Mapping the Universe.- Distilling Support Opportunities to Improve Urban Search and Rescue Missions.- A New Approach to Design an Interactive System for Molecular Analysis.- The Differences of Aviation Human Factors between Individualism and Collectivism Culture.- Web-Based Training System for Improving Aviation Maintenance Performance.- Allocating Human-System Interfaces Functions by Levels of Automation in an Advanced Control Room.- Development of an Expert System as a User Interface for an RFID Application.- Developing a Validation Methodology for Educational Driving Simulators and a Case Study.- Developing a Usable Mobile Flight Case Learning System in Air Traffic Control Miscommunications.",,2009.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
972b20f1a231cb991f43b5a8dc99b8892c6a3db9,https://www.semanticscholar.org/paper/972b20f1a231cb991f43b5a8dc99b8892c6a3db9,Stress Detection for Keystroke Dynamics,"Background. Stress can profoundly affect human behavior. Critical-infrastructure operators (e.g., at nuclear power plants) may make more errors when overstressed; malicious insiders may experience stress while engaging in rogue behavior; and chronic stress has deleterious effects on mental and physical health. If stress could be detected unobtrusively, without requiring special equipment, remedies to these situations could be undertaken. In this study a common computer keyboard and everyday typing are the primary instruments for detecting stress. Aim. The goal of this dissertation is to detect stress via keystroke dynamics – the analysis of a user’s typing rhythms – and to detect the changes to those rhythms concomitant with stress. Additionally, we pinpoint markers for stress (e.g., a 10% increase in typing speed), analogous to the antigens used as markers for blood type. We seek markers that are universal across all typists, as well as markers that apply only to groups or clusters of typists, or even only to individual typists. Data. Five types of data were collected from 116 subjects: (1) demographic data, which can reveal factors (e.g., gender) that influence subjects’ reactions to stress; (2) psychological data, which capture a subject’s general susceptibility to stress and anxiety, as well as his/her current stress state; (3) physiological data (e.g., heart-rate variability and blood pressure) that permit an objective and independent assessment of a subject’s stress level; (4) self-report data, consisting of subjective self-reports regarding the subject’s stress, anxiety, and workload levels; and (5) typing data from subjects, in both neutral and stressed states, measured in terms of keystroke timings – hold and latency times – and typographical errors. Differences in typing rhythms between neutral and stressed states were examined to seek specific markers for stress. Method. An ABA, single-subject design was used, in which subjects act as their own controls. Each subject provided 80 typing samples in each of three conditions: (A) baseline/neutral, (B) induced stress, and (A) post-stress return/recovery-to-baseline. Physiological measures were analyzed to ascertain the subject’s stress level when providing each sample. Typing data were analyzed, using a variety of statistical and machine learning techniques, to elucidate markers of stress. Clustering techniques (e.g., K-means) were also employed to detect groups of users whose responses to stress are similar. Results. Our stressor paradigm was effective for all 116 subjects, as confirmed through analysis of physiological and self-report data. We were able to identify markers for stress within each subject; i.e., we can discriminate between neutral and stressed typing when examining any subject individually. However, despite our best attempts, and the use of state-of-the-art machine learning techniques, we were not able to identify universal markers for stress, across subjects, nor were we able to identify clusters of subjects whose stress responses were similar. Subjects’ stress responses, in typing data, appear to be highly individualized. Consequently, effective deployment in a realworld environment may require an approach similar to that taken in personalized medicine.",,2018.0,10.1184/R1/6723227.V3,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5418000890eeef3cf4f813bb5ec747344dfed9e5,https://www.semanticscholar.org/paper/5418000890eeef3cf4f813bb5ec747344dfed9e5,Dynamic Adaptive Remote Health Monitoring for Patients with Chronic Disease,"Chronic diseases are the leading causes of death and disability in the United States. More than 70% of deaths among Americans are caused by chronic diseases and more than 133 million Americans have at least one chronic disease. Due to the prevalence of chronic disease-related issues, it is prudent to seek out methodologies that would facilitate the prevention, monitoring, and feedback for patients with chronic diseases.This dissertation describes WANDA (Weight and Activity with Other Vital Signs Monitoring System); a system that leverages sensor technologies and wireless communications to monitor the health-related measurements of patients with chronic diseases. The system was developed and validated in conjunction with the Computer Science Department, the School of Nursing and Ronald Regan Medical Center at the University of California, Los Angeles to enable real-time patient monitoring, user task optimization, missing data imputation and key clinical symptom prediction. The main contributions of designing and developing the WANDA system are 1) data abstraction and integration of the server side; 2) development of the smartphone and web applications; 3) data backup and recovery; 4) algorithm design and development of missing data imputation; 5) algorithm design and development of task optimization and early adaptive alarm; and 6) system deployment for clinical trials.The WANDA system is a three-tier architecture consisting of wireless sensors, web servers, and back-end data analytics engines. The first tier comprises sensors that measure patients' vital signals and transmit data to the web server tier. The second tier consists of web servers that receive data from the first tier and maintains data integrity. The third tier is a back-end database server that performs data backup and recovery and various data analysis including dynamic task optimization, missing data imputation and adverse event prediction.The WANDA dynamic task optimization function applies data analytics in real-time to discretize continuous features and apply data clustering and association rule mining techniques to manage a sliding window size dynamically and to prioritize required user tasks. The developed algorithm minimizes the number of daily action items required by patients using association rules that satisfy a minimum support, confidence, confirmation and conditional probability thresholds. Each of these tasks maximizes information gain, thereby improving the overall level of patient adherence and satisfaction. Experimental results from applying EM-based clustering and Apriori and confirmation-based rule mining algorithms show that the developed algorithm can reduce the number of user tasks by up to 76.19% with higher confidence levels.Although missing data is highly undesirable as automated alarms may fail to notify healthcare professionals of potentially dangerous patient conditions, many studies reported high missing data rates in remote health monitoring. In this dissertation, I exploit machine learning techniques including projection adjustment by contribution estimation regression (PACE), Bayesian methods, and voting feature interval (VFI) algorithms to predict both non-binomial and binomial data. The experimental results show that the aforementioned algorithms are superior to other methods with high accuracy and recall. This approach also shows an improved ability to predict missing data when training on entire populations, as opposed to training unique classifiers for each individual.The WANDA early adaptive alarm function discretize continuous features, applying Expectation Maximization (EM) clustering and association rule mining techniques for predicting future sensor readings and system non-use dynamically. The experiment results shows that developed algorithm can predict upto 27.08% of sensor readings and system non-use within the next three days.Additionally, the results of performed clinical trials shows that patients monitored by WANDA are less likely to have readings fall outside a healthy raange and have higher adherence rate and more communications with health care professionals.",,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f935771c64e7670c2814c0ab463a2c183cf98c8a,https://www.semanticscholar.org/paper/f935771c64e7670c2814c0ab463a2c183cf98c8a,Toward real-time in-home activity recognition using indoor positioning sensor and power meters,"Automatic recognition of activities of daily living (ADL) can be applied to realize services to support user life such as elderly monitoring, energy-saving home appliance control, and health support. In particular, “real-time” ADL recognition is essential to realize such a service that the system needs to know the user's current activity. There are many studies on ADL recognition. However, none of these studies address all of the following problems: (1) privacy intrusion due to the utilization of high privacy-invasive devices such as cameras and microphones; (2) limited number of recognizable activities; (3) low recognition accuracy; (4) high deployment and maintenance costs due to many sensors used; and (5) long recognition time. In our prior work, we proposed a system which solves the problems (1)– (4) to some extent by using user's position data and power consumption data of home electric appliances. In this paper, aiming to solve all the above problems including (5), we propose a new system by extending our prior work. To realize “real-time” ADL recognition while keeping good recognition accuracy, we developed new power meters with higher sensing frequency and introduced new techniques such as adding new features, selecting the best subset of the features, and selecting the best training dataset used for machine learning. We collected the sensor data in our smart home facility for 11 days, and applied the proposed method to these sensor data. As a result, the proposed method achieved accuracy of 79.393% in recognizing 10 types of ADLs.",2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops),2017.0,10.1109/PERCOMW.2017.7917620,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ea89d5ab69627a9361a340d43866cc0950a50fa1,https://www.semanticscholar.org/paper/ea89d5ab69627a9361a340d43866cc0950a50fa1,Distributed Learning Algorithms for Sensor Networks,"Wireless sensor networks have received significant attention in the last decade owing to their widespread use not only in monitoring the physical world but also in surveillance. The energy and communication constraints of sensor nodes, coupled with distributed processing of sensed signals, lead to challenges in developing effective methods to perform desired inference tasks such as object detection or classification. Further, the lack of well-calibrated sensors is a major obstacle for the rapid deployment of sensor networks. This dissertation develops gossip-based learning algorithms for distributed signal processing in sensor networks. In gossip-based algorithms, sensor nodes share information with local neighbors to converge upon common knowledge about the sensed environment. Gossip-based methods allow for manageable communication among energy-constrained nodes and also accommodate changing network communication topologies. We consider three related problems and develop gossip-based processing solutions. We first consider the problem of joint signature estimation and node calibration using distributed measurements over a large-scale sensor network. We develop a new Distributed Signature Learning and Node Calibration algorithm, called D-SLANC, which estimates the signature of a commonly-sensed source signal and simultaneously estimates calibration parameters local to each sensor node. The approach we take is ii to model the sensor network as a connected graph and make use of the gossip-based distributed consensus to update the estimates at each iteration of the algorithm. We prove convergence of the algorithm to the centralized data pooling solution. We also compare its performance with the Cramér-Rao bound (CRB), and study the scaling performance of both the CRB and the D-SLANC algorithm. Secondly, we develop a gossip-based algorithm for distributed `1-optimization in a large-scale sensor network setting. Specifically, we consider sensor nodes which can measure only a part of the entire measurement vector. We formulate the `1optimization problem as quadratic optimization and develop a distributed, gossipbased algorithm using the projected-gradient approach. We analyze the performance of the proposed algorithm using synthetic data and compare it with a standard `1 solver. Third, we consider the problem of distributed classifier learning in a large-scale sensor network setting. We adopt a machine learning approach to the problem and develop a distributed, gossip-based algorithm that learns the optimal (large-margin) hyperplane separating the two classes, using the projected-gradient approach. We illustrate the performance of the proposed algorithm using both synthetic and realworld datasets.",,2010.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4b60b1f6cd09d0a4396d1012dcaa488919a0f2c0,https://www.semanticscholar.org/paper/4b60b1f6cd09d0a4396d1012dcaa488919a0f2c0,Hands-On Microservices with C#,"Build enterprise-grade microservice ecosystems with intensive case studies using C#About This BookLearn to build message-based microservicesPacked with case studies to explain the intricacies of large-scale microservicesBuild scalable, modular, and robust architectures with C#Who This Book Is ForC# developers, software architects, and professionals who want to master the art of designing the microservice architecture that is scalable based on environment. Developers should have a basic understanding of.NET application development using C# and Visual StudioWhat You Will LearnExplore different open source tools within the context of designing microservicesLearn to provide insulation to exception-prone function callsBuild common messages used between microservices for communicationLearn to create a microservice using our base class and interfaceDesign a quantitative financial machine microserviceLearn to design a microservice that is capable of using Blockchain technologyIn DetailC# is a powerful language when it comes to building applications and software architecture using rich libraries and tools such as .NET.This book will harness the strength of C# in developing microservices architectures and applications.This book shows developers how to develop an enterprise-grade, event-driven, asynchronous, message-based microservice framework using C#, .NET, and various open source tools. We will discuss how to send and receive messages, how to design many types of microservice that are truly usable in a corporate environment. We will also dissect each case and explain the code, best practices, pros and cons, and more.Through our journey, we will use many open source tools, and create file monitors, a machine learning microservice, a quantitative financial microservice that can handle bonds and credit default swaps, a deployment microservice to show you how to better manage your deployments, and memory, health status, and other microservices. By the end of this book, you will have a complete microservice ecosystem you can place into production or customize in no time.Style and approachA step-by-step guide that enables readers to create a complete microservice ecosystem they can place into production or customize in no time.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ac0895098efa38910fc6941309dcc5f74ede316d,https://www.semanticscholar.org/paper/ac0895098efa38910fc6941309dcc5f74ede316d,Predictive Models in Medicine: Some Methods for Construction and Adaptation,"Health care personnel make predictions routinely every day. They group patients according to disorders, render prognoses of the health status of a given patients at a future point in time, or classify laboratory specimens. With the emergence of integrated hospital information systems, the potential of using computerized predictive models to support tasks like these is significant. This thesis concerns itself with problems of realizing predictive models based on knowledge of associations, e.g., findings – diagnosis associations. The theoretical context of the work contained in this thesis lies in the intersection between artificial intelligence, machine learning in particular, statistics and medicine. Although predictive model results reported in the literature often surpass the results of control groups of relevant health care professionals, few are found in clinical practice. The reasons for this are multiple and touch upon issues concerned with ethics, sociology, psychology and technology. The work presented here aims at lowering this deployment barrier by addressing some technical problems of predictive models. It also offers methodological showcases for the use of genetic algorithms as search heuristics and the use of empirical measures in construction and adaption of predictive models. This is done in the main part of this thesis, a collection of the following five papers. Minimal Approximate Hitting Sets and Rule Templates A genetic algorithm approach to multi-disorder diagnosis A genetic algorithm to select variables in logistic regression: example in the domain of myocardial infarction A recalibration method for predictive models with dichotomous outcomes Effects of Case Removal in Prognostic Models for Medicine",,2000.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6f070c05dbd342d3906ee2fbdd2c3529ed558851,https://www.semanticscholar.org/paper/6f070c05dbd342d3906ee2fbdd2c3529ed558851,Designing and evaluating techniques to mitigate misinformation spread on microblogging web services,"Online social media is a powerful platform for dissemination of information during important realworld events. Beyond the challenges of volume, variety and velocity of content generated on online social media, veracity poses a much greater challenge for effective utilization of this content by citizens, organizations, and authorities. Veracity of information refers to the trustworthiness / credibility / accuracy / completeness of the content. Over last few years social media has also been used to disseminate misinformation in the form of rumors, hoaxes, fake images, and videos. We aim to address this challenge of veracity or trustworthiness of content posted on social media. The spread of such untrustworthy content online has caused the loss of money, infrastructure and threat to human lives in the offline world. We focus our work on Twitter, which is one of the most popular microblogging web service today. We provide an in-depth analysis of misinformation spread on Twitter during real-world events. We propose and evaluate automated techniques to mitigate misinformation spread in real-time. The main contributions of this work are: (i) we analyzed how true versus false content is propagated through the Twitter network, with the purpose of assessing the reliability of Twitter as an information source during real-world events; (ii) we showed the effectiveness of automated techniques to detect misinformation on Twitter using a combination of content, meta-data, network, user profile and temporal features; (iii) we developed and deployed a novel framework for providing indication of trustworthiness / credibility of tweets posted during events. We evaluated the effectiveness of this real-time system with a live deployment used by real Twitter users. First, we analyzed Twitter data for 25+ global events from 2011-2014 for the spread of fake images, rumors, and untrustworthy content. Some of the prominent events analyzed by us are: Mumbai blasts (2011), England Riots (2011), Hurricane Sandy (2012), Boston Marathon Blasts (2013), Polar Vortex (2014). We identified tens of thousands of tweets containing fake images, rumors, fake websites, and by malicious user profiles for these events. We performed an in-depth characterization study of how this false versus the true data is introduced and disseminated in the Twitter network. Second, we showed how features of meta-data, network, event and temporat from user-generated content can be used effectively to detect misinformation and predict its propagation during realworld events. Third, we proposed and evaluated an automated methodology for assessing credibility of information in tweets using supervised machine learning and relevance feedback approach. We developed and deployed a real-time version in TweetCred, a system that assigns a credibility score to tweets. TweetCred, available as a browser plug-in, has been installed and used by 1,808 real Twitter users. During ten months of its deployment, the credibility score for about 12 million tweets was computed, allowing us to evaluate TweetCred in terms of accuracy, performance, effectiveness and usability. The system TweetCred built as part of this thesis work is used effectively by emergency responders, firefighters, journalists and general users to obtain credible content from Twitter. This thesis work has shown that measuring credibility of the Twitter content is possible using semi-automated techniques, and the results can be valuable to the real-world users. The insights obtained from this research and deployment provide a basis for building more sophisticated technology to tackle similar problems on different social media.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b801d6d59f7a728ff9a85955a21c2c4c7b2d7e2f,https://www.semanticscholar.org/paper/b801d6d59f7a728ff9a85955a21c2c4c7b2d7e2f,Operational Data Based Anomaly Detection for Locomotive Diagnostics,"Locomotives are complex electromechanical systems. Continuously monitoring the health state of locomotives is critical in modern cost-effective maintenance strategy. A typical locomotive is equipped with the capability to monitor their state and generate fault messages and a snapshot of sensed parametric readings in response to anomalous conditions. In our previous studies, we have developed and deployed a case-based reasoning system for locomotive diagnostics where fault codes were used as the inputs to the system. In order to increase the lead-time from detection to failure and allow for more proactive actions, one important effort in locomotive diagnostics is to perform anomaly detection on parametric operational data. In this paper, we present an anomaly detection strategy that is based on a combination of nonparametric statistical testing and machine learning methodology. We demonstrate the effectiveness of the anomaly detection strategy using real-world operational data from locomotives.",MLMTA,2006.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d31a7209656b2e5529ddae3d629fcc5dbbcc57b1,https://www.semanticscholar.org/paper/d31a7209656b2e5529ddae3d629fcc5dbbcc57b1,Strategies for Adopting Additive Manufacturing Technology Into Business Models,"Strategies for Adopting Additive Manufacturing Technology Into Business Models by Robert Martens MS, University of Glamorgan, 2007 MBA, Keele University, 2006 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Business Administration Walden University August 2018 Abstract Additive manufacturing (AM), also called 3-dimensional printing (3DP), emerged as a disruptive technology affecting multiple organizations’ business models and supply chains and endangering incumbents’ financial health, or even rendering them obsolete. The world market for products created by AM has increased more than 25% year over year. Using Christensen’s theory of disruptive innovation as a conceptual framework, theAdditive manufacturing (AM), also called 3-dimensional printing (3DP), emerged as a disruptive technology affecting multiple organizations’ business models and supply chains and endangering incumbents’ financial health, or even rendering them obsolete. The world market for products created by AM has increased more than 25% year over year. Using Christensen’s theory of disruptive innovation as a conceptual framework, the purpose of this multiple case study was to explore the successful strategies that 4 individual managers, 1 at each of 4 different light and high-tech manufacturing companies in the Netherlands, used to adopt AM technology into their business models. Participant firms originated from 3 provinces and included a value-added logistics service provider and 3 machine shops serving various industries, including the automotive and medical sectors. Data were collected through semistructured interviews, member checking, and analysis of company documents that provided information about the adoption of 3DP into business models. Using Yin’s 5-step data analysis approach, data were compiled, disassembled, reassembled, interpreted, and concluded until 3 major themes emerged: identify business opportunities for AM technology, experiment with AM technology, and embed AM technology. Because of the design freedom the use of AM enables, in combination with its environmental efficiency, the implications for positive social change include possibilities for increasing local employment, improving the environment, and enhancing healthcare for the prosperity of local and global citizens by providing potential solutions that managers could use to deploy AM technology. Strategies for Adopting Additive Manufacturing Technology into Business Models by Robert Martens MBA, University of Keele, 2006 MS, University of Glamorgan, 2007 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Business Administration Walden University August 2018 Dedication I dedicate this work to my family, who believed in me during this quest. In particular, I wish to thank my father, Dominicus Martens, for telling me about the many journeys he made across the world, for giving me the appreciation for mechanical engineering and procurement, and for showing me technology and business go well together. To my mother, Cornelia, for gifting me with stamina, and an inquisitive and critical mind. I want to thank my wife, Lu Dongmei, for her constant encouragement during this research and belief in my abilities to achieve this goal. To my children Niek, Louis, Max, and Franc: thanks for your support along this journey; I hope I have shown you the importance of goal setting and dedication. Never stop learning. Acknowledgments I would like to acknowledge my family, friends, colleagues, classmates, and Walden faculty for their support during this doctoral study project. To my coach while in China, Lynda Aurora, who pushed me to pursue this dream. In particular, I wish to thank my chair, Dr. Susan Fan, for her guidance, Dr. Charles Needham, for his professionalism, and Dr. Lisa Kangas, for her eye to detail, towards the completion of quality research. To my Walden classmates with whom I shared many ups and downs: thank you for your time, support, motivation, and inspiration.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6ecabaf7e320f860c9b09d6c21f4f338cde6b926,https://www.semanticscholar.org/paper/6ecabaf7e320f860c9b09d6c21f4f338cde6b926,Biosurveillance for Invasive Fungal Infections via Text Mining,"Invasive fungal diseases (IFDs) cause more than 1,000 deaths in hos- pitals and cost the health system more than AUD100m in Australia each year. The most common life-threatening IFD is aspergillosis and a patient with this IFD typically has 12 days prolonged in-patient time in hospital and an 8% mor- tality rate. Surveillance and detection of IFDs irrespective of the stage of diag- nosis (i.e., early or late in disease) is important. We describe an application of text mining techniques, using machine learn- ing over a range of features, to automatically detect cases of patients with IFD from the text in the reports of CT scans performed on them. We focus on de- tecting the presence of aspergillosis; however, we anticipate the approach to be transferable to other diseases or conditions by training the text mining compo- nent over appropriate reports. Previous systems based on language technology have been deployed for processing radiology reports and for detecting hospital- acquired infection using language-processing technology, with significant suc- cess. Our approach differs by using a purely statistical/machine-learning ap- proach to the language technology, and by being trained and tested on data col- lected from a number of hospitals. We collected reports for 288 IFD and 291control patients from three different hospitals in Melbourne, Australia: Alfred Health, Melbourne Health, and Peter MacCallum Cancer Centre. We extracted a sample of 69 IFD and 49 control pa- tients to perform detailed analysis of the text with regard to IFD; each patient had possibly multiple scans (and associated reports), resulting in a total of 398 scan reports from IFD-positive patients and 83 scan reports from control pa- tients. We had medical experts annotate the patient-level classification on all scan reports at both sentence and report level: The annotators had to decide, for each sentence and report, whether it was positive, neutral, or negative with re- gards to IFD. We classify reports and patients as IFD-positive if they contain at least one positive sentence, and as negative otherwise. We used the Weka SVM implementation and employed a variety of text- and concept-based features, including bag-of-words, punctuation, UMLS concepts and negated contexts extracted using MetaMap. We also automatically extract-",CLEF,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4867a63e5edd7ee10f28067d6dd5b07d69321de7,https://www.semanticscholar.org/paper/4867a63e5edd7ee10f28067d6dd5b07d69321de7,Thesis Title: A Framework for Improving the Performance of Signature-based Network Intrusion Detection Systems,"Network Intrusion detection systems (NIDSs) have been widely deployed in different network environments (e.g., banks, schools) to defend against a variety of network attacks (e.g., Trojans, worms). Generally, a network intrusion detection system can be classified into two categories: signature-based NIDS and anomaly-based NIDS. In realworld applications, the signature-based NIDS is more prevalent than the anomaly-based detection as the false alarm rate of the former is much lower than the latter. However, we identify three major issues that can greatly affect the performance of a signature-based NIDS. Expensive signature matching. The traditional signature matching in a signature-based NIDS is too expensive that the computing burden is at least linear to the size of an incoming string. Therefore, the operational burden of a signature-based NIDS could be significantly increased in a large-scale network environment. Overhead network packets. In a large-scale network environment, a signature-based NIDS usually has to drop lots of network packets since the number of incoming packets exceeds its maximum processing capability. Massive false alarms. Although the false alarm rate of a signature-based NIDS is much smaller than that of an anomaly-based NIDS. The number of false alarms generated by a signature-based NIDS can still increase the difficulty in analyzing true alarms and adversely affect the analysis results. To mitigate the above issues, in this thesis, we propose several approaches in improving the performance of a signature-based NIDS such as Snort in the following three aspects: Signature matching improvement.We design an exclusive signature matching scheme to help perform a more efficient signature matching with the purpose of enhancing the performance of signature matching in a heavy traffic environment. Network packet filtration and reduction. To mitigate this issue, we advocate the method of constructing a packet filter such as blacklist-based packet filter, list-based packet filter and trust-based packet filter to help filter out target network packets for a signature-based NIDS such as Snort in terms of IP reputation. This packet filter can be deployed in front of a signature-based NIDS and reduce its workload in an intensive traffic network. False alarm reduction. To resolve this issue, we design several false alarm filters such as machine-learning based false alarm filters, alarm filters using knowledge-based alert verification and context-based alarm filters to help reduce false alarms (or non-critical alarms) that are generated by a signature-based NIDS. A Framework. In addition, we further propose a framework by combining the above work to overall improve the performance of a signature-based NIDS such as Snort. As a case study of the framework, we implement an enhanced filter mechanism (shortly EFM) that consists of three major components: a context-aware blacklist-based packet filter, an exclusive signature matching component and a KNN-based false alarm filter. In particular, the component of context-aware blacklist-based packet filter is responsible for filtering out network packets in terms of IP reputation. The exclusive signature matching component is implemented in the context-aware blacklist-based packet filter and aims to speed up the signature matching. At last, the component of KNN-based false alarm filter is responsible for filtering out false alarms which are produced by the context-aware blacklist-based packet filter and the NIDS. In the evaluation, the experimental results demonstrate that our framework is promising and by deploying with the EFM, the performance of a signature-based NIDS such as Snort can be improved in the aspects of network packet filtration, signature matching improvement and false alarm reduction.",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5ddfa89e667afd305bb46d63a531a91b7084ddee,https://www.semanticscholar.org/paper/5ddfa89e667afd305bb46d63a531a91b7084ddee,A piece of my mind: The unasked question.,"The Unasked Question MY FIRST POSTGRADUATE YEAR AFTER MEDICAL SCHOOL was routine. The second year was not. Seven weeks after induction into the Army, I was sent to Vietnam, issued combat gear, an M-16, and a .45-caliber pistol, and then embedded with 900 infantry troops and 30 medics as the only physician. At first I felt like an imposter—a civilian dressed up to look like a soldier—but this feeling evaporated when I began treating wounded troops while under fire, drenched by monsoon rains, or kneeling in a minefield. The learning curve for medical improvisation is steep when there is no suction, oxygen, blood products, or most of the equipment I had previously taken for granted. Unlike recent wars where soldiers are meticulous about wearing body armor, we often wore baseball caps and cotton shirts in the tropical heat—one of the reasons there were 57 000 dead soldiers by the war’s end. When I was hospitalized with severe headaches and fever, I self-diagnosed meningitis, but was relieved to learn it was only dengue fever. It required a machine gun–mounted jeep and a squad of men to ensure security, but I still looked forward to treating smiling Vietnamese children in the local villages as a diversion from my regular workday. So when I returned to civilian life, I trained to become a pediatrician. By that time, an improbable transformation had somehow taken place. Now I felt like an Army doctor who was dressed up to look like a civilian. As a resident physician at a teaching hospital, I was irreverent when asked to perform tasks I thought were unnecessary; after all, I was used to taking charge and carrying a weapon. I forced myself to order x-ray films and laboratory tests instead of relying on instinct alone, and if I treated an injured adolescent male patient, the unwelcome smell of mud mixed with blood might suddenly appear in my nostrils. I noted the location of windows and doors when I entered public places, and when I went fishing, I found it necessary to check the tree line of our local lake before baiting my hook. I married, started a family, and settled into a rewarding career as a community pediatrician. During the four decades that followed, I developed an assortment of medical ailments. A few were of uncertain etiology, but most seemed consistent with my age. It is only recently that I realized that although there had been dozens of medical encounters, without my prompt I had never been asked by a medical student, resident, or attending physician if I had served in the military, or if my deployment might be responsible for my medical symptoms. In fact, I am embarrassed to say, I had not given it much thought either. Like most physicians, I was never trained to routinely ask patients if they were veterans or taught how to take a military health history. I believed that the likelihood of seeing patients who were veterans was small and that those with service-related conditions were already receiving attention at the Veterans Health Administration. Both assumptions were wrong. I am quite certain that I would seem like an ordinary patient to most physicians. But I also know that I carry the psychological imprint of my Vietnam experience and that I am at increased risk for developing medical complications from constant exposure to the dioxin-containing defoliant known as Agent Orange. We were told that it was nontoxic. Toxicity is now measured in parts per billion, and Agent Orange has been shown to cause cancers, neurological disease, leukemia, type 2 diabetes, ischemic heart disease, and many other conditions. In retrospect, regardless of my unremarkable appearance, questions that every physician should have asked me at every age were: Did you ever serve in the military. (Yes.) When and where were you stationed? What was your job description? Were you physically injured? (No.) Did you ever receive a blood transfusion before routine screening for hepatitis C? (No.) Were you ever exposed to Agent Orange? (Yes.) Were you ever treated for parasitic or tropical diseases? (Yes. Yes.) Have you ever been treated for a service-related condition? (Yes.) Were you affected psychologically by your military experiences? (Yes.) When I reviewed the most recent US census data that pertained to veterans, I could not have been more surprised by the results: The 19.4 million male and 1.8 million female veterans who live in the United States comprise about 10% of the population 18 years and older. Of these, one of every six men (16.5%) between the ages of 35 and 64 years is a veteran; the percentages are higher for those older than 64 years and lower for those younger than 35 years. Only 40% receive some portion of their medical care from the Veterans Health Administration. And, like me, the majority use traditional health care resources that are covered by Medicare, Medicaid, or private insurance. The public health implications are important: Large numbers of veterans who might have sequelae from their military service are receiving medical care from civilian physicians who have no awareness that they are veterans. The 63-year-old man who presents with multiple myeloma and Parkinson disease, the 41-year-old woman with chronic fatigue and myalgia, and the 30-year-old patient with memory loss and panic attacks might all have symptoms related to",JAMA,2012.0,10.1001/jama.2012.14254,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
392ab2bf4e1ad37d55a55cdfffbd59d49c58940d,https://www.semanticscholar.org/paper/392ab2bf4e1ad37d55a55cdfffbd59d49c58940d,Assessing and managing Parkinson's disease from home: A 21st century vision closer to reality,"The application of technology to Parkinson’s disease (PD) holds a considerable potential to monitor disease features in clinical care and research, guide management, and as a therapeutic tool. In spite of this, digital health technology solutions have failed so far to fundamentally change how patients report their symptoms, physicians collect clinical information about their patients between clinical visits, or how we document the efficacy of novel experimental interventions in clinical trials. Zhan and colleagues provide an example of how such promises of a digital technology revolution may shape the near future. The Mobile Parkinson Disease Score (mPDS) is a summary measure of the severity of PD motor features generated solely by a smartphone-based application used remotely by patients. The use of a smartphone confers to the mPDS the unique ability to provide a rapid, remote, frequent, and objective assessment, which could inform care decisions, and allow for more patients with PD to take part in clinical trials, by reducing (though not expected to eliminate) the burden of in-person visits in a trial. To develop the mPDS, the researchers started by establishing its item structure from a pool of 435 unique features extracted from five tasks done on a smartphone in a development cohort of 129 PD patients. The final 15-item version of the mPDS was tested clinimetrically in a small group of PD patients (n = 23). The mPDS had a good-to-excellent correlation with well-validated clinical rating scales in PD (total MDS-UPDRS and corresponding part III, H & Y scale) and was sensitive to change in onversus off-dopaminergic medication conditions. This article provides a critical proof-of-concept study for the validation and deployment of a digital motor scale in PD, in contrast with other recent studies that explored isolated motor features using similar smartphone-based testing. The researchers adopted novel data analyses methods involving machine-learning that challenge the language and methods most clinical researchers know. Once a distant reality, these approaches are no longer science fiction and call for a novel set of skills by the clinical researcher for an appropriate critical appraisal and use. Providing a more home-based assessment is an intuitive example of how the use of technology can revolutionize PD care in the 21st century. Although accessibility is well addressed with the use of widely available smartphones some PD patients may not be tech savvy and may feel challenged by the small dimensions of a smartphone. Also, the study sample was not representative of a broad PD population, which raises concerns about the usability and compliance of the mPDS. These features need to be adequately assessed, given that these will likely determine its successful uptake. Co-design approaches that incorporate patient and care partners views from inception to full development of a health technology solution may be beneficial in the preparation of a future larger study for a more comprehensive validation of this promising digital measure in PD.",Movement disorders : official journal of the Movement Disorder Society,2018.0,10.1002/mds.112,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7df654a6f14f39cc3bfc12bda487a226ace529a9,https://www.semanticscholar.org/paper/7df654a6f14f39cc3bfc12bda487a226ace529a9,REAL-TIME MULTIVARIATE MULTI-TIME-SCALE ANOMALY DETECTION SYSTEM FOR NEXT GENERATION NETWORKS,"Techniques are described herein for a real-time multi-variate, multi-scale, contextaware anomaly detection system. This system is built using concepts of edge/cloud distributed processing and orchestration. DETAILED DESCRIPTION By 2021 networks are forecast to grow by a factor of 75% (61,000 connected network devices) and corresponding incidents per hour will reach the order of 10,000 quotas. Information Technology (IT) providers have responded by delivering to the market a new generation of network devices which will extract more information about the health and status of each network device and export such telemetry at a higher frequency rate (evolving to a real-time push model to deliver network telemetry). While this will grant IT providers with fresher and richer data, next generation anomaly detection systems are called to address many technical challenges: how to effectively process massive amounts of data; how to analyze such data in streaming; how to design anomaly detection systems that can operate across many metrics of observation and multiple time-scales; how to introduce learning and intelligence into those next generation systems such that they can become smarter the longer they are used and exposed to domain-experts; etc. Today, a typical enterprise comprises an average of 35,000 connected network devices which are managed by processing, on average, 750 Gigabytes of diagnostic data per day (e.g., syslogs, command line interface (CLI) data, configuration files, etc.). Usually such data is pulled by the IT provider after the occurrence of a network problem or customer escalation and used to precisely troubleshoot the issue, identify the root cause, and hence deploy a successful remediation. This process requires a long cycle (requires an 2 Nucci et al.: REAL-TIME MULTI-VARIATE MULTI-TIME-SCALE ANOMALY DETECTION SYSTEM Published by Technical Disclosure Commons, 2018 2 5707 average of five hours per incident), is executed by the IT provider on a very regular and frequent basis (enterprises reported in 2017 an average of 400 incidents per hour), and is very prone to human error (e.g., IT domain experts play a critical role in the overall troubleshooting process). While IT is already struggling today, next generation networks will make it even worse. Next-generation anomaly detection systems are called to continuously ingest 70+ Terabytes of telemetry every hour (assuming a forecasted 61,000 router enterprise, with a network device generating an average of 20 Megabytes per minute). Clearly the delivery of such voluminous amounts of data to enterprise Data Centers (DCs) (or even worse, private/public clouds for analysis) will result in a high level of network congestion, prolonged analytical workflow completion times, and long remediation cycles. Next generation anomaly detection systems should adopt a distributed data processing model, meaning that some data processing should be executed as close as possible to the source of the data while other processing may still be executed in the enterprise DC or clouds. The correct distribution of processing workloads guarantees lighter data volumes to be exported to the DC and the cloud (no network congestion), shorter completion times for advanced machine learning analytics workloads (model training may use smaller amounts of data as input) and hence shorter remediation cycles (faster troubleshooting translates into faster deployment of fixes). Next-generation network devices may generate very rich telemetry, which allows IT providers to properly monitor the correct behavior of network devices from many vantage points. For example, certain devices may export telemetry which includes details about the memory and Central Processing Unit (CPU) utilization of each device, comprising logical nodes, counters of packets traversing each device interface, rich statistics about power consumption and usage of its logical and physical components, etc. As a result, anomaly detection systems are called to generate more holistic profiles of network devices or the network-as-a-whole by modeling many distinct collected metrics together. More specifically, they need to profile every metric in isolation (like memory utilization on every logical node of the device) while discovering and modeling possible hidden and stealthy correlations across the distinct metrics (like memory utilization across logical nodes of the device). 3 Defensive Publications Series, Art. 1579 [2018] https://www.tdcommons.org/dpubs_series/1579 3 5707 Many problems affecting a network device do not manifest themselves with major deviations of a single metric but rather appear as smaller, hard-to-see deviations spread across many distinct metrics with strong temporal synchronicity. This is similar for entire networks. Consider as an example the most devastating Distributed Denial of Services (DDoS) attacks which target a network element causing resource exhaustion and starvation. The network element being targeted is attacked using many machines which send similar Internet Protocol (IP) packets (same size, same Transmission Control Protocol (TCP) flags set, etc.) with strong time synchronicity to starve resources at the victim endpoint. The packets are spread across many logical paths in the network which cross many interfaces of the many routers traversed toward their destination. Profiling a single metric such as a packet counter on a single interface of a single router would not trigger any alert. Conversely, correlating the same (or similar) IP packets across all router interfaces and across all routers along the logical path in the network would signify the active presence of the attack. Algorithms that generate behavioral models which take into account more than one time-series metric are called multi-variate. Furthermore, because the drifting from the normal behavior state happens at different frequencies (and hence at different timescales such as minutes, hours, days, or weeks), it is imperative for anomaly detection systems to model and profile the behavior of each network device at different time-scales, from a micro-time-scale of minutes to a macro-time-scale of weeks. This property is called multi-timescale behavioral profiling. It is imperative for IT providers to access detailed telemetry during the troubleshooting phase (which starts upon the generation of an alert). Today, this is achieved by exporting all collected telemetry to a central data storage infrastructure (e.g., a data lake) which makes the data accessible to the IT provider via standard Application Programming Interfaces (APIs). But with networks streaming over 80 Terabytes of telemetry every hour, this solution is clearly not feasible any longer. Hence, there remains the question of what can be done to provide the IT provider with the information needed to troubleshoot an alert while avoiding network congestion. Although unsupervised anomaly detection systems are appealing for any IT organization for being less labor intensive than supervised systems, they are based on the assumption that any pattern that deviates from the learned normal patterns should be 4 Nucci et al.: REAL-TIME MULTI-VARIATE MULTI-TIME-SCALE ANOMALY DETECTION SYSTEM Published by Technical Disclosure Commons, 2018 4 5707 considered an anomaly. However, this assumption may not hold true because it is very difficult or impossible to define a normal event which takes all possible normal patterns/behaviors into account. More importantly, the boundary between normal and anomalous behaviors is often ambiguous, as in the case of an enterprise planned maintenance cycle. In addition, under realistic conditions, the same behavior could be a normal or an anomalous behavior under different conditions. As alerts are investigated by domain experts it is important for the anomaly detection system to assimilate the domainexpert knowledge to improve the learning process. The system described herein (also referred to as “SQUID”) distributes the data processing between the network itself and DC/cloud. The system embeds some data processing functionality directly into the network infrastructure itself (referred to as edge processing) to execute light processing functions such as collection, parsing, anomaly detection classifier at the device level, etc. The edge processing leverages dedicated compute resources available in the next generation network devices; for example, devices that dedicate up to four virtual CPUs (vCPUs) and 400 Gigabytes of Solid Disk Drive (SDD) for pure computing. The system also deploys some data processing functionality in the DC and/or cloud environments, (referred to as a cloud/DC processing environment) to execute more compute and memory intensive data processing. Examples of data intensive processing include the training of the machine and deep learning models. Furthermore, the cloud/DC processing environment may also correlate group alerts generated by each processing engine to uncover network-wide incidents which may affect more than one network device. Examples include DDoS attacks (wherein large numbers of machines generate an attack with strong time synchronicity toward a target endpoint), validation of correctness maintenance cycles (multiple devices may be power-cycled at approximately the same time), blast radius (multiple neighboring devices logically connected at approximately the same time), etc. The system connects the ecosystem of edge processing environments and the central processing environment via a secure bi-directional connectivity which is used to regularly distribute the learned / refreshed machine / deep learning models from the central to the edge processing environments. The system described herein departs from more established single-variate anomaly detection systems, Exponential Weighted Moving Average (EWMA), Holt-Winters, etc., 5 Defensive Publications Series, Art. 1579 [2018] https://www.tdcommons.org/dpubs_series/1579 ",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6edc440b44f37133c44c8004ade1cdb425547aa7,https://www.semanticscholar.org/paper/6edc440b44f37133c44c8004ade1cdb425547aa7,REACT : Physical Interactions Models of Companion Robots Supervisors :,"Robotics used for assistance to frail people draws nowadays a considerable interest in the domain of e-health thanks to the extended range of applications that it offers, together with the scientific and technological challenges that it brings forth. While the first generation of robots was conceived for the execution of repetitive and specific industrial tasks, the new generation introduces robots as artificial companions with cognitive and interactive skills allowing them to operate in open worlds. In particular, assistive service robots aim at helping people with disabilities due to age or sickness, to improve their independence et well-being at the long-term, while continuing to live within their social circle, instead of retirement institutions that tend to become increasingly costly and less available. In order to integrate a robot within living spaces, it has to be able to physically interact with its environment. We distinguish the interactions allowing for a robot to operate in its environment, such as stairs traversal and delivery/retrieval of objects. Given the diversity in forms and the robot sensing limits, a probabilistic approach with respect to the behaviour of the robot is required in terms of its interaction. This in turn should be based on the definition of probabilistic models able to capture the variance as well as the novelty, allowing for a robot to generalise its actions, or otherwise, retract. In this context, we propose in this thesis to study the introduction of new personal assistance services, by the definition and deployment of probabilistic models of physical interaction, between the robot and its environment. These models will serve two objectives: (1) render the operation of the robot more reliable from the user perspective and (ii) homogenise a given service across heterogeneous robots. The research to pursue in this context amounts to associating the actions of the robot with its effects on the environment, where the least controllable effects of an interaction are treated stochastically. The identification of these effects should finally allow to delimit the steps composing a robot service and to fine-tune the most controllable via the application of machine learning.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b287fabb703539712af7cbc38fc94323f8944da6,https://www.semanticscholar.org/paper/b287fabb703539712af7cbc38fc94323f8944da6,"Soft Information Systems and Technologies Methodology, SISTeM¢*: A case study on developing the electronic patient record",,Requirements Engineering,1997.0,10.1007/BF02802895,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
662f74f51c62fb2a0645f989a7e93bec82bdb04f,https://www.semanticscholar.org/paper/662f74f51c62fb2a0645f989a7e93bec82bdb04f,MI-Lab - A Laboratory Environment for Medical Informatics Students,"Medical research and health care highly depend on the use of information technology. There is a wide range of application systems (patient administration system, laboratory information system, communication server etc.) and heterogeneous data types (administrative data, clinical data, laboratory data, image data, genomic data etc.). Students and researchers do not often have the possibility to use productive application systems of e.g. hospitals or medical practices to gain practical experiences or examine new components and technologies. Therefore, the aim of this project is to develop a dedicated laboratory environment for patient health care and clinical research. Essential application systems were identified and a suitable architecture was designed for this purpose. It is accompanied by a teaching plan that considers learning modules for bachelor and master degrees in medical informatics. We implemented the laboratory environment called MI-Lab with multiple free and open source software components. All components are installed on virtual machines and/or Docker containers. This modular architecture creates a flexible system which can be deployed in various scenarios. The preliminary evaluation results suggests that laboratory environments like MI-Lab work well in teaching practical aspects of medical informatics and are widely accepted by students.",MIE,2016.0,10.3233/978-1-61499-678-1-48,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
24e5196c3ff3dba286b8b8ae10d774ba30de80c2,https://www.semanticscholar.org/paper/24e5196c3ff3dba286b8b8ae10d774ba30de80c2,An Intelligent System for Monitoring and Predicting Water Quality,"In this paper we present an intelligent system for monitoring and predicting water quality, whose main aim is to help the authorities in the ""decision-making"" process in the battle against the pollution of the aquatic environment, which is very vital for the public health and the economy of Northern Greece. Two sensor-telematic networks for collecting water quality measurements in real time (Andromeda, for sea waters, and Interrisk, for surface/fresh waters) were developed and deployed. Sensor readings (water temperature, pH, dissolved oxygen, conductance, turbidity, sea currents, and salinity) are transmitted to a main station for processing and storage. The intelligent system monitors sensor data, reasons, using fuzzy logic, about the current level of water suitability for various aquatic uses, such as swimming and piscicultures, and flags out appropriate alerts. Furthermore, the system employs Machine Learning and Adaptive Filtering techniques and algorithms which successfully predict measurements a day ahead, as well as techniques to incorporate the window of past values in order to be able to make a more precise prediction. The results showed that these algorithms can help make accurate predictions one day ahead and are better than the naive prediction that the value will be similar to today.",,2009.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5262defa4ca27a08d5fceb62a82b4356d0356318,https://www.semanticscholar.org/paper/5262defa4ca27a08d5fceb62a82b4356d0356318,Persim : Simulation of Human Activities in Pervasive Spaces,"Today, the computing elements are pervading through our environment that brings cyberphysical research as an emergent computing paradigm. Computational and physical elements have become so intertwined with each other that computing is embedded in almost all everyday objects. This has opened a new dimension to various research areas such as assisted living, health care, elder care etc. Researchers are engaged in developing new algorithms and techniques in machine learning and data mining in order to detect activity, learn context, and act autonomously without any human intervention. Thus cyber-computing research involves building and instrumenting a smart space, recruiting participants, and finally collecting data from the space. To obtain data from physical deployments is crucial in order to longitudinally evaluate the accuracy and performance of the developed models and algorithms. But this is very challenging because of the huge cost, significant ground work, lack of access to human subjects, and the time consuming process of acquiring meaningful data from real world settings. Now, the community needs a ‘supportive’ research initiative which will look for alternative and practical approaches to overcome aforementioned challenges and accelerate experiments with the smart space. Realistic simulation is a promising idea to support the rising demand for test data. Simulation also allows a wider community of researchers to engage and collaborate to solve a specific problem. Hence, algorithms and models based on preliminary simulation studies would most likely to be a more robust and help researchers assess their ideas and algorithms quickly and cost-effectively. In this proposal, an event-driven simulation tool – Persim is proposed to simulate hierarchical activities in pervasive space. The idea is to create a simulated environment of actual pervasive space via modeling activity and generating activity data in standardized format corresponding to the environment. Such simulations can be used in early stage research that can help researchers evaluate their ideas quickly and with reasonable accuracy. The tool is intended to create a knowledge base for human activities and emulate specific scenarios. It can also be used for automatic annotation of dataset based on the knowledge base.",,2010.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
164e478d23f3110b36ae93586c1172cfc05f5e0c,https://www.semanticscholar.org/paper/164e478d23f3110b36ae93586c1172cfc05f5e0c,Dynamic deployment of applications in wireless sensor networks,"Over the past decades, the progress inWirelss Sensor Network (WSN) technology, both in terms of processing capability and energy consumption reduction, has evolved WSNs into complex systems that can gather information about the monitored environment and make prompt and intelligent decisions. In the beginning, military applications drove the research and development of WSNs, with large-scale acoustic systems for underwater surveillance, radar systems 
for the collection of data on air targets, and Unattended Ground Sensor (UGS) systems for ground target detection. Typical civil WSNs are basically not complex monitoring systems, whose applications encompass environment and habitat monitoring, infrastructure security and 
terror threat alerts, industrial sensing for machine health monitoring, and traffic control. In these WSNs, sensors gather the required information, mostly according to a fixed temporal schedule, and send it to the sink, which interfaces with a server or a computer. Only at this point data from sensors can be processed, before being stored. 
Recent advances in Micro-Eletro-Mechanical Systems (MEMS), low power transceivers and microprocessor dimensions have led to cost effective tiny sensor devices that combine sensing with computation, storage and communication. These developments have contributed to the efforts on interfacing WSNs with other technologies, enabling them to be one of the pillars of the Internet of Things (IoT) paradigm. In this context, WSNs take a key role in application 
areas such as domotics, assisted living, e-health, enhanced learning automation and industrial manufacturing logistics, business/process management, and intelligent transportation of people and goods. In doing so, a horizontal ambient intelligent infrastructure is made possible, wherein 
the sensing, computing and communicating tasks can be completed using programmable middleware that enables quick deployment of different applications and services. 
One of the major issues with WSNs is the energy scarcity, due to the fact that sensors are mainly battery powered. In several cases, nodes are deployed in hostile or unpractical environments, such as underground or underwater, where replacing battery could be an unfeasible operation. Therefore, extending the network lifetime is a crucial concern. Lifetime improvement has been approached by many recent studies, from different points of view, including 
node deployment, routing schemes, and data aggregation Recently, with the consistent increase in WSN application complexity, the way distributed applications are deployed in WSNs is another important component that affects the network lifetime. For instance, incorrect execution of data processing in some nodes or the transmission 
of big amounts of data with low entropy in some nodes could heavily deplete battery energy without any benefit. Indeed, application tasks are usually assigned statically to WSN nodes, which is an approach in contrast with the dynamic nature of future WSNs, where nodes frequently join and leave the network and applications change over the time. This brings to issue talked in this thesis, which is defined as follows. Dynamic deployment of distributed applications in WSNs: given the requirements of WSN 
applications, mostly in terms of execution time and data processing, the optimal allocation of tasks among the nodes should be identified so as to reach the application target and to satisfy the requirements while optimizing the network performance in terms of network lifetime. This 
issue should be continuously addressed to dynamically adapt the system to changes in terms of application requirements and network topology.",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9bf03947a946d6af2026b1e90c5ff5ebd976b494,https://www.semanticscholar.org/paper/9bf03947a946d6af2026b1e90c5ff5ebd976b494,Models for the acceptance of tele-care solutions: Intention vs behaviour,"Purpose Tele-care is expected to replace regular home care when an integrated set of health monitoring devices and a communication network enables nursing staff to provide remotely appropriate care. While cost considerations and scarcity of nursing staff are strong motivators for tele-care, the actual effectiveness and acceptance of tele-care systems still falls short of expectations with an attrition rate often higher than 50%. As standard models of technology acceptance are poor predictors of actual adoption of tele-care systems we argue that the theoretical assumptions of models of technology acceptance are inadequate, and that the complexity of tele-care implementation has many facets that are not appropriately factored into those models. The identification of relevant factors will benefit and improve the development and acceptance process of tele-care systems. Method The study is based on a broad range of evaluation studies of tele-care systems, under development or installed in the Netherlands, in which many variables could be observed from the earliest stages of conception up to the full operation and (sometimes) demise of the systems. In addition the assumptions behind technology acceptance models (TAM) have been critically analyzed and serious methodological flaws were identified. Also the deployment of tele-care systems was systematically compared with the introduction of application software in industrial settings as described by TAM theories. Results & Discussion A main reason for poor acceptance level is that tele-care does not materialize as a stand-alone product with a specific and clear functionality, like a TV set or an espresso machine. Tele-care can have a surprising variety of instantiations and functions that easily obscure the functionality for the individual user. Another reason is that, even on somewhat longer trial periods, it is not evident to what extent it supersedes other and earlier functions and services that were available to the client. While many clients claim that their tele-care system is easy to use, its inherent complexity often seriously reduces its actual effectiveness. Currently there is more evidence on factors that reduce the adoption rate, than on those that increase it. We also show that part of the poor predictive value of the technology acceptance models can be explained by an inadequate interpretation of the attitude and intention concepts. There is, fortunately also more recent evidence that the use of assistive systems like tele-care can be promoted effectively by increasing self-efficacy of users. Both introductory individual guidance and errorless learning appear to affect user-system interaction in rehabilitation and tele-care to a considerable degree.",,2012.0,10.4017/GT.2012.11.01.007.00,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4ea8230a6aaaea45049152643bed3baaa6d5818a,https://www.semanticscholar.org/paper/4ea8230a6aaaea45049152643bed3baaa6d5818a,EvoRecSys: Evolutionary Framework for Health and Wellbeing Recommender Systems. User Modeling and User-Adapted Interaction.,"In recent years, recommender systems have been employed in domains like e-commerce, tourism, and multimedia streaming, where personalising users’ experience based on their interactions is a fundamental aspect to consider. Recent recommender system developments have also focused on well-being, yet existing solutions have been entirely designed considering one single well-being aspect in isolation, such as a healthy diet or an active lifestyle. This research introduces EvoRecSys, a novel recommendation framework that proposes evolutionary algorithms as the main recommendation engine, thereby modelling the problem of generating personalised well-being recommendations as a multi-objective optimisation problem. EvoRecSys captures the interrelation between multiple aspects of well-being by constructing conﬁgurable recommendations in the form of bundled items with dynamic properties. The preferences and a predeﬁned well-being goal by the user are jointly considered. By instantiating the framework into an implemented model, we illustrate the use of a genetic algorithm as the recommendation engine. Finally, this implementation has been deployed as a Web application in order to conduct a users’ study. when a user is going to an exercise routine based on their previous behaviour and thus prevent it. The proposed model uses a machine learning algorithm as the core of the recommendation process. The previous user behaviour is used as a training vector which has 34 features including covered distance, workout duration, and rest time. Once the algorithm is trained, it is able to predict if a user is going to abandon the routine. If so, a recommendation for encouraging the user to continue the routine is triggered. Otherwise, the system predicts the user will not abandon the routine. The study tested 4 classiﬁcation algorithms: (i) random forest, (ii) AdaBoost, (iii) extra trees, and (iv) multi-layer perceptron; where random forest obtained the best performance. Data used for the analysis were taken from the u4ﬁt platform. ence modelling and aggregation, and AI for Sustainable Development Goals. Dr. Palomares’s research results have been published in top journals and conference proceedings, including IEEE TRANSACTIONS ON FUZZY SYSTEMS; IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS: SYSTEMS; European Journal of Operational Research; Applied Soft Computing; International Journal of Intelligent Systems; Information Fusion, Knowledge-Based Systems; Applied Intelligence; Renewable & Sustainable Energy Reviews, amongst others.",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2fb2168fb12548bad8b75f703fe30755f588cd45,https://www.semanticscholar.org/paper/2fb2168fb12548bad8b75f703fe30755f588cd45,Semi-analytical method for analyzing models and model selection measures,"Considering the large amounts of data that is collected everyday in various domains such as health care, financial services, astrophysics and many others, there is a pressing need to convert this information into knowledge. Machine learning and data mining are both concerned with achieving this goal in a scalable fashion. The main theme of my work has been to analyze and better understand prevalent classification techniques and paradigms which are an integral part of machine learning and data mining research, with an aim to reduce the hiatus between theory and practice. 
Machine learning and data mining researchers have developed a plethora of classification algorithms to tackle classification problems. Unfortunately, no one algorithm is superior to the others in all scenarios and neither is it totally clear as to which algorithm should be preferred over others under specific circumstances. Hence, an important question now is, what is the best choice of a classification algorithm for a particular application? This problem is termed as classification model selection and is a very important problem in machine learning and data mining. The primary focus of my research has been to propose a novel methodology to study these classification algorithms accurately and efficiently in the non-asymptotic regime. In particular, we propose a moment based method where by focusing on the probabilistic space of classifiers induced by the classification algorithm and datasets of size N drawn independently and identically from a joint distribution (i.i.d.), we obtain efficient characterizations for computing the moments of the generalization error. Moreover, we can also study model selection techniques such as cross-validation, leave-one-out and hold out set in our proposed framework. This is possible since we have also established general relationships between the moments of the generalization error and moments of the hold-out-set error, cross-validation error and leave-one-out error. Deploying the methodology we were able to provide interesting explanations for the behavior of cross-validation. The methodology aims at covering the gap between results predicted by theory and the behavior observed in practice.",,2009.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
88ea92d8b618525ff2a7815c08f0fc2c68d8daa2,https://www.semanticscholar.org/paper/88ea92d8b618525ff2a7815c08f0fc2c68d8daa2,Human Activity Inference via physical sensing in support of Industrial Equipment Maintenance,"The paper describes an active research project at Intel’s High Volume Manufacturing (HVM) facility located at Leixlip, Co. Kildare, Ireland. The project explores the practical aspects of deploying RFID transponders, subtle sensing platforms and machine learning based inferencing in a harsh, realworld environment. The key features of the sensing platform, the data collection process and the translation of data into information using visualization and inferencing techniques are described.",,2006.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
03ef900c25500c5f2b206cc8abd71278cbb57143,https://www.semanticscholar.org/paper/03ef900c25500c5f2b206cc8abd71278cbb57143,"A Survey on Service Oriented Architecture on Big Data, Cloud Computing and IOT","As the number of patients treated in-home are increasing exponentially mainly in countries such as Japan, US A and Europe etc., these people often enter into a critical situation that may require help immediately (e.g. when facing an accident, or becoming depressed). Researches and Advances in computing areas and the Internet of Things (IOT) have provided efficient and cheap equipments including wireless communication and cameras, such as smart phones or embedded devices that enable the deployment of Health S mart Homes (HS H) that can provide medical treatment of patients in their homes. The images captured from these cameras can help nurses or caretakers of patients to provide timely help. The use of such patient images and emotional detection to assist patients and elderly people within home is provided in this article. Internet of Things and Cloud computing can work together, which can address to the Big Data problems. Big data is actually a term used for a huge data set that performs operations like storage of data, analysis, sharing, transfer, predictive analysis; updating etc. data set can grow rapidly. Data sets have different analytics on data that involve process of inspecting, transformation and modeling of data so as to discover new information, and to reach on some particular decision. There are some particular data analysis techniques from which data mining is a popular one which focuses on modeling and discovery of new facts. The discovered knowledge helps in predictive analysis purposes as well as text analysis. Further on data mining is performed on data set which involves discovery of patterns by applying different operations at databases, and using artificial intelligence, machine learning, statics etc. 
 
 Keywords: Cloud computing, IOT, AI, face recognition, big data, data mining.",,2017.0,10.26483/ijarcs.v8i7.4554,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7991b7b0317c0d29bc209f18acc18b5933ac71be,https://www.semanticscholar.org/paper/7991b7b0317c0d29bc209f18acc18b5933ac71be,"Part B 1 ] 1 ( to be evaluated in Step 1 ) Ubiquitous , spatiotemporal , multimodal action recognition Act Now","Action and activity recognition lie at the core of a panoply of scenarios in human machine interaction, ranging from gaming, mobile computing and video retrieval to health monitoring, surveillance, robotics and biometrics. The problem, however, is made really challenging by the inherent variability of motions carrying the same meaning, the unavoidable over-fitting due to limited training sets, and the presence of numerous nuisance factors such as locality, viewpoint, illumination, and occlusions that make real-world deployment extremely difficult. The most successful recent approaches, which mainly classify bags of local features, have reached their limits: only understanding the spatial and temporal structure of human activities can help us to successfully locate and recognise them in a robust and reliable way. We propose here to develop novel frameworks for the integration of spatiotemporal action structure in both generative and discriminative models, pushing for a breakthrough ripe with enormous exploitation potential. A new class of hierarchical part-based discriminative models originally developed for object recognition are reinvented for action localisation and recognition, as a fundamental way of coping with complex activities formed by series of simple actions and addressing the issues with locality and multiple actors. New manifold learning techniques for generative graphical models are developed to tackle the presence of nuisance factors and improve their generalisation power. Finally, novel classes of graphical models able to handle whole convex sets of probabilities are formulated in order to address the issue of overfitting due to the limited size of the training sets. As companies are heavily investing on virtual mice, smart TVs, phones and cars, and range sensors are changing clinical practice and the entertainment industry, the timeliness and potential impact of this project could not be understated.",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b5833291475084e893379f5d797753b366c61751,https://www.semanticscholar.org/paper/b5833291475084e893379f5d797753b366c61751,Privacy Literacy: Extending Information Literacy in the Age of Social Media and Big Data,"This paper argues that there is a need for extending the concept of information literacy to include privacy literacy, which we conceptualise as the awareness and tools needed to understand and navigate our contemporary world of connected information and synergistic technologies whilst also protecting ones personal information. The paper is based on an interview study of participants in combination with online ethnographic observations of social media, and a cognitive walkthrough of their social media use. Background In our information age, all of our lives are increasingly monitored and configured by digital technologies (Lupton, 2015) and this has implications on the goods and services we receive, including health, car, and home insurance (Pingo & Narayan, 2016). Google, Facebook, Twitter, and YouTube provide platforms for people to create a personal profile, share information, link to others, befriend strangers, connect with others, subscribe to channels, and follow people. This involves the sharing of personal information for verification that is later used to profile individuals for advertisements and other purposes (Buchman, 2013; Meikle, 2016). Such massively generated data from use of digital devices or applications is referred to as “big data” (Agnellutti, 2014), with a huge trend in data mining and machine learning in order to understand users’ preferences, and behaviour patterns. Such personal information can potentially be used beyond intended purposes (Pierson, 2012), and has sparked discussions on how they simultaneously empower and disempower users in various ways, creating opportunities and exposing users to vulnerabilities (Christiansen, 2011; Pierson, 2012; Rosenblat, Kneese, & Boyd, 2014). They also point to a shift in the responsiility of privacy to the user as is evident from the messaging from the Office of the Australian Information Commissioner, which says ‘privacy in your hands.’ (OAIC, 2016). This raises the question of whether users have the awareness, knowledge, and tools to take privacy in their hands. Therefore, the research question this study addresses is: Do everyday users of social media understand its implications for personal information privacy, and what measures do they take to protect their privacy? Conceptual framework Westin (1967) defined privacy as ‘the claim of individuals, groups or institutions to determine for themselves when, how, and to what extent information about them is communicated to others’. The process of regulating privacy is a dynamic process of optimizing two psychological needs: the need to preserve one’s privacy and control access to and distribution of personal information, and the need to interact socially, where one has to disclose personal information (Altman, 1975). Hence, privacy is constructed and negotiated in social processes (Solove, 2002). Information privacy is often considered a technical design problem in information systems research (Cavoukian & Jonas, 2012, p. 863; Lehikoinen, 2008). Rather than this system-centred approach, Debatin (2011, p. 57) recommends that people need to develop an understanding of technology and its unintended consequences. In other words, users of digital technologies need to develop an informed concern about their privacy, avoiding both moral panic and ignorant or naïve indifference towards information technologies (Debatin, 2011, p. 57). Christiansen (2011) notes two distinct information sharing practices which users of technologies need to know or understand: voluntary sharing and involuntary disclosures. Debatin (2011) defines privacy literacy as ‘an informed concern for individuals privacy and effective strategies to protect it’. From an information literacy perspective, privacy literacy is proposed as one’s level of understanding and awareness of how personal information is tracked and used in online environments, and how information can retain or lose its private nature (Givens, 2015, p. 53). Möllers and Hälterlein’s (2013) argue that people need to exhibit active participation in negotiating for their privacy through understanding what is at stake when using digital technologies. When people use digital devices or applications, they need to decide on whether to give personal information by consciously considering the terms and conditions of the service (Debatin, 2011), which often requires high-level cognitive effort, which users hardly have the time or the tools for (Gindin, 2009; Solove, 2012), and hence avoid engaging with it. This information avoidance is a stress and coping method deployed by humans to deal with cognitive dissonance or is a result of cognitive bias (Case, Andrews, Johnson, & Allard, 2005). Narayan, Case, and Edwards (2011) note that ‘people tend to seek out information that agrees with their pre-existing world-view and cognitive skill levels rather than acknowledge or seek new information that may cause an uncomfortable conflict in their minds’. The negotiated nature and commodification of privacy (Barnes, 2006; Thrift, 2005) causes such a cognitive dissonance and hence attracts information behaviour perspectives. The reason people avoid this information is not deliberate, but due to the sheer amount of time needed to read the privacy terms and the complexity of the language [and the interfaces] used (Potter, 2015). Methodology Perik, de Ruyter, and Markopoulos (2005) noted that there is a methodological problem especially in the domain of privacy in computer-mediated communication research. In a study of people’s information privacy perceptions though observations of actual use of a system, many respondents demonstrate risk-taking behaviours compared to interview responses (van de Garde-Perik, 2009, p. 21). To address these issues, a triangulation of methods was used in our study (Yin, 2013); we used a combination of online observations or digital ethnography (Talip, Narayan, Edwards, & Watson, 2015) and cognitive walkthroughs (Blackmon, 2004) alongside interviews with participants about their perceptions, awareness, and use of social media. Six university students participated in this study. Findings Findings show that privacy is a negotiated process wherein users decide on how much personal information they want to disclose online, and for what returns. Participants also exhibited various information behaviours such as information avoidance, due to information overload and the lack of cognitive tools to process the information. The cognitive walkthrough revealed that the interface of social media sites was a huge issue also — they are designed to be seamless which also means that most users did not know how to work the privacy settings. That said, we found two distinct groups amongst the participants. Those who, when there are two competing needs, choose to ignore their need for privacy over the immediate gains they can get from a transaction or interaction, while others were so paranoid about their privacy that it inhibited their online social interactions. We believe that both of these groups can benefit from privacy literacy that helps them engage with the online world without compromising their personal information. This calls for a need to incorporate privacy literacy as an essential complement to information literacy.",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8224ca005f3671b88222e83ca4c62291f9bebce3,https://www.semanticscholar.org/paper/8224ca005f3671b88222e83ca4c62291f9bebce3,Technological Transformation Processes and Organizational Learning-Limits to Collaboration,"INTRODUCTION In the process of technical transformation, the management of technological learning is an important aspect of organizational change. For decades, neoclassic economic theory has treated technological change in organizations as a black box. A growing interest in technological change and economic growth has outlined a superficial functionalist view on the processes of technical change, perceiving business firms as following a specific technological trajectory defined by the set of routines and competences generated over the years (Nelson & Winter, 1982; Dosi, 1982). Organizational competences are to be conceptualized as institutionalized bodies of knowledge, or routines, determined by norms and values originating from professional training systems and institutions. Hence, future decisions concerning technological choices are constrained by organizational routines developed in the past. Therefore, we must view firms as embedded, or specialized, in certain technological repertories, or paths, that keep them relatively rigid in relation to the implementation of new technologies (Teece et al., 1990; Karnoe, 1995; Nicolini & Meznar, 1995). Which trajectory to follow is determined by external relations, i.e. formal and informal networks. Thus, the links between individuals, institutions and business firms are important analytical benchmarks, as individual behaviour and interaction form the institutional and industrial patterns that constitute a given technological trajectory. Therefore, we will emphasize social interaction, i.e. interaction binding individuals to individuals, individuals to institutions, and institutions to other institutions (Fruin, 1994; Granovetter, 1992). Emphasis should be given to the role of individuals or groups of actors, e.g. communities of practitioners in order to identify historical paths in the deployed strategies for search and learning (Constant, 1984; Teece et al., 1990; Rosenberg, 1994; Fouts & Brown, 1995). AN ACCIDENTAL MEETING WITH BIOTECHNOLOGY Since 1934, Rynkeby has been a product oriented firm with no formal research activities. Technological and engineering problems are solved through extensive network relationships with the Danish dairy sector and machine shops. Over the years, these relationships have evolved, partly due to careful recruitment of dairy technicians. In 1977, the technical director of Rynkeby, a trained engineer, met an old student acquaintance who worked at Novo Nordisk (1). Talking about their jobs, they also discussed the possibilities of 1 producing protein enriched foodstuffs through the traditional enzymatic process, hydrolyzation. Novo had developed an enzyme, alkalase, that could be used as a catalyst for protein enrichments. (2) The technical director convinced the owner of Rynkeby, Dagmar Andreasen, to initiate a development project aimed at creating a line of protein enriched fruit juices for the Danish health care sector. The project appeared promising, not only would a protein enriched juice address certain nutrition problems in the elderly care sector, but could also shorten hospital stays for patients, who had undergone surgery. Furthermore, the protein might have other applications (e.g., for pharmaceuticals and as an ingredient in a variety of foodstuffs). Finally, idealistically, the owner of the company believed that, in the long term perspective, the protein might help to solve some of the third world countries' hunger problems (Andreasen, 1984). (3) In developing the project, Rynkeby had to establish some research and scientific alike relationship to the world's largest single manufacturer of industrial enzymes, Novo Nordisk. Novo Nordisk was to assist Rynkeby technically in building an experimental plant. From this point, Rynkeby should be able to handle the development of a large scale production plant. Since the enzyme alkalase was a well known product, and the process of hydrolyzing soy protein were well described in scientific journals, both Novo Nordisk and Rynkeby thought that development project would only take a few months. …",,1997.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9cb522bc3dfcd2dccc2b11fbba21b59f31d9835b,https://www.semanticscholar.org/paper/9cb522bc3dfcd2dccc2b11fbba21b59f31d9835b,Upsetting the Apple Cart Whilst Pulling it along the Road: Implementing the National Service Framework for Mental Health,"This paper argues that the traditional approach to translating national policy into local practice, based as it is on a metaphor of organisations as machines, will not lead to effective implementation of the national service framework for mental health. The recent innovations of performance management and evidence‐based practice will not rectify the failures inherent in that traditional approach. Rather, the paper contends that there is need for a broader range of metaphors of organisations to be deployed in the creation of a robust implementation process and suggests three ‐ negotiated order, chaos theory and learning theory ‐ that the authors have found of particular value.",,2000.0,10.1108/14769018200000017,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
719e0291e1581e808c7234ad028c92ddc4d64e06,https://www.semanticscholar.org/paper/719e0291e1581e808c7234ad028c92ddc4d64e06,"In response to ""Development, implementation and impact of an automated early warning and response system for sepsis"".","We greatly appreciate the letter (1) regarding our publication describing the development, implementation and impact of an automated Early Warning and Response System (EWRS) for Sepsis at our institution (2). We used established criteria for severe sepsis as predictors in our algorithm to expedite the derivation, validation and implementation of the EWRS. This resulted in implementation across a multi-hospital healthcare system within one year from the date that vital signs first became available in our electronic health record (EHR). Although the ability of our model as a predictive classifier was fair, its clinical utility was robust. With a positive likelihood ratio >5 and screen positive rate <5%, the model enabled the timely identification and care of patients at risk for sepsis, improved sepsis documentation, and potentially reduced mortality, thereby supporting the notion that simple classifiers can compete with more complex algorithms (3). 
 
Although the original model implemented could have been improved using other variables and approaches, we were concerned at the time about the diminishing returns of additional complexity, particularly when deploying the model in a production environment with high demands. We thus favored simplicity at all stages, with the knowledge that complexity could be added once the clinical feasibility of the system was established. 
 
More recently, we have applied machine learning algorithms to leverage “big data” available from our EHR, using random forest models to predict hospital readmissions (4) and improve sepsis predictions (in an initiative labelled EWRS 2.0). As Drs. Bhattacharjee and Edelson suggest, these methods can have advantages over using more manual regression approaches to select predictors, a particularly cumbersome process when an acutely ill inpatient can generate hundreds of variables and >1,000 data points daily (5). Yet, although machine learning algorithms can theoretically be constructed using all variables in real-time, from an implementation perspective, it can be difficult to continuously collect and maintain such a complete information set for each patient. Therefore, we strive to develop models using subsets of predictors without sacrificing performance. 
 
What we’ve learned is that the development of highly accurate predictive algorithms using these approaches is often less complex than the technical and administrative aspects of implementing these algorithms into practice. To address these challenges, we are currently developing an open platform to allow researchers and data scientists to tap into the wealth of data available in the EHR and other connected devices in order to build, test, and deploy novel intelligent predictive solutions. Our goal in developing this platform is to accelerate the development and deployment of innovative solutions. Once in production, algorithm performance can then be improved iteratively as more data (in terms of volume and velocity) become available through technological advances such as streaming health data from wearables and other connected devices. 
 
With the implementation of EWRS 1.0, we thus set the stage for the development of high performance predictive models, as well as the implementation of these models into practice, with the ultimate goal of improving the quality and value of care we provide.",Journal of hospital medicine,2015.0,10.1002/jhm.2362,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c32678603e4a44f523e22ae1765df3447687ae11,https://www.semanticscholar.org/paper/c32678603e4a44f523e22ae1765df3447687ae11,"An automated framework for predicting obstructive sleep apnea using a brief, daytime, non-intrusive test procedure","Sleep constitutes a big portion of our lives and is a major part of health and well-being. The vital repair and regeneration tasks carried out during sleep are essential for our physical, mental and emotional health. Obstructive sleep apnea (OSA) is a sleep disorder that is characterized by repeated pauses in breathing during sleep. These pauses, or apneas, deplete the brain and the rest of the body of oxygen and disrupt the normal sleep cycle. OSA is associated with a number of adverse safety and health consequences, including excessive daytime sleepiness and fatigue, which increase the risk for motor vehicle and work-related accidents. OSA also results in an increased risk for hypertension, cardiovascular disease, the development of diabetes and even premature death. The gold standard method for diagnosing OSA patients is polysomnography (PSG). PSG is an overnight sleep test that monitors a participant's biophysical changes (EEG, ECG, etc.) that occur during sleep. Despite its wide use and multi-parametric nature, there are multiple complications associated with that test that make it ineffective as an early-stage diagnosis tool. In this paper, we propose a daytime OSA screening tool that addresses the shortcomings of PSG. The framework consists of a data collection component that acquires information about the subject being tested, and a prediction component that analyzes the collected data and makes a diagnosis. We identify patients' key physiological, psychological and contextual features and apply advanced machine learning algorithms to build effective prediction models that help identify OSA patients in the comfort of their own home. The system was deployed in a pilot sleep apnea study of 16 patients. Results demonstrate the proposed system's great potential in helping sleep specialists in the initial assessment of patients with suspected OSA.",PETRA,2015.0,10.1145/2769493.2769541,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
50c1184569211e62e320bdea1d87b285e6cd1466,https://www.semanticscholar.org/paper/50c1184569211e62e320bdea1d87b285e6cd1466,Towards a New Safety Assurance Method for Complex Safety-Critical Systems,"Know your enemy and know yourself and you can fight a hundred battles without disaster. Sun Tzu, The Art of War This essay investigates the making of timely and acceptable safety assurance decision throughout a safety-critical system’s lifecycle in a complex environment. This ‘battle’ of assuring a safety-critical system is safe enough to avoid the ‘disaster’ of accident is a long and treacherous journey. It demands a structured and persistent method to support safety analysis despite challenges from the non-deterministic and non-linear environment throughout the system lifecycle. Learning from Sun Tzu, this journey begins by searching for clarity regarding the two important questions: ‘know yourself’ by understanding the current way of conducting safety management throughout a system lifecycle; and ‘know the enemy’ by examining the potential risk and hazards cause by the unique characteristics of complexity. This is followed by a survey of possible methods that can be used to analyse and mitigate the risk under a complex system. Systems Engineering Essay Competition 2015 Page 2 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS The literature reviews make three observations. First, while there are established safety management processes to analyse safety at specific milestones of the system lifecycle, there is a lack of continuity in managing and utilising the system knowledge regarding safety throughout the system lifecycle. Secondly, safety assessment must adapt to changing social-technical context especially when a system acquisition lifecycle comprises multiple distinct phases that introduce different constraints to safety assessment. Lastly, uncertainty in the complex environment can never be eliminated but there should be more efforts to minimise the surprises due to incomplete and imperfect information so as to create the confidence in the safety analysis. The paper concludes by providing a preliminary approach to develop a safety assurance method that aims to be applied throughout the system lifecycle to provide a structured and continual way to support decision making. Introduction: Where are the Hazards? As technology advances, more and more systems in domains like defence, air traffic management, railway transport, nuclear power plant, offshore drilling and health care are becoming highly networked and complex. These are described as safety-critical systems as any failure can potentially lead to the loss of life and damage to property or environment. For example, in the defence industry, networked of large-scale safety-critical systems (often refers to as Network Centric Warfare or System-of-Systems 1 [1]) have been revolutionising the applications of military technology as machines and computers are used to carry out complex and time-critical tasks. These machines are inter-connected to form larger inter-dependent systems and continuing to expand in numbers and complexity as the armed forces attempt to accomplish more challenging missions. Unfortunately, while there are established safety management processes, accidents that led to the loss of Systems Engineering Essay Competition 2015 Page 3 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS life and damage to properties continue to surface from such highly complex safety-critical systems. Some of the most notable accidents and incidents in recent years include:  (Space) NASA space shuttle Challenger (1986) [2] and Columbia (2003) [3] disasters  (Military Operation) B-1B Lancer bomber friendly fire on coalition soldiers in Afghanistan (2014) [4]  (Drilling) Piper Alpha offshore oil production explosion (1988) [5]  (Maintenance) F-111 (Fuel Tank) De-seal/Reseal program leading to chemical exposure (2001) [6]  (Health-care) Overdose of radiation during Therac-25 radiation therapy (1985) [7]  (Rail) Wenzhou high speed railway collision (2011) [8] While the faults for each of these disasters are unique, one common observation is that it is extremely difficult to narrow down to a specific failure mode. Unlike complicated but linear systems where traditional safety analysis method is capable of using linear reductionist approach to deduce the root causes, the failure modes in complex safety-critical systems are different. Reiman [9] observes that effects from a complex system have “several parallel contributing factors, instead of one or few causal chains 2 as in linear systems”. Dekker [10] also believes that “the behaviour of such complex system cannot be reduced to an aggregate of the behaviour of its constituent components”. Hence, even if one root cause has been identified, decision makers may face the frustrating but real challenge of not being able to fully comprehend the full casual chains of complex relations. One good example of a complex safety-critical system is Air Traffic Control (ATC). On 12 Dec 2014, an air traffic disruption at the Swanwick ATC resulted in numerous flight cancellations across Heathrow, Gatwick and London City [11]. The System Flight Servers failed when more workstations were being brought online during the transition between 1 The System-of-Systems (SoS) refers to a set of systems that are cooperating for a common purpose while simultaneously working as independent entities. 2 A causal chain refers to the path or sequence of events that runs from a root cause to problem symptoms in the real world. Systems Engineering Essay Competition 2015 Page 4 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS normal and standby operation [12]. This affected air traffic control as it was impossible for controllers to access aircraft flight plans. While the final report has yet to be released, NATS has announced that the failure is unprecedented in its 13 years of operations. The incident highlights the difficulties in managing system safety in complex environment. There will be intense pressure when failures occur and rightfully so since safety-critical systems are utilised in critical situations (e.g. ATC keeping the airspace safe) where there are severe consequences (e.g. disruption to commercial flights and passengers’ safety) when the systems fail. It is also possible that certain failures may never manifest themselves during system development as it is impossible to predict and conduct safety assessment on all operational scenarios (e.g. overloading of the ATC System Flight Servers). Active sharing of knowledge regarding safety throughout the system lifecycle can help to better anticipate and identify such ‘blind-spots’ during operation. In terms of managing safety-critical projects, social, technical and organisation tensions continue to pose safety challenges when it comes to acquiring a system in such complex environment. The following shows a sample of such concerns highlighted by Atkinson [13] and Saunders [14] from their surveys on managing project uncertainty of complex safety-critical system:  Novelty of design and technology  Diverse and conflicting stakeholders expectations and belief  Failure to anticipate concurrency of activities and capture dependency relationships  Ineffective communication and knowledge management with changing stakeholders throughout system lifecycle  Lack of continuity in personal and responsibilities when managing different interoperating systems  Incomplete and imperfect information  Lack of systematic process to capture corporate knowledge and lessons learned While the list represents uncertainty in managing projects, it is equally relevant to safety management and highlights the diversity of social-technical context that would affect the Systems Engineering Essay Competition 2015 Page 5 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS effectiveness of any safety analysis. Most safety-critical systems comprise human-machine interactions and it will be important to consider explicitly the impact of changing socio-technical context during safety analysis so as to create attention to potential hazards in such circumstances. The System Lifecycle – where it begins One approach to appreciate the safety hazards facing a safety-critical system is to consider its lifecycle. A system can be considered as a “combination, with defined boundaries, of elements that are used together in a defined operating environment to perform a given task or achieve a specific purpose”[15]. Taking reference from the military, a system is realised by following the system acquisition lifecycle. A full-scale system acquisition lifecycle includes multiple stages, milestones and decision points that shape the development of a system till its operationalisation. Two examples of military acquisition lifecycles are shown in Figure 1. They are the UK MoD CADMID 3 acquisition cycle and the US DoD Defence Acquisition Process. Figure 1 Categorisation of System Acquisition Lifecycle in defence A system lifecycle has two distinct phases: development and operation. Both phases are subjected to risk and safety hazards in the complex environment but exhibit different system characteristics. The following table provides a comparison of the two phases. Characteristics System Development System Operation 3 CADMID refers to the six phases of acquisition lifecycle: Concept, Assessment, Demonstration, Manufacture, In-service and Disposal. Systems Engineering Essay Competition 2015 Page 6 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS Characteristics System Development System Operation Type of processes Design, plan, production, testing, and deployment Operation, maintenance and support, ret",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
148b7d09bc9513a8b269b393e15f95c878f4c112,https://www.semanticscholar.org/paper/148b7d09bc9513a8b269b393e15f95c878f4c112,Movement-Related Desynchronization in EEG-based Brain-Computer Interface applications for stroke motor rehabilitation,"Neurological degenerative diseases like stroke, Alzheimer, Amyothrophic Lateral Sclerosis (ALS), Parkinson and many others are constantly increasing their incidence in the world 
health statistics as far as the mean age of the global population is getting higher and higher. 
This leads to a general need for effective, at-home and low-cost rehabilitative and health-daily-care tools. The latter should consist either of technological devices implemented for operating in a remote way, i.e. tele-medicine is quickly spreading around the world, or very-advanced computer-based and robotic systems to realize intense and repetitive trainings. This is the challenge in which Information and Communications Technology (ICT) is asked to play a major role in order to bring medicine to reach further advancements. 
Indeed, no way to cope with these issues is possible outside a strong and vivid cooperation among multi-disciplinary teams of clinicians, physicians, biologists, neuro-psychologists and engineers and without a resolute pushing towards a widespread inter-operability between Institutes, Hospitals and Universities all over the world, as recently highlighted during the main International conferences on ICT in healthcare. The establishment of well-defined standards for gathering and sharing data will then represent a key element to enhance the efficacy of the aforementioned collaborations. 
Among the others, stroke is one of the most common neurological pathologies being the second or third cause of mortality in the world; moreover, it causes more than sixty 
percent survivors remain with severe cognitive and motor impairments that impede them in living normal lives and require a twenty-four-hours daily care. As a consequence, on one side stroke survivors experience a frustrating condition of being completely dependent on other people even to perform simple daily actions like reach and grasp an object, hold a glass of water to drink it and so on. States, by their side, have to take into account additional costs to provide stroke patients and their families with appropriate cares and supports to cope with their needs. For this reason, more and more fundings 
are recently made available by means of grants, European and International projects, programs to exchange different expertise among various countries with the aim to study 
how to accelerate and make more effective the recovery process of chronic stroke patients. 
The global research about this topic is conducted on several parallel aspects: as regard as the basic knowledge of brain processes, neurophysiologists, biologists and engineers are 
particularly interested in an in-depth understanding of the so-called neuroplastic changes that brain daily operates in order to adapt individuals to life changes, experiences and to realize more extensively their own potentialities. 
Neuroplasticity is indeed the corner stone for most of the trainings nowadays adopted by the standard as well as the more innovative methods in the rehabilitative programs for post-stroke recovery. Specifically speaking, motor rehabilitation usually includes long term, repetitive and intense goal-directed exercises that promote neuroplastic mechanisms such as neural sprouting, synapto-genesis and dendritic branching. These processes are strictly related with motor improvements and their study could - one day - serve as prognostic measures of the recovery. 
Another aspect of this eld of neuroscience research is the number of applications that it makes feasible. One of the most exciting is to connect an injured brain to a computer or a robotic device in a Brain-Computer or Brain-Machine Interface (BCI or BMI) scheme aiming at bypassing the impairments of the patient and make him/her autonomously move again or train his/her motor abilities in a more effective way. This kind of research can already count an amount of literature that provides several proofs of concept that these heterogeneous systems constituted by humans and robots can work at the purpose. 
A particular application of BCI for restoring or enhancing, at least, the reaching abilities of chronic stroke survivors was implemented and is still currently being improved at I.R.C.C.S. San Camillo Hospital Foundation, an Institute for the rehabilitation from neurological diseases located in Lido of Venice and partially technically supported by the Department of Information Engineering of Padua in range of an agreement signed in 2009. 
This specific BCI platform allows patients to train and improve their reaching movements by means of a robotic arm that provides a force that helps patients in completing the training exercise, i.e. to hit a predetermined target. This force feedback is however subject to a strict condition: during the movement, the person has to produce the expected pattern of cerebral activity. Whenever this is accomplished, a force is delivered proportionally to the entity of the latter activity, otherwise the patient is obliged to operate without any help. In this way, this platform implements the so-called operant-learning, that is one of the most effective conditioning techniques to make a subject learn or re-learn a task. If, on one hand, the primary and explicit task is to improve a movement, on the other side the secondary but most important task is to deploy the perilesional part of the brain - still healthy - in becoming responsible for the control of the movement. It is a popular and widely-accepted opinion within the neuroscience community, indeed, that a healthy region of the sensorimotor area nearby the damaged one - which was previously in charge of performing the (reaching) movement - can optimally accomplish the impaired motor function substituting the original control area. 
Technically speaking, the main crucial feature that can ensure the effectiveness of the whole system is the precise and in real-time identification and quantification of the cerebral pattern associated with the movement, the worldwide named movement-related desynchronization (MRD). Starting from its original definition, passing through the most used techniques for its recognition, the thesis work presents a series of criticisms of the current signal processing method to detect the MRD and a complete analysis of the possible features that can better represent the movement condition and that can be more easily extracted during the on-line operations. 
Brain - it is well-known - learns by trials and errors and it needs a slightly-delayed (in the range of fraction of seconds) feedback of its performance to learn a task in the best way. This BCI application was born with the purpose to provide the above-mentioned feedback: however, this is only feasible if a computationally easy and contingent signal processing technique is available. This thesis work would like to cope with the lack of a well-planned real-time signal analysis in the current experimental protocol.",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
be51e5dd5b79b7de073babff9baf55d91c3787d3,https://www.semanticscholar.org/paper/be51e5dd5b79b7de073babff9baf55d91c3787d3,A spatial decision support system to assess personal exposure to air pollution integrating sensor measurements,"Recent epidemiological studies have reinforced the link between short and long-term exposure to air pollutants and adverse effects on public health especially over the weaker part of the population, like children and older adults. The creation of simple tools to locate sensible areas as well as of dedicated Spatial Decision Support System (SDSS) to improve the management of pollution risk areas system is strongly advised. The aim of this work is to develop a SDSS methodology, based on easy to find data and usable by decision makers, to assess and reduce the impact of air pollutants in a urban context. To achieve this goals I tested the exploitability of a set of low-cost sensors for outdoor air quality monitoring, I characterized the urban micro-environments and the spatial variability of air pollutants using remote sensing compared to field data and eventually I developed a SDSS to improve the public health designing and comparing different scenarios. The city centre of Edinburgh has been used as study case for the purposed methodology. To test the reliability and applicability of low cost sensors as proxies for remote sensed data, we conducted a measurements campaign to compare the observed data between an official measurements station (OMS) in Trento (Italy) and electrochemical and thick film sensors respectively of Carbon Monoxide (CO) and Ozone ($O_3$). Due to data quality and availability we decided to characterize the urban micro-environments of Edinburgh (Scotland, UK) in eight main classes (water, grass, vegetation, road, car, bus, buildings and shadow) combining the Geographic Object-Based Image Analysis (GEOBIA) with Machine Learning algorithms to process the high resolution (0.25m x 0.25m) RGB aerial ortho-rectified images. This land-use characterization combined with other geographical informations, like the classification of the roads and the urban morphology, were compared with 37 Nitrogen Dioxide (NO2) concentration data, collected using passive tubes during a six week campaign of measurements conducted by the school of Chemistry of the University of Edinburgh. 
I developed a new open-source GIS python library (PyGRASS), integrated in the stable release of GRASS GIS, to speed-up the prototyping phase and to create and test new GIS tools and methodologies. Different studies on SDSS were carried out to implement procedures and models. Based on these models and data all the factors (land-use, roads and geo-morphological features) were ranked to identify which are driving forces for urban air quality and to help decision makers to develop new policies. The sensor tested in Trento revealed an evident drift in measurement residues for CO, furthermore the measurements were also quite sensitive to external factors such as temperature and humidity. Since these sensors required frequent recalibration in order to obtain reliable results, their use was not as low-cost as expected. The characterization of urban land-use in Edinburgh with GEOBIA and machine learning provided an overall accuracy of 93.71\% with a Cohen's k of 0.916 using a train/test dataset of 9301 objects. The $NO_2$ data confirm the assumption that air concentration is strongly dependent on geographical position and it is strongly influenced by the position of the pollutant's source. Using the results of the tests and remote sensing analysis, I developed an SDSS. Starting from the current situation, I designed three scenarios to assess the effect that different policies and actions could have on improving air quality at on the local and district level. The outcomes of this work can be used to define and compare different scenarios and develop effective policies to reduce the impact of air pollutants in an urban context using simple and easy to find data. The GIS-based tool can help to identify critical areas before deploying sensors and splitting the study area in homogeneous micro-environments clusters. The model is easy to expand following different procedures.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6479db81c4b95fa15b709da1f94142675abf54f3,https://www.semanticscholar.org/paper/6479db81c4b95fa15b709da1f94142675abf54f3,P. Falzon (ed): Constructive Ergonomics,,Journal of Occupational Rehabilitation,2015.0,10.1007/s10926-015-9566-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6701cdc3063ceb2be2347fc95c7ceb34befb6461,https://www.semanticscholar.org/paper/6701cdc3063ceb2be2347fc95c7ceb34befb6461,An enhanced mobile ambulatory assessment system for alcohol craving studies,"Currently, most methods in clinical psychology research primarily rely on questionnaires and interviews with examiners instead of providing real-life subject behavioral and psychology data monitoring and collecting services. This thesis presents an android-OS-based mobile Ambulatory Assessment System, for psychology research -especially alcohol craving studies – to improve current methods and provide real-time data monitoring, collecting and processing. As current generation smartphones provide more powerful communication platform, embedded with robust built-in sensor suits and vigorous processing and storage capabilities, smartphones play an increasingly significant role in various sensing tasks such as activities monitoring personal health surveillance and environment. This system consists of four parts: a wearable sensor (Equivital EQ2 sensor) that measures physiological data, an Android smartphone, a web server and a data analysis module. The smartphone is responsible for collecting and recording physiological data from the wireless wearable sensor, interacting with the users to conduct various surveys, and uploading data to the web server. The server is responsible for data processing, computation, and visualization. Utilizing machine learning methods, data from the sensor and survey build models that predict how various psychological disorders cause alcohol or other substance cravings and emotion dysregulation. The system has been deployed in a field study of alcohol craving, and initial data collected from real subjects proved promising.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8003f27c8965688c6c2499759e0350ab6f3c608,https://www.semanticscholar.org/paper/c8003f27c8965688c6c2499759e0350ab6f3c608,Ambient Assisted Living for the Motor Impaired,"The field of Ambient Assisted Living (AAL) has shown great potential in counteracting some of the effects of the worldwide population ageing phenomenon. Its main goal is to promote a safe, healthy, and functional living environment for the elderly and people with disabilities who wish to live independently in their home. To achieve this goal, AAL environments utilize Information and Communication Technologies (ICTs) and the emerging Ambient Intelligence (AmI) paradigm in order to provide sophisticated solutions that can support the needs of an elderly person or a person with disabilities, at home. This chapter will present examples of AAL environments found in research and academic literature and the solutions they offer to cater for the basic needs of motor-impaired people in order to support their independent living and quality of life. The challenges of using such technologies will also be discussed. INTRODUCTION The World Health Organization (WHO) World Report on Disability (World Health Organization, 2011), states that approximately one billion people worldwide experience a disabling condition. This is the first ever global estimate of persons with disabilities in the last 40 years. The term “disabled” according to WHO is used for people who are experiencing a limitation in their movement, activities, and senses due to a physical or mental condition. The report also states that almost everyone will be temporarily or permanently impaired at some point in his or her life, especially when at old age. At the same time, people with disabilities are more susceptible to poorer health outcomes and lower education achievements, which often lead to higher rates of poverty than people without disabilities. Disabled people are in need of rehabilitation services in order to maximize their functioning required to support independence. But in developing countries such access to rehabilitation services is often limited and in some cases nonexistent altogether. Even in high-income countries about 20%40% of people with disabilities have limited assistance for their everyday activities. In the US, for example, 70% of adults have to rely on family and friends for assistance with daily activities. The number of people experiencing motor impairments and other disabilities is only expected to rise in the near future, as the world population continues to age at an unprecedented rate. According to the United Nations World Population Ageing report (United Nations, 2000), worldwide population ageing is enduring and has a growing rate of 2.6%per year, considerably faster than the population as a whole, which is increasing at 1.2 % annually. Europe is currently holding the highest proportion of older persons, with a population of 60 or over currently constituting 24.5% of its total population. In the United States that number is 19.1% respectively. From the above, it can be argued that the increase of the ageing population will have major implications for all aspects of people’s everyday life particularly of socio-economic nature. The number of people that will need some form of institutionalized help is going to increase, adding on the burden of the existing health care systems. Governments around the world have taken serious notice of this reality and of the need to come up with strategies to adapt their social practices and processes in order to accommodate this dynamic population shift in the population. The need to find ways to make it easier for people with age and other related disabilities to live a longer, satisfying and independent life in their own homes is now more imperative than ever. Ambient Assisted Living (AAL) is a domain that has attracted a steadily growing attention in the scientific community because it involves emerging innovative technological solutions that can counteract some of the challenges described above. The main focus in AAL is on supporting persons with disabilities in their own environment and providing the means to increase the degree of independent living. Its aim is to provide integral solutions in the areas of home care, independent living, and institutionalized care homes that will improve the quality of life and lower the costs involved with health, home care and related social services. In order to achieve the above, AAL depends heavily on Information and Communication Technologies (ICTs) and the emerging Ambient Intelligence paradigm. This chapter provides an overview of how Ambient Assisted Living technologies can play a catalytic role in improving the living environment for people with motor impairments by providing solutions that can increase their level of independence. The chapter begins with an overview of the fields of Ambient Intelligence and Ambient Assisted Living, followed by a brief presentation of the latest research initiatives in Europe. It then discusses how AAL can provide solutions for the fulfillment of the four identified requirements for independent living: mobility, environment control, safety, health and emergency assistance, and social inclusion. Finally, the major challenges of AAL are discussed followed by the conclusion. AMBIENT ASSISTED LIVING (AAL) OVERVIEW AAL refers to the use of Information and Communication Technologies (ICT) in a person's living environment in an unobtrusive way enabling them to continue living a comfortable, independent, active life and staying socially connected well into old age. AAL’s main goal is to provide the technological platform to support individuals in living an autonomous life for as long as possible. The roots of AAL are in traditional Assistive Technologies for people with disabilities, ‘Design for All’ approaches to usability and accessibility, as well as in the emerging computing paradigm of Ambient Intelligence (Pieper, Antona, Cortes, 2011). Ambient Intelligence (AmI) is a term that refers to the vision of a world in which smart, intuitively operated devices support users in an unobtrusive way in their everyday life. AmI has enabled the introduction of ubiquitous information, computational, and communication technology in a seamless yet unobtrusive way creating smart everyday living environments (Encarnação & Kriste, 2005). In such smart environments, intelligent applications and devices become aware of the human goals and needs by operating collectively and sharing information and intelligence through a hidden network that connects them in a way that is natural and intuitive to the user (Aarts & Encarnação, 2008). AmI infrastructures have gained a great momentum in today’s world in many industries such as home automation, entertainment, automotive, and healthcare to name a few. The technologies involved have the capacity to transform everyday common objects from CD players to coffee machines into smart objects that support context awareness, personalization, anticipatory behavior, and adaptation, all of which enable a certain degree of autonomous decision-making. Lighting, sound, vision, home appliances, and other electronic devices, all come into play in an AmI environment and share the same purpose, to improve user experience by facilitating the user’s interaction with it (Aarts & Kriste, 2005). Aarts and Encarnação (2008) stated that the notion intelligence reflects that the digital surroundings in a smart environment exhibit certain forms of social interaction, in other words they are able to recognize the occupants, adapt themselves to their needs, learn from their behavior, and possibly act on their behalf. Based on the described notion of intelligence they have synthesized the following list of the most important features of Ambient Intelligence: • Integration through large-scale embedding electronics into the environment • Context-awareness through user, location, and situation identification – the system uses sensors to perceive a situation, the location where that situation is taking place, and the user involved • Personalization through interface and service adjustment – the system can change its behavior according to the needs of the user • Adaptation through learning the user’s behaviors • Anticipatory behavior through reasoning – the system acts on behalf of the user making decisions based on predictions and expectations about future actions AAL with the help of the Ambient Intelligence (AmI) paradigm and new ICT technologies can now provide smart sophisticated solutions that offer the potential to change dramatically the quality of life for a disabled person, often making the difference from living with personal assistance on a daily basis to living an autonomous life. One of AAL’s focal concerns is also to offer user-friendly interfaces that are adaptable to the needs and abilities of the user and user-centric methods of interaction for the individual with his or her immediate environment (Pieper et al, 2011). AAL RESEARCH INITIATIVES IN EUROPE In the recent years, policy initiatives have been launched in Europe on the field of Ambient Assisted Living (AAL) in order to create a favorable ground towards research, development, and deployment of ICT technologies with focus on addressing the challenges, but also the opportunities of ageing. The “Ageing Well in the Information Society” Action Plan was adopted in June 2007 by the European Commission with the goal to bring forward a package of measures that should lead to greater uptake of ICTs by Europe’s senior citizens and stimulate industry to produce technologies appropriate for them (Stephanidis, 2011). For that purpose, the European Commission launched a dedicated action in the 7 Framework Programme and partial funding of the Ambient Assisted Living Joint Research and Innovation Programme, involving most EU Member States (Stephanidis, 2011). By 2013, the EU and Member States, and the private sector will have invested more than €1 billion in research and innovation for ageing well: some €600m in the Ambient Assisted Living Joint Programme (AAL JP), and an ",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4f220bf40a5d325e1ad681bea18ad172d899fc04,https://www.semanticscholar.org/paper/4f220bf40a5d325e1ad681bea18ad172d899fc04,A Cloud Based Autonomic Mental State Monitoring System Using Wearable Body Sensors,"Development of body- and bio-sensor network opens a new horizon of healthcare especially to measure the vital physical signs of personnel for diseases diagnosis and patient monitoring. And the cloud computing technology is enabling patient monitoring service dynamically scalable and ubiquitously accessible. Physical and mental health, both are important for the existence of human being with happiness and smartness. The success of mental health monitoring system depends on real life data accusation from patient with mental diseases and some historical data about patients and also his predecessors. This paper proposes a ubiquitous mental state monitoring system on cloud environment. In this system, patient’s real-time vital diseases symptoms are collected through body sensor network (BSN) and then analyzed the collected data on the healthcare agent of cloud including patient’s historical repository of diseases, habits and rehabilitations. Here, we model the mental statuses of patients as the discrete set of states of hidden Markov model (HMM) and BSNs data with clouds facts as the observations of HMM. Finally, we use Viterbi, a machine learning algorithm to generate the most probable mental state sequence of the patients. By deploying this method on mental patients dataset, we validate the proposal.",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a07b2e2eda3034512a3a78c455c84f5d181a7a62,https://www.semanticscholar.org/paper/a07b2e2eda3034512a3a78c455c84f5d181a7a62,An Affective Computing Multilayer Cognitive Architecture for Evolutionary Cognitive Robotics,"Robots are entering our daily lives from self-driving cars to health-care robots. Historically, pre-programmed robots were vulnerable to changing conditions in daily life, primarily because of a lack of ability to generate novel, non-preset flexible solutions. Thus there is a need for robotics to incorporate adaptation, which is a trait of higher order natural species. This adaptation allows higher-order natural species to change their behaviours and internal mechanisms based on experience with often dynamic environment. The ability to adapt emerged through evolutionary processes. Evolutionary Robotics is an approach to create autonomous robots that are capable of automatically generating artificial behaviors and morphologies to achieve adaptation. Evolutionary robotics has the potential to automatically synthesize controllers for real autonomous robots and generate solutions to complete tasks in the uncertain real-world. Compared to the inflexibility of pre-programmed robots, evolutionary robots are able to learn flexible solutions to given tasks through evolutionary methods.  Cognitive robotics, a branch of artificial cognitive systems research, is such an attempt to create autonomous robots by applying bio-inspired methods. As the robot interacts with environment, an underlying cognitive system can learn its own solutions toward task completion. This learning-solution-from-interaction approach, also termed as a Reinforcement Learning (RL) approach, is widely applied in cognitive robotics to learn the solutions automatically. Ideally, the solutions can emerge in the cognitive system through the trial-and-error process of the RL approach without introducing human bias.  This thesis aims to develop an evolutionary cognitive architecture (system) for a robot that can learn adaptive solutions to complete tasks. Inspired by emotion theories, this work proposes Affective Computing Multilayer Cognitive Architecture (ACMCA), a universal cognitive architecture, which is able to learn diverse solutions. Extending from previous work, ACMCA has a five-layer structure, where each layer aims to achieve different components of the solutions. The position of this thesis is that introducing a novel emotion inspired multilayer architecture that produces task solutions through subsumption operations and underlying appropriate machine learning algorithms will allow a robot to complete admissible tasks.  ACMCA’s five layers are: primary reinforcer layer, secondary reinforcer layer, core affect state layer, strategy layer, and behaviour layer. This five-layer decomposition also meets the traditional decomposition of a mobile control system into functional modules (e.g. perception, modelling, planning, task execution, and motor control). Each layer contains computing nodes as functional modules that process various Stimuli, Actions, and their consequential Outcomes of the cognitive system. In this work, 17 computing nodes and their connections in ACMCA represent the solutions that a mobile robot has learned to complete navigation tasks in complex scenarios.  Inspired by the Constructive Theory 1 and the robotic subsumption system, this work proposes a contingency-based subsumption approach to construct ACMCA. This contingency is termed Stimuli-Action-Outcome Contingency (SAOC), which is extended from the Action-Outcome (AO) contingency of Construction Theory. SAOCs are represented by “if-then” rules, termed SAOC rules, which encapsulate Stimuli, Actions, and their consequential Outcomes, providing clear symbolic interpretations. That is, the symbolic meaning of a SAOC rule can be interpreted as: if the input stimulus is perceived, the output action will be advocated as a cognitive response, expecting the outcome of the action with an estimation of relevance. As low-level computing nodes encapsulate Stimulus, Actions, and Outcomes, high-level computing nodes can subsume these low-level ones through the form of SAOC rules. Therefore, the proposed ACMCA can be constructed by subsumption layers of Stimuli-Action-Outcome Contingency (SAOC) rules.  This work applies machine learning techniques to facilitate ACMCA’s real-world robotic implementation. This work selects Accuracy-based Learning Classifier Systems (XCS) algorithms as the underlying machine learning techniques that are deployed at computing nodes for the contingency-based subsumption operations. The mitosis approach of XCS and the XCS with a Combined Reward method (XCSCR) are two novel variants of XCS algorithm. They are proposed to amend two challenges that occur when the standard XCS approaches are applied for robotic applications. The mitosis approach introduces an accuracy pressure into the algorithm’s evolutionary process, improving the algorithms’ performance in robotic applications where noisy interferences exist. The XCSCR enables the policy to emerge earlier and more frequently than the existing benchmark approaches in multistep problems. Therefore, a robot with the XCSCR can handle a multistep scenario more effectively than those with the benchmarked algorithms.  This work conducts five experiments to test the capability of ACMCA and its underlying algorithms in learning solutions for robotic navigation tasks. The five experiments are conducted as follows: reflex-learning, IR-tuning, deliberation-establishing, emotion model, and combined reward assignment. As the results of the experiments, three different affective patterns have emerged in the first three experiments, an emotion model has emerged in the fourth experiments, and the fifth experiment explores ACMCA’s potential implementation in the life-long learning scenario.  These results demonstrate that ACMCA, a novel emotion inspired multilayer architecture, can produce task solutions through contingency-based subsumption operations and underlying appropriate machine learning algorithms, allowing a robot to complete admissible tasks through evolutionary processes. The contingency-based subsumption operations can establish three contingencies and one emotion model between the subsumed components by multiple RL agents which deploy the proposed mitosis approach of XCS algorithms. These three emotion patterns and emotion model can consistently improve the robot’s navigation performance with interpretable explanations. These two variants of XCS algorithms can amend shortfalls of the standard XCS approach in real-world robotic implementations. It has been demonstrated that the diverse solutions learned by ACMCA improve the navigation performance of the robot in terms of higher flexibility, reduction in continuous collisions and shorter navigation time consumption.",,,10.26686/wgtn.17148398.v1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
61ea3c6e6d9935baa9f8a687bdb7246a9a34108c,https://www.semanticscholar.org/paper/61ea3c6e6d9935baa9f8a687bdb7246a9a34108c,Improving System Reliability for Cyber-Physical Systems Thesis proposal,"System reliability is a fundamental requirement of Cyber-Physical System, i.e., a system featuring a tight combination of, and coordination between, the systems computational and physical elements. Cyber-physical system includes systems ranging from the critical infrastructure such as power grid and transportation system to the health and biomedical devices. An unreliable system often leads to disruption of service, financial cost and even loss of human life. This thesis aims to improve system reliability for cyber-physical systems that meet following criteria: processing large amount of data; employing software as a system component; running online continuously; having operator-in-the-loop because of human judgment and accountability requirement for safety critical systems. The reason that I limit the system scope to this type of cyber-physical system is that this type of cyber-physical systems are important and becoming more prevalent. To improve system reliability for this type of cyber-physical systems, I propose a system evaluation approach named automated online evaluation. It works in parallel with the cyberphysical system to conduct automated evaluation at the multiple stages along the workflow of the system continuously and provide operator-in-the-loop feedback on reliability improvement. It is an approach whereby data from cyber-physical system is evaluated. For example, abnormal input and output data can be detected and flagged through data quality analysis. As a result, alerts can be sent to the operator-in-the-loop. The operator can then take actions and make changes to the system based on the alerts in order to achieve minimal system downtime and higher system reliability. To implement the proposed approach, I further propose a system architecture named ARIS (Autonomic Reliability Improvement System). One technique used by the approach is data quality analysis using computational intelligence that applies computational intelligence in evaluating data quality in some automated and efficient way to ensure data quality and make sure the running system to perform as expected reliably. The computational intelligence is enabled by machine learning, data mining, statistical and probabilistic analysis, and other intelligent techniques. In a cyber-physical system, the data collected from the system, e.g., software bug reports, system status logs and error reports, are stored in some databases. In my approach, these data are analyzed via data mining and other intelligent techniques so that useful information on system reliability including erroneous data and abnormal system state can be concluded. These reliability related information are directed to operators so that proper actions can be taken, sometimes proactively based on the predictive results, to ensure the proper and reliable execution of the system. Another technique used by the approach is self-tuning that automatically self-manages and self-configures the evaluation system to ensure it adapts itself based on the changes in the system and feedback from the operator. The self-tuning adapts the evaluation system to ensure its proper functioning, which leads to a more robust evaluation system and improved system reliability. For feasibility study of the proposed approach, I first present NOVA (Neutral Online Visualizationaided Autonomic) system, a data quality analysis system for improving system reliability for power grid cyber-physical system. I then present a feasibility study on effectiveness of some self-tuning techniques, including data classification, redundancy checking and trend detection. The self-tuning leads to an adaptive evaluation system that works better under system changes and operator feedback, which will lead to improved system reliability. The contribution of the work is an automated online evaluation approach that is able to improve system reliability for cyber-physical systems in the domain of interest as indicated above. It enables online reliability assurance of the deployed systems that are not possible to perform robust tests prior to actual deployment.",,2011.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17696776a83c12581e8e90d73e7be7c666729c5e,https://www.semanticscholar.org/paper/17696776a83c12581e8e90d73e7be7c666729c5e,Closing the Loop: The Capacities and Constraints of Information and Communication Technologies for Development (ICT4D),"As a mechanism for collecting and sharing information, information and communications technologies (ICT) hold immense potential for individuals and institutions in lowand middle-income countries. Currently the distribution and adoption of ICTs—particularly mobile devices—has far outpaced the provision of other household services like clean water, sanitation, hygiene, or energy services. At the same time, the development and deployment of Internet of Things (IoT) devices including cellularand satellite-connected sensors is facilitating more rapid feedback from remote regions where basic services are most limited. When used in conjunction with economic development or public health interventions, these devices and the feedback they provide can inform operation and maintenance activities for field staff and improve the monitoring and evaluation of outcomes for project stakeholders. This dissertation includes three chapters written as journal articles. While each chapter is framed around the work and research efforts being undertaken by the Sustainable Water, Energy, and Environmental Technologies Lab (SweetLab) at Portland State University, the common thread that weaves all three investigations together is the theme of ICT-enabled programmatic feedback. The first chapter introduces the three theoretical lenses that inform these investigations and the ways that ICTs and the data they provide can (1) serve as more appropriate proxies for measuring access to services, (2) reduce information asymmetries between various stakeholders including communities, governments, implementers, and funders, and (3) enable more robust methodologies for measuring outcomes and impacts of interventions within complex adaptive systems. The second chapter presents a critical review of the methodologies and technologies being used to track progress on sanitation and hygiene development goals. Chapter three describes how simple sensors and weight measurements can be combined with complex machine learning algorithms to facilitate more reliable and",,2000.0,10.15760/etd.6879,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
45118e07026d6fe3c534c9f1c3d5765a98e242fd,https://www.semanticscholar.org/paper/45118e07026d6fe3c534c9f1c3d5765a98e242fd,From the President,"The process used to prefer certain products across drug classes for diabetes is generally focused on comparative effectiveness and cost. However, payers rarely tie patient preference for treatment attributes to formulary management, resulting in a misalignment of value as defined by providers, payers, and patients. Our study explores patient preferences and willingness to pay for treatment attributes of predetermined high-value and low-value medications within a health plan, in order to redefine value to incorporate patient preferences. A cross-sectional discrete choice experiment (DCE) questionnaire study design determined patient preferences for the benefit, risk, and cost attributes of type 2 diabetes treatments. A comprehensive literature review of patient preference studies in diabetes identified studied attributes, and a review of guidelines and medical literature identified clinical attributes. Patients and diabetes experts were interviewed and instructed to identify, prioritize, and comment on which attributes of diabetes medications were most important to them. From these interviews, a total of 7 attributes were selected for the dissemination for a DCE survey: 1) hemoglobin A1C reduction, 2) cardiovascular (CV) risk reduction, 3) heart failure (HF) risk reduction, 4) out-of-pocket cost, 5) route of administration, 6) dosing flexibility, and 7) gastrointestinal (GI) side effects. From the 58 health plan beneficiaries who responded to the DCE survey, patients preferred to be treated versus foregoing care. Attribute preferences such as cost, HF risk reduction, CV risk reduction, and GI side effects were found to be statistically significant. These survey results were used to calculate the willingness-to-pay thresholds to demonstrate which diabetic medications are preferred most by patients. These findings will then be compared with how the health plan ranks medications in order to compare where patients’ and health plans’ definitions of value are aligned and where differences arise. By aligning patient and stakeholder preferences, our study has the potential to yield improved patient outcomes and increase cost-savings to patients, beneficiaries, and health plans. The objective of this study is to obtain a quantitative measure of the value of fear of contagion in COVID-19 care. A discrete choice experiment (DCE) will be conducted. A list of important attributes of COVID-19 medical options – including the possibility of disease exposure and cost – will be obtained from literature, clinical experts, and adults from the general public. The attributes will be used to generate DCE choice sets, which are included in a self-administered, web-based survey. A total of 500 adults with and without COVID-19 infection will be asked to respond to the survey. Statistical analysis based on Random Utility Theory will be used to determine the relative importance between all study attributes and cost. The willingness-to-pay for reducing the possibility of disease exposure will be calculated. Study findings will be applied for value assessments when dealing with not only COVID-19 care but also care for other infectious diseases. defined trial cohorts for generation of value evidence limit the generalizability applicability of the results to broader populations that may be treated in real-world practice. This study will provide important insights into the risk profile of a real-world population well as how it might differ from the risk profile of the clinical trial population, using the case study of the Diabetes Prevention Program (DPP) for individuals with prediabetes. The first-place team conducted an analysis of COVID-19 vaccine preferences among underrepresented populations. Using latent class analysis, the team built a model identifying key factors underlying the disparities in COVID-19 vaccination. They found that health care interventions intended to reduce health disparities that do not reflect the underlying values of individuals in underrepresented populations are unlikely to be successful. a two-pronged to increase the diversity of populations that participate in research and address drivers of health disparities to better inform value assessment. The first part of this strategy consisted of a comprehensive national campaign to inform, create buy-in, and generate excitement for participation in research. Following this, the researchers proposed an expediting of current methodological initiatives to require a minimum set of patient-reported social determinants of health elements to be collected and reported in research, including clinical trials and observational studies, as a way to enhance the information used in value assessment frameworks. Understanding predictors of the low accrual in older adult-specific clinical trials and demonstrating the value of such trials, when successful, can help overcome the underrepresentation of older adults in trials. Aim 1 of this study is to identify trial-level predictors for low accrual in older adult-specific trials. Using AACT data, I will develop prediction models for low accrual based on traditional and machine-learning approaches. Aim 2 of the study is to quantify the realized value of older adult-specific trials, the AVEX and CALGB9343 study. A retrospective analysis of Surveillance, Epidemiology, and End Results (SEER)-Medicare data will be used to estimate the change in practice after the trial publications. State transition models will be developed to estimate the long-term outcomes of treatment studied in the trials. The realized value will be calculated based on these two estimates. By assessing the feasibility and estimating the potential value of older adult-specific trials, this study will facilitate investment and design decisions by funders. therapeutic inertia. using real-world data to the evidence base for glycemic control and therapeutic inertia in people with type 2 diabetes. The public health significance of the is to optimize patients’ diabetes care and management across their lifetimes and mitigate the occurrence of subsequent diabetes-related complications. This study aims to 1) identify trajectories of medication adherence of chronic diseases treated with oral medications, and 2) distinguish the predisposing, enabling, need, and provider/care characteristics factors that determine trajectory membership using group-based trajectory modelling. Additionally, this study will investigate the association between adherence trajectories and economic and health outcomes. This association will be investigated by deploying two alternative predictive methods, one based on classic logistic regression and the other based on machine-learning algorithms. It is hoped that the findings of this study will elicit longitudinal medication adherence trajectories, the factors that determine trajectory membership, as well as establish optimal medication adherence trajectories based on the association with outcomes. Lastly, the conclusions of this study will allow health care professionals to identify patients at risk and payers to develop new value-based payments schemes based on medication adherence. Despite an increasing trend of neoadjuvant chemotherapy (NAC) use in breast cancer, evidence on benefits/risks of NAC — specifically in older women and within cancer subtypes – is limited, possibly contributing to the sizable variation in NAC use. This project aims to examine the effect of NAC versus adjuvant chemotherapy (AdC) alone on survival, health care utilization, and costs, in addition to assessing the temporal trends of NAC use and identifying factors related to NAC use among older women. The project will use the population-based Surveillance, Epidemiology, and End Results (SEER)-Medicare linked database to identify stage I-III breast-cancer patients. Subtype heterogeneity will be incorporated throughout, and propensity score matching is proposed to reduce bias. The research is expected to provide otherwise unavailable evidence on NAC in a large elderly population, which will inform patient-physician decision-making and ultimately improve clinical and economic outcomes. care of high-value is a major problem for older adults. Cognitive impairment (CI), including both mild cognitive impairment (MCI) and Alzheimer’s disease and related dementias (ADRD), is prevalent for older adults and likely affects HV and LV utilization. Patient harm and unnecessary costs of LV replacing HV care could be especially high and widespread in this vulnerable subpopulation, but these relationships have not been studied. The Centers (CMS) has called for value promotion, but policies cannot be adequately targeted and implemented without understanding the aforementioned relationships. Therefore, we propose to close this gap by identifying the association between CI and utilization of LV and HV care. Results will depict trajectories of utilization of relevant services for individuals at different stages of CI and inform policies to improve patient welfare and promote healthy aging. generic medications for infusion therapies, such as those used in oncology or neurology, and have great potential to lower prices and increase access to otherwise expensive treatments. The first aim of our research is to explore and examine key factors associated with coverage decisions regarding biosimilars that have been approved by the U.S. Food and Drug Administration (FDA) and have become available on the U.S. market, drawing on unique data provided by the Tufts Cost-Effectiveness Analysis Registry and the Specialty Drug Evidence and Coverage Database. Our second aim is to study the social welfare gain from biosimilar entry in the U.S. health care system. By using the SSR Health US Brand Rx Net Pricing data, we will estimate the additional number of patients receiving access to therapy following biosimilar entry, thus enabling us to quantify the extensive margin. We will use data on average net (post-rebate) pric",ASDC journal of dentistry for children,2013.0,10.1177/000313131306300202,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6e1f5f10d6670bb2ebd713ee3473cfcb295c18eb,https://www.semanticscholar.org/paper/6e1f5f10d6670bb2ebd713ee3473cfcb295c18eb,"Miniaturized wireless, skin-integrated sensor networks for quantifying full-body movement behaviors and vital signs in infants","Significance Early detection of infant neuromotor pathologies is critical for timely therapeutic interventions that rely on early-life neuroplasticity. Traditional assessments rely on subjective expert evaluations or specialized medical facilities, making them challenging to scale in remote and/or resource-constrained settings. The results presented here aim to democratize these evaluations using wireless networks of miniaturized, skin-integrated sensors that digitize movement behaviors and vital signs of infants in a cost-effective manner. The resulting data yield full-body motion reconstructions in the form of deidentified infant avatars, along with a range of important cardiopulmonary information. This technology approach enables rapid, routine evaluations of infants at any age via an engineering platform that has potential for use in nearly any setting across developed and developing countries alike. Early identification of atypical infant movement behaviors consistent with underlying neuromotor pathologies can expedite timely enrollment in therapeutic interventions that exploit inherent neuroplasticity to promote recovery. Traditional neuromotor assessments rely on qualitative evaluations performed by specially trained personnel, mostly available in tertiary medical centers or specialized facilities. Such approaches are high in cost, require geographic proximity to advanced healthcare resources, and yield mostly qualitative insight. This paper introduces a simple, low-cost alternative in the form of a technology customized for quantitatively capturing continuous, full-body kinematics of infants during free living conditions at home or in clinical settings while simultaneously recording essential vital signs data. The system consists of a wireless network of small, flexible inertial sensors placed at strategic locations across the body and operated in a wide-bandwidth and time-synchronized fashion. The data serve as the basis for reconstructing three-dimensional motions in avatar form without the need for video recordings and associated privacy concerns, for remote visual assessments by experts. These quantitative measurements can also be presented in graphical format and analyzed with machine-learning techniques, with potential to automate and systematize traditional motor assessments. Clinical implementations with infants at low and at elevated risks for atypical neuromotor development illustrates application of this system in quantitative and semiquantitative assessments of patterns of gross motor skills, along with body temperature, heart rate, and respiratory rate, from long-term and follow-up measurements over a 3-mo period following birth. The engineering aspects are compatible for scaled deployment, with the potential to improve health outcomes for children worldwide via early, pragmatic detection methods.",Proceedings of the National Academy of Sciences,2021.0,10.1073/pnas.2104925118,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aabb74bf88f742f0f0cb80a887ff3e1dc1b6b87a,https://www.semanticscholar.org/paper/aabb74bf88f742f0f0cb80a887ff3e1dc1b6b87a,An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence,,ICIOT,2021.0,10.1007/978-3-030-96068-1_1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
82030c891ac1d5e9d28ad484a57bf8cfada5b138,https://www.semanticscholar.org/paper/82030c891ac1d5e9d28ad484a57bf8cfada5b138,Enhancing behavioral sleep care with digital technology: study protocol for a hybrid type 3 implementation-effectiveness randomized trial,,Trials,2021.0,10.1186/s13063-020-04974-z,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7a0392ef4c607392de92ee1f7c84e68780e7976b,https://www.semanticscholar.org/paper/7a0392ef4c607392de92ee1f7c84e68780e7976b,"Cybersecurity, Data Privacy and Blockchain: A Review",,SN Comput. Sci.,2022.0,10.1007/s42979-022-01020-4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0ca2e97e9b09f0c5d723f8b9844eadb4a036af14,https://www.semanticscholar.org/paper/0ca2e97e9b09f0c5d723f8b9844eadb4a036af14,Life Cycle Assessment (LCA) of biogas and biomethan used in building energy systems,"the of a is disturbed. is by heavy valuable information that can be of assistance in reducing catastrophic losses. The objective of this study is to assess the vulnerability of different types of building structures to landslides. To accomplish the aim, it is first necessary to identify the multiple factors related to landslides, to evaluate the related contribution of the factors causing slope failures, to establish a relationship between the factors and the landslides. Secondly, based on the previously defined parameters and existing methodologies it is required to develop a general methodology for assessing the vulnerability of predefined types of building structures. and is clarify the the procedures and the model that will be used to design shot -earth reinforced structures. A second aim of this project is to control if and how the water uptake might influene the strength of the material. The project includes laboratory test on cement pastes and mortars with techniques such as isothermal calorimetry and rheolometer. This internship will be conducted in the framework of “HISTO-RENO” a European research project funded by the Interreg France-Switzerland fund. This project aims to develop a web-based simplified energy pre-audit tool to guide the building owner in their energy-related renovation. The goal of this internship is to derive statistical distributions on the input parameters (U-values, surface area of the main elements: external walls, roof, slab, windows, etc.) of the building heating demand of the current Swiss building stock with the help of the information of individual buildings in the Building energy certificate database (EPC), called “CECB” in Switzerland. The methodology of the analysis will be based on the previous work from Streicher et al 2018. The statistical analysis on the heating demand parameters will then serve to define probability density function (PDF) as input for a stochastic simplified energy audit tool used in a preliminary step of a renovation process indicating the estimates in kWh, carbon footprint and costs of a set of renovation measures. The Laboratory of Solar thermal Energy and Building Physics (LESBAT) from HEIG-VD has been funded by the Interreg France-Keywords: this topic, the minimum duration of this internship is 4 months (preferably 6 months). Proven knowledge in numerical and scientific programming tools like Python or R is required in order to successfully achieve the goals of this internship. analyse, 2) in the literature review of existing LCA of biogas and biomethan in order to get a range of carbon footprint for a unit of biogas/biomethan, 3) in the LCA of the heat and/or electricity produced with the technologies selected and 4) in the comparative LCA of heat production with other technologies (e.g. electric-based air-to-water heat pump) or electricity production in micro-CHP comparing biogas/biomethan solutions with electricity ones (using electricity from the grid). The data used for the carbon footprint of the Swiss electricity mix will be based on the ones available at HEIG-VD. in numerical and programming tools like duration 4 months, preferentially 6 months. Environmental alterations trigger changes in the underlying plant physiological processes portrayed by distinct variations of the electrical potential. Advanced signal processing and data analysis techniques enabled an automatic recognition of patterns in the electrical response of plants growing under typical production conditions allowing the identification of a plant's health status with high accuracy. However, current developments are based on classical machine learning algorithms requiring the extraction of features from the signal. The proposed project aims to extend the existing modeling approach by developing a classification framework that will extract features in an automated manner, such as applying deep-learning-based algorithms. system based on machine Commercial orchards are increasingly dependent on proper irrigation to ensure the highest yields and optimize production quality. Still, current monitoring tools need greater accuracy that could be achieved by incorporating indicators based directly on the plants. Moreover, tomatoes show difficulty adapting to the water and nutritional contributions provided by automatic systems in the greenhouses, resulting in physiological damage of the fruit, such as skin “cracking” leading to important yield losses. The main objective of the project is to model the growth of the fruits by using intelligent data analysis techniques on data from fruit dendrometer and micro-climate measurements in combination with the expertise of agronomists, to provide a tool for fruit growers that would help them predict physiological damage of the fruits and improve the quality of the crops, while optimizing harvest timing and reducing water usage. is spermatozoa morphology is one of the fundamental parameters for evaluating sperm quality. Evaluation of the morphology from microscopic sperm images could help reduce the required time and the observer-based variability of the manual analysis currently used as a clinical gold standard. Moreover, morphological abnormalities represent various forms and shapes on different cell parts, making classification a challenging task. This project aims to use image processing and machine learning algorithms on spermatozoa images to automatically distinguish abnormal from normal cells and classify different abnormal sperm morphology. to use advanced signal processing and machine learning algorithms on ECG signals to model patterns that identify and automatically discriminate different heart anomalies represented by the ECG curves. the of a kid's survival. to study, design, implement and evaluate a secure geolocation solution for mobiles. Today, geolocation on smartphones is mainly achieved through GNSS, Wi-Fi positioning, or BLE beacons. Still, none offer a strong guarantee as they can be unavailable or spoofable. After completing a state-of-the-art of existing technologies and their availability on mobile platforms, the trainee will propose a solution and realize a PoC. Several approaches are possible to realize this project; one possibility is the design of a BLE beacon integrating cryptographic features. Deep neural networks have shown to be very good at image classification and object recognition tasks. The objective of this project is to train a custom system to process and analyze satellite images (both from day and night). To achieve this, we will take advantage of pretrained models provided by the major actors in the domain and proceed to fine-tune them with our own data. Potential applications include, forest monitoring, population growth analyses, socio-economic issues, etc. For more information: http://iict-space.heig-vd.ch/ape The increasing availability of wearable sensors embedded in smartphones, watches and physical activity trackers has open the door to original applications, mainly in health and wellness improvement. One typically collects data by means of sensors like GPS, accelerometers, gyroscopes, barometers, microphones, cameras, depth sensors, etc. To make sense of these data, Machine learning algorithms can be used to establish correlations among the variables under investigation, and as in every attempt to understand high-dimensional data, visualization and dimensionality reduction techniques can suggest new knowledge about the aspects of the person's life being monitored. The objective of this project is to deal with diverse application domains including self-tracking of physical activity, self-tracking and characterization of style and performance in sport (e.g., racket sports, running), daily-life logging , or 24/7 self-monitoring as a means to enhace our wellbeing. more information: http://iict-space.heig-vd.ch/ape such robots more human-like with the aim of increasing our trust in them. For more For the conception phase, you’ll have to create wireframe of user interface. MEI can help with this phase. The development expected is a proof of concept for the fullstack. of law imposes new specialized hardware solutions to serve the increasing computing demand. System composed by several domain specific accelerators are available, but from the system integration and programming point of view they rely on custom solutions. The idea of this project is exploring the state of the art in compiler infrastructure for heterogeneous hardware and implement a prototype to measure real benefit and compromises of these solutions. Several research project have already been carried out in our laboratory on this subject. in we the and this will on extending its functionalities and benchmark it extensively. Data centres demand more and more computation efficiency. Standard CPU are unable to cope with the demand and GPU can only serve specific computation patterns. FPGAs are an attractive technology in this field, but its integration in the data centre infrastructure is not trivial. Smart Network interface (NICs) solutions are attractive for offloading many filtering and computation directly at the network attachment point relieving the CPU of many tasks. This project will explore the state of the art in the domain with the aim at developing a prototype capable to off-load tasks to an FPGA. management between edge and cloud. To maximize performance and minimize the energy consumption of both edge devices and cloud platforms, there is a need to develop efficient resource management techniques able to take workload allocation decisions, on when and where to execute the workload, in the edge to cloud continuum in an elastic way. To exploit elasticity, these techniques need to be aware of the underlying hardware and software stack, which often consist on a lightweight virtualization (like containers) deployed on ARM or RISC-V based edge devices. This project proposes the design of heuristic and meta-heuristic based workload m",,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
849d470245aed80394124dc54f1ebaf30e854a81,https://www.semanticscholar.org/paper/849d470245aed80394124dc54f1ebaf30e854a81,Security as a Solution: An Intrusion Detection System Using a Neural Network for IoT Enabled Healthcare Ecosystem,"Aim/Purpose The primary purpose of this study is to provide a cost-effective and artificial intelligence enabled security solution for IoT enabled healthcare ecosystem. It helps to implement, improve, and add new attributes to healthcare services. The paper aims to develop a method based on an artificial neural network technique to predict suspicious devices based on bandwidth usage. Background COVID has made it mandatory to make medical services available online to every remote place. However, services in the healthcare ecosystem require fast, uninterrupted facilities while securing the data flowing through them. The solution in this paper addresses both the security and uninterrupted services issue. This paper proposes a neural network based solution to detect and disable suspicious devices without interrupting critical and life-saving services. Methodology This paper is an advancement on our previous research, where we performed manual knowledge-based intrusion detection. In this research, all the experiments were executed in the healthcare domain. The mobility pattern of the devices was divided into six parts, and each one is assigned a dedicated slice. The security module regularly monitored all the clients connected to slices, and machine learning was used to detect and disable the problematic or suspicious devices. We have used MATLAB’s neural network to train the dataset and automatically detect and disable suspicious devices. The different network architectures and different training algorithms (Levenberg–Marquardt and Bayesian Framework) in MATLAB software have attempted to achieve more precise values with different properties. Five iterations of training were executed and compared to get the best result of R=99971. We configured the application to handle the four most applicable use cases. We also performed an experimental application simulation for the assessment and validation of predictions. Contribution This paper provides a security solution for the IoT enabled healthcare system. The architectures discussed suggest an end-to-end solution on the sliced network. Efficient use of artificial neural networks detects and block suspicious devices. Moreover, the solution can be modified, configured and deployed in many other ecosystems like home automation. Findings This simulation is a subset of the more extensive simulation previously performed on the sliced network to enhance its security. This paper trained the data using a neural network to make the application intelligent and robust. This enhancement helps detect suspicious devices and isolate them before any harm is caused on the network. The solution works both for an intrusion detection and prevention system by detecting and blocking them from using network resources. The result concludes that using multiple hidden layers and a non-linear transfer function, logsig improved the learning and results. Recommendations Everything from offices, schools, colleges, and e-consultation is currently for Practitioners happening remotely. It has caused extensive pressure on the network where the data flowing through it has increased multifold. Therefore, it becomes our joint responsibility to provide a cost-effective and sustainable security solution for IoT enabled healthcare services. Practitioners can efficiently use this affordable solution compared to the expensive security options available in the commercial market and deploy it over a sliced network. The solution can be implemented by NGOs and federal governments to provide secure and affordable healthcare monitoring services to patients in remote locations. Recommendations Research can take this solution to the next level by integrating artificial intellifor Researchers gence into all the modules. They can augment this solution by making it compatible with the federal government’s data privacy laws. Authentication and encryption modules can be integrated to enhance it further. Impact on Society COVID has given massive exposure to the healthcare sector since last year. With everything online, data ecurity and privacy is the next most significant concern. This research can be of great support to those working for the security of health care services. This paper provides “Security as a Solution”, which can enhance the security of an otherwise less secure ecosystem. The healthcare use cases discussed in this paper address the most common security issues in the IoT enabled healthcare ecosystem. Future Research We can enhance this application by including data privacy modules like authentication and authorisation, data encryption and help to abide by the federal privacy laws. In addition, machine learning and artificial intelligence can be extended to other modules of this application. Moreover, this experiment can be easily applicable to many other domains like e-homes, e-offices and many others. For example, e-homes can have devices like kitchen equipment, rooms, dining, cars, bicycles, and smartwatches. Therefore, one can use this application to monitor these devices and detect any suspicious activity. © 2021 Informing Science Institute. All rights reserved.",,2021.0,10.28945/4838,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8e2db36fc1de5c190338627c50d4d82cda5e664f,https://www.semanticscholar.org/paper/8e2db36fc1de5c190338627c50d4d82cda5e664f,Computational Models & Methods in Systems,"With the current emphasis on ‘big data’ marking a new stage in the advance of biomedical sciences, improvements in computational capability, together with the impact of high throughput techniques and genome-wide methods, mean that biological and medical fields are now data-rich to a degree that was unknown a few decades ago. Increased data availability has not only highlighted the complementarity needed between biology and computer science, but has served to emphasise interdisciplinary overlap with mathematical and physical sciences in the formulation of computational models, posing of hypotheses and statistical interpretation of results. Information derived from diverse sources means that linking system behaviour to changes at cellular and molecular scales has become a viable goal, facilitated by techniques such as network theory, stochastic processes and integrative data analysis. The studies of systems of biological components, their dynamic behaviour and reliance on wide-ranging data, together with translation to disease progression and treatment options, define systems biology and medicine. The IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM) is a well-established research conference, providing a leading forum for disseminating the latest research in bioinformatics and health informatics. It attracts contributions from both academic and industrial scientists, which range from biology and medicine, to chemistry, computer science, mathematics and statistics. In particular, and in addition to its over-arching remit and general proceedings, IEEE BIBM provides an important platform for showcasing computational and mathematical modelling methods, together with the data integration, analysis and visualisation, which underpin these. Selected and extended papers from several of their important workshops thus provide the focus of this Special Issue. The papers deal with basic model formulation, data analysis and the incorporation of these analyses in the decision-making process for clinical treatment. The algorithms and methods include ant colony optimisation (Sapin et al.) of the interactions between a number of single-nucleotide polymorphisms (SNPs). Discriminatory performance of the algorithm is found to agree well with SNP identification from large-scale genome-wide association studies for Type II diabetes. Medical image analysis is the objective for applying both evolutionary and swarm intelligence algorithms. In the former case, data classification and monitoring in Parkinson’s disease in humans is considered, together with characterisation of genetic mutations in the fruit fly vector (Smith et al.). Deployment of swarm intelligence algorithms, such as stochastic diffusion search for CT scans and X-Rays, and learning vector quantisation for identification of abnormal tumour regions in MR segmentation (al-Rifaie et al.), also demonstrate the applicability of these methods. Wong-Lin & Cullen explore the importance of dopamine as a neurotransmitter for multiple brain functions using a computational model that spans multiple levels of function and different dynamics, and lay the foundation for an integrated approach to realistic in silico simulation of dopaminergic systems in neuropharmacology. Investigation, similarly, of the relative dynamics and structure of human intestinal crypts in malignant systems, provides the motivation for the formulation of an epigenetic model using the agent-based paradigm (Roznovat & Ruskin). Epigenetics, the additional layer of inherited genome regulation, together with epigenome-wide association studies, linking intra-individual epigenetic variation, are linked to the evolution of human diseases, such as cancer, and to autoimmune and neuropsychiatric disorders. The derived computational model enables comparative analysis on aberrant DNA methylation levels in cancer development and the investigation of the effect of potential methylation inhibitors during disease initiation. Inhibitors, both time-dependent and time-independent, merit important distinction in the characterisation of compound potency and drug-response. Reversibility properties for both are investigated by means of a simple kinetic model (Yue & You) and analysis of the outcomes and their contrast with supporting numerical studies. The complexity of the drug-receptor process in this case indicates the contribution that can be made by computational modelling, as well as the need to support formulation and parameterisation with good quality data. A further example of the flexibility and scope offered by the modelling approach is provided by studies of microtubule ordering and the way in which this is affected by collision and crossover. A 3-state model is used to determine the influence of spontaneous catastrophe, crossover and ketaninmediated severing on plant microtubule ordering across different temperatures (Mace & Wang). It is evident, however, that, while many dynamic biological systems share similar properties and constraints, model specification, particularly in the context of sparse or poor experimental data, is often anything but straightforward. Achieving an unambiguous estimation of the full set of parameters is frequently challenging and may be impossible. The identifiability in this context, of typical S-System models for dynamic biological systems, is discussed with respect to an application on yeast fermentation pathway determination (Li et al.). The authors note also that, even where data are available, these may be noisy or incomplete, which also affects the identification process. When analysing such data, a range of statistical and computational methods are available. These can be categorised by their level of automation, the sophistication of their algorithms, their data type and size and so on. Bioinformatics, often described as the intersection of mathematics, biology and computer science, typically involves processing large amounts of data, so methods are usually machine-based. The paper (by Akutekwe et al.) thus describes a two-stage optimisation process in the modelling of protein-protein networks. This is applied to complex diseases, such as colorectal cancer, and discusses the performance of machine learning methods and selected algorithms, such as particle swarm optimisation and differential evolution for parameter optimisation for classification and automatic discovery of biomarkers, with Bayesian network analysis used to predict their temporal linkage. Ultimately, systems modelling and simulation-optimisation, with appropriate data analysis, can play a major role in decision-support systems for biomedical applications. The Heartsearcher for patient risk classification is proposed by Park & Kang, while Bansal et al. describe a cardiac monitoring system which uses ECG signal analysis and pattern recognition provided through a mobile device, a remote server, and medical practitioner point-of-care communication. Evidently, the use of computational models and methods is widespread in Systems Biology and Medicine and, as datasets grow in size and complexity, biomedical systems increase in sophistication, and computing power escalates, this trend looks set to continue.",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2b1f7e138febec0debe2f004727742a431f26a38,https://www.semanticscholar.org/paper/2b1f7e138febec0debe2f004727742a431f26a38,EarlyScreen: Multi-scale Instance Fusion for Predicting Neural Activation and Psychopathology in Preschool Children,"Emotion dysregulation in early childhood is known to be associated with a higher risk of several psychopathological conditions, such as ADHD and mood and anxiety disorders. In developmental neuroscience research, emotion dysregulation is characterized by low neural activation in the prefrontal cortex during frustration. In this work, we report on an exploratory study with 94 participants aged 3.5 to 5 years, investigating whether behavioral measures automatically extracted from facial videos can predict frustration-related neural activation and differentiate between low- and high-risk individuals. We propose a novel multi-scale instance fusion framework to develop EarlyScreen – a set of classifiers trained on behavioral markers during emotion regulation. Our model successfully predicts activation levels in the prefrontal cortex with an area under the receiver operating characteristic (ROC) curve of 0.85, which is on par with widely-used clinical assessment tools. Further, we classify clinical and non-clinical subjects based on their psychopathological risk with an area under the ROC curve of 0.80. Our model’s predictions are consistent with standardized psychometric assessment scales, supporting its applicability as a screening procedure for emotion regulation-related psychopathological disorders. To the best of our knowledge, EarlyScreen is the first work to use automatically extracted behavioral features to characterize both neural activity and the diagnostic status of emotion regulation-related disorders in young children. We present insights from mental health professionals supporting the utility of EarlyScreen and discuss considerations for its subsequent deployment. CCS Concepts: • Human-centered computing → Ubiquitous and mobile computing systems and tools ; • Computing methodologies → Machine learning ; • Applied computing → Psychology Health informatics . Multi-scale Neural Psychopathology",Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2022.0,10.1145/3534583,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
551f1a035d3707f6ecc9e608509e7191749fd03a,https://www.semanticscholar.org/paper/551f1a035d3707f6ecc9e608509e7191749fd03a,Therapeutic Innovations in Neuroscience: What’s New on the Horizon?,"The theme of this issue of Clinical Pharmacology & Therapeutics (CPT) encompasses neuroscience in the broad sense to include neurology and psychiatry, nonclinical and clinical aspects, novel clinical trial methodologies, and modeling and simulation approaches applicable to central nervous system (CNS) drug development and therapy. While naturally the last two years have been dominated by coronavirus disease 2019 (COVID19), it is important not to forget that drug development for other indications has not been stopped, albeit many trials were affected in terms of delays in recruitment and collection of clinical data. There are numerous rare to ultrarare neurological diseases in which the very limited number of patients, combined with the lack of reliable biomarkers and targeted therapies, pose a real challenge for traditional drug development, including appropriate dosefinding studies. Abuasal et al. discuss the role of regulatory flexibility in the approval of new drugs and give examples from US Food and Drug Administration (FDA) scientific assessment and conclusions based on a relatively limited data set, using modeling and simulation to select the optimal dose, extrapolation among populations, or pharmacodynamic biomarkers. The authors also provide an optimistic outlook into the future regarding the expected role of quantitative systems pharmacology, artificial intelligence, and machine learning, as well as disease progression models using realworld data (Figure 1). Stephenson et al. discuss whether and how innovative trial designs and technologies, including multiarm adaptive platform designs and digital health tools to monitor progression in rare diseases like Duchenne muscular dystrophy and amyotrophic lateral sclerosis (ALS), can drive the advancement of treatments for common neurological diseases like Parkinson’s disease. At the same time, the authors provide an excellent insight into the importance of collaborative efforts: Novel platforms containing data from completed clinical trials, registries, natural history studies, and preclinical data do not only foster data sharing but also provide a means of connectivity to sophisticated tools like disease progression models and clinical trial simulation applications. Clinical trials in neuroscience are frequently challenged by the extensive heterogeneity between patients and their survival and a nonnegligible number of patients dying during the course of a clinical trial, particularly in rapidly progressive diseases like ALS. Van Eijk et al. present an overview of commonly used strategies to address death in efficacy end points for clinical trials, which may have implications for the interpretation of the study results. Exemplified by clinical trials in ALS, their review provides guidance to define the exact research question of a trial, to align its objectives with the study design, including",Clinical pharmacology and therapeutics,2022.0,10.1002/cpt.2547,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8bdec1dca2b54402ad431c2dfbbbb005c7ba7ac,https://www.semanticscholar.org/paper/c8bdec1dca2b54402ad431c2dfbbbb005c7ba7ac,"AS&T virtual collection: Toxicity of ambient particulate matter – impact of chemical composition, emission sources and atmospheric processes","An increasing number of studies in recent years have linked ambient particulate matter (PM) to diseases such as asthma (Fan et al. 2016), myocardial infarction (Madrigano et al. 2013), stroke (O’Donnell et al. 2011) and even Alzheimer’s (Shou et al. 2019). There have also been several epidemiological studies that predict a surge in global disease burden and mortality in the near future if the present trend in rising PM emissions continues (Burnett et al. 2018; Li et al. 2019; Apte et al. 2015). Most of these models use PM mass as a metric although a few complex models also include some of the key chemical species present in PM such as metals and organic compounds (Heo et al. 2014; Wang et al. 2022). However, these models still ignore the complexity of PM chemical composition, which is influenced not only by heterogeneous emission sources of PM but also by atmospheric processes (R€ onkk€ o et al. 2018). Moreover, these models ignore the interactions among various chemical components of PM which can alter the overall toxicity of PM as obtained by the simple summation of individual toxicities (Yu et al. 2018; Wang et al. 2020). Thus, the notion that higher PM mass implies higher mortality or prevalence of diseases is not completely true. It is clear that there is a necessity to search for alternative metric(s) than PM mass to represent PM toxicity in epidemiological models, which in turn requires clarity on the exact mechanisms underlying PM toxicity. Currently, some progress has been made in this regard in the past two decades and it has indicated that PM sources, atmospheric processes, chemical composition and pathology of diseases share a complex relationship with each other. Investigations for linking the PM toxicity with chemical composition have often shown varied and sometimes contradictory results and presently face several issues that need attention. For example, the traditional toxicity characterization methods are labor-intensive and time-consuming, and therefore, only a limited number of samples can be analyzed for the toxicity evaluation. Furthermore, there is also a range of toxicity endpoints that one could choose from, which has often led to debate on whether or not a single endpoint could adequately represent PM toxicity. Recently, oxidative potential (OP) has emerged as a proxy for PM toxicity, although currently there is a lack of consensus regarding the most appropriate method to measure PM OP (Yu, Puthussery, and Verma 2020). Moreover, there is a lack of standard protocols for the procedures of PM collection, extraction and exposure to lung cells, although these factors have been shown to heavily influence results (Daher et al. 2011), making comparison among different studies difficult. Overcoming the hurdles described in the previous paragraph would better equip us to answer some important questions that can be addressed by the aerosol community, and this is possible through focused research into certain areas. These include the development of methodologies that can better mimic physiological processes in the human body, leading to a more accurate assessment of the health impacts. Design of simple, inexpensive and high throughput methods to evaluate PM toxicity is needed to generate large datasets that can be incorporated into epidemiological models. Development of real-time instruments for field deployment could also greatly expand our capabilities to generate such large datasets. Investigations into spatiotemporal variations in PM toxicity and their correlations with chemical composition could refine our understanding of the role of emission sources and atmospheric processing in influencing PM toxicity. Such studies could also lead to development of machine learning based models to make predictions in data-sparse regions. Another research area that requires immediate attention is the interaction between various chemical components and their role in altering the overall toxicity of PM. Currently, little work has been undertaken in this area and, except for preliminary information regarding the interaction among a few prominent species, not much is known. We have collated a selection of articles published by AS&T to form a Virtual Collection as an attempt to highlight the efforts made by aerosol researchers so far to answer the questions posed here, addressing issues vital to further our understanding of PM toxicity. For example, Landreman et al. (2008) developed an assay to measure the PM OP in alveolar macrophages subjected to short-term exposure. This assay has been widely used in PM studies revealing important information regarding the spatiotemporal variations in OP. Yu, Puthussery, and Verma (2020) developed an instrument for measuring five commonly used OP endpoints to provide a rapid and comprehensive assessment of PM OP of a large number of PM samples. Such large-scale studies are necessary for understanding the relationship between",Aerosol Science and Technology,2022.0,10.1080/02786826.2022.2051960,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
924420707edd1e75b735b577b7dc4ff2a2cf1932,https://www.semanticscholar.org/paper/924420707edd1e75b735b577b7dc4ff2a2cf1932,Cybertrust: From Explainable to Actionable and Interpretable AI (AI2),"To benefit from AI advances, users and operators of AI systems must have reason to trust it. Trust arises from multiple interactions, where predictable and desirable behavior is reinforced over time. Providing the system’s users with some understanding of AI operations can support predictability, but forcing AI to explain itself risks constraining AI capabilities to only those reconcilable with human cognition. We argue that AI systems should be designed with features that build trust by bringing decision-analytic perspectives and formal tools into AI. Instead of trying to achieve explainable AI, we should develop interpretable and actionable AI. Actionable and Interpretable AI (AI2) will incorporate explicit quantifications and visualizations of user confidence in AI recommendations. In doing so, it will allow examining and testing of AI system predictions to establish a basis for trust in the systems’ decision making and ensure broad benefits from deploying and advancing its computational capabilities. Decision Making: Humans and Artificial Intelligence (AI) “Can I trust the recommendation of an AI agent?” This question is difficult to answer, especially if the decision at stake is complex and spans different spatial and temporal scales. Such difficulty is exacerbated when the outcomes of an AI-influenced decision may heighten existing risks to humans or introduce new risks altogether. Yet such high-stakes situations have become routine within the diverse systems that currently incorporate AI, like controls for chemical plants, defense systems, and health insurance rate determinations. Stakeholders must be prepared not only to configure AI and its enabling technologies for a given industry or activity, but also to have tools and methodologies to examine and recognize its failures, limitations, and needs for quality control at various stages of its development and implementation. The ultimate goal of AI is to provide users with actionable recommendations that meet both implicit and explicit goals of the decision makers and stakeholders. Recommendations generated from AI-based This is a preprint version of the paper by Igor Linkov, Stephanie Galaitsi, Benjamin D. Trump, Jeffrey M. Keisler, and Alexander Kott, ""Cybertrust: From Explainable to Actionable and Interpretable Artificial Intelligence,"" IEEE Computer, Sept. 2020, pp. 91-96, vol. 53 DOI Bookmark: 10.1109/MC.2020.2993623 ................................. approaches hold advantages over human decision makers through their ability to analyze vast bodies of information in limited time in an objective and logic-centered fashion. In many situations, these benefits are clear and already implemented in practice, such as machine learning systems for the detection of phishing attempts [Khonji et al. 2013]. AI applications are also capable of providing multistep and adaptable strategies, as demonstrated by programs that compete in chess or Go, as well as AI-based cybersecurity systems [Al-Shaer et al. 2019; Kott et al. 2019] However, AI recommendations may not account for decision maker values or specific mission needs. For example, following a cyberattack, an AI-generated decision engine may recommend disabling an application on the compromised computer system. Such an action may neutralize the threat posed by the compromised system, but could simultaneous endanger a mission, negatively impact a critical user, or enable the adversary to extend the duration or scope of the cyberattack. The broader scale impacts of the recommended path forward may not have been incorporated into the AI’s design or scope, causing the AI decision processes to omit critical conditions that a human operator would implicitly account for. Such incomplete scoping of AI-driven analysis is especially problematic when unspoken, unacknowledged, or subjective variables influence or shape what a successful outcome looks like. For example, an AI system may not account for the need for a particular asset to be available to achieve a mission later on, or for psychological impact on the system’s users. The AI solves the problem it is given, but it the human’s role to ensure the recommendation’s suitability in context. Similarly, the human users making this judgment will benefit from understanding the factors that produced the AI’s decision, especially when that understanding helps the users see the value of factors they themselves could have overlooked. While AI-driven analysis enhances our decision making ability, providing insight into AI’s shifts in its analysis of needs, expectations, and mission requirements will ensure its decisions’ relevance and credibility and make its expectations for the future explicit. If AI’s analytical outputs do not account for these and other broader and potentially subjective concerns, an overly myopic focus upon a tactical decision can derail strategic mission requirements. As such, a more effective deployment of AI into decision making must resolve the ‘black box’ concerns of AI – in that it is unclear how to explain, interpret, or act upon AI’s conclusions as its underlying algorithm and parameters are difficult to decipher. Inevitable Disagreements: The Challenge of Fusing Human and AI Decision Making Capabilities We can expect AI recommendations to differ, in some percentage of circumstances, from the choice the operator alone would have made. There are three possibilities on how this plays out for any yes/no decision: the AI is more risk-averse than the human, the AI is more risk-tolerant than the human, or the AI and the human agree (Table 1).",ArXiv,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9b277ae33c0b04a8cabb6c8fc5bc072afd275cbd,https://www.semanticscholar.org/paper/9b277ae33c0b04a8cabb6c8fc5bc072afd275cbd,COVID Choices: Research and Online System for Main Street Decision Making,"During the spring of 2020 ChoiceFlows Inc. (Choiceflows) researchers document an approach for small and medium-sized businesses to make informed decisions about equitable and resilient reopening after COVID-19 pandemic shutdowns and restrictions. The client is 501(c)(3) chartered Restart Partners in Washington State and their client, the State of Washington Department of Commerce. After several revisions, an agreement is signed on December 30, 2020 to make the approach real with development and deployment in 2021 using Cares Act Grant money from the U.S. Federal Government. The result is Smart WA – and can be freely accessed online here: https://smartwa.us Smart WA is the result of unique primary research conducted by Choiceflows involving citizens and residents of Washington State, and many days of secondary research finding publicly available data sources and bringing them together in one place to provide both comprehensive and easier to use data to make informed decisions. The research behind Smart WA is the first study to comprehensively examine how specific COVID-19 transmission reduction actions influence planned visits to different types of businesses. Data on Smart WA is organized by Human Health, Economic Health, and Community Experience metrics – and displayed as composite scores. The entire online system is powered by Tanjo.ai machine learning, a Choiceflows business partner, and is updated from all data sources daily.The advent of the COVID pandemic disrupts a wide range of businesses that directly serve the public and causes a dramatic fall in visits to these establishments. Businesses face a wide range of options in how to respond ranging from the pre-pandemic status quo and doing nothing to prevent the spread of the virus to shutting down businesses due to a lack of customers.Recognizing this, Smart WA has a “what-if” game-like section that allows a business to model the choices that they can make for reopening, and what they can expect from customers based on real data from people in the state. The relevant question from a small business perspective is: If we take an action or actions that influence COVID-19 transmission and make it known to our customers, how will that influence those customers to visit? The research supporting this function was conducted in four waves of surveys designed and administered during 2021, making it one of the most comprehensive research programs of its type during COVID with snapshots of customer preferences being collected over several month intervals.We document the development of this COVID Choices research using the Choiceflows pioneered Volumetric Choice Experiment (VCE) method and design and in parallel the online system. This provides a platform for projecting how the insights and methods from this work can be used for other issues facing small and medium size businesses to aid in and speed decision making and choice. This includes and dashboards for policymakers and main street for allocating resources for commerce, including economic development, ongoing community health, and supporting quality of life indicators.",Global Issues: Disease Control and Pandemic Prevention,2022.0,10.54941/ahfe1001361,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b0ed25630d66d052bff2a9218d141a24b19e4d68,https://www.semanticscholar.org/paper/b0ed25630d66d052bff2a9218d141a24b19e4d68,THE BENEFITS OF APPLYING AI TO COMPRESSION,"Artificial intelligence (AI) is a popular subject today. Currently used across various verticals, from medicine to autonomous vehicles and finance, it is projected to have a significant impact. Today, AI is used for video compression, not just to provide bitrate savings but also to improve the quality of experience (QoE) and savings in processing power. This paper will present three applications of AI for video compression, explaining how each helps with the delivery of video content over broadcast and OTT networks. The applications that will be examined include Dynamic Encoding Style (DES), which enables a better trade-off between video quality and bitrate; Dynamic Resolution Encoding (DRE), which enables a superior QoE and density; and Dynamic Frame Rate Encoding (DFE), which allows for improved density and QoE. After a brief presentation of the methods, the paper will then present the results of implementing these technologies in the real world. INTRODUCTION Video compression for broadcast TV services started more than 20 years ago. Over time, several key improvements, such as dual-pass, statistical multiplexing, and software migration, were made to compression technology in order to boost performance. Artificial Intelligence (AI) is driving the next frontier of video compression enhancements. AI is effective at detecting objects and at surveillance. Machines are capable of detecting cancer cells with excellent accuracy, which can be a great help for medical doctors (1, 2). AI algorithms can also be useful at processing a lot of data. Some companies use it to clean large data sets, an activity called data wrangling. More and more, AI can be used for decision-making. The autonomous vehicle collapses many of these uses. Indeed, detection is important in an autonomous car, as other vehicles, persons, objects, and signs on the road need to be clearly identified along with their motion. Together with the internals of the car, it becomes a lot of data to process. The autonomous car has to constantly make decisions about the speed, direction, signaling, and more. In other terms, AI is very effective at predictions (3). More details on the evolution from human-designed algorithm to using AI for live video compression can be found in (10). In the VOD encoding domain, Netflix has been the pioneer in developing an AI-based system to assist file encoding, known as per-title or per-chunk encoding (4). Those techniques only apply to offline encoding and cannot be used for live video. This paper presents three examples of AI applied to live video encoding to optimize broadcast and OTT content delivery. The first three sections present the three examples. For each example, the paper presents a brief presentation of the methods followed by the results, including real-life effects. In this paper, both “AI” and “machine learning” expressions are used, knowing that machine learning is, in fact, a part of AI. DYNAMIC ENCODING STYLE (DES) OR CONTENT-AWARE ENCODING (CAE) FOR BITRATE SAVINGS In this first application, the video compression algorithm itself has improved thanks to machine learning technology. The goal is to improve the video quality/bitrate trade-off, meaning reducing the bitrate while maintaining the video quality or keeping a bitrate and improving the video quality. This is done by the means of encoding styles. Encoding styles are compression algorithm configurations well-suited for particular content. Results DES has been thoroughly tested across a lot of material, and it has shown a bitrate reduction vs. deployed system from 20% up to 30% on VBR content in broadcast applications, and 35% on average up to 50% compared with CBR for streaming applications. Table 1 shows the comparison of the AI-based algorithm with the deployed solution for a customer’s use case. The AI-based algorithm is run at different lower bitrates compared with the deployed solution, from 10% to 30% lower. At 10% the AI-based algorithm is better, at 20% it is equal and at 30% it is worse. The last two columns provide a comparison of lowering the bitrate for both algorithms for verification purposes. The conclusion is that the AI-based algorithm provides a 20% gain. Prog Channel AI version Pool bitrate -10% AI version Pool bitrate -20% AI version Pool bitrate -30% Both versions Pool bitrate -10% Both versions Pool bitrate -20% 1 Documentary = AI slightly lower AI lower AI better AI better 2 Cartoon = = AI lower = = 3 General Entertainment = = AI lower = AI slightly better 4 Movie = = AI slightly lower = AI slightly better 5 Sport AI better = AI lower AI better AI better 6 High action shows AI better AI slightly better = AI better AI better Table 1 – Video quality comparison on different channels between deployed and AI-based algorithm DES and CAE have been deployed in many streaming situations, with some examples and results shown below. The first example is a large streaming service with more than 1 million subscribers and more than 50 channels. This service supports live, VOD, cloud DVR, time-shift and serverside dynamic ad insertion. Due to the COVID-19 global health crisis, the service provider observed a dramatic increase in the bandwidth use and needed a solution to relieve the pressure without changing its infrastructure. By turning on DES and CAE the service provider saw significant improvements on their network. The backbone traffic was reduced by 50%, and the CDN peak usage was reduced by 30%. Figure 1 shows the backbone traffic reduction after DES/CAE was activated. Figure 1 Backbone traffic reduction thanks to DES and CAE The second example involves a large European streaming provider. The measurements were also made during the lockdown period due to COVID-19. In this example we show the average bitrate variation between normal compression and with DES/CAE turned on. For sports content, a bitrate reduction of 30% was measured, and for studio content a bitrate reduction of 40% was observed. Studio content includes television programs, such as talk shows and games shows. Figure 2 Studio content average bitrate reduction thanks to DES/CAE DES/CAE Activated",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4d6428da0d99ba07cf26d5ee481b9b4accb4e9d3,https://www.semanticscholar.org/paper/4d6428da0d99ba07cf26d5ee481b9b4accb4e9d3,"Building a Shared, Scalable, and Sustainable Source for the Problem-Oriented Medical Record: Developmental Study","Background Since the creation of the problem-oriented medical record, the building of problem lists has been the focus of many studies. To date, this issue is not well resolved, and building an appropriate contextualized problem list is still a challenge. Objective This paper aims to present the process of building a shared multipurpose common problem list at the Geneva University Hospitals. This list aims to bridge the gap between clinicians’ language expressed in free text and secondary uses requiring structured information. Methods We focused on the needs of clinicians by building a list of uniquely identified expressions to support their daily activities. In the second stage, these expressions were connected to additional information to build a complex graph of information. A list of 45,946 expressions manually extracted from clinical documents was manually curated and encoded in multiple semantic dimensions, such as International Classification of Diseases, 10th revision; International Classification of Primary Care 2nd edition; Systematized Nomenclature of Medicine Clinical Terms; or dimensions dictated by specific usages, such as identifying expressions specific to a domain, a gender, or an intervention. The list was progressively deployed for clinicians with an iterative process of quality control, maintenance, and improvements, including the addition of new expressions or dimensions for specific needs. The problem management of the electronic health record allowed the measurement and correction of encoding based on real-world use. Results The list was deployed in production in January 2017 and was regularly updated and deployed in new divisions of the hospital. Over 4 years, 684,102 problems were created using the list. The proportion of free-text entries decreased progressively from 37.47% (8321/22,206) in December 2017 to 18.38% (4547/24,738) in December 2020. In the last version of the list, over 14 dimensions were mapped to expressions, among which 5 were international classifications and 8 were other classifications for specific uses. The list became a central axis in the electronic health record, being used for many different purposes linked to care, such as surgical planning or emergency wards, or in research, for various predictions using machine learning techniques. Conclusions This study breaks with common approaches primarily by focusing on real clinicians’ language when expressing patients’ problems and secondarily by mapping whatever is required, including controlled vocabularies to answer specific needs. This approach improves the quality of the expression of patients’ problems while allowing the building of as many structured dimensions as needed to convey semantics according to specific contexts. The method is shown to be scalable, sustainable, and efficient at hiding the complexity of semantics or the burden of constraint-structured problem list entry for clinicians. Ongoing work is analyzing the impact of this approach on how clinicians express patients’ problems.",JMIR medical informatics,2021.0,10.2196/29174,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4653b885696c062c41579f6b333637b492c42c9d,https://www.semanticscholar.org/paper/4653b885696c062c41579f6b333637b492c42c9d,"Crowdsourcing sensitive data using public displays—opportunities, challenges, and considerations",,Personal and Ubiquitous Computing,2020.0,10.1007/s00779-020-01375-6,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
728742d1886a476b3208619953fe814fa3170184,https://www.semanticscholar.org/paper/728742d1886a476b3208619953fe814fa3170184,"Centering disability perspectives in algorithmic fairness, accountability, & transparency","It is vital to consider the unique risks and impacts of algorithmic decision-making for people with disabilities. The diverse nature of potential disabilities poses unique challenges for approaches to fairness, accountability, and transparency. Many disabled people choose not to disclose their disabilities, making auditing and accountability tools particularly hard to design and operate. Further, the variety inherent in disability poses challenges for collecting representative training data in any quantity sufficient to better train more inclusive and accountable algorithms. This panel highlights areas of concern, present emerging research efforts, and enlist more researchers and advocates to study the potential impacts of algorithmic decision-making on people with disabilities. A key objective is to surface new research projects and collaborations, including by integrating a critical disability perspective into existing research and advocacy efforts focused on identifying sources of bias and advancing equity. In the technology space, discussion topics will include methods to assess the fairness of current AI systems, and strategies to develop new systems and bias mitigation approaches that ensure fairness for people with disabilities. For example, how do today's currently-deployed AI systems impact people with disabilities? If developing inclusive datasets is part of the solution, how can researchers ethically gather such data, and what risks might centralizing data about disability pose? What new privacy solutions must developers create to reduce the risk of deductive disclosure of identities of people with disabilities in ""anonymized"" datasets? How can AI models and bias mitigation techniques be developed that handle the unique challenges of disability, i.e., the ""long tail"" and low incidence of many types of disability - for instance, how do we ensure that data about disability are not treated as outliers? What are the pros and cons of developing custom/personalized AI models for people with disabilities versus ensuring that general models are inclusive? In the law and policy space, the framework for people with disabilities requires specific study. For example, the Americans with Disabilities Act (ADA) requires employers to adopt ""reasonable accommodations"" for qualified individuals with a disability. But what is a ""reasonable accommodation"" in the context of machine learning and AI? How will the ADA's unique standards interact with case law and scholarship about algorithmic bias against other protected groups? When the ADA governs what questions employers can ask about a candidate's disability, and HIPAA and the Genetic Information Privacy Act regulate the sharing of health information, how should we think about inferences from data that approximate such questions? Panelists will bring varied perspectives to this conversation, including backgrounds in computer science, disability studies, legal studies, and activism. In addition to their scholarly expertise, several panelists have direct lived experience with disability. The session format will consist of brief position statements from each panelist, followed by questions from the moderator, and then open questions from and discussion with the audience.",FAT*,2020.0,10.1145/3351095.3375686,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cb2e04f35a1cda2720d0a19121129cafbf434d0c,https://www.semanticscholar.org/paper/cb2e04f35a1cda2720d0a19121129cafbf434d0c,COVID-19: Visualizing regional socioeconomic indicators forEurope,"The COVID-19 pandemic struck the world out of the blue and displayed unprecedented transmission rates. Part of the reason for its rapid worldwide spread, was the nature of the virus itself, its presentation (symptoms were visible well after a person was infected) and the highly complex, interconnected world we live in today. An equally important contributing factor is our, now apparent, collective inability to deal with a rapidly emerging global threat in a coherent and integrated manner across countries and continents. Our existing multilateral systems are simply not yet geared to respond to such an emerging global challenge in an adequate and timely manner. The plethora of national responses have also been shown to be inadequate. 
 
The extent of our inter-connectedness has led us to recognize that we live in a global village, and this pandemic has removed any remaining doubts. However, the underlying global order of pervasive tourism, trade, business, education has the potential to create vulnerabilities while also generating critical sector specific information that could be systematically harnessed in order to allow rapid and effective global and national responses to risks. Undoubtedly this data is being collected in some form. At a more operational level the world is still struggling to bring together the necessary data from across different sectors of society, across scales and a sufficiently integrated manner to fully enable a rapid analysis and a comprehensive disaster risk mitigation response. The looming era of machine learning and artificial intelligence too has the potential to fast-track our capabilities and responsiveness to such epidemics, but presently, we are still struggling to access relevant information and timely data at appropriate scales and resolutions. 
 
Early information from the COVID-19 pandemic suggested a greater vulnerability of older citizens to the virus. Current mortality patterns support the notion that the elderly, especially those with underlying medical conditions, are more vulnerable. However, clearly, all segments of the population are vulnerable. In the absence of an available cure for the virus, key measures deployed to limit transmission include to curb mobility, social distancing, to strengthen the medical infrastructure to improve the palliative treatment for vulnerable patients (ventilators) and protect key medical practitioners (protective clothing and masks). A fully functional coordinated system of international cooperation would help with the effective execution of many of these measures. Given that the pandemic has now reached nearly all countries around the world and is still spreading, countries are responding by shutting borders and are competing for scarce resources - medical, technical, and/or financial. The developing geography of the pandemic illustrates how different countries become more vulnerable at different times during the development of the pandemic - not all countries are necessarily equally vulnerable at the same time. The same principle applies to different parts within a country (Northern Italy, New York). In understanding these differences, mortality rates are probably a more robust indicator, albeit delayed, considering the different modes and extents of COVID-19 testing implemented around the world. 
 
Clearly COVID-19 has caught all of us o_ guard, yet we need to respond to the emerging crisis to the best of our ability. While numerous epidemiological analyses and models are currently informing and assisting global decision makers to respond to the virus, we at IIASA can assist by making available critical socioeconomic and demographic data that may be of use to policymakers and the health community to allocate scarce resources more strategically between countries and even within countries. 
 
This IIASA mapbook is made available to rapidly and urgently disseminate key demographic and population information in a visible form to assist health professionals, disaster response operations, governments and policymakers from across the European Union. This IIASA mapbook publishes and will continue to expand on a list of key indicators that can be used to better understand the socioeconomic and demographic contexts under which the current COVID-19 crisis is unfolding. Accessible data is presently limited to the EU.",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7718b30f96f97f10e113518b56502aa13e7cd98a,https://www.semanticscholar.org/paper/7718b30f96f97f10e113518b56502aa13e7cd98a,Opportunities and Challenges for Interpreting Rare Variation in Clinically Important Genes,"Genome sequencing is enabling precision medicine—tailoring treatment to the unique constellation of variants in an individual’s genome. The impact of recurrent pathogenic variants is often understood, leaving a long tail of rare genetic variants that are uncharacterized. The problem of uncharacterized rare variation is especially acute when it occurs in genes of known clinical importance with functionally consequent frequent variants and associated mechanisms. Variants of unknown significance (VUS) in these genes are discovered at a rate that outpaces current ability to classify them using databases of previous cases, experimental evaluation, and computational predictors. Clinicians are thus left without guidance about the significance of variants that may have actionable consequences. Computational prediction of the impact of rare genetic variation is increasingly becoming an important capability. In this paper, we review the technical and ethical challenges of interpreting the function of rare variants in two settings: inborn errors of metabolism in newborns, and pharmacogenomics. We propose a framework for a genomic learning healthcare system with an initial focus on early-onset treatable disease in newborns and actionable pharmacogenomics. We argue that (1) a genomic learning healthcare system must allow for continuous collection and assessment of rare variants, (2) emerging machine learning methods will enable algorithms to predict the clinical impact of rare variants on protein function, and (3) ethical considerations must inform the construction and deployment of all rare-variation triage strategies, particularly with respect to health disparities arising from unbalanced ancestry representation.",,2020.0,10.20944/preprints202011.0599.v1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3f76ff4358c5529243aaf03bb0df018081a2998c,https://www.semanticscholar.org/paper/3f76ff4358c5529243aaf03bb0df018081a2998c,A new scoring system for upper gastrointestinal bleeding: Too simple or still complicated?,"Risk stratification for patients with upper gastrointestinal bleeding (UGIB) is recommended by international care guidelines and thought to be part of the standard of care. In particular, pre-endoscopic risk scores are useful because they provide earlier risk assessment compared to scores that use endoscopic findings. However, most of these scores involve multiple clinical and biochemical parameters and are too complicated to be used in a busy emergency medicine or gastroenterology unit on a regular basis. In this issue of the Journal of Gastroenterology and Hepatology, Redondo-Cerezo et al. have developed a “simple” risk score named MAP (ASH) score (using six parameters namely mental status, American Society of Anesthesiologists score, pulse and blood pressure, and albumin and hemoglobin levels and a simple calculator) that performs well and is easily implementable at the point of care. This score was developed from an international cohort of patients with UGIB and validated in a single tertiary referral center. It performed similarly to the best performing risk score (Glasgow-Blatchford Score) in predicting need for hospital-based intervention (area under the curve [AUC] 0.83), 30-day mortality (AUC 0.74), endoscopic intervention (AUC 0.61), and rebleeding (AUC 0.73). MAP (ASH) is simpler than the Glasgow-Blatchford Score and easier to calculate, which may help busy practitioners apply the score in practice. MAP (ASH) was developed for risk stratification in patients presenting to the hospital prior to endoscopic evaluation to guide provider decision making. The score uses mostly clinical variables, including a global physician assessment with the American Society of Anesthesiologists score. The current study demonstrates a valiant effort to reduce the mental load in calculating risk for patients with UGIB, but the inherent difficulty of performing a complex calculation during a busy clinical workflow remains unsolved particularly because the ideal use would be making the calculation directly from memory rather than having to break the workflow to enter data into an online calculator. The simplified point system still requires remembering which elements represent higher point totals, and there are two A’s (American Society of Anesthesiologists score and albumin level) that have different point values that may create confusion. Furthermore, specific cutoffs (e.g. albumin < 2.5 and hemoglobin < 10) still must be memorized. While MAP (ASH) and other clinical scores will continue to shed light on meaningful factors that can be used for prognostic modeling, the challenges of clinical uptake by clinicians and good performance of outcome prediction will be difficult to surmount. One solution to improve clinical uptake is through automatic deployment using the electronic health record that is available in many established healthcare systems. This would minimize manual data entry and potentially provide the score at the point of care for clinical decision support. More computationally complex solutions such as machine learning has shown promise in improving performance beyond that of existing clinical risk scores. Recently, a pre-endoscopic risk score was developed using a machine learning gradient-boosted model with improved performance overall and better ability to identify very low risk patients compared with the Glasgow-Blatchford Score. The potential of machine learning also includes the ability of the model to “learn” over time and for models to be customized for each center by retraining the model on center-specific data. Hence, this AI-assisted prediction model will continue to improve with time and experience. However, machine learning models increase the burden of data entry because they include of more variables, require computational infrastructure that is not widely available, and are not easily interpretable. Much work has to be done in this area, but we are starting to see new light at the end of tunnel. In summary, the development of MAP (ASH) represents a new simplified model that can be used to prognosticate in patients with UGIB. Hopefully, the addition of this score to the array of risk scores in UGIB will provide another option for busy providers to triage patients appropriately as part of timely and high-quality care.",Journal of gastroenterology and hepatology,2020.0,10.1111/jgh.14959,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
09a4ab6a61eaa69d1ce496a4f291d565329fc8d5,https://www.semanticscholar.org/paper/09a4ab6a61eaa69d1ce496a4f291d565329fc8d5,eResearch Collaboration Projects-supporting CSIRO's digital science and research,"Background CSIRO is Australia’s largest research agency and is a recognised leader in a diverse set of
science domains: Agricultural Sciences, Environment/Ecology, Plant and Animal Sciences,
Geosciences, Chemistry and Materials Science. CSIRO also manages research infrastructure
like the Australia Telescope National Facility (ATNF), the Marine Research Vessel RV
Investigator and the Pawsey Supercomputing Centre. For many years in Australia, and also worldwide [2], research and science have undergone
transformational changes with the introduction of new instruments and advanced facilities
with matching increases in storage and computing capabilities. Individual researchers were
taking a bespoke approach to matching these technologies and capabilities to the way that
research and science were carried out. Wider adoption of new practices required social
change (in the practice of science and research) and these changes remained fragmented
and tailored to specific sciences or even projects. Organisations, by and large, varied
enormously in their support of these new practices.As far back as 2007 [1], CSIRO eResearch practitioners advocated that science and research
practices within CSIRO adapt to deal with these challenges. Much like the rest of the world,
practices matured over the years: in CSIRO’s health and biosecurity, oceanographic and
atmospheric research, radio astronomy, agriculture and food as well as geological and
other earth sciences. However, a significant shift occured in 2018, with a formal recognition by the CSIRO Board
of the need to support the new “digital” science and research at an organisational level.
CSIRO developed strategic digital transformation initiatives, including CSIRO’s Managed
Data Ecosystem (MDE), Missions and the Digital Academy [4].The aim of the MDE is to connect current and new platforms in a seamless way and improve
interoperability between datasets so users will be able to easily find and work on multiple
datasets. It will provide a set of tools and approaches enabling CSIRO and partners to
improve our collaboration, mining and analysis of data. CSIRO Missions are major scientific and collaborative research programs aimed at making
significant breakthroughs in one of six major challenges facing Australia. They include the
resilient and valuable environments, food security and quality, health and well-being, future
industries, sustainable energy and resources, and regional security. CSIRO's Digital Academy is focused on investing in the digital capability of our staff and
involves a rethink in planning for a digitally driven research environment. It provides a
learning opportunity for our staff, helping define the digital talent, skills and new ways of
working. The Academy will help attract and retain new digital talent within the Australian
innovation system, develop new digital skills and mindsets in Australian’s scientists and
facilitate digital talent accessibility and collaboration across Australia’s innovation system.Existing Support for “Digital” Science through “eResearch” initiativesCSIRO Scientific Computing Services group has been providing a dedicated eResearch service
since 2011 [3] This service is delivered through ""eResearch Collaboration Projects” (eRCPs)
which now delivers specialist capabilities that includes Machine Learning, Data Analytics,
Scientific Visualisation, Workflow Management and Science Data Handling into research and
science projects. The eRCP process is run as a competitive grant process and continues to be very successful. In the latest cycle, forty Scientific Computing Services specialists successfully completed and
delivered over sixty eRCPs outcomes from a total of eighty submissions. The underlying
capabilities are delivered by members from each of teams in the Scientific Computing
Services group: Technical Solutions; Data Analytics and Visualisation; Research Software
Engineering; and Modelling and Dataflow. The eRCP process also provides a mechanism to
promote and introduce new tools and frameworks for consumption to CSIRO’s research
community eg Jupyter and R/Shiny. In the latest cycle, forty Scientific Computing Services specialists successfully completed and
delivered over sixty eRCPs outcomes from a total of eighty submissions. The underlying
capabilities are delivered by members from each of teams in the Scientific Computing
Services group: Technical Solutions; Data Analytics and Visualisation; Research Software
Engineering; and Modelling and Dataflow. The eRCP process also provides a mechanism to
promote and introduce new tools and frameworks for consumption to CSIRO’s research
community eg Jupyter and R/Shiny. Specialists from the Scientific Computing program are then assigned to work on one or more
approved eRCPs. Over the six-month cycle, the resource allocation is around 0.2 FTE, with
each staff member allocated 3 eRCP projects per cycle. Importantly, eRCPs are provided to
CSIRO researchers and scientists at no additional charge.The eRCP has been enormously successful over the years, with demand outstripping
capability to allocate staff to the projects. The program has demonstrated a range of useful
outcomes including – including for example - an augmented reality tool for analysing
bushfire plumes over Tasmania; a dashboard to interrogate cotton crop physiological
measurements and an online platform to monitor algal blooms for multiple water bodies.Scientific Computing specialists also provide dedicated support to CSIRO researchers, based
around the same set of core capabilities, via an entirely separate funding models known as
“pan deployments” as well as secondments. In both cases, CSIRO projects fund the specialists’
time at larger allocations, often extending over 12 months or more. In a sense, this acts like a
contractor service for Business Units, providing them with highly specialised skills but without
the need to recruit new staff of their own.Future PlansCSIRO Scientific Computing will respond to the major initiatives – MDE, Digital Academy and
Missions as follows:MDE - Redirect Scientific Computing expertise currently working on eRCPs and pan
deployments to MDE related activities. In the first instance, these specialists
will apply their skills and domain knowledge to one of several nominated
pilots, helping design and build foundational components of the MDE. - Over time, it is anticipated that those same specialists will contribute to the
ongoing development and enhancement of additional MDE components in
line with its progressive organisational rollout. Digital Academy - Develop/adapt training content as appropriate for the Digital Academy. For
example, making use of existing Software Carpentry material for HPC usage,
but customising appropriate aspects for our own computing environment.- Delivering training content to CSIRO staff. This has already proven very
successful in the machine learning area – with hundreds of staff attending
sessions - and will no doubt continue to grow over time.Missions - Scientific Computing will continue to provide CSIRO researchers with the
eResearch support they need in response to the significant scientific
challenges tackling Missions. REFERENCES 1. J. A. Taylor, J. Zic, and J. Morrissey, “Building CSIRO e-Research Capabilities,” in eResearch Australasia 2008.2. T. Hey, S. Tansley, and K. Tolle, “The Fourth Paradigm: Data-Intensive Scientific
Discovery,” Data-Intensive Sci. Discov. Microsoft Res., 2009.3. S. Moskwa, “The Accelerated Computing Initiative,” in eResearch Australasia, 2012.4. CSIRO Chief Executive's Report 2018-19: https://www.csiro.au/en/About/Ourimpact/Reporting-our-impact/Annual-reports/18-19-annual-report/part-1/chiefexecutive-reportABOUT THE AUTHOR(S) Dr John Zic is the Executive Manager of CSIRO’s Science Computing Services Mr Justin Baker is Leader of the Scientific Computing Data Analytics and Visualisation
Team.",,2020.0,10.6084/M9.FIGSHARE.11929647.V1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0878f21553a04ae10ed1a3e55ddf4091e6238df2,https://www.semanticscholar.org/paper/0878f21553a04ae10ed1a3e55ddf4091e6238df2,ICIN 2020 Program,"For nearly fifty years, beginning with Kleinrock's pioneering work on using queueing theory to model packet flows in communication networks, network modeling has adopted the individual packet as primary level of granularity for network modeling and analysis. With the advent of terabit-switching capabilities, information-centric networking, and data centers with complex workloads and hundreds of thousands of components, the time would seem ripe to raise the level of abstraction beyond the packet. In this talk, we identify higher-level modeling abstractions are already proving useful as well as new needed abstractions. But also we identify cases where packet-level models are still crucial in providing important insights. Wednesday, February 26 10:00 11:00 K2: Keynote 2 Softwarization and IoT evolution Lefteris Mamatas (University of Macedonia, Greece) Room: La Grande Scène Chair: Alex Galis (University College London (UCL), United Kingdom (Great Britain)) Abstract: The Internet of Things (IoT), a main enabler for Industry 4.0, is considered as a system connecting myriads of people, things and services. IoT enables new large-scale applications with diverse constraints (e.g., limited resource availability or mobility) and requirements (e.g., ultra low delays). A main challenge is the evolution beyond large networks of sensing devices to multiple cooperating network deployments that implement context-sensitive communication and cloud processing strategies, through the seamless adoption of Softwarization technologies. The talk includes the following aspects: (i) a motivation of the above vision with two novel use-cases on smart-city and maritime contexts; (ii) a discussion on the evolutionary and clean-slate approaches to the IoT Softwarization; (iii) the missing elements and open issues in Software-Defined IoT and Edge Cloud technologies; and (iv) insights from our practical experience in relevant implementations and real experiments. The Internet of Things (IoT), a main enabler for Industry 4.0, is considered as a system connecting myriads of people, things and services. IoT enables new large-scale applications with diverse constraints (e.g., limited resource availability or mobility) and requirements (e.g., ultra low delays). A main challenge is the evolution beyond large networks of sensing devices to multiple cooperating network deployments that implement context-sensitive communication and cloud processing strategies, through the seamless adoption of Softwarization technologies. The talk includes the following aspects: (i) a motivation of the above vision with two novel use-cases on smart-city and maritime contexts; (ii) a discussion on the evolutionary and clean-slate approaches to the IoT Softwarization; (iii) the missing elements and open issues in Software-Defined IoT and Edge Cloud technologies; and (iv) insights from our practical experience in relevant implementations and real experiments. Wednesday, February 26 11:30 12:30 TS3: Network Slicing Room: La Grande Scène Chair: Prosper Chemouil (Orange Labs (retired), France) TS3.1 A Lightweight Policy-aware Broker for Multi-domain Network Slice Composition Xuan-Thuy Dang (Technische Universität Berlin & DAI Labor, Germany); Fikret Sivrikaya (GT-ARC gGmbH & Technische Universität Berlin, Germany) TS3.2 Enhancing the performance of 5G slicing operations via multi-tier orchestration Miquel Puig Mena (i2cat Foundation, Spain); Apostolos Papageorgiou, Leonardo Ochoa-Aday and Muhammad Shuaib Siddiqui (Fundació i2CAT, Internet i Innovació Digital a Catalunya, Spain); Gabriele Baldoni (ADLINK Technology, France) TS3.3 An Efficient Online Heuristic for Mobile Network Slice Embedding Katja Ludwig (University of Augsburg, Germany); Andrea Fendt (Nokia Bell Labs & University of Augsburg, Germany); Bernhard Bauer (University of Augsburg, Germany) Wednesday, February 26 12:30 13:00 DPS: Demo/Poster ""Elevator Pitch"" Session Room: La Grande Scène Chair: Prosper Chemouil (Orange Labs (retired), France) DPS.1 A QUIC-based proxy architecture for an efficient hybrid backhaul transport Michele Luglio and Mattia Quadrini (University of Rome Tor Vergata Dip. Ing. Elettronica, Italy); Cesare Roseti and Francesco Zampognaro (University of Rome Tor Vergata, Italy); Simon Pietro Romano (University of Napoli Federico II, Italy) DPS.2 A Blockchain-based Brokerage Platform for Fog Computing Resource Federation Marco Savi, Daniele Santoro, Katarzyna Di Meo and Daniele Pizzolli (Fondazione Bruno Kessler, Italy); Miguel Pincheira (OpenIoT Research Area, FBK CREATE-NET & University of Trento, Italy); Raffaele Giaffreda (FBK CREATE-NET, Italy); Silvio Cretti (Fondazione Bruno Kessler, Italy); Seung-woo Kum (Korea Electronics Technology Institute, Korea (South)); Domenico Siracusa (Fondazione Bruno Kessler, Italy) DPS.3 Optimized Network Slicing Proof-of-Concept with Interactive Gaming Use Case José J Alves Esteves, Jr. (Orange Labs & Sorbonne Université, France); Amina Boubendir and Fabrice M. Guillemin (Orange Labs, France); Pierre Sens (Université de Paris 6, France) DPS.4 A Deployable Containerized 5G Core Solution for Time Critical Communication in Smart Grid Van Giang Nguyen, Karl-Johan Grinnemo, Javid Taheri and Anna Brunstrom (Karlstad University, Sweden) DPS.5 FogGuru: a Fog Computing platform based on Apache Flink Davaadorj Battulga (University of Rennes 1 & U-Hopper, Italy); Daniele Miorandi (U-Hopper, Italy); Cedric Tedeschi (University of Rennes I / INRIA, France) DPS.6 5G Experimentation Framework: Architecture Specifications, Design and Deployment Louiza Yala (Orange Labs, France); Sihem Cherrared (University of Rennes 1 & Orange Labs and INRIA, France); Grzegorz Panek (Orange Polska, Poland); Sofiane Imadali and Ayoub Bousselmi (Orange Labs, France) DPS.7 A New Service Management Framework for Vehicular Networks Jose Ramirez, Onyekachukwu Augustine Ezenwigbo, Gayathri Karthick and Ramona Trestian (Middlesex University, United Kingdom (Great Britain)); Glenford E Mapp (MIddlesex University & Cantego Limited, United Kingdom (Great Britain)) DPS.8 Creating trust in automation in intent-based mobile network management Ville Vartiainen (Aalto University, Finland); Dmitry Petrov and Vilho Räisänen (Nokia Bell Labs, Finland) DPS.9 Interoperable and discrete eHealth Data Exchange between Hospital and Patient Andreea Ancuta Corici, Olaf Rode, Ben Kraufmann, Andreas Billig, Jörg Caumanns and Markus Deglmann (Fraunhofer FOKUS, Germany); Viktoria Walter, Janina Rexin and Gunther Nolte (Vivantes Netzwerk für Gesundheit GmbH, Germany) Wednesday, February 26 14:00 15:00 K3: Keynote 3 Network Operations and AI Rafia Inam (Ericsson, Sweden) Room: La Grande Scène Chair: Diego Lopez (Telefonica I+D, Spain) Abstract: The Fifth Generation Mobile Networks (5G) are seen as a key enabler for diverse-natured industry verticals (such as automotive, manufacturing, mining, utility, health, etc.) by providing a platform to support heterogeneous sets of network quality requirements. The presentation will discuss how Artificial Intelligence and automation can support Telecom industry to manage the increased complexity, scalability, and diversity in its use cases. The work presents different aspects of the network operations of the future, done in an automated, proactive, and intent-driven fashion using different AI techniques. The Fifth Generation Mobile Networks (5G) are seen as a key enabler for diverse-natured industry verticals (such as automotive, manufacturing, mining, utility, health, etc.) by providing a platform to support heterogeneous sets of network quality requirements. The presentation will discuss how Artificial Intelligence and automation can support Telecom industry to manage the increased complexity, scalability, and diversity in its use cases. The work presents different aspects of the network operations of the future, done in an automated, proactive, and intent-driven fashion using different AI techniques. Wednesday, February 26 15:00 16:10 TS4: Improving Service Performance Room: La Grande Scène Chair: Amina Boubendir (Orange Labs, France) TS4.1 Multimedia Service Management with Virtualized Cache Migration Reza Shokri Kalan (Ege UniversityTurkey, Turkey); Muge Sayit (Ege University, Turkey); Stuart Clayman (University College London (UCL), United Kingdom (Great Britain)) TS4.2 Proposal of Profile and Event Sharing by Agent Communication Masafumi Katoh (Fujitsu Labotatories Ltd., Japan); Tomonori Kubota and Eiji Yoshida (Fujitsu Laboratories, Japan); Yuji Kojima (Fujitsu Limited, Japan); Yuuichi Yamagishi (FUJITSU LIMITED, Japan) TS4.3 Double Mask: An Efficient Rule Encoding for Software Defined Networking Ahmad Abboud (University of Lorraine, France); Abdelkader Lahmadi (INRIA Nancy Grand Est, France); Michael Rusinowitch (INRIA Nancy-Grand Est, France); Miguel Couceiro (University of Lorraine, France); Adel Bouhoula (Higher School of Communication of Tunis & University of Carthage, Tunisia); Mondher Ayadi (Numeryx, France) Wednesday, February 26 16:35 18:00 TS5: Network Security Room: La Grande Scène Chair: Ved P. Kafle (National Institute of Information and Communications Technology, Japan) TS5.1 Neural network based anomaly detection for SCADA systems Lenhard Reuter (AIT Austrian Institute of Technology, Austria); Oliver Jung (AIT Austrian Institute of Technology GmbH, Austria); Julian Magin (AIT Austrian Institute of Technology, Austria) TS5.2 DDoS Detection System Using Feature Selection and Machine Learning Algorithms in a Distributed System Amjad Alsirhani (Dalhousie University, Faculty of Computer Science & Canada, Canada); Geetanshu Grover and Srinivas Sampalli (Dalhousie University, Canada); Peter Bodorik (Dalhousie University, Faculty of Computer Science, Canada) TS5.3 Configuration of the Detection Function in a Distributed IDS Using Game Theory Clement Weill (Institut Polytechnique de Paris & CEA LIST, France); Alexis Olivereau (CEA, LIST, France); Djamal Zeghlache (Insti","2020 23rd Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)",2020.0,10.1109/icin48450.2020.9059372,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a93e75b9cdcff21f0cc804d33271b6fff38c7a22,https://www.semanticscholar.org/paper/a93e75b9cdcff21f0cc804d33271b6fff38c7a22,Digitizing the Pharma Neurons - A Technological Operation in Progress!,"BACKGROUND
Digitization and automation is the buzzword in clinical research and pharma companies are investigating heavily here. Right from drug discovery to personalized medicine, digital patients and patient engagement, there is great consideration of technology at each step.


METHODS
The published data and online information available is reviewed to give an overview of digitization in pharma, across the drug development cycle, industry collaborations and innovations. The regulatory guidelines, innovative collaborations across industry, academics and thought leadership are presented. Also included are some ideas, suggestions, way forwards while digitizing the pharma neurons, the regulatory stand, benefits and challenges.


RESULTS
The innovations range from discovering personalized medicine to conducting virtual clinical trials, and maximizing data collection from the real-world experience. To address the increasing demand for the real-world data and the needs of tech-savvy patients, the innovations are shaping up accordingly. Pharma companies are collaborating with academics and they are co-innovating the technology. E.g. Massachusetts Institute of Technology's program. This focuses on the modernization of clinical trials, strategic use of artificial intelligence and machine learning using real-world evidence, assess the risk-benefit ratio of deploying digital analytics in medicine, and proactively identifying the solutions.


CONCLUSIONS
With unfolding data on impact of science and technology amalgamation, we need a need shared mindset between data scientists and medical professionals to maximize the utility of enormous health and medical data. To tackle this efficiently, there is a need of cross-collaboration and education, and align with ethical and regulatory requirements. A perfect blend of industry, regulatory, and academia will ensure a successful digitization of pharma neurons.",Reviews on recent clinical trials,2020.0,10.2174/1574887115666200621183459,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
73520f778e5d6033a05963a5309c248781d54a8f,https://www.semanticscholar.org/paper/73520f778e5d6033a05963a5309c248781d54a8f,Robots in Space: Sharing the Sidewalk with Autonomous Delivery Vehicles,"Industrial robots originated in mid-Twentieth Century factories where they increased the efficiency of manufacturing. Their implementation was an extension of earlier industrial automation such as the introduction of Henry Ford’s mechanized assembly line in 1913. In Ford’s assembly line, a rope-and-pully system advanced each vehicle from one worker to the next allowing each worker to remain stationary. Half a century later, in 1961, the first robotic arm, created by Unimate, was introduced to auto manufacturing, which further increased efficiency. More recently, following advancements in artificial intelligence and sensor technology, industrial robots have acquired greater autonomy and transformed the logistics and delivery industries. Like Ford’s assembly line, and Unimate’s robotic arm, Amazon’s fulfillment center robots, originally designed by Kiva Robotics, reduced the daily steps workers must take. Instead of walking through aisles to stock warehouse shelves or retrieve products for distribution, workers remain stationary, and the robots bring the products to them. Today, with even greater autonomy than their predecessors, robots are migrating out of factories, warehouses, and fulfillment centers and into neighborhood streets, sidewalks, and skies. The technological advancements that allowed robots to automate private industrial spaces, such as machine learning and sophisticated sensors, now enable autonomous delivery robots (ADVs) to travel independently in the outside world and deliver packages, meals, groceries, and other retail purchases to people’s homes.<br><br>This article focuses on the evolution of ADVs used for “last-mile delivery,” the final step of the delivery process that ends at the customer’s door. It breaks ADVs down into four different categories: unmanned aerial vehicles (UAVs or “drones”); self-driving cars; autonomous delivery pods; and sidewalk delivery robots, which are sometimes called personal delivery robots (PDRs). The article describes the risks and benefits of deploying ADVs for last-mile delivery and analyzes the laws and federal agencies that regulate them. Last mile delivery is generally thought to be “the most expensive and time-consuming part of the shipping process” because it is the most personalized and unpredictable. Industry estimates suggest that last-mile delivery can account for up to 53 percent of total shipping costs. ADV manufacturers claim they can reduce delivery time, increase efficiency, cut costs, improve the consumer experience, decrease traffic congestion, reduce carbon emissions, assist seniors and people with disabilities who may have decreased mobility, and democratize access to logistics and delivery resources for small businesses allowing them to compete with large corporations. Critics claim ADVs may negatively impact public health by encouraging inactivity, obstructing roads and sidewalks and impairing the mobility of seniors and people with disabilities, and endangering public safety due to their potential to collide with people who are not agile enough to get out of the way. ADVs may also reduce the need for human delivery workers, cause noise pollution, violate people’s privacy, and represent the increasing privatization of public spaces such as sidewalks. Though all ADVs will be discussed, my focus is primarily on sidewalk delivery robots because they are the newest and fastest growing segment of the ADV industry, and they face the fewest legal and regulatory hurdles. Particular attention will be paid to the differences between the laws that regulate sidewalk delivery robots and the laws that govern other types of ADVs. The article concludes by drawing lessons from the regulation of UAVs and self-driving cars to propose legislation to regulate sidewalk delivery robots that will increase their safety and utility while limiting the privatization of public spaces.",SSRN Electronic Journal,2019.0,10.2139/ssrn.3347466,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5d85748055ff954e38c4c1f24138d614d4323fa,https://www.semanticscholar.org/paper/a5d85748055ff954e38c4c1f24138d614d4323fa,SmartDashCam: Automatic Live Calibration for DashCams,"Dashboard camera installations are becoming increasingly common due to various Advanced Driver Assistance Systems (ADAS) based services provided by them. Though deployed primarily for crash recordings, calibrating these cameras can allow them to measure real-world distances, which can enable a broad spectrum of ADAS applications such as lane-detection, safe driving distance estimation, collision prediction, and collision prevention Today, dashboard camera calibration is a tedious manual process that requires a trained professional who needs to use a known pattern (e.g., chessboard-like) at a calibrated distance. In this paper, we propose SmartDash-Cam, a system for automatic and live calibration of dashboard cameras which always ensures highly accurate calibration values. Smart-DashCam leverages collecting images of a large number of vehicles appearing in front of the camera and using their coarse geometric shapes to derive the calibration parameters. In sharp contrast to the manual process we are proposing the use of a large amount of data and machine learning techniques to arrive at calibration accuracies that are comparable to the manual process. SmartDashCam implemented using commodity dashboard cameras estimates realworld distances with mean errors of 5.7 % which closely rivals the 4.1% mean error obtained from traditional manual calibration using known patterns.",2019 18th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN),2019.0,10.1145/3302506.3310397,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
efdbf9e19d6033b52d5b27cf64ea9d3256445676,https://www.semanticscholar.org/paper/efdbf9e19d6033b52d5b27cf64ea9d3256445676,Alveolar Osteitis Following Tooth Extraction: Systematic Review and Google Trends Analysis Instigated by the First Upper Premolar Case Reported from Iraq,"Introduction： Alveolar osteitis is a painful condition that may occur following permanent teeth extraction due to the failure of formation of a blood clot or its dislodgement before the complete healing of the wound. We aim to provide a systematic review and trends analytic on the epidemiology and the digital epidemiology as well as the management of alveolar osteitis and to seek any available data in connection with alveolar osteitis following upper premolar tooth extraction. Methods： This study represents a combinatory of literature review, analytics of Google Trends, and the first documented case from Iraq of alveolar osteitis following extraction of the maxillary first premolar. Three literature databases were explored, using Boolean operators, including NCBI-PubMed, Elsevier, and the Cochrane Library. Google Trends database was examined to assess the digital epidemiology. Results：The total number of hits was 54417. There was an overall deficit of literature concerning the condition in connection with the extraction of maxillary premolars. The digital epidemiology was limited to twenty-two countries including three countries from the Middle East accounting for 13.63% of the total geographic mapping while Iraq was absent. Conclusion：Our exceptional case report instigated a systematic analytic of a trends database and the literature. The analysis confirmed the inadequacy of studies from the Middle East. Future studies should deploy the use of machine learning algorithms for a rigour statistical inference based on data from online and offline big data repositories of public health records. 
 ",Modern Applied Science,2019.0,10.5539/mas.v13n3p1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c7bdcc259eebfe235306ae8f7d5ec71e183cc05b,https://www.semanticscholar.org/paper/c7bdcc259eebfe235306ae8f7d5ec71e183cc05b,Cyber-healthcare for public healthcare in the developing world,"The recent advances in sensor/actuator and RFID technologies have spun out a new healthcare model enabling capture and dissemination of patient vital signs over the Internet for ubiquitous monitoring of these patients anytime and from anywhere. This provides new opportunities for enhancing healthcare through participatory consultation, medical diagnosis and many other novel healthcare services. Some of the advantages of this emerging technology referred to in this paper as “Cyber-healthcare” includes low acquisition cost, flexible deployment and improved accuracy resulting from replacing manual operations by fully digitized processes. It is expected that the emerging healthcare technology will change the way healthcare is delivered in both rural and urban settings of the developing world by building upon this technology to leapfrog from poorly prepared to medically equipped environments capable of tackling some of the most challenging medical issues of the developing world such as patients' vital signs capture, patient prioritization and preparedness to virus outbreaks such as Ebola. This paper proposes a Cyber-healthcare system as a first step towards the implementation of least cost digital health systems in the developing countries. We assess the field readiness of the off-the-shelf sensor technology used by the system and evaluate the performance of its underlying patient prioritization module using two machine learning algorithms: 1) multivariate linear regression and 2) support vector machine.",2016 IEEE Symposium on Computers and Communication (ISCC),2016.0,10.1109/ISCC.2016.7543707,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
023dc669070168a27ea6c422a7e61b7fe673f4de,https://www.semanticscholar.org/paper/023dc669070168a27ea6c422a7e61b7fe673f4de,A DID for Everything,"The decentralized identifer (DID) is a new and open standard type of globally unique identifer that ofers a model for lifetime-scope portable digital identity that does not depend on any centralized authority and that can never be taken away by third-parties [14]. DIDs are supported by the W3C community [14] and the Decentralized Identity Foundation (DIF) [16]. They are the ""atomic units"" of a new layer of decentralized identity infrastructure. However, DIDs can be extended from identifers for people to any entity, thus identifying everything. We can use DIDs to help us identify and manage objects, machines, or agents through their digital twins; we can expand them to locations, to events, and even to pure data objects, which we refer to as decentralized autonomic data (DAD) items [1][3]. The paper will present novel use-cases for DIDs and DADs and propose a new cryptographic data structure that 01/17/19 A DID for Everything 1.0 1 is a self-contained blockchain of DADs. This enables the verifcation of the provenance of a given data fow. It builds on a prior paper [1] and an associated reading [2]. DIDs are only the base layer of decentralized identity infrastructure. The next higher layer (where most of the value is unlocked) is verifable claims. This is the technical term for a digitally signed electronic data structure that conforms to the interoperability standards being developed by the W3C Verifable Credentials Working Group [15]. When a DID and hence DADs of the resultant data are extended to machines and autonomic data, the provenance chain of the data fow can provide the basis for verifable claims and attestations about the data fow as well as the basis for a reputation. WHY THIS MATTERS Today, the Internet is probably best described as a network comprised of all interconnected entities, traditionally referring to human users and computers. When we add connected entities and devices in the so-called Internet of Things (IoT), the number of addressable elements is in the tens of billions, with an estimate of 75 bn connected IoT devices in 2025 [4]. Software services, such as algorithms and bots, further extend this universe of identifable entities. The resulting combinatorics of possible connections between any given set of entities is an impossibly large number. Yet in today's user journeys or business environments, agents (whether human, machine, or software) increasingly need to communicate, access or transact with a diverse group of these interconnected objects to achieve their goals in both the digital and physical worlds. This requires a straightforward and ubiquitous method to address, verify, and connect these elements together. Defnition of Entity: Something that has a distinct and independent existence either in the real or the digital world. Examples of an entity are: • Living Organism • Physical Object • Locations or Events • Machines and Devices in the Internet of Things (IoT) • Digital Asset, Data Set, or Agent Human or object identities are stored in multiple centralised or federated systems such as government, ERP, IoT, or manufacturing systems. From the standpoint of cryptographic trust verifcation, each of these centralised authorities serves as its own root of trust. An entity trailing along a value chain is interacting with multiple systems. Consequently, a new actor in any given value chain has no method to independently verify credentials of a human or attributes of either a physical object or data item (provenance, audit trail). This results in the existence of complex validation, quality inspection, and paper trail processes, and enormous hidden trust overhead costs are added to all value chains and services. 01/17/19 A DID for Everything 1.0 2 To be a truly global solution, easy to use and still safe from hacking and sovereign interference, such a scheme must include: • preservation of privacy • security from tampering • reliable trust verifcation • assurance of risk • independence from any vendor-defned naming API • one-to-one mappable onto each entity. Therefore, a universal addressing, trust-verifcation system and associated interoperable protocol must be utilised, empowering every form of entity. Why it Matters for People Today when entities want their identities to be confrmed they transfer information such as a birth certifcate, physical address, or social security number to multiple third parties, who start to validate the same data in diferent contexts for KYC and authentication processes. The parties to which they sent that information retains it, meaning the data is out there in silos, creating risks in terms of data loss, privacy breaches, and use of inconsistent data and forcing companies that might not want to be in that position to store that information. It also enables businesses to harvest people's personal data for commercial purposes, which does not necessarily refect the intentions of the individual people. This situation results in big problems for humans such as broken health care records. Patients will need a universally addressable healthcare record system that is controlled by the patient itself, that consistently stores all relevant verifed health care data, and that is able to share this data with doctors that need to connect with it. To enable the doctors or algorithms, they need a data-fow provenance to verify the integrity, quality, or reputation of a healthcare record to decide on treatments and give the patient confdence about the proposed treatments. Why it Matters for Businesses Defnition of a Digital Twin: A digital twin is a digital representation of either a real-world or digital entity. A digital twin exists over the life-cycle of an entity from planning, manufacturing, testing, birth, and operations to decommissioning and reuse. The more past and present data are related and analysed, the more knowledge can be deployed to drive signifcant improvements on an individual entity or system level. It is estimated that by 2022 the IoT powered by digital twins will save consumers and businesses worth $1 trillion a year in asset maintenance [5]. The notion of digital twinning for objects, machines, and agents is becoming relevant to an increasing number of human services and Industry 4.0 use cases. This is the result of the growth in digital services, connections, and 01/17/19 A DID for Everything 1.0 3 data streams from the Internet of Things (IoT) devices that increasingly drive integration with machine learning algorithms, resulting in graph-type data chains for processing the IoT data streams. Today, digital twins are captured in siloed, proprietary IoT solutions by individual corporates that do not own the physical object over the life-cycle and even do not interact with parties using the object further down a value chain. Decentralized solutions are liberating the digital twins from silos and establishing more valuable and interoperable verifable attributes about entities and the data chains they connect with. Why it Matters for Objects, Machines and Agents There is no widely adopted authentication or verifcation systems in place to provide the equivalent of KYC (know-your-customer) for non-human entities, that is: KYA (know-your-agent), KYB (know-your-bot), KYM (know-your-machine), or KYO (know-your-object). In a world when objects and machines are connected with datastreams and intelligent agents that perform transaction on behalf of the entity, the number of agent-to-agent transactions will outgrow the number of human transactions by many orders. An agent transacting with another party can independently verify the identifer of the this party, its attributes, and the provenance of the data sets that are involved in the transaction. Digital twins of 3D-printed objects for safety critical parts such as a turbine of an airplane provide an important example. For these parts, it is important to have an precise audit trail about the 3D printing process to prove that the object was manufactured in accordance to stringent specifcations. The digital twin stores design, manufacturing, post processing, and quality-assurance data about the 3D-printed object. These data are coming from multiple systems resulting in a variety of data chains. With DIDs and DADs the integrity of the data chains can be verifed. The verifcation of the datachains and the underlying data results in important proofs about the provenance of 3D printed object. Why it Matters for the World The diverse application of decentralized identifers (DIDs) will have substantial infuences in broader applications on a global scale. The seamless provenance of physical objects or data items through any value chain has major implications on the risk and value properties of the processed data. Within any dynamic process, participating entities have substantial interest in the authenticity and trustworthiness in any individual step. Data that is accumulated with an unforgeable audit trail that references decentralized identifying information (Person, Device or any other Entity) for any transformation step holds greater value then it would have without such properties. Managing the sustainability of the commons requires mechanisms to value natural capital and to account for the externalities that arise from human activities. This should attribute extractions from and contributions to the commons by organisations, organisms, machines and information. We need to identify these entities and must 01/17/19 A DID for Everything 1.0 4 identify both positive and negative impacts these entities are having on the commons. Knowing what these impacts are enables us to count what matters and to put a value on what counts. The promise of a overarching prevalence through the broad use of DIDs also provides the key component for achieving the vision of a circular economy: a regenerative system in which resource input and waste, emission, and energy leakage are minimized by slowing, closing, and narrowing energy an",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8afb292e21dacac92957e214a40eab372df80a4b,https://www.semanticscholar.org/paper/8afb292e21dacac92957e214a40eab372df80a4b,Brain Hemorrhage: When Brainwaves Leak Sensitive Medical Conditions and Personal Information,"Brain Computer Interfaces (BCI) are rapidly gaining popularity in consumer market. It is therefore important to analyze the security and privacy threats these devices may introduce to their users. In this paper, we explore how malicious access to brainwave signals may surreptitiously reveal users' privacy-sensitive medical conditions and personal information, while they are browsing the web (or interacting with an app). At a conceptual level, we investigate the potential of brainwave signals, captured during a user's normal interactions with visual stimuli (e.g., images and audio-visuals) through a website or computer, in exposing whether the user is suffering from a given medical disorder (e.g., drug abuse or autism) and to which demographics group the user belongs (e.g., young vs. elderly or male vs. female). At an empirical level, as two representative case studies into such conceptual attacks, we present a concrete brainwave privacy attack, (Brain) Hemorrhage11In the context of our work, the term “Hemorrhage” is an attack against brainwave privacy. Brain Hemorrhage is a type of alcoholic cocktail, and hence the terminology is also intended to capture one of the case studies of our work on Alcohol Use Disorder., focusing on the leakage of Alcohol Usage Disorder (AUD) and users' age group. Hemorrhage is designed using machine learning techniques to identify the users suffering from AUD and age group by analyzing the seemingly innocuous brainwave signals leaked online in response to users' viewing of simple images or watching of videos. Based on the publicly available EEG datasets on AUD and aging, our study shows that Hemorrhage can predict the presence or absence of alcohol usage disorder with the precision of 96% and the presence or absence of aging condition with 94% accuracy. We also analyze, visualize and interpret the differences in the brainwave signals corresponding to AUD and aging, which serves to justify why our attack succeeds. While the use of neuroimaging devices to diagnose medical disorders in clinical settings is a common practice in the medical field, our study constitutes one of the first steps towards exploring the malicious use of brainwave devices in compromising people's health information privacy in an online setting (otherwise protected under the HIPAA law) as well as their age privacy. Given any website can have unfettered, permission-less access to the signals captured by the current BCI devices, we believe that our work raises a serious online health privacy and age privacy issues as these devices get widely deployed.","2019 17th International Conference on Privacy, Security and Trust (PST)",2019.0,10.1109/PST47121.2019.8949062,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6fda516e3cce22ddfc31f8267587a28d3b71de8f,https://www.semanticscholar.org/paper/6fda516e3cce22ddfc31f8267587a28d3b71de8f,Guest Editorial: Countering Security Issues in the Digital World,"Guest editorial
 The adoption of digital technologies in the oil and gas industry is generating exciting new opportunities to improve performance, profitability, and sustainability, but brings new safety and security challenges across all operations.
 According to a 2017 survey by the Ponemon Institute, cyber attacks are on the rise. Successful breaches per company each year have risen more than 27%, from an average of 102 to 130. The energy and utilities industry, including oil and gas, suffered average annualized losses from cyber crime of $17.2 million per sampled organization, just behind the financial services sector at $18.2 million.
 In June 2017, the NotPetya computer virus affected many companies around the world, including the Russian oil and gas giant, Rosneft. In the same year, another report stated that almost three-quarters of US oil and gas companies had a cyber incident, yet only a handful cited cyber risk as a major concern in their annual reports.
 Cyber Concerns
 As the global oil and gas industry grasps the benefits that digitalization, automation, machine learning, and artificial intelligence can bring to production and profitability, its relatively immature cyber systems are making it an attractive soft target for hackers.
 The traditional focus of cyber security has been on IT, such as the office IT infrastructure. Now, there is an increasing trend for networks on production sites to be connected to wider corporate networks, to allow remote monitoring and control. This increases vulnerability. Managing operational technology, such as control and automation systems, requires both oil and gas operational domain competence, as well as proficiency in general information security.
 The level of threat depends on the level of communications. Cybersecurity can be simplest when data is moving in just one direction, for instance, from the production system into the corporate network. However, if using a remote or centralized control room, the need for protection becomes more pertinent and problematic, as control rooms must be able to alter critical offshore systems. The complexity and challenge for fail-safe security deepens if vendors are able to access and perhaps control equipment on the plant via corporate systems.
 As each rig operation involves a significant number of suppliers and contractors, all deploying safety critical systems, it is vital that the industry introduces controls and security barriers to eliminate any weaknesses.
 Without the understanding and knowledge of how to implement and integrate such systems securely, unnecessary risk and expense can be added to a project. Breaches can lead to lost production; raised health, safety, and environmental risk; costly damages claims; breach of insurance conditions; negative reputational impacts; and loss of licence to operate. Therefore, cybersecurity needs to be a consideration throughout the lifecycle of any project, especially across digital transition activity.",Journal of Petroleum Technology,2019.0,10.2118/0619-0014-JPT,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5f3b8edbd37262dd580effc506e679863cde51d,https://www.semanticscholar.org/paper/a5f3b8edbd37262dd580effc506e679863cde51d,The Whyis Knowledge Graph Framework in Action,"We will demonstrate a reusable framework for developing knowledge graphs that supports general, open-ended development of knowledge curation, interaction, and inference. Knowledge graphs need to be easily maintainable and usable in sometimes complex application settings. Often, scaling knowledge graph updates can require developing a knowledge curation pipeline that either replaces the graph wholesale whenever updates are made, or requires detailed tracking of knowledge provenance across multiple data sources. Fig. 1 shows how Whyis provides a semantic analysis ecosystem: an environment that supports research and development of semantic analytics for which we previously had to build custom applications [3,4]. Users interact through a suite of knowledge graph views driven by the node type and view requested in the URL. Knowledge curation methods include Semantic ETL, external linked data mapping,and Natural Language Processing (NLP). Autonomous inference agents expand the available knowledge using traditional deductive reasoning as well as inductive methods that can include predictive models, statistical reasoners, and machine learning. Whyis is used in a number of areas today, including nanopolymers, spectrum policy, and health informatics. We demonstrate Whyis by creating and deploying an example Biological Knowledge Graph (BioKG), using data from DrugBank and Uniprot1, and briefly discuss benefits of using our approach over a conventional knowledge graph pipeline.",SEMWEB,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d61d66be25889374639e9064f3543f72bde11839,https://www.semanticscholar.org/paper/d61d66be25889374639e9064f3543f72bde11839,iDASH secure genome analysis competition 2017,,BMC Medical Genomics,2018.0,10.1186/s12920-018-0396-0,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
50dd3d6eb63c1ced611c345919259283a578ff0e,https://www.semanticscholar.org/paper/50dd3d6eb63c1ced611c345919259283a578ff0e,Cloud computing and big data: Technologies and applications,"Cloud computing has emerged as a new paradigm of computing, in which scalable and virtualized resources are dynamically provided (anytime, everywhere, and in a transparent way) as services over the Internet.1-3 In cloud computing environments, users can use anytime a variety of devices like PCs, laptops, smart phones, and PDAs to access programs, storage, and application-development platforms using services offered by cloud computing providers. In fact, users can benefit from the high availability, easy scalability, and low costs in using cloud computing resources (ie, software, infrastructure, and platform).4 For instance, cloud computing offers a collection of IT services referred to as Software-as-a-Service to allow users remotely performing their applications. Infrastructure-as-a-Service refers to computing resources as services, whereas Platform-as-a-Service offer some tools and resources for applications' development, including operating systems. Data-Storage-as-a-Service has also emerged in the past few years to provide users with storage capabilities. Generally, cloud computing infrastructures have emerged to allow managing transparently all hardware/software issues such as job scheduling and resources allocation by hiding all implementations, so users can focus on how to access and use remote resources and services instead of focusing on computing and data storage/access issues. Furthermore, various efforts have been recently dedicated to improve the performances of all services offered by cloud computing environments. However, there are still many issues that need to be tackled, mainly, scalability, availability, security, and privacy.4 Despite these issues, cloud computing will remain an environment that continues to play a considerable role in many existing and emerging application domains.5,6 In parallel to this progress, big data technologies have been developed and deployed so rapidly and are relying heavily on cloud computing infrastructures for both storage and data processing. In many studies, these technologies are considered among the most remarkable technologies for developing context-driven applications and services in many domains such as transportation, health, and energy.7-9 In other words, big data technologies have been some of the current and future research frontiers. They revolutionize many fields, including business, scientific research, and public administration. However, the high-volume, high-velocity, and/or high-variety of available information require new forms of processing to enable enhanced decision making, insight discovery, and processes' optimization.10,11 Even though these technologies have been developing very fast over the past few years, we are also facing, in addition to inconsistency and incompleteness, a lot of challenges when handling big data; difficulties mainly lie in real-time data gathering, storage, mining, predictive analytics, and visualization.12 Furthermore, IoT technologies have shown great potential for collecting large amounts of data streams from sensor readings. In fact, a myriad of sensors can be deployed for gathering contextual data that could be integrated with other data such as location, weather data, and social media data. The processing of these heterogeneous data allows the development of context-aware applications and services, which can, for example, provide real-time traffic routing throughout the city, detect, and immediately act on environmental pollution peaks or automatically optimize the logistics chain by allowing instantaneous reactions (eg, via actuators). These data streams have to be first pre-processed locally before sending it to the cloud infrastructures using IoT platforms (eg, ThingSpeak) and via wireless technologies (eg, Wifi and LTE) for storage and processing using machine learning algorithms (eg, deep learning). These heavy processing and high communication factors are, however, serious challenges for the development of large-scale IoT applications over cloud computing environments.7,9 The aim of this special issue is to present recent contributions and results in the fields of cloud computing, IoT and big data applications, systems architecture and services, virtualization, security and privacy, high-performance computing, and applications, with an emphasis on how to build cloud computing platforms with real impacts.",Concurr. Comput. Pract. Exp.,2018.0,10.1002/cpe.4517,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
278ed93dee876d8fa5e876e0fe0440bda222962a,https://www.semanticscholar.org/paper/278ed93dee876d8fa5e876e0fe0440bda222962a,Digital epidemiology and geographic mapping of G6PD deficiency: retrospective analytic of trends database existing on the surface web,"Background: Glucose-6-phosphate dehydrogenase (G6PD) deficiency is an inherited X-linked recessive condition in which the body does not synthesise a sufficient quantity of the G6PD enzyme. Hemolytic anaemic episodes occur following exposure to some medications, foods, or even infections in G6PD-deficient individuals.Aims and Objectives: To assess the digital epidemiology as well as the geographic mapping of G6PD deficiency in the world including countries of the Mediterranean basin.Materials and Methods: This study is primarily based on a digital epidemiological analysis and geographic mapping based on data retrieved from Google Trends database, a very large database, existing on the surface web. A retrospective analysis was carried out for the period from the 22nd of March 2015 to the 24th of January 2016. Trends data will also be contrasted with a collateral data set of a cross-sectional analytic for the same period which was conducted based on the exploration of cases of G6PD deficiency admitted to Jordan University Hospital.Results: Concerning geographic mapping, countries of the Basin of the Mediterranean Sea and the Arabian Gulf accounted for one-third of the entire geographic map at 15.66% and 18.18% respectively. Countries of the Mediterranean basin included Jordan, Italy, Lebanon, Israel, Egypt, Greece, Syria, Cyprus, Tunisia, Algeria, and Morocco. Contributing countries surrounding the Arabian Gulf included Kuwait, Kingdom of Saudi Arabia, Bahrain, Iran, United Arab Emirates, Qatar, and Iraq. The Hashemite Kingdom of Jordan contributed to 2.78% of the global map which accounted for 17.74% of the entire Mediterranean basin. Concerning digital epidemiology, the prevalence was recorded as highest during May 2015 (12.10%), August 2015 (11.17%), and November 2015 (11.28%). Concerning the percentile contribution of monthly records, data were in harmony for those cases admitted to hospital and signals recorded via Google Trends. Both datasets averaged a percentile contribution of approximately 9% per month.Conclusion: This study is the first inferential research on G6PD deficiency based on data from a trends database and parallel data from Jordan University Hospital. Ambitious future research should deploy the use of machine learning for real-time and predictive analytics which will provide an excellent value for public health services and epidemiological studies.Asian Journal of Medical Sciences Vol.9(5) 2018 57-61",Asian Journal of Medical Sciences,2018.0,10.3126/AJMS.V9I5.20495,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ded67de0581d3c8b410473e123a9ba0edd7237a7,https://www.semanticscholar.org/paper/ded67de0581d3c8b410473e123a9ba0edd7237a7,"Dry Rivers, Scary Strangers: Are Financial And Cyber Crises Alike?","The internet and the financial system show crucial affinities: both are tightly interconnected global networks whose orderly functioning is a prerequisite for economic prosperity. In financial and cyber crises alike, vulnerabilities are a consequence of distorted economic incentives, contagion is fast, and the most serious risk is loss of trust. Lessons learned from financial meltdowns translate to the cybersecurity world: stability cannot be achieved until policies are in place to address all of these issues. Steps have been taken to rectify incentives, as exemplified by recent European Union legislation. Data that helps identify weak nodes are still scarce, notwithstanding recent efforts. The preservation of trust is the hardest challenge: in the financial system, a global governance framework was put in place to help maintain and rebuild confidence at critical junctions, but conflicting national interests make it difficult to establish a cyber equivalent. 1 Please cite as: Biancotti, Claudia and Paolo Ciocca, “Dry Rivers, Scary Strangers: Are Financial and Cyber Crises Alike?,” in Demchak, Chris C. and Benjamin Schechter, eds. Military Cyber Affairs: Systemic Cyber Defense 3, no. 2 (2018). 2 Senior Economist at the Bank of Italy, the Italian central bank. The views here expressed are those of the authors and should not be attributed to the Bank of Italy. 3 Commissioner at Consob, the Italian Securities and Exchange Commission. The views here expressed are those of the authors and should not be attributed to Consob. 1 Biancotti and Ciocca: Are Financial And Cyber Crises Alike? Published by Scholar Commons, 2018 2 Advanced economies are immersed in cyberspace. In 2016, 95 percent of businesses in OECD countries had a broadband internet connection; 77 percent had a web presence. More than half of the adult population had purchased a product or service online, compared to 36 per cent in 2010. As digitalization progresses, a growing share of production and consumption activities depend on connectivity. From an economist’s point of view, there are evident analogies between the internet and the global financial system: both are tightly interconnected networks that provide lifeblood to the real economy, via transfers of information and funding, respectively. Indeed, a financial crisis and a cyber crisis look alike in three key dimensions: (i) vulnerabilities accumulate because of excessive risk-taking on the part of some agents, which eventually translates to systemic risk on account of interdependencies; (ii) disruption can start at a single weak point and spread to the whole system in a matter of days or even hours; (iii) the ultimate casualty is trust: once it is lost, transactions – and the whole economy – can grind to a halt as counterparties disconnect from each other. Policy responses can be deployed to address these problems so that crises can be prevented or at least managed effectively. In the financial system, safeguards have been established over time: examples are strict capital requirements for lenders, orderly resolution procedures for failing institutions, and collection of micro-level data aimed at identification of individual weak nodes. They are not all-encompassing, but they do help reduce the risk. Where cyberspace is concerned, this process is still in its infancy. Some results have been achieved with respect to (i) above. A small but insightful literature on the economics of cybersecurity points out that distorted economic incentives, rather than technically sophisticated attacks, are at the heart of the problem. Software is born vulnerable because of network externalities. For products such as operating systems and messaging platforms, the value increases with the size of the installed base; developers 4 OECD, OECD Digital Economy Outlook 2017, (Paris: OECD Publishing, 2017), 161-171. 5 European Central Bank, “The Eurosystem Household Finance and Consumption Survey: Results from the First Wave” , Statistics Papers Series no. 2 (April 2013): 7-8. 6 See among others: Ross Anderson, “Why Internet Security Is Hard – An Economic Perspective”, Proceedings of the 17 Annual Computer Security Applications Conference (December 2001). Hal Varian, “Managing Online Security Risks”, The New York Times, June 1, 2000. Tyler Moore and Ross Anderson, “Internet Security”, in The Oxford Handbook of the Internet Economy, ed. Martin Peitz and Joel Waldfogel (Oxford: Oxford University Press, 2011). 2 Military Cyber Affairs, Vol. 3 [2018], Iss. 2, Art. 7 https://scholarcommons.usf.edu/mca/vol3/iss2/7 DOI: https://doi.org/10.5038/2378-0789.3.2.1061 3 forego security as they scramble to get to the market first, attract a critical mass of users, and shut competition off. The absence of developer liability for buggy software does not help. The market for cyber defense is plagued by information asymmetries. Vendors know more than their customers: they may have an opportunity to push whatever solution maximizes their own profit, independent of how effective it is. Finally, the cost of cyber attacks in many cases is not fully internalized by the immediate victims: for example, the owner of a vulnerable IoT device that gets recruited into a botnet typically has no statutory liability (yet) for damage caused by the botnet. Some corrective measures have already been introduced, while others are being drafted. In the European Union, the General Data Protection Regulation (GDPR) – coming into force in May 2018 – imposes steep fines to businesses that put the confidentiality of personal data at risk and mandates disclosure of breaches to both authorities and data subjects. The Directive on Security of Networks and Information Systems (NIS), also coming into force this year, introduces cyber protection requirements and incident disclosure obligations for key players in sectors such as energy, finance, and healthcare. A regulation proposal put forth by the European Commission envisages an EU-wide framework for security certification of hardware and software, fashioned after the notoriously strict CE scheme for safety, health and environmental protection. These are necessary steps, but they are not enough; the effects of GDPR and NIS are confined to certain cases or sectors. More theoretical work is needed to define broader principles: generalized liability for damage caused to third parties may be a good idea, yet an ordinary citizen whose email account gets spoofed by phishers should probably not be forced to compensate victims. With respect to (ii), there is still a significant knowledge gap about the location and interconnections of weak nodes. As pointed out by the G7 Finance Ministers and Central Bank Governors in 2017, “reliable, impartial, comprehensive and widely accessible” data on the frequency and economic impact of cyber attacks are still rare. The same goes for information on network and economic connections, e.g. through digital and physical supply chains. Evidence from the Bank of Italy’s business surveys suggests that cyber risk may be concentrated among high-tech, non-ICT businesses, which are more exposed and interesting to attackers compared to low-tech ones, and less proficient at defense than the ICT sector. The data also suggest that mass adoption of relatively simple internet-based solutions, such as e-commerce 7 G7 Finance Ministers and Central Bank Governors, Bari Communiqué, May 12-13, 2017. 8 Claudia Biancotti, “The Price of Cyber (In)security: Evidence from the Italian Private Sector”, Bank of Italy Occasional Papers no. 407 (November 2017). 3 Biancotti and Ciocca: Are Financial And Cyber Crises Alike? Published by Scholar Commons, 2018 4 platforms, cloud computing services or IoT devices is a stronger risk factor than the selective adoption of advanced technologies, like machine learning or industrial robotics. These indications are vital in understanding which sectors of the economy need urgent intervention, be it in terms of awareness campaigns, dedicated incentives, or regulation. The problem sub (iii) is the hardest to solve. After the 2009 financial meltdown, trust was only restored after a series of large-scale, highly controversial injections of public money in the banking system, and substantial reinforcement of a global governance framework which encompasses broad-based organizations such as the Financial Stability Board, the Bank for International Settlements and the International Monetary Fund, regional institutions such as the European System of Financial Supervision, and national authorities. In a cyber crisis, there is no immediately evident equivalent of a public-sector backstop. Perhaps more importantly, a global governance framework is very hard to build because in cyberspace a crisis is generally triggered by an intentional act of aggression; an adversary is in the picture and may serve, directly or indirectly, the interests of a nation-state. In this sense, the right comparison might be with currency or trade wars; the problem is mostly one of political, diplomatic and military relations, especially in a world where the weight of authoritarian governments increases. This is where input from economics is not sufficient and must be complemented by scholarship in the various facets of international relations. 4 Military Cyber Affairs, Vol. 3 [2018], Iss. 2, Art. 7 https://scholarcommons.usf.edu/mca/vol3/iss2/7 DOI: https://doi.org/10.5038/2378-0789.3.2.1061",Military Cyber Affairs,2018.0,10.5038/2378-0789.3.2.1061,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
57b672bbd41fa4fae7b4307191978599513107f4,https://www.semanticscholar.org/paper/57b672bbd41fa4fae7b4307191978599513107f4,Data Engineering Project (Educating For The Future PhUSE WG),"With an expected 100% increase, over the next 3 years, of data from non-EDC sources (such as smartphones, wearables and custom apps) the traditional methods of managing data for clinical trials presents executives with a resourcing headache. As such, many companies are looking for lower cost strategies to sure up this shortfall in resourcing. However, citing case studies from other industries, there are new methodologies/technologies in data engineering which could enable automation of much of the “heavy-lifting” currently practiced in clinical data management and statistical programming. This paper discusses the Data Engineering Project within the PhUSE Computational Science (CS) Working Group, Educating For The Future, with a view to educate clinical data managers in data engineering principles so that they can be prepared, equipped and effective in dealing with the coming “data tsunami” heading to the shores of clinical research. INTRODUCTION Did you realise we are living in the age of the Fourth Industrial Revolution? Perhaps you have been busy downloading a myriad of “apps” designed to make your life easier or connecting on social media, uncovering relationships and associations you didn’t even know you had. Perhaps you have been shopping a global marketplace, comparing prices, quality and availability, all at your fingertips and in a minutes’ time. While this has been happening, the Fourth Industry Revolution has been evolving at exponential proportions ​. Just ask Siri! The term “Industrie 4.0”, was originated in Germany, as a government-led initiative, to transform manufacturing through advanced digital capability. Thus creating the concept of a “smart factory”, based on four key design principles ​: 1. Interconnection of machines, devices, sensor and people 2. Vast amounts of useful information (data) to drive decision making 3. Technical assistance to aid humans, for example to visualise data or to perform tasks that may be of safety concern for a human. 4. The use of cyber-physical systems to make decisions on their own and to perform tasks as autonomously as possible. Emerging from the premise of “Industrie 4.0” is the advent of the term “The Fourth Industrial Revolution” (also referred to as “4IR” or “I4.0”). This term originated in 2016 when described by Klaus Schwab (Founder and Executive Chairman of the World Economic Forum), as a “technological revolution that will fundamentally alter the way we live, work, and relate to one another”. Klaus goes on to describe it as a digital revolution with innovative uses of a combination of technologies that build upon the premise of the third revolution (i.e. electronics and information technology to automate production). As a result, emerging technologies have brought forth advancements in fields such as ​artificial intelligence, robotics, the Internet of Things, autonomous vehicles, 3D printing, nanotechnology, biotechnology, materials science, energy storage, and quantum computing. This rapid evolution will undoubtedly affect industries world-wide, already disrupting many industries, such as travel agencies, video rentals and bookstores​ . The pharmaceutical industry is also experiencing the impacts of I4.0. Digital and mobile technologies has brought on significant advancements in data acquisition and accessibility as it relates to health care and patient data. As reported in the Tufts-Veeva eClinical Landscape study in 2017, data coming from sources such as, smartphones, custom applications, and mobile health are expected to double in the next 3 years ​. Therefore requiring greater capabilities in handling large volumes of data, as well as data from coming in through various data streams and 1 PhUSE EU Connect 2018 formatting. As with other industries, data will become a critical asset to their business and the effective utilisation of this data can play a critical role in driving growth in the business and bringing novel therapies to the patients who need them. In this paper, we will focus on the works of the Data Engineering Project within the Educating For The Future Working Group. With the formation of the Working Group in early 2018, the team had taken on the mission to explore how data engineering techniques, successfully deployed in other industries, could be utilised in the pharmaceutical industry, with a goal to ​facilitate the education ​of the pharmaceutical industry on these techniques. We will share with you some introductory information about Data Engineering and Data Science and explore how embracing new data engineering techniques may affect the industry culture. You will learn about use cases of Data Engineering in other industries and how advances in digital capability have affected their business model. We will also share some of the many software packages and tools available to enable automation, commonly used in Data Engineering and Data Science. Finally we will reflect on the benefits that data standardisation has brought to the pharmaceutical industry and share our vision for disseminating information to facilitate your learning going forward. DATA ENGINEERING To start this learning journey, exploring the term “Data Engineering” opens the door to the vast opportunities and roles available today centered around data. In doing a simple search on the internet, ​“what is data engineering?​”, one will find many posts expressing their understanding of Data Engineering with some variation but also some similarity. However, what is clear is that Data Engineering encompasses the many considerations that need to be taken into account to optimally curate, transform, secure and disseminate data suitable for analysis. As technology and tools have become more advanced, building such a platform and infrastructure requires engineers and architects of both general and specific expertise. The Data Engineer combines knowledge in areas such as software development, infrastructure, data architecture, data warehousing, cloud technology and data cleaning in order to design, build and test solutions that define the pipelines of data throughout the enterprise, making the data accessible to the organisation.​ [5] [27] [31] Optimised Data Engineering appropriately balances the efficiency of an automated process against the cost of development and maintenance of that process, ensuring repetitive processes that require humans to write code, press keys, cut-and-paste and update documents are minimised or eliminated. DATA SCIENCE Often paired with the term “Data Engineering” is also the term “Data Science”. According to Kelle O’Neal and Charles Roe: “Data Science allows enterprises the ability to turn their data assets into a narrative. Data Science allows that narrative to be expanded across timelines, in different data spaces that trace from the past into the future, with much more involved questions and answers about an enterprise, different potential outcomes, and repercussions based on recommendations. Data Science employs a range of mathematical, business, and scientific techniques to solve complex problems about an organisation’s data assets.” ​ In contrast, the focus of the Data Engineer is on the process from data curation to dissemination and the focus of the Data Scientist is on the analytics of the data, thus extracting knowledge from the data. To achieve quality data capture, near-real-time accessibility and meaningful analytics, one cannot function without the other, and effective teamwork optimises the value of each role. As such, an analytics team would be composed of distinct roles/capabilities​ : ● Data Engineers (in areas such as database architecture, database development, machine learning architecture, ETL scripting , etc.) ● Data Scientists ● Business Analysts Data Engineering brings together the broad expertise, of these roles, to ensure the data are curated and accessible to the Data Scientist, and in our environment today, this process is becoming more and more complex. Therefore, 2 PhUSE EU Connect 2018 expertise in curating big-data and data of varying formats (structured and unstructured) is a critical core competency to optimise the potential impact of these digital assets (i.e. the data). The Data Scientist works deep in the data, utilizing various tools and techniques to discover patterns in the data that may drive decision making for the business. Optimising utilisation of the data to enable accurate conclusions can bear greater value to the organisation. As an example, per Tom Eunice’s post, “a fraud-detection algorithm may be very accurate when based on many months of historical data. However, months of historical data may not always be available. Designing a fraud-detection model that is still accurate using historical data from only a few days would be of more use and more practical to implement.” ​ The Business Analyst helps the Data Scientist understand the meaning of the data and the relevance of any discovered relationships. Initially, uncovering relationships in the data and upon further investigation, identifies meaningful patterns that may reveal information that otherwise may not have been known. ​ As you will see in the sections to follow, the full complement of the roles in an analytics team is what drives the business value. One discipline without the other (e.g. data engineering without data science) will result in missed opportunities. In the sections to follow, we often refer to Data Engineering, however, due to the close ties to Data Science, some examples elude to both Data Engineering and Data Science. USE CASES FROM OTHER INDUSTRIES In this section, we present three use cases from the transportation, retail, and agricultural industry. The use cases illustrate the importance and usage of Data Engineering. In each example the data collected, the consumer of the data, and the value of the organisation is reviewed. Similarities and potential applications to the pharmaceutical industry are discussed. UBER When",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
89512385796bbef74a0e73cb14813cefe51cc9a6,https://www.semanticscholar.org/paper/89512385796bbef74a0e73cb14813cefe51cc9a6,"Brain-CODE – A Comprehensive Informatics Platform for Research Data Federation , Query and Analysis","The Ontario Brain Institute, in partnership with the Indoc Consortium and Baycrest, has built Brain-CODE – a comprehensive neuroinformatics platform for managing the acquisition, curation, integration and analysis of multi-dimensional data for over 240 researchers from over 40 research institutions. BrainCODE’s architecture is designed to incorporate and integrate a wide range of data management, curation and analysis tools. Clinical assessments in the form of clinician-administered and patient-reported outcomes are collected using REDCap and OpenClinica. Imaging and physiological measures (MRI, EEG, etc.) are managed using SPReD, an XNAT-based system. Brain-CODE also supports multiple omics modalities with the LabKey system serving as a repository for sample information, raw data files, processed data and associated metadata. Despite recent advances, research datasets largely exist in isolation with no practical avenue for sharing and pooling across data sources. Brain-CODE addresses this challenge through a data federation system utilizing a combination of data warehousing and NoSQL approaches to aggregate data across modalities and databases. This enables query and analysis capabilities which would otherwise require researchers to invest significant study-specific manual effort and technical resources. Brain-CODE’s flexible and scalable architecture can suit a variety of research settings and has been recently deployed at the Centre for Addiction and Mental Health. Machine Learning for Brain Health Symposium",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
02c6278b0aa5ab8687ba02a68520e961343d2202,https://www.semanticscholar.org/paper/02c6278b0aa5ab8687ba02a68520e961343d2202,ARX Model of a Residential Heating System With Backpropagation Parameter Estimation Algorithm,"Model predictive control (MPC) strategies hold great potential for improving the performance and energy efficiency of building heating, ventilation, and air-conditioning (HVAC) systems. A challenge in the deployment of such predictive thermostatic control systems is the need to learn accurate models for the thermal characteristics of individual buildings. This necessitates the development of online and data-driven methods for system identification. In this paper, we propose an autoregressive with exogenous terms (ARX) model of a thermal zone within a building. To learn the model, we present a backpropagation approach for recursively estimating the parameters. Finally, we fit the linear model to data collected from a residential building with a forced-air heating and ventilation system and validate the accuracy of the trained model. INTRODUCTION Heating, ventilation, and air-conditioning (HVAC) account for 43% of commercial and 54% of residential energy consumption [1]. Space heating alone accounts for 45% of all residential energy use. HVAC systems are an integral part of buildings responsible for regulating temperature, humidity, carbon dioxide, and airflow, conditions which directly impact occupant health and comfort. Estimates suggest that component upgrades and advanced HVAC control systems could reduce building energy ∗Address all correspondence to this author. usage by up to 30% [2]. Such intelligent systems can improve the efficiency of building operations, better regulate indoor conditions to improve air quality and occupant comfort, and enable buildings to participate in demand response services to improve power grid stability and reduce energy related carbon emissions [3–8]. To effectively control the operation of an HVAC system, it is essential that a model predictive controller incorporate an accurate mathematical representation of a building’s thermal dynamics. The processes that determine the evolution of temperatures within a building are complex and uncertain. A reliable model improves the ability of a controller to forecast conditions and meet cost, efficiency, and/or comfort objectives [9, 10]. Simulation software, such as EnergyPlus and TRNSYS, is capable of high fidelity modeling of building HVAC systems. These mathematical models play a crucial role in the architectural and mechanical design of new buildings, however, due to high dimensionality and computational complexity, are not suitable for incorporation into HVAC control systems [9, 11]. The American Society of Heating, Refrigeration, and AirConditioning Engineers (ASHRAE) handbook [12] describes how to determine the thermal resistance values of a building surface given it materials and construction type. However, for existing buildings, details about the materials in and construction of walls and windows may be difficult to obtain or nonexistent [13]. Additionally, modifications to the building or changes brought about by time and use (e.g. cracks in windows 1 Copyright c © 2017 by ASME or walls) further diminish the potential for characterizing a building based on design or construction information. Therefore, an ideal control-oriented model would capture the predominant dynamics and disturbance patterns within a building, enable accurate forecasting, adapt to future changes in building use, provide a model structure suitable for optimization, and be amenable to real-time data-driven model identification methods. For these reasons, low order linear models are widely employed for control-oriented thermal building models [13–15]. Such models trade complexity and accuracy for simplicity and efficiency. In this paper, we present an autoregressive with exogenous terms (ARX) model for the thermostatic control of buildings and a recursive backpropagation method for parameter estimation. The structure of the linear model enables the approximate identification of unmodeled dynamics, in particular higher-order dynamics and time delays related to changes in the mechanical state of the system. By employing a recursive parameter estimation technique, we are able to perform online data-driven learning of the model. We do not model heating from solar gain, building occupants, or equipment. This does not restrict the applicability of this work because the model structure can be extended for such cases. By estimating these effects with a single time-varying gain, we produce a simpler model better suited for predictive control. This paper is organized as follows. Section 2 presents our autoregressive exogenous thermal model and Section 3 overviews the parameter estimation problem. Section 4 formulates our recursive parameter estimation approach employing backpropagation and stochastic gradient descent. Section 5 provides numerical examples of our proposed model and algorithm for the parameter estimation of an apartment with a forced-air heating and ventilation system. Finally, Section 6 summarizes key results. BUILDING THERMAL MODEL LINEAR THERMAL MODEL In this paper, we focus on the modeling of an apartment with a forced-air heating system. To begin, we consider a simple linear discrete time model [4, 5, 16, 17] T k+1 = θaT k +θbT k ∞ +θcm k +θd (1) where T k ∈ R, T k ∞ ∈ R, and mk ∈ {0,1} are the indoor air temperature (state, ◦C), outdoor air temperature (disturbance input, ◦C), and heater state (control input, On/Off), respectively, at time step k. The parameters θa and θb correspond to the thermal characteristics of the conditioned space as defined by θa = exp(−∆t/RC) and θb = 1−exp(−∆t/RC), θc to the energy transfer due to the system’s mechanical state as defined by θb = (1− exp(−∆t/RC))RP, and θd to an additive process accounting for energy gain or loss not directly modeled. The linear discrete time model (1) is a discretization of a RCequivalent continuous time model and thus derived from (very basic) concepts of heat transfer. As noted in [5, 17], the discrete time model implicitly assumes that all changes in mechanical state occur on the time steps of the simulation. In this paper, we assume that this behavior reflects the programming of the systems being modeled. In other words, we assume that the thermostat has a sampling frequency of 1/(3600∆t) Hz or once per minute. AUTOREGRESSIVE EXOGENOUS THERMAL MODEL The linear discrete time model (1) is capable of representing the predominant thermal dynamics within a conditioned space. Unfortunately, because it does not capture any higher-order dynamics or time delays related to changes in the mechanical state of the system, the model is fairly inaccurate in practice. Research into higher-order RC models, in particular multi-zone network models and the modeling of walls as 2R-1C or 3R-2C elements, have shown potential for producing higher fidelity building models [13–15]. However, this comes at the cost of increasing the model complexity and the need for temperature sensing (in particular, within interior and exterior walls). In this paper, we present an autoregressive exogenous (ARX) model capable of approximating dynamics related to trends in the ambient temperature and to changes in the mechanical state of the system. We note that the linear discrete time model (1) is, by definition, a first-order ARX model. The distinguishing characteristic of the ARX model presented below is that the model is higher-order with respect to the exogenous input terms. By increasing the number of exogenous input terms, we can better approximate observed dynamics in the systems. However, we will not pursue a physics-based justification for the number of exogenous terms and thus the ARX model represents a slight departure from the practice of increasing the model order through RC-equivalent circuit modeling. Our autoregressive exogenous (ARX) thermal model is given by T k+1 = θaT k + s−1 ∑ i=0 (θb,iT k−i ∞ +θc,im )+θd (2) where T k ∈ R, T k ∞ ∈ R, and mk ∈ {0,1} are the indoor air temperature (state, ◦C), outdoor air temperature (disturbance input, ◦C), and heater state (control input, On/Off), respectively, at time 2 Copyright c © 2017 by ASME step k. The order of the exogenous terms (and thus the number of θb and θc parameters) is given by s. The ARX model can be expressed more compactly as T k+1 = θaT k +θ T b T k ∞ +θ T c m k +θd (3) where T k ∈ R, T∞ ∈ Rs, and mk ∈ {0,1}s are the indoor air temperature (state, ◦C), previous outdoor air temperatures (disturbance input, ◦C), and previous heater states (control input, On/Off), respectively, at time step k. Lastly, θb ∈Rs and θc ∈Rs are the parameters of the exogenous terms. PARAMETER ESTIMATION BACKGROUND A fundamental machine learning problem involves the identification of a linear mapping",,2017.0,10.1115/DSCC2017-5315,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
99f205fe60616b4f087ba895589b0894e7b9dbca,https://www.semanticscholar.org/paper/99f205fe60616b4f087ba895589b0894e7b9dbca,EDXL-LD and Architectural Tactics towards Information Sharing and Interoperability in Emergency Context,"s of Scientific Papers-WADEM Congress on Disaster and Emergency Medicine 2017 EDXL-LD and Architectural Tactics towards Information Sharing and Interoperability in Emergency Context Julia Kantorovitch, Jarmo Kalaoja, Ilkka Niskanen VTT Technical Research Center of Finland, Espoo/Finland Study/Objective: The objective of this study is to propose a new architectural approach supported by information models, to manage knowledge in the dynamic emergency context towards interoperable knowledge sharing and reuse. Background: The knowledge systems for emergency management are based on evolvable information provided by various actors, by diverse collections of sensors and information supplied by human volunteers. In order to achieve a common operational picture situation awareness, various knowledge, vocabulary and information models need to be aligned. This requires extendable time, application context architecture and models representing detailed evolvable knowledge about the types of adverse events, their potential impact and the means and resources that are best suited for response. The existing semantic research has a potential to address the identified needs, however the reported ontologies are rarely publically available, and they are also disconnected from widely used standard data models, data-exchange formats, and protocols related to emergency management. Methods: The literature review and the inputs provided by domain experts in the CONCORDE consortium and WHO, have facilitated the addressing of shortcomings and challenges identified above. Results: The Emergency Data Exchange Language (EDXL) based domain specific standards are taken as a base to create domain specific vocabularies. Vocabularies are published as a Linked Data (LD) and can be downloaded from GitHub software repository https://github.com/OntoRep/EDXL. The Model-View-Presentation (MVP) based architectural tactics as a software engineering pattern (see below) are exploited to achieve a desired extensibility and dynamicity of the system at its deployment stage. Conclusion: By keeping applications’ business logic separate from data and semantics, the underlying knowledge models can evolve without necessarily requiring changes to the interfaces and applications built on top of the models. Prehosp Disaster Med 2017;32(Suppl. 1):s228 doi:10.1017/S1049023X17005878 The J-SPEED: A Medical Relief Activities Reporting System for Emergency Medical Teams in Japan Tatsuhikiko Kubo, Hisayoshi Kondo, Yuichi Koido 1. Department Of Public Health, University of Occupational and Environmental Health, Kitakyusyu/Japan 2. National Disaster Medical Center, Tokyo/Japan Study/Objective: To introduce the J-SPEED; medical relief activities reporting system for Emergency Medical Teams (EMTs) of Japan. Background: During a disaster, information gathering and analysis are key elements for better coordination and timely response. Previous cases revealed that EMTs sometimes became the only capacity which could report medical, or more broadly health situations to a coordination body, and standardization of the reporting process from EMTs to the EMT Cortication Cell (EMTCC) will allow for better coordination, and for strengthening of the disease early warning system, since EMTs will act as additional sentinel reporting sites. One good existing model for this issue is the Surveillance in Post Extreme Emergencies and Disasters (SPEED) system employed in the Philippines. The SPEED was developed by Philippine’s Department of Health and the WHO in 2010. Based on the lessons learned from relief mission of the Japan Disaster Relief Medical Team against the super typhoon Yolanda in 2013, a Japanese version of the SPEED, so called J-SPEED has been developed and published in 2015. Methods: Field study. Results: The J-SPEED was first activated at the Kumamoto earthquake which occurred on April 14, 2016. During the 48 days of response, EMTs from various affiliation sent 1,828 daily reports to the EMTCC, which represented medical demand of 8,089 patients. Standardized information processing and quantitative information made communications among stakeholders efficient, and supported evidence, consensus based decision making by the local authority. Conclusion: Employment of the J-SPEED drastically changed the EMT coordination in Japan. Countries which don’t have a relevant system can easily set up a national reporting system utilizing the SPEED framework. Prehosp Disaster Med 2017;32(Suppl. 1):s228 doi:10.1017/S1049023X1700588X How do we Measure Severity? An Assessment of Five Indexes used in Sudden Onset Disasters and Complex Emergencies to Measure Severity and Risk Anneli Eriksson, Martin Gerdin, Thorkild Tylleskär, Johan Von Schreeb 1. Public Health Science, Karolinska Institutet, Stockholm/Sweden 2. Centre For International Health, Bergen University, Bergen/Norway 3. Department Of Public Health Sciences, Karolinska Institutet, Stockholm/Sweden SITUATIONAL AWARENESS SYSTEMS Prehospital and Disaster Medicine Vol. 32, Supplement 1 Study/Objective: The aim was to, 1) study the relation between disaster outcomes after earthquakes, expressed as number of dead and injured, and the performance of five preidentified severity, and risk-scoring indexes, 2) to inform a model that in an initial phase of a disaster can be used to predict severity and levels of need, and thereby guide toward the appropriate levels of response. Background: A disaster is as an event that overwhelms local capacity, necessitating national or international assistance. Disasters can be categorized, based on the type of hazard causing them. An earthquake is a hazard that can lead to a disaster. The disaster-severity depends on the magnitude of the hazard, underlying vulnerability, the level of exposure, coping capacity and the disaster response. While assistance should be based on needs, determined by the severity of a situation, there is no recognized way to compare severity between disaster contexts. Several initiatives have been developed to provide information on global severity and risks in disaster situations. In this study we compare five indexes and their ability to define severity: GDACs, GEO, KI’s 7-need, INFORM and ECHO’s Crisis index. Methods: We did a mapping of the existing indexes and indicators used. Index-scores were standardized and then compared with the number of dead and injured as an absolute outcome, in earthquakes with magnitude equal to or higher than 6,5 that occurred in populated areas, between year 2001 and November 2016. Results: The five indexes evaluated were all indicating the severity after the examined earthquakes. There was not one single index that gave an absolute correlation. Indexes built on higher numbers of indicators had several indicators that gave identical information. Conclusion: It is possible to predict the severity of a disaster through proxy indicators. The number of indicators used is not automatically increasing the preciseness or validity of the outcome. Prehosp Disaster Med 2017;32(Suppl. 1):s228–s229 doi:10.1017/S1049023X17005891 Enhanced Situational Awareness through a Decision Support Service for Optimal Allocation of Resources and Response Capacity Irene Christodoulou, George M. Milis, Panayiotis Kolios, Christos Panayiotou, Marios Polycarpou, Ilkka Niskanen 1. Kios Research Center For Intelligent Systems And Networks, University of Cyprus, Nicosia/Cyprus 2. VTT Technical Research Center of Finland, Espoo/Finland Study/Objective: We designed and developed e-services, aiming to support the decision makers during various contexts of medical emergency response, offering them machine-aided enhanced situational awareness. Background: Currently, decisions are being made by human experts with hands-on experience in emergency fields. However, in most cases, experts do not have the required computational capacity to process the relevant heterogeneous information and perform informed decisions. Evidently, time is a very critical parameter in emergency situations, especially in large-scale incidents with large number of casualties. Methods: Taking this into account the services we develop, are based on the mathematical modeling of optimization problems for timely resources’ allocation, addressing different phases of the response. The formulated problems address: i) the optimal allocation of Emergency Medical Services (EMS) units (in terms of demand satisfaction and time), to active emergency incident fields, ii) the optimal allocation (in terms of exploiting their capacities and response time) of EMS staff to tasks on the incident field such, as triage and retrieval running, transferring of patients to medical treatment area, offering medical treatment, and iii) the optimal allocation (in terms of profile matching, demand satisfaction and time) of patients to EMS vehicles and subsequently to first receivers (hospitals). The services are supported by semantic modeling of EMS vehicles, hospital, staff and patients profiles, as well as by machine learning tools that estimate demand for resources given historical emergency incident data. The services offer clear interfaces, so as to be interoperable with existing emergency management systems, as long as access to the necessary information is given. Results: Our solution achieves the recommendation on allocation of resources, based on real-time collected information from the emergency field. Conclusion: Further work will focus on modeling different cost functions in the optimization, so as to customize the recommendations based on incident and/or decisionmaker needs. Prehosp Disaster Med 2017;32(Suppl. 1):s229 doi:10.1017/S1049023X17005908 Comparison of UAV Technology vs No UAV Technology in Identification of Hazards at a MCI Scenario in Primary Care Paramedic Students Trevor N. Jain, Aaron Sibley, Henrik Stryhn, Ives Hubloue 1. Biology (paramedicine), University of Prince Edward Island/ Holland College, Charlottetown/PE/Canada 2. H",Prehospital and Disaster Medicine,2017.0,10.1017/S1049023X17005878,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7b4b4b0c6aed5e6f850872b52ea1e4d3457b2b6c,https://www.semanticscholar.org/paper/7b4b4b0c6aed5e6f850872b52ea1e4d3457b2b6c,"The Semantic Web: Research and Applications, 5th European Semantic Web Conference, ESWC 2008, Tenerife, Canary Islands, Spain, June 1-5, 2008, Proceedings",,ESWC,2008.0,10.1007/978-3-540-68234-9,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,https://www.semanticscholar.org/paper/4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,Implementing Operational Analytics using Big Data Technologies to Detect and Predict Sensor Anomalies,"Operational analytics when combined with Big Data technologies and predictive techniques have been shown to be valuable in detecting mission critical sensor anomalies that might be missed by conventional analytical techniques. Our approach helps analysts and leaders make informed and rapid decisions by analyzing large volumes of complex data in near real-time and presenting it in a manner that facilitates decision making. It provides cost savings by being able to alert and predict when sensor degradations pass a critical threshold and impact mission operations. Operational analytics, which uses Big Data tools and technologies, can process very large data sets containing a variety of data types to uncover hidden patterns, unknown correlations, and other relevant information. When combined with predictive techniques, it provides a mechanism to monitor and visualize these data sets and provide insight into degradations encountered in large sensor systems such as the space surveillance network. In this study, data from a notional sensor is simulated and we use big data technologies, predictive algorithms and operational analytics to process the data and predict sensor degradations. This study uses data products that would commonly be analyzed at a site. This study builds on a big data architecture that has previously been proven valuable in detecting anomalies. This paper outlines our methodology of implementing an operational analytic solution through data discovery, learning and training of data modeling and predictive techniques, and deployment. Through this methodology, we implement a functional architecture focused on exploring available big data sets and determine practical analytic, visualization, and predictive technologies. APPROACH This study developed an operational analytics implementation that uses Big Data technologies and machine learning algorithms to determine and predict sensor anomalies. A previous study [1] showed that Big Data Analytics can uncover anomalies that may be missed through conventional analyses. This study enhances that effort and shows a methodology to implement operational analytics that can be applied toward common solutions for data analysis. Our operational analytics implementation relies on continuous learning from historical data to analyze data in the stream of real-time operations. In the previous study, where data was identified that can be used to uncover anomalies, this implementation extends that approach and now identifies trends and correlations that reveal anomalies that can be missed by traditional analytic techniques with limited datasets. This study adopted a three-step methodology to implementing operational analytics – Discovery, Modeling and Operations as shown in Fig. 1. Copyright © 2016 Advanced Maui Optical and Space Surveillance Technologies Conference (AMOS) – www.amostech.com Fig. 1. Operational Implementation Approach Fig. 1 shows the three steps to implement operational analytics and the continuous feedback between learning and operational deployment. The following sections will elaborate on the methodology employed as applied to a realworld problem of analyzing large datasets such as would be encountered at an operational site.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64e29d129df83dc3c5bf699f6610ed0cb16fdaed,https://www.semanticscholar.org/paper/64e29d129df83dc3c5bf699f6610ed0cb16fdaed,A Framework for Enhancing the Query and Medical Record Representations for Patient Search,"This thesis focuses on enhancing the search of electronic medical records (EMRs), with the aim of identifying patients with medical histories relevant to the medical conditions stated in a text query. During retrieval, a healthcare practitioner indicates a number of inclusion criteria describing the medical conditions of the patients of interest. However, finding patients with particular medical conditions is challenging, due to the implicit knowledge inherent within the patients' medical records and queries - such knowledge may be known by medical practitioners, but may be hidden from an information retrieval (IR) system. For instance, the mention of a treatment such as a drug may indicate to a practitioner that a particular diagnosis has been made for the patient, but this diagnosis may not be explicitly mentioned in the patient's medical records. Moreover, the use of negated language (e.g. 'without', 'no') to describe a medical condition of a patient (e.g. the patient has no fever) may cause a search system to erroneously retrieve that patient for a query when searching for patients with that medical condition (e.g. find patients with fever). To attain effective retrieval performance, we hypothesise that, in a patient search system, both the information needs and patients' histories should be represented based upon the medical decision process. In particular, this thesis argues that since the medical decision process typically encompasses four aspects (symptom, diagnostic test, diagnosis and treatment), a patient search system should take into account these aspects and apply inferences to recover the possible implicit knowledge. We postulate that considering these aspects and their derived implicit knowledge at three different levels of the retrieval process (namely, sentence, medical record and interrecord levels) enhances the retrieval performance. Indeed, we propose a novel framework that can gain insights from EMRs and queries, by modelling and reasoning upon informationduring retrieval in terms of the four aforementioned aspects at the three levels of the retrieval process, and can use these insights to enhance patient search. Firstly, at the sentence level, we extract the medical conditions in the medical records and queries. In particular, we propose to represent only the medical conditions related to the four medical aspects in order to improve the accuracy of our search system. In addition, we identify the context (negative/positive) of terms, which leads to an accurate representation of the medical conditions both in the EMRs and queries. In particular, we aim to prevent patients whose EMRs state the medical conditions in the contexts different from the query from being ranked highly. For example, preventing patients whose EMRs state ""no history of dementia"" from being retrieved for a query searching for patients with dementia. Secondly, at the medical record level, using external knowledge-based resources (e.g. ontologies and health-related websites), we leverage the relationships between medical terms to infer the wider medical history of the patient in terms of the four medical aspects. In particular, we estimate the relevance of a patient to the query by exploiting association rules that we extract from the semantic relationships between medical terms using the four aspects of the medical process. For example, patients with a medical history involving a CABG surgery (treatment) can be inferred as relevant to a query searching for a patient suffering from heart disease (diagnosis), since a CABG surgery is a treatment of heart disease. Thirdly, at the inter-record level, we enhance the retrieval of patients in two different manners. First, we exploit knowledge about how the four medical aspects are handled by different hospital departments to gain a better understanding about the appropriateness of EMRs created by different departments for a given query. We propose to aggregate EMRs at the department level (i.e. inter-record level) to extract implicit knowledge (i.e. the expertise of each department) and model this department's expertise, while ranking patients. For instance, patients having EMRs from the cardiology department are likely to be relevant to a query searching for patients who suffered from a heart attack. Second, as a medical query typically contains several medical conditions that the relevant patients should satisfy, we propose to explicitly model the relevance towards multiple query medical conditions in the EMRs related to a particular patient during retrieval. In particular, we rank highly those patients that match all the stated medical conditions in the query by adapting coverage-based diversification approaches originally proposed for the web search domain. Finally, we examine the combination of our aforementioned approaches that exploit the implicit knowledge at the three levels of the retrieval process to further improve the retrieval performance by adapting techniques from the fields of data fusion and machine learning. In particular, data fusion techniques, such as CombSUM and CombMNZ, are used to combine the relevance scores computed by the different approaches of the proposed framework. On the other hand, we deploy state-of-the-art learning to rank approaches (e.g. LambdaMART and AdaRank) to learn from a set of training data an effective combination of the relevance scores computed by the approaches of the framework. In addition, we introduce a novel selective ranking approach that uses a classifier to effectively apply one of the approaches of the framework on a per-query basis. This thesis draws insights from a thorough evaluation and analysis of the proposed framework using a standard test collection provided by the TREC Medical Records track. The experimental results show the effectiveness of the framework. In particular, the results demonstrate the importance of dealing with the implicit knowledge in patient search by focusing on the medical decision criteria aspects at the three levels of the retrieval process.",SIGIR Forum,2015.0,10.1145/2795403.2795420,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
52d7872a825e8b058c2a281b49d7a0a447abb7c0,https://www.semanticscholar.org/paper/52d7872a825e8b058c2a281b49d7a0a447abb7c0,Automatic x-ray screening for tuberculosis,"Tuberculosis (TB) is widespread among immunocompromised HIV-positive patients in developing nations that have scarce medical resources. Tackling the disease, while at the same time avoiding complications of antiretroviral (HIV) treatment, requires rapid-result tests for detecting infection. Previously, healthcare practitioners determined TB exposure using immune response skin tests. However, if the patient had previously been vaccinated, this could compromise the accuracy of the result, and the test was therefore not a true indicator of active disease. A recent definitive test for TB diagnosis based on DNA analysis1 speeds up earlier sputum culture microscopy-based methods, but is expensive and inappropriate for population screening. Consequently, analyzing chest x-ray (CXR) images remains a relatively inexpensive and mandatory part of every patient evaluation. In developing regions, the challenge is to address the imbalance between the size of the affected population and the available radiology services. To achieve this aim—and to fulfill the objectives of the National Institutes of Health global health initiative—we have conducted research and development in advanced biomedical image diagnostics, and translated it into low-cost automated tools. This article highlights our work in developing and deploying a reliable, low-cost, automatic screening system for pulmonary TB in CXR images. We have conducted population screening in western Kenya in collaboration with Academic Model Providing Access To Healthcare (AMPATH), an NGO that provides treatment to some 200,000 HIV-positive patients. For TB infection screening, we provide lightweight digital x-ray units that are mounted in custom-designed trucks (see Figures 1 and 2). Using a lowpower computer, the system analyzes a digital CXR image immediately after acquisition (see Figure 3) using advanced image processing and machine learning algorithms, and Figure 1. An HIV-positive patient being led to the truck-mounted x-ray unit for tuberculosis (TB) screening.",,2015.0,10.1117/2.1201509.006128,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5b014e55d39682ede47cf248d3c0a7d6973577b,https://www.semanticscholar.org/paper/d5b014e55d39682ede47cf248d3c0a7d6973577b,Beyond 5G Challenges: White Paper,"This white paper was prepared as an output from the highly successful EPSRC sponsored CommNet 5G workshop on 13 March 2014. The objective of the paper is to describe some of the major research challenges as perceived by the research community, where successful solutions ought to be implemented in future wireless systems in the next ten years. Introduction – Beyond 5G Wireless Standards Though the most recent fourth generation (4G) standard for cellular mobile communication systems, termed Long Term Evolution Advanced (LTE-A), targets downlink and uplink peak data rates of 1 Gbit/s and 500 Mbit/s, respectively, attention has already turned to a future 5G system where not only higher data rates are sought but also significant increases in throughput area efficiency (i.e. bit/s/km 2 ) to meet exponentially growing data demands. 5G will see a stronger interplay between communications, computing and control communities 1 . Rates at the wireless edge will be on a par with wireline connectivity, largely guaranteed by the heavy “densification” of access points and heavily liberated spectral resources. We will see the operators’ core network thinned and flattened further, due to e.g. a heavily reduced number of packet-gateways; many more direct Internet Protocol (IP)-injection points; the X2 interface carrying more traffic than just control messages; virtualization and cloudification being core to the design; etc. The Internet will be strictly software defined network (SDN)-enabled with many competing connectivity protocols offering a truly deregulated end-to-end connectivity to achieve a high Quality of Experience (QoE). For standards Beyond 5G (B5G) there are important challenges which require radical new solutions:  Ever-Growing Rate. Cisco forecasts 16 Exabytes of data sent through mobile networks in 2018, equivalent to 1.8 million years of HD video every month 2 , threatening a ‘radio frequency spectrum crunch’ in wireless communications. This trend is fuelled by new wireless paradigms such as the Internet-of-Everything (IoE), where devices rather than people wirelessly communicate over the Internet. The expectation is that by 2020, there will be over 1000 wireless devices per person on the planet. This will result in over 500 billion sensors being connected to the Internet in 2030. The IoE, a more general term for a wider range of applications than the Internet of Things (which envisages predominantly low data rate sensors), is heavily based on machine-to-machine (M2M) technology and facilitates markets such as the smart grid, home automation, e-health, and intelligent transportation. 1 See D. Soldani, ""Report on the 5G European Summit (5G ES), Munich, on Feb 10th,"" Next Generation Network Infrastructures, EIF Breakfast Debate, European Parliament, Feb. 19th, 2014. 2 See http://tinyurl.com/mokcut3  Architecture Deficiencies. Current network architectures lack the waveforms and signalling strategies and are too rigid to accommodate new and yet unforeseen services/functionalities and also inflexible in supporting a wide range of expected services of IoE, M2M and mobile broadband in general.  Energy Usage. Lastly, the operation of existing wireless networks requires an unsustainable amount of energy which is equivalent to the entire air-traffic network. In the year 2020, when B5G network designs are likely to commence, we expect to see a superstandard emerge which will orchestrate efforts of the 3GPP, the IETF, the IEEE, and other related standards development organisations. For the UK to take a leading role in research B5G systems there needs to be a solid University research base. Given the EPSRC typically funds such projects, an early lead with strong proposals will have a strong impact onto B5G developments globally. The following sections outline the technical challenges, as viewed by our academic community. Beyond 5G Architecture & Orchestration Any B5G communications architecture will necessitate a quantum-leap in design to cope with the predicted information tsunami, with inherent network scalability, intelligence and orchestration being core to the design. Scalability can only be achieved with a complete flattening, and thus complete removal, of the Core network. A flat architecture allows any IP-enabled system, whether incumbent or emerging, to offer seamless data delivery. This however poses significant research challenges related to core properties of mobile networks, such as mobility and billing. To this end, device-centric mobility solutions will likely emerge which will redefine our notion of cellular deployments. Furthermore, virtualized escrow-like control entities, completely decoupled from data bearers, will ensure appropriate billing and control. To cope with the exponentially increasing data and control flux, the fairly simple (in operation) network routers will need to be replaced by highly intelligent, individually as well as systememergent, entities which are able to curb traffic at the source as well as on the fly. Unprecedented research challenges lay ahead with self-learning middleware able to understand and interpret traffic injected from unknown systems, advanced data science methods understanding traffic content and thus facilitating best delivery mechanisms, quantumalgorithmic routers able to find (close-to) optimal delivery routes in shortest time, etc, all will be the norm in a B5G system. Ultra Dense Cell Networks Small cells, heterogeneous networks or Hetnets (which comprise multiple radio standards, e.g. cellular and Wi-Fi) and massive MIMO (multiple-in multiple-out) antenna technologies have been investigated separately, whereas significant benefits may be derived by integration of these technologies. A massive MIMO system scales up conventional MIMO by seeking to adopt possibly hundreds of antenna elements at a base station to simultaneously serve tens of high data rate users within the same frequency band. Aggressive spatial multiplexing and large array gain offers large increases in capacity combined with a reduction in transmission power per user. The high density deployment of small cells also offers high capacity gains in a cost and energy efficient manner through the intense reuse of the frequency spectrum. The shorter distances between the base station and user result in reduced path-loss and total network transmit power. By combining small and large cells in a heterogeneous network, an efficient architecture is achieved whereby small cells meet the needs of traffic hot spots while large cells provide reliable coverage for high mobility users. However, the dense deployment of small cells necessitates wideband backhaul connections. There is significant merit in combining these technologies such that the large cell massive MIMO technique is applied as both a backhaul connection to the network and as fronthaul to serve, via wireless, multiple small cell basestations with direct user support. Wireless backhaul is considerably easier to set-up than a cable backhaul and it enables simpler reconfiguration and upgrading. As massive MIMO must support a number of users directly as well as the small cells, the choice of frequency (in-band or out-band) has important implications for inter-cell interference management. In general, out-band signalling requires a less complex interference management regime but at the expense of failing to realise the largest possible capacity. Further options, in terms of time vs frequency division duplex operation, provide additional opportunities for system optimization. The following research is key to achieving the above goals:  New waveforms that allow scalability from ultra high density cells/high capacity to large coverage (100% coverage availability) and low data rates per device expected for IoE;  Interference management in ultra dense cells and in hetnets;  Hyper transceivers for cooperative ultra dense cells;  Co-existence between license and license-exempt bands;  Full duplex radio technologies;  Exploitation of different antenna polarizations as new degrees of freedom for data transmission. Reconfigurable Hardware design challenges from RF to THz It is inevitable fact that future spectrum is going to be highly fragmented, ranging from frequencies below 6 GHz to the millimeter(mm)-band and THz. New hardware design and manufacturing paradigms are key to the exploitation of such a fragmented spectrum and in particular for the mm-wave part of the spectrum, essential for achieving the data rates required for B5G systems. Electronically-steered high-gain 3D antennas and high levels of RF/DSP integration are essential, as demonstrated in Samsung’s 28 GHz 64-antenna system 3 . With unprecedented aggregate data rates in the backbone network, fibre connections and wireless backhaul at E/W-bands and beyond will be required. It is an immense challenge to realise hardware (transceivers, filters, power amplifiers, antennas) at frequencies from 28 GHz to 300 GHz, and beyond, with the low manufacturing costs demanded by network operators. Silicon RFIC technology is the key enabler, potentially even up to 1 THz, but considerable advances in RF design techniques are required to realise complete B5G subsystems, with research required in:  Concurrent and switchable multi-band mm-wave power amplifiers that are ultra linear and power efficient; 3 See: http://www.commnet.ac.uk/documents/comment_5g_workshop_130314/2_Samsung_5G.pdf  Reconfigurable and ultra broadband transceivers for all-spectrum access;  Tuneable filters and multiplexers with very high selectivity and linearity;  Steerable and multiband antennas integrated with RF transceivers and DSP with advanced new packaging solutions;  mm-wave phase-locked loops with fast switching and low spurious;  New transceiver architectures, working hand-in-hand with DSP researchers;  Low loss mm-wave to optical conversion. Furthermore, while mm-waves are key to providing the expected > 10 Gbit/s B5G sy",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b4acbd2c49b085a65466f84e15f84c85a814f78e,https://www.semanticscholar.org/paper/b4acbd2c49b085a65466f84e15f84c85a814f78e,Data Dissemination in Mobile Phone Sensor Networks,"Deploying sensors over large areas is costly in terms of configuration, hardware, and maintenance. Using onboard sensors of today mobile phones can significantly reduce the expenses in monitoring areas and disseminating events or data. Via the available short-range Bluetooth and/or WiFi interfaces, measured data are not only gradually delivered, but also possibly more reliable. In our simulation, existing Delay-Tolerant Network routing algorithms show poor performance on a complex network comprising diverse kinds of sensor nodes, such as, mobile phones, cars, and road side units. New approaches that can perform well on such heterogeneous networks are needed. They also need to support exchanging measurements among sensors for more accurate inference. In the early phase, we set up a heterogeneous architecture composed of different sorts of sensors, and propose an algorithm, Unified routing, for routing and disseminating. A further variant of the scheme is being developed. Early simulation results are consistent with theoretical prediction. After finishing the first step, Unified routing, the focus of our research will be on distributed data processing. Finally, routing and distributed data processing will be investigated in a testbed in a realistic context. Viet-Duc Le joined Pervasive Systems in June 2011 for a 4-year Ph.D. program. He is doing his research in the SenSafety project, where the main focus is on opportunistic sensing and networking, and on distributed sensor data processing. He received a Bachelor degree in ElectricalElectronics Engineering from Ho Chi Minh City University of Technology, Vietnam, in 2002, and a Master degree in Computer Engineering from KyungHee University, South Korea, in 2009. He is interested in Machine Learning and Pattern Recognition. More specifically, the focus of his research is to design and analyze inference algorithms for data in Wireless Sensor Networks and Opportunistic Network that can be applied to Health-care applications, Location Tracking, Public Safety, and Smart Transportation Systems. Besides his academic research, he has worked more than six years as a researcher or a team leader of many industrial projects related to sensor applications and web database.",,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5164a69f2115e623703c3e0f91a8b18331e61ff8,https://www.semanticscholar.org/paper/5164a69f2115e623703c3e0f91a8b18331e61ff8,"One list to rule them all and many semantics to bind them: Building a shared, scalable and sustainable source for the problem oriented medical record (Preprint)","
 BACKGROUND
 Since the creation of the Problem Oriented Medical Record, the building of problem lists has been the focus of many researches. To this day, this issue is not well resolved, and building an appropriate contextualized problem list is still a challenge.
 
 
 OBJECTIVE
 This paper presents the process of building a shared multi-purpose common problem list at the University Hospitals of Geneva, a consortium of all public hospitals and 30 outpatient clinics of the state of Geneva. This list aims at bridging the gap between clinicians’ language expressed in free text and secondary usages requiring structured information.
 
 
 METHODS
 The strategy focuses on the needs of clinicians by building a list of uniquely identified expressions to support their daily activities. In a second stage, these expressions are connected to additional information, building a complex graph of information. A list of 45,946 expressions manually extracted from clinical documents has been manually curated and encoded in multiple semantic dimensions, such as ICD-10, ICPC-2, SNOMED-CT or dimensions dictated by specific usages, such as identifying expressions specific to a domain, a gender, or an intervention. The list has been progressively deployed for clinicians with an iterative process of quality control, maintenance and improvements, including addition of new expressions, or dimensions for specific needs. The problem management of the electronic health record allowed to measure and correct the encoding based on real-world usage.
 
 
 RESULTS
 The list was deployed in production in January 2017 and was regularly updated and deployed in new divisions of the hospital. In 4 years, 684,102 problems were created using the list. The proportion of free text entries reduced progressively from 37.47% (8,321/22,206) in December 2017 to 18.38% (4,547/24,738) in December 2020. 
In the last version of the list, over 14 dimensions were mapped to expressions, among them 5 international classifications and 8 other classifications for specific usages. The list became a central axis in the EHR, being used for many different purposes linked to care such as surgical planning or emergency wards, or in research, for various predictions using machine learning techniques.
 
 
 CONCLUSIONS
 This work breaks with common approaches primarily by focusing on real clinicians’ language when expressing patient’s problems and secondly by mapping whatever is required, including controlled vocabularies to answer specific needs. This approach improves the quality of the expression of patients’ problems, while allowing to build as many structured dimensions as needed to convey semantics according to specific contexts. The method is shown to be scalable, sustainable and efficient at hiding the complexity of semantics or the burden of constraint structured problem list entry for clinicians. Ongoing work is analyzing the impact of this approach at influencing how clinicians express patient’s problems.
",,,10.2196/preprints.29174,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7d4fb2af1232d49f60ff194d2da46846cf729323,https://www.semanticscholar.org/paper/7d4fb2af1232d49f60ff194d2da46846cf729323,International symposium on distributed computing and artificial intelligence 2008 (DCAI 2008),,,2008.0,10.1007/978-3-540-85863-8,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aecb51cdeb26b104fed164f67081bedb08003429,https://www.semanticscholar.org/paper/aecb51cdeb26b104fed164f67081bedb08003429,Ambient Networks : toward a Future Internet embracing the Wireless World,"The mobile phone is becoming a trusted personal device with fundamental new capabilities. New form factors of mobile device and their user interfaces require new concepts for transformable mechanics. Integration of electronics and user interface functions into structural components will be necessary. Modular architecture will enable use of optimal technology for any particular functionality and optimization of power consumption. Nanomaterials, new manufacturing solutions and energy sources together with increased memory and computing capacity will enhance the capabilities of mobile devices. Nanotechnologies will also enable embedding of intelligence into human everyday environments and body area networks. We have presented a concept device called the Morph that illustrates use and bene_ts of nanotechnologies in real life applications. 1. Transformation of mobile communication During the following ten years mobile communication and the Internet will converge into a global information platform. Mobile phones have already become an enabling platform for digital services and applications. Mobile phones are powerful multimedia computers with wide range of functionality, e.g., imaging, navigation, music, content management, browsing, email, and time management. Increasingly they will have advanced multi-access communication, information processing, multimedia, mass storage and multimodal user interface capabilities. In the continuation these trusted personal devices will also have new capabilities: Interacting with local environment via embed-ded short range radios, sensors, cameras, and audio functionality; Functioning both as servers for global and local internet services and as clients for global internet services; Serving as gateways that connect local information and global internet based services; Carrying the digital identity of the user and enabling easy-to-use secure communication and controlled privacy in future smart spaces; Sensing local context and the behaviour of its user. Context awareness, including location, is the fundamental underlying capability of the future mobile devices. These context sensitive devices will open wide range of solutions for Internet services and mobile communication. Sensors, positioning and powerful signal processing embedded in mobile devices make it possible to detect, observe and follow different events and patterns in user's behavior and surrounding environments with precise location. Mobile device becomes a cognitive user interface that is continuously connected to the local environment and to the Internet Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES services. Context awareness has also profound inuence on the development of future communication and computing solutions by enabling intelligent allocation and sharing of resources. Form factors and user interface concepts of mobile multimedia computers will vary according to the usage scenario. The tendency towards smaller and thinner structures as well as towards reliable transformable mechanics will continue. The desire to have curved, flexible, compliant, stretchable structures and more freedom for industrial design sets demanding requirements for displays, keyboard, antennas, batteries, electromagnetic shielding and electronics integration technologies. A possibility to integrate electronics and user interface functions into structural components, such as covers, will be necessary. Modular device architecture of mobile multimedia computers will consist of several functional subsystems that are connected together via very high speed asynchronous serial interfaces [5, 6]. The modular approach enables the use of optimal technology for any particular functionality, optimization of power consumption, and the modular development of device technologies and software. The same modular architecture can be extended from one device to a distributed system of devices that shares the same key content, e.g., a remote mass storage, display or a printer. Nanoscience means capabilities to image, measure and manipulate physical and chemical processes at molecular level. These capabilities convert into nanotechnologies that are based on physical and chemical phenomena that emerge at nanoscale. Thus nanotechnologies are not just a continuation of the miniaturization roadmap but offer new capabilities to create solutions for health care, information technologies, materials and manufacturing. These pervasive capabilities will affect mobile communication [2]. Nanotechnologies for sensing, computing, radios, displays, structural and surface materials will enable creative design of future mobile devices and services. Mobile communication and the Internet are converging: wireless communication will nd optimal solutions based on both regulated mobile communication (3GPP track) and unregulated local access (IEEE track) solutions. Flexible and efficient local access will support sensing, computing and actuation in mobile devices that are continuously onnected to the Internet services. Implementation of sensors and multi-modal user interface features together with energy efficient local connectivity will enable new mobile services and new paradigms of communication, e.g., ad hoc social networking. Context awareness and machine learning will create the user experience seamless connectivity and information access but require powerful embedded computing solutions. Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES 2. Sensing and signal processing Sensors can already be found as key features of various battery powered, handheld devices. Especially, location, motion and gesture recognition are new pervasive elements of applications, user interfaces and services. One of the enablers of this rapid development has been microelectromechanical systems (MEMS) based on micromachining of silicon (see a review in [4]). The need for low cost, reliable sensors for automotive applications initiated the mass manufacture of silicon MEMS sensors. The requirements of consumer electronics, especially of sport gadgets, mobile phones and game controllers, have driven further the miniaturization of MEMS devices. Today MEMS and CMOS technologies provide a solid basis for large scale deployment of sensor applications. The opportunity to connect locally measured information to Internet services and to incorporate this local information into structured global information might be even more significant. Example of benefits include real time tracking of the spread of a disease or epidemic or interpretation of changes in traffic patterns on roads through a combination of local sensors and the Internet. The Internet is becoming a massive store of heterogeneous data and linked information. Extremely efficient search and data mining technologies are creating a dynamic and real time map of the physical world with its various economical and social networks. Nanotechnologies may not revolutionize sensor technologies and applications. Existing sensor technologies based on MEMS and CMOS platforms have not yet fully met their potential to provide sensor applications and networks that improve the human everyday environment. However, nanotechnologies, i.e., different nanoscale building blocks and fabrication processes, will affect the development of sensors, their signal processing and actuators. Nanotechnologies will extend the applications of sensors to new potential fields, such as smart spaces, body area networks, remote health care, and pervasive environmental monitoring (see a review in [7, 8]). Many nanoscale sensors are related to chemical and biochemical sensing where nanoscale transducers create a possibility to derive more detailed information on observed phenomena. Nanotechnologies offer a new possibility to create nanoscale transducers, memory and computing elements and to merge these elements together to form an intelligent sensor system. The same technology, e.g., silicon or ZnO nanowires or carbon nanotubes, can be used to create various functional elements for these systems. Several possible architectures, e.g., coupled resonator arrays, nanowire crossbars, plasmonics, and spiking neuron networks can be used for both sensing and signal processing. Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES 3. Morph Nanotechnologies in future mobile devices Transformation of the device can essentially happen in many levels: transformation of graphical user interface, mechanical configuration, available applications and services. The Morph device [1] is transformable in many different ways. The user interface of the device can adapt to the context of the user in terms of functionality but also its appearance. Transformability can be used to enable the ease of use of the device, applications and services. The Morph device is transformable in its form and conformation. The Morph is a cognitive user interface, capable of sensing both the user and the environment, making decisions based on this information, adapting to the context and give feedback to the user. The Morph learns about its user and becomes a trusted personal companion. The last forty years of development in electronics have targeted to ever increasing integration of functionality, i.e., very large scale integration. There is no doubt that this development will continue to build even more efficient solutions for sensing, computing and communication. However, interfaces of future devices with the physical world and their users require new type of intelligent and energy efficient sensors and actuators that can benefit of development of low cost electronics manufacturing and functional materials. Printed electronics creates capabilities to integrate functio",,2010.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5dffa86ee25138623b71f4d03a5ff5757fbdfdd,https://www.semanticscholar.org/paper/a5dffa86ee25138623b71f4d03a5ff5757fbdfdd,On National Projects,"Albania used the support from the Safe Online initiative to end violence against children online on multiple levels. To reach children, the agency trained children to become peer educators on online violence, increasing their knowledge on safe Internet navigation and helping them spread that information to their peers. UNICEF Albania conducted research on children’s use of the Internet and risk of online violence using the Global Kids Online methodology. The results from this study are being used to conduct national awareness activities. UNICEF Albania also worked at the national level by strengthening the national child helpline and hotline, which alert authorities about child sexual abuse material online. They also carried out an assessment of national legislation, policies and programmes currently targeting online child sexual exploitation and abuse in-line with the WePROTECT Global Alliance Model National Response. This will inform measures to improve the systematic response to online child sexual exploitation and abuse. UNICEF Albania also helped the government to develop a national strategy for cyber-security with a focus on children’s online safety. The agency also supported law enforcement authorities, strengthening their ability to investigate and prosecute cases of online child sexual abuse and exploitation. In addition, they worked with local municipalities and Internet service providers to promote “Albania Friendly Wi-Fi,” a safe certification standard for public Wi-Fi. These services will make Internet navigation safer for children, while also increasing national awareness on internet safety. They also used the support from the Safe Online initiative to engage the information, communications and technology sector on children’s Internet usage and risks in the digital space. to better detect, deter and prevent this type of violence. To do so, Justice and Care will explore the profiles of those who perpetrate and facilitate online sexual exploitation of children, interviewing convicted offenders, key informants, and others. This analysis will fill a gap in global research into online child exploitation of children and shed light on the “supply-side” of such violence in a country known to be an epicenter of live-streamed child sexual abuse. Ultimately, this research will seek to inform practical strategies and enhance industry, prevention and law enforcement response to the issue. The project also trained parents, teachers, social service providers and other adults to become advocates for cyber safety. At the industry level, the project also engaged Internet service providers and other technology companies in the fight against online child sexual exploitation and abuse. protect children from being victims of child sexual abuse. The chatbot will first be developed for pilot use in the United Kingdom with the potential for scaling up in other countries. The Safe Online initiative supported ChildFund Australia’s Swipe Safe program in Vietnam, which aimed to help young people navigate the Internet safely by educating them on potential risks, such as cyber scams, bullying or sexual abuse, and offering them strategies to protect themselves. ChildFund Australia designed, created and tested a training program to promote online safety – and ever since, the curriculum has been adapted by non-governmental organisations not just in Viet Nam, but in Laos and Myanmar as well. Swipe Safe mobilizes parents, youth, schools and the private sector to play an active role in children’s online safety. The program provided training for parents and Internet café owners and managers to identify and address risks that might happen to children, from online to offline and vice versa. It also supported schools to develop child-friendly policies and guidance on online safety. Swipe Safe is active in advocating to the national government with lessons learned to inform national policy and response and linking such legislation with the strengthening of existing structures. A key innovation of the program is that it engaged young volunteers in local communities with extensive knowledge on technology to train young people and others, as these trainers can more directly relate to their peers’ experiences and help keep the curriculum up to date. Disrupting Harm is a large-scale data collection and research project to better understand online child sexual exploitation and abuse across the world. This study is assessing the scale, nature and context of this issue in 14 countries across Southern and Eastern Africa and Southeast Asia. Supported by the Safe Online initiative, three grantee partners will work together to conduct the study, including ECPAT International, INTERPOL and the UNICEF Office of Research – Innocenti. ECPAT's role is to conduct a comprehensive analysis, allowing partners (and all others working in this arena) to better understanding the context of children's safety online. A new version of Disrupting Harm is currently bringing design, and it is expected to bring the large-scale research project to other regions. NTERPOL will bring the most advanced technology to investigators of online CSEA through its new DevOps Group Project. The initiative will facilitate research and development by an expert group of investigators, non-governmental organisations, academia, and information technology companies, and extend solutions to specialised officers worldwide via INTERPOL’s secure channels. Headquartered in France, this project has a global reach. Disrupting Harm is a large-scale data collection and research project to better understand online child sexual exploitation and abuse across the world. This study is assessing the scale, nature and context of this issue in 14 countries across Southern and Eastern Africa and Southeast Asia. Supported by the Safe Online initiative, three grantee partners will work together to conduct the study, including ECPAT International, INTERPOL and the UNICEF Office of Research – Innocenti. INTERPOL's role is to examine the threats facing children online and analyse data from law enforcement agencies across the world. A new version of Disrupting Harm is being designed and is expected to bring the research project to other regions. with INHOPE and other specific will explore and quantify the issues facing content moderators, as it relates to their exposure of traumatic child sexual abuse material. They will also identify coping strategies currently used by content moderators, and highlight what works – and what does not work – for individuals and organisations that do this work. Results of this study will be used to develop a pilot intervention to support and protect the mental health of content moderators. Lapsia Ry will develop and launch ReDirection, an evidence-based self-help programme working to prevent the consumption of CSAM on the Dark Web. By providing targeted support for these individuals, the project will also reveal new information about these searchers and their pathways to CSAM access and use. This programme builds on the Finnish government’s accredited New Direction rehabilitation programme for sex offenders. Headquartered in Finland, this project has a global reach. Through this project, Technological University Dublin will develop a deployable tool that reveals the patterns of adults perpetrating online child sexual abuse and the children who are affected by such violence. By using advanced artificial intelligence machine learning for text, the study will advance global understanding of trends in perpetrator behaviour (conduct, contact, content) – including grooming – and debunk strategies and tactics used to lure and coerce children into sexually exploitative acts. N-Light will be created in collaboration with two essential partner organisations, the Irish Society for the Prevention of Cruelty to Children (ISPCC) and Hotline.ie, the Irish national centre combatting illegal content online, specifically child sexual abuse material (CSAM) and activities relating to online child sexual exploitation (OCSE). Once finalized, N-Light will be tested by both partner organisations, with the intention to make it available to other hotlines in the INHOPE network and child agencies for their use, which would in turn lead to an enriched, more robust and representative data sample and analysis capacity. In addition, the data and insights will serve to better understand and conceptualise victim and perpetrator behavior, patterns and activity, ultimately informing the further development of evidence-based solutions that would have the potential of transformative impact in tackling this heinous crime against children. on the psychological processes through which people of online sexual and professional support. In addition, the group will explore the efficacy and impact of prevention interventions targeting people engaging with online abuse. Overall, the project will ask a fundamental – and often overlooked – question: who seeks help for child sexual exploitation and abuse, and can we get more people to do so before committing a crime? This project will expand the group’s existing model of psychological predicators of help-seeking for people at risk of offending and examine how to amplify the psychological factors that support such help-seeking behaviors. At the same time, the project will also look into the psychological barriers that prevent help-seeking and explore ways to weaken those barriers in the sphere. The World Health Organisation is using Safe Online investments to explore current systems of prevention and response to online child sexual exploitation and abuse. These findings will support governments and civil society organisations, giving them the tools and evidence, they need to implement effective, evidence-based programs to keep children safe online. After determining what works and does not work around preventing and responding to sexual and emotional online child abuse, the proj",,2003.0,10.6027/9789289335157-8-en,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a407364d8d1c6cd44bffb2fa7918b4733c246a64,https://www.semanticscholar.org/paper/a407364d8d1c6cd44bffb2fa7918b4733c246a64,"Digital libraries : people, knowledge, and technology : 5th International Conference on Asian Digital Libraries, ICADL 2002, Singapore, December 11-14, 2002 : proceedings","Keynote and Invited Papers.- Challenges in Building Digital Libraries for the 21st Century.- Building Digital Libraries Made Easy: Toward Open Digital Libraries.- Dublin Core: Process and Principles.- From Digital Library to Digital Government: A Case Study in Crime Data Mapping and Mining.- Progress on Educational Digital Libraries: Current Developments in the National Science Foundation's (NSF) National Science, Technology, Engineering, and Mathematics Education Digital Library (NSDL) Program.- Examples of Practical Digital Libraries: Collections Built Internationally Using Greenstone.- Data Mining Technologies for Digital Libraries and Web Information Systems.- Papers.- Chinese Text Summarization Using a Trainable Summarizer and Latent Semantic Analysis.- A Linear Text Classification Algorithm Based on Category Relevance Factors.- A Hierarchical Framework for Multi-document Summarization of Dissertation Abstracts.- Generality of Texts.- The Effiectiveness of a Graph-Based Algorithm for Stemming.- Searching Digital Music Libraries.- The NUS Digital Media Gallery - A Dynamic Architecture for Audio, Image, Clipart, and Video Repository Accessible via the Campus Learning Management System and idtvukcan the Digital Library.- A Schema Language for MPEG-7.- Bitmap-Based Indexing for Multi-dimensional Multimedia XML Documents.- What People Do When They Look for Music: Implications for Design of a Music Digital Library.- Distributing Relevance Feedback in Content Based Image Retrieval Systems.- Multistrategy Learning of Rules for Automated Classification of Cultural Heritage Material.- VideoCube: A Novel Tool for Video Mining and Classification.- Developing Tsinghua University Architecture Digital Library for Chinese Architecture Study and University Education.- Retrieving News Stories from a News Integration Archive.- A Data Mining Approach to New Library Book Recommendations.- Grouping Web Pages about Persons and Organizations for Information Extraction.- Personalized Services for Digital Library.- Automatic References: Active Support for Scientists in Digital Libraries.- Organizing and Maintaining Dynamic Digital Collections.- Navigation, Organization, and Retrieval in Personal Digital Libraries of Email.- A Work Environment for a Digital Library of Historical Resources.- A Personalized Collaborative Digital Library Environment.- Virtual Tutor: A System for Deploying Digital Libraries in Classrooms.- Resource Annotation Framework in a Georeferenced and Geospatial Digital Library.- Building Policy, Building Community: An Example from the US National Science, Technology, Engineering, and Mathematics Education Library (NSDL).- Building a Digital Library from the Ground Up: An Examination of Emergent Information Resources in the Machine Learning Community.- Subscription Clubs for E-journals: Indian Initiatives.- A Multilingual Multi-script Database of Indian Theses: Implementation of Unicode at Vidyanidhi.- A Workbench for Acquiring Semantic Information and Constructing Dictionary for Compound Noun Analysis.- Building Parallel Corpora by Automatic Title Alignment.- Offline Isolated Handwritten Thai OCR Using Island-Based Projection with N-Gram Models and Hidden Markov Models.- A Cache-Based Distributed Terabyte Text Retrieval System in CADAL.- Rural Digital Library: Connecting Rural Communities in Nepal.- Collection Development for the Digital Age: The Case of Malaysia.- Digital Divide: How Can Digital Libraries Bridge the Gap?.- Digital Libraries in Academia: Challenges and Changes.- Building Digital Libraries for Children: Reviewing Information Literacy of Students and Teachers.- The Use and Functionality of the Environmental Data Registry: An Evaluation of User Feedback.- Adding Semantics to 3D Digital Libraries.- INEXP: Information Exchange Protocol for Interoperability.- Study on Data Placement and Access Path Selection in an FC-SAN Virtual Storage Environment.- Building an OAI-Based Union Catalog for the National Digital Archives Program in Taiwan.- Intergenerational Partnerships in the Design of a Digital Library of Geography Examination Resources.- Pie Charts for Visualizing Query Term Frequency in Search Results.- Information Therapy in Digital Libraries.- Evaluation of Task Based Digital Work Environment.- A Framework for Flexible Information Presentation in Digital Collections.- Electronic Journal of the University of Malaya (EJUM): An Attempt to Provide a Truly Electronic Environment.- Patenting the Processes for Content-Based Retrieval in Digital Libraries.- Secure Content Distribution for Digital Libraries.- A Strategic Level for Scientific Digital Libraries.- Bridging the Gap between Information Resource Design and Enterprise Content Management.- A Digital Content Management Model for Making Profits in Digital Content Sites.- Posters.- The Idea of a Digital Library: Issues of Today.- US-Korea Collaboration on Digital Libraries: An Overview and Generalization for Pacific Rim Collaboration.- ETDs at HKU: A Spearhead for Digital Library Growth.- MiMedicalLibrary: A Digital Health Library for Michigan.- Reference Services in a Digital Library of Historical Artifacts.- An Integrative User-Centered Purchase Request Service in the Age of Digital Library Development.- Vitalising Library and Information Science Education: A Challenge in the Digital Information Environment.- Developing a Dialogue Library System.- WebClipper: A Personal/Community Link Library Builder Based on Web Link Management Technique.- Hiding a Logo Watermark in an Image for Its Copyright Protection.- Searching Video Segments through Transcript, Metadata, and SVG Objects.- Similar Sub-trajectory Retrieval Based on k-Warping Distance Algorithm for Moving Objects in Video Databases.- A Keyword Spotting System of Korean Document Images.- An Efficient Strategy for Adding Bulky Data into B+-Tree Indices in Information Retrieval Systems.",,2002.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
815bd89ee3b5b64981e2098b07f21a05f4d39d3b,https://www.semanticscholar.org/paper/815bd89ee3b5b64981e2098b07f21a05f4d39d3b,Uncovering Individualised Treatment Effect: Evidence from Educational Trials,"The use of large-scale Randomised Controlled Trials (RCTs) is fast becoming ""the gold standard"" of testing the causal effects of policy, social, and educational interventions. RCTs are typically evaluated — and ultimately judged — by the economic, educational, and statistical significance of the Average Treatment Effect (ATE) in the study sample. However, many interventions have heterogeneous treatment effects across different individuals, not captured by the ATE. One way to identify heterogeneous treatment effects is to conduct subgroup analyses, such as focusing on low-income Free School Meal pupils as required for projects funded by the Education Endowment Foundation (EEF) in England. These subgroup analyses, as we demonstrate in 48 EEF-funded RCTs involving over 200,000 students, are usually not standardised across studies and offer flexible degrees of freedom to researchers, potentially leading to mixed results. Here, we develop and deploy a machine-learning and regression-based framework for systematic estimation of Individualised Treatment Effect (ITE), which can show where a seemingly ineffective and uninformative intervention worked, for whom, and by how much. Our findings have implications for decision-makers in education, public health, and medical trials.",,2020.0,10.31219/osf.io/8nsw4,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b058cdd4e0b861af51a79a76b71ba53f46e1e88f,https://www.semanticscholar.org/paper/b058cdd4e0b861af51a79a76b71ba53f46e1e88f,PREDICTION OF COVID-19 FATALITY CASES BASED ON REGRESSION TECHNIQUES,"The COVID-19 was first reported to affect human life in Wuhan city, within the Hubei province of China in December 2019. An analysis of around 75,465 cases of COVID19 in China has revealed that the virus is transmitted between people from the blowout of respiratory droplets through sneezing and coughing. Corona is the world's most viral threat warning to people's health and the best pandemic in the world record. This paper presents a comparative study of regression techniques for the prediction of fatality cases due to Coronavirus. The objective of this paper is to predict the fatality cases of the top five affected countries which severely fight against COVID19. Time series forecasting analysis based on machine learning models like Linear Support Vector Regression (LSVR), Random Forest Regression, and Decision Tree Regressions are deployed to predict the fatality cases in the upcoming days. A comparative analysis is also carried out to identify which model best predicts the fatality cases. Covid-19 Data is considered from January 23, 2020, to October 30, 2020.",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
12ffb762cb3684c0de366b0be2dd5dbc6df80945,https://www.semanticscholar.org/paper/12ffb762cb3684c0de366b0be2dd5dbc6df80945,Intitute for Statistics Master Thesis with the title : Imputation and Prediction of HIV using NHS Survey Data from Nigeria,"The human immunodeficiency virus (HIV) is one of the biggest pandemic of our time. As there exists a therapy that can suppress the viral load, it is important to identify as many HIV positive people as possible since the majority does not know about their condition. To gather information, national health services (NHS) conduct surveys which include a voluntary HIV test. It would be desirable to be able to predict the result of that test for people who did not attend it. To achieve this, first multiple imputation is used to accommodate the missing data in co-variables. Then, machine learning methods are applied. Five models are deployed to construct classifiers. The models are a logistic regression model, a mixed effects logistic regression model, random forests, boosted trees and naive Bayes. Additionally, sampling techniques are used to accommodate the highly imbalanced data of the HIV test result. With none of the techniques was it possible to construct a satisfactory classifier. All classifiers predicted all missing test results as negative. Though it is possible to classify some cases as positive, this comes at a high cost of many false predicted positive test results.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ce5de174c2d95702bb144dde942dd321e5dbed6d,https://www.semanticscholar.org/paper/ce5de174c2d95702bb144dde942dd321e5dbed6d,Hypertension Diagnosis and Management in Africa Using Mobile Phones: A Scoping Review.,"Target 3.4 of the third Sustainable Development Goal (SDG) of the United Nations (UN) General Assembly proposes to reduce premature mortality from non-communicable diseases (NCDs) by one-third. Epidemiological data presented by the World Health Organization (WHO) in 2016 show that out of a total of 57 million deaths worldwide, approximately 41 million deaths occurred due to NCDs, with 78% of such deaths occurring in low-and-middle-income countries (LMICs). The majority of investigations on NCDs agree that the leading risk factor for mortality worldwide is hypertension. Over 75% of the world's mobile phone subscriptions reside in LMICs, hence making the mobile phone particularly relevant to mHealth deployment in Africa. This study is aimed at determining the scope of the literature available on hypertension diagnosis and management in Africa, with particular emphasis on determining the feasibility, acceptability and effectiveness of interventions based on the use of mobile phones. The bulk of the evidence considered overwhelmingly shows that SMS technology is yet the most used medium for executing interventions in Africa. Consequently, the need to define novel and superior ways of providing effective and low-cost monitoring, diagnosis, and management of hypertension- related NCDs delivered through artificial intelligence and machine learning techniques is clear.",IEEE reviews in biomedical engineering,2022.0,10.1109/RBME.2022.3186828,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
536c4246b3467c9b2084be8e3705d2d7646eec27,https://www.semanticscholar.org/paper/536c4246b3467c9b2084be8e3705d2d7646eec27,A Hybrid Method for Prediction of Ash Fouling on Heat Transfer Surfaces,"Soot blowing optimization is a key, but challenging question in the health management of coal-fired power plant boiler. The monitoring and prediction of ash fouling for heat transfer surfaces is an important way to solve this problem. This study provides a hybrid data-driven model based on advanced machine-learning techniques for ash fouling prediction. First, the cleanliness factor is utilized to represent the level of ash fouling, which is the original data from the distributed control system. The wavelet threshold denoising algorithm is employed as the data preprocessing approach. Based on the empirical mode decomposition (EMD), the denoised cleanliness factor data is decoupled into a series of intrinsic mode functions (IMFs) and a residual component. Second, the support vector regression (SVR) model is used to fit the residual, and the Gaussian process regression (GPR) model is applied to estimate the IMFs. The cleanliness factor data of ash accumulation on the heat transfer surface of diverse devices are deployed to appraise the performance of the proposed SVR + GPR model in comparison with the sole SVR, sole GPR, SVR + EDM and GPR + EDM models. The illustrative results prove that the hybrid SVR + GPR model is superior to other models and can obtain satisfactory effects both in one-step- and the multistep-ahead cleanliness factor predictions.",Energies,2022.0,10.3390/en15134658,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4fe83e9c3ccd032cb1ce9d72dd40e63d931d3866,https://www.semanticscholar.org/paper/4fe83e9c3ccd032cb1ce9d72dd40e63d931d3866,ABET Cybersecurity Continual Course Improvements for Secure Software Development,"This is an innovative practice full paper. The need to develop software securely cannot be over-emphasized. The changing legal and regulatory international and local landscape for software requirements is astounding. For example, the European Union's General Data Protection Regulation (GDPR), the United States' Health Insurance Portability and Accountability Act (HIPAA), the Chinese Cybersecurity laws, and the credit card industry's Payment Card Industry Data Security Standard (PCI-DSS) are all upholding higher standards for system development and deployment. Such legal and regulatory changes of necessity require modifications and updating in software development methods that must be incorporated into cybersecurity software development courses to properly prepare students for successfully working in the field. To address these and other changes within the computing field, the Accreditation Board for Engineering (ABET) recently proposed preliminary cybersecurity accreditation criteria for which fewer than 20 universities have both applied and become ABET Cybersecurity accredited. The accreditation requires maintaining continuous course improvement in the core courses including a secure software development course. This research first reports on important topics incorporated into a senior-level secure software development for cybersecurity majors. Our research then analyses student Institutional Review Board (IRB) approved surveys to learn which course components could benefit from continuous course improvements. We apply machine learning to help build categories for ABET continual improvement. Finally, we share lessons learned and plans for future work.",2021 IEEE Frontiers in Education Conference (FIE),2021.0,10.1109/FIE49875.2021.9637296,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e3195e97c3082f70c8182971d0c6ffc244bfa645,https://www.semanticscholar.org/paper/e3195e97c3082f70c8182971d0c6ffc244bfa645,High-Performance Mining of COVID-19 Open Research Datasets for Text Classification and Insights in Cloud Computing Environments,"The COVID-19 global pandemic is an unprecedented health crisis. Many researchers around the world have produced an extensive collection of literature since the outbreak. Analysing this information to extract knowledge and provide meaningful insights in a timely manner requires a considerable amount of computational power. Cloud platforms are designed to provide this computational power in an on-demand and elastic manner. Specifically, hybrid clouds, composed of private and public data centers, are particularly well suited to deploy computationally intensive workloads in a cost-efficient, yet scalable manner. In this paper, we developed a system utilising the Aneka Platform as a Service middleware with parallel processing and multi-cloud capability to accelerate the data process pipeline and article categorising process using machine learning on a hybrid cloud. The results are then persisted for further referencing, searching and visualising. The performance evaluation shows that the system can help with reducing processing time and achieving linear scalability. Beyond COVID-19, the application might be used directly in broader scholarly article indexing and analysing.",2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC),2020.0,10.1109/UCC48980.2020.00048,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6034c6d9eca03d5877d12da4a7e253af87c7e46d,https://www.semanticscholar.org/paper/6034c6d9eca03d5877d12da4a7e253af87c7e46d,UAV-Based Crowd Surveillance in Post COVID-19 Era,"Since outdoor events are gradually allowed within the current pandemic situation, a close monitoring of the crowd activity is needed to avoid undesired contact and disease transmission. In this context, unmanned aerial vehicles (UAVs) can be occasionally used to watch these activities, to ensure that health measures are applied, and to trigger alerts when an anomaly is detected. Consequently, we propose in this paper a complete UAV framework for intelligent monitoring of post COVID-19 outdoor activities. Specifically, we propose a three-step approach. In the first, captured images are analyzed using machine learning to detect and locate individuals. The second step consists of a novel coordinates mapping approach to evaluate distances among individuals and cluster them, while the third step provides an energy-efficient and reliable UAV trajectory to further inspect clusters for restrictions violation. Obtained results provide important insights towards the efficient design of the framework: 1) Efficient detection of individuals depends on the angle from which the images were captured, 2) coordinates mapping is very sensitive to estimate errors in individuals’ bounding boxes, and 3) UAV trajectory design algorithm 2-Opt is recommended for practical real-time deployments due to its low-complexity and near-optimal performance.",IEEE Access,2021.0,10.1109/access.2021.3133796,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
be55fd77c4ff59800af2de4f822c22500f8c2dc0,https://www.semanticscholar.org/paper/be55fd77c4ff59800af2de4f822c22500f8c2dc0,High Performance Mining of Covid-19,"Abstract: The COVID-19 global pandemic is an unprecedented health crisis. Many researchers around the world have produced an extensive collection of literature since the outbreak. Analysing this information to extract knowledge and provide meaningful insights in a timely manner requires a considerable amount of computational power. Cloud platforms are designed to provide this computational power in an on-demand and elastic manner. Specifically, hybrid clouds, composed of private and public data centers, are particularly well suited to deploy computationally intensive workloads in a cost-efficient, yet scalable manner. In this paper, we developed a system utilising the Aneka Platform as a Service middleware with parallel processing and multi-cloud capability to accelerate the data process pipeline and article categorising process using machine learning on a hybrid cloud. The results are then persisted for further referencing, searching and visualising. The performance evaluation shows that the system can help with reducing processing time and achieving linear scalability. Beyond COVID-19, the application might be used directly in broader scholarly article indexing and analysing.",International Journal for Research in Applied Science and Engineering Technology,2022.0,10.22214/ijraset.2022.45702,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64637e9255dec4482aff922b6dd7bb5d391ffd3e,https://www.semanticscholar.org/paper/64637e9255dec4482aff922b6dd7bb5d391ffd3e,Reducing Significances of Mesh Sensors Technologies through Dimensionality Reduction Algorithm,"In today's world, the breadth of real-time applications and networks is not limited to business and social activities. They are expanding as a field to provide improved and competitive settings for a variety of activities such as home, health, and commercial procedures. Data analytic method is used to maintain network accessibility as well as the robustness of expert services. It is necessary to clean up the data in order to reduce the computational complexity of extracting and pre-processing models. Because present approaches are sophisticated, they necessitate large computations. To this effect, the objective is to deploy a machine learning algorithm – “cuckoo search algorithm” for dimensionality reduction problems in data extraction for IoTs application. The cuckoo search-based feature extraction algorithm is a mutant algorithm that organizes itself depending on the unpredictable amount of input and generates a new and improved feature space. After the cuckoo search-based feature extraction is implemented, a few test benchmarks are provided to assess the performance of mutant cuckoo search algorithms. As a result of the low-dimensional data, classification accuracy is improved while complexity and expense are lowered.",Engineering International,2020.0,10.18034/EI.V8I2.556,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cb28b0d00a5d1db05cd297bd4f73dd5b92594d8b,https://www.semanticscholar.org/paper/cb28b0d00a5d1db05cd297bd4f73dd5b92594d8b,Translational Ethics: Justified Roles of Bioethicists Within and Beyond Lifecycles of Artificial Intelligence Systems in Health,"""Background: Artificial Intelligence (AI) systems hold great promise for the future development within a variety of sectors. At the same time, there is also great concern about harms and potential misuse of AI. Upscaling and implementing existing AI systems do already have the potential of affecting severely, and potentially irreversibly, fundamental social conditions for social interaction, professional autonomy, and political governance. Therefore, guiding principles and frameworks to support developers and governing authorities are emerging around the world to foster justified trust in AI research and innovation. Ultimately, these safeguarding institutions and mechanisms rely on human knowledge and wisdom. Health is an area that is expected to benefit from AI based technologies aimed at promoting beneficial, accurate and effective preventive and curative interventions. Also, machine learning technologies might be used to improve the accuracy of the evidence base for cost-effective and beneficial decision-making. How can bioethicists contribute to promote beneficial AI interventions and avoid harms produced by AI technology? What would be justified roles of bioethicists in development and use of AI systems? Method: The paper is based on literature review and philosophical reflection. Discussion: In this presentation, we will base our analysis on an analytical decomposition of the life cycle of AI systems into the phases of development, deployment and use. Furthermore, we will use a framework of translational ethics proposed by Bærøe, and identify a variety of structural tasks, as well as limitations to such, for bioethicists to undertake within this emerging multifold area of experts and disciplines. """,Studia Universitatis Babeş-Bolyai Bioethica,2021.0,10.24193/subbbioethica.2021.spiss.10,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7b63a396f39d22b0b47e5f7030c972f1280dba94,https://www.semanticscholar.org/paper/7b63a396f39d22b0b47e5f7030c972f1280dba94,"Fog-to-Cloud Computing for Animal Farming: Towards Low-Cost Technologies, Data Exchange and Animal Welfare","Coordinated fog-to-cloud computing systems are expected to expedite the evolution of cloud-based smart farming, towards openness and data sharing, while making farming economically sustainable for smaller farms. We demonstrate a fog-to-cloud enabled animal farming system that not only deploys low-cost technology for data collection and sharing, but also uniquely considers animal welfare and quality-of-life. On an practical example of a multi-master replication of SQL Server databases between Microsoft Azure Cloud and multiple fog nodes on the farm, we show that fog-based systems can help improve performance, scale to higher amounts of database entries, pre-process data with aid of machine learning, while providing reliability of the system in an easy-to-use fashion. Considerations of animal welfare, cloud-based data analysis, fog-enabled farming along with mobile applications are envisioned as common place for future farmers and consumers alike, and are in line with a recent trends connecting animal welfare, human health and the environment.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b43a9250d3d6d65af648dbf80a7444775a3a79f8,https://www.semanticscholar.org/paper/b43a9250d3d6d65af648dbf80a7444775a3a79f8,Hybrid Multi-Cloud based Disease Prediction Model for Type II Diabetes,"Advancements in health informatics pave the way to explore new medical decision making systems which are characterized by an exponential evolution of knowledge. In the medical domain, disease prediction has become the centre of research with the increasing trend of healthcare applications. The predictive knowledge for the diagnosis of disease highly depends on the subjective knowledge of the experts. So the development of a disease prediction model in time is essential for patients and physicians to overcome the problem of medical distress. This paper explores a hybrid approach (Cooperative Ant Miner Genetic Algorithm) for classifying the medical data. Three benchmarked Type II diabetic datasets (US, PIMA, German) from the UCI machine learning repository were used to analyze the effectiveness of the disease prediction model. The devised classification algorithm with a Soft-Set approach was deployed in a Multi-Cloud environment for enhancing the storage and retrieval of data with reduced response and computation time. The cooperative classification algorithm in the cloud database distinguishes the diseased cases from the normal ones .The soft set theory analyzes the severity of the diseased cases by calculating the percentage of diabetic risk using soft intelligent rules and stores them in a separate knowledge base. Thus the proposed model serves as a suitable tool for eliciting and representing the expert’s decision which aids in prediction of Type II diabetic risk percentage leading to the timely treatment of patients.",International Journal of Engineering and Advanced Technology,2020.0,10.35940/ijeat.c5680.029320,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
867094a6653d4125b664214303d6c455b1118110,https://www.semanticscholar.org/paper/867094a6653d4125b664214303d6c455b1118110,Biodynamic Lighting to Support the Wellbeing of People Living with Dementia in Care Facilities,"Exposure to natural daylight has a positive impact on human health and wellbeing. The non-visual effects of daylight stimulate a response in the circadian system which oversees fundamental mechanisms within the human body, such as metabolism, hormone balance and sleep-wake cycles. For people with dementia, the working capacity and regularity of these processes becomes further compromised as their exposure to daylight is reduced, due largely to age-contributing factors such as increased eye sensitivity and reduced mobility. In light of this, artificial lighting has been revolutionised to enable tailored output based on the photobiological demands of humans. This is known as biodynamic lighting which encompasses varying light intensity and spectral composition. Within dementia cohorts, this design concept has not been well studied, making it difficult to optimally administer and quantify related benefits. Fortunately, by building on the recent progression in the fields of machine learning and the internet of things, the potential for simultaneous behaviour monitoring and actuation of lighting intervention technologies is possible, enabling production of a viable biodynamic lighting solution. To this end, the present study provides a review of related work in the field of biodynamic technology designed to improve wellbeing in dementia, and identifies areas where improvements may be made. Following this, a proposed solution for future study designs and technologies is suggested. The proposed solution exists in the prototype stage, with a route to deploying in care facilities in the near future.","2021 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)",2021.0,10.1109/SWC50871.2021.00050,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1dd053ae6202ffe17593b965996bd90a90ed7c97,https://www.semanticscholar.org/paper/1dd053ae6202ffe17593b965996bd90a90ed7c97,When Personalization Harms: Reconsidering the Use of Group Attributes in Prediction,"The standard approach to personalization in machine learning consists of training a model with group attributes like sex, age group, and blood type. In this work, we show that this approach to personalization fails to improve performance for all groups who provide personal data. We discuss how this eﬀect inﬂicts harm in applications where models assign predictions on the basis of group membership. We propose collective preference guarantees to ensure the fair use of group attributes in prediction. We characterize how common approaches to personalization violate fair use due to failures in model development and deployment. We conduct a comprehensive empirical study of personalization in clinical prediction models. Our results highlight the prevalence of fair use violations, demonstrate actionable interventions to mitigate harm, and underscore the need to measure the gains of personalization for all groups who provide personal data. Credentialed Health Data License. The heart dataset is hosted on the UCI ML Repository under an Open Data license. The apnea and saps datasets must be requested from the authors of the papers listed above [57, 77]. We minimally process each dataset to impute the values of missing points (using mean value imputation), and repair class imbalances across intersectional groups (to eliminate “trivial"" fair use violations that occur due to class imbalance).",ArXiv,2022.0,10.48550/arXiv.2206.02058,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
30635d85ebdd9abf11ae2930fc5112de3ad01501,https://www.semanticscholar.org/paper/30635d85ebdd9abf11ae2930fc5112de3ad01501,Developing an Automatic System for Classifying Chatter About Health Services on Twitter: Case Study for Medicaid (Preprint),"
 BACKGROUND
 The wide adoption of social media in daily life renders it a rich and effective resource for conducting near real-time assessments of consumers’ perceptions of health services. However, its use in these assessments can be challenging because of the vast amount of data and the diversity of content in social media chatter.
 
 
 OBJECTIVE
 This study aims to develop and evaluate an automatic system involving natural language processing and machine learning to automatically characterize user-posted Twitter data about health services using Medicaid, the single largest source of health coverage in the United States, as an example.
 
 
 METHODS
 We collected data from Twitter in two ways: via the public streaming application programming interface using Medicaid-related keywords (Corpus 1) and by using the website’s search option for tweets mentioning agency-specific handles (Corpus 2). We manually labeled a sample of tweets in 5 predetermined categories or other and artificially increased the number of training posts from specific low-frequency categories. Using the manually labeled data, we trained and evaluated several supervised learning algorithms, including support vector machine, random forest (RF), naïve Bayes, shallow neural network (NN), k-nearest neighbor, bidirectional long short-term memory, and bidirectional encoder representations from transformers (BERT). We then applied the best-performing classifier to the collected tweets for postclassification analyses to assess the utility of our methods.
 
 
 RESULTS
 We manually annotated 11,379 tweets (Corpus 1: 9179; Corpus 2: 2200) and used 7930 (69.7%) for training, 1449 (12.7%) for validation, and 2000 (17.6%) for testing. A classifier based on BERT obtained the highest accuracies (81.7%, Corpus 1; 80.7%, Corpus 2) and F1 scores on consumer feedback (0.58, Corpus 1; 0.90, Corpus 2), outperforming the second best classifiers in terms of accuracy (74.6%, RF on Corpus 1; 69.4%, RF on Corpus 2) and F1 score on consumer feedback (0.44, NN on Corpus 1; 0.82, RF on Corpus 2). Postclassification analyses revealed differing intercorpora distributions of tweet categories, with political (400778/628411, 63.78%) and consumer feedback (15073/27337, 55.14%) tweets being the most frequent for Corpus 1 and Corpus 2, respectively.
 
 
 CONCLUSIONS
 The broad and variable content of Medicaid-related tweets necessitates automatic categorization to identify topic-relevant posts. Our proposed system presents a feasible solution for automatic categorization and can be deployed and generalized for health service programs other than Medicaid. Annotated data and methods are available for future studies.
 
 
 CLINICALTRIAL
 
",,2020.0,10.2196/preprints.26616,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8c7519faecd876ccea12602e0030457fa59982cd,https://www.semanticscholar.org/paper/8c7519faecd876ccea12602e0030457fa59982cd,AI-enabled Microscopic Blood Analysis for Microfluidic COVID-19 Hematology,"Microscopic blood cell analysis is an important methodology for medical diagnosis, and complete blood cell counts (CBCs) are one of the routine tests operated in hospitals. Results of the CBCs include amounts of red blood cells, white blood cells and platelets in a unit blood sample. It is possible to diagnose diseases such as anemia when the numbers or shapes of red blood cells become abnormal. The percentage of white blood cells is one of the important indicators of many severe illnesses such as infection and cancer. The amounts of platelets are decreased when the patient suffers hemophilia. Doctors often use these as criteria to monitor the general health conditions and recovery stages of the patients in the hospital. However, many hospitals are relying on expensive hematology analyzers to perform these tests, and these procedures are often time consuming. There is a huge demand for an automated, fast and easily used CBCs method in order to avoid redundant procedures and minimize patients’ burden on costs of healthcare. In this research, we investigate a new CBC detection method by using deep neural networks, and discuss state of the art machine learning methods in order to meet the medical usage requirements. The approach we applied in this work is based on YOLOv3 algorithm, and our experimental results show the applied deep learning algorithms have a great potential for CBCs tests, promising for deployment of deep learning methods into microfluidic point-of-care medical devices. As a case of study, we applied our blood cell detector to the blood samples of COVID-19 patients, where blood cell clots are a typical symptom of COVID-19.",2020 5th International Conference on Computational Intelligence and Applications (ICCIA),2020.0,10.1109/ICCIA49625.2020.00026,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4ea8230a6aaaea45049152643bed3baaa6d5818a,https://www.semanticscholar.org/paper/4ea8230a6aaaea45049152643bed3baaa6d5818a,EvoRecSys: Evolutionary Framework for Health and Wellbeing Recommender Systems. User Modeling and User-Adapted Interaction.,"In recent years, recommender systems have been employed in domains like e-commerce, tourism, and multimedia streaming, where personalising users’ experience based on their interactions is a fundamental aspect to consider. Recent recommender system developments have also focused on well-being, yet existing solutions have been entirely designed considering one single well-being aspect in isolation, such as a healthy diet or an active lifestyle. This research introduces EvoRecSys, a novel recommendation framework that proposes evolutionary algorithms as the main recommendation engine, thereby modelling the problem of generating personalised well-being recommendations as a multi-objective optimisation problem. EvoRecSys captures the interrelation between multiple aspects of well-being by constructing conﬁgurable recommendations in the form of bundled items with dynamic properties. The preferences and a predeﬁned well-being goal by the user are jointly considered. By instantiating the framework into an implemented model, we illustrate the use of a genetic algorithm as the recommendation engine. Finally, this implementation has been deployed as a Web application in order to conduct a users’ study. when a user is going to an exercise routine based on their previous behaviour and thus prevent it. The proposed model uses a machine learning algorithm as the core of the recommendation process. The previous user behaviour is used as a training vector which has 34 features including covered distance, workout duration, and rest time. Once the algorithm is trained, it is able to predict if a user is going to abandon the routine. If so, a recommendation for encouraging the user to continue the routine is triggered. Otherwise, the system predicts the user will not abandon the routine. The study tested 4 classiﬁcation algorithms: (i) random forest, (ii) AdaBoost, (iii) extra trees, and (iv) multi-layer perceptron; where random forest obtained the best performance. Data used for the analysis were taken from the u4ﬁt platform. ence modelling and aggregation, and AI for Sustainable Development Goals. Dr. Palomares’s research results have been published in top journals and conference proceedings, including IEEE TRANSACTIONS ON FUZZY SYSTEMS; IEEE TRANSACTIONS ON SYSTEMS, MAN AND CYBERNETICS: SYSTEMS; European Journal of Operational Research; Applied Soft Computing; International Journal of Intelligent Systems; Information Fusion, Knowledge-Based Systems; Applied Intelligence; Renewable & Sustainable Energy Reviews, amongst others.",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
023dc669070168a27ea6c422a7e61b7fe673f4de,https://www.semanticscholar.org/paper/023dc669070168a27ea6c422a7e61b7fe673f4de,A DID for Everything,"The decentralized identifer (DID) is a new and open standard type of globally unique identifer that ofers a model for lifetime-scope portable digital identity that does not depend on any centralized authority and that can never be taken away by third-parties [14]. DIDs are supported by the W3C community [14] and the Decentralized Identity Foundation (DIF) [16]. They are the ""atomic units"" of a new layer of decentralized identity infrastructure. However, DIDs can be extended from identifers for people to any entity, thus identifying everything. We can use DIDs to help us identify and manage objects, machines, or agents through their digital twins; we can expand them to locations, to events, and even to pure data objects, which we refer to as decentralized autonomic data (DAD) items [1][3]. The paper will present novel use-cases for DIDs and DADs and propose a new cryptographic data structure that 01/17/19 A DID for Everything 1.0 1 is a self-contained blockchain of DADs. This enables the verifcation of the provenance of a given data fow. It builds on a prior paper [1] and an associated reading [2]. DIDs are only the base layer of decentralized identity infrastructure. The next higher layer (where most of the value is unlocked) is verifable claims. This is the technical term for a digitally signed electronic data structure that conforms to the interoperability standards being developed by the W3C Verifable Credentials Working Group [15]. When a DID and hence DADs of the resultant data are extended to machines and autonomic data, the provenance chain of the data fow can provide the basis for verifable claims and attestations about the data fow as well as the basis for a reputation. WHY THIS MATTERS Today, the Internet is probably best described as a network comprised of all interconnected entities, traditionally referring to human users and computers. When we add connected entities and devices in the so-called Internet of Things (IoT), the number of addressable elements is in the tens of billions, with an estimate of 75 bn connected IoT devices in 2025 [4]. Software services, such as algorithms and bots, further extend this universe of identifable entities. The resulting combinatorics of possible connections between any given set of entities is an impossibly large number. Yet in today's user journeys or business environments, agents (whether human, machine, or software) increasingly need to communicate, access or transact with a diverse group of these interconnected objects to achieve their goals in both the digital and physical worlds. This requires a straightforward and ubiquitous method to address, verify, and connect these elements together. Defnition of Entity: Something that has a distinct and independent existence either in the real or the digital world. Examples of an entity are: • Living Organism • Physical Object • Locations or Events • Machines and Devices in the Internet of Things (IoT) • Digital Asset, Data Set, or Agent Human or object identities are stored in multiple centralised or federated systems such as government, ERP, IoT, or manufacturing systems. From the standpoint of cryptographic trust verifcation, each of these centralised authorities serves as its own root of trust. An entity trailing along a value chain is interacting with multiple systems. Consequently, a new actor in any given value chain has no method to independently verify credentials of a human or attributes of either a physical object or data item (provenance, audit trail). This results in the existence of complex validation, quality inspection, and paper trail processes, and enormous hidden trust overhead costs are added to all value chains and services. 01/17/19 A DID for Everything 1.0 2 To be a truly global solution, easy to use and still safe from hacking and sovereign interference, such a scheme must include: • preservation of privacy • security from tampering • reliable trust verifcation • assurance of risk • independence from any vendor-defned naming API • one-to-one mappable onto each entity. Therefore, a universal addressing, trust-verifcation system and associated interoperable protocol must be utilised, empowering every form of entity. Why it Matters for People Today when entities want their identities to be confrmed they transfer information such as a birth certifcate, physical address, or social security number to multiple third parties, who start to validate the same data in diferent contexts for KYC and authentication processes. The parties to which they sent that information retains it, meaning the data is out there in silos, creating risks in terms of data loss, privacy breaches, and use of inconsistent data and forcing companies that might not want to be in that position to store that information. It also enables businesses to harvest people's personal data for commercial purposes, which does not necessarily refect the intentions of the individual people. This situation results in big problems for humans such as broken health care records. Patients will need a universally addressable healthcare record system that is controlled by the patient itself, that consistently stores all relevant verifed health care data, and that is able to share this data with doctors that need to connect with it. To enable the doctors or algorithms, they need a data-fow provenance to verify the integrity, quality, or reputation of a healthcare record to decide on treatments and give the patient confdence about the proposed treatments. Why it Matters for Businesses Defnition of a Digital Twin: A digital twin is a digital representation of either a real-world or digital entity. A digital twin exists over the life-cycle of an entity from planning, manufacturing, testing, birth, and operations to decommissioning and reuse. The more past and present data are related and analysed, the more knowledge can be deployed to drive signifcant improvements on an individual entity or system level. It is estimated that by 2022 the IoT powered by digital twins will save consumers and businesses worth $1 trillion a year in asset maintenance [5]. The notion of digital twinning for objects, machines, and agents is becoming relevant to an increasing number of human services and Industry 4.0 use cases. This is the result of the growth in digital services, connections, and 01/17/19 A DID for Everything 1.0 3 data streams from the Internet of Things (IoT) devices that increasingly drive integration with machine learning algorithms, resulting in graph-type data chains for processing the IoT data streams. Today, digital twins are captured in siloed, proprietary IoT solutions by individual corporates that do not own the physical object over the life-cycle and even do not interact with parties using the object further down a value chain. Decentralized solutions are liberating the digital twins from silos and establishing more valuable and interoperable verifable attributes about entities and the data chains they connect with. Why it Matters for Objects, Machines and Agents There is no widely adopted authentication or verifcation systems in place to provide the equivalent of KYC (know-your-customer) for non-human entities, that is: KYA (know-your-agent), KYB (know-your-bot), KYM (know-your-machine), or KYO (know-your-object). In a world when objects and machines are connected with datastreams and intelligent agents that perform transaction on behalf of the entity, the number of agent-to-agent transactions will outgrow the number of human transactions by many orders. An agent transacting with another party can independently verify the identifer of the this party, its attributes, and the provenance of the data sets that are involved in the transaction. Digital twins of 3D-printed objects for safety critical parts such as a turbine of an airplane provide an important example. For these parts, it is important to have an precise audit trail about the 3D printing process to prove that the object was manufactured in accordance to stringent specifcations. The digital twin stores design, manufacturing, post processing, and quality-assurance data about the 3D-printed object. These data are coming from multiple systems resulting in a variety of data chains. With DIDs and DADs the integrity of the data chains can be verifed. The verifcation of the datachains and the underlying data results in important proofs about the provenance of 3D printed object. Why it Matters for the World The diverse application of decentralized identifers (DIDs) will have substantial infuences in broader applications on a global scale. The seamless provenance of physical objects or data items through any value chain has major implications on the risk and value properties of the processed data. Within any dynamic process, participating entities have substantial interest in the authenticity and trustworthiness in any individual step. Data that is accumulated with an unforgeable audit trail that references decentralized identifying information (Person, Device or any other Entity) for any transformation step holds greater value then it would have without such properties. Managing the sustainability of the commons requires mechanisms to value natural capital and to account for the externalities that arise from human activities. This should attribute extractions from and contributions to the commons by organisations, organisms, machines and information. We need to identify these entities and must 01/17/19 A DID for Everything 1.0 4 identify both positive and negative impacts these entities are having on the commons. Knowing what these impacts are enables us to count what matters and to put a value on what counts. The promise of a overarching prevalence through the broad use of DIDs also provides the key component for achieving the vision of a circular economy: a regenerative system in which resource input and waste, emission, and energy leakage are minimized by slowing, closing, and narrowing energy an",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6d2acdf479ef7568bc4dc02eb576b987042790f1,https://www.semanticscholar.org/paper/6d2acdf479ef7568bc4dc02eb576b987042790f1,14-LB: Clinical Utility of KidneyIntelX on Patients with Early-Stage Diabetic Kidney Disease—A Real-World Evidence Study,"Introduction: KidneyIntelX is a multiplex immunoassay of 3 plasma biomarkers with 7 clinical variables combined using machine-learning to generate a risk score for progressive decline in kidney function over 5 years in individuals with early-stage diabetic kidney disease (DKD) .
 Methods: A Population Health defined Mount Sinai approved care pathway for DKD patients informed by the KidneyIntelX test was introduced into the Mount Sinai Health System in New York, NY as part of a Real World Evidence (RWE) study (NCT04802395) . Decision impact of medication management (anti-hypertensives, SGLT2 inhibitors/GLP1 agonists) and specialist referral was tracked. An interim analysis was performed for 1) Assessing comparability between RWE and a published clinical validation cohort based on KidneyIntelX risk score distribution; 2) Determining if necessary EHR clinical fields were captured; 3) Identifying early evidence of KidneyIntelX impact on provider decision-making.
 Results: Between Mar-Nov 2021, 1,112 patients had KidneyIntelX test results, with post-test follow up to 36 weeks. The risk breakdown of RWE population was similar to the clinical validation cohort [High 14% vs. 17%, intermediate 40% vs. 37% and low risk 46% vs. 46%]. EHR record review for care changes confirmed ability to meet study objectives. Compared to patients scored low risk, there were changes in anti-hypertensives (OR 3.0; 95% CI 1.6-5.6) , initiation of SGLT2i/GLP-1a (OR 6.4; 95% CI 2.9-14) and increased referrals to nephrologists, endocrinologists, or dieticians (OR 2.8;95% CI 1.7-4.7) in patients scored as high-risk (Figure) .
 Conclusions: KidneyIntelX was successfully deployed in a health care system in a comparable population to the validation cohort with high data capture fidelity. Application of guideline-based
 therapies and specialist referral increased in the proportion to reported risk level by 3-6 and >2-fold, respectively.
 
 
 J. Tokita: None. M. J. Donovan: Employee; Renalytix. R. Fields: None.
",Diabetes,2022.0,10.2337/db22-14-lb,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
99d72202999460543e6b7c1a82fd171ee187cfcb,https://www.semanticscholar.org/paper/99d72202999460543e6b7c1a82fd171ee187cfcb,Biomedical and health informatics continue to contribute to COVID-19 pandemic solutions and beyond,"As I write this editorial in May of 2021, there are broad indications of reopening and decreasing COVID-19 pandemic restrictions in the US, while there are major pandemic hotspots globally. Like many others, I am hopeful that the lessons from the pandemic can be applied to major public health issues in the future. How transferrable are the theories, models, algorithms, and informatics-based solutions that we’ve developed? Through the years, we’ve certainly argued that this is a fundamental characteristic of informatics as a scientific field. I highlight 5 COVID-related studies in this issue, and I ask you to reflect, as I have done, on the key lessons for the future. In partnership with state and local public health agencies as well as health systems, Dixon et al describe the development and implementation of population-level dashboards that are deployed on top of a statewide health information exchange. Two dashboards collate information on individuals tested for and infected with COVID19. The primary dashboard enables authorized users working in public health agencies to monitor populations in detail. In contrast, a public version provides higher-level situational awareness to inform ongoing pandemic response efforts in communities. Over the span of 2 months, the dashboards were accessed by 74 317 distinct users, indicating substantial use. In terms of usefulness, the private dashboard enabled detection of a local community outbreak associated with a meat-packing plant. The authors call for continued investment in a statewide health information exchange as a critical component of public health infrastructure. Klann and co-authors describe the development and validation of a computable phenotype for COVID-19 severity by the Consortium for Clinical Characterization of COVID-19 by EHR (4CE). 4CE is an international collaboration that is addressing COVID-19 through federated analyses of electronic health record (EHR) data. They developed an EHR-based severity phenotype, consisting of 6 code classes using patient hospitalization data, and validated the phenotype in twelve 4CE international sites against the outcomes of intensive care unit admission and/or death. The full 4CE severity phenotype developed by experts had a pooled sensitivity of 0.73 and specificity 0.83 for the combined outcome of intensive care unit admission and/or death; however, the sensitivity of individual code categories for acuity had high variability. The authors also conducted a pilot in 1 site in which they compared selected predictors of severity between a machine learning approach and the 4CE phenotype with mean areas under the curve reported as 0.956 (95% confidence interval, 0.952–0.959) and 0.903 (95% confidence interval, 0.886– 0.921), respectively. The authors suggest that the severity phenotype comprising 6 code classes was resilient to coding variability across institutions, but they raised the concern that machine learning approaches may overfit hospital-specific orders. These findings contribute to the literature about generic vs institution-specific approaches. Malden, Heeney, Bates, and Sheikh conducted a qualitative study to develop an in-depth understanding of how hospitals with a long history of health information technology (HIT) use responded to the COVID-19 pandemic from an HIT perspective. Informed by a topic guide, they interviewed 44 healthcare professionals with a background in informatics from 6 hospitals internationally via videoconference. They applied thematic analysis to develop a coding framework and identify emerging themes. This resulted in 3 themes and 6 subthemes. Key findings included (a) HIT was employed to manage time and resources during a surge in patient numbers through fast-tracked governance procedures and the creation of real-time bed capacity tracking within EHRs; (b) improving the integration of different hospital systems was important across sites; (c) use of hard-stop alerts and order sets was perceived as effective in helping to respond to potential medication shortages and select available drug treat-",J. Am. Medical Informatics Assoc.,2021.0,10.1093/jamia/ocab130,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
da4e1cb2a7b7d45842b3aa1798cd928f6f50eddd,https://www.semanticscholar.org/paper/da4e1cb2a7b7d45842b3aa1798cd928f6f50eddd,Online Sentinel: A Sentiment Analysis Tool for Identifying Pseudoscience in the Cancer Care Continuum,"Background/Context: The online narrative of the cancer care continuum shows an alarming rise in pseudoscience-driven material; often acting to confuse patients who are in the cancer journey, especially those with inadequate information, for making various decisions on cancer treatment and care. This worrying phenomenon is co-opting more patients away from scientifically tested care strategies. Sentiment analysis refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information in populations. Working together, MIMOS Berhad, Malaysia's largest Applied Research and Development Centre in Information and Communications Technology, Industrial Electronics Technology and Nano-Semiconductor Technology; and the National Cancer Society of Malaysia aimed to tackle this serious health systems gap in provision of health information to cancer patients, families and the larger public. Aim: The aim of this project was to construct a sentiment analysis tool on cancer and develop an expert-driven support network for utilizing this tool for identifying pseudoscience-related cancer discussions and material in the Malaysian online space; and act to counterbalance these discussions with scientific facts. Strategy/Tactics: First, the tool was evaluated to determine its accuracy in identifying cancer-related pseudoscience news in the Malaysian context. This was done by having content experts objectively ascertain the analysis carried out by the tool. Once consensus had been reached with the experts, the tool was deployed. The support system mechanism consisted of a voluntarily recruited expert panel consisting of healthcare professionals briefed on the mechanism of the tool. Once the tool was deployed, the resultant analysis was shared out to the expert panel who then responded; counterbalancing the pseudoscience material identified in the respective online medium with accurate information. Program/Policy process: The sentiment analysis tool deployed machine learning, statistics, and natural language processing techniques to automate sentiment analysis on large collections of online cancer-related texts, including Web pages, online news, Internet discussion groups, online reviews, Web blogs, and social media. The tool was combined with a support-systems network of healthcare professionals who acted on the analysis results. A weekly run analysis and feedback mechanism was determined to be viable in terms of turn-around-time (TOT) while still remaining 'current' in the fast-paced online scene. Outcomes/What was learned: A marriage of an artificial intelligence system backed by human content experts can be a viable, sustainable mechanism in reducing the impact of pseudoscience in the online cancer ecosphere and help in provisioning accurate health information to cancer patients, families and the general public as a whole.",Journal of Global Oncology,2018.0,10.1200/JGO.18.97100,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
760018fdd1b109aa339e5602dc9cc4b92198b8e3,https://www.semanticscholar.org/paper/760018fdd1b109aa339e5602dc9cc4b92198b8e3,Utilising Big Data Analytics in the E-Government Health Sector,"The world has witnessed massive technological improvements in the Information Technology (IT) sector, giving rise to unprecedented IT penetration into every facet of life and daily living. It has affected the way we live and interact, the way businesses are conducted, and most especially how the government makes decisions that affect its citizenry. Presently, government officials deploy IT techniques in their decision-making process to reach the ever-growing needs of their populace. The traditional approach to large data processing is proving difficult. Hence, the dawn of Big Data Analytics, a phenomenon that describes the processing of large volumes of datasets, being generated at a very high velocity, coming in various forms, and are largely unstructured. This paper examines literatures on Big Data Analytics and its application in e-government. A prototype framework which is divided into two will be proposed for its application. The first section will have the Hadoop infrastructure deployed for distributed storage in clusters, while the second section used a machine learning software – Waikato Environment for Knowledge Analysis (WEKA) for data mining. Finally, the different data mining algorithms provided by WEKA was explored and used in analyzing medical records obtained from the UCI online repository to demonstrate the data analysis of the proposed prototype. From the results of the analysis, J48 algorithm was used to build prediction trees, to ascertain patterns that determine the likelihood of citizens having breast cancer, and to generate predictions rules that will help in curbing or detecting breast cancer early among the populace.",Science View Journal,2022.0,10.55989/hzdc4338,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
297bb55cd7355b11e1630e75515d65eb3d8a4542,https://www.semanticscholar.org/paper/297bb55cd7355b11e1630e75515d65eb3d8a4542,Wavelet Based Real-Time Planetary Gearbox Health Monitoring Under Non-Stationary Operation,,Experimental Techniques,2021.0,10.1007/s40799-021-00518-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
98848b7aab22008c64760c81bfdf02df81410b25,https://www.semanticscholar.org/paper/98848b7aab22008c64760c81bfdf02df81410b25,Special section: Selected papers from the Fourth International Workshop on Recent Advances in Monte Carlo Techniques for Radiation Therapy,"Monte Carlo (MC) computational techniques are widely used for applications in radiation medicine and have traditionally covered the areas of radiation dosimetry, shielding, radiotherapy treatment planning, and radiological imaging. Moreover, they have contributed to the improvement and understanding of the link between physical parameters of radiation delivery and therapy success. Recently, MC methods are being integrated with other technologies used in radiation therapy, such as inverse optimization, deformable image registration, and machine learning techniques for outcomes studies, etc. The Fourth International Monte Carlo Workshop was held from 8–10 June, 2011 on the campus of McGill University, Montreal, Canada. The 2.5-day workshop was the fourth edition in a series that started at McGill University in 2001, proceedings of which have been published (Seuntjens and Mobit, 2002; Verhaegen and Seuntjens, 2005; Verhaegen and Seuntjens, 2008). These events have garnered interest across the world and were highly successful; parallel successful events have been organized by the European Workgroup on Monte Carlo treatment planning (Reynaerts, 2007; Spezi, 2010). The fourth edition of the workshop was co-organized by McGill University (Medical Physics) and Université Laval. In what turned out to be sunny and pleasant Canadian spring days, the status of MC techniques was examined as related to radiation medicine, but in a broader sense in terms of techniques and applicability compared to previous editions. Developers of MC technologies were brought together with users from clinical, industrial and academic backgrounds. The topics discussed at the workshop included code development, variance reduction, clinical implementation and evaluation, parallel processing, GPUs, planning and correlation studies, applications in adaptive radiation therapy, imaging and dosimetry as well as integration of MC techniques with non-MC related applications involving machine learning and radiation biology outcome modeling. The workshop was attended by 106 participants from nine countries. 43 oral presentations were given and the poster session contained 13 presentations discussed integrally in the workshop program. Selected papers from the workshop comprise the content of this special section and the papers were peer-reviewed in accordance with the typical high standards of Physics in Medicine and Biology (PMB). In broad strokes, representative papers from almost all sessions can be found in the section. The clinical impetus of accurate dose calculations in radiation therapy is often linked to specific applications, such as lung cancer radiation therapy: the need for accurate dose calculations in heterogeneous clinical treatment planning and delivery verification scenarios. Radiation medicine benefits from MC calculations for a variety of other applications that we will briefly discuss. To arrive at accurate dose calculations, one needs to examine the basics of underlying physics; models, implementations and geometric inputs play fundamental roles. MC codes used in radiation medicine applications frequently undergo changes and updates that affect their accuracy. In the first session, recent developments in stopping power models for Penelope, low energy photon cross-sections in EGSnrc, new algorithms and input geometries with Geant4 were presented. The paper by Sawkey et al (2012) discusses electron scattering algorithms in Geant4 and compares them to detailed experiments in other papers in this section. Source modeling plays a very important role in radiotherapy applications, whether the algorithm is MC-based or not. Beam modeling was introduced in an excellent plenary presentation by Kawrakow and accuracy of these models was further discussed by Faddegon. An upcoming radiation therapy application that requires accurate beam modeling is MERT (modulated electron beam radiation therapy), which represents the use of a large number of intensity and energy modulated radiation fields. In this section, Connell et al (2012) investigate the benefit of scattering foil-free beams for the application of MERT using experimental and MC techniques. Brachytherapy is an application that has been receiving increased 'MC attention' due to the importance of low energies of the radiation involved as well as successes of certain brachytherapy treatments in terms of local control (e.g., Vuong et al 2002). Detailed source modeling and approaches for fast treatment planning-type calculations are being developed to replace approximate methods currently used in clinical applications. Afsharpour et al (2012) discuss the development and performance of the ALGEBRA algorithm based on Geant4 and its interfacing to clinical TP stations through DICOM-RT. Computational acceleration has always been an important consideration for the more widespread deployment of MC techniques in different areas including radiation therapy. A computer architecture that received significant attention in recent years is the Graphics Processing Unit (GPU) technology in conjunction with MC and other modeling methods in radiation therapy. At the workshop Jiang presented a summary of the efforts by the San Diego group in this regard. Complementary to the role of GPUs and other hardware acceleration platforms, alternative grid-based solvers such as deterministic transport methods have made their entrée into the world of clinical treatment planning. In this context, Wareing discussed the background and strengths of the Acuros deterministic solver of the Boltzmann equation. One of the time consuming components in MC transport is ray tracing or the navigation and the handling of boundary crossing. Schümann et al (2012) discuss optimal techniques for voxel navigation through patient Cartesian grids in Geant4. The explicit simulation of time-dependencies with MC techniques, known as 4D MC, is of importance in a variety of studies including anatomical variations, source modulation as well as correlative outcome studies. 4D MC options have become part of the most radiation therapy-related packages including BEAMnrc/EGSnrc, Geant4 and Penelope. Shin et al (2012) study a modular framework for the simulation of time-dependent quantities in the Geant4 toolkit TOPAS. Another topic of significant interest is nuclear medicine and molecular imaging. Zaidi reviewed the role of MC techniques in positron emission tomography, which is very relevant to recent developments in imaging technologies, such as PET-MR. The efficacy of proton therapy and its potential in clinical treatment is affected by accurate knowledge of particle range uncertainties in tissues, which is influenced by fundamental as well as clinical issues. In this section, Paganetti (2012) presents a topical review of the role of MC in proton therapy and estimation of its range uncertainties. The application of radiation therapy to a patient provokes a response of a 'system' that depends not only on an accurate description of the manner in which energy is absorbed in the patient tissues but, more importantly, on radiation biological and clinical aspects, whereas the role of MC techniques is witnessing increased interest on this front. The workshop devoted a dedicated session to applications of MC in radiation biology and treatment outcomes, which has been reviewed in this section by El Naqa et al (2012) from macroscopic and microscopic perspectives. Incerti presented the progress of the Geant4-DNA track structure project whereas Lee et al (2012) discussed analytical modeling of radiation therapy lung late effects and local MC dose over time. Chow et al (2012) applied MC techniques to quantify dose enhancement effects by gold nanoparticles in electron beams. Significant discussions took place about suitable ways for dose-to-medium reporting for clinical applications such as brachytherapy and Gadolinium neutron capture therapy. The workshop concluded with two sessions involving dosimetry starting with the impact of tissue characterization from different imaging technologies on accuracy of dose calculations in a presentation by Verhaegen. Dosimetry involving absorbed dose detectors is an area in which MC techniques have a longstanding, established role. Bouchard (2012) discussed a formal cavity theory suitable for MC implementation and Kairn et al (2012) presented a comparison between gel dosimetry and MC dosimetry in a stereotactic application. The role of MC techniques as a radiation physics modeling approach in the optimization of efficacy and success of radiation therapy is expanding. We have witnessed its role in radiation therapy physics as an invaluable and accurate technique to understand basic measurement dosimetry. It has become the ultimate treatment planning dose calculation algorithm and it will play both a fundamental as well as a technical role in improving the understanding of a variety of effects and processes that are part of the patient system response to radiation therapy. This evolution will be fueled with the ever-improving computer hardware and algorithmic developments. There may be a day where one can contemplate in-silico clinical trials as a result of these developments. We would like to gratefully acknowledge the financial support from the Research Institute, the Department of Radiation Oncology and the Cancer Mission of the McGill University Health Centre, the Department of Oncology of McGill University, the Canadian Organization of Medical Physicists (COMP), Association Québequoise des physiciens médicaux (AQPMC) and the following corporate sponsors: Nucletron, BV (official sponsor of the day for 8 June, 2011); Varian Medical Systems (official sponsor of the day for 9 June, 2011) and Elekta/CMS Inc. (official sponsor of the day for 10 June, 2011). The workshop was also endorsed by the International Atomic Energy Agency. A final word of thanks goes out to all of those who contributed to the successful workshop: our local medi",Physics in medicine and biology,2012.0,10.1088/0031-9155/57/11/E01,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,https://www.semanticscholar.org/paper/4f8c4025b2ce0c0eb837b7389bba31f6f1cae7c7,Implementing Operational Analytics using Big Data Technologies to Detect and Predict Sensor Anomalies,"Operational analytics when combined with Big Data technologies and predictive techniques have been shown to be valuable in detecting mission critical sensor anomalies that might be missed by conventional analytical techniques. Our approach helps analysts and leaders make informed and rapid decisions by analyzing large volumes of complex data in near real-time and presenting it in a manner that facilitates decision making. It provides cost savings by being able to alert and predict when sensor degradations pass a critical threshold and impact mission operations. Operational analytics, which uses Big Data tools and technologies, can process very large data sets containing a variety of data types to uncover hidden patterns, unknown correlations, and other relevant information. When combined with predictive techniques, it provides a mechanism to monitor and visualize these data sets and provide insight into degradations encountered in large sensor systems such as the space surveillance network. In this study, data from a notional sensor is simulated and we use big data technologies, predictive algorithms and operational analytics to process the data and predict sensor degradations. This study uses data products that would commonly be analyzed at a site. This study builds on a big data architecture that has previously been proven valuable in detecting anomalies. This paper outlines our methodology of implementing an operational analytic solution through data discovery, learning and training of data modeling and predictive techniques, and deployment. Through this methodology, we implement a functional architecture focused on exploring available big data sets and determine practical analytic, visualization, and predictive technologies. APPROACH This study developed an operational analytics implementation that uses Big Data technologies and machine learning algorithms to determine and predict sensor anomalies. A previous study [1] showed that Big Data Analytics can uncover anomalies that may be missed through conventional analyses. This study enhances that effort and shows a methodology to implement operational analytics that can be applied toward common solutions for data analysis. Our operational analytics implementation relies on continuous learning from historical data to analyze data in the stream of real-time operations. In the previous study, where data was identified that can be used to uncover anomalies, this implementation extends that approach and now identifies trends and correlations that reveal anomalies that can be missed by traditional analytic techniques with limited datasets. This study adopted a three-step methodology to implementing operational analytics – Discovery, Modeling and Operations as shown in Fig. 1. Copyright © 2016 Advanced Maui Optical and Space Surveillance Technologies Conference (AMOS) – www.amostech.com Fig. 1. Operational Implementation Approach Fig. 1 shows the three steps to implement operational analytics and the continuous feedback between learning and operational deployment. The following sections will elaborate on the methodology employed as applied to a realworld problem of analyzing large datasets such as would be encountered at an operational site.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b0ed25630d66d052bff2a9218d141a24b19e4d68,https://www.semanticscholar.org/paper/b0ed25630d66d052bff2a9218d141a24b19e4d68,THE BENEFITS OF APPLYING AI TO COMPRESSION,"Artificial intelligence (AI) is a popular subject today. Currently used across various verticals, from medicine to autonomous vehicles and finance, it is projected to have a significant impact. Today, AI is used for video compression, not just to provide bitrate savings but also to improve the quality of experience (QoE) and savings in processing power. This paper will present three applications of AI for video compression, explaining how each helps with the delivery of video content over broadcast and OTT networks. The applications that will be examined include Dynamic Encoding Style (DES), which enables a better trade-off between video quality and bitrate; Dynamic Resolution Encoding (DRE), which enables a superior QoE and density; and Dynamic Frame Rate Encoding (DFE), which allows for improved density and QoE. After a brief presentation of the methods, the paper will then present the results of implementing these technologies in the real world. INTRODUCTION Video compression for broadcast TV services started more than 20 years ago. Over time, several key improvements, such as dual-pass, statistical multiplexing, and software migration, were made to compression technology in order to boost performance. Artificial Intelligence (AI) is driving the next frontier of video compression enhancements. AI is effective at detecting objects and at surveillance. Machines are capable of detecting cancer cells with excellent accuracy, which can be a great help for medical doctors (1, 2). AI algorithms can also be useful at processing a lot of data. Some companies use it to clean large data sets, an activity called data wrangling. More and more, AI can be used for decision-making. The autonomous vehicle collapses many of these uses. Indeed, detection is important in an autonomous car, as other vehicles, persons, objects, and signs on the road need to be clearly identified along with their motion. Together with the internals of the car, it becomes a lot of data to process. The autonomous car has to constantly make decisions about the speed, direction, signaling, and more. In other terms, AI is very effective at predictions (3). More details on the evolution from human-designed algorithm to using AI for live video compression can be found in (10). In the VOD encoding domain, Netflix has been the pioneer in developing an AI-based system to assist file encoding, known as per-title or per-chunk encoding (4). Those techniques only apply to offline encoding and cannot be used for live video. This paper presents three examples of AI applied to live video encoding to optimize broadcast and OTT content delivery. The first three sections present the three examples. For each example, the paper presents a brief presentation of the methods followed by the results, including real-life effects. In this paper, both “AI” and “machine learning” expressions are used, knowing that machine learning is, in fact, a part of AI. DYNAMIC ENCODING STYLE (DES) OR CONTENT-AWARE ENCODING (CAE) FOR BITRATE SAVINGS In this first application, the video compression algorithm itself has improved thanks to machine learning technology. The goal is to improve the video quality/bitrate trade-off, meaning reducing the bitrate while maintaining the video quality or keeping a bitrate and improving the video quality. This is done by the means of encoding styles. Encoding styles are compression algorithm configurations well-suited for particular content. Results DES has been thoroughly tested across a lot of material, and it has shown a bitrate reduction vs. deployed system from 20% up to 30% on VBR content in broadcast applications, and 35% on average up to 50% compared with CBR for streaming applications. Table 1 shows the comparison of the AI-based algorithm with the deployed solution for a customer’s use case. The AI-based algorithm is run at different lower bitrates compared with the deployed solution, from 10% to 30% lower. At 10% the AI-based algorithm is better, at 20% it is equal and at 30% it is worse. The last two columns provide a comparison of lowering the bitrate for both algorithms for verification purposes. The conclusion is that the AI-based algorithm provides a 20% gain. Prog Channel AI version Pool bitrate -10% AI version Pool bitrate -20% AI version Pool bitrate -30% Both versions Pool bitrate -10% Both versions Pool bitrate -20% 1 Documentary = AI slightly lower AI lower AI better AI better 2 Cartoon = = AI lower = = 3 General Entertainment = = AI lower = AI slightly better 4 Movie = = AI slightly lower = AI slightly better 5 Sport AI better = AI lower AI better AI better 6 High action shows AI better AI slightly better = AI better AI better Table 1 – Video quality comparison on different channels between deployed and AI-based algorithm DES and CAE have been deployed in many streaming situations, with some examples and results shown below. The first example is a large streaming service with more than 1 million subscribers and more than 50 channels. This service supports live, VOD, cloud DVR, time-shift and serverside dynamic ad insertion. Due to the COVID-19 global health crisis, the service provider observed a dramatic increase in the bandwidth use and needed a solution to relieve the pressure without changing its infrastructure. By turning on DES and CAE the service provider saw significant improvements on their network. The backbone traffic was reduced by 50%, and the CDN peak usage was reduced by 30%. Figure 1 shows the backbone traffic reduction after DES/CAE was activated. Figure 1 Backbone traffic reduction thanks to DES and CAE The second example involves a large European streaming provider. The measurements were also made during the lockdown period due to COVID-19. In this example we show the average bitrate variation between normal compression and with DES/CAE turned on. For sports content, a bitrate reduction of 30% was measured, and for studio content a bitrate reduction of 40% was observed. Studio content includes television programs, such as talk shows and games shows. Figure 2 Studio content average bitrate reduction thanks to DES/CAE DES/CAE Activated",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10b7e11424bd8778d4def8f0a4b2c5f2eff9a632,https://www.semanticscholar.org/paper/10b7e11424bd8778d4def8f0a4b2c5f2eff9a632,Detecting Foodborne Illness Complaints in Multiple Languages Using English Annotations Only,"Health departments have been deploying text classification systems for the early detection of foodborne illness complaints in social media documents such as Yelp restaurant reviews. Current systems have been successfully applied for documents in English and, as a result, a promising direction is to increase coverage and recall by considering documents in additional languages, such as Spanish or Chinese. Training previous systems for more languages, however, would be expensive, as it would require the manual annotation of many documents for each new target language. To address this challenge, we consider cross-lingual learning and train multilingual classifiers using only the annotations for English-language reviews. Recent zero-shot approaches based on pre-trained multi-lingual BERT (mBERT) have been shown to effectively align languages for aspects such as sentiment. Interestingly, we show that those approaches are less effective for capturing the nuances of foodborne illness, our public health application of interest. To improve performance without extra annotations, we create artificial training documents in the target language through machine translation and train mBERT jointly for the source (English) and target language. Furthermore, we show that translating labeled documents to multiple languages leads to additional performance improvements for some target languages. We demonstrate the benefits of our approach through extensive experiments with Yelp restaurant reviews in seven languages. Our classifiers identify foodborne illness complaints in multilingual reviews from the Yelp Challenge dataset, which highlights the potential of our general approach for deployment in health departments.",LOUHI,2020.0,10.18653/v1/2020.louhi-1.15,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
29710fde444f3afeb4c666c893478ae5ce4c4e5f,https://www.semanticscholar.org/paper/29710fde444f3afeb4c666c893478ae5ce4c4e5f,An Industrial-Grade Solution for Crop Disease Image Detection Tasks,"Crop leaf diseases can reflect the current health status of the crop, and the rapid and automatic detection of field diseases has become one of the difficulties in the process of industrialization of agriculture. In the widespread application of various machine learning techniques, recognition time consumption and accuracy remain the main challenges in moving agriculture toward industrialization. This article proposes a novel network architecture called YOLO V5-CAcT to identify crop diseases. The fast and efficient lightweight YOLO V5 is chosen as the base network. Repeated Augmentation, FocalLoss, and SmoothBCE strategies improve the model robustness and combat the positive and negative sample ratio imbalance problem. Early Stopping is used to improve the convergence of the model. We use two technical routes of model pruning, knowledge distillation and memory activation parameter compression ActNN for model training and identification under different hardware conditions. Finally, we use simplified operators with INT8 quantization for further optimization and deployment in the deep learning inference platform NCNN to form an industrial-grade solution. In addition, some samples from the Plant Village and AI Challenger datasets were applied to build our dataset. The average recognition accuracy of 94.24% was achieved in images of 59 crop disease categories for 10 crop species, with an average inference time of 1.563 ms per sample and model size of only 2 MB, reducing the model size by 88% and the inference time by 72% compared with the original model, with significant performance advantages. Therefore, this study can provide a solid theoretical basis for solving the common problems in current agricultural disease image detection. At the same time, the advantages in terms of accuracy and computational cost can meet the needs of agricultural industrialization.",Frontiers in Plant Science,2022.0,10.3389/fpls.2022.921057,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4d6428da0d99ba07cf26d5ee481b9b4accb4e9d3,https://www.semanticscholar.org/paper/4d6428da0d99ba07cf26d5ee481b9b4accb4e9d3,"Building a Shared, Scalable, and Sustainable Source for the Problem-Oriented Medical Record: Developmental Study","Background Since the creation of the problem-oriented medical record, the building of problem lists has been the focus of many studies. To date, this issue is not well resolved, and building an appropriate contextualized problem list is still a challenge. Objective This paper aims to present the process of building a shared multipurpose common problem list at the Geneva University Hospitals. This list aims to bridge the gap between clinicians’ language expressed in free text and secondary uses requiring structured information. Methods We focused on the needs of clinicians by building a list of uniquely identified expressions to support their daily activities. In the second stage, these expressions were connected to additional information to build a complex graph of information. A list of 45,946 expressions manually extracted from clinical documents was manually curated and encoded in multiple semantic dimensions, such as International Classification of Diseases, 10th revision; International Classification of Primary Care 2nd edition; Systematized Nomenclature of Medicine Clinical Terms; or dimensions dictated by specific usages, such as identifying expressions specific to a domain, a gender, or an intervention. The list was progressively deployed for clinicians with an iterative process of quality control, maintenance, and improvements, including the addition of new expressions or dimensions for specific needs. The problem management of the electronic health record allowed the measurement and correction of encoding based on real-world use. Results The list was deployed in production in January 2017 and was regularly updated and deployed in new divisions of the hospital. Over 4 years, 684,102 problems were created using the list. The proportion of free-text entries decreased progressively from 37.47% (8321/22,206) in December 2017 to 18.38% (4547/24,738) in December 2020. In the last version of the list, over 14 dimensions were mapped to expressions, among which 5 were international classifications and 8 were other classifications for specific uses. The list became a central axis in the electronic health record, being used for many different purposes linked to care, such as surgical planning or emergency wards, or in research, for various predictions using machine learning techniques. Conclusions This study breaks with common approaches primarily by focusing on real clinicians’ language when expressing patients’ problems and secondarily by mapping whatever is required, including controlled vocabularies to answer specific needs. This approach improves the quality of the expression of patients’ problems while allowing the building of as many structured dimensions as needed to convey semantics according to specific contexts. The method is shown to be scalable, sustainable, and efficient at hiding the complexity of semantics or the burden of constraint-structured problem list entry for clinicians. Ongoing work is analyzing the impact of this approach on how clinicians express patients’ problems.",JMIR medical informatics,2021.0,10.2196/29174,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
20584705081dff9ab56cac856cb8e082565564d6,https://www.semanticscholar.org/paper/20584705081dff9ab56cac856cb8e082565564d6,Ensemble approach for identifying medical concepts with special attention to lexical scope,,Sādhanā,2021.0,10.1007/S12046-021-01593-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bd19383a9d52a5fdf7c896a21fbfeba7a7c2d0f9,https://www.semanticscholar.org/paper/bd19383a9d52a5fdf7c896a21fbfeba7a7c2d0f9,Harnessing AI for health equity in oncology research and practice.,"67 Background: Recent advances in artificial intelligence (AI) carry underexplored practical and ethical implications for the practice of clinical oncology. As oncologic applications of AI proliferate, a framework for guiding their ethical implementations and equitable distribution will be crucial. Methods: We reviewed the current landscape of AI applications in oncology research and clinical practice by reviewing the current body of evidence in PubMed and Medline. Key ethical challenges and opportunities to address health equity are critically evaluated and highlighted. Ethical implications for patients, clinicians and society at large are delineated, with particular focus on the impact and ramifications of AI with respect to healthcare disparities and equity of oncology care delivery. Results: Growing concerns that AI may widen disparities in oncologic care by virtue of lack of affordability, inconsistent accessibility and biased machine-learning models are addressed. Although there is potential for AI to widen disparities in oncology care, using foresight in application, AI has the potential to (1) democratize access to specialized clinical knowledge, (2) improve the accuracy of predicting cancer susceptibility, recurrence and mortality, (3) prevent diagnostic errors in under-resourced settings, (4) minimize unintended bias and (5) enable access to tailored therapeutic options including clinical trials if appropriately deployed. Separately, AI can be harnessed to identify areas of underserved needs and optimize systems of health-information sharing and reimbursements as blockchain technology converges with AI. As AI advances it will have a larger presence in oncology research and clinical practice. Conclusions: A strategic framework integrating ethical standards and emphasizing equitable implementation can help ensure that the potential of AI to address disparities in oncology are maximally captured and its perils averted. Further work is being done on exploring these challenges and will be submitted as a manuscript.",Journal of Clinical Oncology,2018.0,10.1200/JCO.2018.36.30_SUPPL.67,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3a7b0240f34002c62bcbb8d5089949b1d7664004,https://www.semanticscholar.org/paper/3a7b0240f34002c62bcbb8d5089949b1d7664004,Digital-Health Tourism Research-Methodology Coronavirus-Vaccination Trials: A Study Interpreting Geometa-Data Profiling to use Mobile-Health Technologies Nigeria,"Digital-Health Tourism Innovation (DTI) worldwide is in its infancy due to the emergent of coronavirus (COVID-19) disease. With the growth of open geometa data, use of government electronic services including electronic health (e-health), electronic commerce (e-commerce) and mobile health (m-health), Artificial Intelligence (AI) and machine learning strategies. Health and primary healthcare sectors are currently adopting these innovations for socio-economic wellbeing. Digital-health (also termed as e-health) is part of digital tourism innovation. Adapting geometa data profiling to develop a digital-health tourism framework for Primary Healthcare Workers (PHWs) to use mobile health technologies in COVID-19 vaccination trials are the key challenges of this study. Nevertheless, digital health tourism skills have been launched in developing Nations that created thousands of jobs to protect digital tourism businesses from potential vulnerabilities. Despite the benefits of this novel innovation, its deployment and implementation have been treated by inadequate of ICT facilities, lack of geometa data pre-processing to remove noise, data integrity, insufficient of academic research fundings, and reliable research methodology beyond COVID-19 vaccination trials to highlight these aspects. Therefore, qualitative, and quantitative research methods using Precaution Adoption Model Process (PAMP) questionnaire are employed to enable new ways of pre-processing behavior intention factors items. Eight academic researchers who were conversant with digital health technology validated 28 behavior intention factors with average factor loading values of 50% to 75%. Pilot survey conducted among 700 respondents from March 18, 2020, to September 10, 2021, among them are undergraduate students that may use this technology for research purposes. Pre-processed geometa data have shown percentage frequency counts of internet access and other online services 8% to 95%, adapted training factors 49% to 92% and factor items 34% to 78.3% for hypothesis generation towards development of digital health tourism framework in finding explanation to COVID-19 economic challenges. Except behavior intention factors and factor items insights are known and mapped, mobile health technology design process may result in poor conclusions. Thus, patients recovered from COVID-19 infection can still be infected again.",Emerging Advances in Integrated Technology,2021.0,10.30880/emait.2021.02.02.005,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
54b6af5f67839f179d4206bbf3b88045aca42e57,https://www.semanticscholar.org/paper/54b6af5f67839f179d4206bbf3b88045aca42e57,A Machine Learning Framework for Space Missions,"A machine learning (ML) framework for space missions has been developed to creates situational awareness and enables anomaly detection, dynamic data filtering and sensor data quality assessments. The ML framework covers four areas; the ML architecture model, ML algorithms and formulism for satellite datasets, a scalable and extensible ML platform, and the ML application portfolio. The ML architecture model defines how a ML system interacts with space and ground assets, ML functionalities, the interfaces among different ML processes, and the ML framework operational concept. ML algorithms and formulism includes data representation, data training, anomaly detection and characterization, and the creation of actionable information for mission/Enterprise situational awareness. The ML platform is a software implementation of a ML architecture model that addresses the challenges of ML solutions in operational environments. The ML application portfolio focuses the applications of the ML framework to the health and safety of satellites and onboard instruments with differing orbital characteristics. The Advanced Intelligent Monitoring System (AIMS) implements the ML platform to provide a common infrastructure and services, while ML algorithms are treated as plug-and-play components. The applications of the ML framework the Geostationary Environment Operational Satellite(GOES) instrument data, and the health and safety data for the Suomi National Polar-orbiting Partnership (NPP) are presented, and it shows that the ML framework bring fundamental advances in maintaining the health and safety of space missions. The ML approach enables early anomaly detection, rapid turnaround in anomaly troubleshooting, and significant improvement in system resiliency. 1. INSTRODUCTION A satellite and its onboard instruments are dynamical systems with states that are time dependent and generally non-deterministic. The amount of data representing the states of the system (or its subsystems or components) could be large in number of datasets and volume (on the order of gigabytes or more per day for example) to make it impossible to perform manual analysis to determine the system operational state. The challenge is how to obtain actionable information from a highly complex system generating large volumes of data in near real-time. The focus of this paper is to present a ML framework that creates situational awareness enabling automated engineering analysis, resulting in fundamental advances in how the health and safety of a highly complex system with a large number of sensors are maintained. Situational awareness for a dynamical system is defined as the ability to perceive, analyze and predict its own behavior. Machine Learning provides a natural platform to create situational awareness by establishing data models through data training, to predict near-term behaviors. The ability of a system to predict its own expected behavior enables anomaly detection, dynamic data filtering, and sensor quality assessment. The theory of situational awareness[1] also provides insights into how a ML system interacts with its managed systems, such as a space mission with both space and ground assets, which leads to the architectural model for a ML system. The ML architecture model defines the ML functionalities , interfaces among ML processes, and the operational concepts. There are considerable challenges in developing and executing ML algorithms in an operational environment due to the large number of datasets and large data volume required for processing (in near real-time). Furthermore, the data used in data training could be defective or anomalous that distort the training outcome. The data training process for a ML system in operational environments must be efficient while maintaining the accuracy of the data training outcome to prevent the distortion of training outcomes from defective data points. This requires flexibility in selecting data models and training algorithms to improve data training efficiency and a systematic approach to handling defective data points. Thus, an effective ML system for space missions must be scalable to handle large data volumes, flexible in selecting different ML algorithms for analyzing specific data patterns, and extensible to 34 Space Symposium, Technical Track, Colorado Springs, Colorado, United States of America Presented on April 16, 2018 Page 2 of 8 address mission specific requirements. The ML platform is a software implementation of a ML architecture model that separates mission-specific and data pattern-specific logic from the logic common to all missions (within the aerospace domain). The algorithms specific to certain data patterns and the processes required to meet mission specific requirements are treated as plug-and-play components deployed within the ML platform. The ML application portfolios refer to the applications of the ML framework for specific missions, and each mission has its own data characteristics that may require different ML algorithms. The different orbital characteristics in space missions, such as Low Earth Orbit (LEO), Medium Earth Orbit (MEO) or Geosynchronous Earth Orbit (GEO), produce different data patterns. The application of the ML framework has been applied to the GOES instrument data[2,7] and Polar satellite health and safety data with considerable success. This paper is organized as follows: Section 2 presents the ML architecture model for space missions; Section 3 shows the general formulism in data training, anomaly detection and characterization, and post training analysis; Section 4 focuses on the ML platform implementation; Section 5 presents the applications of the ML framework developed for GOES instrument data and the spacecraft housekeeping telemetry data for the NPP satellite; Section 6 provides the summary and future outlook of ML applications for space missions. 2. THE ML ARCHITECTURE MODEL FOR SPACE MISSIONS Figure 1 shows the ML architecture model. The managed element represents a dynamical system characterized by its state variables{Sj(ti)}, which are time dependent. The datasets {dj(ti)} are the measurements of the state variables {Sj(ti)}, which are noisy and follow the Gaussian probability distribution. The ML architecture model is based on the theory of situational awareness for dynamical systems[1] that defines how a ML system interacts with its managed element(s), and it is an information loop between a ML system and its managed element. The datasets from a dynamical system are monitored, analyzed, and appropriate actions are taken to change/enhance system behavior ensuring that system performance meets mission objectives. Situational awareness of the managed element is achieved through data training on existing data and establishes data models to predict near-term system behaviors, and enables dynamical monitoring for anomaly detection, dynamic data filtering, and data quality assessment. The data models are trained with “normal” data, where “normal” data refers to data that was assessed for quality, containing few or no errors/anomalies. Since datasets with Gaussian probability distribution form a tight data bound, these data sets are highly sensitive to deviations from their expected behavior above the calculated noise level. The dynamic monitoring function compares the values of datasets with predictions of their data models. An anomaly in a dataset is defined as the unexpected change from its normal data pattern, which can be detected through either dynamic data monitoring in real or near real-time and or a post training analysis process. Data training outputs allow dynamic data filtering to determine the actual values of state variables {Sj(ti)} by combining values of incoming datasets with predictions of ML data models. The Kalman filter is a dynamic filter widely used in space missions for determining spacecraft orbit characteristics, where the spacecraft orbit is predicted by classical orbital mechanics. The application of a Kalman filter with ML algorithms to predict the expected behavior of state variables has not been fully investigated. Additionally, a potential application of the dynamic filter is in Figure 1 The Architecture Model of the ML System 34 Space Symposium, Technical Track, Colorado Springs, Colorado, United States of America Presented on April 16, 2018 Page 3 of 8 instrument data calibrations, where the calibration coefficients are derived from the observations in spacelooks and internal targets that are generally noisy. The ML algorithms can be used to predict its near future behavior. The post training analysis process is performed after data training in each session to obtain actionable information from a large amount of data training outputs which include data quality and system operation status. Furthermore, long-term trending can also be performed in the post training analysis process to investigate system degradations and make predictions on when a system is expected to fail. Clustering techniques are generally implemented in post-training analysis, and these techniques are performed with data quality metrics as its attributes. The operations concept for a ML system is shown in Figure 2. A training session generally covers a period long enough so that input training sets contain sufficient information for predictions of near-term behaviors. Training sessions are repeated periodically, which enables data models to adapt to long term or seasonal pattern changes. Since daily changes in data patterns are small, the retraining of datasets is a minor adjustment of the training output from previous training sessions. Data training for current sessions uses the output from previous training sessions as the input. This is particularly important for data training of nonlinear data models, such as neural networks; data retraining on existing data models makes the training algorithm much more efficient and enables data training for opera",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ec0cf6037a2dde63c8fbcd6b9935902b17996922,https://www.semanticscholar.org/paper/ec0cf6037a2dde63c8fbcd6b9935902b17996922,Diagnosing the major contributing factors in the classification of the fetal health status using cardiotocography measurements: An AutoML and XAI approach,"The universal criticality of mother’s and child’s health can scarcely be overstated. Deterioration in an expectant mother’s health may lead to several complications in the antepartum and intrapartum period that which may be fatal. Hence, simultaneous tracking of prenatal parameters such as uterine contraction and Fetal Heart Rate (FHR) through Cardiotocography (CTG) is of critical importance. This preponderantly remains a manual procedure in developing nations as the inclusion of machine learning (ML) technology is still not widespread. Numerous studies have pointed to the fact that electronic monitoring of FHR has not had any noteworthy benefit in lowering the incidence of perinatal mortality and morbidity. Further, FHR monitoring is beset with other problems such as high disparities in intra-and inter-observations and enhanced rate of caesarean vis-à-vis normal delivery. These drawbacks of FHR notwithstanding, the fact remains that FHR is regarded as a vital obstetric procedure and CTG as equipment is deployed the most in perinatal diagnostics. With advancements in medical technology, techniques viz. computerized analysis of FHR and ECG are now being utilized as an accompaniment to CTG. These sophisticated computerized methods enable an analysis of variations in heart rate and assessing the patterns of short term heart rate. Further studies about multiple parameters causing FHR variability is needed to better our understanding of the primacy and salience of various parameters of raw fetal heartbeat data. Our experimental results using AutoML approach gave an accuracy rate of 0.9561, Recall 0.9056, Kappa 0.8792, Precision 0.9552, AUC 0.9864, F1 0.9550, MCC 0.8805 with model handling time of 2 minutes.","2021 13th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)",2021.0,10.1109/ECAI52376.2021.9515033,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2b1f7e138febec0debe2f004727742a431f26a38,https://www.semanticscholar.org/paper/2b1f7e138febec0debe2f004727742a431f26a38,EarlyScreen: Multi-scale Instance Fusion for Predicting Neural Activation and Psychopathology in Preschool Children,"Emotion dysregulation in early childhood is known to be associated with a higher risk of several psychopathological conditions, such as ADHD and mood and anxiety disorders. In developmental neuroscience research, emotion dysregulation is characterized by low neural activation in the prefrontal cortex during frustration. In this work, we report on an exploratory study with 94 participants aged 3.5 to 5 years, investigating whether behavioral measures automatically extracted from facial videos can predict frustration-related neural activation and differentiate between low- and high-risk individuals. We propose a novel multi-scale instance fusion framework to develop EarlyScreen – a set of classifiers trained on behavioral markers during emotion regulation. Our model successfully predicts activation levels in the prefrontal cortex with an area under the receiver operating characteristic (ROC) curve of 0.85, which is on par with widely-used clinical assessment tools. Further, we classify clinical and non-clinical subjects based on their psychopathological risk with an area under the ROC curve of 0.80. Our model’s predictions are consistent with standardized psychometric assessment scales, supporting its applicability as a screening procedure for emotion regulation-related psychopathological disorders. To the best of our knowledge, EarlyScreen is the first work to use automatically extracted behavioral features to characterize both neural activity and the diagnostic status of emotion regulation-related disorders in young children. We present insights from mental health professionals supporting the utility of EarlyScreen and discuss considerations for its subsequent deployment. CCS Concepts: • Human-centered computing → Ubiquitous and mobile computing systems and tools ; • Computing methodologies → Machine learning ; • Applied computing → Psychology Health informatics . Multi-scale Neural Psychopathology",Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2022.0,10.1145/3534583,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ed1898bc7abc69754746b119442113b1773bc799,https://www.semanticscholar.org/paper/ed1898bc7abc69754746b119442113b1773bc799,Repetitive but not single blast mild traumatic brain injury increases ethanol responsivity in mice and risky drinking behavior in combat Veterans,"Mild traumatic brain injury (mTBI) is common in civilians and highly prevalent among military Servicemembers and in contact sports athletes. mTBI, especially within military populations, is often comorbid with posttraumatic stress disorder (PTSD), and can increase health-risk behaviors (e.g., sensation/novelty seeking, impulsivity, risk taking, irritability/aggression) and substance misuse/abuse, but underlying mechanisms remain poorly understood. Using an established mouse model of blast mTBI, here we examined the effects of single (1x) and repetitive (3x) blast exposure on ethanol responsivity using a battery of tests, each associated with distinct aspects of alcohol abuse vulnerability. While both single and repetitive blast exposure increased the sedative properties of high-dose ethanol (with no change in tolerance or metabolism), only repetitive blast exposure potentiated ethanol-induced locomotor stimulation and shifted ethanol intake patterns (i.e., increased consumption front-loading) during intermittent two bottle choice. To establish translational relevance, we next examined self-report responses to the Alcohol Use Disorders Identification Test-Consumption Questions (AUDIT-C) and used a novel unsupervised machine learning approach to investigate whether a history of blast with acute symptoms and mTBI affected drinking behaviors in Iraq and Afghanistan Veterans. AUDIT-C scores were increased in Veterans with a history of blast exposure and subsequent cluster analysis identified a three-cluster solution: ""low"" (low intake and low frequency), ""frequent"" (low intake but high frequency), and ""risky"" (high intake and high frequency), where Veterans with a history of blast mTBI displayed a shift in cluster assignment from ""frequent"" to ""risky"", as compared to Veterans who were deployed to Iraq and/or Afghanistan who had no lifetime history of TBI. Together, these results offer new insight regarding how blast mTBI may give rise to increased substance use/misuse and highlight the increased potential for adverse health-risk behaviors following repetitive blast mTBI exposure.",medRxiv,2020.0,10.1101/2020.11.10.20229427,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
52d7872a825e8b058c2a281b49d7a0a447abb7c0,https://www.semanticscholar.org/paper/52d7872a825e8b058c2a281b49d7a0a447abb7c0,Automatic x-ray screening for tuberculosis,"Tuberculosis (TB) is widespread among immunocompromised HIV-positive patients in developing nations that have scarce medical resources. Tackling the disease, while at the same time avoiding complications of antiretroviral (HIV) treatment, requires rapid-result tests for detecting infection. Previously, healthcare practitioners determined TB exposure using immune response skin tests. However, if the patient had previously been vaccinated, this could compromise the accuracy of the result, and the test was therefore not a true indicator of active disease. A recent definitive test for TB diagnosis based on DNA analysis1 speeds up earlier sputum culture microscopy-based methods, but is expensive and inappropriate for population screening. Consequently, analyzing chest x-ray (CXR) images remains a relatively inexpensive and mandatory part of every patient evaluation. In developing regions, the challenge is to address the imbalance between the size of the affected population and the available radiology services. To achieve this aim—and to fulfill the objectives of the National Institutes of Health global health initiative—we have conducted research and development in advanced biomedical image diagnostics, and translated it into low-cost automated tools. This article highlights our work in developing and deploying a reliable, low-cost, automatic screening system for pulmonary TB in CXR images. We have conducted population screening in western Kenya in collaboration with Academic Model Providing Access To Healthcare (AMPATH), an NGO that provides treatment to some 200,000 HIV-positive patients. For TB infection screening, we provide lightweight digital x-ray units that are mounted in custom-designed trucks (see Figures 1 and 2). Using a lowpower computer, the system analyzes a digital CXR image immediately after acquisition (see Figure 3) using advanced image processing and machine learning algorithms, and Figure 1. An HIV-positive patient being led to the truck-mounted x-ray unit for tuberculosis (TB) screening.",,2015.0,10.1117/2.1201509.006128,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
62b4305b47f197b496573083be209072a6d8905c,https://www.semanticscholar.org/paper/62b4305b47f197b496573083be209072a6d8905c,Applicability of classifier to discovery knowledge for future prediction modelling,,Journal of Ambient Intelligence and Humanized Computing,2022.0,10.1007/s12652-022-03694-3,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3ea3443d402ba253c7f4719ab3dd6768c19445c5,https://www.semanticscholar.org/paper/3ea3443d402ba253c7f4719ab3dd6768c19445c5,ECG diagnosis device based on machine learning,"ECG signal can reflect rich physiological information of human body. The health state of human body can be obtained through the analysis of ECG signal. At present, most ECG detectors can only detect ECG signal and calculate heart rate, but can not carry out intelligent diagnosis. A STM32 development board with a front-end acquisition module is used to collect the analog ECG signal generated by an ECG simulator in this works, and the collected signal is uploaded to the Edge Impulse platform for the construction and training of diagnostic model. Then, the trained ECG diagnosis neural network model is deployed in the main controller of the development board for heart rate calculation and ECG signal diagnosis. The device can not only monitor the user's ECG signal, but also display the graphical ECG signal, calculate heart rate value and classify diagnostic results.",2021 IEEE International Conference on Emergency Science and Information Technology (ICESIT),2021.0,10.1109/ICESIT53460.2021.9697057,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
18aed41b20c8f3ed2eb1208f5e81cc0a54f9d5f6,https://www.semanticscholar.org/paper/18aed41b20c8f3ed2eb1208f5e81cc0a54f9d5f6,A Dataset Centric Feature Selection and Stacked Model to Detect Breast Cancer,"World Health Organisation declared breast cancer (BC) as the most frequent suffering among women and accounted for 15 percent of all cancer deaths. Its accurate prediction is of utmost significance as it not only prevents deaths but also stops mistreatments. The conventional way of diagnosis includes the estimation of the tumor size as a sign of plausible cancer. Machine learning (ML) techniques have shown the effectiveness of predicting disease. However, the ML methods have been method centric rather than being dataset centric. In this paper, the authors introduce a dataset centric approach(DCA) deploying a genetic algorithm (GA) method to identify the features and a learning ensemble classifier algorithm to predict using the right features. Adaboost is such an approach that trains the model assigning weights to individual records rather than experimenting on the splitting of datasets alone and perform hyper-parameter optimization. The authors simulate the results by varying base classifiers i.e, using logistic regression (LR), decision tree (DT), support vector machine (SVM), naive bayes (NB), random forest (RF), and 10-fold crossvalidations with a different split of the dataset as training and testing. The proposed DCA model with RF and 10-fold cross-validations demonstrated its potential with almost 100% performance in the classification results that no research could suggest so far. The DCA satisfies the underlying principles of data mining: the principle of parsimony, the principle of inclusion, the principle of discrimination, and the principle of optimality. This DCA is a democratic and unbiased ensemble approach as it allows all features and methods in the start to compete, but filters out the most reliable chain (of steps and combinations) that give the highest accuracy. With fewer characteristics and splits of 50-50, 66-34, and 10 fold cross-validations, the Stacked model achieves 97 % accuracy. These values and the reduction of features improve upon prior research works. Further, the proposed classifier is compared with some state-of-the-art machine-learning classifiers, namely random forest, naive Bayes, support-vector machine with radial basis function kernel, and decision tree. For testing the classifiers, different performance metrics have been employed – accuracy, detection rate, sensitivity, specificity, receiver operating characteristic, area under the curve, and some statistical tests such as the Wilcoxon signed-rank test and kappa statistics – to check the strength of the proposed DCA classifier. Various splits of training and testing data –namely, 50–50%, 66–34%, 80–20% and 10-fold cross-validation – have been incorporated in this research to test the credibility of the classification models in handling the unbalanced data. Finally, the proposed DCA model demonstrated its potential with almost 100% performance in the classification results. The output results have also been compared with other research on the same dataset where the proposed classifiers were found to be best across all the performance dimensions.",International Journal of Intelligent Systems and Applications,2021.0,10.5815/ijisa.2021.04.03,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1f1ef38f1f00c8ccaeaba78e12981ad37c633664,https://www.semanticscholar.org/paper/1f1ef38f1f00c8ccaeaba78e12981ad37c633664,"Identifying prospective frequent readmitters for hospital to home
 intervention using machine learning","Introduction: Singapore is a developed country with a population of 5.6 million and an acute-centric healthcare system. While the acute hospitals deliver extensive care, patients with multiple care needs face challenges in managing their conditions post-discharge, due to various reasons, such as weak caregiver support. This phenomenon is especially evident in older and frail patients who are frequently readmitted as their condition(s) deteriorate post-discharge. Methods: In April 2017, Singapore’s Ministry of Health (MOH) launched a nationwide Hospital to Home (H2H) care model to provide holistic patient-centric care to support patients discharging from public hospitals, so that they can transit back home, and stay well in the community. H2H targets high healthcare utilizers who are frail with complex care needs. The service includes medication reconciliation, case management, care coordination, telephonic support and caregiver training. To facilitate the development and deployment of the predictive model to risk stratify and segment the patients for enrolment assessment into H2H, a workgroup consisting of clinicians and data scientists across the various public hospitals was formed. The dependent variable for the model was three or more non-elective inpatient admissions within a 1-year period. Independent variables, generated based on literature review and input from clinicians and care managers, were segmented into 3 primary categories: sociodemographic, past hospital utilization and past medical conditions. Results: The top important variable was “total LOS in the past 12 months” followed by “number of days from previous non-elective admission” which lifted the model performance significantly. The best performing machine learning algorithm has an AUC of 0.79, recall of 39%, with precision set at 70% after consultation with the H2H clinical committee to capture very high risk patients. The prediction list, generated on daily basis, is now an integrated part of patient assessment workflow. The list helps the care team to support and follow up with the high healthcare utilizers and their caregivers after discharge. As of Oct 2018, more than 23,000 patients had benefited. Conclusions: The predictive model exemplifies the benefit of augmenting prediction model with clinical assessment. By having the prediction tool act as a bigger “sieve” to do the first level of filtering and the subsequent removal of potential false positives by clinicians when they assessed the patient in-ward provides a targeted intervention with minimal clinical resources. Lessons learnt: To manage the multidisciplinary development team in this endeavour efficiently, we adopted an iterative development process that allow us to fail fast and often. To convince clinicians to shift their decision making process to be augmented with a predictive model, we engaged reputable clinicians in the H2H clinical committee and analytics teams from different public hospitals to co-develop the model. Limitations: In this discussion, we had not been able to cover in depth on areas such as comparing the predictive model performance with different set of features. Future research: Future enhancements include the use of Natural Language Processing on unstructured clinical notes to extract care-giver and non-clinical information as additional features for the prediction model.",International Journal of Integrated Care,2019.0,10.5334/IJIC.S3228,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6479db81c4b95fa15b709da1f94142675abf54f3,https://www.semanticscholar.org/paper/6479db81c4b95fa15b709da1f94142675abf54f3,P. Falzon (ed): Constructive Ergonomics,,Journal of Occupational Rehabilitation,2015.0,10.1007/s10926-015-9566-5,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
514ce8be29824781ca0e5489c680502b0f31242f,https://www.semanticscholar.org/paper/514ce8be29824781ca0e5489c680502b0f31242f,Real Prediction Machines,"Predicting the future is no longer about the mystical reading of natural and celestial phenomena. Today it is all about data. 
The Real Prediction Machine (RPM) is a domestic product that uses big and small data, in combination with machine learning and predictive modelling to make predictions about specific future events. 
 
Contemporary use of digital networked technology, such as personal computers and smart phones, is effectively feeding a live global human behaviour laboratory with data scientists experimenting on an (often) unknowing pool of billions. The futures that emerge from this research are as yet mostly unknown, but there are hints – as this data accumulates it can be analysed, mined and used in algorithms; patterns or trends invisible to the human observer can be identified; and seemingly random events become predictable. At this time prediction algorithms are predominantly being exploited by big industries such as banking, insurance and commerce, or examined in massive research projects such as the EU funded FuturICT project. They are, however, making surreptitious steps into our lives through tailored internet browsing and predictive shopping with occasional Kafkaesque consequences. 
RPMs exploits the potential of this technology motivated not by the interests of industry and research but by the more emotive and personal needs/desires of people – this has the purpose of communicating the transformative potential of big data in domestic life, and asking if the future possibilities described by the project are desirable. 
 
The concept 
When things fail they rarely do so instantaneously but through a gradual process of deterioration. Based on this observation, predictive analytics, through the deployment of sensors in pertinent places and contexts, can determine the when things begin to fail. Such techniques are increasingly used in the mechanical and structural world - to predict for example when a vehicle or bridge might be in need of pre-emptive maintenance. 
 
The RPMs use similar techniques but in the context of human everyday life to predict anything from health related events such as a heart attack to more emotive forecasts such as a domestic argument. 
 
Once the event has been chosen the necessary and available data streams, from local sensors to RSS feeds, determined they are fed into the prediction algorithm - the output of which controls the visual display on the prediction machine. This informs the viewer if the chosen event is approaching, receding or impending. 
 
The Real Prediction Machines was commissioned by the Crafts Council for the exhibition Crafting Narrative. This explored how contemporary designers and makers use objects as mediums to tell stories. 
 
Project developed in collaboration with Subramanian Ramamoorthy and Alan Murray. Engineering by Nick Williamson.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aabfdea7a2f6c8aef71fa044f9475a4e79e97236,https://www.semanticscholar.org/paper/aabfdea7a2f6c8aef71fa044f9475a4e79e97236,"Managing Tasks Across the Work-Life Boundary: Opportunities, Challenges, and Directions","ABSTRACT With the global shift towards remote work, understanding how people maintain their desired boundary has become critically relevant to HCI research at large. In this paper, we examine how people employed task management tools across the work-life boundary before the emergence of COVID-19. We report findings from a survey deployed to 150 information workers during Summer 2019 that inquired about task management tool usage, contextual task management practice, and preferences for separating work and nonwork. We first characterize and identify trends across tool use, job role, and task management practice. We find that the majority of task management activity occurs during work hours, and that information workers regularly managing work tasks beyond work hours and vice versa. We use the findings to inform new research questions that are pertinent to managing work-life boundaries in the context of the pandemic, its resulting stay-at-home orders, and more broadly, in the new future of work. CCS CONCEPTS • Human-centered computing → Human computer interaction (HCI); Empirical studies in HCI. KEYWORDS task management practices, work-life boundary, online survey. ABOUT THE AUTHOR/S Alex C. Williams University of Tennessee acw@utk.edu Alex C. Williams is a postdoctoral researcher in the School of Information and Computer Sciences at the University of California, Irvine. His research intersects the areas of human-computer interaction, machine learning, cognitive science, and workplace studies. He holds a PhD in Computer Science from the University of Waterloo. His dissertation research focused on designing and studying new systems for aiding people in the work-related transitions experienced in daily life. (https://acw.io) Shamsi Iqbal Microsoft Research shamsi@microsoft.com Shamsi Iqbal is a Principal Researcher in the Information and Data Sciences group at Microsoft Research AI, Redmond. Her primary research expertise is in the area of Attention Management for Multitasking Domains. Her work is motivated by the vision of transforming the field of productivity research in response to the changing technology landscape with an eye towards making people happy and satisfied with the process and the outcome. Currently she is focusing on how productivity is defined in the new era of multitasking and distraction, introducing novel ways of being productive and determining metrics for evaluating productivity. More specifically, she develops experiences and technology that helps people maintain focus when needed, but at the same time introduce new concepts of getting things done in limited focus environments. Julia Kiseleva Microsoft Research julia.kiseleva@microsoft.com Ryen White Microsoft Research ryenw@microsoft.com Ryen White is a Partner Research Manager at Microsoft Research AI, where he leads a large team of world-class scientists and engineers researching and developing intelligent experiences. In recent roles, Ryen led the applied science organization for Cortana and he served as chief scientist for Microsoft Health. Ryen’s research has focused on understanding search interaction and on developing tools to help people search more effectively. New Future of Work 2020, August 3–5, 2020 © 2020 Copyright held by the owner/author(s).",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4867a63e5edd7ee10f28067d6dd5b07d69321de7,https://www.semanticscholar.org/paper/4867a63e5edd7ee10f28067d6dd5b07d69321de7,Thesis Title: A Framework for Improving the Performance of Signature-based Network Intrusion Detection Systems,"Network Intrusion detection systems (NIDSs) have been widely deployed in different network environments (e.g., banks, schools) to defend against a variety of network attacks (e.g., Trojans, worms). Generally, a network intrusion detection system can be classified into two categories: signature-based NIDS and anomaly-based NIDS. In realworld applications, the signature-based NIDS is more prevalent than the anomaly-based detection as the false alarm rate of the former is much lower than the latter. However, we identify three major issues that can greatly affect the performance of a signature-based NIDS. Expensive signature matching. The traditional signature matching in a signature-based NIDS is too expensive that the computing burden is at least linear to the size of an incoming string. Therefore, the operational burden of a signature-based NIDS could be significantly increased in a large-scale network environment. Overhead network packets. In a large-scale network environment, a signature-based NIDS usually has to drop lots of network packets since the number of incoming packets exceeds its maximum processing capability. Massive false alarms. Although the false alarm rate of a signature-based NIDS is much smaller than that of an anomaly-based NIDS. The number of false alarms generated by a signature-based NIDS can still increase the difficulty in analyzing true alarms and adversely affect the analysis results. To mitigate the above issues, in this thesis, we propose several approaches in improving the performance of a signature-based NIDS such as Snort in the following three aspects: Signature matching improvement.We design an exclusive signature matching scheme to help perform a more efficient signature matching with the purpose of enhancing the performance of signature matching in a heavy traffic environment. Network packet filtration and reduction. To mitigate this issue, we advocate the method of constructing a packet filter such as blacklist-based packet filter, list-based packet filter and trust-based packet filter to help filter out target network packets for a signature-based NIDS such as Snort in terms of IP reputation. This packet filter can be deployed in front of a signature-based NIDS and reduce its workload in an intensive traffic network. False alarm reduction. To resolve this issue, we design several false alarm filters such as machine-learning based false alarm filters, alarm filters using knowledge-based alert verification and context-based alarm filters to help reduce false alarms (or non-critical alarms) that are generated by a signature-based NIDS. A Framework. In addition, we further propose a framework by combining the above work to overall improve the performance of a signature-based NIDS such as Snort. As a case study of the framework, we implement an enhanced filter mechanism (shortly EFM) that consists of three major components: a context-aware blacklist-based packet filter, an exclusive signature matching component and a KNN-based false alarm filter. In particular, the component of context-aware blacklist-based packet filter is responsible for filtering out network packets in terms of IP reputation. The exclusive signature matching component is implemented in the context-aware blacklist-based packet filter and aims to speed up the signature matching. At last, the component of KNN-based false alarm filter is responsible for filtering out false alarms which are produced by the context-aware blacklist-based packet filter and the NIDS. In the evaluation, the experimental results demonstrate that our framework is promising and by deploying with the EFM, the performance of a signature-based NIDS such as Snort can be improved in the aspects of network packet filtration, signature matching improvement and false alarm reduction.",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
677e7b93c4bb987ca5de6a7defad0e4751894ff5,https://www.semanticscholar.org/paper/677e7b93c4bb987ca5de6a7defad0e4751894ff5,How to Make Decisions ( Optimally ),"Distributed systems are constantly faced with difficult decisions to make, such as in scheduling, caching, and traffic routing, to name a few. In most of these scenarios, the optimal decision is unknown and depends heavily on context. How can a system designer know if they have deployed the best decision-making policy, or if a different policy would perform better? As a community, we have developed a few methodologies for answering this question, some of them offline (e.g., simulation, trace-driven modeling) and some of them online (e.g., A/B testing). Neither approach is satisfactory: the offline methods suffer from bias and rely heavily on domain knowledge; the online methods are costly and difficult to deploy. What system designers ideally seek is the ability to ask “what if” questions about a policy without ever deploying it, which is called counterfactual evaluation. In this talk, I will show how reinforcement learning and causal inference can be synthesized to counterfactually evaluate a distributed system. We will apply this methodology to infrastructure systems in Azure, and face fundamental challenges and opportunities along the way. This talk will serve as an introduction to reinforcement learning and the counterfactual way of thinking, which I hope will interest and inspire the OPODIS community. I will start by introducing reinforcement learning (RL) as the right framework for modeling decisions in a distributed system. In RL, an agent learns by interacting with its environment: i.e., making decisions and receiving feedback for them. This is a stark contrast to traditional (supervised) learning, where the correct answer, or “label”, is known. Since an RL agent does not know the correct answer, it must constantly explore its world by randomizing some of its decisions. Now it turns out that this randomization, if used correctly, can give us a special superpower: the ability to evaluate policies that have never been deployed. As magical as this may sound, we can use statistics to show that this evaluation is indeed correct. Unfortunately, applying this methodology to distributed systems is far from straightforward. Systems are complex, stateful amalgamations of components that navigate large decision spaces. We will need to wear both an RL hat and a systems hat to address these challenges. On the other hand, systems also present exciting opportunities. Many systems already use randomization in their decisions, e.g., to distribute data or work over replicas, or to manage resource contention. Sometimes, a conservative decision can implicitly yield feedback for other decisions: for example, when waiting for a timeout to expire, we automatically get feedback for what would have happened if we waited for any shorter amount of time. I will show how we can harvest this randomness and implicit feedback to achieve more effective counterfactual evaluation. We will apply all of the above ideas to two production infrastructure systems in Azure: a machine health monitor that decides when to reboot unresponsive machines, and a geo-distributed edge proxy that chooses the TCP configuration of each proxy machine. In both cases, we are able to counterfactually evaluate arbitrary policies with estimates that match the ground truth. Production environments raise interesting constraints and challenges, some of which are preventing us from scaling up our methodology. I will describe a possible path forward, and invite others in the community to contemplate these problems as well. 2012 ACM Subject Classification Computing methodologies → Reinforcement learning, Software and its engineering → Software organization and properties",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
551f1a035d3707f6ecc9e608509e7191749fd03a,https://www.semanticscholar.org/paper/551f1a035d3707f6ecc9e608509e7191749fd03a,Therapeutic Innovations in Neuroscience: What’s New on the Horizon?,"The theme of this issue of Clinical Pharmacology & Therapeutics (CPT) encompasses neuroscience in the broad sense to include neurology and psychiatry, nonclinical and clinical aspects, novel clinical trial methodologies, and modeling and simulation approaches applicable to central nervous system (CNS) drug development and therapy. While naturally the last two years have been dominated by coronavirus disease 2019 (COVID19), it is important not to forget that drug development for other indications has not been stopped, albeit many trials were affected in terms of delays in recruitment and collection of clinical data. There are numerous rare to ultrarare neurological diseases in which the very limited number of patients, combined with the lack of reliable biomarkers and targeted therapies, pose a real challenge for traditional drug development, including appropriate dosefinding studies. Abuasal et al. discuss the role of regulatory flexibility in the approval of new drugs and give examples from US Food and Drug Administration (FDA) scientific assessment and conclusions based on a relatively limited data set, using modeling and simulation to select the optimal dose, extrapolation among populations, or pharmacodynamic biomarkers. The authors also provide an optimistic outlook into the future regarding the expected role of quantitative systems pharmacology, artificial intelligence, and machine learning, as well as disease progression models using realworld data (Figure 1). Stephenson et al. discuss whether and how innovative trial designs and technologies, including multiarm adaptive platform designs and digital health tools to monitor progression in rare diseases like Duchenne muscular dystrophy and amyotrophic lateral sclerosis (ALS), can drive the advancement of treatments for common neurological diseases like Parkinson’s disease. At the same time, the authors provide an excellent insight into the importance of collaborative efforts: Novel platforms containing data from completed clinical trials, registries, natural history studies, and preclinical data do not only foster data sharing but also provide a means of connectivity to sophisticated tools like disease progression models and clinical trial simulation applications. Clinical trials in neuroscience are frequently challenged by the extensive heterogeneity between patients and their survival and a nonnegligible number of patients dying during the course of a clinical trial, particularly in rapidly progressive diseases like ALS. Van Eijk et al. present an overview of commonly used strategies to address death in efficacy end points for clinical trials, which may have implications for the interpretation of the study results. Exemplified by clinical trials in ALS, their review provides guidance to define the exact research question of a trial, to align its objectives with the study design, including",Clinical pharmacology and therapeutics,2022.0,10.1002/cpt.2547,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fb852ea91316402e2ad06dde850bb59549d04548,https://www.semanticscholar.org/paper/fb852ea91316402e2ad06dde850bb59549d04548,High Spatial-Temporal PM2.5 Modeling Utilizing Next Generation Weather Radar (NEXRAD) as a Supplementary Weather Source,"PM2.5, a type of fine particulate with a diameter equal to or less than 2.5 micrometers, has been identified as a major source of air pollution, and is associated with many health issues. Research on utilizing various data sources, such as remote sensing and in situ sensors, for PM2.5 concentrations modeling remains a hot topic. In this study, the Next Generation Weather Radar (NEXRAD) is used as a supplementary weather data source, along with European Centre for Medium-Range Weather Forecasts (ECMWF), solar angles, and Geostationary Operational Environmental Satellite (GOES16) Aerosol Optical Depth (AOD) to model high spatial-temporal PM2.5 concentrations. PM2.5 concentrations as well as in situ weather condition variables are collected from the 31 sensors that are deployed in the Dallas Metropolitan area. Four machine learning models with different predictor variables are developed based on an ensemble approach. Since in situ weather observations are not widely available, ECMWF is used as an alternative data source for weather conditions in studies. Hence, the four established models are compared in three groups. Both models in this first group use weather variables collected from deployed sensors, but one uses NEXRAD and the other does not. In the second group, the two models use weather variables retrieved from ECMWF, one using NEXRAD and one without. In the third group, one model uses weather variables from ECMWF, and the other uses in situ weather variables, both without NEXRAD. The first two environmental groups investigate how NEXRAD can enhance model performances with weather variables collected from in situ observations and ECMWF, respectively. The third group explores how effective using ECMWF as an alternative source of weather conditions. Based on the results, the incorporation of NEXRAD achieves an R2 score of 0.86 and 0.83 for groups 1 and 2, respectively, for an improvement of 2.8% and 9.6% over those models without NEXRAD. For group three, the use of ECMWF as an alternative source of in situ weather observations results in a 0.13 R2 drop. For PM2.5 estimation, weather variables including precipitation, temperature, pressure, and surface pressure from ECMWF and deployed sensors, as well as NEXRAD velocity, are shown to be significant factors.",Remote. Sens.,2022.0,10.3390/rs14030495,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
df040ba4b648810e393d337ef05ded56e882802f,https://www.semanticscholar.org/paper/df040ba4b648810e393d337ef05ded56e882802f,hpcNMF: A high-performance toolbox for non-negative matrix factorization,"Non-negative matrix factorization (NMF) is a widely used machine learning algorithm for dimension reduction of large-scale data. It has found successful applications in a variety of fields such as computational biology, neuroscience, natural language processing, information retrieval, image processing and speech recognition. In bioinformatics, for example, it has been used to extract patterns and profiles from genomic and text-mining data as well as in protein sequence and structure analysis. While the scientific performance of NMF is very promising in dealing with high dimensional data sets and complex data structures, its computational cost is high and sometimes could be critical for delivering analysis results in a timely manner. In this paper, we describe a high-performance C++ toolbox for NMF, called hpcNMF, that is designed for use on desktop computers and distributed computer clusters. Algorithms based on different statistical models and cost functions as well as various metrics for model selection and evaluating goodness-of-fit are implemented in the toolbox. hpcNMF is platform independent and does not require the use of any special libraries. It is compatible with Windows, Linux and Mac operating systems; and message-passing interface is required for hpcNMF to be deployed on computer clusters to leverage the power of parallelized computing. We illustrate the utility of this toolbox using several real examples encompassing a broad range of applications. hpcNMF: A high-performance toolbox for non-negative matrix factorization Karthik Devarajan a,∗ aDepartment of Biostatistics & Bioinformatics, Fox Chase Cancer Center, Temple University Health System, Philadelphia, PA Guoli Wang b b3M Healthcare, Bethesda, MD Abstract Non-negative matrix factorization (NMF) is a widely used machine learning algorithm for dimension reduction of large-scale data. It has found successful applications in a variety of fields such as computational biology, neuroscience, natural language processing, information retrieval, image processing and speech recognition. In bioinformatics, for example, it has been used to extract patterns and profiles from genomic and text-mining data as well as in protein sequence and structure analysis. While the scientific performance of NMF is very promising in dealing with high dimensional data sets and complex data structures, its computational cost is high and sometimes could be critical for delivering analysis results in a timely manner. In this paper, we describe a high-performance C++ toolbox for NMF, called hpcNMF, that is designed for use on desktop computers and distributed computer clusters. Algorithms based on different statistical models and cost functions as well as various metrics for model selection and evaluating goodness-of-fit are implemented in the toolbox. hpcNMF is platform independent and does not require the use of any special libraries. It is compatible with Windows, Linux and Mac operating systems; and message-passing interface is required for hpcNMF to be deployed on computer clusters to leverage the power of parallelized computing. We illustrate the utility of this toolbox using several real examples encompassing a broad range of applications.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9ceaacaecb4bbd060285ea71348a4e6caafc2dc8,https://www.semanticscholar.org/paper/9ceaacaecb4bbd060285ea71348a4e6caafc2dc8,Marfusion: An Attention-Based Multimodal Fusion Model for Human Activity Recognition in Real-World Scenarios,"Human Activity Recognition(HAR) plays an important role in the field of ubiquitous computing, which can benefit various human-centric applications such as smart homes, health monitoring, and aging systems. Human Activity Recognition mainly leverages smartphones and wearable devices to collect sensory signals labeled with activity annotations and train machine learning models to recognize individuals’ activity automatically. In order to deploy the Human Activity Recognition model in real-world scenarios, however, there are two major barriers. Firstly, sensor data and activity labels are traditionally collected using special experimental equipment in a controlled environment, which means fitting models trained with these datasets may result in poor generalization to real-life scenarios. Secondly, existing studies focus on single or a few modalities of sensor readings, which neglect useful information and its relations existing in multimodal sensor data. To tackle these issues, we propose a novel activity recognition model for multimodal sensory data fusion: Marfusion, and an experimental data collection platform for HAR tasks in real-world scenarios: MarSense. Specifically, Marfusion extensively uses a convolution structure to extract sensory features for each modality of the smartphone sensor and then fuse the multimodal features using the attention mechanism. MarSense can automatically collect a large amount of smartphone sensor data via smartphones among multiple users in their natural-used conditions and environment. To evaluate our proposed platform and model, we conduct a data collection experiment in real-life among university students and then compare our Marfusion model with several other state-of-the-art models on the collected datasets. Experimental Results do not only indicate that the proposed platform collected Human Activity Recognition data in the real-world scenario successfully, but also verify the advantages of the Marfusion model compared to existing models in Human Activity Recognition.",Applied Sciences,2022.0,10.3390/app12115408,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
92b0c49c5a856b83bc8ac76082e5b4d52e29ef49,https://www.semanticscholar.org/paper/92b0c49c5a856b83bc8ac76082e5b4d52e29ef49,CogniSoft: A Platform for the Automation of Cognitive Assessment and Rehabilitation of Multiple Sclerosis,"Cognitive disorders remain a major cause of disability in Multiple Sclerosis (MS). They lead to unemployment, the need for daily assistance, and a poor quality of life. The understanding of the origin, factors, processes, and consequences of cognitive disfunction is key to its prevention, early diagnosis, and rehabilitation. The neuropsychological testing and continuous monitoring of cognitive status as part of the overall evaluation of patients with MS in parallel with clinical and paraclinical examinations are highly recommended. In order to improve health and disease understanding, a close linkage between fundamental, clinical, epidemiological, and socio-economic research is required. The effective sharing of data, standardized data processing, and the linkage of such data with large-scale cohort studies is a prerequisite for the translation of research findings into the clinical setting. In this context, this paper proposes a software platform for the cognitive assessment and rehabilitation of patients with MS called CogniSoft. The platform automates the Beck Depression Inventory (BDI-II) test and diagnostic tests for the evaluation of memory and executive functions based on the nature of Brief International Cognitive Assessment for MS (BICAMS), as well as implementing a set of games for cognitive rehabilitation based on BICAMS. The software architecture, core modules, and technologies used for their implementation are presented. Special attention is given to the development of cognitive tests for diagnostics and rehabilitation. Their automation enables better perception, avoids bias as a result of conducting the classic paper tests of various neurophysiologists, provides easy administration, and allows data collection in a uniform manner, which further enables analysis using statistical and machine learning algorithms. The CogniSoft platform is registered as medical software by the Bulgarian Drug Agency and it is currently deployed in the Neurological Clinic of the National Hospital of Cardiology in Sofia, Bulgaria. The first experiments prove the feasibility of the platform, showing that it saves time and financial resources while providing subjectivity in the interpretation of the cognitive test results.",Comput.,2020.0,10.3390/computers9040093,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
93421cef562eda8f4546bdba692e45a3e95692e8,https://www.semanticscholar.org/paper/93421cef562eda8f4546bdba692e45a3e95692e8,Hybrid Fault Prognostics for Nuclear Applications: Addressing Rotating Plant Model Uncertainty,"Nuclear plant operators are required to understand the uncertainties associated with the deployment of prognostics toolsin order to justify their inclusion in operational decision making processes and satisfy regulatory requirements. Operationaluncertainty can cause underlying prognostics models to underperform on assets that are subject to evolving impactsof age, manufacturing tolerances, operating conditions, and operating environment effects, of which may be capturedthrough a condition monitoring (CM) system that itself may be degraded. Sources of uncertainty in the data acquisitionpipeline can impact the health of CM data used to estimate the remaining useful life (RUL) of assets. These uncertaintiescan disguise or misrepresent developing faults, where (for example) the fault identification is not achieved until it hasprogressed to an unmanageable state. This leaves little flexibility for the operator’s maintenance decisions and generallyundermines model confidence. 
One method to quantify and account for operational uncertainty is calibrated hybrid models, employing physics, knowledgeor data driven methods to improve model accuracy and robustness. Hybrid models allow known physical relations tooffset full reliance on potentially untrustworthy data, whilst reducing the need for an abundance of representative historicaldata to reliably identify the monitored asset’s underlying behavioural trends. Calibration of the model then ensuresthe model is updated and representative of the real monitored asset by accounting for differences between the physics orknowledge model and CM data. 
In this paper, an open-source bearing knowledge informed machine learning (ML) model and CM datasets are utilizedin an illustrative bearing prognostic application. The uncertainty incurred by the decisions made at key stages in thedevelopment of the model’s data acquisition and processing pipeline are assessed and demonstrated by the resultant impacton RUL prediction performance. It was shown that design decisions could result in multiple valid pipeline designswhich generated different predicted RUL trajectories, increasing the uncertainty in the model output.",PHM Society European Conference,2022.0,10.36001/phme.2022.v7i1.3321,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
07d1f21911f881ee23f512a9a58cd46a689eb3f2,https://www.semanticscholar.org/paper/07d1f21911f881ee23f512a9a58cd46a689eb3f2,2236. Stool-Derived Inflammatory Mediators Serve as Biomarkers of Severity in Clostridium difficile Infection,"Abstract Background Clostridium difficile infection (CDI) is a major public health concern and frequently results in severe disease, including death. Predicting subsequent complications early in the course can help optimize treatments and improve outcomes. However, models based on clinical criteria alone are not accurate and/or do not validate. We hypothesized that inflammatory mediators from the stool would be biomarkers for severity and complications. Methods Subjects were included after testing positive for toxigenic C. difficile by the clinical microbiology laboratory via enzyme immunoassay (EIA) for glutamate dehydrogenase and toxins A/B, with reflex to tcdB gene PCR for discordants. Stool was thawed on ice, diluted 1:1 with PBS and protease inhibitor, centrifuged, and the supernatant was analyzed by a custom antibody-linked bead array with 17 inflammatory mediators. Measurements were normalized and log-transformed. IDSA severity was defined by serum white blood cell count > 15000 cells/µL or creatinine 1.5-fold above baseline. Primary 30-day outcomes were all-cause mortality and attributable disease-related complications (DRC): ICU admission, colectomy, and/or death. Analyses included principal components, permutational multivariate ANOVA (PERMANOVA), and logistic regression ± L1 regularization and 5-fold cross validation. The area under the receiver operator characteristic curve (AuROC) was computed. Results We included 225 subjects, with 124 females (55.1%), average age 58.5 (±17), and more PCR+ than toxin EIA+ (170 vs. 55, respectively). IDSA severity, death, and DRCs occurred in 79 (35.1%), 14 (6.2%), and 12 (5.3%) subjects, respectively. PCA and PERMANOVA showed IDSA severity (P = 0.009) but not death or DRCs associated with the panel (figure). Several inflammatory mediators associated with IDSA severity and death (table). Machine learning models had AuROCs of 0.77 (IDSA severity), 0.84 (death), and 0.7 (DRCs). Conclusion We found that specific inflammatory mediators from the stool of patients with CDI associate with severity and complications. These results are promising, but need replication in a larger dataset and should be incorporated into models that include clinical covariates prior to deployment. Disclosures All authors: No reported disclosures.",Open Forum Infectious Diseases,2019.0,10.1093/ofid/ofz360.1914,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4c1f86c627af4b81933d054e069a49e460120c6d,https://www.semanticscholar.org/paper/4c1f86c627af4b81933d054e069a49e460120c6d,New Application of Blood Pressure Monitor with Software Environment Oranta-AO based on Arterial Oscillography Methods,"The authors for the first time offered new application of blood pressure monitor. For this the original methods of arterial oscillography are substantiated and developed. The methods were implemented in developed Oranta-AO information system. The methods application to the arterial oscillogram registered at measurement of arterial pressure gives the possibility to carry out the supplementary systematic assessment of health, functional state of cardiovascular system, its reserve possibilities; to study the condition of blood vessels; to identify the state of a pre-disease, the effectiveness of therapeutic, preventive and rehabilitative measures. The authors also developed an expert system (based on machine learning methods) for the differential diagnosis of risks of heart, lung, mental illnesses and prognosis of some blood parameters. Based on the methods and algorithms developed as a result of research, Oranta-AO information system was developed allowing the user to take measurements with an electronic blood pressure monitor, load them into the system, get calculated indicators, view them in a convenient way and see analytical information on the basis of which one can assess the state of the cardiovascular system and decide on further action. Information system is deployed on AWS servers and is being tested now. The software developed will significantly expand the scope of electronic pressure monitors. The developed environment aims to be integrated into new models of electronic meters. The next step will be to establish cooperation with manufacturers of electronic pressure monitors and certification in Europe, America and other countries. The activities of Oranta-AO information system provides the ability to integrate into patient monitoring systems and other information systems as well.",IDDM,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fa72c56f6ca63720966eee32b53dbd67a81345dd,https://www.semanticscholar.org/paper/fa72c56f6ca63720966eee32b53dbd67a81345dd,IMPROVED ASSESSMENT OF DELAYED NEUTRON DETECTOR DATA IN CANDU REACTORS,"A common challenge at nuclear power plants is to ensure that routinely-collected data is fully utilised. Data analytics provides an opportunity for improvements in prognostics and health monitoring by identifying correlations in related datasets without major capital investment. This paper describes work focused on improving the fuel defect identification process in Bruce Power’s eight CANDU nuclear reactors in the province of Ontario, Canada. The CANDU reactor comprises individually-pressurised horizontal channels which can be refuelled without taking the reactor offline. The detection and location of fuel defects is typically achieved using two systems: the first monitors the primary coolant for the presence of fission products and specific radionuclides, and is used to detect the presence of fuel defects within the core. The second system is deployed periodically and uses the emission of delayed neutrons to identify the channel containing defect fuel. In this paper we focus on improving the assessment of online delayed neutron monitoring data, with the aim of reducing the time period between initial detection of an in-core defect to identification and removal of the damaged fuel. The existing process is manually intensive, reliant on the judgement of a domain expert and operating experience demonstrates that this time period varies considerably. A first stage of investigation examines potential improvements to the current data processing system: developing and applying new analytic techniques in this area has shown promising results, with some fuel defects potentially identified several days earlier than the current system. Results from some short representative case studies are presented and further work will consider a larger volume of data. In addition, an extensive historical dataset is available which spans several years. In the second stage of investigation, the paper explores previously undocumented trends in this data and discusses the potential to produce correlations with other reactor parameters. The application of this knowledge can lead to opportunities in the use of Machine Learning algorithms to allow more accurate predictions to be made.",The Proceedings of the International Conference on Nuclear Engineering (ICONE),2019.0,10.1299/jsmeicone.2019.27.1541,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0dd6b27fc633e0a892ae0e69e16462f59ee57eea,https://www.semanticscholar.org/paper/0dd6b27fc633e0a892ae0e69e16462f59ee57eea,DIGITAL CAMPAIGN TRACKING WITH RESPECT TO APPLICATION INFRASTRUCTURE,"Digital campaigns are often derailed from their goals due to amiss or often miscalculated aspects of the impact of the campaign on application infrastructure. To mitigate this problem, an approach is described herein which unifies these otherwise disjoint domains of digital marketing and application monitoring analytics. A solution is provided whereby a user may perform capacity planning for upcoming campaigns and perform real time correlation on campaign and infrastructure Key Performance Indicators (KPIs), thus maximizing revenue and optimizing infrastructure cost. Through machine learning algorithms which are running on top of correlated data from both the domains, a plethora of actionable and valuable insights may be unraveled. DETAILED DESCRIPTION In today’s age of technology, companies drive engagement, conversions, traffic, and revenue by running many digital marketing campaigns. The success of these campaigns is of utmost importance to the firm as it ties in with the overarching goals of the organization. Although multiple factors can contribute to the derailment of a campaign from its goals, one oft-ignored factor is how these campaigns affect the infrastructure health of the application. These campaigns usually introduce a spike in application usage and reveal application infrastructure to be under-provisioned. To mitigate the adverse effect of the campaign to an application, firms currently deploy an ad-hoc process. This approach involves capturing key data points of user traffic from campaigns and key performance metrics from an Application Performance Manager 2 Mathur et al.: DIGITAL CAMPAIGN TRACKING WITH RESPECT TO APPLICATION INFRASTRUCT Published by Technical Disclosure Commons, 2018 Copyright 2018 Cisco Systems, Inc. 2 5609 (APM), and attempting to correlate the two. This is limited because the whole process is usually manual, accounts for a limited historical data set, is non-adaptive to continuous changes in campaign strategy or application infrastructure, and is mostly pivoted on prior human experience. Figure 1 below provides examples illustrating these problems.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
17696776a83c12581e8e90d73e7be7c666729c5e,https://www.semanticscholar.org/paper/17696776a83c12581e8e90d73e7be7c666729c5e,Closing the Loop: The Capacities and Constraints of Information and Communication Technologies for Development (ICT4D),"As a mechanism for collecting and sharing information, information and communications technologies (ICT) hold immense potential for individuals and institutions in lowand middle-income countries. Currently the distribution and adoption of ICTs—particularly mobile devices—has far outpaced the provision of other household services like clean water, sanitation, hygiene, or energy services. At the same time, the development and deployment of Internet of Things (IoT) devices including cellularand satellite-connected sensors is facilitating more rapid feedback from remote regions where basic services are most limited. When used in conjunction with economic development or public health interventions, these devices and the feedback they provide can inform operation and maintenance activities for field staff and improve the monitoring and evaluation of outcomes for project stakeholders. This dissertation includes three chapters written as journal articles. While each chapter is framed around the work and research efforts being undertaken by the Sustainable Water, Energy, and Environmental Technologies Lab (SweetLab) at Portland State University, the common thread that weaves all three investigations together is the theme of ICT-enabled programmatic feedback. The first chapter introduces the three theoretical lenses that inform these investigations and the ways that ICTs and the data they provide can (1) serve as more appropriate proxies for measuring access to services, (2) reduce information asymmetries between various stakeholders including communities, governments, implementers, and funders, and (3) enable more robust methodologies for measuring outcomes and impacts of interventions within complex adaptive systems. The second chapter presents a critical review of the methodologies and technologies being used to track progress on sanitation and hygiene development goals. Chapter three describes how simple sensors and weight measurements can be combined with complex machine learning algorithms to facilitate more reliable and",,2000.0,10.15760/etd.6879,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
90ad7e6d2e81cc2c29173e200742bae595e8f895,https://www.semanticscholar.org/paper/90ad7e6d2e81cc2c29173e200742bae595e8f895,Blind Identification of Output-Only Systems and Structural Damage via Sparse Representations,,,2021.0,10.1007/978-3-642-35344-4_77,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
19858e7726e1a23805331da47b4d2ade9af5b716,https://www.semanticscholar.org/paper/19858e7726e1a23805331da47b4d2ade9af5b716,An empirical model-based framework for operational monitoring and prediction of heatwaves based on temperature data,,Modeling Earth Systems and Environment,2022.0,10.1007/s40808-022-01450-2,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a93e75b9cdcff21f0cc804d33271b6fff38c7a22,https://www.semanticscholar.org/paper/a93e75b9cdcff21f0cc804d33271b6fff38c7a22,Digitizing the Pharma Neurons - A Technological Operation in Progress!,"BACKGROUND
Digitization and automation is the buzzword in clinical research and pharma companies are investigating heavily here. Right from drug discovery to personalized medicine, digital patients and patient engagement, there is great consideration of technology at each step.


METHODS
The published data and online information available is reviewed to give an overview of digitization in pharma, across the drug development cycle, industry collaborations and innovations. The regulatory guidelines, innovative collaborations across industry, academics and thought leadership are presented. Also included are some ideas, suggestions, way forwards while digitizing the pharma neurons, the regulatory stand, benefits and challenges.


RESULTS
The innovations range from discovering personalized medicine to conducting virtual clinical trials, and maximizing data collection from the real-world experience. To address the increasing demand for the real-world data and the needs of tech-savvy patients, the innovations are shaping up accordingly. Pharma companies are collaborating with academics and they are co-innovating the technology. E.g. Massachusetts Institute of Technology's program. This focuses on the modernization of clinical trials, strategic use of artificial intelligence and machine learning using real-world evidence, assess the risk-benefit ratio of deploying digital analytics in medicine, and proactively identifying the solutions.


CONCLUSIONS
With unfolding data on impact of science and technology amalgamation, we need a need shared mindset between data scientists and medical professionals to maximize the utility of enormous health and medical data. To tackle this efficiently, there is a need of cross-collaboration and education, and align with ethical and regulatory requirements. A perfect blend of industry, regulatory, and academia will ensure a successful digitization of pharma neurons.",Reviews on recent clinical trials,2020.0,10.2174/1574887115666200621183459,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
45c6f3f13f3a66989d808541c2cdd7b2085b2f05,https://www.semanticscholar.org/paper/45c6f3f13f3a66989d808541c2cdd7b2085b2f05,Sequentially-reduced representation of artificial neural network to determine cardiovascular intrinsic frequencies,"Analysis of cardiovascular waveforms provides valuable clinical information about the state of health and disease. The intrinsic frequency (IF) method is a recently introduced framework that uses a single arterial pressure waveform to extract physiologically relevant information about the cardiovascular system. The clinical usefulness and physiological accuracy of the IF method have been well-established via several preclinical and clinical studies. However, the computational complexity of the current L2 optimization solver for IF calculations remains a bottleneck for practical deployment of the IF method in real-time settings. In this paper, we propose a machine learning (ML)-based methodology for determination of IF parameters from a single carotid waveform. We use a sequentially-reduced Feedforward Neural Network (FNN) model for mapping carotid waveforms to the output parameters of the IF method, thereby avoiding the non-convex L2 minimization problem arising from the conventional IF approach. Our methodology also includes procedures for data pre-processing, model training, and model evaluation. In our model development, we used both clinical and synthetic waveforms. Our clinical database is composed of carotid waveforms from two different sources: the Huntington Medical Research Institutes (HMRI) iPhone Heart Study and the Framingham Heart Study (FHS). In the HMRI and FHS clinical studies, various device platforms such as piezoelectric tonometry, optical tonometry (Vivio), and an iPhone camera were used to measure arterial waveforms. Our blind clinical test shows very strong correlations between IF parameters computed from the FNN-based method and those computed from the standard L2 optimization-based method (i.e., R≥0.93 and P-value ≤0.005 for each IF parameter). Our results also demonstrate that the performance of the FNN-based IF model introduced in this work is independent of measurement apparatus and of device sampling rate.",bioRxiv,2022.0,10.1101/2022.02.14.480311,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
df58137d8738ae80f7dcf345f6c8ca7f17dbea69,https://www.semanticscholar.org/paper/df58137d8738ae80f7dcf345f6c8ca7f17dbea69,"The Role of Energy Reservoirs in Distributed Computing: Manufacturing, Implementing, and Optimizing Energy Storage in Energy-Autonomous Sensor Nodes","Author(s): Cowell, Martin A | Advisor(s): Wright, Paul K | Abstract: The world already hosts more internet connected devices than people, and that ratio is only increasing. These devices seamlessly integrate with peoples lives to collect rich data and give immediate feedback about complex systems from business, health care, transportation, and security. As every aspect of global economies integrate distributed computing into their industrial systems and these systems benefit from rich datasets. Managing the power demands of these distributed computers will be paramount to ensure the continued operation of these networks, and is elegantly addressed by including local energy harvesting and storage on a per-node basis. By replacing non-rechargeable batteries with energy harvesting, wireless sensor nodes will increase their lifetimes by an order of magnitude.This work investigates the coupling of high power energy storage with energy harvest- ing technologies to power wireless sensor nodes; with sections covering device manufacturing, system integration, and mathematical modeling. First we consider the energy storage mechanism of supercapacitors and batteries, and identify favorable characteristics in both reservoir types. We then discuss experimental methods used to manufacture high power supercapacitors in our labs. We go on to detail the integration of our fabricated devices with collaborating labs to create functional sensor node demonstrations.With the practical knowledge gained through in-lab manufacturing and system integration, we build mathematical models to aid in device and system design. First, we model the mechanism of energy storage in porous graphene supercapacitors to aid in component architecture optimization. We then model the operation of entire sensor nodes for the purpose of optimally sizing the energy harvesting and energy reservoir components. In consideration of deploying these sensor nodes in real-world environments, we model the operation of our energy harvesting and power management systems subject to spatially and temporally varying energy availability in order to understand sensor node reliability. Looking to the future, we see an opportunity for further research to implement machine learning algorithms to control the energy resources of distributed computing networks.",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
505195a1db461b083ee30141923b1610ec2cb8ee,https://www.semanticscholar.org/paper/505195a1db461b083ee30141923b1610ec2cb8ee,Artificial intelligence and the dreaded 's.,"Numerous industries are being disrupted by growth in new technologies, especially information technologies, and healthcare is no exception. Advances in robotics, wireless sensor networks, 5D printing, and cloud technologies are reshaping countless industries. I am intrigued by the increasing importance of automation, machine learning, and artifi cial intelligence (AI) in healthcare. Let us explore three questions together: • Where are common applications of AI and automation in healthcare? • What implications for physician assistants (PAs) arise from increased automation and AI in caring for patients? • Did AI bring back the ’s that causes any self-respecting PA to cringe? I nearly panicked recently when I caught sight of the following two headlines from online articles about new healthcare technologies, which might lead a person to think the PAs of the future are not people at all. At the very least, I was ready to e-mail the AAPA communications team to combat those pesky apostrophes. The articles actually detailed advances in automation and AI within healthcare. Bright.MD raises another $8M for “virtual physician’s assistant” SmartExam (www.mobihealthnews.com/content/ brightmd-raises-another-8m-virtual-physicians-assistantsmartexam) Healthcare Chatbots: The Physician’s Assistant of the Future? (http://blog.kantarhealth.com/blog/brian-mondry/ 2016/11/28/healthcare-chatbots-the-physician’s-assistantof-the-future) Next, let us sort out AI and automation. According to Merriam Webster, artifi cial intelligence is the capability of a machine to imitate intelligent human behavior. Automation, on the other hand, is the automatically controlled operation of an apparatus, process, or system by mechanical or electronic devices that take the place of human labor. COMMON APPLICATIONS A widely adopted automation in healthcare is appointment reminder software that automatically reminds patients of their upcoming scheduled appointments, with options to customize the message and/or time it is delivered for patient preference. Similarly, missed appointment notifi cation systems can alert a PA to a potentially worrisome pattern of missed appointments for a patient identifi ed as high-risk. Robotics, commonly deployed in areas such as pharmacy and surgery, are automations proven to increase effi ciency and safety. According to CB Insights, about 86% of healthcare provider organizations, life science companies, and healthcare technology vendors are using AI technology. The most common applications seem to fall into one of ten categories: managing medical records and other data; doing repetitive jobs such as analyzing tests, interpreting radiologic studies, and data entry; helping design treatment plans; digital consultation (such as the Babylon app); virtual nurses (such as the Molly app), medication management (such as the AiCure app); drug development; precision medicine; health monitoring; and healthcare system analysis.1 Numerous tech giants are investing heavily in AI applications for healthcare as well, such as Microsoft’s Healthcare NExT initiative and Google’s Deepmind Health.",JAAPA : official journal of the American Academy of Physician Assistants,2018.0,10.1097/01.JAA.0000530302.23280.25,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
92079950bb4c636c26cf39f1d9d774d30e8140a9,https://www.semanticscholar.org/paper/92079950bb4c636c26cf39f1d9d774d30e8140a9,A Hybrid Optimized LSTM Models for Human Activity Recognition with IOT Devices,"With the advent of Internet of things(IoT),HA (HA) recognition has contributed the more application in health care in terms of diagnosis and Clinical process. These devices must be aware of human movements to provide better aid in the clinical applications as well as user’s daily activity.Also , In addition to machine and deep learning algorithms, HA recognition systems has significantly improved in terms of high accurate recognition. However, the most of the existing models designed needs improvisation in terms of accuracy and computational overhead. In this research paper, we proposed a BAT optimized Long Short term Memory (BAT-LSTM) for an effective recognition of human activities using real time IoT systems. The data are collected by implanting the Internet of things) devices invasively. Then, proposed BAT-LSTM is deployed to extract the temporal features which are then used for classification to HA. Nearly 10,0000 dataset were collected and used for evaluating the proposed model. For the validation of proposed framework, accuracy, precision, recall, specificity and F1-score parameters are chosen and comparison is done with the other state-of-art deep learning models. The finding shows the proposed model outperforms the other learning models and finds its suitability for the HA recognition.","International Journal of Advanced Research in Science, Communication and Technology",2021.0,10.48175/ijarsct-2326,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6b50c433bdfee628e81f0f4b5dc922b9c2cc4fa7,https://www.semanticscholar.org/paper/6b50c433bdfee628e81f0f4b5dc922b9c2cc4fa7,Machine Learning Prediction of Surgical Intervention for Small Bowel Obstruction,"Small bowel obstruction (SBO) results in >350,000 operations and >$2 billion annual health care expenditures in the US. Prompt, effective identification of patients at high/low surgery risk could improve survival, lower complication rates, and shorten hospitalization lengths. SBO surgery prediction models were developed based on SBO-related encounters in the Duke University Health System between 2013 and 2017. A total of 3,910 encounters among 3,374 unique patients were identified. Performance was assessed in each hour after admission when predicting whether patients will (a) receive surgery within 24 hours, and (b) receive surgery during the current encounter. Potential benefits of model-based discharge were assessed using the incorrect discharge rate and average reduction in hospital stay. Model-based discharge of low-risk patients was projected to reduce the average length of stay among patients not receiving surgery by >60 hours while maintaining an incorrect discharge rate lower than the observed readmission rate (9.3%). AUROC for the 24-hour prediction task increased from 0.644 to 0.779 at 12 and 72 hours post-admission, respectively. Future work will prospectively explore the benefits of model deployment in an inpatient setting.",medRxiv,2021.0,10.1101/2021.04.13.21255428,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bd34e252c3219f51f9ef569e506ca5d078daddde,https://www.semanticscholar.org/paper/bd34e252c3219f51f9ef569e506ca5d078daddde,"Come What May, Digital Health Technologies Will Never Be Able to Predict the Emergence of Unknown Viruses and Microorganisms with any Degree of Certainty",,Journal of Medical Systems,2020.0,10.1007/s10916-020-01667-7,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f05ae3411a1e1b01631514b85fbf25f7437ed639,https://www.semanticscholar.org/paper/f05ae3411a1e1b01631514b85fbf25f7437ed639,A Study of Convolutional Neural Networks Learning Mechanisms for Machine Health Monitoring Applications,"In recent years, Deep Learning (DL) and Internet of Things (IoT) technologies have been used and deployed jointly to solve a wide range of modern technical challenges in different areas. With the continuous advancement of IoT connectivity solutions, the range of applications that can benefit from such an increase is limitless. One area that can benefit significantly from the combined strength of DL and IoT technologies is Machine Health Monitoring (MHM) Systems. MHM utilizes different analytical approaches and tools to determine the state and health of different components in running machinery. The traditional MHM system uses control limits from predetermining values that determine if a component has failed depending on the preset limits of the machinery. The main disadvantage of using such technique us the unpredictable nature of the timing and component failure. This type of failure causes unplanned production time loss and increases the cost of maintenance due to the unpredictability of the failure events. With DL and low-cost sensors that use different IoT connectivity solutions, MHM systems can utilize the learning capabilities of the DL network to perform end-to-end prognosis. One crucial fact is that features learned by Deep Neural Networks (DNN) are part of a large black box, and there are valuable underlying physical meanings embedded within the features. Hence, there is an exciting research area to explore underlying mechanisms and interpret physical meanings within DNN. In this paper, DNN learning mechanisms are evaluated using three different models: stacked autoencoders (SAE), denoising autoencoders (DAE), and convolutional neural networks (CNN). Initial results indicate that the input layer behaves similarly to a band-pass filter.  However, deep layers require optimal input design to maximize neuron activation, which leads to an extensive understanding of deep layer learning consequently (In progress).",,2020.0,10.36001/PHMCONF.2020.V12I1.1196,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c73a5bbaa78e38774e19302eb2da534e6d0cb322,https://www.semanticscholar.org/paper/c73a5bbaa78e38774e19302eb2da534e6d0cb322,17. Comparative Assessment of a Machine Learning Model and Rectal Swab Surveillance to Predict Hospital Onset Clostridioides difficile,"Abstract Background Hospital onset Clostridioides difficile infection (HO-CDI) is associated with significant morbidity and mortality. Screening individuals at risk could help limit transmission, however swab-based surveillance for HO-CDI is resource intensive. Applied to electronic health records (EHR) data, machine learning (ML) models present an efficient approach to assess patient risk. We compare the effectiveness of swab surveillance against daily risk estimates produced by a ML model in detecting patients who will develop HO-CDI. Methods Patients presenting to Michigan Medicine’s ICUs and oncology wards between June 6th and October 8th 2020 had rectal swabs collected on admission, weekly, and at discharge from the unit, as part of VRE surveillance. We performed anaerobic culture on the residual media followed by a custom, multiplex PCR on isolates to identify toxigenic C. difficile. Risk of HO-CDI was calculated daily for each patient using a previously validated EHR-based ML model. Swab results and model risk scores were aggregated for each admission and assessed as predictors of HO-CDI. Holding sensitivity equal, we evaluated both approaches in terms of accuracy, specificity, and positive predictive value (PPV). Results Of 2,044 admissions representing 1,859 patients, 39 (1.9%) developed HO-CDI. 23.1% (95% CI: 11.1–37.8%) of HO-CDI cases had at least one positive swab. At this sensitivity, model performance was significantly better than random but worse compared to swab surveillance—accuracy: 87.5% (86.0–88.9%) vs. 94.3% (93.3–95.3%), specificity: 88.7% (87.3–90.0%) vs. 95.7% (94.8–96.6%), PPV: 3.8% (1.6–6.4%) vs. 9.4% (4.3–16.1%). Combining swab AND model yielded lower sensitivity 2.6% (0.0–8.9%) compared to combining swab OR model at 43.6% (27.3–60.0%), and yielded PPV 7.1% (0.0–25.0%) vs. 43.6% (27.3–60.0%) respectively (Figure 1). Figure 1. Surveillance & risk score performance. Binary classification performance metrics of ML model (Model), toxigenic C. difficile rectal swab surveillance (Swab), and combination approaches (Model AND Swab and Model OR Swab), reported in terms of percentage points. Bold numbers highlight the best performing approach for a given performance metric. The combined approach of monitoring the Model AND Swab yielded the highest accuracy 97.5% (95% confidence interval: 96.8%, 98.1%), it also had the highest specificity 99.4% (99.0%, 99.7%). The combined approach of monitoring the Model OR Swab yielded the highest sensitivity 43.6% (27.3%, 60.0%) and negative predictive value (NPV) 98.7% (98.2, 99.2%). Using the Swab alone yielded the highest PPV 9.4% (4.3%, 16.1%) and F1 score 13.3% (6.2%, 21.8%). These results highlight the complementarity of the model and swab-based approaches. Conclusion Compared to swab surveillance using a ML model for predicting HO-CDI results in more false positives. The ML model provides daily risk scores and can be deployed using different thresholds. Thus, it can inform varied prevention strategies for different risk categories, without the need for resource intensive swabbing. Additionally, the approaches may be complimentary as the patients with HO-CDI identified by each approach differ. Disclosures Vincent B. Young, MD, PhD, American Society for Microbiology (Other Financial or Material Support, Senior Editor for mSphere)Vedanta Biosciences (Consultant) Krishna Rao, MD, MS, Bio-K+ International, Inc. (Consultant)Merck & Co., Inc. (Grant/Research Support)Roche Molecular Systems, Inc. (Consultant)Seres Therapeutics (Consultant)",Open Forum Infectious Diseases,2021.0,10.1093/ofid/ofab466.017,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
eaab67c647fe36f99217b5486965525d32b14193,https://www.semanticscholar.org/paper/eaab67c647fe36f99217b5486965525d32b14193,On-Device Implementation for Deep-Learning-Based Cognitive Activity Prediction,"Cognitive activity prediction (CAP) from electroencephalogram (EEG) signals is progressively utilized in the field of brain–computer interface (BCI) and mental health management. Various machine and deep learning methods have been proposed recently for CAP. However, since Internet-of-Things-based real-time BCI systems demand low latency, power, and portability, these methods need to be deployable on resource-constrained edge devices. Towards this aspect, we propose a real-time implementation of a lightweight 1-D convolutional neural network on an Arduino Due microcontroller for CAP from EEG signals. The performance evaluation on two public datasets and one real-time recorded dataset indicates that the proposed work achieves subject-independent prediction accuracies of 99.30%, 82.50%, and 99.02% in these datasets. Furthermore, the prediction of real-time recorded EEG signals is accurate for majority of the subjects. The proposed work outperforms the existing techniques and achieves low power consumption of <inline-formula><tex-math notation=""LaTeX"">$\text{0.63}\,\text{W}$</tex-math></inline-formula> in real-time on-device implementation with an average latency of <inline-formula><tex-math notation=""LaTeX"">$\text{455.12}\,\text{ms}$</tex-math></inline-formula> in model deployment, test output prediction, and activity-based transmission.",IEEE Sensors Letters,2022.0,10.1109/lsens.2022.3156158,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ecfda50a15a143be0e5b0cae0ca710a53ba39718,https://www.semanticscholar.org/paper/ecfda50a15a143be0e5b0cae0ca710a53ba39718,CONFERENCE ON ACTIVE & HEALTHY AGEING,"Active Healthy Ageing (AHA) systems such as REACH turn clinical and care environments such as homes, home care, and everyday life, day care centers, and other geriatric facilities into highly personalized and data-driven early intervention settings that engage older persons in meaningful preventative and rehabilitative activity (primarily physical activity but also with regard to cognitive, mobility, social, and nutritional aspects). A unique feature of REACH is the integrated utilization of personalized behavior change and engagement techniques informing the deployment of the toolkit elements (sensors, interfaces, devices, etc.). REACH implements a combination of wearable and ambient sensors for each Touchpoint along with a set of co-adapted Machine Learning elements. Personalized Intelligent Interior Units (PI2Us) are used to integrate the above described functional elements physically and seamlessly into daily life. Prof. Andrew Sixsmith, Simon Fraser Univ.: Responding to the Challenge of Aging The Canadian AGE-WELL Network of Centres of Excellence Abstract: Information and communication technologies (ICTs) have huge potential to enhance the health, well-being, and independence of seniors, and also open up opportunities for new services and businesses. ICTs can be used to meet the desire of most seniors to age in place and to provide solutions to increased demands on health and community services. Despite this “win-win” scenario, the actual impact of research has often been limited, with good ideas and technologies failing to be turned into new products and services. This presentation looks at how AGE-WELL (Aging Gracefully across Environments using Technology to Support Wellness, Engagement, and Long Life NCE Inc.), a Canadian Network of Centres of Excellence (http:// www.agewell-nce.ca), is working towards taking the outcomes of great research from the laboratory into the real-world. Information and communication technologies (ICTs) have huge potential to enhance the health, well-being, and independence of seniors, and also open up opportunities for new services and businesses. ICTs can be used to meet the desire of most seniors to age in place and to provide solutions to increased demands on health and community services. Despite this “win-win” scenario, the actual impact of research has often been limited, with good ideas and technologies failing to be turned into new products and services. This presentation looks at how AGE-WELL (Aging Gracefully across Environments using Technology to Support Wellness, Engagement, and Long Life NCE Inc.), a Canadian Network of Centres of Excellence (http:// www.agewell-nce.ca), is working towards taking the outcomes of great research from the laboratory into the real-world.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
be51e5dd5b79b7de073babff9baf55d91c3787d3,https://www.semanticscholar.org/paper/be51e5dd5b79b7de073babff9baf55d91c3787d3,A spatial decision support system to assess personal exposure to air pollution integrating sensor measurements,"Recent epidemiological studies have reinforced the link between short and long-term exposure to air pollutants and adverse effects on public health especially over the weaker part of the population, like children and older adults. The creation of simple tools to locate sensible areas as well as of dedicated Spatial Decision Support System (SDSS) to improve the management of pollution risk areas system is strongly advised. The aim of this work is to develop a SDSS methodology, based on easy to find data and usable by decision makers, to assess and reduce the impact of air pollutants in a urban context. To achieve this goals I tested the exploitability of a set of low-cost sensors for outdoor air quality monitoring, I characterized the urban micro-environments and the spatial variability of air pollutants using remote sensing compared to field data and eventually I developed a SDSS to improve the public health designing and comparing different scenarios. The city centre of Edinburgh has been used as study case for the purposed methodology. To test the reliability and applicability of low cost sensors as proxies for remote sensed data, we conducted a measurements campaign to compare the observed data between an official measurements station (OMS) in Trento (Italy) and electrochemical and thick film sensors respectively of Carbon Monoxide (CO) and Ozone ($O_3$). Due to data quality and availability we decided to characterize the urban micro-environments of Edinburgh (Scotland, UK) in eight main classes (water, grass, vegetation, road, car, bus, buildings and shadow) combining the Geographic Object-Based Image Analysis (GEOBIA) with Machine Learning algorithms to process the high resolution (0.25m x 0.25m) RGB aerial ortho-rectified images. This land-use characterization combined with other geographical informations, like the classification of the roads and the urban morphology, were compared with 37 Nitrogen Dioxide (NO2) concentration data, collected using passive tubes during a six week campaign of measurements conducted by the school of Chemistry of the University of Edinburgh. 
I developed a new open-source GIS python library (PyGRASS), integrated in the stable release of GRASS GIS, to speed-up the prototyping phase and to create and test new GIS tools and methodologies. Different studies on SDSS were carried out to implement procedures and models. Based on these models and data all the factors (land-use, roads and geo-morphological features) were ranked to identify which are driving forces for urban air quality and to help decision makers to develop new policies. The sensor tested in Trento revealed an evident drift in measurement residues for CO, furthermore the measurements were also quite sensitive to external factors such as temperature and humidity. Since these sensors required frequent recalibration in order to obtain reliable results, their use was not as low-cost as expected. The characterization of urban land-use in Edinburgh with GEOBIA and machine learning provided an overall accuracy of 93.71\% with a Cohen's k of 0.916 using a train/test dataset of 9301 objects. The $NO_2$ data confirm the assumption that air concentration is strongly dependent on geographical position and it is strongly influenced by the position of the pollutant's source. Using the results of the tests and remote sensing analysis, I developed an SDSS. Starting from the current situation, I designed three scenarios to assess the effect that different policies and actions could have on improving air quality at on the local and district level. The outcomes of this work can be used to define and compare different scenarios and develop effective policies to reduce the impact of air pollutants in an urban context using simple and easy to find data. The GIS-based tool can help to identify critical areas before deploying sensors and splitting the study area in homogeneous micro-environments clusters. The model is easy to expand following different procedures.",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8d41a4382c9da6887bb7eb011c157aa312229841,https://www.semanticscholar.org/paper/8d41a4382c9da6887bb7eb011c157aa312229841,"Measuring Network Experience Meaningfully, Accurately, and Scalably","We take the position that end-users should not be expected to understand network quality in terms of engineering metrics such as throughput, latency and loss. A typical user cares how well their network supports “experience” on their “application” i.e. how often will their streaming video freeze, their game lag spike, and their conference stutter and they need to be told this directly rather than by inference. We further contend that emerging capabilities in Programmable Networking and Machine Learning make it viable to measure application experience in a meaningful, accurate, and scalable manner. We briefly comment on recent academic research supporting our thesis, and on our experiences building and deploying a commercial platform to directly measure application experience at scale in carrier networks. 1. Application Experience Metrics Meaningful to Users Network performance is reported today in terms of throughput speed-test services like Ookla publish global indices [1] of average mobile and broadband speeds per country, and government regulators e.g. ACCC in Australia [2] operate nationally funded broadband speed-measurement programs. It is unclear if the outcomes are meaningful to a lay user; for example consider the headline figure below taken from the ACCC’s Measuring Broadband Australia (MBA) latest monthly report: Fig. 1: Average download speed by ISP, taken from the ACCC MBA Report 14, Aug 2021 [2] A lay user would infer from the figure above: “if I choose Telstra as my ISP, I will get 99.8% of my plan speed on average during peak hour, whereas if I choose Optus, I will get 100.4%”. A user would have no idea whether the reported speed difference across ISPs is significant or not to their streaming video, gaming, or conferencing experience. Add to this the variability of speed-test results (the error bars are larger than the differences across providers), their susceptibility to test conditions (such as server location, number of test threads, etc.), and their synthetic bursty traffic patterns that are unrepresentative of typical application behavior, the value of throughput measurement is indeed questionable [3]. As broadband speeds approach 100 Mbps, further increases in speed become largely imperceptible to users [4]. Indeed, growth in broadband speed is eclipsed by the growth in volume the average Australian household consumed 355 GB in Dec 2020, representing a 59% year-on-year increase [5]. Our Internet usage is therefore increasingly resembling a marathon of video streaming, gaming, and teleconferencing consuming more and more data miles each day, rather than a few-second sprint as measured and reported using speed -tests. In contrast to the speed-test comparison shown above, imagine if we could present the user with a direct comparison of streaming video and gaming experience across ISPs: Fig. 2: Video streaming across ISPs: (a) % time in highest quality; and (b) buffer stalls per hour Fig. 3: Lag spikes (90-th percentile latency) for selected game titles across ISPs A lay person can easily glean from Fig. 2 that users are most likely to get the highest resolution video during busy hours from ISP2, while buffer stalls are lowest with ISP1. Fig. 3 informs them that ISP9 offers the most stable latency (i.e. lowest jitter) for online shooting games. Similar comparisons can be shown for conferencing apps [6], game downloads, etc. Speed-test metrics can be enriched (if not replaced) with the application-level metrics above, since end-users can much more easily relate the latter with their everyday usage of the Internet. 2. Measuring Application Experience Accurately at Scale Our second contention is that application experience meaningful to users (as described above) can be measured accurately and at scale, using emerging technologies of Programmable Networks and Machine Learning. Prior academic works such as [7,8,9] have shown that streaming video experience including stream resolution and buffer health can be estimated accurately by analysing network traffic, and recently in [10] we have shown that similar inferences can be made for live video streams. These methods work agnostic to packet encryption, using network behavioral patterns video streams transfer data in chunks, with conspicuous spurts of network activity separated by idle periods machine learning models can be trained to correlate the video resolution quality and buffer state with the time-series patterns of height, width, and spacing of chunks across potentially multiple flows corresponding to a video stream. Similar techniques have been developed for inferring online gaming experience [11] state machines track the various stages (lobby, matchmaking, server-selection, and game-play) of each gaming stream, along with latency and jitter (using multiple techniques adapted to specific TCP and UDP games), and map them to experience values specific to the game genre (e.g shooting, strategy, sports, role-play, etc.). In (as yet) unpublished work we have extended our machines to deduce user experience for the major conferencing application platforms such as Zoom, Teams, WebEx, WhatsApp, and Discord. Further, the application experience measurements above can be done at Terabit speeds using emerging programmable networks switches. Canopus Networks (https://www.canopusnet.com/) has built a commercial platform that: (a) takes a raw feed of Terabit traffic by optically tapping links in a carrier network; (b) extracts stream-level attributes (named FlowPulseTM) using custom P4-code operating on a Intel/Barefoot Tofino-powered Programmable Switch; (c) exports these attributes via push (postcard-based) telemetry to ML engines in general purpose compute; (d) makes inferences on application type (video on-demand, live video, gaming, conferencing, downloads, etc.) and provider (Netflix, CoD, Zoom, Steam, etc.) for each long-lived traffic flow; and (e) estimates user experience in easy-to-understand terms (resolution and buffer health for streaming video, latency for gaming, stutters for conferencing, download speeds for gaming updates, etc.). These are exported via APIs for real-time consumption, and logged in databases for forensic evaluation. 3. Deployments and Learnings The Canopus platform for application experience measurement is commercially deployed in multiple carrier networks in Australia, covering hundreds of thousands of broadband subscribers. Our ongoing engagements and preliminary results show promise in helping ISPs address various blind spots: 1. Better network dimensioning: Network operators in Australia need to purchase network capacity on a daily/weekly basis from the nationalised access infrastructure (NBN); data on usage behavior patterns coupled with quantification of user experience is allowing operators to minimise over-provisioning (which incurs unnecessary expense) while avoiding under-provisioning (which impacts user experience). The data is also helping them prepare for shock events, such as release of large game patches. 2. Quantifying premium gaming products: Network operators are starting to offer premium gaming products, such as gaming-optimised home routers and gaming VPN/CDN overlays. Data on user experience is helping operators benchmark the efficacy of their premium offerings in combating various factors affecting gameplay experience, including contention in the home, congestion in the aggregation network, and dynamic selection of game servers. 3. Identifying root cause of network problems: Customer support and churn affects the ISP bottom line. Visibility into user experience is enabling operators to trouble-shoot specific customer complaints relating to streaming, gaming, and conferencing experience degradation, by giving them fine-grained data on the potential root cause of the degradation event. In some instances it was found to be household contention (devices doing backups and cloud sync unbeknownst to the user), and in other instances it was determined to be more likely the home WiFi. 4. Network tuning: An interesting use-case enabled by the real-time experience measurement capability is to tune the network to achieve an explicit trade-off point in performance across applications. For example, tuning the shaping buffer in the BNG to a larger value improves the throughput of a download stream (including traffic blasts from a speed-test), but worsens jitter for a game-play stream (which sends periodically spaced packets). The ability to explicitly capture this application experience trade-off allows operators to make better network tuning decisions.",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3f76ff4358c5529243aaf03bb0df018081a2998c,https://www.semanticscholar.org/paper/3f76ff4358c5529243aaf03bb0df018081a2998c,A new scoring system for upper gastrointestinal bleeding: Too simple or still complicated?,"Risk stratification for patients with upper gastrointestinal bleeding (UGIB) is recommended by international care guidelines and thought to be part of the standard of care. In particular, pre-endoscopic risk scores are useful because they provide earlier risk assessment compared to scores that use endoscopic findings. However, most of these scores involve multiple clinical and biochemical parameters and are too complicated to be used in a busy emergency medicine or gastroenterology unit on a regular basis. In this issue of the Journal of Gastroenterology and Hepatology, Redondo-Cerezo et al. have developed a “simple” risk score named MAP (ASH) score (using six parameters namely mental status, American Society of Anesthesiologists score, pulse and blood pressure, and albumin and hemoglobin levels and a simple calculator) that performs well and is easily implementable at the point of care. This score was developed from an international cohort of patients with UGIB and validated in a single tertiary referral center. It performed similarly to the best performing risk score (Glasgow-Blatchford Score) in predicting need for hospital-based intervention (area under the curve [AUC] 0.83), 30-day mortality (AUC 0.74), endoscopic intervention (AUC 0.61), and rebleeding (AUC 0.73). MAP (ASH) is simpler than the Glasgow-Blatchford Score and easier to calculate, which may help busy practitioners apply the score in practice. MAP (ASH) was developed for risk stratification in patients presenting to the hospital prior to endoscopic evaluation to guide provider decision making. The score uses mostly clinical variables, including a global physician assessment with the American Society of Anesthesiologists score. The current study demonstrates a valiant effort to reduce the mental load in calculating risk for patients with UGIB, but the inherent difficulty of performing a complex calculation during a busy clinical workflow remains unsolved particularly because the ideal use would be making the calculation directly from memory rather than having to break the workflow to enter data into an online calculator. The simplified point system still requires remembering which elements represent higher point totals, and there are two A’s (American Society of Anesthesiologists score and albumin level) that have different point values that may create confusion. Furthermore, specific cutoffs (e.g. albumin < 2.5 and hemoglobin < 10) still must be memorized. While MAP (ASH) and other clinical scores will continue to shed light on meaningful factors that can be used for prognostic modeling, the challenges of clinical uptake by clinicians and good performance of outcome prediction will be difficult to surmount. One solution to improve clinical uptake is through automatic deployment using the electronic health record that is available in many established healthcare systems. This would minimize manual data entry and potentially provide the score at the point of care for clinical decision support. More computationally complex solutions such as machine learning has shown promise in improving performance beyond that of existing clinical risk scores. Recently, a pre-endoscopic risk score was developed using a machine learning gradient-boosted model with improved performance overall and better ability to identify very low risk patients compared with the Glasgow-Blatchford Score. The potential of machine learning also includes the ability of the model to “learn” over time and for models to be customized for each center by retraining the model on center-specific data. Hence, this AI-assisted prediction model will continue to improve with time and experience. However, machine learning models increase the burden of data entry because they include of more variables, require computational infrastructure that is not widely available, and are not easily interpretable. Much work has to be done in this area, but we are starting to see new light at the end of tunnel. In summary, the development of MAP (ASH) represents a new simplified model that can be used to prognosticate in patients with UGIB. Hopefully, the addition of this score to the array of risk scores in UGIB will provide another option for busy providers to triage patients appropriately as part of timely and high-quality care.",Journal of gastroenterology and hepatology,2020.0,10.1111/jgh.14959,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7d6a17b28d98787fccf163c50be070d6f4dab186,https://www.semanticscholar.org/paper/7d6a17b28d98787fccf163c50be070d6f4dab186,AI-Augmented Clinical Decision Support in a Patient-Centric Precision Oncology Registry,"Purpose: xDECIDE is a clinical decision support system, accessed through a web portal and powered by a ""Human-AI Team"", that offers oncology healthcare providers a set of treatment options personalized for their cancer patients, and provides outcomes tracking through an observational research protocol. This article describes the xDECIDE process and the AI-assisted technologies that ingest semi-structured electronic medical records to identify and then standardize clinico-genomic features, generate a structured personal health record (PHR), and produce ranked treatment options based on clinical evidence, expert insights, and the real world evidence generated within the system itself. Method: Patients may directly enroll in the IRB-approved pan-cancer XCELSIOR registry (NCT03793088). Patient consent permits data aggregation, continuous learning from clinical outcomes, and sharing of limited datasets within the research team. Assisted by numerous AI-based technologies, the xDECIDE team aggregates and processes patients' electronic medical records, and applies multiple levels of natural language processing (NLP) and machine learning to generate a structured case summary and a standardized list of patient features. Next a ranked list of treatment options is created by an ensemble of AI-based models, called xCORE. The output of xCORE is reviewed by molecular pharmacologists and expert oncologists in a virtual tumor board (VTB). Finally a report is produced that includes a ranked list of treatment options and supporting scientific and medical rationales. Treating physicians can use an interactive portal to view all aspects of these data and associated reports, and to continuously monitor their patients' information. The xDECIDE system, including xCORE, is self-improving; feedback improves aspects of the process through machine learning, knowledge ingestion, and outcomes-directed process improvement. Results: At the time of writing, over 2,000 patients have enrolled in XCELSIOR, including over 650 with CNS cancers, over 300 with pancreatic cancer, and over 100 each with ovarian, colorectal, and breast cancers. Over 150 VTBs of CNS cancer patients and ~100 VTBs of pancreatic cancer patients have been performed. In the course of these discussions, ~450 therapeutic options have been discussed and over 2,000 consensus rationales have been delivered. Further, over 500 treatment rationale statements (""rules"") have been encoded to improve algorithm decision making between similar therapeutics or regimens in the context of individual patient features. We have recently deployed the xCORE AI-based treatment ranking algorithm for validation in real-world patient populations. At present approximately 15 patients are processed each week via the full xDECIDE process, including xCORE, under the continuing oversight of experts and VTBs. Conclusion: Clinical decision support through xDECIDE is available for oncologists to utilize in their standard practice of medicine by enrolling a patient in the XCELSIOR trial and accessing xDECIDE through its web portal. This system can help to identify potentially effective treatment options individualized for each patient, based on sophisticated integration of real world evidence, human expert knowledge and opinion, and scientific and clinical publications and databases.",medRxiv,2022.0,10.1101/2022.03.14.22272390,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c404631799f6601e6ac021602383ef0b5da686d8,https://www.semanticscholar.org/paper/c404631799f6601e6ac021602383ef0b5da686d8,"Society for Technology in Anesthesia STA Virtual Annual Meeting Syllabus January 15 , 2021 7 : 00 am-4 : 30","Full Abstract Title Presenting Author Institution C L IN IC A L A P P L IC A T IO N S 1 A Novel Device That May Lower the Incidence of Injectable Medication Errors Tariq Chaudhry, MD Tufts Medical Center 2 Design and Implementation of a Voice-Based Controller for the Solar 8000 Monitor Christopher Connor, MD, PhD Brigham and Women's Hospital 3 Pre-Deployment Assessment of NETCCN COVID-19 Tele Critical Care Technologies in a Laboratory Environment David Arney, PhD Massachusetts General Hospital 4 Intraoperative Arterial Pressure Waveforms Shows Temporal Structure Complexity Correlated with Acuity of Liver Transplant by Pulse Wave Manifold Learning Analysis Shen-Chih Wang, MD, PhD Taipei Veterans General Hospital 5 Resurrecting a 'Shocking' Dinosaur: Updating the Original Mechanomyography Gold Standard for 2020 Kelly Michaelsen, MD, PhD University of Washington 6* Analgesic Monitoring Indices in Response to Noxious Stimuli of Laparoscopic Cystectomy Surgery and Their Time Optimization Yu-Ting Lin, MD, PhD Taipei Veterans General Hospital 7 Approximating the Interand Intra-Patient PK/PD of PropofolInduced Burst Suppression Jason Huang, BS University of Utah 8 Comparison of Near-Infrared Spectroscopy-Derived Cerebral and Somatic Oxygenation Indices During Pediatric Scoliosis Surgery Michael Wood, PhD University of British Columbia A D V A N C E M E N T S IN T E C H N O L O G Y 9** Measuring the Performance of Multi-Pump Infusion Systems with Spectrophotometry David Arney, PhD Massachusetts General Hospital/Harvard University 10 Preliminary Experience With a New High-Speed Flow Sensor for Investigating and Improving Syringe Pump Flow Performance Robert Butterfield, BSE RDB Consulting 11 Detecting Abnormalities on Displays of Patient Information Sydney Fleishman Vanderbilt University 12 A Framework for Evaluating Healthcare Machine Learning Models: Application and Analysis Using Hospital Readmission Eilon Gabel, MD University of California, Los Angeles 13 Improved Sedation Capnography And Enhanced Patient Safety For Sedation Anesthesia Michael Jach, MD 14*** Reduction of Preoperative Anxiety Using Virtual Reality vs Midazolam: A Randomized Controlled Trial Anthony Koo, MD Sanjana Khanna, BS Phoenix Children's Hospital 15 Leveraging the Human Digital Twin for Perioperative Monitoring of Pediatric PatientsAn Early Case Study Hannah Yates, BS Johns Hopkins B IG D A T A & D A T A B A SE R E SE A R C H 16 Modeling the Cost Savings of Continuous Pulse Oximetry and Capnography Monitoring of United States Hospital Ward Patients Receiving Opioids Ashish Khanna, MD, FCCP, FCCM Wake Forest School of Medicine 17 Defining Gender and Race/Ethnicity-Specific Laboratory Reference Ranges and its Impact on Predicting Post-Operative Acute Kidney Injury and Mortality Outcomes Andrew Lee, MS University of California, Los Angeles 18 Machine Learning Approaches to Predict Intraoperative Transfusion Matthew Zapf, MD Vanderbilt University 19 Simulation Study to Evaluate Fidelity of Continuous Pulse Oximetry Recording in the Electronic Health Record Diane Dao, MD Children's Hospital of Philadelphia/University of Pennsylvania Abstract Table of",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
372f1a53d31309485fc5938bd309effe104ac2ec,https://www.semanticscholar.org/paper/372f1a53d31309485fc5938bd309effe104ac2ec,Scaling of containerized network functions,"This research extends on the EPI project [1]. That project tries to create a data sharing path between health care providers securely and dynamically. If two providers do not have a data sharing path or they violate data-sharing policies because of missing functionalities such as no way to encrypt traffic. A proxy is set up between the two providers where traffic gets redirected through. This proxy can then add the functionality as encryption by deploying network functions called bridging function and redirecting the traffic through those functions. In our research a proof of concept is created that is based on Kubernetes and allows us to deploy the EPI framework, pass traffic through the framework and scale the bridging function. Scaling of the bridging function can make it that resources are better utilized or that fluctuations in traffic can be better accommodated. By scaling horizontally we can add more bridging functions to help with traffic demands. Our research focused on how application traffic’s latency changed when scaling the bridging functions horizontally. The scaling of the bridging functions is researched in this report by looking at the impact of varying Kubernetes autoscaling thresholds for bridging functions on end-user application traffic. So we can see if autoscaling can improve the performance of the bridging functions. While implementing everything, we decided on experimenting on the horizontal autoscaler as this is more adjustable than the vertical autoscaler, and would certainly have some impact on the application traffic. Therefore in our experiments, we implemented the Horizontal Pod Autoscalers from Kubernetes. Experiments were conducted on it by adjusting the threshold of when to scale pods and adding load to the system by increasing the number of requests made that passed through the bridging functions. The experiments of this project unfold that long-lived traffic sessions don’t benefit from horizontal scaling of the bridging function due to the load balancing logic of Kubernetes services. Moreover, the processing logic of the bridging function used in the Proof of concept is CPU-centric; thus, the steady memory usage didn’t cause any scale-out events. And finally, testing results also consistently shows an impact on end-user experience due to a slight increase in response time due to the scale-out load distribution overhead. This research can be complemented by examining different types of application traffic and bridging functions as well as using machine learning to find the optimal scaling threshold.",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2c7e46ef2cc83d7cd0343f8e807cff590eca5a9f,https://www.semanticscholar.org/paper/2c7e46ef2cc83d7cd0343f8e807cff590eca5a9f,Construction and Application of an Intelligent Response System for COVID-19 Voice Consultation in China: A Retrospective Study,"Background: The outbreak of novel coronavirus disease 2019 (COVID-19) has led to tremendous individuals visit medical institutions for healthcare services. Public gatherings and close contact in clinics and emergency departments may increase the exposure and cross-infection of COVID-19. Objectives: The purpose of this study was to develop and deploy an intelligent response system for COVID-19 voice consultation, to provide suggestions of response measures based on actual information of users, and screen COVID-19 suspected cases. Methods: Based on the requirements analysis of business, user, and function, the physical architecture, system architecture, and core algorithms are designed and implemented. The system operation process is designed according to guidance documents of the National Health Commission and the actual experience of prevention, diagnosis and treatment of COVID-19. Both qualitative (system construction) and quantitative (system application) data from the real-world healthcare service of the system were retrospectively collected and analyzed. Results: The system realizes the functions, such as remote deployment and operations, fast operation procedure adjustment, and multi-dimensional statistical report capability. The performance of the machine-learning model used to develop the system is better than others, with the lowest Character Error Rate (CER) 8.13%. As of September 24, 2020, the system has received 12,264 times incoming calls and provided a total of 11,788 COVID-19-related consultation services for the public. Approximately 85.2% of the users are from Henan Province and followed by Beijing (2.5%). Of all the incoming calls, China Mobile contributes the largest proportion (66%), while China Unicom and China Telecom are accounted for 23% and 11%. For the time that users access the system, there is a peak period in the morning (08:00–10:00) and afternoon (14:00–16:00), respectively. Conclusions: The intelligent response system has achieved appreciable practical implementation effects. Our findings reveal that the provision of inquiry services through an intelligent voice consultation system may play a role in optimizing the allocation of healthcare resources, improving the efficiency of medical services, saving medical expenses, and protecting vulnerable groups.",Frontiers in Medicine,2021.0,10.3389/fmed.2021.781781,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6e8efe174d1f25c9ace28fca07e929ab99b3847a,https://www.semanticscholar.org/paper/6e8efe174d1f25c9ace28fca07e929ab99b3847a,Smart-Object-Based Reasoning System for Indoor Acoustic Profiling of Elderly Inhabitants,"Many countries are facing significant challenges in relation to providing adequate care for their elderly citizens. The roots of these issues are manifold, but include changing demographics, changing behaviours, and a shortage of resources. As has been witnessed in the health sector and many others in society, technology has much to offer in terms of supporting people’s needs. This paper explores the potential for ambient intelligence to address this challenge by creating a system that is able to passively monitor the home environment, detecting abnormal situations which may indicate that the inhabitant needs help. There are many ways that this might be achieved, but in this paper, we will describe our investigation into an approach involving unobtrusively ’listening’ to sound patterns within the home, which classifies these as either normal daily activities, or abnormal situations. The experimental system we built was composed of an innovative combination of acoustic sensing, artificial intelligence (AI), and the Internet-of-Things (IoT), which we argue in the paper that it provides a cost-effective approach to alerting care providers when an elderly person in their charge needs help. The majority of the innovation in our work concerns the AI in which we employ Machine Learning to classify the sound profiles, analyse the data for abnormal events, and to make decisions for raising alerts with carers. A Neural Network classifier was used to train and identify the sound profiles associated with normal daily routines within a given person’s home, signalling departures from the daily routines that were then used as templates to measure deviations from normality, which were used to make weighted decisions regarding calling for assistance. A practical experimental system was then designed and deployed to evaluate the methods advocated by this research. The methodology involved gathering pre-design and post-design data from both a professionally run residential home and a domestic home. The pre-design data gathered the views on the system design from 11 members of the residential home, using survey questionnaires and focus groups. These data were used to inform the design of the experimental system, which was then deployed in a domestic home setting to gather post-design experimental data. The experimental results revealed that the system was able to detect 84% of abnormal events, and advocated several refinements which would improve the performance of the system. Thus, the research concludes that the system represents an important advancement to the state-of-the-art and, when taken together with the refinements, represents a line of research which has the potential to deliver significant improvements to care provision for the elderly.",Electronics,2021.0,10.3390/ELECTRONICS10121433,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
662f74f51c62fb2a0645f989a7e93bec82bdb04f,https://www.semanticscholar.org/paper/662f74f51c62fb2a0645f989a7e93bec82bdb04f,MI-Lab - A Laboratory Environment for Medical Informatics Students,"Medical research and health care highly depend on the use of information technology. There is a wide range of application systems (patient administration system, laboratory information system, communication server etc.) and heterogeneous data types (administrative data, clinical data, laboratory data, image data, genomic data etc.). Students and researchers do not often have the possibility to use productive application systems of e.g. hospitals or medical practices to gain practical experiences or examine new components and technologies. Therefore, the aim of this project is to develop a dedicated laboratory environment for patient health care and clinical research. Essential application systems were identified and a suitable architecture was designed for this purpose. It is accompanied by a teaching plan that considers learning modules for bachelor and master degrees in medical informatics. We implemented the laboratory environment called MI-Lab with multiple free and open source software components. All components are installed on virtual machines and/or Docker containers. This modular architecture creates a flexible system which can be deployed in various scenarios. The preliminary evaluation results suggests that laboratory environments like MI-Lab work well in teaching practical aspects of medical informatics and are widely accepted by students.",MIE,2016.0,10.3233/978-1-61499-678-1-48,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d67664ba9d82cd5c2f24c492da0b901d38f4c266,https://www.semanticscholar.org/paper/d67664ba9d82cd5c2f24c492da0b901d38f4c266,"Introduction to the Special Issue on the Wearable Technologies for Smart Health, Part 2","Wearable health-tracking consumer products are gaining popularity, including smart watches, fitness trackers, smart clothing, and head-mounted devices. These wearable devices promise new opportunities for the study of health-related behavior, for tracking of chronic conditions, and for innovative interventions in support of health and wellness. Next-generation wearable technologies have the potential to transform today’s hospitalcentered healthcare practices into proactive, individualized care. Although it seems new technologies enter the marketplace every week, there is still a great need for research on the development of sensors, sensor-data analytics, wearable interaction modalities, and more. In this special issue, we sought to assemble a set of articles addressing novel computational research related to any aspect of the design or use of wearables in medicine and health, including wearable hardware design, AI and data analytics algorithms, human-device interaction, security/privacy, and novel applications. Here, in Part 2 of a two-part collection of articles on this topic, we are pleased to share four articles about the use of wearables for skill assessment, activity recognition, mood recognition, and deep learning. In the first article, Generalized and Efficient Skill Assessment from IMU Data with Applications in Gymnastics and Medical Training, Khan et al. propose a new framework for skill assessment that generalizes across application domains and can be deployed for different near-real-time applications. The effectiveness and efficiency of the proposed approach is validated in gymnastics and surgical skill training of medical students. In the next article, Privacy-preserving IoT Framework for Activity Recognition in Personal Healthcare Monitoring, Jourdan et al. propose a framework that uses machine learning to recognize the user activity, in the context of personal healthcare monitoring, while limiting the risk of users’ re-identification from biometric patterns that characterize an individual. Their solution trades off privacy and utility with a slight decrease of utility (9% drop in accuracy) against a large increase of privacy. Next, the article Perception Clusters: Automated Mood Recognition using a Novel Cluster-driven Modelling System proposes a mood-recognition system that groups individuals in “perception clusters” based on their physiological signals. This method can provide inference results that are more accurate than generalized models, without the need for the extensive training data necessary to build personalized models. In this regard, the approach is a compromise between generalized and personalized models for automated mood recognition (AMR). Finally, in an article about the Ensemble Deep Learning on Wearables Using Small Datasets, Ngu et al. describe an in-depth experimental study of Ensemble Deep Learning techniques on small time-series datasets generated by wearable devices, which is motivated by the fact that there are no publicly available, large, annotated datasets that can be used for training for some healthcare applications, such as the real-time fall detection. The offline experimental results show that an ensemble of Recurrent Neural Network (RNN) models outperforms a single RNN model and achieves a significantly higher precision without reducing much of the recall after re-training with real-world user feedback.",ACM Trans. Comput. Heal.,2021.0,10.1145/3442350,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c6015c232287b08a8f8dd58aeb2def76baca8f29,https://www.semanticscholar.org/paper/c6015c232287b08a8f8dd58aeb2def76baca8f29,AESGRU: An Attention-Based Temporal Correlation Approach for End-to-End Machine Health Perception,"Accurate and real-time perception of the operating status of rolling bearings, which constitute a key component of rotating machinery, is of vital significance. However, most existing solutions not only require substantial expertise to conduct feature engineering, but also seldom consider the temporal correlation of sensor sequences, ultimately leading to complex modeling processes. Therefore, we present a novel model, named Attention-based Equitable Segmentation Gated Recurrent Unit Networks (AESGRU), to improve diagnostic accuracy and model-building efficiency. Specifically, our proposed AESGRU consists of two modules, an equitable segmentation approach and an improved deep model. We first transform the original dataset into time-series segments with temporal correlation, so that the model enables end-to-end learning from the strongly correlated data. Then, we deploy a single-layer bidirectional GRU network, which is enhanced by attention mechanism, to capture the long-term dependency of sensor segments and focus limited attention resources on those informative sampling points. Finally, our experimental results show that the proposed approach outperforms previous approaches in terms of the accuracy.",IEEE Access,2019.0,10.1109/ACCESS.2019.2943381,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8750622af7172a3d707de2d502a1875712b9c986,https://www.semanticscholar.org/paper/8750622af7172a3d707de2d502a1875712b9c986,Abstract IA04: Clinical challenges in oncologic imaging: AI support from image analysis to integrated diagnostics,"The automated analysis of large-scale clinical datasets poses new compelling challenges for data-driven and model-based computational methods in medical imaging. As a matter of fact, the amount of heterogeneous biomedical data is considerably increasing due to the advances in medical imaging acquisition modalities and high-throughput technologies for multi-omics. In addition, electronic health records can be properly integrated to support personalized screening and diagnosis. In such a context, artificial intelligence (AI) is revolutionizing cancer image analysis by relying on sophisticated machine learning and computational intelligence techniques. Therefore, cutting-edge AI methods can enable the shift from organization-centric to patient-centric models, leading to effective multi-institutional health care services in terms of both clinical outcomes and costs. Computerized oncologic image analysis is encouraging the transition from largely qualitative image interpretation to quantitative assessment through automated methods aiming at early detection as well as lesion characterization. Nevertheless, several challenges and opportunities exist: • Reproducible and reliable segmentation methods are required to cope with time-consuming and error-prone manual delineation in laborious human decision-making tasks. As a matter of fact, accurate operator-independent segmentation procedures can improve the robustness of radiomics analyses. • Accurate computer-assisted diagnosis, associated with proper data curation, can reduce the risk of overlooking the diagnosis in a clinical environment. • Prognostic/predictive biomarker discovery by capturing the underlying tumor heterogeneity. • Quantification and monitoring of intra-/intertumoral heterogeneity during the course of the disease, by a proper integration of imaging, clinical, and molecular data on a patient-by-patient level • From a health-economics perspective, increasing costs of highly specific oncologic treatments (including immunotherapies) require accurate patient selection strategies, as well as better biomarkers of treatment response. Currently, many state-of-the-art methods based on deep learning have been achieving outstanding performance. The key to their success is the strong learning ability of fully supervised ML models and the availability of large-scale labeled datasets that include precise annotations. Unfortunately, in biomedical research, collecting such accurate annotations is an expensive process due to the need for domain experts’ knowledge. The generation of large mineable imaging datasets might mitigate this challenge by overcoming data paucity and heterogeneity issues. However, along with the availability of samples, data quality and diversity should be considered by collecting and preparing harmonized datasets. Therefore, the generalization abilities in multi-institutional studies can be improved by exploiting transfer learning and domain adaptation techniques. Finally, the explainability and safety of clinical decision support systems should be guaranteed, by avoiding “black-box” AI models exhibiting unpredictable behaviors. In conclusion, precision oncology should be directed towards the development of integrated radiogenomics paradigms that provide robust computational tools for investigating cancer biology as well as its implications for predicting treatment response. This solution allows for large-scale data collection (from multiple institutions) and continuous learning, by dealing with cyber-security and privacy issues. At present, the ultimate challenge is bridging the gap between AI and clinical practice, by firstly performing well-validated clinical research studies. This step is vital for the final translation and deployment of these advanced AI approaches in precision oncology. Citation Format: Evis Sala. Clinical challenges in oncologic imaging: AI support from image analysis to integrated diagnostics [abstract]. In: Proceedings of the AACR Special Conference on Advancing Precision Medicine Drug Development: Incorporation of Real-World Data and Other Novel Strategies; Jan 9-12, 2020; San Diego, CA. Philadelphia (PA): AACR; Clin Cancer Res 2020;26(12_Suppl_1):Abstract nr IA04.",Oral Presentations - Invited Abstracts,2020.0,10.1158/1557-3265.advprecmed20-ia04,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
43697482bf65b98506f77d80ef35676470d52925,https://www.semanticscholar.org/paper/43697482bf65b98506f77d80ef35676470d52925,Interpreting Multimodal Machine Learning Models Trained for Emotion Recognition to Address Robustness and Privacy Concerns,"Many mobile applications and virtual conversational agents now aim to recognize and adapt to emotions. These predicted emotions are used in variety of downstream applications: (a) generating more human like dialogues, (b) predicting mental health issues, and (c) hate speech detection and intervention. To enable this, data are transmitted from users' devices and stored on central servers. These data are then processed further, either annotated or used as inputs for training a model for a specific task. Yet, these data contain sensitive information that could be used by mobile applications without user's consent or, maliciously, by an eavesdropping adversary. My work focuses on two major issues that are faced while training emotion recognition algorithms: (a) privacy of the generated representations and, (b) explaining and ensuring that the predictions are robust to various situations. Tackling these issues would lead to emotion based algorithms that are deployable and helpful at a larger scale, thus enabling more human like experience when interacting with AI.",AAAI,2020.0,10.1609/aaai.v34i10.7130,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c17da2168d6376b32e1599b0c2f6ad8b5a8e8651,https://www.semanticscholar.org/paper/c17da2168d6376b32e1599b0c2f6ad8b5a8e8651,Event Detection and Estimation Using Distributed Population Owned Sensors,"Author(s): Ibrahim, Ahmed Mokhtar Nagy | Advisor(s): Eltawil, Ahmed | Abstract: Smart phones are an indispensable tool in modern day-to-day life. Their widespread use has spawned numerous applications targeting diverse domains such as bio-medical, environment sensing and infrastructure monitoring. In such applications, the accuracy of the sensors at the core of the system is still questionable, since these devices are not originally designed for high accuracy sensing purposes. In this thesis, we investigate the accuracy limits of one of the commonly used sensors, namely, a smart phone accelerometer. As a use case, we focus on utilizing smart phone accelerometers in structural health monitoring (SHM). Using the already deployed network of distributed citizen-owned sensors is considered a cheap alternative to standalone sensors. These devices can capture floors vibration during disasters, and consequently compute the instantaneous displacement of each floor. Hence, damage indicators defined by government standards such as peak relative displacement can be estimated. In this work, we study the displacement estimation accuracy and propose a zero-velocity update (ZUPT) method for noise cancellation. Theoretical derivation and experimental validation are presented, and we discuss the impact of sensor error on the achieved building classification accuracy. Moreover, in spite of the presence of sensor error, SHM systems can be resilient by adopting machine learning. Several algorithms such as support vector machine (SVM), K-nearest neighbor (KNN) and convolutional neural network (CNN) are adopted and compared. Techniques for addressing noise levels are proposed and the results are compared to regular noise cancellation techniques such as filtering.Finally, since most previous work focused on modelling the sensor chip error itself, we study other sources of error such as sampling time uncertainty which is introduced by the device operating system (OS). That type of error can be considered a major contributor to the overall error, specially for sufficiently large signals. Hence, we propose a novel smart device accelerometer error model that includes the traditional additive noise as well as sampling time uncertainty errors. The model is validated experimentally using shake table experiments, and maximum likely-hood estimation (MLE) is used to estimate the model parameters. Moreover, we derive the Cramer-Rao lower bound (CRLB) of acceleration estimation based on the proposed model.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6ea59f72f3239e524b7fb5d09eaf2fc9638cb018,https://www.semanticscholar.org/paper/6ea59f72f3239e524b7fb5d09eaf2fc9638cb018,Ai Technology Achieving General Purpose Ai That Can,"Artificial IntelligenceArtificial Intelligence in Cyber Security: Impact and ImplicationsTechnological Progress, Artificial Intelligence, and Inclusive GrowthEnergy Research AbstractsCan Artificial Intelligence ImproveHandbook of Pharmaceutical Granulation TechnologyArtificial Intelligence for BusinessArtificial Intelligence in EducationThe Democratization of Artificial IntelligenceAdvances in Artificial Intelligence, Software and Systems EngineeringFinancing Our FutureProceedings of the Future Technologies Conference (FTC) 2021, Volume 1Artificial IntelligenceNew Technologies in Dermatological Science and PracticeArtificial IntelligenceGame Theory and Machine Learning for Cyber SecurityRegulatory Aspects of Artificial Intelligence on BlockchainConcise Encyclopedia of Software EngineeringEuropean Artificial Intelligence (AI) Leadership, the Path for an Integrated VisionAI In The Age Of Cyber-DisorderReadings in Artificial Intelligence and DatabasesHuman decisionsConstitution 3.0Artificial Intelligence and IoT-Based Technologies for Sustainable Farming and Smart AgricultureArtificial Intelligence and Deep Learning for Decision MakersThe Regional Economics of Technological TransformationsArchitects of IntelligenceArtificial IntelligenceArtificial Intelligence and Integrated Intelligent Information SystemsECIAIR 2019 European Conference on the Impact of Artificial Intelligence and Robotics Intelligence UnboundHow to Achieve Inclusive GrowthArtificial Intelligence for Business OptimizationArtificial Intelligence in SocietyThe Myth of Artificial IntelligenceThe Digital Innovation RaceAI-First HealthcareProject Management Best Practices: Achieving Global ExcellenceConnected WorldBiotechnology: Concepts, Methodologies, Tools, and Applications The interaction of database and AI technologies is crucial to such applications as data mining, active databases, and knowledge-based expert systems. This volume collects the primary readings on the interactions, actual and potential, between these two fields. The editors have chosen articles to balance significant early research and the best and most comprehensive articles from the 1980s. An in-depth introduction discusses basic research motivations, giving a survey of the history, concepts, and terminology of the interaction. Major themes, approaches and results, open issues and future directions are all discussed, including the results of a major survey conducted by the editors of current work in industry and research labs. Thirteen sections follow, each with a short introduction. Topics examined include semantic data models with emphasis on conceptual modeling techniques for databases and information systems and the integration of data model concepts in high-level data languages, definition and maintenance of integrity constraints in databases and knowledge bases, natural language front ends, object-oriented database management systems, implementation issues such as concurrency control and error recovery, and representation of time and knowledge incompleteness from the viewpoints of databases, logic programming, and AI.The artificial intelligence (AI) landscape has evolved significantly from 1950 when Alan Turing first posed the question of whether machines can think. Today, AI is transforming societies and economies. It promises to generate productivity gains, improve well-being and help address global challenges, such as climate change, resource scarcity and health crises.As technology continues to saturate modern society, agriculture has started to adopt digital computing and data-driven innovations. This emergence of “smart” farming has led to various advancements in the field, including autonomous equipment and the collection of climate, livestock, and plant data. As connectivity and data management continue to revolutionize the farming industry, empirical research is a necessity for understanding these technological developments. Artificial Intelligence and IoT-Based Technologies for Sustainable Farming and Smart Agriculture provides emerging research exploring the theoretical and practical aspects of critical technological solutions within the farming industry. Featuring coverage on a broad range of topics such as crop monitoring, precision livestock farming, and agronomic data processing, this book is ideally designed for farmers, agriculturalists, product managers, farm holders, manufacturers, equipment suppliers, industrialists, governmental professionals, researchers, academicians, and students seeking current research on technological applications within agriculture and farming.This book constitutes the refereed proceedings of the Second International Conference, SLAAI-ICAI 2018, held in Moratuwa, Sri Lanka, in December 2018. The 32 revised full papers presented were carefully reviewed and selected from numerous submissions. The papers are organized in the following topical sections: ?intelligence systems; neural networks; game theory; ontology engineering; natural language processing; agent based system; signal and image processing.After a long time of neglect, Artificial Intelligence is once again at the center of most of our political, economic, and socio-cultural debates. Recent advances in the field of Artifical Neural Networks have led to a renaissance of dystopian and utopian speculations on an AI-rendered future. Algorithmic technologies are deployed for identifying potential terrorists through vast surveillance networks, for producing sentencing guidelines and recidivism risk profiles in criminal justice systems, for demographic and psychographic targeting of bodies for advertising or propaganda, and more generally for automating the analysis of language, text, and images. Against this background, the aim of this book is to discuss the heterogenous conditions, implications, and effects of modern AI and Internet technologies in terms of their political dimension: What does it mean to critically investigate efforts of net politics in the age of machine learning algorithms?Intelligence Unbound explores the prospects, promises, and potential dangers of machine intelligence and uploaded minds in a collection of stateof-the-art essays from internationally recognized philosophers, AI researchers, science fiction authors, and theorists. Compelling and intellectually sophisticated exploration of the latest thinking on Artificial Intelligence and machine minds Features contributions from an international cast of philosophers, Artificial Intelligence researchers, science fiction authors, and more Offers current, diverse perspectives on machine intelligence and uploaded minds, emerging topics of tremendous interest Illuminates the nature and ethics of tomorrow’s machine minds—and of the convergence of humans and machines—to consider the pros and cons of a variety of intriguing possibilities Considers classic philosophical puzzles as well as the latest topics debated by scholars Covers a wide range of viewpoints and arguments regarding the prospects of uploading and machine intelligence, including proponents and skeptics, pros and consCompanies that don't use AI to their advantage will soon be left behind. Artificial intelligence and machine learning will drive a massive reshaping of the economy and society. What should you and your company be doing right now to ensure that your business is poised for success? These articles by AI experts and consultants will help you understand today's essential thinking on what AI is capable of now, how to adopt it in your organization, and how the technology is likely to evolve in the near future. Artificial Intelligence: The Insights You Need from Harvard Business Review will help you spearhead important conversations, get going on the right AI initiatives for your company, and capitalize on the opportunity of the machine intelligence revolution. Catch up on current topics and deepen your",,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
38a7d2c18146f0944dd661b5aef9ee43bda7d75e,https://www.semanticscholar.org/paper/38a7d2c18146f0944dd661b5aef9ee43bda7d75e,Receipts,"Videos from mobile phones and security cameras are one form of proof of the aggressions experienced by victims and witnesses of various forms of discrimination against equity-seeking individuals and groups in public spaces. At the same time, people do not always feel that they can safely record an incident or easily gain access to archived data. They may also need time and space to process what they have experienced. Furthermore, official channels to lodge complaints are often exclusionary, byzantine, isolating, individuating, demoralizing cul-de-sacs. The result is that the experiences and voices of victims and witnesses of hate and discrimination in public spaces are often diluted or silenced. Computer vision and artificial intelligence tools increasingly deployed as part of “smart city” infrastructures have been proposed as a means to address these issues in real time by predicting, identifying, and aggregating transgressions. Yet, in practice, these tools lack nuance, approximate and automate-out the importance of relationship building with communities, and have generally been used to identify patterns and build predictive surveillance that disproportionately disadvantages already discriminated-against groups.
This paper will report on two iterations of our ongoing Receipts project. The project serves as a means to experiment with and propose processes that use social practice and machine learning technologies to prepare testimonies and listeners to more clearly and impactfully speak, hear, and feel what it is like to respond to mimetic trauma and be part of an equity-deserving group in public space. The work is guided by the following question: How can the process of facilitating the preparation and presention of anonymized testimonies of discriminatory aggression in public spaces with the witnesses and victims of said agressions create structures of accountability, solidarity, healing, and community?
The first project, Receipts (2020) — https://receipts.publicvisualizationstudio.co/ — was presented as part of The Bentway’s Safe in Public Space program in Toronto, and addressed anti-Asian aggression in public spaces. The second project, Receipts NB, in collaboration with ArtFix, an organization that works with artists with substance abuse and mental health lived experience in North Bay, will address the stigmatization and isolation of this community during the pandemic. It will be presented as part of IceFollies 2023, a week-long public art festival on frozen Lake Nipissing.
These explorations emerge from, and reflect upon a theoretical framework that connects visual culture, data creation, visual perception, cognition, machine learning processes, human-computer interaction, social practice and a practice-based framework for research-creation. The work is also informed by an approach to technoscience that uses a critical race, feminist , and decolonial lens. A necessary component of this framework is to prioritize equity through an emphasis on critical pedagogy, co-creation , and participatory art and design practice.
The critical media art practices and processes of Receipts do not aim to replace identifying video as an important means of holding people accountable. Instead, we hope that the project can shape technical, social, cultural practices of testimony and listening and make collectivized community resistance resonate more deeply.",Interactive Film &amp; Media Journal,2022.0,10.32920/ifmj.v2i2.1568,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
113ea7bae644e1e96e1c0af6a86ebaa016c52af1,https://www.semanticscholar.org/paper/113ea7bae644e1e96e1c0af6a86ebaa016c52af1,Broadening the Ethical Scope,"McCradden and colleagues’ (2022) argues that machine learning in health care poses new challenges to appropriate evaluation for safe use in clinical care. It also claims that “the longstanding system of institutional ethics oversight for clinical research can be adapted to health care ML” (11) and offers an approach for doing so. There is a lot to applaud in the proposed process, particularly in stages 2 and 3. Our main concerns focus on stage 1. We would also be interested to learn more about the potential of implementation of the whole, of the reasons the authors believe it will be accepted by universities and firms and what the obstacles might be. The authors begin by describing problems that AI/ ML create when applied in clinical health practice. Some of these have long been recognized in AI, i.e., the introduction of algorithmic biases, particularly in relation to race, gender, and class. Other problems, such as violations of privacy, have also been noted, but the authors are correct to emphasize that personal health data creates a raft of different complexities than consumer or other administrative data. Additionally, there are issues of proprietary techniques and interventions that the medical world has long dealt with but which receive less attention in this piece. The authors do point out some important lacuna in the system of institutional ethics, particularly as constituted in institutional review boards (IRBs). These make less convincing their claim that the system could be adapted for ML, or at least easily adapted, as they seem to imply. The first lacuna is that only publicly funded research is required to be reviewed, but, as the authors themselves point out, the development of most of the ML applications is privately funded. And this raises serious questions about how and at what point an ethical review is initially required, as we argue below. The second is the fact that “...many applications of technology in medicine are validated without research ethics oversight” (9). While the authors argue that this is not necessarily a big problem and that it is dealt with through the data governance framework offered in Phase 1, this framework is not yet standard practice. Thus, it is worrisome that a crucial feature of ML development is not subject to scrutiny. Of equal concern to us is that emphasis on the current methods means an emphasis only on the harms to human subjects. IRBs’ rules and regulations in the United States (Department of Health, Education, and Welfare 1979) focus on risks to human subjects, not risks to human society. In contrast, many of the risks embedded in AI research are best understood as risks to society rather than risks to human subjects: for example, when training data or stakeholders do not include communities likely to be impacted by the algorithm’s deployment, when the algorithm might be deployed by malicious actors or in ways that the researchers never intended, or when subgroups in society are harmed as through job displacement. From our work, we have identified a number of potential ethical concerns inherent in medical research employing AI. For example, research that uses electronic medical records to develop a model that informs patient treatment options could embed the societal biases inherent in the EMRs within the model itself; the development of a model intended to predict likely",The American journal of bioethics : AJOB,2022.0,10.1080/15265161.2022.2055219,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8584d9ccddd6c2caaeaa8c76b0612d7e72bea07,https://www.semanticscholar.org/paper/c8584d9ccddd6c2caaeaa8c76b0612d7e72bea07,Foot-to-Ground Phases Detection: A Comparison of Data Representation Formatting Methods with Respect to Adaption of Deep Learning Architectures,"Identifying the foot stance and foot swing phases, also known as foot-to-ground (FTG) detection, is a branch of Human Activity Recognition (HAR). Our study aims to detect two main phases of the gait (i.e., foot-off and foot-contact) corresponding to the moments when each foot is in contact with the ground or not. This will allow the medical professionals to characterize and identify the different phases of the human gait and their respective patterns. This detection process is paramount for extracting gait features (e.g., step width, stride width, gait speed, cadence, etc.) used by medical experts to highlight gait anomalies, stance issues, or any other walking irregularities. It will be used to assist health practitioners with patient monitoring, in addition to developing a full pipeline for FTG detection that would help compute gait indicators. In this paper, a comparison of different training configurations, including model architectures, data formatting, and pre-processing, was conducted to select the parameters leading to the highest detection accuracy. This binary classification provides a label for each timestamp informing whether the foot is in contact with the ground or not. Models such as CNN, LSTM, and ConvLSTM were the best fits for this study. Yet, we did not exclude DNNs and Machine Learning models, such as Random Forest and XGBoost from our work in order to have a wide range of possible comparisons. As a result of our experiments, which included 27 senior participants who had a stroke in the past wearing IMU sensors on their ankles, the ConvLSTM model achieved a high accuracy of 97.01% for raw windowed data with a size of 3 frames per window, and each window was formatted to have two superimposed channels (accelerometer and gyroscope channels). The model was trained to have the best detection without any knowledge of the participants’ personal information including age, gender, health condition, the type of activity, or the used foot. In other words, the model’s input data only originated from IMU sensors. Overall, in terms of FTG detection, the combination of the ConvLSTM model and the data representation had an important impact in outperforming other start-of-the-art configurations; in addition, the compromise between the model’s complexity and its accuracy is a major asset for deploying this model and developing real-time solutions.",Comput.,2022.0,10.3390/computers11050058,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8d18aa4b23b4f9124b9eb46427eeb9929a63fa05,https://www.semanticscholar.org/paper/8d18aa4b23b4f9124b9eb46427eeb9929a63fa05,IEEE Access Special Section Editorial: Mobile Multimedia for Healthcare,"With the availability of easy access to the Internet, and the proliferation of various mobile devices, people can get access to mobile multimedia ubiquitously in order to have a desktop experience. Mobile multimedia refers to different types of multimedia content (e.g., text, images, audios, and videos), which are accessed via heterogeneous mobile devices, such as mobile phones, portable devices, and smartphones. Mobile multimedia services and applications have tremendous potential in the healthcare sector. Currently, as the healthcare sector is increasingly dependent on mobile multimedia services and applications, many challenges remain unsolved for the successful deployment of mobile multimedia services in order to have a balance between power-limited mobile devices and resource hungry medical multimedia content. This Special Section aims to theme innovative research achievements in the field of related techniques, applications, services, and systems for mobile multimedia healthcare. The articles in this Special Section bring together academic and industrial researchers to identify and discuss technical challenges and recent results related to mobile multimedia for healthcare. As an application area, mobile multimedia is one of the most active and successful fields of use in the domain of the healthcare industry. The Special Section focuses on particular aspects of mobile multimedia for healthcare, such as comprehensive data sensing, assistive sensory media, and sharing mobile-healthcare big data. After a rigorous review process, we accepted the following articles to form the Special Section. In the article titled, ‘‘DEEP-SEE FACE: A mobile face recognition system dedicated to visually impaired people,’’ by Mocanu et al., the authors introduce a novel assistive device designed to improve cognition, interaction, and communication of visually impaired (VI) people in social encounters. The proposed approach jointly exploits computer vision algorithms and deep convolutional neural networks in order to detect, track, and recognize, in real time, various people’s existence in video streams. The major contribution of the article concerns a global, fixed-size face representation that takes into account various video frames while remaining independent of the length of the image sequence. For this purpose, the authors introduce an effective weight adaptation scheme that can determine the relevance assigned to each face instance, depending on the frame degree of motion/ camera blur, scale variation, and compression artifacts. The experimental results carried out on a large-scale data set validate the proposed methodology with an average accuracy and recognition rates superior to 92%.When tested in real-life indoor/outdoor scenarios, the proposed framework proves to be effective and easy to use, allowing the VI people to access visual information during social events. In the article, ‘‘Voice disorder identification by using machine learning techniques,’’ by Verde et al., the authors introduce an exhaustive comparison between the most used machine learning algorithms existing in the literature. The aim of this study is to identify the techniques capable of discriminating between pathological and healthy voices with more accuracy. This is fundamental to realizing a valid and precise mobile health system and a promising solution for people who desire the detection, monitoring, and treatment of their health conditions anywhere and at any time. All analyses are performed on a dataset of voices selected from the freely available Saarbrucken Voice Database. They show that the best accuracy in voice disease detection is achieved by the support vector machine algorithm or the decision tree one, depending on the features evaluated by using opportune feature selection methods. The article ‘‘Performance analysis of personal cloud storage services for mobile multimedia health record management,’’ by Akter et al., focuses on performance analysis of personal cloud storage services for mobile multimedia personal health record (PHR) management. In particular, the authors investigated using qualitative and quantitative analyses of the strengths and weaknesses of personal cloud storage services for PHR management scenarios. The qualitative analysis includes chunking, bundling, deduplication, delta-encoding, and data compression features. The quantitative analysis includes control data overhead, application data exchanged, and impact of data size on number of packets, as well as transmission rate, synchronization initialization time, and protocol overhead. Experimental results on various benchmark cloud storage datasets showed satisfactory outcomes. Wearable technology and personal health devices (PHDs) play a critical role in shaping the future of healthcare. The International Organization for Standardization (ISO) realized the role of personal health systems and proposed the 11 073 family of standards. To this end, the article ‘‘ISO/IEEE 11 073 personal health device (X73-PHD) standards",IEEE Access,2020.0,10.1109/access.2020.3017119,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
de54d22466f6078ea5295692c8cd3c686a316874,https://www.semanticscholar.org/paper/de54d22466f6078ea5295692c8cd3c686a316874,Introducing an All-mechanized Surgical Assistant for Use in Reconstructive Surgeries,"1 Copyright © 2019 The Authors. Published by Wolters Kluwer Health, Inc. on behalf of The American Society of Plastic Surgeons. This is an open access article distributed under the Creative Commons Attribution License 4.0 (CCBY), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Sir, T is currently a critical lack of surgeons in many advanced countries, including Japan. A geographic shortage of plastic surgeons is also sometimes considered to be a social problem.1,2 The key to solving this issue depends on proper and thoughtful deployment of surgical resources and on how smoothly the medical education system can provide residents with appropriate educational opportunities. During surgeries, surgical assistants often do nothing but simple tasks such as keeping the surgical field clear and simply follow top-down orders throughout the operation. Performance of these activities is a waste of talent and time for an assistant who has similar or higher skills than the senior surgeon. Alternatively, if the assistant is at the training level, he or she rarely gets effective learning opportunities due to standing in a position from which it is not possible to see the surgical field clearly. This situation provides young surgeons with nothing but a very poor view and position from which to have new surgical ideas. A totally automated operation could be one solution to these problems. Automated, unmanned hotels and retail services are becoming common. Machines and robots have already replaced people for helpful and essential assistance in daily life, and utilization of similar systems in the role of a surgical assistant is plausible. A good example is provided by the Octopus (MEDNOSBRO GmbH, Rudolfstetten, Switzerland), a device that serves as a versatile retractor system, and has 3 joints similar to those in a human upper limb, which allows precise all-direction maneuvers. In addition to this function, the system has flexible settings that allow a surgeon to place the machine in ideal positions to have a perfect view only by tightening or loosening a special screw attached to the device. A single surgeon can then complete an entire surgery using various tip parts of the retractor. Just like an assistant, the system plays a major role in the surgery, including facilitating a variety of flap elevations. Our surgical team has introduced the Octopus device into many kinds of reconstructive surgery, although mainly breast reconstruction, and we have shown that many plastic and reconstructive surgeries can be performed without an assistant. The device enables a single surgeon to complete the surgery alone, even in emergency situations, and never disturbs the surgeon’s work, loses focus, or becomes tired. The device makes it possible to reduce labor costs and to place sufficient talent in suitable positions, which releases assistants from unfruitful positions and consequently allows them to contribute much more in another field. If assistants are inexperienced residents, they can freely observe a surgery with a clear view that may not differ from the surgeon’s point of view, which allows acquisition of an understanding of a detailed procedure in an efficient way. There have been many beneficial results of device-assisted operations in various surgical fields,3–5 but relatively few in plastic and reconstructive surgery. However, this approach has great potential in this field, and we believe that this new surgical concept will spread quickly in the future.",Plastic and reconstructive surgery. Global open,2019.0,10.1097/GOX.0000000000002403,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ed9ae6ec0f52f7216ca5faa2fd9dc61a2d989db9,https://www.semanticscholar.org/paper/ed9ae6ec0f52f7216ca5faa2fd9dc61a2d989db9,The use of ERDDAP in a self-monitoring and nowcast hazard alerting coastal flood system,"<div>
<p>In the UK,&#160;&#163;150bn of assets and 4 million people are at risk from coastal flooding. With reductions in public funding,&#160;rising sea levels and&#160;changing storm conditions, cost-effective and accurate early&#160;warning&#160;flood&#160;forecasting&#160;systems are required.&#160;However, numerical tools currently used to estimate wave overtopping are based on tank experiments and very limited previous field measurements of total overtopping volumes only.&#160;Furthermore, the&#160;setting of tolerable hazard thresholds&#160;in&#160;flood&#160;forecasting models&#160;requires site-specific information of wave overtopping during storms of varying severity.&#160;</p>
</div><div>
<p>The National Oceanography Centre (NOC) are&#160;currently developing&#160;a new nowcast wave overtopping alert system&#160;that can be deployed in site-specific&#160;coastal settings&#160;to detect potentially dangerous&#160;flood&#160;conditions in near real-time&#160;(NRT)&#160;while&#160;validating&#160;operational&#160;forecasting&#160;services.&#160;At its core, it utilises a&#160;prototype overtopping sensor&#160;and&#160;an instance of&#160;the National Oceanic and Atmospheric Administration&#8217;s&#160;ERDDAP&#160;data server&#160;in&#160;a&#160;self-monitoring&#160;and alerting&#160;control&#160;system.&#160;In-situ&#160;detection will be&#160;performed&#160;by&#160;WireWall, a&#160;novel&#160;capacitance wire&#160;sensor that&#160;measures&#160;at the high (400 Hz) frequencies required to&#160;obtain&#160;the distribution of overtopping volume and horizontal velocity on a wave-by-wave basis.&#160;The sensor&#160;includes&#160;on-board data processing and 2-way telemetry&#160;to enable automation&#160;and control.&#160;The telemetry posts&#160;regular health summaries&#160;and&#160;high-resolution (1 sec)&#160;hazard data (produced by&#160;the&#160;on-board processing) using&#160;the standard&#160;internet protocol (https) to an open&#160;ERDDAP&#160;server&#160;so data are freely available via an application programming interface (API) alongside other&#160;NRT&#160;and delayed-mode&#160;global coastal ocean and weather information&#160;for&#160;further&#160;data exploration.&#160;ERDDAP allows&#160;NRT hazard&#160;data to be accessed&#160;by statistical algorithms and visual applications,&#160;as well as receiving&#160;alerts&#160;that are also fed&#160;to&#160;messaging queue points&#160;(RabbitMQ)&#160;that&#160;can be monitored by&#160;external systems.&#160;Combined, this will enable&#160;automated&#160;health monitoring&#160;and&#160;sensor operation&#160;as well as offer the potential for downstream hazard management tools (such as navigation systems and transport management systems) to ingest the nowcast wave overtopping hazard data.&#160;To&#160;integrate&#160;data&#160;with wider systems&#160;and&#160;different disciplines,&#160;ERDDAP&#160;data sets&#160;will be enriched with common and well-structured metadata. Data provenance, controlled vocabularies,&#160;Quality Control and&#160;attribution&#160;information embedded in&#160;the&#160;data workflow is fundamental to ensuring user trust in the data and any products generated, while&#160;enhancing&#160;FAIR&#160;data&#160;principles.&#160;</p>
</div><div>
<p>The new nowcast wave overtopping alert system&#160;will be tested in 2021 during field deployments of multiple&#160;WireWall&#160;systems at&#160;two high energy&#160;coastal&#160;sites in the UK.&#160;Such data are crucial for validating&#160;operational&#160;flood forecast services&#160;as well as protecting local communities&#160;and minimising transport service disruptions.&#160;The addition of&#160;SMART monitoring optimises sensor maintenance&#160;and operation,&#160;reducing&#160;the&#160;costs associated with&#160;teams travelling to the site.&#160;Using&#160;ERDDAP&#160;embedded with well-structured metadata&#160;enables&#160;machines to&#160;access multiple&#160;flood&#160;parameters&#160;through a single&#160;point that abstracts users from the complexities associated with the source data,&#160;offering the potential for further&#160;data&#160;exploration&#160;through modelling or&#160;techniques&#160;such as machine learning.&#160;</p>
</div>",,,10.5194/egusphere-egu21-14621,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a407364d8d1c6cd44bffb2fa7918b4733c246a64,https://www.semanticscholar.org/paper/a407364d8d1c6cd44bffb2fa7918b4733c246a64,"Digital libraries : people, knowledge, and technology : 5th International Conference on Asian Digital Libraries, ICADL 2002, Singapore, December 11-14, 2002 : proceedings","Keynote and Invited Papers.- Challenges in Building Digital Libraries for the 21st Century.- Building Digital Libraries Made Easy: Toward Open Digital Libraries.- Dublin Core: Process and Principles.- From Digital Library to Digital Government: A Case Study in Crime Data Mapping and Mining.- Progress on Educational Digital Libraries: Current Developments in the National Science Foundation's (NSF) National Science, Technology, Engineering, and Mathematics Education Digital Library (NSDL) Program.- Examples of Practical Digital Libraries: Collections Built Internationally Using Greenstone.- Data Mining Technologies for Digital Libraries and Web Information Systems.- Papers.- Chinese Text Summarization Using a Trainable Summarizer and Latent Semantic Analysis.- A Linear Text Classification Algorithm Based on Category Relevance Factors.- A Hierarchical Framework for Multi-document Summarization of Dissertation Abstracts.- Generality of Texts.- The Effiectiveness of a Graph-Based Algorithm for Stemming.- Searching Digital Music Libraries.- The NUS Digital Media Gallery - A Dynamic Architecture for Audio, Image, Clipart, and Video Repository Accessible via the Campus Learning Management System and idtvukcan the Digital Library.- A Schema Language for MPEG-7.- Bitmap-Based Indexing for Multi-dimensional Multimedia XML Documents.- What People Do When They Look for Music: Implications for Design of a Music Digital Library.- Distributing Relevance Feedback in Content Based Image Retrieval Systems.- Multistrategy Learning of Rules for Automated Classification of Cultural Heritage Material.- VideoCube: A Novel Tool for Video Mining and Classification.- Developing Tsinghua University Architecture Digital Library for Chinese Architecture Study and University Education.- Retrieving News Stories from a News Integration Archive.- A Data Mining Approach to New Library Book Recommendations.- Grouping Web Pages about Persons and Organizations for Information Extraction.- Personalized Services for Digital Library.- Automatic References: Active Support for Scientists in Digital Libraries.- Organizing and Maintaining Dynamic Digital Collections.- Navigation, Organization, and Retrieval in Personal Digital Libraries of Email.- A Work Environment for a Digital Library of Historical Resources.- A Personalized Collaborative Digital Library Environment.- Virtual Tutor: A System for Deploying Digital Libraries in Classrooms.- Resource Annotation Framework in a Georeferenced and Geospatial Digital Library.- Building Policy, Building Community: An Example from the US National Science, Technology, Engineering, and Mathematics Education Library (NSDL).- Building a Digital Library from the Ground Up: An Examination of Emergent Information Resources in the Machine Learning Community.- Subscription Clubs for E-journals: Indian Initiatives.- A Multilingual Multi-script Database of Indian Theses: Implementation of Unicode at Vidyanidhi.- A Workbench for Acquiring Semantic Information and Constructing Dictionary for Compound Noun Analysis.- Building Parallel Corpora by Automatic Title Alignment.- Offline Isolated Handwritten Thai OCR Using Island-Based Projection with N-Gram Models and Hidden Markov Models.- A Cache-Based Distributed Terabyte Text Retrieval System in CADAL.- Rural Digital Library: Connecting Rural Communities in Nepal.- Collection Development for the Digital Age: The Case of Malaysia.- Digital Divide: How Can Digital Libraries Bridge the Gap?.- Digital Libraries in Academia: Challenges and Changes.- Building Digital Libraries for Children: Reviewing Information Literacy of Students and Teachers.- The Use and Functionality of the Environmental Data Registry: An Evaluation of User Feedback.- Adding Semantics to 3D Digital Libraries.- INEXP: Information Exchange Protocol for Interoperability.- Study on Data Placement and Access Path Selection in an FC-SAN Virtual Storage Environment.- Building an OAI-Based Union Catalog for the National Digital Archives Program in Taiwan.- Intergenerational Partnerships in the Design of a Digital Library of Geography Examination Resources.- Pie Charts for Visualizing Query Term Frequency in Search Results.- Information Therapy in Digital Libraries.- Evaluation of Task Based Digital Work Environment.- A Framework for Flexible Information Presentation in Digital Collections.- Electronic Journal of the University of Malaya (EJUM): An Attempt to Provide a Truly Electronic Environment.- Patenting the Processes for Content-Based Retrieval in Digital Libraries.- Secure Content Distribution for Digital Libraries.- A Strategic Level for Scientific Digital Libraries.- Bridging the Gap between Information Resource Design and Enterprise Content Management.- A Digital Content Management Model for Making Profits in Digital Content Sites.- Posters.- The Idea of a Digital Library: Issues of Today.- US-Korea Collaboration on Digital Libraries: An Overview and Generalization for Pacific Rim Collaboration.- ETDs at HKU: A Spearhead for Digital Library Growth.- MiMedicalLibrary: A Digital Health Library for Michigan.- Reference Services in a Digital Library of Historical Artifacts.- An Integrative User-Centered Purchase Request Service in the Age of Digital Library Development.- Vitalising Library and Information Science Education: A Challenge in the Digital Information Environment.- Developing a Dialogue Library System.- WebClipper: A Personal/Community Link Library Builder Based on Web Link Management Technique.- Hiding a Logo Watermark in an Image for Its Copyright Protection.- Searching Video Segments through Transcript, Metadata, and SVG Objects.- Similar Sub-trajectory Retrieval Based on k-Warping Distance Algorithm for Moving Objects in Video Databases.- A Keyword Spotting System of Korean Document Images.- An Efficient Strategy for Adding Bulky Data into B+-Tree Indices in Information Retrieval Systems.",,2002.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1b6bbb72f9c939f630dfb37fdb9240adb20a18c1,https://www.semanticscholar.org/paper/1b6bbb72f9c939f630dfb37fdb9240adb20a18c1,Editorial: Perinatology in the Era of Big Data and Nanoparticles,"How do prenatal exposures to various stimuli impact postnatal development for the duration of a person’s life? To answer this, the tripartite challenge is biological, medical, and technological. The biological challenge is to understand the plethora of effects causing trajectory shifts. The medical and technological challenges are to identify and follow fetuses and babies at risk for diseases in later life. Systems to accomplish this must be deployable across variably equipped healthcare settings at a reasonable cost. 
 
Many researchers believe that such challenges can be tackled with complex signals bioinformatics. This research topic attracted articles on fetal heart rate (FHR) monitoring during labor, optimization of technologies for pediatric ventilation and the impact of the developing neonatal microbiome on health over the life span. How do these topics connect? They all share a clinical and translational demand for integrating relatively large amounts of spatio-temporally distributed data from various modalities to reveal patterns not clearly discernible to the human eye, with the goal of optimizing medical decision-making. 
 
The right idea has to arrive at the right time to be met by a technology that can implement it, to be taken up by practitioners, and to produce change in health outcomes (1–3). Although technology seems at hand, a paradigm shift is required for practitioners to embrace this challenge. We can no longer afford to rely on human perception alone to detect patterns in the twenty-first century’s onslaught of multi-modal and multi-dimensional data streams reflecting human health in acute and chronic care settings (4). Such data streams are commonly referred as Big Data. 
 
Big data can be defined with three Vs: “high-volume, high-velocity, and high-variety information assets that demand cost-effective, innovative forms of information processing for enhanced insight and decision making” (5). 
 
In this research topic, Durosier et al. show that sampling rate affects the ability of FHR monitoring to detect acidemia as it occurs during human labor (6). Acquiring ~250 times more data points per second than currently practiced in delivery rooms worldwide improves accuracy. New technologies, some re-discovered form the early 1980s, are now coming to market to address this need, although their indication for use in delivery rooms is not yet fully exploiting their potential (7–11). As current computing capacity no longer limits the sampling rate possibilities for online monitoring, “bigger” data are becoming a logical next step in improving health care (12). One challenge is the integration of live streams into electronic medical records to facilitate retrieval for diagnostic and research purposes and for medical decision-making in real time. 
 
The common thread connecting Durosier’s work to the next study in the research topic is the notion of unveiling physiological variability using higher temporal resolution of data acquisition and modalities of human–machine interaction that account for the natural biological variability. In the case of fetal monitoring, this variability is contained in the subtle temporal FHR fluctuations that remain hidden to human eye when acquired with the conventional tools at a 4-Hz sampling rate. 
 
Baudin et al. explore how biological variability is impacted by the various mechanical ventilation regimes when it comes to monitoring breathing patterns in infants requiring machine support (13, 14). Intuitively, machine ventilation algorithms that are most closely attuned to the physiological respiratory pattern produce breathing signals that most closely resemble those of the control infants. Although larger prospective studies are necessary to understand the differential impact of ventilatory modes on cardio-respiratory variability and their effect on clinical outcomes, this study shows the possibility of deploying off- or online tools to quantify the physiological variability in respiration from bedside pediatric data streams. In the long term, this might help to fine-tune the ventilation parameters beyond the current possibilities, accounting for the non-linear nature of respiratory patterns. Again, the theme of how biological variability can be usefully monitored in real time emerges. 
 
Munyaka et al. explore early postnatal maturation of immune regulation as a function of the exposure to gut microbiome (15). The human gut houses up to 1014 bacteria, exceeding by ~10-fold the number of host cells. Microbiome–host immune system interactions appear to have a profound and life-lasting impact on the host’s health status beginning well before the baby is born (16–21). We are faced with the challenge of quantifying microbial diversity in space and time, which approximates at least two of the above “3 Vs” definition of the big data, variety, and volume. Although the previous manuscripts represent intuitive approaches to temporal profiling and pattern analysis of streaming data, embodying all three Vs, current approaches to microbiome analysis need to catch up to the third V (velocity) to provide higher spatiotemporal resolution (microbiome in different organs at various time points). Meanwhile, current studies are cross-sectional in nature, sometimes with multiple sampling of the same cohort over time. They can offer population-level insights into changes in the microbiome due to various exposures, but with low temporal or spatial resolution to gage intra- and interindividual microbial dynamics. 
 
Sorani et al. provided an early proof-of-principle for creation of multivariate pattern recognition within physiological time series commonly acquired in an intensive care unit setting (22). Heat maps in which genes are displayed across the top row and related genes cluster together are commonly used in genetics. In their neurocritical care heat map, Sorani et al. replaced genes by physiological variables that cluster on the basis of association within and across patients into three groups of patients. Surprisingly, intracranial pressure (ICP) and fraction of inspired oxygen were clustered, leading to the identification of previously unrecognized ICP elevations during bedside suctioning. As a perinatal example of unexpected connections, multi-dimensional properties of fHRV encode signatures of inflammation (23–26) or progressive labor acidemia (10, 11, 27) and may relate to EEG parameters (28, 29). Modern machine learning will help to integrate microbiome indices and continuous bedside acquisition of multi-modal data to elucidate clinically relevant patterns and optimize treatment (4, 22). Data intelligence is the next logical step in evolution of health monitoring (2, 3, 30). 
 
Focusing machine learning approaches on clinical questions that arise in perinatal medicine is needed as relatively little progress has been made in the past decades in regard to monitoring and translation into clinical practice, with the notable exception of the HeRo score monitors (31, 32). Recent advances in artificial intelligence have brought the vision of data-driven case identification and decision-making closer to reality (33–37).",Front. Pediatr.,2015.0,10.3389/fped.2015.00095,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
bbdeb87277cc503cb9eb72da637139800b343ace,https://www.semanticscholar.org/paper/bbdeb87277cc503cb9eb72da637139800b343ace,Unobtrusive Pedestrian Identification by Leveraging Footstep Sounds with Replay Resistance,"The ability to identify pedestrians unobtrusively is essential for smart buildings to provide customized environments, energy saving, health monitoring and security-enhanced services. In this paper, we present an unobtrusive pedestrian identification system by passively listening to people's walking sounds. The proposed acoustic system can be easily integrated with the widely deployed voice assistant devices while providing the context awareness ability. This work focuses on two major tasks. Firstly, we address the challenge of recognizing footstep sounds in complex indoor scenarios by exploiting deep learning and the advanced stereo recording technology that is available on most voice assistant devices. We develop a Convolutional Neural Network-based algorithm and the footstep sound-oriented signal processing schemes to identify users by their footstep sounds accurately. Secondly, we design a ""live"" footstep detection approach to defend against replay attacks. By deriving the novel inter-footstep and intra-footstep characteristics, we distinguish live footstep sounds from the machine speaker's replay sounds based on their spatial variances. The system is evaluated under normal scenarios, traditional replay attacks and the advanced replays, which are designed to forge footstep sounds both acoustically and spatially. Extensive experiments show that our system identifies people with up to 94.9% accuracy in one footstep and shields 100% traditional replay attacks and up to 99% advanced replay attacks.",Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2021.0,10.1145/3494963,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d31a7209656b2e5529ddae3d629fcc5dbbcc57b1,https://www.semanticscholar.org/paper/d31a7209656b2e5529ddae3d629fcc5dbbcc57b1,Strategies for Adopting Additive Manufacturing Technology Into Business Models,"Strategies for Adopting Additive Manufacturing Technology Into Business Models by Robert Martens MS, University of Glamorgan, 2007 MBA, Keele University, 2006 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Business Administration Walden University August 2018 Abstract Additive manufacturing (AM), also called 3-dimensional printing (3DP), emerged as a disruptive technology affecting multiple organizations’ business models and supply chains and endangering incumbents’ financial health, or even rendering them obsolete. The world market for products created by AM has increased more than 25% year over year. Using Christensen’s theory of disruptive innovation as a conceptual framework, theAdditive manufacturing (AM), also called 3-dimensional printing (3DP), emerged as a disruptive technology affecting multiple organizations’ business models and supply chains and endangering incumbents’ financial health, or even rendering them obsolete. The world market for products created by AM has increased more than 25% year over year. Using Christensen’s theory of disruptive innovation as a conceptual framework, the purpose of this multiple case study was to explore the successful strategies that 4 individual managers, 1 at each of 4 different light and high-tech manufacturing companies in the Netherlands, used to adopt AM technology into their business models. Participant firms originated from 3 provinces and included a value-added logistics service provider and 3 machine shops serving various industries, including the automotive and medical sectors. Data were collected through semistructured interviews, member checking, and analysis of company documents that provided information about the adoption of 3DP into business models. Using Yin’s 5-step data analysis approach, data were compiled, disassembled, reassembled, interpreted, and concluded until 3 major themes emerged: identify business opportunities for AM technology, experiment with AM technology, and embed AM technology. Because of the design freedom the use of AM enables, in combination with its environmental efficiency, the implications for positive social change include possibilities for increasing local employment, improving the environment, and enhancing healthcare for the prosperity of local and global citizens by providing potential solutions that managers could use to deploy AM technology. Strategies for Adopting Additive Manufacturing Technology into Business Models by Robert Martens MBA, University of Keele, 2006 MS, University of Glamorgan, 2007 Doctoral Study Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Business Administration Walden University August 2018 Dedication I dedicate this work to my family, who believed in me during this quest. In particular, I wish to thank my father, Dominicus Martens, for telling me about the many journeys he made across the world, for giving me the appreciation for mechanical engineering and procurement, and for showing me technology and business go well together. To my mother, Cornelia, for gifting me with stamina, and an inquisitive and critical mind. I want to thank my wife, Lu Dongmei, for her constant encouragement during this research and belief in my abilities to achieve this goal. To my children Niek, Louis, Max, and Franc: thanks for your support along this journey; I hope I have shown you the importance of goal setting and dedication. Never stop learning. Acknowledgments I would like to acknowledge my family, friends, colleagues, classmates, and Walden faculty for their support during this doctoral study project. To my coach while in China, Lynda Aurora, who pushed me to pursue this dream. In particular, I wish to thank my chair, Dr. Susan Fan, for her guidance, Dr. Charles Needham, for his professionalism, and Dr. Lisa Kangas, for her eye to detail, towards the completion of quality research. To my Walden classmates with whom I shared many ups and downs: thank you for your time, support, motivation, and inspiration.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
844b74c0dae8a2675116f6f970001536006a25e1,https://www.semanticscholar.org/paper/844b74c0dae8a2675116f6f970001536006a25e1,Design and Testing of an Electrochemical Trace Pesticide Assessment System in Soil Run-Off,"Despite recent efforts and breakthroughs in the development of environmental biosensors, one particular vital component of the environment has been probed comparatively much more sparsely-namely, the soil ecosystem that directly and indirectly affects the agricultural health and throughput as well as ecosystem balance. One specific problem that is understudied is the application of pesticides in crops and other plants often finds its way seeping into soil in a large manner and there exists a leaching effect at the soil and ground water sources. This causes long-term effects that is deteriorating for environmental as well as human health- due to soil and ground water contamination that further causes dampening of food production and safety as well as causing acute and chronic diseases in the human body. The potential for a sensor system that detects in-field: the levels of pesticide residue in soil run-off is immense and would be beneficial to understand its negative effect on food security and food safety by inhibiting soil microbial activity and therefore impacting crop throughput and food quality. This field deployable sensor probe would help promote responsible agricultural practices and curb overapplication of harmful agents to the soil. Electrochemistry proves to be a viable choice of application for such a sensor to track pesticides in soil samples due to its feasibility for in-situ analysis used as well as solving for the ASSURED criteria as given by the World Health Organization (WHO), wherein it denotes- Affordable, Sensitive, Specific, User-friendly, Rapid, and robust, Equipment-free and Deliverable to end-users. The proposed system would have to utilize minimally complex sensor modification/functionalization and no pre-processing of samples. Hence citing all these factors and requirements, in this work- we present a highly intuitive electroanalytical sensor approach towards rapid, on-demand screening of 2 commonly used pesticides in this proof-of-feasibility study- Glyphosate and Atrazine in soil run-off which have a half-life of 47 days and 60-75 days respectively. By studying the levels of soil contaminant residues at the field site-the sensor acts as a screening instrument for soil pollution levels. The proposed sensor functions based on affinity biosensing mechanism driven via thiol-crosslinker and antibody receptors that holistically behaves as a recognition immunoassay stack that is specific and sensitive to track test pesticide analytes with a detection limit of 0.19 ng/mL or parts per billion (ppb) range for glyphosate and 0.15 pg/mL or parts per trillion (ppt) range for atrazine. Then, this developed sensor is integrated further to create a pesticide sensing ecosystem by means of a front-end field-deployable smart device with post-hoc Machine Learning (ML) assisted classification (LOW-MID-HIGH levels of pesticide) and thereby, a universal pesticide screening analytical device is designed and fabricated for pesticide assessment in real soil run-off samples.
 
 
 
 
 
 Figure 1
",ECS Meeting Abstracts,2022.0,10.1149/ma2022-01522143mtgabs,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
75fccf9eda7cf9c961efd3e9d42ba73ed37ab2e9,https://www.semanticscholar.org/paper/75fccf9eda7cf9c961efd3e9d42ba73ed37ab2e9,Tutorial: Edge Computing for Mobile Internet of Things,"Internet of things (IoT) has emerged as the enabling technology for smart applications in different domains, such as transportation, health-care, industry, smart homes and buildings, and education (e.g., [1-5]). IoT applications rely on the deployment of resourceconstrained devices that collect data from the environment it is immersed and control events of interest through actuators. One of the daunting challenges in many IoT applications is the need for the real-time processing of a large amount of produced data. Such processing is often impractical to be performed at the IoT devices, due to their resource-constrained nature and the incurred energy cost. In this regard, IoT data is often offloaded to be processed on distant powerful cloud servers, which return to IoT devices as the result of the heavy computations. This approach is well-suited for computation-intensive tasks in IoT applications. However, the process of task offloading to cloud servers incurs additional delays for the IoT application, in addition to the network overhead. Therefore, edge computing has been proposed to provide computation, communication, and storage resources closer to IoT devices. The general idea is to place resources in the proximity of IoT devices that will demand them. Thus, the latency involved in the IoT application is reduced since computation-intensive tasks are processed on edge devices rather than on distant cloud servers. One of the critical challenges in edge-aided IoT applications is that edge devices have limited resource capabilities when compared to cloud servers. In this regard, edge devices' resources must be managed and allocated in an efficient way, aimed at providing resources to IoT applications with guaranteed quality of service (QoS). This tutorial will motivate and explore the challenges, design principles, and goals of edge computing for IoT applications. It presents the building blocks for the design of optimization models for IoT task offloading to edge nodes. By doing so, it discusses the communication challenges between IoT and edge devices and highlights the different mathematical formulations commonly used in the literature to model IoT to edge communication. Furthermore, this tutorial discusses optimization-based and machine learning (ML)-based solutions for tackling the task offloading decision problem. Besides, this tutorial presents recent advancements in resource management solutions aimed at efficient resource allocation at edge devices. Finally, this tutorial shall conclude with a discussion of research opportunities and challenges in the edge-assisted Internet of things.",DIVANet,2021.0,10.1145/3479243.3494705,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
04665c9d99ff50ade214780f2fad2d2d7521c32b,https://www.semanticscholar.org/paper/04665c9d99ff50ade214780f2fad2d2d7521c32b,Smart Healthcare System for Severity Prediction and Critical Tasks Management of COVID-19 Patients in IoT-Fog Computing Environments,"COVID-19 has depleted healthcare systems around the world. Extreme conditions must be defined as soon as possible so that services and treatment can be deployed and intensified. Many biomarkers are being investigated in order to track the patient's condition. Unfortunately, this may interfere with the symptoms of other diseases, making it more difficult for a specialist to diagnose or predict the severity level of the case. This research develops a Smart Healthcare System for Severity Prediction and Critical Tasks Management (SHSSP-CTM) for COVID-19 patients. On the one hand, a machine learning (ML) model is projected to predict the severity of COVID-19 disease. On the other hand, a multi-agent system is proposed to prioritize patients according to the seriousness of the COVID-19 condition and then provide complete network management from the edge to the cloud. Clinical data, including Internet of Medical Things (IoMT) sensors and Electronic Health Record (EHR) data of 78 patients from one hospital in the Wasit Governorate, Iraq, were used in this study. Different data sources are fused to generate new feature pattern. Also, data mining techniques such as normalization and feature selection are applied. Two models, specifically logistic regression (LR) and random forest (RF), are used as baseline severity predictive models. A multi-agent algorithm (MAA), consisting of a personal agent (PA) and fog node agent (FNA), is used to control the prioritization process of COVID-19 patients. The highest prediction result is achieved based on data fusion and selected features, where all examined classifiers observe a significant increase in accuracy. Furthermore, compared with state-of-the-art methods, the RF model showed a high and balanced prediction performance with 86% accuracy, 85.7% F-score, 87.2% precision, and 86% recall. In addition, as compared to the cloud, the MAA showed very significant performance where the resource usage was 66% in the proposed model and 34% in the traditional cloud, the delay was 19% in the proposed model and 81% in the cloud, and the consumed energy was 31% in proposed model and 69% in the cloud. The findings of this study will allow for the early detection of three severity cases, lowering mortality rates.",Computational Intelligence and Neuroscience,2022.0,10.1155/2022/5012962,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
6edc440b44f37133c44c8004ade1cdb425547aa7,https://www.semanticscholar.org/paper/6edc440b44f37133c44c8004ade1cdb425547aa7,REACT : Physical Interactions Models of Companion Robots Supervisors :,"Robotics used for assistance to frail people draws nowadays a considerable interest in the domain of e-health thanks to the extended range of applications that it offers, together with the scientific and technological challenges that it brings forth. While the first generation of robots was conceived for the execution of repetitive and specific industrial tasks, the new generation introduces robots as artificial companions with cognitive and interactive skills allowing them to operate in open worlds. In particular, assistive service robots aim at helping people with disabilities due to age or sickness, to improve their independence et well-being at the long-term, while continuing to live within their social circle, instead of retirement institutions that tend to become increasingly costly and less available. In order to integrate a robot within living spaces, it has to be able to physically interact with its environment. We distinguish the interactions allowing for a robot to operate in its environment, such as stairs traversal and delivery/retrieval of objects. Given the diversity in forms and the robot sensing limits, a probabilistic approach with respect to the behaviour of the robot is required in terms of its interaction. This in turn should be based on the definition of probabilistic models able to capture the variance as well as the novelty, allowing for a robot to generalise its actions, or otherwise, retract. In this context, we propose in this thesis to study the introduction of new personal assistance services, by the definition and deployment of probabilistic models of physical interaction, between the robot and its environment. These models will serve two objectives: (1) render the operation of the robot more reliable from the user perspective and (ii) homogenise a given service across heterogeneous robots. The research to pursue in this context amounts to associating the actions of the robot with its effects on the environment, where the least controllable effects of an interaction are treated stochastically. The identification of these effects should finally allow to delimit the steps composing a robot service and to fine-tune the most controllable via the application of machine learning.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
4861af53198fe2d7cd84aceba16d5d5d33f58910,https://www.semanticscholar.org/paper/4861af53198fe2d7cd84aceba16d5d5d33f58910,Technology Literacy in Undergraduate Medical Education: Review and Survey of the US Medical School Innovation and Technology Programs,"Background Modern innovations, like machine learning, genomics, and digital health, are being integrated into medical practice at a rapid pace. Physicians in training receive little exposure to the implications, drawbacks, and methodologies of upcoming technologies prior to their deployment. As a result, there is an increasing need for the incorporation of innovation and technology (I&T) training, starting in medical school. Objective We aimed to identify and describe curricular and extracurricular opportunities for innovation in medical technology in US undergraduate medical education to highlight challenges and develop insights for future directions of program development. Methods A review of publicly available I&T program information on the official websites of US allopathic medical schools was conducted in June 2020. Programs were categorized by structure and implementation. The geographic distribution of these categories across US regions was analyzed. A survey was administered to school-affiliated student organizations with a focus on I&T and publicly available contact information. The data collected included the founding year, thematic focus, target audience, activities offered, and participant turnout rate. Results A total of 103 I&T opportunities at 69 distinct Liaison Committee on Medical Education–accredited medical schools were identified and characterized into the following six categories: (1) integrative 4-year curricula, (2) facilitated doctor of medicine/master of science dual degree programs in a related field, (3) interdisciplinary collaborations, (4) areas of concentration, (5) preclinical electives, and (6) student-run clubs. The presence of interdisciplinary collaboration is significantly associated with the presence of student-led initiatives (P=.001). “Starting and running a business in healthcare” and “medical devices” were the most popular thematic focuses of student-led I&T groups, representing 87% (13/15) and 80% (12/15) of respondents, respectively. “Career pathways exploration for students” was the only type of activity that was significantly associated with a high event turnout rate of >26 students per event (P=.03). Conclusions Existing school-led and student-driven opportunities in medical I&T indicate growing national interest and reflect challenges in implementation. The greater visibility of opportunities, collaboration among schools, and development of a centralized network can be considered to better prepare students for the changing landscape of medical practice.",JMIR medical education,2022.0,10.2196/32183,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1b8d1de7d0939840ee2487df3351c96fdaa95d4d,https://www.semanticscholar.org/paper/1b8d1de7d0939840ee2487df3351c96fdaa95d4d,A Bayesian Network Decision Support Tool for Low Back Pain Using a RAND Appropriateness Procedure: Proposal and Internal Pilot Study (Preprint),"
 BACKGROUND
 Low back pain (LBP) is an increasingly burdensome condition for patients and health professionals alike, with consistent demonstration of increasing persistent pain and disability. Previous decision support tools for LBP management have focused on a subset of factors owing to time constraints and ease of use for the clinician. With the explosion of interest in machine learning tools and the commitment from Western governments to introduce this technology, there are opportunities to develop intelligent decision support tools. We will do this for LBP using a Bayesian network, which will entail constructing a clinical reasoning model elicited from experts.
 
 
 OBJECTIVE
 This paper proposes a method for conducting a modified RAND appropriateness procedure to elicit the knowledge required to construct a Bayesian network from a group of domain experts in LBP, and reports the lessons learned from the internal pilot of the procedure.
 
 
 METHODS
 We propose to recruit expert clinicians with a special interest in LBP from across a range of medical specialties, such as orthopedics, rheumatology, and sports medicine. The procedure will consist of four stages. Stage 1 is an online elicitation of variables to be considered by the model, followed by a face-to-face workshop. Stage 2 is an online elicitation of the structure of the model, followed by a face-to-face workshop. Stage 3 consists of an online phase to elicit probabilities to populate the Bayesian network. Stage 4 is a rudimentary validation of the Bayesian network.
 
 
 RESULTS
 Ethical approval has been obtained from the Research Ethics Committee at Queen Mary University of London. An internal pilot of the procedure has been run with clinical colleagues from the research team. This showed that an alternating process of three remote activities and two in-person meetings was required to complete the elicitation without overburdening participants. Lessons learned have included the need for a bespoke online elicitation tool to run between face-to-face meetings and for careful operational definition of descriptive terms, even if widely clinically used. Further, tools are required to remotely deliver training about self-identification of various forms of cognitive bias and explain the underlying principles of a Bayesian network. The use of the internal pilot was recognized as being a methodological necessity.
 
 
 CONCLUSIONS
 We have proposed a method to construct Bayesian networks that are representative of expert clinical reasoning for a musculoskeletal condition in this case. We have tested the method with an internal pilot to refine the process prior to deployment, which indicates the process can be successful. The internal pilot has also revealed the software support requirements for the elicitation process to model clinical reasoning for a range of conditions.
 
 
 INTERNATIONAL REGISTERED REPORT
 DERR1-10.2196/21804
",,2020.0,10.2196/preprints.21804,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
590c72f28a55f4525b758ca366e03f3cd85a408f,https://www.semanticscholar.org/paper/590c72f28a55f4525b758ca366e03f3cd85a408f,"Drones Move From ""Nice To Have"" to Strategic Resources for Projects","While drones have been used on oil and gas facilities for video inspections and other tasks, they have been operated by an on-site pilot or one positioned on a bobbing workboat adjacent to an offshore platform. Now a proof-of-concept study conducted by TechnipFMC has tested the feasibility of a global drone system with drones operated remotely by pilots based anywhere in the world. The study is the subject of a paper (OTC 30241) presented at the Offshore Technology Conference Asia in Kuala Lumpur in November.
 Construction supervision and health, safety, and environmental (HSE) monitoring were the main drivers of the study. The construction supervision application is part of a larger digitalization ambition to monitor and manage construction activities with data generated from the drone ultimately feeding an internal software dedicated to this business process. Potential HSE applications include crisis management, human safety, evacuation assistance, hazardous-area identification, traffic control, carbon-footprint reduction, and environmental surveys.
 One of the study’s main objectives was to move from traditional unmanned autonomous vehicles (UAV) to resident systems and to investigate the possibilities they could offer. Aerial views have been used extensively to reduce personnel exposure in specific situations such as difficult access or potentially dangerous inspection areas like active flares, confined spaces, or high structures. In these cases, the drones are controlled by an on-site pilot who is either within their line of sight or a short distance away.
 Combining AUV technology with embedded and associated intelligence from the internet of things (IoT), artificial intelligence (AI), and cloud and edge computing should enable drones to fly safely in complex and dynamic environments, resulting in integrated, resident systems that are permanently deployed at construction sites and available 24/7 without the need for an on-site certified pilot. Implementing these technologies will make data accessible and available in real time to people working on the project worldwide and it will also generate new work processes for project management and execution.
 Flight and Operations Testing
 According to the paper’s primary author, Nicolas Tcherniguin, manager of offshore business and technology with TechnipFMC, digital tools such as image recognition, machine learning, and simulation of digital twins based on the drone’s flight have been tested. Remaining bottlenecks have been identified, and some have been addressed while others will require additional efforts. AI development will offer additional features, especially if they can be integrated with other ground monitoring devices.",,2020.0,10.2118/1220-0029-JPT,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b4acbd2c49b085a65466f84e15f84c85a814f78e,https://www.semanticscholar.org/paper/b4acbd2c49b085a65466f84e15f84c85a814f78e,Data Dissemination in Mobile Phone Sensor Networks,"Deploying sensors over large areas is costly in terms of configuration, hardware, and maintenance. Using onboard sensors of today mobile phones can significantly reduce the expenses in monitoring areas and disseminating events or data. Via the available short-range Bluetooth and/or WiFi interfaces, measured data are not only gradually delivered, but also possibly more reliable. In our simulation, existing Delay-Tolerant Network routing algorithms show poor performance on a complex network comprising diverse kinds of sensor nodes, such as, mobile phones, cars, and road side units. New approaches that can perform well on such heterogeneous networks are needed. They also need to support exchanging measurements among sensors for more accurate inference. In the early phase, we set up a heterogeneous architecture composed of different sorts of sensors, and propose an algorithm, Unified routing, for routing and disseminating. A further variant of the scheme is being developed. Early simulation results are consistent with theoretical prediction. After finishing the first step, Unified routing, the focus of our research will be on distributed data processing. Finally, routing and distributed data processing will be investigated in a testbed in a realistic context. Viet-Duc Le joined Pervasive Systems in June 2011 for a 4-year Ph.D. program. He is doing his research in the SenSafety project, where the main focus is on opportunistic sensing and networking, and on distributed sensor data processing. He received a Bachelor degree in ElectricalElectronics Engineering from Ho Chi Minh City University of Technology, Vietnam, in 2002, and a Master degree in Computer Engineering from KyungHee University, South Korea, in 2009. He is interested in Machine Learning and Pattern Recognition. More specifically, the focus of his research is to design and analyze inference algorithms for data in Wireless Sensor Networks and Opportunistic Network that can be applied to Health-care applications, Location Tracking, Public Safety, and Smart Transportation Systems. Besides his academic research, he has worked more than six years as a researcher or a team leader of many industrial projects related to sensor applications and web database.",,2012.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
007cff33291104a207d5cd114b10ecd83abfa415,https://www.semanticscholar.org/paper/007cff33291104a207d5cd114b10ecd83abfa415,Author Responses to Reviewer Comments and Manuscript Revisions,"Advances in ambient environmental monitoring technologies are enabling concerned communities and citizens to collect data to better understand their local environment and potential exposures. These mobile, low-cost tools make it possible to collect data with increased temporal and spatial resolution providing data on a large scale with unprecedented levels of detail. This type of data has the potential to empower people to make personal decisions about their exposure and support the development 5 of local strategies for reducing pollution and improving health outcomes. However, calibration of these low-cost instruments has been a challenge. Often, a sensor package is calibrated via field calibration. This involves colocating the sensor package with a high-quality reference instrument for an extended period, and then applying machine learning or other model fitting technique such as multiple-linear regression to develop a calibration model for converting raw sensor signals to pollutant concentrations. Although this method helps to correct for the effects of 10 ambient conditions (e.g., temperature) and cross-sensitivities with non-target pollutants, there is a growing body of evidence that calibration models can overfit to a given location or set of environmental conditions on account of the incidental correlation between pollutant levels and environmental conditions, including diurnal cycles. As a result, a sensor package trained at a field site may provide less reliable data when moved, or transferred, to a different location. This is a potential concern for applications seeking to perform monitoring away from regulatory monitoring sites, such as personal mobile monitoring or 15 high-resolution monitoring of a neighborhood. We performed experiments confirming that transferability is indeed a problem and show that it can be improved by collecting data from multiple regulatory sites and building a calibration model that leverages data from a more diverse dataset. We deployed three sensor packages to each of three sites with reference monitors (nine packages total), and then rotated the sensor packages through the sites over time. Two sites were in San Diego, CA, with a third outside of Bakersfield, CA, offering 20 varying environmental conditions, general air quality composition, and pollutant concentrations. When compared to prior single-site calibration, the multi-site approach exhibits better model transferability for a range of modeling approaches. Our experiments also reveal that random forest, is especially prone to overfitting, and confirms prior results that transfer is a significant source of both bias and standard error. Linear regression on the other hand, although it",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
5262defa4ca27a08d5fceb62a82b4356d0356318,https://www.semanticscholar.org/paper/5262defa4ca27a08d5fceb62a82b4356d0356318,Persim : Simulation of Human Activities in Pervasive Spaces,"Today, the computing elements are pervading through our environment that brings cyberphysical research as an emergent computing paradigm. Computational and physical elements have become so intertwined with each other that computing is embedded in almost all everyday objects. This has opened a new dimension to various research areas such as assisted living, health care, elder care etc. Researchers are engaged in developing new algorithms and techniques in machine learning and data mining in order to detect activity, learn context, and act autonomously without any human intervention. Thus cyber-computing research involves building and instrumenting a smart space, recruiting participants, and finally collecting data from the space. To obtain data from physical deployments is crucial in order to longitudinally evaluate the accuracy and performance of the developed models and algorithms. But this is very challenging because of the huge cost, significant ground work, lack of access to human subjects, and the time consuming process of acquiring meaningful data from real world settings. Now, the community needs a ‘supportive’ research initiative which will look for alternative and practical approaches to overcome aforementioned challenges and accelerate experiments with the smart space. Realistic simulation is a promising idea to support the rising demand for test data. Simulation also allows a wider community of researchers to engage and collaborate to solve a specific problem. Hence, algorithms and models based on preliminary simulation studies would most likely to be a more robust and help researchers assess their ideas and algorithms quickly and cost-effectively. In this proposal, an event-driven simulation tool – Persim is proposed to simulate hierarchical activities in pervasive space. The idea is to create a simulated environment of actual pervasive space via modeling activity and generating activity data in standardized format corresponding to the environment. Such simulations can be used in early stage research that can help researchers evaluate their ideas quickly and with reasonable accuracy. The tool is intended to create a knowledge base for human activities and emulate specific scenarios. It can also be used for automatic annotation of dataset based on the knowledge base.",,2010.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
02ee08087aaecb5dbf4cfcad68ea3af96162b574,https://www.semanticscholar.org/paper/02ee08087aaecb5dbf4cfcad68ea3af96162b574,Methodological guide to deploy Functional Analysis into CODAC Systems for the Tritium Processing in ITER,"The present document is focused on the a nalysis of the ITER - TBM‘s Proto - CODAC system. ITER is considered to be the first nuclear fusion reactor to be energetically feasible for a sustained period of time with a rated fusion power of 500 MW. ITER Project involves 35 countries with a total est imated budget of some 15.000 M€; being the first of its kind from the point of view of international collaboration, engineering and supply sources; where every country participate with the best of its possibilities. The hearth of the fusion reactor is a giant Tokamak (6.2 m plasma major radius) with a se ries of ancillary buildings and facilities that might complete the whole p roject. The operation of ITER is scheduled to operate along the next 50 years , after completion of the facilities construction and commissioning of the plant, considering first to b e operated in D - D and further in a D - T modes. In this sense, the activity that supports the development of the present work was stated to be necessary to consider a tritium balance for the self - sufficient reaction and operation of the whole. Tritium is a v ery scarce element being its global sto cks to the present date of 2016 of some 20 kg, being produced mainly collected from the operation of Candu reactors in Canada [Raeder, 1986] . Also the operation of the ITER reactor might produce Tritium at a rate that might b e able to support the fusion reaction indefinitely on a time basis. Because of the tritium balance it is difficult to state due to its highly permeation throughout confinement of first walls and joint materials . Not to mention its high ly dangerous potential to human health, according to radiologic al properties . This is why it is necessary to establish predictive tools that might indicate the concentration and inventory across the facility, including emissions to the environment. In this sense, ITER Instrumentation and Control systems for Control and Data Acquisition (DACS) mainly constitute the layers between the users (Control Room) and the field Instrumentation (sensors and actuators). This is nam ed as ITER CODAC, which is the primary global system analyzed in the present document. The control philosophy it is stated to be predictive and from the author‘s point of view must include the comparison between field measurement and advanced modeling, including machine learning utility system that might be deployed in computational base.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
3f9d9414a3077ee1630c65a9258ec3728ed5e778,https://www.semanticscholar.org/paper/3f9d9414a3077ee1630c65a9258ec3728ed5e778,Statistical Communications in Infectious Diseases,"Background: Human immunodeficiency virus (HIV) viral failure occurs when antiretroviral therapy fails to suppress and sustain a person’s viral load count below 1,000 copies of viral ribonucleic acid per milliliter. For those newly diagnosed with HIV and living in a setting where healthcare resources are limited, such as a lowand middle-income country, the World Health Organization recommends viral load monitoring six months after initiation of antiretroviral treatment and yearly thereafter. Deviations from this schedule are made in cases where viral failure occurs or at the discretion of the clinician. Failure to detect viral failure in a timely fashion can lead to delayed administration of essential interventions. Clinical prediction models based on information available in the patient medical record are increasingly being developed and deployed for decision support in clinical medicine and public health. This raises the possibility that prediction models can be used to detect potential for viral failure in advance of viral measurements, particularly when those measurements occur infrequently. Objective: Our goal is to use electronic health record data from a large HIV care program in Kenya to characterize and compare the predictive accuracy of several statistical machine learning methods for predicting viral failure at the first and second measurements following initiation of antiretroviral therapy. Predictive accuracy is measured in terms of sensitivity, specificity and area under the receiver-operator characteristic curve. Methods: We trained and cross-validated 10 statistical machine learningmodels and algorithms on data from over 10,000 patients in the Academic Model Providing Access to Healthcare care program in western Kenya. These included parametric, non-parametric, ensemble, and Bayesian methods. The input variables included 50 items from the clinical record, hand picked in consultation with clinician experts. Predictive accuracy measures were calculated using 10-fold cross validation. Results: Viral load failure rate is about 20% in this patient cohort at both the first and second measurements. Ensemble techniques generally outperformed other methods. For predicting viral failure at the first follow up measure, specificity was over 90% for these methods, but sensitivity was typically in the 50–60% range. Predictive accuracy was greater for the second follow upmeasure, with sensitivities over 80%. Super Learner, gradient boosting and Bayesian additive regression trees consistently outperformed other methods. For a viral *Corresponding author: Joseph W. Hogan, Brown University, Providence, Rhode Island, USA; and Academic Model Providing Access to Healthcare (AMPATH), Eldoret, Kenya, E-mail: jwh@brown.edu. https://orcid.org/0000-0001-7959-7361 Allan Kimaina, Moi University, Eldoret, Kenya; Brown University, Providence, RI, USA; and Academic Model Providing Access to Healthcare (AMPATH), Eldoret, Kenya JonathanDick, IndianaUniversity, Indianapolis, IN, USA; AcademicModel Providing Access to Healthcare (AMPATH), Eldoret, Kenya Allison DeLong, Stavroula A. Chrysanthopoulou and Rami Kantor, Brown University, Providence, RI, USA Statistical Communications in Infectious Diseases 2020; 12(s1): 20190017",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
354c445d8fe45a1bdcc862dd2cdfce4289acfc4f,https://www.semanticscholar.org/paper/354c445d8fe45a1bdcc862dd2cdfce4289acfc4f,"Privacy, Health, and Race Equity in the Digital Age","Privacy is a basic and foundational human good meriting moral and legal protection (Allen 2011). Privacy isn’t, however, everything (Allen 2003). Other goods and values matter, too (Solove 2003; Marmor 2015). Bioethicists are rethinking privacy and confidentiality as health-related policy imperatives in light of the common good and digital life (Austin 2003). In the 1990s, the era of the Human Genome Project, prevailing bioethical perspectives emphasized the importance of privacy and confidentiality in clinical, research and health administrative settings (Dhir and Aggarwal 1998; Allen 1999; Goldman, Schwartz, and Tang 2000). Many debated whether genetic information required exceptional levels of concealment (Gostin and Hodge 1999). It was also the era when the Health Insurance Portability and Accountability Act (HIPAA) was enacted (Allen 2021). By the early 2000s, regulators had implemented HIPAA’s Privacy and Security Rules, and the Genetic Information Nondiscrimination Act was enacted (Allen 2021). Today, a shift from privacy enthusiasm to skepticism can be discerned, with applications of artificial intelligence and machine learning at a historic apex. Older ideals promoting generous health data privacy clashes with newer ideals promoting generous health data sharing (Romoser 2018). Cautious critics of neuroscience applications harken back to older ideals of the privacy of mental states and the brain (Farahany 2023). The federal government’s marketing of the “All of Us Project” reflects the newer ideal and attendant priorities (Denny et al. 2019). Among the pressures on the older ideals of health privacy is the concern that socially useful, even lifesaving, technological innovations could be thwarted by “individualistic” privacy impediments. The philosophic worry that an individualistic interpretation of privacy works mischief in the world is not new to the digital age. Philosophers have long argued, including in the face of feminist and progressive critiques (Allen 1988), that although the concept of privacy can be deployed for anti-social purposes, privacy is not an inherently anti-social value. On the contrary, privacy functions to empower individuals to be more fit for the varied social roles and responsibilities comprising everyday lives in our inevitably social world. Indeed, “opportunities for individual forms of personal privacy make persons more fit for social participation and contribution to the pool of resources and assets available to all” (Allen 1988, 51). Dignity, self-determination and well-being require opportunities for privacy and private choices, rendering privacy an aspect of the collective good. Put differently, privacy is socially and politically embedded (Mokrosinska 2018). When both data privacy and data disclosure commend themselves, nuanced and context-specific accommodation (“balancing”) are required (Francis 2008; Miedema 2020), not eschewals of privacy based on its alleged “individualism.” It’s time to move beyond pitting individual privacies against collective goods. Bioethicists on the cutting edge are turning to equity issues raised by the privacy protection project. As fundamental as it is, the problem of how a world clamoring for big data honors privacy interests traditionally enshrined in moral and legal rights is but one meriting the attention of bioethicists in the digital age. Another fundamental contemporary concern worthy of emphasize is how marginalized and racialized populations fare in efforts to regulate privacy (Goodwin 2020). Do regulations proposed and enacted on the state and federal level protect the interests of all members of the collective equally well? Do underlying structures of racism, prejudice, and privilege, along with differences in compliance and enforcement mean that some people’s privacy is better protected than others’? (Allen 2015) The privacy of African Americans is not consistently well-protected, whether in the name of individuals or the collective. The new ethos of data sharing is",The American journal of bioethics : AJOB,2022.0,10.1080/15265161.2022.2076405,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
83338fac01dcee281ad4f41d05559a71a5d582bf,https://www.semanticscholar.org/paper/83338fac01dcee281ad4f41d05559a71a5d582bf,2019-01242-Temporary scientific engineer / Software development and machine learning for network security,"Scientific Context: In last years, Internet-of-Things became a reality with numerous protocols, platforms and devices [8] being developed and used to support the growing deployment of smart* services: smart-home, transport, -health, -city... and even the rather usual rigid systems with industry 4.0. Providing new services have required first the development of new functionalities with as underlining goals to have more powerand computeefficient devices which can embed various sensors. Obviously, IoT also supposes a full infrastructure to guarantee the efficiency of communications and processing of information. The embedded devices are thus completed by access points, routers, servers, etc. At the higher levels services are developed and provided to the users. This ecosystem is very rich and cannot be controlled by a unique entity, e.g. services are o en developed by third parties, manufacturer of embed devices are different to those providing connectivity... As a result, such a complex system is naturally a source of potential threats and real cases recently demonstrates that IoT can be affected by naïve weaknesses [1,6]. At Inria, we even demonstrated how simple and cheap can it be take over the control of a Z-Wave home installation in a silent manner [2]. Therefore, security is paramount of importance. In last decade, many IoT architectures have been proposed, such as the reference model IoT-A [3], including security modules. However, as highlighted before, security cannot be guaranteed without failure or by-design and this is all the more true with evolving ecosystems such as IoT, with now the emerging trend of using fog-based architecture rather than well-established cloud models. To enhance security, one option is to redesign an IoT architecture with stronger security but this will face the same problems as before, since some security issues can appear afterwards. Maintaining the architecture with new security elements would be therefore required but a remaining problems is the numerous number protocols or platforms that already exist. Nowadays, the only viable solution is so to provide new security mechanisms that could be composed on demand and deployed in any IoT deployment by the operators, the integrators or the vendors rather than developing protocolor architecture-centric security solutions. [1] Manos Antonakakis et. al , Understanding the Mirai Botnet, USENIX Security, 2017 [2] L. Rouch et. Al, A Universal Controller to Take Over a Z-Wave Network, Black Hat Europe, 2017 [3] Alessandro Bassi, Martin Bauer, Martin Fiedler, Thorsten Kramp, Rob van Kranenburg, Sebastian Lange, Stefan Meissner (eds), “Enabling Things to Talk”, Designing IoT solutions with the IoT Architectural Reference Model, Springer, 2013 [4] J. François et. al, PTF: Passive Temporal Fingerprinting, IFIP/IEEE International Symposium on Integrated Network Management (IM), 2011 [5] BF Van Dongen et. al, The prom framework: A new era in process mining tool support, ICATPN 2005 [6] C. Kolias, G. Kambourakis, A. Stavrou and J. Voas, ""DDoS in the IoT: Mirai and Other Botnets,"" in Computer, vol. 50, no. 7, pp. 80-84, 2017. [7] Markus Miettinen, Samuel Marchal, Ibbad Hafeez, N. Asokan, Ahmad-Reza Sadeghi, Sasu Tarkoma: IoT SENTINEL: Automated Device-Type Identification for Security Enforcement in IoT. ICDCS 2017: [8] A. Al-Fuqaha, M. Guizani, M. Mohammadi, M. Aledhari and M. Ayyash, ""Internet of Things: A Survey on Enabling Technologies, Protocols, and Applications,"" in IEEE Communications Surveys & Tutorials , vol. 17, no. 4, pp. 2347-2376, Fourthquarter 2015.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c54d8b94e3290ae5e02ffcfdc407e6d519ceec2f,https://www.semanticscholar.org/paper/c54d8b94e3290ae5e02ffcfdc407e6d519ceec2f,Medical Healthcare System with Hybrid Block based Predictive models for Quality preserving in Medical Images using Machine Learning Techniques,"Cloud technology is a business strategy that aims to provide the necessary material to customers depending on their needs. Individuals and cloud businesses alike have embraced the cloud storage service, which has become the most widely used service. The industries outsource their data to cloud storage space to relieve themselves of a load of dealing with redundant data contents. This must be protected to prevent the theft of personal belongings, and privacy must be improved as well. Different research projects have been suggested to ensure the safe management of the information included within the data content. The security of current research projects, on the other hand, still needs improvement. As a result, this method has been suggested to address the security concerns associated with cloud computing. The primary goal of this study effort is to offer a safe environment for cloud users while also increasing the profit of cloud resource providers by managing and securely delivering data contents to the cloud users. The bulk of sectors, including business, finance, the military, and the healthcare industry, do not store data in cloud-based storage systems. This technique is used to attract these kinds of customers. Increasing public acceptance Medical researchers are drawn to cloud computing because it allows them to store their study material in a centralized location and distribute and access it in a more flexible manner. They were collected from numerous individuals who were being evaluated for medical care at the time. Scalable and Enhanced Key Aggregate Cryptosystem is a protected data protection method that provides highly effective security in the health care industry. This approach handles disagreements in the outflow of sensitive information and guarantees the data security deployment of a Cloud-based Intelligent Health Monitoring system for the parties involved in the dispute. Using the suggested method, the encrypted data format of medical and health-care prescriptions is recorded as it passes through the hands of patients and healthcare institutions. To increase the level of security, the double encryption method is used. During the encryption process, the Ciphertext ID is referred to as a class. The keyholder is a master secret key that aids in the retrieval of the secret keys of different kinds of monsters and creatures. The extracted key is transmitted and kept as a single aggregate for the benefit of the patient or client to facilitate decryption. Between the use of a key aggregation cryptosystem and double encryption method, the Cloud-based Intelligent Health Monitoring systems may establish a secure link with Healthcare Organizations and patients. As a result, when compared to prior methods, the results demonstrate that the study methodology achieves high levels of security in terms of confidentiality and integrity, as well as great scalability.",2022 International Conference on Advanced Computing Technologies and Applications (ICACTA),2022.0,10.1109/ICACTA54488.2022.9753355,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cd4f1c3ad1118281da7029ff7be6771b05e9bdde,https://www.semanticscholar.org/paper/cd4f1c3ad1118281da7029ff7be6771b05e9bdde,S29 Physical activity and sleep quality as related to patient-reported outcomes and physiology during recovery from severe COPD exacerbation,"S29 Figure 1 (A) Daily physical activity in patients with severe (n=15) or very severe (n=48) airflow obstruction, (b) Hourly physical activity count per 24-hour period for 4 weeks post-discharge following sentence AECOPD. Spoken sessions A22 Thorax 2021;76(Suppl 2):A1–A205 on Jauary 6, 2022 by gest. P rocted by coright. httphorax.bm jcom / T hrax: frst pulished as 10.113orax-2021-B T S absacts.35 on 8 N ovem er 221. D ow nladed fom demonstrated associations between PA and age (b=-2.37, p=0.01) and lean mass (b=2.45,p=0.002). PA was lower in males (b=-49.84,p=0.001), on weekends (b=-5.49, p=0.01) and in those who died within 1-year (b=-41.24,p=0.04), and was associated with total sleep time (TST) (b=0.01,p=0.003), EXACT score (b=-0.97,p=0.002), COPD assessment test (b=1.63,p=0.02), FEV1 (b=46.38,p<0.001), inspiratory capacity (b=44.17,p<0.001), PImax (b=2.14,p<0.001) and neural respiratory drive, measured using parasternal EMG (b=-2.12, p=0.01). Patients readmitted within 28-days exhibited poorer sleep quality than non-readmitted patients (TST: b=-110, p=0.004, latency: b=34,p=0.03). Conclusions This study provides a novel insight into the improvement in daytime activity occurring in the 28 days following hospital discharge after severe COPD exacerbation. Physical activity related inversely to age, symptom burden, health status and neural respiratory drive, and positively to lean mass, respiratory muscle strength, expiratory airflow and inspiratory capacity. Total sleep time fell following hospital discharge, and sleep quality was lower in readmitted patients. Future research is needed to evaluate the impact of targeted interventions that enhance physical activity and sleep quality on hospital readmission in this high-risk population. S30 PREDICTING HOSPITAL LENGTH OF STAY FOR ACUTE ADMISSIONS IN PATIENTS WITH COPD G Cox, S Burns, A Taylor, P McGinness, DJ Lowe, C Carlin. StormID, Edinburgh, UK; Queen Elizabeth University Hospital, Glasgow, UK 10.1136/thorax-2021-BTSabstracts.36 Introduction Accurate predictions of hospital length of stay (LOS) at the time of admission allows clinicians to direct patients to the most appropriate medical services, prevent overcrowding in emergency departments via improved patient flow, and better manage hospital resources. Objectives To develop, evaluate and explain machine learning classifiers that predict prolonged LOS ( 2 days) using information that is known at the time of acute admission, does not change during the patient’s hospital stay, and would be easy to input to a model deployed in a clinical setting. Methods A SafeHaven dataset of de-identified electronic health records for acute admissions of patients with COPD to four Scottish hospitals between January 2010 and March 2019 was prepared. Using XGBoost algorithms and a binary classifier (admission <48 hours or >48 hours) we developed a set of machine-learning models that predict whether a patient will have a prolonged LOS and investigated which variables contribute the most to prediction performance. We produced separate models for: 1) all acute admissions in the study period (n=75387); 2) COPD related admissions (n=12137); 3) admissions relating to COPD or a broader set of respiratory conditions (n=20134). We evaluated model performance on an unseen test data set based on Receiver Operating Characteristic and Precision Recall Curves, and the precision, recall and F1 scores. Further, we compared models to two established clinical scores to predict emergency department disposition: the Glasgow Admission Prediction Score (GAPS) and the Ambulatory Score (Ambs). We used SHapley Additive exPlanations to explain why specific model predictions are made for individual patients. Results Our models highlighted several key factors that contribute to prolonged LOS in COPD patients. Some relate to patient clinical history, such as certain existing comorbidities, previous diagnoses on discharge and LOS for previous hospital visits, which is rarely considered in LOS prediction models. Conclusions We have identified several factors relating to clinical and admission history that influence COPD patients’ likelihood of prolonged acute admissions and are able to explain the rationale behind individual predictions. Since these factors would be known at admission time, they could be passed to a deployed LOS predictive model to aid clinical decision","COPD exacerbations: prevention, treatment, recovery",2021.0,10.1136/thorax-2021-btsabstracts.35,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a21fc370a7e0854d456c921d6a061a84c82ffee,https://www.semanticscholar.org/paper/2a21fc370a7e0854d456c921d6a061a84c82ffee,Letter from the Special Issue Editor,"As Artificial Intelligence (AI) and Machine Learning (ML) are increasingly being used to make consequential decisions that may critically impact individuals and many aspects of our society such as criminal justice, health care, education, and employment, there is a growing recognition that AI systems may perpetuate or, worse, exacerbate the unfairness of existing social systems. To tackle this problem, there has been a sharp recent focus on fair AI/ML research in the Machine Learning community. These efforts tend to focus on how to engineer fair AI models by (a) defining appropriate metrics of fairness and (b) designing new algorithms to mitigate bias and ensure fairness. It however frequently overlooks the messy, complex and ever changing contexts in which these systems are deployed. As AI fairness is a complex socio-technical issue which cannot be addressed by a purely technical solution, designing fair AI systems requires close collaboration across multiple disciplines to deeply integrate the social, historical, legal, and technical context and concerns in the design process. In this special issue on Interdisciplinary Perspectives on Fairness and Artificial Intelligence Systems, leading researchers from engineering, social science and humanities present their work on ethical considerations in developing fair AI systems specifically, and responsible socio-technical systems in general. We sought highquality contributions that integrate ideas from more than one field across the disciplines of technology, social science and the humanities. These papers will provide readers deep insights into the nature and complexity of AI biases, their manifestations in developing practical socio-technical systems and typical mitigation strategies. They also identify opportunities for the AI community to engage with the experts from the humanities. Safiya U. Noble and Sarah T. Roberts from UCLA seek to expand the conversations about socio-technical systems beyond individual, moral and ethical concerns. They believe that the field of “ethical AI” must contend with how it affects and is affected by power structures that encode systems of sexism, racism, and class. They advocate the need for independent research institutes, such as the UCLA Center for Critical Internet Inquiry (C2i2) to promote investigations into the politics, economics, and impacts of technological systems. Jennifer Keating from the University of Pittsburgh discusses the importance of incorporating ethical standards and responsible design features into the development of new technologies. Covid contact tracing was used as a case study to illustrate how rapidly developed tools can have unintended consequences if they are not carefully designed/monitored. She advocates that technologists should collaborate with experts from the humanities to integrate deeper cultural concerns and social/political context into technology development. Lisa Singh and her co-authors from Georgetown University overview the challenges associated with using social media data and the ethical considerations they create. They frame the ethical dilemmas within the context of data privacy and algorithmic fairness and show how and when different ethical concerns arise. Sebastian Schelter from University of Amsterdam and Julia Stoyanovich from NYU present a discussion on technical bias that arises in the data processing pipeline. A number of potential sources of bias during the preprocessing, model development and deployment phases of the ML development lifecycle are identified, with illustrative examples. They show how software support can help avoid these technical bias issues. The broader point of the work is to shed light on the challenge of bias introduced due to data engineering decisions, and to promote an emerging research direction on developing solutions to mitigate it. James Foulds and Shimei Pan from UMBC aim to shed light on whether parity-based metrics are valid measures of AI fairness. They consider the arguments both for and against parity-based fairness definitions and provide a set of guidelines on their use in different contexts. Finally, Jared Sylvester and Edward Raff from Booz Allen Hamilton argue that good-faith efforts toward implementing fairness in practical ML applications should be encouraged, even when the fairness interventions may not result from completely resolving thorny philosophical debates, as this represents progress over the (likely unfair) status quo. This viewpoint is discussed in several contexts: choosing the right fairness metric, solving trolley problems for self-driving cars, and selecting hyper-parameters for fair learning algorithms. James Foulds and Shimei Pan University of Maryland, Baltimore County",IEEE Data Eng. Bull.,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
58dc374e2669cd54638605c336334c9aff818095,https://www.semanticscholar.org/paper/58dc374e2669cd54638605c336334c9aff818095,Selected Papers from the Eleventh ITU Kaleidoscope Academic Conference,"This special section contains two updated papers, originally presented at the eleventh International Telecommunication Union’s (ITU) Kaleidoscope academic conference. The title of the conference was “ICT for Health: Networks, Standards and Innovation,” and took place in the United States, specifi cally in Atlanta, Georgia from 4-6 December 2019. The host was the Georgia Tech Research Institute with the collaboration of the World Health Organization (WHO). There were nearly 100 participants: 70 physically at the venue coming from 16 countries and over 30 on the web. The proceedings are available on the ITU website at https://www.itu.int/pub/T-PROC-KALEI-2018, and from the IEEE Xplore Digital Library. Pictorial highlights from the conference are available at https://www.fl ickr.com/photos/ itupictures/with/49237161532/. The topic of the next conference is “Industry-Driven Digital Transformation.” It was originally scheduled for 7-9 September 2020 in Hanoi, Viet Nam, in conjunction with the ITU Digital World 2020. However, due to the Covid-19 pandemic, it is now an online conference from 7–11 December 2020 running four hours per day to accommodate the various time zones. To access the conference, check its main page at https://www.itu.int/en/ITU-T/academia/kaleidoscope/2020. The ITU Kaleidoscope series of academic conferences started in 2008 to provide an interdisciplinary forum for the discussion of Information and Communication Technologies (ICTs) relevant to future telecommunication standards. Participants typically include researchers, academics, students, engineers, policymakers, regulators as well as futurists. The fi rst article in this issue deals with Machine Learning (ML) and Artifi cial Intelligence (AI) in medicine. The main challenge is that, because of the wide variety of patients and clinical conditions, ML/AI models must produce results that practitioners can rely on even when the algorithms process previously unseen data. Another diffi culty is that these algorithms are black boxes because their exact workings are unknown. Some bioethicists have suggested that applying trust to AI is a corruption of language that can corrupt thought because it is “a category error, mistakenly assuming that AI belongs to a category of things that can be trusted” [1]. This is why international cooperation is indispensable because it allows substantial synergies in the selection of the training and test data sets as well as the validation of the software, from both engineering and clinical viewpoints. This invited article from the Fraunhofer Heinrich Hertz Institute and the Technische Universität Berlin, titled “Toward Global Validation Standards for Health AI,” covers these aspects. The authors, Markus A. Wenzel and Thomas Wiegand, present an overview of the work being carried out under the joint auspices of the ITU-T and WHO to address the use of machine learning and artifi cial intelligence in healthcare, and highlight what has been achieved in terms of guidelines. On the regulatory side, they mention the contributions of the National Health Service in the UK and the International Medical Device Regulators Forum. On the standardization side, they list activities by a variety of organizations such as the U.S. National Institute of Standards and Technology (NIST), the Chinese Electronics Standards Institute, the European Union High-Level Expert Group on AI, the German Deutsches Institut für Normung (DIN), the IEEE, and the International Organization for Standardization (ISO). The second article, “Converged Internet of Lights Network for Telecommunication, Positioning, Illumination and Medical Therapy,” is a joint contribution from several Chinese and British universities and research institutions. The authors are Jian Song, Xiaofei Wang, Jintao Wang, Hongming Zhang, Changyong Pan, Yue Zhang, and John Cosmas. They focus on the spectrum of the visible light from 380nm to 850nm, which is nearly one thousand times broader than the Radio Frequency (RF) spectrum. This is because Light Emitting Diodes (LEDs) can be deployed to modulate visible light for Visible Light Communication (VLC). Accordingly, lighting systems can be designed to combine information services using a network of LEDs integrated with sensors. This would constitute what the authors call the Internet of Lights (IoL). IoL, however, can have both positive and negative impact on human beings (as well as other animals), because of its eff ect on the circadian rhythms and hence body functions. On the positive side, it can be used as a non-intrusive intervention therapy to alleviate degenerative neurological diseases such as SeLecTeD Papers froM The ELeVenTh ITU KaLeiDoscope AcaDeMic Conference",IEEE Commun. Stand. Mag.,2020.0,10.1109/MCOMSTD.2020.9204601,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d90e2746a5a8e6a713aff7fcd8e2ab5fd64657f8,https://www.semanticscholar.org/paper/d90e2746a5a8e6a713aff7fcd8e2ab5fd64657f8,Introduction to the Minitrack on Design and Application of Body Sensor Systems in Healthcare,"Body sensor systems are becoming increasingly ubiquitous and have amazing potential to revolutionize healthcare delivery. Sensors come in a variety of form factors (e.g. wearable, ambient, ingestible or injectable) and can measure a plethora of physiologic and behavioral states in a near continuous fashion. Integrated into networks of sensors, these body sensor systems offer a mechanism to integrate technology into daily life. Perhaps most promising is the potential of such sensor systems to contextualize sensor data, to provide understanding of the milieu in which changes in health occur and to intervene in an automated, real time fashion to change behavior and promote health. Many challenges need to be overcome before body sensor systems can be widely adopted and highly effective. Designing sensors that are highly accurate while being non-obtrusive and aesthetically acceptable to users is a top priority for designers. Optimization of machine learning approaches, big data management, and privacy are other considerations that will influence success and uptake. In addition, the design process must involve the end users, maximize acceptability and intercalate with daily life. The ideal end product is a body sensor system that can track specific behaviors, but also create a new opportunity to deliver feedback, corrective interventions and other behavioral modifications in the setting of detection of specific parameters. Last year’s mini-track focused on the state of art of wearable sensor systems and generated recommendations regarding design of closed loop sensor systems and methods for evaluating sensor systems. This year’s mini-track builds upon last year’s work by discussing deployments of body sensor systems, interpretation of data generated from systems and the implications that body sensor systems have on understanding health, wellness and populations. This year, the mini-track has two exciting papers that describe practical and innovative approaches to body sensor system applications. In our first paper, the authors leverage off-the-shelf wearable devices and on-board smartphone sensors to contextualize the daily activity of adolescents and quantify opportunities to increase academic engagement during the daily activities of students. Our second paper discusses the use of contactless body sensors in the form of ultra-wide band radar to detect the presence of an individual in a room and measure respiratory rate noninvasively. The authors of both papers will describe novel applications of body sensor systems for unobtrusive detection of biometrics that may correlate with key features of daily life or health status. Importantly, these papers establish important preliminary data which can be used to develop automated interventions, whether the context of academic engagement or healthcare Following the paper presentations, we will open the forum for discussion on the material presented. We will use the challenges and successes from each paper to explore how this information can immediately inform research, commercial and clinical endeavors. We will also crowdsource ideas for a follow-up mini-track that will fill identified gaps and be highest yield for future HICSS participants. We anticipate that presentations and discussion will help attendees consider key design factors in their own work evaluating body sensors and generate new ideas for collaborations and applications in this space. Proceedings of the 53rd Hawaii International Conference on System Sciences | 2020",HICSS,2020.0,10.24251/hicss.2020.410,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e31589522b066d9096e67a2c21ef593039041795,https://www.semanticscholar.org/paper/e31589522b066d9096e67a2c21ef593039041795,A Battery Digital Twin framework for Predictive Maintenance and State of Health Estimation of Electric Vehicles,"To maximize the performance of Electric Vehicle (EV) battery, the requirements of the battery management system (BMS) are getting higher and higher, especially in terms of safety, predictive maintenance, and battery life. The on-board BMS cannot store or process large amounts of data during the operation of a vehicle, with poor real-time capability and data utilization rate. To effectively manage the battery, it is vital to build an Off-board digital twin that can mimic the actual battery with more intelligence. The paper proposes the digital twin framework of Li-Ion battery packs for a fleet of vehicles. This work presents the digital model of the battery, data driven models, contextual information, operational data and the cloud-based deployment. To extend the lifetime of the battery and bring more security into the system, an anomaly detection technique is proposed by using a machine intelligence approach that captures the temporal and spatial relationship between various battery parameters. Also, a learning-based prediction technique is proposed to estimate the health status of battery. The paper outlines the design methodology followed, challenges faced, drawbacks and further opportunities involved in developing the framework for creating a battery digital twin. The performance of the system is analysed with NASA prognostic data set and from the vehicle’s plant model with various drive cycles. Introduction A digital twin is a virtual representation of a physical asset. The digital twin technology helps the global industries to develop a digital DNA of their assets; ranging from as small as smartphone, to as large as a city and as complicated as a human, spanning across industries and processes. This cutting-edge technology helps the companies to optimize performance, maintenance and achieve better results. It came into prominence only upon the advent of other technologies like cloud, artificial intelligence, machine learning etc. VDI-Berichte Nr. 2384, 2021 579 https://doi.org/10.51202/9783181023846-579 Generiert durch IP '54.191.176.224', am 07.11.2021, 18:57:40. Das Erstellen und Weitergeben von Kopien dieses PDFs ist nicht zulässig. The electric vehicles (EV) are the future, and the automakers are investing more on to their EV sector nowadays. The key performance component of an EV is its battery. The electric battery is a merger of chemical, thermal, and mechanical processes. The lifetime of these devices depends greatly on the materials used, the system design and the operating conditions. This complexity has therefore made real-world control of battery systems challenging. Timely preparation for future eventualities is a cornerstone for managing batteries in an EV. The battery management system (BMS) of an EV receives considerable amount of data, and processing them is computationally intensive and requires more memory and processing power. Such processing would be difficult to be contained within the on-board systems, and all this data has to be computed elsewhere. With the advent of the Internet of Things and wireless communication in automotive, the information can be stored in the cloud, offering relentless computational power. However, sending the battery data separates it from the physical battery. The battery is still on-board, while the data is offboard. To effectively manage the battery, it is vital to build an off-board digital system that can resemble the actual battery with more intelligence. Due to aging, the parts of a vehicle are invariably at the risk. Not knowing the risk earlier can keep your car out of the road from sometime, the sooner the better. Electric vehicles reduced the output emissions, but the safety side of the batteries are certainly a costlier affair than the internal combustion engine, considering the multiple facets to include such as the chemicals used, the thermal state, mechanical parts, etc. The frequency and cost of regular maintenance service can be reduced if able to diagnose the issues in advance using digital techniques. Such a system identifies the risks and hinders it from becoming an issue, which not only reduces the downtime, but also the repair costs. If the system is able to warn early, component damage can be eliminated to an extent. The common type of batteries used in EV; the Lithium-ion cells are classified as class 9 hazardous materials. The safety risks involved due to thermal hazards alone from the battery perspective opens up a whole new world of risks; let alone the maintenance due to mechanical failure. Predicting a potential risk and subsequent drive to the mechanic ensures your vehicle in mint condition. Hence, this paper proposes the digital twin framework of Li-Ion battery packs for a fleet of vehicles for predictive maintenance. Our contributions in a nutshell:  Developed a digital twin framework of EV batteries for operating and diagnosing a fleet of vehicles VDI-Berichte Nr. 2384, 2021 580 https://doi.org/10.51202/9783181023846-579 Generiert durch IP '54.191.176.224', am 07.11.2021, 18:57:40. Das Erstellen und Weitergeben von Kopien dieses PDFs ist nicht zulässig.  Developed the State of health (SOH) prediction system of battery for the fleet of vehicles using battery digital twin  Developed an intelligent anomaly detection system to analyse the unusual nature of battery behaviour  Developed the digital twin framework and conducted performance evaluation using NASA dataset and data set generated using plant model. Related Works Even though the battery management system of EVs is well discussed in the literature, digital twin-based battery diagnosis is in the primitive stage only. Tanizawa et al. [6] propose a cloud-connected battery management system that continuously connects the batteries to the cloud, manages their state of charge and monitors changes in its characteristics. Koko Friansa et al. [2] proposes a battery monitoring system to monitor the operational and performance of batteries in a small microgrid system. Taesic Kim et al. [5] proposes a cloud-based battery condition monitoring and fault diagnosis platform for largescale lithium-ion battery energy storage systems. Weihan Li et al. [4] proposes a cloud battery management system with online state-of-charge and state-of-health estimates. Billy Wu et al. [1] discusses their perspectives on battery modelling, data-driven approaches and how these elements can be combined in a framework for creating a battery digital twin. Shichun Yang et al. [3] proposes a framework utilizing a cloud architecture for a cloud-based battery management system based on Cyber Hierarchy and Interactional Network (CHAIN) to leverage the use of algorithms that can be used to realize the state-of-X-estimation, thermal management, and other functions of traditional BMS system. The aforementioned works do not delve upon even the scantiest possibilities of irregularity in the battery data. They all assume that the data from the physical asset is in its pristine form. This paper focus on building a digital twin framework and an anomaly detection system by using a machine intelligence approach that captures the temporal and spatial relationship between various battery parameters. The paper also proposes to estimate the State of the health of the EV battery using Long Short-Term Memory (LSTM), a machine learning approach. Proposed Digital Twin Architecture The digital twin architecture of battery system consists of mainly two parts. First part is the physical system of Electric vehicle battery with real-world data and other is the twin of the system implemented on cloud infrastructure. The vehicle will be added to the digital twin VDI-Berichte Nr. 2384, 2021 581 https://doi.org/10.51202/9783181023846-579 Generiert durch IP '54.191.176.224', am 07.11.2021, 18:57:40. Das Erstellen und Weitergeben von Kopien dieses PDFs ist nicht zulässig. eco-system when the driver completes the initial registration process with vehicle information. Successful registration will create an instance of the digital twin in cloud, specific to the vehicle. This way, it is possible to manage multiple vehicles at the same time by creating instances of the digital twin.",ELIV 2021,2021.0,10.51202/9783181023846-579,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
db8ed4bae4bd2ee1209570be653701333e689f8e,https://www.semanticscholar.org/paper/db8ed4bae4bd2ee1209570be653701333e689f8e,Economic Impact Analysis of Hospital Readmission Rate and Service Quality Using Machine Learning,"The hospital readmission rate has been proposed as an important outcome indicator computable from routine statistics. The purpose of this research is to investigate the Economic Impact of service in hospitals and integrated delivery networks in the United States based on the readmission rates as the target variable. The data set includes information from 130 hospitals and integrated delivery networks in the United States from 1999 to 2008 to investigate significance of different factors in readmission rate. The dataset contains 101,766 patients’ encounters and 50 variables. The 30-day readmission rate is considered as an indicator of the quality of the health providers and is used as target variable in this project. Preliminary data analysis shows that age, admission type, discharge disposition etc. is correlated to the readmission rate and will be incorporated for further data analysis. Data analysis are performed on the diabetic patient dataset to develop a classification model to predict the likelihood for a discharged patient to be readmitted within 30 days. KNN, Naive Bayes and Logistic Regression algorithm were used to classify data and KNN appears to be the best approach to develop the model. Hospitalisations and drug prescriptions accounted for 50% and 20% of total readmission expenditure, respectively. Long term nursing home care after hospital admission cost an additional £46.4 million. With the ability to identify those patients who are more likely to be readmitted within 30 days, we can deploy the hospital resources more economically affordable while improving services. Based on the results it can be concluded that the direct cost of readmission rate for hospitals rose to £459 million in 2000 and nursing home costs rose to £111 million. Also, it can be perceived that a reduced length of hospital stay was associated with increased readmission rates for jaundice and dehydration.",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
61ea3c6e6d9935baa9f8a687bdb7246a9a34108c,https://www.semanticscholar.org/paper/61ea3c6e6d9935baa9f8a687bdb7246a9a34108c,Improving System Reliability for Cyber-Physical Systems Thesis proposal,"System reliability is a fundamental requirement of Cyber-Physical System, i.e., a system featuring a tight combination of, and coordination between, the systems computational and physical elements. Cyber-physical system includes systems ranging from the critical infrastructure such as power grid and transportation system to the health and biomedical devices. An unreliable system often leads to disruption of service, financial cost and even loss of human life. This thesis aims to improve system reliability for cyber-physical systems that meet following criteria: processing large amount of data; employing software as a system component; running online continuously; having operator-in-the-loop because of human judgment and accountability requirement for safety critical systems. The reason that I limit the system scope to this type of cyber-physical system is that this type of cyber-physical systems are important and becoming more prevalent. To improve system reliability for this type of cyber-physical systems, I propose a system evaluation approach named automated online evaluation. It works in parallel with the cyberphysical system to conduct automated evaluation at the multiple stages along the workflow of the system continuously and provide operator-in-the-loop feedback on reliability improvement. It is an approach whereby data from cyber-physical system is evaluated. For example, abnormal input and output data can be detected and flagged through data quality analysis. As a result, alerts can be sent to the operator-in-the-loop. The operator can then take actions and make changes to the system based on the alerts in order to achieve minimal system downtime and higher system reliability. To implement the proposed approach, I further propose a system architecture named ARIS (Autonomic Reliability Improvement System). One technique used by the approach is data quality analysis using computational intelligence that applies computational intelligence in evaluating data quality in some automated and efficient way to ensure data quality and make sure the running system to perform as expected reliably. The computational intelligence is enabled by machine learning, data mining, statistical and probabilistic analysis, and other intelligent techniques. In a cyber-physical system, the data collected from the system, e.g., software bug reports, system status logs and error reports, are stored in some databases. In my approach, these data are analyzed via data mining and other intelligent techniques so that useful information on system reliability including erroneous data and abnormal system state can be concluded. These reliability related information are directed to operators so that proper actions can be taken, sometimes proactively based on the predictive results, to ensure the proper and reliable execution of the system. Another technique used by the approach is self-tuning that automatically self-manages and self-configures the evaluation system to ensure it adapts itself based on the changes in the system and feedback from the operator. The self-tuning adapts the evaluation system to ensure its proper functioning, which leads to a more robust evaluation system and improved system reliability. For feasibility study of the proposed approach, I first present NOVA (Neutral Online Visualizationaided Autonomic) system, a data quality analysis system for improving system reliability for power grid cyber-physical system. I then present a feasibility study on effectiveness of some self-tuning techniques, including data classification, redundancy checking and trend detection. The self-tuning leads to an adaptive evaluation system that works better under system changes and operator feedback, which will lead to improved system reliability. The contribution of the work is an automated online evaluation approach that is able to improve system reliability for cyber-physical systems in the domain of interest as indicated above. It enables online reliability assurance of the deployed systems that are not possible to perform robust tests prior to actual deployment.",,2011.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5793116b8d0c9749afa91df50b10de5487880e0,https://www.semanticscholar.org/paper/a5793116b8d0c9749afa91df50b10de5487880e0,Spacecraft Informatics,"Spacecraft informatics is one of the most exciting and contemporary research topics in recent years. Many countries are deploying related technologies such as AI, robotics, machine learning, etc., in the deep-space explorations. Moreover, considering the high-complexity, high cost and high risk involved in spacecraft, advanced technologies in information modelling, simulation, optimisation and decision support methods are required to improve the effectiveness, efficiencies, reliabilities and safety of the space operations (Du et al. 2017; Rui et al. 2014). The emerging informatics approach offers the benefit to the area of spacecraft regarding in-orbit spacecraft, satellites, space-stations of any types in deep-space exploration missions from ground control, user payload, space weather and conditions, remote sensing and telemetry, and many more spaceflight missions and activities of designing, forecasting, planning and control. To contribute the present and future space exploration and spacecraft development, in this special issue, we have collected excellent papers of research in spacecraft informatics. Each paper underwent a double-blind peer review by independent, anonymous expert referees. After the reviewing processes, eight highquality papers were accepted and are published in this issue. The first paper is ‘Optimisation problems and resolution methods in satellite scheduling and spacecraft operation: a survey’ by Xhafa and Ip (2019). This paper aims to study the state of the art in the satellite scheduling regarding the spacecraft design, operation and satellite deployment system. With heuristics methods, the constraint features in satellite mission planning, including window accessibility and visibility requirements can be addressed for producing smalland low-cost satellites. The second paper, entitled ‘Moon image segmentation with a new mixture histogram model’ by Hsu et al. (2019) is related to an application of image processing technology in the spacecraft. This paper aims to develop a histogram mixture model with genetic algorithm for improving the effectiveness in segmenting the moon surface image. Instead of the manual parameters measurement, the parameters can be obtained by a genetic algorithm. The results show that the proposed algorithm improved the drawbacks of previous non-parametric methods for moon image segmentation. In the papers, entitled ‘Blockchain adoption for information sharing: risk decisionmaking in spacecraft supply chain’ by Zheng et al. (2019) and ‘A framework for rocket and satellite launch information management systems based on blockchain technology’ by Li, Wang, and Zhang (2019), they employed blockchain technology for information management and sharing in the spacecraft supply chain. The use of blockchain technology allows the stakeholders in the spacecraft to (i) reduce transaction cost and risks, and (ii) improve the reliability and traceability of the spacecraft information to enhance the overall effectiveness and efficiency of the supply chain. The paper ‘Health condition estimation of spacecraft key components using belief rule base’ by Tang et al. (2019) developed a semi-quantitative method to examine the ENTERPRISE INFORMATION SYSTEMS 2021, VOL. 15, NO. 8, 1019–1021 https://doi.org/10.1080/17517575.2021.1886331",Enterp. Inf. Syst.,2021.0,10.1080/17517575.2021.1886331,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9b277ae33c0b04a8cabb6c8fc5bc072afd275cbd,https://www.semanticscholar.org/paper/9b277ae33c0b04a8cabb6c8fc5bc072afd275cbd,COVID Choices: Research and Online System for Main Street Decision Making,"During the spring of 2020 ChoiceFlows Inc. (Choiceflows) researchers document an approach for small and medium-sized businesses to make informed decisions about equitable and resilient reopening after COVID-19 pandemic shutdowns and restrictions. The client is 501(c)(3) chartered Restart Partners in Washington State and their client, the State of Washington Department of Commerce. After several revisions, an agreement is signed on December 30, 2020 to make the approach real with development and deployment in 2021 using Cares Act Grant money from the U.S. Federal Government. The result is Smart WA – and can be freely accessed online here: https://smartwa.us Smart WA is the result of unique primary research conducted by Choiceflows involving citizens and residents of Washington State, and many days of secondary research finding publicly available data sources and bringing them together in one place to provide both comprehensive and easier to use data to make informed decisions. The research behind Smart WA is the first study to comprehensively examine how specific COVID-19 transmission reduction actions influence planned visits to different types of businesses. Data on Smart WA is organized by Human Health, Economic Health, and Community Experience metrics – and displayed as composite scores. The entire online system is powered by Tanjo.ai machine learning, a Choiceflows business partner, and is updated from all data sources daily.The advent of the COVID pandemic disrupts a wide range of businesses that directly serve the public and causes a dramatic fall in visits to these establishments. Businesses face a wide range of options in how to respond ranging from the pre-pandemic status quo and doing nothing to prevent the spread of the virus to shutting down businesses due to a lack of customers.Recognizing this, Smart WA has a “what-if” game-like section that allows a business to model the choices that they can make for reopening, and what they can expect from customers based on real data from people in the state. The relevant question from a small business perspective is: If we take an action or actions that influence COVID-19 transmission and make it known to our customers, how will that influence those customers to visit? The research supporting this function was conducted in four waves of surveys designed and administered during 2021, making it one of the most comprehensive research programs of its type during COVID with snapshots of customer preferences being collected over several month intervals.We document the development of this COVID Choices research using the Choiceflows pioneered Volumetric Choice Experiment (VCE) method and design and in parallel the online system. This provides a platform for projecting how the insights and methods from this work can be used for other issues facing small and medium size businesses to aid in and speed decision making and choice. This includes and dashboards for policymakers and main street for allocating resources for commerce, including economic development, ongoing community health, and supporting quality of life indicators.",Global Issues: Disease Control and Pandemic Prevention,2022.0,10.54941/ahfe1001361,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0ca2e97e9b09f0c5d723f8b9844eadb4a036af14,https://www.semanticscholar.org/paper/0ca2e97e9b09f0c5d723f8b9844eadb4a036af14,Life Cycle Assessment (LCA) of biogas and biomethan used in building energy systems,"the of a is disturbed. is by heavy valuable information that can be of assistance in reducing catastrophic losses. The objective of this study is to assess the vulnerability of different types of building structures to landslides. To accomplish the aim, it is first necessary to identify the multiple factors related to landslides, to evaluate the related contribution of the factors causing slope failures, to establish a relationship between the factors and the landslides. Secondly, based on the previously defined parameters and existing methodologies it is required to develop a general methodology for assessing the vulnerability of predefined types of building structures. and is clarify the the procedures and the model that will be used to design shot -earth reinforced structures. A second aim of this project is to control if and how the water uptake might influene the strength of the material. The project includes laboratory test on cement pastes and mortars with techniques such as isothermal calorimetry and rheolometer. This internship will be conducted in the framework of “HISTO-RENO” a European research project funded by the Interreg France-Switzerland fund. This project aims to develop a web-based simplified energy pre-audit tool to guide the building owner in their energy-related renovation. The goal of this internship is to derive statistical distributions on the input parameters (U-values, surface area of the main elements: external walls, roof, slab, windows, etc.) of the building heating demand of the current Swiss building stock with the help of the information of individual buildings in the Building energy certificate database (EPC), called “CECB” in Switzerland. The methodology of the analysis will be based on the previous work from Streicher et al 2018. The statistical analysis on the heating demand parameters will then serve to define probability density function (PDF) as input for a stochastic simplified energy audit tool used in a preliminary step of a renovation process indicating the estimates in kWh, carbon footprint and costs of a set of renovation measures. The Laboratory of Solar thermal Energy and Building Physics (LESBAT) from HEIG-VD has been funded by the Interreg France-Keywords: this topic, the minimum duration of this internship is 4 months (preferably 6 months). Proven knowledge in numerical and scientific programming tools like Python or R is required in order to successfully achieve the goals of this internship. analyse, 2) in the literature review of existing LCA of biogas and biomethan in order to get a range of carbon footprint for a unit of biogas/biomethan, 3) in the LCA of the heat and/or electricity produced with the technologies selected and 4) in the comparative LCA of heat production with other technologies (e.g. electric-based air-to-water heat pump) or electricity production in micro-CHP comparing biogas/biomethan solutions with electricity ones (using electricity from the grid). The data used for the carbon footprint of the Swiss electricity mix will be based on the ones available at HEIG-VD. in numerical and programming tools like duration 4 months, preferentially 6 months. Environmental alterations trigger changes in the underlying plant physiological processes portrayed by distinct variations of the electrical potential. Advanced signal processing and data analysis techniques enabled an automatic recognition of patterns in the electrical response of plants growing under typical production conditions allowing the identification of a plant's health status with high accuracy. However, current developments are based on classical machine learning algorithms requiring the extraction of features from the signal. The proposed project aims to extend the existing modeling approach by developing a classification framework that will extract features in an automated manner, such as applying deep-learning-based algorithms. system based on machine Commercial orchards are increasingly dependent on proper irrigation to ensure the highest yields and optimize production quality. Still, current monitoring tools need greater accuracy that could be achieved by incorporating indicators based directly on the plants. Moreover, tomatoes show difficulty adapting to the water and nutritional contributions provided by automatic systems in the greenhouses, resulting in physiological damage of the fruit, such as skin “cracking” leading to important yield losses. The main objective of the project is to model the growth of the fruits by using intelligent data analysis techniques on data from fruit dendrometer and micro-climate measurements in combination with the expertise of agronomists, to provide a tool for fruit growers that would help them predict physiological damage of the fruits and improve the quality of the crops, while optimizing harvest timing and reducing water usage. is spermatozoa morphology is one of the fundamental parameters for evaluating sperm quality. Evaluation of the morphology from microscopic sperm images could help reduce the required time and the observer-based variability of the manual analysis currently used as a clinical gold standard. Moreover, morphological abnormalities represent various forms and shapes on different cell parts, making classification a challenging task. This project aims to use image processing and machine learning algorithms on spermatozoa images to automatically distinguish abnormal from normal cells and classify different abnormal sperm morphology. to use advanced signal processing and machine learning algorithms on ECG signals to model patterns that identify and automatically discriminate different heart anomalies represented by the ECG curves. the of a kid's survival. to study, design, implement and evaluate a secure geolocation solution for mobiles. Today, geolocation on smartphones is mainly achieved through GNSS, Wi-Fi positioning, or BLE beacons. Still, none offer a strong guarantee as they can be unavailable or spoofable. After completing a state-of-the-art of existing technologies and their availability on mobile platforms, the trainee will propose a solution and realize a PoC. Several approaches are possible to realize this project; one possibility is the design of a BLE beacon integrating cryptographic features. Deep neural networks have shown to be very good at image classification and object recognition tasks. The objective of this project is to train a custom system to process and analyze satellite images (both from day and night). To achieve this, we will take advantage of pretrained models provided by the major actors in the domain and proceed to fine-tune them with our own data. Potential applications include, forest monitoring, population growth analyses, socio-economic issues, etc. For more information: http://iict-space.heig-vd.ch/ape The increasing availability of wearable sensors embedded in smartphones, watches and physical activity trackers has open the door to original applications, mainly in health and wellness improvement. One typically collects data by means of sensors like GPS, accelerometers, gyroscopes, barometers, microphones, cameras, depth sensors, etc. To make sense of these data, Machine learning algorithms can be used to establish correlations among the variables under investigation, and as in every attempt to understand high-dimensional data, visualization and dimensionality reduction techniques can suggest new knowledge about the aspects of the person's life being monitored. The objective of this project is to deal with diverse application domains including self-tracking of physical activity, self-tracking and characterization of style and performance in sport (e.g., racket sports, running), daily-life logging , or 24/7 self-monitoring as a means to enhace our wellbeing. more information: http://iict-space.heig-vd.ch/ape such robots more human-like with the aim of increasing our trust in them. For more For the conception phase, you’ll have to create wireframe of user interface. MEI can help with this phase. The development expected is a proof of concept for the fullstack. of law imposes new specialized hardware solutions to serve the increasing computing demand. System composed by several domain specific accelerators are available, but from the system integration and programming point of view they rely on custom solutions. The idea of this project is exploring the state of the art in compiler infrastructure for heterogeneous hardware and implement a prototype to measure real benefit and compromises of these solutions. Several research project have already been carried out in our laboratory on this subject. in we the and this will on extending its functionalities and benchmark it extensively. Data centres demand more and more computation efficiency. Standard CPU are unable to cope with the demand and GPU can only serve specific computation patterns. FPGAs are an attractive technology in this field, but its integration in the data centre infrastructure is not trivial. Smart Network interface (NICs) solutions are attractive for offloading many filtering and computation directly at the network attachment point relieving the CPU of many tasks. This project will explore the state of the art in the domain with the aim at developing a prototype capable to off-load tasks to an FPGA. management between edge and cloud. To maximize performance and minimize the energy consumption of both edge devices and cloud platforms, there is a need to develop efficient resource management techniques able to take workload allocation decisions, on when and where to execute the workload, in the edge to cloud continuum in an elastic way. To exploit elasticity, these techniques need to be aware of the underlying hardware and software stack, which often consist on a lightweight virtualization (like containers) deployed on ARM or RISC-V based edge devices. This project proposes the design of heuristic and meta-heuristic based workload m",,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7991b7b0317c0d29bc209f18acc18b5933ac71be,https://www.semanticscholar.org/paper/7991b7b0317c0d29bc209f18acc18b5933ac71be,"Part B 1 ] 1 ( to be evaluated in Step 1 ) Ubiquitous , spatiotemporal , multimodal action recognition Act Now","Action and activity recognition lie at the core of a panoply of scenarios in human machine interaction, ranging from gaming, mobile computing and video retrieval to health monitoring, surveillance, robotics and biometrics. The problem, however, is made really challenging by the inherent variability of motions carrying the same meaning, the unavoidable over-fitting due to limited training sets, and the presence of numerous nuisance factors such as locality, viewpoint, illumination, and occlusions that make real-world deployment extremely difficult. The most successful recent approaches, which mainly classify bags of local features, have reached their limits: only understanding the spatial and temporal structure of human activities can help us to successfully locate and recognise them in a robust and reliable way. We propose here to develop novel frameworks for the integration of spatiotemporal action structure in both generative and discriminative models, pushing for a breakthrough ripe with enormous exploitation potential. A new class of hierarchical part-based discriminative models originally developed for object recognition are reinvented for action localisation and recognition, as a fundamental way of coping with complex activities formed by series of simple actions and addressing the issues with locality and multiple actors. New manifold learning techniques for generative graphical models are developed to tackle the presence of nuisance factors and improve their generalisation power. Finally, novel classes of graphical models able to handle whole convex sets of probabilities are formulated in order to address the issue of overfitting due to the limited size of the training sets. As companies are heavily investing on virtual mice, smart TVs, phones and cars, and range sensors are changing clinical practice and the entertainment industry, the timeliness and potential impact of this project could not be understated.",,,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a5dffa86ee25138623b71f4d03a5ff5757fbdfdd,https://www.semanticscholar.org/paper/a5dffa86ee25138623b71f4d03a5ff5757fbdfdd,On National Projects,"Albania used the support from the Safe Online initiative to end violence against children online on multiple levels. To reach children, the agency trained children to become peer educators on online violence, increasing their knowledge on safe Internet navigation and helping them spread that information to their peers. UNICEF Albania conducted research on children’s use of the Internet and risk of online violence using the Global Kids Online methodology. The results from this study are being used to conduct national awareness activities. UNICEF Albania also worked at the national level by strengthening the national child helpline and hotline, which alert authorities about child sexual abuse material online. They also carried out an assessment of national legislation, policies and programmes currently targeting online child sexual exploitation and abuse in-line with the WePROTECT Global Alliance Model National Response. This will inform measures to improve the systematic response to online child sexual exploitation and abuse. UNICEF Albania also helped the government to develop a national strategy for cyber-security with a focus on children’s online safety. The agency also supported law enforcement authorities, strengthening their ability to investigate and prosecute cases of online child sexual abuse and exploitation. In addition, they worked with local municipalities and Internet service providers to promote “Albania Friendly Wi-Fi,” a safe certification standard for public Wi-Fi. These services will make Internet navigation safer for children, while also increasing national awareness on internet safety. They also used the support from the Safe Online initiative to engage the information, communications and technology sector on children’s Internet usage and risks in the digital space. to better detect, deter and prevent this type of violence. To do so, Justice and Care will explore the profiles of those who perpetrate and facilitate online sexual exploitation of children, interviewing convicted offenders, key informants, and others. This analysis will fill a gap in global research into online child exploitation of children and shed light on the “supply-side” of such violence in a country known to be an epicenter of live-streamed child sexual abuse. Ultimately, this research will seek to inform practical strategies and enhance industry, prevention and law enforcement response to the issue. The project also trained parents, teachers, social service providers and other adults to become advocates for cyber safety. At the industry level, the project also engaged Internet service providers and other technology companies in the fight against online child sexual exploitation and abuse. protect children from being victims of child sexual abuse. The chatbot will first be developed for pilot use in the United Kingdom with the potential for scaling up in other countries. The Safe Online initiative supported ChildFund Australia’s Swipe Safe program in Vietnam, which aimed to help young people navigate the Internet safely by educating them on potential risks, such as cyber scams, bullying or sexual abuse, and offering them strategies to protect themselves. ChildFund Australia designed, created and tested a training program to promote online safety – and ever since, the curriculum has been adapted by non-governmental organisations not just in Viet Nam, but in Laos and Myanmar as well. Swipe Safe mobilizes parents, youth, schools and the private sector to play an active role in children’s online safety. The program provided training for parents and Internet café owners and managers to identify and address risks that might happen to children, from online to offline and vice versa. It also supported schools to develop child-friendly policies and guidance on online safety. Swipe Safe is active in advocating to the national government with lessons learned to inform national policy and response and linking such legislation with the strengthening of existing structures. A key innovation of the program is that it engaged young volunteers in local communities with extensive knowledge on technology to train young people and others, as these trainers can more directly relate to their peers’ experiences and help keep the curriculum up to date. Disrupting Harm is a large-scale data collection and research project to better understand online child sexual exploitation and abuse across the world. This study is assessing the scale, nature and context of this issue in 14 countries across Southern and Eastern Africa and Southeast Asia. Supported by the Safe Online initiative, three grantee partners will work together to conduct the study, including ECPAT International, INTERPOL and the UNICEF Office of Research – Innocenti. ECPAT's role is to conduct a comprehensive analysis, allowing partners (and all others working in this arena) to better understanding the context of children's safety online. A new version of Disrupting Harm is currently bringing design, and it is expected to bring the large-scale research project to other regions. NTERPOL will bring the most advanced technology to investigators of online CSEA through its new DevOps Group Project. The initiative will facilitate research and development by an expert group of investigators, non-governmental organisations, academia, and information technology companies, and extend solutions to specialised officers worldwide via INTERPOL’s secure channels. Headquartered in France, this project has a global reach. Disrupting Harm is a large-scale data collection and research project to better understand online child sexual exploitation and abuse across the world. This study is assessing the scale, nature and context of this issue in 14 countries across Southern and Eastern Africa and Southeast Asia. Supported by the Safe Online initiative, three grantee partners will work together to conduct the study, including ECPAT International, INTERPOL and the UNICEF Office of Research – Innocenti. INTERPOL's role is to examine the threats facing children online and analyse data from law enforcement agencies across the world. A new version of Disrupting Harm is being designed and is expected to bring the research project to other regions. with INHOPE and other specific will explore and quantify the issues facing content moderators, as it relates to their exposure of traumatic child sexual abuse material. They will also identify coping strategies currently used by content moderators, and highlight what works – and what does not work – for individuals and organisations that do this work. Results of this study will be used to develop a pilot intervention to support and protect the mental health of content moderators. Lapsia Ry will develop and launch ReDirection, an evidence-based self-help programme working to prevent the consumption of CSAM on the Dark Web. By providing targeted support for these individuals, the project will also reveal new information about these searchers and their pathways to CSAM access and use. This programme builds on the Finnish government’s accredited New Direction rehabilitation programme for sex offenders. Headquartered in Finland, this project has a global reach. Through this project, Technological University Dublin will develop a deployable tool that reveals the patterns of adults perpetrating online child sexual abuse and the children who are affected by such violence. By using advanced artificial intelligence machine learning for text, the study will advance global understanding of trends in perpetrator behaviour (conduct, contact, content) – including grooming – and debunk strategies and tactics used to lure and coerce children into sexually exploitative acts. N-Light will be created in collaboration with two essential partner organisations, the Irish Society for the Prevention of Cruelty to Children (ISPCC) and Hotline.ie, the Irish national centre combatting illegal content online, specifically child sexual abuse material (CSAM) and activities relating to online child sexual exploitation (OCSE). Once finalized, N-Light will be tested by both partner organisations, with the intention to make it available to other hotlines in the INHOPE network and child agencies for their use, which would in turn lead to an enriched, more robust and representative data sample and analysis capacity. In addition, the data and insights will serve to better understand and conceptualise victim and perpetrator behavior, patterns and activity, ultimately informing the further development of evidence-based solutions that would have the potential of transformative impact in tackling this heinous crime against children. on the psychological processes through which people of online sexual and professional support. In addition, the group will explore the efficacy and impact of prevention interventions targeting people engaging with online abuse. Overall, the project will ask a fundamental – and often overlooked – question: who seeks help for child sexual exploitation and abuse, and can we get more people to do so before committing a crime? This project will expand the group’s existing model of psychological predicators of help-seeking for people at risk of offending and examine how to amplify the psychological factors that support such help-seeking behaviors. At the same time, the project will also look into the psychological barriers that prevent help-seeking and explore ways to weaken those barriers in the sphere. The World Health Organisation is using Safe Online investments to explore current systems of prevention and response to online child sexual exploitation and abuse. These findings will support governments and civil society organisations, giving them the tools and evidence, they need to implement effective, evidence-based programs to keep children safe online. After determining what works and does not work around preventing and responding to sexual and emotional online child abuse, the proj",,2003.0,10.6027/9789289335157-8-en,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2f470cfddc970e8d134aacfa42600f0c399eed48,https://www.semanticscholar.org/paper/2f470cfddc970e8d134aacfa42600f0c399eed48,Evaluating Intrusion Detection Systems for Energy Diversion Attacks,"The widespread deployment of smart meters and ICT technologies is enabling continuous collection of high resolution data about consumption behavior and health of grid infrastructure. This has also spurred innovations in technological solutions using analytics/machine learning methods that aim to improve efficiency of grid operations, implement targeted demand management programs, and reduce distribution losses. One one hand, the technological innovations can potentially lead large-scale adoption of analytics driven tools for predictive maintenance and anomaly detection systems in electricity industry. On the other hand, private profit-maximizing firms (distribution utilities) need accurate assessment of the value of these tools to justify investment in collection and processing of significant amount of data and buy/implement analytics tools that exploit this data to provide actionable information (e.g. prediction of component failures, alerts regarding fraudulent customer behavior, etc.) In this thesis, the focus on the value assessment of intrusion/fraud detection systems, and study the tradeoff faced by distribution utilities in terms of gain from fraud investigations (and deterrence of fraudulent customer) versus cost of investigation and false alarms triggered due to probabilistic nature of IDS. Our main contribution is a Bayesian inspection game framework, which models the interactions between a profit-maximizing distribution utility and a population of strategic customers. In our framework, a fraction of customers are fraudulent they consume same average quantity of electricity but report less by strategically manipulating their consumption data. We consider two sources of information incompleteness: first, the distribution utility does not know the identity of fraudulent customers but only knows the fraction of these consumers, and second, the distribution utility does not know the actual theft level but only knows its distribution. We first consider situation in which only the first source of information incompleteness is present, i.e., the distribution utility has complete information about the actual theft level. We present two simultaneous game models, which have same assumption 3 about customer preferences and fraud, but differ in the way in which the distribution utility operates the IDS. In the first model, the distribution utility probabilistically chooses to use IDS with a default (fixed) configuration. In the second model, the distribution utility can configure/tune the IDS to achieve an optimal operating point (i.e. combination of detection probability and false alarm rate). Throughout, we assume that the theft level is greater than cost of attack. Our results show that for, the game with default IDS configuration, the distribution utility does not use the IDS in equilibrium if the fraction of fraudulent customers is less than a critical fraction. Also the distribution utility realizes a positive “value of IDS” only if one or both have the following conditions hold: (a) the ratio of detection probability and false alarm probability is greater than a critical ratio, (b) the fraction of fraudulent customers is greater than the critical fraction. For the tunable IDS game, we show that the distribution utility always uses an optimal configuration with non-zero false alarm probability. Furthermore, the distribution utility does not tune the false alarm probability when the fraction of fraudulent customers is greater than a critical fraction. In contrast to the game with fixed IDS, in the game of tunable IDS, the distribution utility realizes a positive value from IDS, and the value increases in fraction of fraudulent customers. Next, we consider the situation in which both sources of information incompleteness are present. Specifically, we present a sequential game in which the distribution utility first chooses the optimal configuration of the IDS based on its knowledge of theft level distribution (Stage 1), and then optimally uses the configured IDS in a simultaneous interaction with the customers (Stage 2). This sequential game naturally enables estimation of the “value of information” about theft level, which represents the additional monetary benefit the distribution utility can obtain if the exact value of average theft level is available in choosing optimal IDS configuration in Stage 1. Our results suggest that the optimal configuration under lack of full information on theft level lies between the optimal configurations corresponding to the high and low theft levels. Interestingly enough, our analysis also suggests that for certain technical (yet realistic) conditions on the ROC curve that characterizes achievable detection probability and false alarm probability configurations, the value of information about certain combination of theft levels can attain negligibly small values. Thesis Supervisor: Saurabh Amin Title: Robert N. Noyce Career Development Assistant Professor",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d083058260c54c9fc3371585a75fc8d7514f9dc2,https://www.semanticscholar.org/paper/d083058260c54c9fc3371585a75fc8d7514f9dc2,Digitizing DILI: Who can? RUCAM? RECAM?,"The age of machine learning (ML) and artificial intelligence (AI) is poised to dramatically alter the practice of medicine in many disciplines, including the field of liver disease. How the radiologist diagnoses hepatic tumors and how the pathologist interprets liver histology are among the areas in which the digital revolution is being incorporated in gastroenterology and hepatology. However, as others have opined, several challenges in the technology involved in deploying these various ML/AI applications remain to be overcome.[1,2] Attempts to computerize the diagnosis of druginduced liver injury (DILI) have been on the minds of hepatologists for years but have thus far remained elusive. In this issue of Hepatology, Hayashi and colleagues,[3] all of whom have longstanding expertise in the causality assessment of DILI, present their evidencebased, computerized modification of the Roussel Uclaf Causality Assessment Methodology (RUCAM), which they have renamed Revised Electronic Causality Assessment Method (RECAM), for diagnosing DILI. Their attempt to bring causality assessment into the digital age is a welcome addition to our diagnostic armamentarium. But although their offering has several advantages over the current version of RUCAM, as the authors themselves recognize, as with other attempts to enter the computerized age of medicine, it remains a work in progress. Given the hundreds of drugs, herbal products, and chemicals that can cause liver injury and mimic every possible form of acute, chronic, benign, and malignant liver disease, the ability to make a firm diagnosis of DILI has remained clinically challenging in the absence of a definitive diagnostic biomarker. Many health care professionals, especially nonhepatologists, rely heavily on consultation with an individual with expertise in the field of drug hepatotoxicity. But despite more than three decades of research searching for a validated and specific biomarker, DILI remains a diagnosis of exclusion.[4] Efforts to devise semiobjective algorithmic approaches to analyze the important elements needed to suspect possible DILI— i.e., a compatible time to onset (latency), time to recovery after the drug has been stopped (positive dechallenge), and the ability to adequately exclude alternative causes— have given rise to a number of causality assessment methodologies over the last several decades. The algorithm that has emerged as the most specific and widely used to diagnose DILI was the result of a consensus meeting of a small group of invited hepatologists with expertise in DILI held in Paris, France, hosted by Drs. Benichou and Danan, and sponsored by Roussel Uclaf Pharmaceuticals under the auspices of the Council for International Organizations of Medical Science in the late 1980s and early 1990s. Their efforts to objectify the diagnostic elements of DILI resulted in what has come to be known as the Roussel Uclaf Causality Assessment Method or RUCAM.[5] Although a RUCAM assessment involves a relatively straightforward approach, each of its seven criteria requires a certain degree of expertise in interpreting the data. Indeed, its interrater reliability has been found to be low.[6] Importantly, although the initial RUCAM was validated by a positive rechallenge response,[7] readministering a drug that may have produced an initial severe hepatotoxic reaction is generally no longer recommended or performed because the response to rechallenge could result in an even more serious reaction— including acute liver failure.[4] Given the limitations and difficulties in scoring based on its relative subjectivity,[6,8] RUCAM was sparsely used in the United States as compared with Europe and other countries during its first two decades. It did not go unnoticed that none of the invited experts at the original RUCAM conferences allowed themselves to be coauthors of the seminal manuscripts, including Drs. Hyman Zimmerman and Willis Maddrey, who felt that the original RUCAM was “not yet ready for prime time.”[9] Although many of the individual components that comprise RUCAM remain the fundamental criteria for suspecting and diagnosing DILI, attributing causality using a RUCAM score alone is still considered an imperfect methodology.[8,10,11] Most notably, although members of the US DILI Network perform their causality assessment using many of the RUCAM criteria, their final assessment relies heavily on an expert opinion process that allows these investigators to overcome many of the shortcomings inherent in RUCAM.[6] In 2015, Danan and Teschke offered a revised and updated version of RUCAM that attempted to address a number of areas of uncertainly (such as whether alcohol, pregnancy, or age >55 years should be used to increase the RUCAM score).[12] However, despite RUCAM being increasingly Received: 3 January 2022 | Accepted: 3 January 2022",Hepatology,2022.0,10.1002/hep.32312,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
93c8039993af1efd9d1f320575755084555bf7ab,https://www.semanticscholar.org/paper/93c8039993af1efd9d1f320575755084555bf7ab,Security and privacy solutions in edge envisioned connected things environment,"The evolution of the Internet of Things and thereafter Internet of Systems and now the latest entry, Internet of Skills has transformed the traditional technological backdrop into a data-driven periphery of connected things. The connected things (devices, sensors, machines, actuators, and so on) deployed in the smart cities generate a large amount of data that is transmitted to geo-located sites for further processing or storage. For instance, a huge amount of content is generated via social networking platforms which create an array of a connected society. Even more, the smart meters deployed at each household generate multi-thousand fold data at regular intervals of time which is processed at a central control center. This data is analyzed using sophisticated machine learning algorithms or big data technologies to identify the hidden correlations, patterns, and associations which in turn improves decision making in the smart ecosystems (comprising Industry 4.0, Health 4.0, Intelligent Transportation, and many more). The data generated from these connected things is transmitted at a high data rate and thereafter processed at remote cloud data centers. For the past some time, cloud data centers have completely driven the market of providing big data solutions. But, nowadays, the need for processing data closer to the location of the user has shifted the processing domain closer to the data sets or end-user, that is, at the edge of the network using edge computing technology. This transition has reshaped the data-driven connected ecosystem to Edge Envisioned Connected Things Environment. In traditional systems, a long delay is incurred when an edge device sends the data to the network and thereafter to a data center for processing at the cloud. However, in an edge envisioned environment, the data generated by connected things is sent to the local gateway, that is, edge nodes rather than transmitting it to the cloud for further processing and analysis. In this way, processing the data closer to the physical world from where the data itself originates can provide manifold benefits like ultra-low latency, higher bandwidth, and quick response time. Edge is nothing but a local compute which provides faster data analytics and also reduces the network traffic. In Edge Envisioned Connected Things Environment, most of the devices use web-based management interfaces where a user can install the updates, accomplish routine tasks, and adjust settings. Although theoretically, it is suggested to have unique and strong passwords practically, on average, the end-users employ weak passwords which are quite easy to crack by the attackers. This means that most of the edge-enabled things are protected with poor passwords that can make them easy targets for attackers to access their confidential data or use them as a potential botnet. The devices connected in such an environment are considered to be innocuous and often the data they collect and transmit is not encrypted or authenticated. Although the data from such devices seem harmless it can still be of value for a potential attacker. In another case, allowing an attacker to access your device without any authentication can be harmful as security is acknowledged at a lower priority in the Internet of Things environment and so. Even more, deploying such devices at locations with minimal oversights and assigning them key roles in organizations without taking proposer security precautions can lead to security implications. The connected devices are designed to send potentially sensitive data to the outside world or the locations outside the organization’s management. For this purpose, they often use mobile-friendly interfaces (due to the popularity of mobile computing), but most such devices have no security enforcement. However, these services need continuous identification of associated risk and security which requires proactive efforts by users and corporate security services. This includes the network log analysis to identify anomalous traffic patterns that are generated by anonymous devices within the organization’s network periphery, and thereafter the design and development of alternative security measures or plans for such unidentified devices or things are essential. An attacker can hack thermostats, cameras, baby monitors, smart meters, temperature controllers, and even assault rifles and thereafter create a panic situation or a security nightmare. As there are so many new nodes or things which are connected to the network and Internet as an open channel will also provide malicious and unanticipated actors who can acknowledge the connected environment with diverse attack vectors and possibly try to create an insecure environment or pour out sensitive data (which can be a patient’s health data). Some investigations suggested that everyday devices like, closed-circuit cameras, smart home equipment were hijacked and controlled by the attackers using malware and used against the servers of popular services providers. As we expect that such connected devices would be envisioned in",Trans. Emerg. Telecommun. Technol.,2020.0,10.1002/ett.4208,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
19e7f3366780503a5bed385d042ffdda61463c50,https://www.semanticscholar.org/paper/19e7f3366780503a5bed385d042ffdda61463c50,Adaptive health monitoring using aggregated energy readings from smart meters,"Worldwide, the number of people living with self-limiting conditions, such as Dementia, Parkinson’s disease and depression, is increasing. The resulting strain on healthcare resources means that providing 24-hour monitoring for patients is a challenge. As this problem escalates, caring for an ageing population will become more demanding over the next decade, and the need for new, innovative and cost effective home monitoring technologies are now urgently required. The research presented in this thesis directly proposes an alternative and cost effective method for supporting independent living that offers enhancements for Early Intervention Practices (EIP). In the UK, a national roll out of smart meters is underway. Energy suppliers will install and configure over 50 million smart meters by 2020. The UK is not alone in this effort. In other countries such as Italy and the USA, large scale deployment of smart meters is in progress. These devices enable detailed around-the-clock monitoring of energy usage. Specifically, each smart meter records accurately the electrical load for a given property at 10 second intervals, 24 hours a day. This granular data captures detailed habits and routines through user interactions with electrical devices. The research presented in this thesis exploits this infrastructure by using a novel approach that addresses the limitations associated with current Ambient Assistive Living technologies. By applying a novel load disaggregation technique and leveraging both machine learning and cloud computing infrastructure, a comprehensive, nonintrusive and personalised solution is achieved. This is accomplished by correlating the detection of individual electrical appliances and correlating them with an individual’s Activities of Daily Living. By utilising a random decision forest, the system is able to detect the use of 5 appliance types from an aggregated load environment with an accuracy of 96%. By presenting the results as vectors to a second classifier both normal and abnormal patient behaviour is detected with an accuracy of 92.64% and a mean squared error rate of 0.0736 using a random decision forest. The approach presented in this thesis is validated through a comprehensive patient trial, which demonstrates that the detection of both normal and abnormal patient behaviour is possible.",,2017.0,10.24377/LJMU.T.00007543,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
14ee9bf682e4200b30dde734726fa9de027fcac3,https://www.semanticscholar.org/paper/14ee9bf682e4200b30dde734726fa9de027fcac3,Predicting Just in Time: Prognostic Health Management for Oilfield Equipment.,"
 Delays in the hydraulic fracturing stimulation process due to equipment issues may result in Non-Productive Time (NPT) and often associated with high costs. Both operators and service companies are interested in implementing a system to predict these events in advance so that they can proactively react and prevent failures before they occur. Our objective was to develop, implement, and demonstrate the capabilities of such a system.
 Based on historical data, we identified the most NPT-prone subcomponents of stimulation equipment. We combined failure reports and maintenance records with sensors data to train Machine Learning (ML) models. The final solution was deployed on the cloud to predict remaining useful time (RUL) in real-time and to start specific notifications sending whenever RUL dropped below the preset value.
 We analyzed 20,000+ failure records and identified the most NPT-prone equipment, subcomponents, failure modes, and root causes. We found out that root causes are very scattered. We evaluated the applicability of physics-based and data analytics approaches for Top-10 root causes by NPT duration and NPT count. When NPT count per root cause is low (<10), the trained ML models had insufficient accuracy. In this case, only subject matter experts and understanding of physics behind performance deterioration allowed us to boost data-driven models’ accuracy. We started with testing on historical data. Then we continued testing on real-time data without field intervention. This stage was required to check and to build trust in the predictive ability of the models. After initial testing, we eliminated some of the models and switched to monitoring with field interventions. For six months of operating, the model helped to decrease the NPT related to the selected subcomponent by 20 times.
 This work presents the process of enabling Intelligent Diagnostics for hydraulic fracturing equipment by implementing failure identification and prediction models. It combines both domain knowledge (failure modes of the equipment, sensors data) and recent advances in ML (time series analysis, data processing, and feature engineering). The developed system to be further extended to different equipment, as the workflow described in the present study is not specific to particular equipment.",,2020.0,10.2118/202957-ms,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
392ab2bf4e1ad37d55a55cdfffbd59d49c58940d,https://www.semanticscholar.org/paper/392ab2bf4e1ad37d55a55cdfffbd59d49c58940d,Assessing and managing Parkinson's disease from home: A 21st century vision closer to reality,"The application of technology to Parkinson’s disease (PD) holds a considerable potential to monitor disease features in clinical care and research, guide management, and as a therapeutic tool. In spite of this, digital health technology solutions have failed so far to fundamentally change how patients report their symptoms, physicians collect clinical information about their patients between clinical visits, or how we document the efficacy of novel experimental interventions in clinical trials. Zhan and colleagues provide an example of how such promises of a digital technology revolution may shape the near future. The Mobile Parkinson Disease Score (mPDS) is a summary measure of the severity of PD motor features generated solely by a smartphone-based application used remotely by patients. The use of a smartphone confers to the mPDS the unique ability to provide a rapid, remote, frequent, and objective assessment, which could inform care decisions, and allow for more patients with PD to take part in clinical trials, by reducing (though not expected to eliminate) the burden of in-person visits in a trial. To develop the mPDS, the researchers started by establishing its item structure from a pool of 435 unique features extracted from five tasks done on a smartphone in a development cohort of 129 PD patients. The final 15-item version of the mPDS was tested clinimetrically in a small group of PD patients (n = 23). The mPDS had a good-to-excellent correlation with well-validated clinical rating scales in PD (total MDS-UPDRS and corresponding part III, H & Y scale) and was sensitive to change in onversus off-dopaminergic medication conditions. This article provides a critical proof-of-concept study for the validation and deployment of a digital motor scale in PD, in contrast with other recent studies that explored isolated motor features using similar smartphone-based testing. The researchers adopted novel data analyses methods involving machine-learning that challenge the language and methods most clinical researchers know. Once a distant reality, these approaches are no longer science fiction and call for a novel set of skills by the clinical researcher for an appropriate critical appraisal and use. Providing a more home-based assessment is an intuitive example of how the use of technology can revolutionize PD care in the 21st century. Although accessibility is well addressed with the use of widely available smartphones some PD patients may not be tech savvy and may feel challenged by the small dimensions of a smartphone. Also, the study sample was not representative of a broad PD population, which raises concerns about the usability and compliance of the mPDS. These features need to be adequately assessed, given that these will likely determine its successful uptake. Co-design approaches that incorporate patient and care partners views from inception to full development of a health technology solution may be beneficial in the preparation of a future larger study for a more comprehensive validation of this promising digital measure in PD.",Movement disorders : official journal of the Movement Disorder Society,2018.0,10.1002/mds.112,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
09a4ab6a61eaa69d1ce496a4f291d565329fc8d5,https://www.semanticscholar.org/paper/09a4ab6a61eaa69d1ce496a4f291d565329fc8d5,eResearch Collaboration Projects-supporting CSIRO's digital science and research,"Background CSIRO is Australia’s largest research agency and is a recognised leader in a diverse set of
science domains: Agricultural Sciences, Environment/Ecology, Plant and Animal Sciences,
Geosciences, Chemistry and Materials Science. CSIRO also manages research infrastructure
like the Australia Telescope National Facility (ATNF), the Marine Research Vessel RV
Investigator and the Pawsey Supercomputing Centre. For many years in Australia, and also worldwide [2], research and science have undergone
transformational changes with the introduction of new instruments and advanced facilities
with matching increases in storage and computing capabilities. Individual researchers were
taking a bespoke approach to matching these technologies and capabilities to the way that
research and science were carried out. Wider adoption of new practices required social
change (in the practice of science and research) and these changes remained fragmented
and tailored to specific sciences or even projects. Organisations, by and large, varied
enormously in their support of these new practices.As far back as 2007 [1], CSIRO eResearch practitioners advocated that science and research
practices within CSIRO adapt to deal with these challenges. Much like the rest of the world,
practices matured over the years: in CSIRO’s health and biosecurity, oceanographic and
atmospheric research, radio astronomy, agriculture and food as well as geological and
other earth sciences. However, a significant shift occured in 2018, with a formal recognition by the CSIRO Board
of the need to support the new “digital” science and research at an organisational level.
CSIRO developed strategic digital transformation initiatives, including CSIRO’s Managed
Data Ecosystem (MDE), Missions and the Digital Academy [4].The aim of the MDE is to connect current and new platforms in a seamless way and improve
interoperability between datasets so users will be able to easily find and work on multiple
datasets. It will provide a set of tools and approaches enabling CSIRO and partners to
improve our collaboration, mining and analysis of data. CSIRO Missions are major scientific and collaborative research programs aimed at making
significant breakthroughs in one of six major challenges facing Australia. They include the
resilient and valuable environments, food security and quality, health and well-being, future
industries, sustainable energy and resources, and regional security. CSIRO's Digital Academy is focused on investing in the digital capability of our staff and
involves a rethink in planning for a digitally driven research environment. It provides a
learning opportunity for our staff, helping define the digital talent, skills and new ways of
working. The Academy will help attract and retain new digital talent within the Australian
innovation system, develop new digital skills and mindsets in Australian’s scientists and
facilitate digital talent accessibility and collaboration across Australia’s innovation system.Existing Support for “Digital” Science through “eResearch” initiativesCSIRO Scientific Computing Services group has been providing a dedicated eResearch service
since 2011 [3] This service is delivered through ""eResearch Collaboration Projects” (eRCPs)
which now delivers specialist capabilities that includes Machine Learning, Data Analytics,
Scientific Visualisation, Workflow Management and Science Data Handling into research and
science projects. The eRCP process is run as a competitive grant process and continues to be very successful. In the latest cycle, forty Scientific Computing Services specialists successfully completed and
delivered over sixty eRCPs outcomes from a total of eighty submissions. The underlying
capabilities are delivered by members from each of teams in the Scientific Computing
Services group: Technical Solutions; Data Analytics and Visualisation; Research Software
Engineering; and Modelling and Dataflow. The eRCP process also provides a mechanism to
promote and introduce new tools and frameworks for consumption to CSIRO’s research
community eg Jupyter and R/Shiny. In the latest cycle, forty Scientific Computing Services specialists successfully completed and
delivered over sixty eRCPs outcomes from a total of eighty submissions. The underlying
capabilities are delivered by members from each of teams in the Scientific Computing
Services group: Technical Solutions; Data Analytics and Visualisation; Research Software
Engineering; and Modelling and Dataflow. The eRCP process also provides a mechanism to
promote and introduce new tools and frameworks for consumption to CSIRO’s research
community eg Jupyter and R/Shiny. Specialists from the Scientific Computing program are then assigned to work on one or more
approved eRCPs. Over the six-month cycle, the resource allocation is around 0.2 FTE, with
each staff member allocated 3 eRCP projects per cycle. Importantly, eRCPs are provided to
CSIRO researchers and scientists at no additional charge.The eRCP has been enormously successful over the years, with demand outstripping
capability to allocate staff to the projects. The program has demonstrated a range of useful
outcomes including – including for example - an augmented reality tool for analysing
bushfire plumes over Tasmania; a dashboard to interrogate cotton crop physiological
measurements and an online platform to monitor algal blooms for multiple water bodies.Scientific Computing specialists also provide dedicated support to CSIRO researchers, based
around the same set of core capabilities, via an entirely separate funding models known as
“pan deployments” as well as secondments. In both cases, CSIRO projects fund the specialists’
time at larger allocations, often extending over 12 months or more. In a sense, this acts like a
contractor service for Business Units, providing them with highly specialised skills but without
the need to recruit new staff of their own.Future PlansCSIRO Scientific Computing will respond to the major initiatives – MDE, Digital Academy and
Missions as follows:MDE - Redirect Scientific Computing expertise currently working on eRCPs and pan
deployments to MDE related activities. In the first instance, these specialists
will apply their skills and domain knowledge to one of several nominated
pilots, helping design and build foundational components of the MDE. - Over time, it is anticipated that those same specialists will contribute to the
ongoing development and enhancement of additional MDE components in
line with its progressive organisational rollout. Digital Academy - Develop/adapt training content as appropriate for the Digital Academy. For
example, making use of existing Software Carpentry material for HPC usage,
but customising appropriate aspects for our own computing environment.- Delivering training content to CSIRO staff. This has already proven very
successful in the machine learning area – with hundreds of staff attending
sessions - and will no doubt continue to grow over time.Missions - Scientific Computing will continue to provide CSIRO researchers with the
eResearch support they need in response to the significant scientific
challenges tackling Missions. REFERENCES 1. J. A. Taylor, J. Zic, and J. Morrissey, “Building CSIRO e-Research Capabilities,” in eResearch Australasia 2008.2. T. Hey, S. Tansley, and K. Tolle, “The Fourth Paradigm: Data-Intensive Scientific
Discovery,” Data-Intensive Sci. Discov. Microsoft Res., 2009.3. S. Moskwa, “The Accelerated Computing Initiative,” in eResearch Australasia, 2012.4. CSIRO Chief Executive's Report 2018-19: https://www.csiro.au/en/About/Ourimpact/Reporting-our-impact/Annual-reports/18-19-annual-report/part-1/chiefexecutive-reportABOUT THE AUTHOR(S) Dr John Zic is the Executive Manager of CSIRO’s Science Computing Services Mr Justin Baker is Leader of the Scientific Computing Data Analytics and Visualisation
Team.",,2020.0,10.6084/M9.FIGSHARE.11929647.V1,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8003f27c8965688c6c2499759e0350ab6f3c608,https://www.semanticscholar.org/paper/c8003f27c8965688c6c2499759e0350ab6f3c608,Ambient Assisted Living for the Motor Impaired,"The field of Ambient Assisted Living (AAL) has shown great potential in counteracting some of the effects of the worldwide population ageing phenomenon. Its main goal is to promote a safe, healthy, and functional living environment for the elderly and people with disabilities who wish to live independently in their home. To achieve this goal, AAL environments utilize Information and Communication Technologies (ICTs) and the emerging Ambient Intelligence (AmI) paradigm in order to provide sophisticated solutions that can support the needs of an elderly person or a person with disabilities, at home. This chapter will present examples of AAL environments found in research and academic literature and the solutions they offer to cater for the basic needs of motor-impaired people in order to support their independent living and quality of life. The challenges of using such technologies will also be discussed. INTRODUCTION The World Health Organization (WHO) World Report on Disability (World Health Organization, 2011), states that approximately one billion people worldwide experience a disabling condition. This is the first ever global estimate of persons with disabilities in the last 40 years. The term “disabled” according to WHO is used for people who are experiencing a limitation in their movement, activities, and senses due to a physical or mental condition. The report also states that almost everyone will be temporarily or permanently impaired at some point in his or her life, especially when at old age. At the same time, people with disabilities are more susceptible to poorer health outcomes and lower education achievements, which often lead to higher rates of poverty than people without disabilities. Disabled people are in need of rehabilitation services in order to maximize their functioning required to support independence. But in developing countries such access to rehabilitation services is often limited and in some cases nonexistent altogether. Even in high-income countries about 20%40% of people with disabilities have limited assistance for their everyday activities. In the US, for example, 70% of adults have to rely on family and friends for assistance with daily activities. The number of people experiencing motor impairments and other disabilities is only expected to rise in the near future, as the world population continues to age at an unprecedented rate. According to the United Nations World Population Ageing report (United Nations, 2000), worldwide population ageing is enduring and has a growing rate of 2.6%per year, considerably faster than the population as a whole, which is increasing at 1.2 % annually. Europe is currently holding the highest proportion of older persons, with a population of 60 or over currently constituting 24.5% of its total population. In the United States that number is 19.1% respectively. From the above, it can be argued that the increase of the ageing population will have major implications for all aspects of people’s everyday life particularly of socio-economic nature. The number of people that will need some form of institutionalized help is going to increase, adding on the burden of the existing health care systems. Governments around the world have taken serious notice of this reality and of the need to come up with strategies to adapt their social practices and processes in order to accommodate this dynamic population shift in the population. The need to find ways to make it easier for people with age and other related disabilities to live a longer, satisfying and independent life in their own homes is now more imperative than ever. Ambient Assisted Living (AAL) is a domain that has attracted a steadily growing attention in the scientific community because it involves emerging innovative technological solutions that can counteract some of the challenges described above. The main focus in AAL is on supporting persons with disabilities in their own environment and providing the means to increase the degree of independent living. Its aim is to provide integral solutions in the areas of home care, independent living, and institutionalized care homes that will improve the quality of life and lower the costs involved with health, home care and related social services. In order to achieve the above, AAL depends heavily on Information and Communication Technologies (ICTs) and the emerging Ambient Intelligence paradigm. This chapter provides an overview of how Ambient Assisted Living technologies can play a catalytic role in improving the living environment for people with motor impairments by providing solutions that can increase their level of independence. The chapter begins with an overview of the fields of Ambient Intelligence and Ambient Assisted Living, followed by a brief presentation of the latest research initiatives in Europe. It then discusses how AAL can provide solutions for the fulfillment of the four identified requirements for independent living: mobility, environment control, safety, health and emergency assistance, and social inclusion. Finally, the major challenges of AAL are discussed followed by the conclusion. AMBIENT ASSISTED LIVING (AAL) OVERVIEW AAL refers to the use of Information and Communication Technologies (ICT) in a person's living environment in an unobtrusive way enabling them to continue living a comfortable, independent, active life and staying socially connected well into old age. AAL’s main goal is to provide the technological platform to support individuals in living an autonomous life for as long as possible. The roots of AAL are in traditional Assistive Technologies for people with disabilities, ‘Design for All’ approaches to usability and accessibility, as well as in the emerging computing paradigm of Ambient Intelligence (Pieper, Antona, Cortes, 2011). Ambient Intelligence (AmI) is a term that refers to the vision of a world in which smart, intuitively operated devices support users in an unobtrusive way in their everyday life. AmI has enabled the introduction of ubiquitous information, computational, and communication technology in a seamless yet unobtrusive way creating smart everyday living environments (Encarnação & Kriste, 2005). In such smart environments, intelligent applications and devices become aware of the human goals and needs by operating collectively and sharing information and intelligence through a hidden network that connects them in a way that is natural and intuitive to the user (Aarts & Encarnação, 2008). AmI infrastructures have gained a great momentum in today’s world in many industries such as home automation, entertainment, automotive, and healthcare to name a few. The technologies involved have the capacity to transform everyday common objects from CD players to coffee machines into smart objects that support context awareness, personalization, anticipatory behavior, and adaptation, all of which enable a certain degree of autonomous decision-making. Lighting, sound, vision, home appliances, and other electronic devices, all come into play in an AmI environment and share the same purpose, to improve user experience by facilitating the user’s interaction with it (Aarts & Kriste, 2005). Aarts and Encarnação (2008) stated that the notion intelligence reflects that the digital surroundings in a smart environment exhibit certain forms of social interaction, in other words they are able to recognize the occupants, adapt themselves to their needs, learn from their behavior, and possibly act on their behalf. Based on the described notion of intelligence they have synthesized the following list of the most important features of Ambient Intelligence: • Integration through large-scale embedding electronics into the environment • Context-awareness through user, location, and situation identification – the system uses sensors to perceive a situation, the location where that situation is taking place, and the user involved • Personalization through interface and service adjustment – the system can change its behavior according to the needs of the user • Adaptation through learning the user’s behaviors • Anticipatory behavior through reasoning – the system acts on behalf of the user making decisions based on predictions and expectations about future actions AAL with the help of the Ambient Intelligence (AmI) paradigm and new ICT technologies can now provide smart sophisticated solutions that offer the potential to change dramatically the quality of life for a disabled person, often making the difference from living with personal assistance on a daily basis to living an autonomous life. One of AAL’s focal concerns is also to offer user-friendly interfaces that are adaptable to the needs and abilities of the user and user-centric methods of interaction for the individual with his or her immediate environment (Pieper et al, 2011). AAL RESEARCH INITIATIVES IN EUROPE In the recent years, policy initiatives have been launched in Europe on the field of Ambient Assisted Living (AAL) in order to create a favorable ground towards research, development, and deployment of ICT technologies with focus on addressing the challenges, but also the opportunities of ageing. The “Ageing Well in the Information Society” Action Plan was adopted in June 2007 by the European Commission with the goal to bring forward a package of measures that should lead to greater uptake of ICTs by Europe’s senior citizens and stimulate industry to produce technologies appropriate for them (Stephanidis, 2011). For that purpose, the European Commission launched a dedicated action in the 7 Framework Programme and partial funding of the Ambient Assisted Living Joint Research and Innovation Programme, involving most EU Member States (Stephanidis, 2011). By 2013, the EU and Member States, and the private sector will have invested more than €1 billion in research and innovation for ageing well: some €600m in the Ambient Assisted Living Joint Programme (AAL JP), and an ",,2013.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e2133bd7f0798719bec09dd9126e8af79d60fc4f,https://www.semanticscholar.org/paper/e2133bd7f0798719bec09dd9126e8af79d60fc4f,Improving Health and Quality of Life in One-Person Households Using IoT and Machine Learning,"Worldwide, there has been an increase in the number of individuals that live alone in one-person households (OPHs). Compared to those living with family, people in OPHs easily lose control of life rhythm. Given that the disturbance of life rhythm leads to chronic disease, they have a higher risk of illness. As such, there is an urgent demand for assistive technology that allows people in OPHs to enjoy healthy, high-quality lives. For decades, there has been significant research and development of smart systems to assist people at home. However, there are still limitations on the practical use of these systems in actual OPHs. More specifically, they are often too intrusive to the lifestyle of users or home objects. In addition, they are often expensive to deploy and maintain. Furthermore, these systems are unable to evaluate the quality of life rhythm. As a result, it is difficult for individual users to determine what their healthy life rhythms should be, and how to improve their current situation.The goal of research is to develop a new smart system for OPHs that can minimize intrusiveness and cost, while also facilitating the assessment of life rhythms of individual users. The new system collects user position and environmental data inside the house in a non-intrusive way, using affordable IoT devices. From this data, the system then recognizes the daily activities of the user. Based on these activities, eventually, the system can quantitatively evaluate the users life rhythms and provide practical advice for maintaining a healthy life.",BCD,2019.0,10.1109/sera.2019.8886791,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e46d58866eb02a30bb129e8d4284856822a1cc2a,https://www.semanticscholar.org/paper/e46d58866eb02a30bb129e8d4284856822a1cc2a,Towards Understanding the Role of Gender in Deploying Social Media-Based Mental Health Surveillance Models,"Spurred by advances in machine learning and natural language processing, developing social media-based mental health surveillance models has received substantial recent attention. For these models to be maximally useful, it is necessary to understand how they perform on various subgroups, especially those defined in terms of protected characteristics. In this paper we study the relationship between user demographics – focusing on gender – and depression. Considering a population of Reddit users with known genders and depression statuses, we analyze the degree to which depression predictions are subject to biases along gender lines using domain-informed classifiers. We then study our models’ parameters to gain qualitative insight into the differences in posting behavior across genders.",CLPSYCH,2021.0,10.18653/V1/2021.CLPSYCH-1.23,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7df654a6f14f39cc3bfc12bda487a226ace529a9,https://www.semanticscholar.org/paper/7df654a6f14f39cc3bfc12bda487a226ace529a9,REAL-TIME MULTIVARIATE MULTI-TIME-SCALE ANOMALY DETECTION SYSTEM FOR NEXT GENERATION NETWORKS,"Techniques are described herein for a real-time multi-variate, multi-scale, contextaware anomaly detection system. This system is built using concepts of edge/cloud distributed processing and orchestration. DETAILED DESCRIPTION By 2021 networks are forecast to grow by a factor of 75% (61,000 connected network devices) and corresponding incidents per hour will reach the order of 10,000 quotas. Information Technology (IT) providers have responded by delivering to the market a new generation of network devices which will extract more information about the health and status of each network device and export such telemetry at a higher frequency rate (evolving to a real-time push model to deliver network telemetry). While this will grant IT providers with fresher and richer data, next generation anomaly detection systems are called to address many technical challenges: how to effectively process massive amounts of data; how to analyze such data in streaming; how to design anomaly detection systems that can operate across many metrics of observation and multiple time-scales; how to introduce learning and intelligence into those next generation systems such that they can become smarter the longer they are used and exposed to domain-experts; etc. Today, a typical enterprise comprises an average of 35,000 connected network devices which are managed by processing, on average, 750 Gigabytes of diagnostic data per day (e.g., syslogs, command line interface (CLI) data, configuration files, etc.). Usually such data is pulled by the IT provider after the occurrence of a network problem or customer escalation and used to precisely troubleshoot the issue, identify the root cause, and hence deploy a successful remediation. This process requires a long cycle (requires an 2 Nucci et al.: REAL-TIME MULTI-VARIATE MULTI-TIME-SCALE ANOMALY DETECTION SYSTEM Published by Technical Disclosure Commons, 2018 2 5707 average of five hours per incident), is executed by the IT provider on a very regular and frequent basis (enterprises reported in 2017 an average of 400 incidents per hour), and is very prone to human error (e.g., IT domain experts play a critical role in the overall troubleshooting process). While IT is already struggling today, next generation networks will make it even worse. Next-generation anomaly detection systems are called to continuously ingest 70+ Terabytes of telemetry every hour (assuming a forecasted 61,000 router enterprise, with a network device generating an average of 20 Megabytes per minute). Clearly the delivery of such voluminous amounts of data to enterprise Data Centers (DCs) (or even worse, private/public clouds for analysis) will result in a high level of network congestion, prolonged analytical workflow completion times, and long remediation cycles. Next generation anomaly detection systems should adopt a distributed data processing model, meaning that some data processing should be executed as close as possible to the source of the data while other processing may still be executed in the enterprise DC or clouds. The correct distribution of processing workloads guarantees lighter data volumes to be exported to the DC and the cloud (no network congestion), shorter completion times for advanced machine learning analytics workloads (model training may use smaller amounts of data as input) and hence shorter remediation cycles (faster troubleshooting translates into faster deployment of fixes). Next-generation network devices may generate very rich telemetry, which allows IT providers to properly monitor the correct behavior of network devices from many vantage points. For example, certain devices may export telemetry which includes details about the memory and Central Processing Unit (CPU) utilization of each device, comprising logical nodes, counters of packets traversing each device interface, rich statistics about power consumption and usage of its logical and physical components, etc. As a result, anomaly detection systems are called to generate more holistic profiles of network devices or the network-as-a-whole by modeling many distinct collected metrics together. More specifically, they need to profile every metric in isolation (like memory utilization on every logical node of the device) while discovering and modeling possible hidden and stealthy correlations across the distinct metrics (like memory utilization across logical nodes of the device). 3 Defensive Publications Series, Art. 1579 [2018] https://www.tdcommons.org/dpubs_series/1579 3 5707 Many problems affecting a network device do not manifest themselves with major deviations of a single metric but rather appear as smaller, hard-to-see deviations spread across many distinct metrics with strong temporal synchronicity. This is similar for entire networks. Consider as an example the most devastating Distributed Denial of Services (DDoS) attacks which target a network element causing resource exhaustion and starvation. The network element being targeted is attacked using many machines which send similar Internet Protocol (IP) packets (same size, same Transmission Control Protocol (TCP) flags set, etc.) with strong time synchronicity to starve resources at the victim endpoint. The packets are spread across many logical paths in the network which cross many interfaces of the many routers traversed toward their destination. Profiling a single metric such as a packet counter on a single interface of a single router would not trigger any alert. Conversely, correlating the same (or similar) IP packets across all router interfaces and across all routers along the logical path in the network would signify the active presence of the attack. Algorithms that generate behavioral models which take into account more than one time-series metric are called multi-variate. Furthermore, because the drifting from the normal behavior state happens at different frequencies (and hence at different timescales such as minutes, hours, days, or weeks), it is imperative for anomaly detection systems to model and profile the behavior of each network device at different time-scales, from a micro-time-scale of minutes to a macro-time-scale of weeks. This property is called multi-timescale behavioral profiling. It is imperative for IT providers to access detailed telemetry during the troubleshooting phase (which starts upon the generation of an alert). Today, this is achieved by exporting all collected telemetry to a central data storage infrastructure (e.g., a data lake) which makes the data accessible to the IT provider via standard Application Programming Interfaces (APIs). But with networks streaming over 80 Terabytes of telemetry every hour, this solution is clearly not feasible any longer. Hence, there remains the question of what can be done to provide the IT provider with the information needed to troubleshoot an alert while avoiding network congestion. Although unsupervised anomaly detection systems are appealing for any IT organization for being less labor intensive than supervised systems, they are based on the assumption that any pattern that deviates from the learned normal patterns should be 4 Nucci et al.: REAL-TIME MULTI-VARIATE MULTI-TIME-SCALE ANOMALY DETECTION SYSTEM Published by Technical Disclosure Commons, 2018 4 5707 considered an anomaly. However, this assumption may not hold true because it is very difficult or impossible to define a normal event which takes all possible normal patterns/behaviors into account. More importantly, the boundary between normal and anomalous behaviors is often ambiguous, as in the case of an enterprise planned maintenance cycle. In addition, under realistic conditions, the same behavior could be a normal or an anomalous behavior under different conditions. As alerts are investigated by domain experts it is important for the anomaly detection system to assimilate the domainexpert knowledge to improve the learning process. The system described herein (also referred to as “SQUID”) distributes the data processing between the network itself and DC/cloud. The system embeds some data processing functionality directly into the network infrastructure itself (referred to as edge processing) to execute light processing functions such as collection, parsing, anomaly detection classifier at the device level, etc. The edge processing leverages dedicated compute resources available in the next generation network devices; for example, devices that dedicate up to four virtual CPUs (vCPUs) and 400 Gigabytes of Solid Disk Drive (SDD) for pure computing. The system also deploys some data processing functionality in the DC and/or cloud environments, (referred to as a cloud/DC processing environment) to execute more compute and memory intensive data processing. Examples of data intensive processing include the training of the machine and deep learning models. Furthermore, the cloud/DC processing environment may also correlate group alerts generated by each processing engine to uncover network-wide incidents which may affect more than one network device. Examples include DDoS attacks (wherein large numbers of machines generate an attack with strong time synchronicity toward a target endpoint), validation of correctness maintenance cycles (multiple devices may be power-cycled at approximately the same time), blast radius (multiple neighboring devices logically connected at approximately the same time), etc. The system connects the ecosystem of edge processing environments and the central processing environment via a secure bi-directional connectivity which is used to regularly distribute the learned / refreshed machine / deep learning models from the central to the edge processing environments. The system described herein departs from more established single-variate anomaly detection systems, Exponential Weighted Moving Average (EWMA), Holt-Winters, etc., 5 Defensive Publications Series, Art. 1579 [2018] https://www.tdcommons.org/dpubs_series/1579 ",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
45118e07026d6fe3c534c9f1c3d5765a98e242fd,https://www.semanticscholar.org/paper/45118e07026d6fe3c534c9f1c3d5765a98e242fd,From the President,"The process used to prefer certain products across drug classes for diabetes is generally focused on comparative effectiveness and cost. However, payers rarely tie patient preference for treatment attributes to formulary management, resulting in a misalignment of value as defined by providers, payers, and patients. Our study explores patient preferences and willingness to pay for treatment attributes of predetermined high-value and low-value medications within a health plan, in order to redefine value to incorporate patient preferences. A cross-sectional discrete choice experiment (DCE) questionnaire study design determined patient preferences for the benefit, risk, and cost attributes of type 2 diabetes treatments. A comprehensive literature review of patient preference studies in diabetes identified studied attributes, and a review of guidelines and medical literature identified clinical attributes. Patients and diabetes experts were interviewed and instructed to identify, prioritize, and comment on which attributes of diabetes medications were most important to them. From these interviews, a total of 7 attributes were selected for the dissemination for a DCE survey: 1) hemoglobin A1C reduction, 2) cardiovascular (CV) risk reduction, 3) heart failure (HF) risk reduction, 4) out-of-pocket cost, 5) route of administration, 6) dosing flexibility, and 7) gastrointestinal (GI) side effects. From the 58 health plan beneficiaries who responded to the DCE survey, patients preferred to be treated versus foregoing care. Attribute preferences such as cost, HF risk reduction, CV risk reduction, and GI side effects were found to be statistically significant. These survey results were used to calculate the willingness-to-pay thresholds to demonstrate which diabetic medications are preferred most by patients. These findings will then be compared with how the health plan ranks medications in order to compare where patients’ and health plans’ definitions of value are aligned and where differences arise. By aligning patient and stakeholder preferences, our study has the potential to yield improved patient outcomes and increase cost-savings to patients, beneficiaries, and health plans. The objective of this study is to obtain a quantitative measure of the value of fear of contagion in COVID-19 care. A discrete choice experiment (DCE) will be conducted. A list of important attributes of COVID-19 medical options – including the possibility of disease exposure and cost – will be obtained from literature, clinical experts, and adults from the general public. The attributes will be used to generate DCE choice sets, which are included in a self-administered, web-based survey. A total of 500 adults with and without COVID-19 infection will be asked to respond to the survey. Statistical analysis based on Random Utility Theory will be used to determine the relative importance between all study attributes and cost. The willingness-to-pay for reducing the possibility of disease exposure will be calculated. Study findings will be applied for value assessments when dealing with not only COVID-19 care but also care for other infectious diseases. defined trial cohorts for generation of value evidence limit the generalizability applicability of the results to broader populations that may be treated in real-world practice. This study will provide important insights into the risk profile of a real-world population well as how it might differ from the risk profile of the clinical trial population, using the case study of the Diabetes Prevention Program (DPP) for individuals with prediabetes. The first-place team conducted an analysis of COVID-19 vaccine preferences among underrepresented populations. Using latent class analysis, the team built a model identifying key factors underlying the disparities in COVID-19 vaccination. They found that health care interventions intended to reduce health disparities that do not reflect the underlying values of individuals in underrepresented populations are unlikely to be successful. a two-pronged to increase the diversity of populations that participate in research and address drivers of health disparities to better inform value assessment. The first part of this strategy consisted of a comprehensive national campaign to inform, create buy-in, and generate excitement for participation in research. Following this, the researchers proposed an expediting of current methodological initiatives to require a minimum set of patient-reported social determinants of health elements to be collected and reported in research, including clinical trials and observational studies, as a way to enhance the information used in value assessment frameworks. Understanding predictors of the low accrual in older adult-specific clinical trials and demonstrating the value of such trials, when successful, can help overcome the underrepresentation of older adults in trials. Aim 1 of this study is to identify trial-level predictors for low accrual in older adult-specific trials. Using AACT data, I will develop prediction models for low accrual based on traditional and machine-learning approaches. Aim 2 of the study is to quantify the realized value of older adult-specific trials, the AVEX and CALGB9343 study. A retrospective analysis of Surveillance, Epidemiology, and End Results (SEER)-Medicare data will be used to estimate the change in practice after the trial publications. State transition models will be developed to estimate the long-term outcomes of treatment studied in the trials. The realized value will be calculated based on these two estimates. By assessing the feasibility and estimating the potential value of older adult-specific trials, this study will facilitate investment and design decisions by funders. therapeutic inertia. using real-world data to the evidence base for glycemic control and therapeutic inertia in people with type 2 diabetes. The public health significance of the is to optimize patients’ diabetes care and management across their lifetimes and mitigate the occurrence of subsequent diabetes-related complications. This study aims to 1) identify trajectories of medication adherence of chronic diseases treated with oral medications, and 2) distinguish the predisposing, enabling, need, and provider/care characteristics factors that determine trajectory membership using group-based trajectory modelling. Additionally, this study will investigate the association between adherence trajectories and economic and health outcomes. This association will be investigated by deploying two alternative predictive methods, one based on classic logistic regression and the other based on machine-learning algorithms. It is hoped that the findings of this study will elicit longitudinal medication adherence trajectories, the factors that determine trajectory membership, as well as establish optimal medication adherence trajectories based on the association with outcomes. Lastly, the conclusions of this study will allow health care professionals to identify patients at risk and payers to develop new value-based payments schemes based on medication adherence. Despite an increasing trend of neoadjuvant chemotherapy (NAC) use in breast cancer, evidence on benefits/risks of NAC — specifically in older women and within cancer subtypes – is limited, possibly contributing to the sizable variation in NAC use. This project aims to examine the effect of NAC versus adjuvant chemotherapy (AdC) alone on survival, health care utilization, and costs, in addition to assessing the temporal trends of NAC use and identifying factors related to NAC use among older women. The project will use the population-based Surveillance, Epidemiology, and End Results (SEER)-Medicare linked database to identify stage I-III breast-cancer patients. Subtype heterogeneity will be incorporated throughout, and propensity score matching is proposed to reduce bias. The research is expected to provide otherwise unavailable evidence on NAC in a large elderly population, which will inform patient-physician decision-making and ultimately improve clinical and economic outcomes. care of high-value is a major problem for older adults. Cognitive impairment (CI), including both mild cognitive impairment (MCI) and Alzheimer’s disease and related dementias (ADRD), is prevalent for older adults and likely affects HV and LV utilization. Patient harm and unnecessary costs of LV replacing HV care could be especially high and widespread in this vulnerable subpopulation, but these relationships have not been studied. The Centers (CMS) has called for value promotion, but policies cannot be adequately targeted and implemented without understanding the aforementioned relationships. Therefore, we propose to close this gap by identifying the association between CI and utilization of LV and HV care. Results will depict trajectories of utilization of relevant services for individuals at different stages of CI and inform policies to improve patient welfare and promote healthy aging. generic medications for infusion therapies, such as those used in oncology or neurology, and have great potential to lower prices and increase access to otherwise expensive treatments. The first aim of our research is to explore and examine key factors associated with coverage decisions regarding biosimilars that have been approved by the U.S. Food and Drug Administration (FDA) and have become available on the U.S. market, drawing on unique data provided by the Tufts Cost-Effectiveness Analysis Registry and the Specialty Drug Evidence and Coverage Database. Our second aim is to study the social welfare gain from biosimilar entry in the U.S. health care system. By using the SSR Health US Brand Rx Net Pricing data, we will estimate the additional number of patients receiving access to therapy following biosimilar entry, thus enabling us to quantify the extensive margin. We will use data on average net (post-rebate) pric",ASDC journal of dentistry for children,2013.0,10.1177/000313131306300202,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
28943e4f8380fc989b2fd6067c9b366f4cdd48cc,https://www.semanticscholar.org/paper/28943e4f8380fc989b2fd6067c9b366f4cdd48cc,Key Aggregation Cryptosystem and Double Encryption Method for Cloud-Based Intelligent Machine Learning Techniques-Based Health Monitoring Systems,"Cloud technology is a business strategy that aims to provide the necessary material to customers depending on their needs. Individuals and cloud businesses alike have embraced the cloud storage service, which has become the most widely used service. The industries outsource their data to cloud storage space to relieve themselves of the load of dealing with redundant data contents. This must be protected to prevent the theft of personal belongings, and privacy must be improved as well. Different research projects have been suggested to ensure the safe management of the information included within the data content. The security of current research projects, on the contrary, still needs improvement. As a result, this method has been suggested to address the security concerns associated with cloud computing. The primary goal of this study effort is to offer a safe environment for cloud users while also increasing the profit of cloud resource providers by managing and securely delivering data contents to the cloud users. The bulk of sectors, including business, finance, military, and healthcare industry, do not store data in cloud-based storage systems. This technique is used to attract these kinds of customers. Increasing public acceptance, medical researchers are drawn to cloud computing because it allows them to store their study material in a centralized location and distribute and access it in a more flexible manner. They were collected from numerous individuals who were being evaluated for medical care at the time. Scalable and enhanced key aggregate cryptosystem is a protected data protection method that provides highly effective security in the healthcare industry. When parties interested in a dispute disagree on the outflow of sensitive information, this technique manages the disputes and ensures the data security deployment of a cloud-based intelligent health monitoring system for the parties involved. The encrypted data structure of medical and healthcare prescriptions is recorded as they move through the hands of patients and healthcare facilities, according to the technique recommended. The double encryption approach is used in order to raise the overall degree of security. An encryption class is created by referring to the Ciphertext ID during the encryption procedure. The keyholder is a master secret key that facilitates in the recovery of the secret keys of various monsters and creatures by acting as a conduit between them. It is transferred and stored as a single aggregate for the benefit of the patient or customer in order to make decryption more convenient and efficient. A safe connection between cloud-based intelligent health monitoring systems and healthcare organizations and their patients may be established via the use of a key aggregation cryptosystem and a double encryption approach, according to the researchers. Because of this, when compared to earlier techniques, the findings reveal that the research methodology provides high levels of security in terms of confidentiality and integrity, in addition to excellent scalability.",Computational intelligence and neuroscience,2022.0,10.1155/2022/3767912,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
af3b3032f2d41afa6d8a75c9958a119ed38197dc,https://www.semanticscholar.org/paper/af3b3032f2d41afa6d8a75c9958a119ed38197dc,"Regulatory Compliance? Elementary: With Overwhelming Data and Complex Regulatory Requirements, Banks Are Turning to Advanced Cognitive Computing to Help Their Compliance Teams","Jeopardy! viewers in 2011 witnessed a first in game show history: a computer not only competed in the show, but wiped the floor with its opponents. Watson, a cognitive computer system, left Ken Jennings and Brad Rutter--previously Jeopardy!'s top champions--in its dust over a three-round matchup. IBM built Watson specifically to compete in a trivia show, but the potential applications proved highly commercial. Watson is programmed to understand human language questions; comb through massive amounts of data; and provide intelligible, quick and correct answers. Unlike humans, Watson remembers everything. With every question and answer, Watson gets a little bit smarter. Through machine learning--by which computers gain capabilities without being explicitly programmed for them--Watson can become a technical expert in a variety of fields. In 2013, for example, Watson was deployed for lung cancer treatment decisions at Memorial Sloan-Kettering Cancer Center in New York City, incorporating symptoms and crunching data to recommend treatment approaches with specified levels of confidence. Crucially, Watson did not supplant doctors' decision-making. Instead, Watson became like a very knowledgeable colleague in the exam room, providing insights and making connections the health care providers might not have recognized otherwise. Last year, IBM acquired Promontory Financial Group, a D.C.-based consulting firm led by former regulators and industry veterans, to bring Watson's expertise to bear on financial regulatory compliance challenges. Promontory founder Gene Ludwig, a former comptroller of the currency, was excited by the opportunity to bring Promontory's in-house expertise to banks of all sizes in addition to the larger institutions that often hire the firm. ""For community and regional banks, the promise is that over time they will have access to our thoughts in an efficient and effective manner, and for the largest institutions, they have a new colleague called Watson,"" he says. Promontory is in the process of teaching Watson about regulations and guidance, increasing Watson's ability to understand the compliance questions bankers will ask it. 'Augmented intelligence' Banks using Watson can use its capability to help their compliance teams connect regulatory requirements to obligations to controls, then manage those controls through an interactive dashboard. For example, a compliance officer might review a document for relevant obligations. Instead of remembering or manually looking up each relevant regulation, Watson can scan the document and highlight specific areas where regulation or guidance is likely to apply. The banker can then review those recommendations and, much more quickly than before, incorporate them into the compliance program. ""It's augmented intelligence, not artificial intelligence,"" says Alistair Rennie, general manager for Watson Financial Services. ""The more we can look at in context, the better we can get answers to be, and the more we can work through expert guided discussions about what the right answer, decision or choice is, the better everything gets. …",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
57657ead9fed182a0bd85ef3f425225e1f35aefb,https://www.semanticscholar.org/paper/57657ead9fed182a0bd85ef3f425225e1f35aefb,Discovering Data-Driven Actionable Intelligence for Clinical Decision Support,"Author(s): Ibrahim, Ahmed Mohamed Alaa | Advisor(s): van der Schaar, Mihaela | Abstract: The rapid digitization of healthcare has led to a proliferation of clinical data, manifesting through electronic health records, biorepositories, and disease registries. This dissertation addresses the question of how machine learning (ML) techniques can capitalize on these data resources to assist clinicians in predicting, preventing and treating illness. To this end, we develop a set of MLbased, data-driven models of patient outcomes that we envision to be embedded within systems of decision support deployed at different stages of patient care.We focus on two broad setups for analyzing clinical data: (1) the cross-sectional setup wherein data is collected by observing many patients at a particular point of time, and (2) the longitudinal setup in which repeated observations of the same patient are collected over time. In both setups, we develop models that are: (a) capable of answering counter-factual questions, i.e., can predict outcomes under alternative treatment scenarios, (b) interpretable in the sense that clinicians can understand how the model predictions for individual patients are issued, and (c) automated in the sense that they adaptively tune their modeling choices for the dataset at hand, with little or no need for expert intervention. Models satisfying these three requirements would enable the realization of actionable, transparent and automated decision support systems that operate symbiotically within existing clinical workflows.Our technical contributions are multi-faceted. In the cross-sectional data setup, we develop ML models that fulfill the aforementioned requirements (a)-(c) as follows. We start by developing a comprehensive theoretical framework for causal inference, whereby we quantify the limits to how well ML models can recover the causal effects of counter-factual treatment decisions on individual patients using observational (retrospective) data, and we build ML models — based on Gaussian processes — that achieve these limits. Next, we develop a novel symbolic meta-modeling approach for interpreting the predictions of any ML-based prognostic model by converting the “black-box” model into an understandable symbolic equation that relates patients’ features to their predicted outcomes. Finally, we develop a model selection approach based on Bayesian optimization that enables the automation of predictive and causal modeling. In the longitudinal data setup, we develop a novel deep probabilistic model for sequential clinical data that satisfies requirements (a)- (c) by capitalizing on the strengths of both state-space models and deep recurrent neural networks.To demonstrate the utility of our models, we evaluate their performance on various real-world datasets for cohorts of breast cancer, cardiovascular disease and cystic fibrosis patients. We show that, compared to existing clinical scorers, our ML-based models can improve the accuracy of predicting individual-level prognoses, guide treatment decisions for individual patients, and provide insights into underlying disease mechanisms.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0a382216eaa782e1832447c73594d98a0f1782d1,https://www.semanticscholar.org/paper/0a382216eaa782e1832447c73594d98a0f1782d1,The journal of knowledge engineering special issue on WorldCist'19—Seventh World Conference on Information Systems and Technologies,"The constant growth of technology leads to the development of expert systems that serve to support critical decision-making and have applications in many areas, such as healthcare, business, chemistry, financial decision-making, and engineering. These systems are computer programs derived from a computer science research branch called Artificial Intelligence (AI) and use human knowledge intensively in problem-solving. These programs combine expert knowledge and use the knowledge necessary to solve problems (Kidd, 2012). In this special issue, we present a range of papers covering some of the subareas of expert systems such as intelligent and decision support systems, ethics, computers, and security, health informatics, simulations, and big-data analytics. This special issue comprises six research papers. All manuscripts are extended versions of selected papers from WorldCIST'19 - 7th World Conference on Information Systems and Technologies, held in at La Toja Island, Galicia, Spain, April 2019. The WorldCIST conference have become a global forum for researchers and practitioners to present and discuss the most recent innovations, trends, results, experiences, and con-cerns in the several perspectives of Information Systems and Technologies, as well as computer science in general. The six selected papers in this special section include a Virtual Programming Lab (VPL), a model's predictions, a novel information systems architecture for the agri-food sector, various approaches for detection of malware, an intelligent system to assess, in real-time, potential HRV indices, that can predict HRQoL in lymphoma patients throughout chemotherapy treatment, as well as an expert system comprising a self-aware framework for resource-efficient and accurate data transmission within a low-power lossy sensor network (LLN) deployed for indoor monitoring. Cardoso et al. (2020) present the VPL, a Moodle plugin that allows students to submit their code and get prompt feedback without the teacher's intervention. To test this concept, an experiment was performed with several classes of beginner programming students, in two editions of Algorithms and Programming course unit of the degree in Informatics Engineering lectured at the Informatics Engineering Department at the School of Engineering, Polytechnic Institute of Porto. on sig-natures and are error-prone. Traditional machine learning techniques are based on static, dynamic, and hybrid analysis; however, for large scale Android malware analysis, these approaches are not feasible. Deep neural architectures can analyze large scale static details of the applications, but static analysis techniques can ignore many malicious behaviours of applications. The study contributes to the documentation of various constructing a 6LoWPAN network in the Contiki Cooja simulator. MCDM is applied to generate an adaptive objective function for the IPv6 routing protocol for the LLN (RPL) and to aid in ranking the nodes to select the best available neighbouring node, while the data accuracy is ensured by the cluster head through data corre-lation among its associated members. The network performance is assessed by analyzing the packet delivery rate, throughput and energy con-sumption against varying sensors and by comparing our proposed MCDM-RPL with a standard RPL and a fuzzy-based RPL, where the results show that our framework is found to be better with gains of 13%, 25% and 13%, respectively.",Expert Syst. J. Knowl. Eng.,2021.0,10.1111/exsy.12711,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7bf86d4c530bf082ea035e0134432305ab766d27,https://www.semanticscholar.org/paper/7bf86d4c530bf082ea035e0134432305ab766d27,Distributed Localization Algorithms in Indoor 802.15.4 Wireless Networks. (Algorithmes de localisation distribués en intérieur pour les réseaux sans fil avec la technologie IEEE 802.15.4),"The Internet of Things is finally blooming through diverse applications, from home automation and monitoring to health tracking and quantified-self movement. Consumers deploy more and more low-rate and low-power connected devices that provide complex services. In this scenario, positioning these intelligent objects in their environment is necessary to provide geo-localized services, as well as to optimize the network operation. However, indoor positioning of devices using only their radio interface is still very imprecise. Indoor wireless localization techniques often deduce from the Radio frequency (RF) signal attenuation the distances that separate a mobile node from a set of reference points called landmarks. The received signal strength indicator (RSSI), which reflects this attenuation, is known in the literature to be inaccurate and unreliable when it comes to distance estimation, due to the complexity of indoor radio propagation (shadowing, multi-path fading). However, it is the only metric that will certainly be available in small and inexpensive smart objects. In this thesis, we therefore seek algorithmic solutions to the following problem: is it possible to achieve a fair localization using only the RSSI readings provided by low-quality hardware? To this extent, we first study the behavior of the RSSI, as reported by real hardware like IEEE 802.15.4 sensor nodes, in several indoor environments with different sizes and configurations , including a large scale wireless sensor network. Such experimental results confirm that the relationship between RSSI and distance depends on many factors; even the battery pack attached to the devices increases attenuation. In a second step, we demonstrate that the classical log-normal shadowing propagation model is not well adapted in indoor case, because of the RSSI values dispersion and its lack of obvious correlation with distance. We propose to correct the observed inconsistencies by developing algorithms to filter irrelevant samples. Such correction is performed by biasing the classical log-normal shadowing model to take into account the effects of multipath propagation. These heuristics significantly improved RSSI-based indoor localization accuracy results. We also introduce an RSSI-based positioning approach that uses a maximum likelihood estimator conjointly with a statistical model based on machine learning. In a third step, we propose an accurate distributed and cooperative RSSI-based localization algorithm that refines the set of positions estimated by a wireless node. This algorithm is composed of two on-line steps: a local update of position?s set based on stochastic gradient descent on each new RSSI measurement at each sensor node. Then an asynchronous communication step allowing each sensor node to merge their common local estimates and obtain the agreement of the refined estimated positions. Such consensus approach is based on both a distributed local gradient step and a pairwise gossip protocol. This enables each sensor node to refine its initial estimated position as well as to build a local map of itself and its neighboring nodes. The proposed algorithm is compared to multilateration, Multi Dimensional Scaling (i.e. MDS) with modern majorization problem and classical MDS. Simulation as well as experimental results obtained on real testbeds lead to a centimeter-level accuracy. Both landmarks and blind nodes communicate in the way that the data processing and computation are performed by each sensor node without any central computation point, tedious calibration or intervention from a human.",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
395b153b5f3d4445e4e2920f5cb7e6531a970a62,https://www.semanticscholar.org/paper/395b153b5f3d4445e4e2920f5cb7e6531a970a62,Read PDF Home Automation Using Internet Of Things modernh.com,"hat bereits begonnen. Ihr Merkmal ist die ungeheuer schnelle und systematische Verschmelzung von Technologien, die die Grenzen zwischen der physischen, der digitalen und der biologischen Welt immer stärker durchbrechen. Wie kein anderer ist Klaus Schwab, der Vorsitzende des Weltwirtschaftsforums, in der Lage aufzuzeigen, welche politischen, wirtschaftlichen, sozialen und kulturellen Herausforderungen diese Revolution für uns alle mit sich bringt.This work presents the design and model implementation of a novel home automation system applying the Internet of Things (IoT) technology. It seeks simplified design protocols for developing a robust home automation system to deal with the problems of complexity, multiple incompatible standards and the resulting expenses in the existing systems. The embedded system featuresthe ubiquitous low-cost 32-bit ESP8266 System-on-chip (SoC) module interfaced to some sensors and actuators for interaction inthe home. Flexibility in the remote access, operation and management is achieved through HTML5 based intuitive mobile and web GUI applications. Web Application Messaging Protocol (WAMP) is deployed to ensure that individual applications and systems seamlessly communicate with a relatively high level of security using robust web service security protocol. This system offers a cost-effective and efficient solution, excluded, which are present mostly in other solutions, because the costs of a dedicated public IP address and a high-end computer are excluded, which are present mostly in other solutions.This book focuses on the emerging advances in distributed communication systems, big data, intelligent computing and Internet of Things, presenting state-of-the-art research in frameworks, algorithms, methodologies, techniques and applications associated with data engineering and wireless distributed communication technologies. In addition, it discusses potential topics like performance analysis, wireless communication networks, data security and privacy, human computer interaction, 5G Networks, and smart automated systems, which will provide insights for the evolving data communication technologies. In a nutshell, this proceedings book compiles novel and high-quality research that offers innovative solutions for communications in IoT networks.This edited book presents point of view and the work being undertaken by active researchers in the domain of IOT and its applications with societal impact. The book is useful to other researchers for the understanding of the research domain and different points of views expressed by the experts in their contributed chapters. The contributions are from both industry and academia; hence, it provides a rich source of both theoretical and practical work going on in the research domain of IOT.Advances in Computing, Communication, Automation and Biomedical Technology aims to bring together leading academic, scientists, researchers, industry representatives, postdoctoral fellows and research scholars around the world to share their knowledge and research expertise, to advances in the areas of Computing, Communication, Electrical, Civil, Mechanical and Biomedical Systems as well as to create a prospective collaboration and networking on various areas. It also provides a premier interdisciplinary platform for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, and concerns as well as practical challenges encountered, and solutions adopted in the fields of innovation.This books objective is to explore the concepts and applications related to Internet of Things with the vision to identify and address existing challenges. Additionally, the book provides future research directions in this domain, and explores the different applications of IoT and its associated technologies. Studies investigate applications for crowd sensing and sourcing, as well as smart applications to healthcare solutions, agriculture and intelligent disaster management. This book will appeal to students, practitioners, industry professionals and researchers working in the field of IoT and its integration with other technologies to develop comprehensive solutions to real-life problemsThis book presents selected research papers on current developments in the fields of soft computing and signal processing from the Third International Conference on Soft Computing and Signal Processing (ICSCSP 2020). The book covers topics such as soft sets, rough sets, fuzzy logic, neural networks, genetic algorithms and machine learning and discusses various aspects of these topics, e.g., technological considerations, product implementation and application issues.Over 60 recipes will help you build smart IoT solutions and surprise yourself with captivating IoT projects you thought only existed in Bond moviesAbout This Book- This book offers key solutions and advice to address the hiccups faced when working on Arduino- based IoT projects in the real world- Take your existing skills and capabilities to the next level by building challenging IoT applications with ease.- Be the tech disruptor you always wanted to be with key recipes that help you solve Arduino IoT related problems smarter and faster.- Put IoT to work through recipes on building Arduino-based devices that take control of your home, health, and life!Who computational techniques with traditional computing methods has inspired researchers and academics alike to focus on developing innovative computational techniques. In the near future, computational techniques may provide vital solutions by effectively using evolving technologies such as computer vision, natural language processing, deep learning, machine learning, scientific computing, and computational vision. A vast number of intelligent computational algorithms are emerging, along with increasing computational power, which has significantly expanded the potential for developing intelligent applications. These proceedings of the International Conference on Inventive Computation Technologies [ICICT 2019] cover innovative computing applications in the areas of data mining, big data processing, information management, and security.There is no doubt that there has been much excitement regarding the pioneering contributions of artificial intelligence (AI), the internet of things (IoT), and blockchain technologies and tools in visualizing and realizing smarter as well as sophisticated systems and services. However, researchers are being bombarded with various machine and deep learning algorithms, which are categorized as a part and parcel of the enigmatic AI discipline. The knowledge discovered gets disseminated to actuators and other concerned systems in order to empower them to intelligently plan and insightfully execute appropriate tasks with clarity and confidence. The IoT processes in conjunction with the AI algorithms and blockchain technology are bound to lay out a stimulating foundation for producing and sustaining smarter systems for society. Advancing Smarter and More Secure Industrial Applications Using AI, IoT, and Blockchain Technology articulates and accentuates various AI algorithms, fresh innovations in the IoT, and blockchain spaces. The domain of transforming raw data to information and to relevant knowledge is gaining prominence with the availability of data ingestion, processing, mining, analytics algorithms, platforms, frameworks, and other accelerators. Covering topics such as blockchain applications, Industry 4.0, and cryptography, this book serves as a comprehensive guide for AI researchers, faculty members, IT professionals, academicians, students, researchers, and industry professionals.“With futuristic homes on the rise, learn to control and automate the living space with intriguing IoT projects.” About This Book Build exciting (six) end-to-end home automation projects with Raspberry Pi 3, Seamlessly communicate and control your existing devices and build your own home automation system, Automate tasks in your home through projects that are reliable and fun Who This Book Is For This book is for all those who a new interconnectivity your world. Style and approach End to end home automation projects with 3.Throughout human history, technological advancements human our advancements, been discover over large this human intervention. These advancements may become essential may book The book includes high-quality research work by academicians and industrial field computing and communication, full-length papers, research-in-progress papers and case studies related to all the areas of data mining, machine learning, Internet of things (IoT) and information security.This book presents chapters from diverse range of authors on different aspects of how Blockchain and IoT are converging and the impacts of these developments. The book provides an extensive cross-sectional and multi-disciplinary look into this trend and how it affects artificial intelligence, cyber-physical systems, and robotics with a look at applications in aerospace, agriculture, automotive, critical infrastructures, healthcare, manufacturing, retail, smart transport systems, smart cities, and smart healthcare. Cases include the impact of Blockchain for IoT Security; decentralized access control systems in IoT; Blockchain architecture for scalable access management in IoT; smart and sustainable IoT applications incorporating Blockchain, and more. The book from and practitioners from diverse perspectives. how Blockchain and IoT are converging and the impacts of these developments on technology and its application; Discusses IoT and Blockchain from cross-sectional and multi-disciplinary perspectives; Includes contributions from researchers, academics, and professionals from around the world.With the recent growth of big data and the internet of things (IoT), individuals can now upload, retrieve, store, and collect massive amounts of information to help drive decisions a",,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1281c900e7f5fa90c3dfd02d28cdb545fea661f1,https://www.semanticscholar.org/paper/1281c900e7f5fa90c3dfd02d28cdb545fea661f1,Machine learning approach to dynamic risk modeling of mortality in COVID-19: a UK Biobank cohort study,"The COVID19 pandemic has resulted in over two million deaths globally. There is an urgent need for robust, scalable monitoring tools supporting resource allocation and stratification of high-risk patients. This research aims to develop and validate prediction models, using the UK Biobank to estimate COVID19 mortality risk in confirmed cases. We developed a random forest classification model using baseline characteristics, pre-existing conditions, symptoms, and vital signs, such that the score could dynamically assess risk of mortality with disease deterioration (AUC: 0.92). The design and feature selection of the framework lends itself to deployment in remote settings. Possible applications include supporting individual-level risk profiling and monitoring disease progression across high volumes of patients with COVID19, especially in hospital-at-home settings. The COVID19 pandemic has precipitated over 100 million confirmed cases and 2.3 million deaths globally. The impact of the pandemic has not been limited to healthcare systems: a ripple effect has resulted in wide-ranging economic and social disruption. Interventions to reduce transmission, such as lockdowns, travel restrictions, and re-allocation of health resources, are critical to limiting the impact. Although large-scale vaccination programmes have begun, many countries globally will not have widespread access to vaccines until 2023, meaning that non-pharmaceutical interventions are likely to remain indispensable national strategies for some time. COVID19 shows highly varied clinical presentation. A significant proportion (17 to 45%) of cases are asymptomatic and require no specific care. Conversely, reviews of severe complications have found that up to 32% of hospitalized COVID19 patients are admitted to ICU7. Between these two extremes, typical symptoms include fever, continuous cough, anosmia, and dyspnoea, which may range from requiring only self-management at home to inpatient care. Understanding which individuals are most vulnerable to severe disease, and thereby in most need of resources, is critical to limit the impact of the virus. Decision-making at all levels requires an understanding of individuals risk of severe disease. Various patient characteristics, comorbidities, and lifestyle factors have been linked to greater risk of death and/or severe illness following infection. Furthermore, socioeconomic factors have also been linked as risk factors for COVID19 mortality. Once patients are infected with SARS CoV 2, additional physiological parameters, such as symptoms and vital signs, can inform real-time prognostication13. Laboratory testing and imaging can also inform risk stratification for early, aggressive intervention, though this data is only accessible to hospital inpatients, who are likely to be already severely affected. Robust, predictive models for acquisition and prognosis of COVID 1916 18 and resource management have been developed to support risk stratification and population management at scale, offering important insights for organizational decision-making. However, the individual is currently overlooked, and granular, patient-specific risk-scoring could potentially unify decision-making at all levels. Existing individualized risk scores, however, often conflate risk of COVID19 acquisition with risk of mortality following infection, which can limit their utility in patient management. For prediction models to achieve impact at scale, assessment of risk factors should be inexpensive and accessible to the general population, ideally without the need for specialized testing or hospital visits. Such risk prediction tools, enabling improved patient triage, could be used to further increase the efficiency of, and confidence in, hospital at home solutions, which have shown promise in reducing hospital burden throughout the pandemic. Risk scores in these circumstances need to be dynamic and contemporaneous, ideally incorporating symptoms and vital sign data to maximise utility to clinical and research teams. Therefore, the primary aim of this study is to develop and validate a population-based prediction model, using a large, rich dataset and a selective, clinically informed approach, which dynamically estimates the COVID19 mortality risk in confirmed diagnoses.",medRxiv,2021.0,10.1101/2021.02.08.21251343,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
148b7d09bc9513a8b269b393e15f95c878f4c112,https://www.semanticscholar.org/paper/148b7d09bc9513a8b269b393e15f95c878f4c112,Movement-Related Desynchronization in EEG-based Brain-Computer Interface applications for stroke motor rehabilitation,"Neurological degenerative diseases like stroke, Alzheimer, Amyothrophic Lateral Sclerosis (ALS), Parkinson and many others are constantly increasing their incidence in the world 
health statistics as far as the mean age of the global population is getting higher and higher. 
This leads to a general need for effective, at-home and low-cost rehabilitative and health-daily-care tools. The latter should consist either of technological devices implemented for operating in a remote way, i.e. tele-medicine is quickly spreading around the world, or very-advanced computer-based and robotic systems to realize intense and repetitive trainings. This is the challenge in which Information and Communications Technology (ICT) is asked to play a major role in order to bring medicine to reach further advancements. 
Indeed, no way to cope with these issues is possible outside a strong and vivid cooperation among multi-disciplinary teams of clinicians, physicians, biologists, neuro-psychologists and engineers and without a resolute pushing towards a widespread inter-operability between Institutes, Hospitals and Universities all over the world, as recently highlighted during the main International conferences on ICT in healthcare. The establishment of well-defined standards for gathering and sharing data will then represent a key element to enhance the efficacy of the aforementioned collaborations. 
Among the others, stroke is one of the most common neurological pathologies being the second or third cause of mortality in the world; moreover, it causes more than sixty 
percent survivors remain with severe cognitive and motor impairments that impede them in living normal lives and require a twenty-four-hours daily care. As a consequence, on one side stroke survivors experience a frustrating condition of being completely dependent on other people even to perform simple daily actions like reach and grasp an object, hold a glass of water to drink it and so on. States, by their side, have to take into account additional costs to provide stroke patients and their families with appropriate cares and supports to cope with their needs. For this reason, more and more fundings 
are recently made available by means of grants, European and International projects, programs to exchange different expertise among various countries with the aim to study 
how to accelerate and make more effective the recovery process of chronic stroke patients. 
The global research about this topic is conducted on several parallel aspects: as regard as the basic knowledge of brain processes, neurophysiologists, biologists and engineers are 
particularly interested in an in-depth understanding of the so-called neuroplastic changes that brain daily operates in order to adapt individuals to life changes, experiences and to realize more extensively their own potentialities. 
Neuroplasticity is indeed the corner stone for most of the trainings nowadays adopted by the standard as well as the more innovative methods in the rehabilitative programs for post-stroke recovery. Specifically speaking, motor rehabilitation usually includes long term, repetitive and intense goal-directed exercises that promote neuroplastic mechanisms such as neural sprouting, synapto-genesis and dendritic branching. These processes are strictly related with motor improvements and their study could - one day - serve as prognostic measures of the recovery. 
Another aspect of this eld of neuroscience research is the number of applications that it makes feasible. One of the most exciting is to connect an injured brain to a computer or a robotic device in a Brain-Computer or Brain-Machine Interface (BCI or BMI) scheme aiming at bypassing the impairments of the patient and make him/her autonomously move again or train his/her motor abilities in a more effective way. This kind of research can already count an amount of literature that provides several proofs of concept that these heterogeneous systems constituted by humans and robots can work at the purpose. 
A particular application of BCI for restoring or enhancing, at least, the reaching abilities of chronic stroke survivors was implemented and is still currently being improved at I.R.C.C.S. San Camillo Hospital Foundation, an Institute for the rehabilitation from neurological diseases located in Lido of Venice and partially technically supported by the Department of Information Engineering of Padua in range of an agreement signed in 2009. 
This specific BCI platform allows patients to train and improve their reaching movements by means of a robotic arm that provides a force that helps patients in completing the training exercise, i.e. to hit a predetermined target. This force feedback is however subject to a strict condition: during the movement, the person has to produce the expected pattern of cerebral activity. Whenever this is accomplished, a force is delivered proportionally to the entity of the latter activity, otherwise the patient is obliged to operate without any help. In this way, this platform implements the so-called operant-learning, that is one of the most effective conditioning techniques to make a subject learn or re-learn a task. If, on one hand, the primary and explicit task is to improve a movement, on the other side the secondary but most important task is to deploy the perilesional part of the brain - still healthy - in becoming responsible for the control of the movement. It is a popular and widely-accepted opinion within the neuroscience community, indeed, that a healthy region of the sensorimotor area nearby the damaged one - which was previously in charge of performing the (reaching) movement - can optimally accomplish the impaired motor function substituting the original control area. 
Technically speaking, the main crucial feature that can ensure the effectiveness of the whole system is the precise and in real-time identification and quantification of the cerebral pattern associated with the movement, the worldwide named movement-related desynchronization (MRD). Starting from its original definition, passing through the most used techniques for its recognition, the thesis work presents a series of criticisms of the current signal processing method to detect the MRD and a complete analysis of the possible features that can better represent the movement condition and that can be more easily extracted during the on-line operations. 
Brain - it is well-known - learns by trials and errors and it needs a slightly-delayed (in the range of fraction of seconds) feedback of its performance to learn a task in the best way. This BCI application was born with the purpose to provide the above-mentioned feedback: however, this is only feasible if a computationally easy and contingent signal processing technique is available. This thesis work would like to cope with the lack of a well-planned real-time signal analysis in the current experimental protocol.",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
fdeab769f14c7f0a89dce5a56eae3b59209af465,https://www.semanticscholar.org/paper/fdeab769f14c7f0a89dce5a56eae3b59209af465,Recognizing foods using deep neural networks under domain shift,"Obesity is one of the health problems in developed countries and it is a contributing factor for many diseases. Keeping the record of daily meal intake is an effective solution for tackling obesity and overweight. This can be done by developing apps that are able to automatically recommend a short list of most probable foods by analyzing the photo taken from food. Additionally, uncontrolled food intake could also lead to micronutrient deficiency which would shorten the life expectancy. One way to cope with vitamin deficiency and tackle obesity is to track our daily meals.
 Instead of using conventional dietary record methods, we can develop a system which is able to accurately estimate calorie intake of the user by analyzing images of foods. After finding the category of food, we can extract nutrition facts of the food and estimate its calorie. By tracking this information over time for a user, the system can recommend the user to change his or her habits or prepare a particular food.
 Recognizing foods from images possess some challenges. On the one hand, foods are highly deformable objects. This means that visual patterns of the same food in the same plate under the same ambient light can change significantly. On the other hand, occlusion of some ingredients by other ingredients makes recognition of food more difficult. Design of food and cooking style are other factors that make the food recognition harder. Furthermore, different seasoning and chopping might change the appearance of the same food. From the machine learning perspective, there are examples showing the intra-class variation problem in the task of food classification. Another challenge in food classification is the inter-class similarity. For instance, pasta with meat and pasta with vegetables visually may look similar. Misclassification of pasta with meat and pasta with vegetables causes miscalculation of their calories.
 There are powerful off-the-shelf machine learning models such as support vector machines and random forest that are able to learn complex decision boundaries. In order to use these models, we first need to extract a compact and informative feature vector. For this purpose, hand-crafted features such as color histogram, HOG, SIFT, LBP, Gabor filter or Bag of Features (BoF) could be extracted for an image. After extracting features, we train a classifier using one of the models that we mentioned above.
 Recent studies showed that the hand-crafted feature extraction methods are not adequately accurate for classifying foods. This is mainly due to the fact that different classes of food may overlap in the feature space. In other words, using the hand-crafted feature extraction methods, different classes of food might not be non-linearly separable (ie. two or more distinct classes might overlap) in the feature space. To train a model with a higher accuracy, we need a more powerful representation for images of food. Recently, Convolutional Neural Networks (ConvNets) have achieved impressive results on the ImageNet dataset. A ConvNet usually consists of several convolution layers and pooling layers that enables it to have more representation power than the hand-crafted approaches.
Given a dataset of adequate size and diversity, it is possible to find an architecture with an admissible accuracy on this dataset. Finding the network could be done manually by trying various architectures or it could be done using automatic architecture search algorithms. Although finding an architecture is still an interesting topic in this field, recent networks have been built by plugging several microarchitectures. It is also shown that different networks with considerably different architectures produce comparable results.
 In this thesis, we focus our attention on more demanding issues of neural networks which are important in developing practical applications. Specifically, we study knowledge adaptation, domain adaptation, active learning and knowledge distillation. Throughout the thesis, we will also study a few other topics and propose new techniques.
 Knowledge adaption is a technique to utilize the current knowledge of the network and adapt it to perform a new task. Knowledge adaptation is a branch of a broader topic called transfer learning. Given a pre-trained network, the common approach is to keep early layers of the network unchanged and finetune late layers of the network on the new task. This approach has been inspired by the fact that early layers of a network learn general features and late layers learn task-specific features.
 Picking layers to be trained and layers to be kept unchanged randomly might not be an accurate solution. Alternatively, we show how to use the Fisher Information Matrix to find which layers must be finetuned during knowledge adaptation. Then, we will propose a multi-task loss function to further improve the results.
 One of the issues in neural networks is that they do not inherently compute the uncertainty of the predictions. This is important in practical applications since we mainly want to report the prediction with high certainty. In other words, if the network is uncertain about the predicted class, we should not report it to the user.
 We will explain different techniques for computing the uncertainty of the prediction based on a single prediction. We will also show a technique called Monte Carlo dropout for estimating the uncertainty. Then, we will propose a method based on multi-crop evaluation for improving the results and approximating uncertainty, simultaneously.
 Whereas knowledge adaptation assumes that the pre-trained network is going to learn a different task using labeled data, unsupervised domain adaptation assumes that the network is going to perform the same task but the domain of source and target datasets are different. In addition, the target dataset is unlabeled. Domain adaptation is another branch of transfer learning and it studies how to reduce the divergence of two domains or how to learn an accurate mapping under domain shift. We will explain most commonly used techniques in this field, and we will propose a technique which is computationally more efficient than the state-of-the-art methods and it performs better in the task of food classification. Our method is a variant of self-training where we take into account uncertainty of prediction and use ensemble of predictions rather than a single prediction.
One way to exploit unlabeled data to improve the results is to use many unlabeled data. Previous results on semi-supervised learning have shown that the accuracy is improved by using unlabeled data together with labeled data. Another practical way to use unlabeled data is through a technique called active learning. Given the annotation budget, the major goal of active learning is to pick samples from a pool of unlabeled samples and ask a human to annotate them. The number of selected samples could not exceed the budget. The newly annotated samples are added to the dataset, and they are used to improving the network. The main question in active learning is how to pick samples that work better than random sampling. We will study various techniques for sample selection and perform a complete experiment on the task of food classification. We will show that informativeness measures work better than random selection.
The last part of our thesis deals with the problem of making our models compact. Our ultimate goal is to deploy the model on an embedded system or a smartphone with limited computational resources. Hence, it is essential to make our network as compact as possible in order to reduce the time to completion and use the resources efficiently. We will define a loss function to use labeled and unlabeled data for training a smaller network (mentee) by a bigger network (mentor). The first term in our loss function computes the cross-entropy between the normalized smoothed logits produced by the mentor and the normalized logits produced by the mentee. The second term in the loss function computed the mean square error of logits produced by the two networks on unlabeled images.
 Then, we will propose a new network architecture with lower complexity. Our network is composed of successive convolution layers followed by several fire-residual modules, expansion block and a classification layer. The first convolution layers are for reducing the spatial size of the input quickly. Then, the fire residual modules do complex transformations. Also, the expansion layer makes it possible to have rectangle shaped receptive fields. We simply use the softened logits as the ground truth data and use the cross-entropy to transfer the knowledge of the mentor to the mentee. Our experiments show that not only the mentee is able to imitate the mentor, it is also able to slightly improve the results.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0fbcb0dc602f7e0a1c18ab2dddfed4802160901b,https://www.semanticscholar.org/paper/0fbcb0dc602f7e0a1c18ab2dddfed4802160901b,Building System Immunity in Real Time,"We identify research directions with regard to real-time security provisions in networks of critical real-time embedded systems, motivated by the recent advances in statistical learning algorithms. New functionality requirements for networked critical real-time embedded and systems (CRTES) are constantly being added while retaining the classical assumptions of severe energy, computation, storage and bandwidth constraints for the system components, making design with security considerations an increasing challenge. Due to the ever higher complexity, the best strategy is that system trustworthiness be addressed at design time, as even analysis or monitoring of system health would be very difficult after the deployment for systems that were not built with these issues in mind from the outset. The large number of nodes in an embedded network and the flexible network topology, wherein system components can dynamically join or leave the network, together with the real-time constraints warrant the use of automated and adaptive methods for system health monitoring, requiring minimal human intervention during run-time. Trustworthiness features, including system safety, security, reliability and privacy all have the uncertainty as a common denominator. It is certainly not possible to predict all fault or misuse scenarios at design time. This is especially true when addressing security, as security related threats should be assumed to be originating from intelligent entities with a malicious intent, trying to contrive novel, polymorphic methods for compromising the system. In the presence of uncertainty and non-predictable system threats, deriving anomaly detection and prevention methods solely from deterministic event classification principles is a recipe for disaster. Probabilistic models and probabilistic reasoning about security should be preferred for properly addressing these questions. Inference algorithms based on the statistical learning theory framework [1], the support vector machine (SVM) classifiers, have a notable potential for automated operation requiring minimal human guidance. SVMs are suitable for analysis of vast amounts of data in situations where functional dependencies between the data and the outcome of the classification are not known a priori, and particularly in situations where not all parts of the analyzed data are equally informative and explicit weights of all the features are not known, or their manual specification is not feasible. SVMs are specifically tailored for inference based on a small sample size, thus simplifying their training. At the time SVM algorithms were introduced it was obvious that they might not be entirely suitable for real-time operation. SVMs were applied successfully to the 1999 KDDCUP intrusion detection data, but this task suggested • a central point of analysis : the collected data were assumed to be communicated to a processing site with virtually unlimited processing resources; dissemination of the classification results, the associated costs and further actions were not considered. • off-line, post-mortem analysis of intrusion events : the goal was to carry out a classification with maximal precision, while there were no timing restrictions or real-time requirements. Clearly, this set of assumptions is not entirely suitable for distributed embedded systems with real-time constraints. However, recent advances in the development of statistical learning algorithms convert some of the above shortcomings of the statistical classifiers into enabling possibilities and introduce new research directions with regard to security considerations in CRTES: Automated Model Selection Standard applications of SVM algorithms require manual selection of a suitable kernel model and manual parameter tunning. Applications of SVMs in networked CRTES pose additional challenges in this respect. Embedded systems tend to be more tightly coupled to the physical world than traditional networked systems. Changes in the physical environment as well as changes in the network topology possibly induced by individual nodes joining or leaving the network in an ad hoc manner, imply behaviors that cannot be anticipated at design time. Additionally, CRTES are expected to work unattended and with very limited direct user interaction. These added prerequisites for CRTES present the need of automatic and adaptive updates of the utilized models. Recent work in SVM algorithms has shown a viable possibility of automating the choice of kernel models ([2]) by learning the best kernel from available data. This further automates the task of model selection and paves the way for reducing the need of human intervention which is essential to real-time operation. Development of mechanisms for achieving self-configuration and adaptivity in the context of networked CRTES is called for in order to take the advantage of these advances in statistical learning algorithms. Incremental On-line Learning and Unlearning The basic SVM algorithm encompasses an off-line learning phase that takes place before the algorithm can be applied to newly generated data. Updating the acquired knowledge requires retraining. This makes the basic algorithm implementation unsuitable for applications in dynamical embedded networked systems because the amounts of data generated by such systems tend to be overwhelming, and a retraining from scratch would require excessive storage space to store the past relevant data. But recent work shows it feasible to endow the SVM algorithm with the ability to learn and unlearn incrementally, as new data arrive ([3], [4]). This opens the door to applying an upgradable SVM learning algorithms in an on-line setting. How to perform recursive learning in real-time, or whether this can be done at all, remains to be answered. Distributed Algorithms One of the prominent challenges arising in the context of CRTES is: How should an embedded network comprising a large number of nodes be coordinated to perform security related tasks in a distributed manner?",,2006.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
920b236f530422313ebccf5d43f7d3dd9103beba,https://www.semanticscholar.org/paper/920b236f530422313ebccf5d43f7d3dd9103beba,"International Conference on Computing and Artificial Intelligence ( ICCAI 2019 ) April 19-22 , 2019 Bali , Indonesia","Recently, deep learning (DL) plays important roles in many academic and industrial areas especially in computer vision and image recognition. Deep learning uses a neural network with deep structure to build a high-level feature space. It learns data-driven, highly representative, hierarchical image features, which have proven to be superior to conventional hand-crafted low-level features and mid-level features. In ILSVRC2015 (an Annual competition of image classification at large scale), higher recognition accuracy by deep learning than human has been achieved. Deep learning (DL) has also been applied to medical image analysis. Compared with DL-based natural image analysis, there are several challenges in DL-based medical image analysis due to their high dimensionality and limited number of labeled training samples. We proposed several deep learning techniques for medical image analysis including medical image segmentation, medical image detection and medical image recognition. In this keynote talk, I will talk about current progress and futures of medical image analysis with deep learning. ICCAI 2019 CONFERENCE ABSTRACT 12 Keynote Speaker IV Prof. Qijun Zhao Sichuan University, China Prof. Qijun Zhao is currently a professor in the College of Computer Science at Sichuan University. He obtained his B.Sc. and M.Sc. degrees in computer science both from Shanghai Jiao Tong University, and his Ph.D. degree in computer science from the Hong Kong Polytechnic University. He worked as a post-doc research fellow in the Pattern Recognition and Image Processing Lab at Michigan State University from 2010 to 2012. His recent research interests lie in 3D face modeling and recognition, with applications to forensics, intelligent video surveillance, mobile security, healthcare, and human-computer interactions. Dr. Zhao has published more than 60 papers in academic conferences and journals, including CVPR, ECCV, AAAI, ICB, IEEE Trans., and PR. He is the principal investigator for two projects funded by NSFC, one project funded by the National Key Research and Development Program of China, and many projects funded by companies. Dr. Zhao is a reviewer for many renowned field journals and conferences, such as IEEE TPAMI, IEEE TIFS, IJCV, PR, PRL, ICCV, CVPR, ECCV, and FG. He served as a program committee co-chair in organizing the 11th Chinese Conference on Biometric Recognition (CCBR 2016), the 2018 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA), and the 2018 6th International Conference on Bioinformatics and Computational Biology (ICBCB 2018), and as a face recognition area co-chair for the 9th IEEE International Conference on Biometrics: Theory, Applications, and Systems (BTAS 2018). Topic: ""3D Face Reconstruction in Recognition Perspective"" Abstract—The face reveals a lot of information of humans, for example, identity, race, gender, age, emotion, intention, and health. 3D face models are thus widely studied in many disciplines. Yet, acquisition of 3D faces is still much more expensive and less convenient than acquisition of 2D face images, making it unaffordable to deploy 3D face technology in many real-world applications. Our research aims to reconstruct 3D face shapes from either single or multiple uncalibrated 2D face images from a perspective of identity recognition. This talk will introduce our recent progress along this direction. The methods we propose enable not only efficient generation of 3D face models when only 2D imaging devices are available, but also effective exploration of 3D face information for improving face recognition accuracy. We believe that 3D faces will play increasingly important roles in many applications with the rapid development of both 3D face acquisition techniques and 3D face modeling methods.The face reveals a lot of information of humans, for example, identity, race, gender, age, emotion, intention, and health. 3D face models are thus widely studied in many disciplines. Yet, acquisition of 3D faces is still much more expensive and less convenient than acquisition of 2D face images, making it unaffordable to deploy 3D face technology in many real-world applications. Our research aims to reconstruct 3D face shapes from either single or multiple uncalibrated 2D face images from a perspective of identity recognition. This talk will introduce our recent progress along this direction. The methods we propose enable not only efficient generation of 3D face models when only 2D imaging devices are available, but also effective exploration of 3D face information for improving face recognition accuracy. We believe that 3D faces will play increasingly important roles in many applications with the rapid development of both 3D face acquisition techniques and 3D face modeling methods. ICCAI 2019 CONFERENCE ABSTRACT 13 Keynote Speaker V Assoc. Prof. Ken‘ichi Morooka Kyushu University, Japan Assoc. Prof. Ken’ichi Morooka received his M.S. and Ph.D. degrees from Kyushu University, in 1997 and 2000, respectively. He was a visiting researcher with Institute of Systems & Information Technologies/KYUSHU. From 2000 to 2006, he was an associate professor in Graduate School of Science and Engineering, Tokyo Institute of Technology. He was an associate professor in Digital Medicine Initiative (2006-2010) and Department of Medical Sciences, Kyushu University (2010). Currently, he is an associate professor in Graduate School of Information Science and Electrical Engineering, Kyushu University. Also he was a visiting researcher, Illinois Institute of Technology, U.S. (2016). He has published more than 100 journal and conference articles. He has served as a member of organizing and program committees at numerous conferences, e.g. he has been program committes of MLMI 2018 and 2017, IFMIA 2017, CARS 2014 and EMBC 2013. His research interests cover computer-aided support system for therapy and surgery by image information processing and machine learning. Topic: ""Computer Aided System for Minimally Invasive Surgery Using Deep Learning"" Abstract—Recently, deep neural networks (DNNs) have been paid attention by various research fields including vision, audio and natural language. Of course, there are many DNN-based systems for therapy and diagnosis. Our research group has been doing research about computer-aided support systems for safe and accurate minimally invasive surgeries. Especially, to provide useful information for surgeons, our support systems use stereo endoscopic images, DNNs and 3D shapes and deformations of organs. I will present the fundamental techniques of our support system.Recently, deep neural networks (DNNs) have been paid attention by various research fields including vision, audio and natural language. Of course, there are many DNN-based systems for therapy and diagnosis. Our research group has been doing research about computer-aided support systems for safe and accurate minimally invasive surgeries. Especially, to provide useful information for surgeons, our support systems use stereo endoscopic images, DNNs and 3D shapes and deformations of organs. I will present the fundamental techniques of our support system. ICCAI 2019 CONFERENCE ABSTRACT 14 Invited Speaker Assoc. Prof. Sugiono Sugiono Brawijaya University, Indonesia Sugiono, Ph.D was born in Blitar, Indonesia, in 1978. He finished Bachelor degree in Mechanical Engineering Department at Brawijaya University in 2001, received Master Degree in Industrial Engineering at Sepuluh Nopember Institute of Technology, Surabaya in 2004, and graduated Ph.D. degree of Art, Design and Technology from University of Derby, UK, in 2012. Title of his thesis (PhD) is: Investigating an Intelligent Concept Design Tool for Automotive Car Body Design. His research interests lie in bioengineering ergonomics and intelligent product design. He worked as project analyser in investigating of fuel distribution for industry at PT. Surveyor Indonesia from 2001 to 2002. He also worked as purchasing vice leader at PT. Mitra Saruta (Textile) from 2004 to 2005. Currently, he is working as a lecturer at Department of Industrial Engineering, Brawijaya University start from 2005. He is a head of Work Design and Ergonomics Laboratory and head of Research Committee at Brawijaya University. He is an international reviewer of research, certificated by ISO 17024. He is also working as editor in chief of the Indonesian Journal of Disability Studies (IJDS). He is a senior member of Hong Kong Chemical, Biological and Environmental Engineering Society (HKCBEES), member of Indonesian Ergonomics Society (Perhimpunan Ergonomi Indonesia – PEI) and Member of International Association of Engineers (IAENG). Topic: ""The Importance of Open Innovation Concept to Improve Health and Safety Factors in Transportation"" Abstract—Controlling driver stress level is going to be popular research and put it a very important factor to reduce the risk of a road accident. Understanding the role of road complexity and information technology in transportation issues and their relationship with humans psychophysiological is a good challenge and profitable prospect for the future. Images from the Electrocardiograph (ECG) and Electroencephalography (EEG) are the important tools to identify the driver stress as part of a safety alert system. The Electrocardiograph (ECG) is to monitor every heart rate change and Electroencephalography (EEG) is to record brain signal change correlated with brain functions (thinking, visual, decision, etc.) from three different road types (city road, rural road, and motorway). In this speech, I will deliver a potential open innovation of health and safety factors in transportation (car, train) from the perspective of interaction among human, car, and environment.Controlling driver stress level is going to be popular research and put it a very important factor to reduce the risk of a road accident. Understanding the role of road complexity and information t",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
9267b0157df0790153466bd6b3670d70c8d7de0b,https://www.semanticscholar.org/paper/9267b0157df0790153466bd6b3670d70c8d7de0b,Resource allocation in future green wireless networks : applications and challenges,"Over the past few years, green radio communication has been an emerging topic since the footprint from the Information and Communication Technologies (ICT) is predicted to increase 7.3% annually and then exceed 14% of the global footprint by 2040. Moreover, the explosive progress of ICT, e.g., the fifth generation (5G) networks, has resulted in expectations of achieving 10-fold longer device battery lifetime, and 1000-fold higher global mobile data traffic over the fourth generation (4G) networks. Therefore, the demands for increasing the data rate and the lifetime while reducing the footprint in the next-generation wireless networks call for more efficient utilization of energy and other resources. To overcome this challenge, the concepts of small-cell, energy harvesting, and wireless information and power transfer networks can be evaluated as promising solutions for re-greening the world. 
 
In this dissertation, the technical contributions in terms of saving economical cost, protecting the environment, and guaranteeing human health are provided. More specifically, novel communication scenarios are proposed to minimize energy consumption and hence save economic costs. Further, energy harvesting (EH) techniques are applied to exploit available green resources in order to reduce carbon footprint and then protect the environment. In locations where implemented user devices might not harvest energy directly from natural resources, base stations could harvest-and-store green energy and then use such energy to power the devices wirelessly. However, wireless power transfer (WPT) techniques should be used in a wise manner to avoid electromagnetic pollution and then guarantee human health. To achieve all these aspects simultaneously, this thesis proposes promising schemes to optimally manage and allocate resources in future networks. 
 
Given this direction, in the first part, Chapter 2 mainly studies a transmission power minimization scheme for a two-tier heterogeneous network (HetNet) over frequency selective fading channels. In addition, the HetNet backhaul connection is unable to support a sufficient throughput for signaling an information exchange between two tiers. A novel idea is introduced in which the time reversal (TR) beamforming technique is used at a femtocell while zero-forcing-based beamforming is deployed at a macrocell. Thus, a downlink power minimizationscheme is proposed, and optimal closed-form solutions are provided. 
 
In the second part, Chapters 3, 4, and 5 concentrate on EH and wireless information and power transfer (WIPT) using RF signals. More specifically, Chapter 3 presents an overview of the recent progress in green radio communications and discusses potential technologies for some emerging topics on the platforms of EH and WPT. Chapter 4 develops a new integrated information and energy receiver architecture based on the direct use of alternating current (AC) for computation. It is shown that the proposed approach enhances not only the computational ability but also the energy efficiency over the conventional one. Furthermore, Chapter 5 proposes a novel resource allocation scheme in simultaneous wireless information and power transfer (SWIPT) networks where three crucial issues: power-efficient improvement, user-fairness guarantee, and non-ideal channel reciprocity effect mitigation, are jointly addressed. Hence, novel methods to derive optimal and suboptimal solutions are provided. 
 
In the third part, Chapters 6, 7, and 8 focus on simultaneous lightwave information and power transfer (SLIPT) for indoor applications, as a complementary technology to RF SWIPT. In this research, Chapter 6 investigates a hybrid RF/visible light communication (VLC) ultrasmall cell network where optical transmitters deliver information and power using the visible light, whereas an RF access point works as a complementary power transfer system. Thus, a novel resource allocation scheme exploiting RF and visible light for power transfer is devised. Chapter 7 proposes the use of lightwave power transfer to enable future sustainable Federated Learning (FL)-based wireless networks. FL is a new data privacy protection technique for training shared machine learning models in a distributed approach. However, the involvement of energy-constrained mobile devices in the construction of the shared learning models may significantly reduce their lifetime. The proposed approach can support the FL-based wireless network to overcome the issue of limited energy at mobile devices. Chapter 8 introduces a novel framework for collaborative RF and lightwave power transfer for wireless communication networks. The constraints on the transmission power set by safety regulations result in significant challenges to enhance the power transfer performance. Thus, the study of technologies complementary to conventional RF SWIPT is essential. To cope with this isue, this chapter proposes a novel collaborative RF and lightwave power transfer technology for next-generation wireless networks.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2a9a8102602d23954e0e8dd457209e5ef9e4b052,https://www.semanticscholar.org/paper/2a9a8102602d23954e0e8dd457209e5ef9e4b052,Deployment of a Free-Text Analytics Platform at a UK National Health Service Research Hospital: CogStack at University College London Hospitals,"As more healthcare organisations transition to using electronic health record (EHR) systems it is important for these organisations to maximise the secondary use of their data to support service improvement and clinical research. These organisations will find it challenging to have systems which can mine information from the unstructured data fields in the record (clinical notes, letters etc) and more practically have such systems interact with all of the hospitals data systems (legacy and current). To tackle this problem at University College London Hospitals, we have deployed an enhanced version of the CogStack platform; an information retrieval platform with natural language processing capabilities which we have configured to process the hospital’s existing and legacy records. The platform has improved data ingestion capabilities as well as better tools for natural language processing. To date we have processed over 18 million records and the insights produced from CogStack have informed a number of clinical research use cases at the hospitals. Section 1: Introduction 4 Epic Systems Corporation 3 University College London Hospitals NHS Foundation Trust, Clinical Research Informatics Unit 2 King’s College London 1 University College London, Institute of Health Informatics Over the past twenty years we have seen an increased uptake of electronic health records (EHR) within healthcare organisations with much of this being attributable to national efforts in having healthcare organisations transition to using full EHR systems [1] [2]. These EHRs represent a rich data asset but there remains a challenge in secondary use of the data for improving clinical care through activities such as service improvement and clinical research. In many cases the EHRs have simply replicated the paper system that they replaced and have not taken full advantage of the opportunities presented in having the health records in this new electronic format. Whilst functional systems to address these gaps are emerging many of the tools and data analytic approaches used on EHR data are limited to structured data, such as coded diagnoses and numeric clinical measurements, despite almost 80% of information being recorded as unstructured free text [10] (such as clinical notes, imaging reports and transfer of care documents). An additional difficulty is that a hospital’s record is typically distributed across numerous disconnected data systems which presents a challenge in data harmonisation. Working with EHRs thus presents a challenge firstly in harmonising and accessing the hospitals entire record from both existing and legacy data systems and secondly having tools and techniques available to mine and extract data from within these records; especially the unstructured free text. Manual analysis of unstructured text is time-consuming, so there has been much interest in developing automated methods for extracting accurate structured information from the text. Interpreting free text is a major analytic challenge; clinical text is written in a variety of styles by numerous authors, and may have mis-spellings, negations and information which does not relate to the patient. There has been intense interest in developing natural language processing techniques to interpret clinical text. Early methods used a rule-based approach, but more modern algorithms incorporate machine learning techniques, enabling the algorithms to ‘learn’ as more data is analysed. The CogStack platform [6] was developed to address these exact problems. The platform can be described as an information retrieval (IR) system designed to interface with a hospital’s EHR system. It was initially developed with an emphasis on ingestion and harmonisation of records from multiple data systems within a healthcare organisation. Whilst certain off the shelf natural language processing (NLP) tools were explored in the first iteration they were added as a proof of concept to demonstrate that the platform could potentially be configured to interact with such tools. In this paper we discuss the deployment of CogStack at University College London Hospital (UCLH) and the improvements introduced to the platform to ensure that platform scales to meet the growing research demands of the hospital. Our deployment has focused on addressing the following three key issues which need to be universally addressed at all research driven healthcare organisations. Multiple Data Systems: The EHRs of an organisation will typically be distributed across a number of different vendor systems, posing a challenge for the use of this information for clinical care and research. It is not uncommon for an organisation to have to maintain oversight over a myriad of data systems and vendors due to the fact that different clinical specialties will have different requirements of how data needs to be stored and managed. The resulting heterogeneity in data means that it is challenging for the organisation to find a common data model or even process through which the organisation's entire record can be harmonised. Methods and systems through which data is stored, collected and retrieved have been improving in order to tackle this challenge. Most notably many NHS trusts have opted to transition into using full scale EHR systems (e.g. Epic) each of which typically enforce their own data models. Some systems such as Epic go further in providing additional systems that allow data from third party data and legacy systems to be integrated with data collected via their own systems (Epic Clarity/Caboodle). Messaging standards (e.g. HL7 FHIR5 ), standardised terminologies (e.g SNOMED CT ) and standardised clinical information models (such as openEHR archetypes6) aim to improve interoperability between systems, but much more work is needed in this area. In order to maximise the benefit of patient data, it is essential that clinicians and researchers can access data in a way that is flexible, easily adaptable and independent of the organisation’s choice of current and previous EHR systems. Multiple Data Formats: A patient’s record may be distributed across both scanned documents (pdfs), text documents (.doc files) as well as data stored in relational databases. Legacy documents for example will likely be stored as files and attachments whereas data that has been generated using a modern EHR system will likely be stored in a more structured way; possibly in a relational database. An IR system would thus need to be able to ingest and interact with records from all the various data formats used by the organisation. The CogStack platform provides a distributed architecture for document processing, including PDF to text conversion, or optical character recognition that may be needed prior to analysis of the text itself. Unstructured Text: A final issue is that data within the EHR systems is recorded in both structured and unstructured fields. Some information is inherently unstructured in nature and needs to be recorded as free text (e.g. patient stories), but even where structured fields are available, clinicians may not use them and enter the information in free text instead. For example, a recent audit in our Trust found that patients admitted with suspected or confirmed COVID-19 had only 62.3% of their key diagnoses and comorbidities recorded in the structured problem list [11]. In order to support use of clinical data at scale and for multiple stakeholders, a successful IR system should provide mechanisms through which the clinical information within the unstructured free text notes can be made available. The CogStack platform provides a convenient user interface for searching free text and invoking information extraction algorithms, presenting the results in a way that is easy to visualise and harness for downstream research or for reintegration as structured data back into the EHR. 6 https://www.openehr.org/ 5 https://www.hl7.org/fhir/overview.html",ArXiv,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
42c9527670182855ec693b469e58925e84998e29,https://www.semanticscholar.org/paper/42c9527670182855ec693b469e58925e84998e29,"""How Robotics are Revolutionizing Rehabilitation""","Capitalizing on the new understanding of brain plasticity, we introduced a paradigm shift in clinical practice in 1989 when we initiated the development of the MIT-Manus robot for neuro-rehabilitation and deployed it into the clinic. Since then we collected evidence to support the potential of enhancing and augmenting recovery following a stroke, first during the sub-acute and then the chronic phase. Our efforts and that of others led to the endorsements starting in 2010 from the American Heart Association, the American Stroke Association, and the Veterans Administration for the use of rehabilitation robots for the Upper Extremity, but not yet for the Lower Extremity. AHA recommendations were the same in the 2016 revision. Furthermore, it was demonstrated in the VA system that upper extremity robotic therapy has an economic advantage over manual therapy. More recently we completed a pragmatic study RATULS under the auspices of the National Health Service of the United Kingdom and its NIHR Health Technology Assessment Programme, which enrolled 770 stroke patients. Thus, we have developed novel robotic treatment and evaluation tools and have managed to collect the experimental evidence that demonstrates the unequivocal therapeutic benefits stemming from robot-aided rehabilitation for the upper extremity as well as present shortcomings. This talk will present an overview of our past rehabilitation robotics efforts and more recent efforts addressing the identified shortcomings. ""Novel Biomarkers: Robotics and Machine Learning "" Hermano Igo Krebs, PhD Abstract: In stroke, we demonstrated that robotic devices promoted upper extremity motor recovery. Those studies raised new questions focused on patients who were mildly or completely resistant to therapy, i.e., patients who did not improve, and prompted the hypothesis In stroke, we demonstrated that robotic devices promoted upper extremity motor recovery. Those studies raised new questions focused on patients who were mildly or completely resistant to therapy, i.e., patients who did not improve, and prompted the hypothesis that we could predict who are the responders, quasi-responders, and non-responders to behavioral therapy. There have been other attempts to create biomarkers to predict outcomes employing clinical scales such as the Fugl-Meyer assessment, the neurologic sensory exam, functional impairment scales, neurophysiology and neuro-imaging analysis; but these attempts have had mixed results and these measures are seldom used in practice to optimize therapy. To understand the variability of recovery, we examined the data collected with the robotic group on a recently completed studies. We investigated the potential for building a more sensitive biomarker, composed of robotic measurements collected during evaluation and training, to analyze the performance of patients recovering from stroke and to predict who will respond to movement-based treatment and who will not. We hypothesize that kinematic and kinetic measurements can predict the response to behavioral therapy in stroke and also determine how to optimize care for a particular patient. Here we will discuss our attempts to employ both linear and non-linear approaches and ascertain the correlation levels between our robot-based biomarker and clinical scales. We will discuss robot biomarker effect-size and compare it to clinical scales to determine whether there are some noticeable efficiencies in using the robotassay instead of the clinical scales. We will also present our efforts in developing an expert algorithm that employs data collected during the baseline assessment and during two consecutive training sessions in order to predict patient outcomes as well as to determine patterns of improvement in stroke patients so as to build an alternative machine learning predictor of outcomes. ""Starting a Venture Company"" Hermano Igo Krebs, PhD Abstract: “Imagine being present at the birth of a new industry. . . trends are now starting to converge and I can envision a future in which robotics devices will become a nearly ubiquitous part of our day-to-day lives. Technologies such as distributed computing, voice and visual recognition, and wireless broadband connectively will open the door to a new generation of autonomous devices that enable computers to perform tasks in the physical world on our behalf. We may be on the verge of a new era, when the PC will get up off the desktop and allow us to see, hear, touch and manipulate objects in places where we are not physically present.” Bill Gates Disruptive technology is a term coined to characterize an innovation that disrupts an existing market or way of doing things and creates a new value network. The concept was first described at Harvard Business School by Clayton M. Christensen, who described the concept in 1996 as: ""Generally, disruptive innovations were technologically straightforward, consisting of off-theshelf components put together in a product architecture that was often simpler than prior approaches. They offered less of what customers in established markets wanted and so could rarely be initially employed there. They offered a different package of attributes valued only in emerging markets remote from, and unimportant to, the mainstream."" Eventually with improvement, borrowing from Malcolm Gladwell, the moment of critical mass, the threshold, the boiling point is reached and the old practices and existing value network is abandoned in favor of the new one. Here I will discuss my experience as an entrepreneur and whether rehabilitation robotics has achieved its “tipping point.” “Imagine being present at the birth of a new industry. . . trends are now starting to converge and I can envision a future in which robotics devices will become a nearly ubiquitous part of our day-to-day lives. Technologies such as distributed computing, voice and visual recognition, and wireless broadband connectively will open the door to a new generation of autonomous devices that enable computers to perform tasks in the physical world on our behalf. We may be on the verge of a new era, when the PC will get up off the desktop and allow us to see, hear, touch and manipulate objects in places where we are not physically present.” Bill Gates Disruptive technology is a term coined to characterize an innovation that disrupts an existing market or way of doing things and creates a new value network. The concept was first described at Harvard Business School by Clayton M. Christensen, who described the concept in 1996 as: ""Generally, disruptive innovations were technologically straightforward, consisting of off-theshelf components put together in a product architecture that was often simpler than prior approaches. They offered less of what customers in established markets wanted and so could rarely be initially employed there. They offered a different package of attributes valued only in emerging markets remote from, and unimportant to, the mainstream."" Eventually with improvement, borrowing from Malcolm Gladwell, the moment of critical mass, the threshold, the boiling point is reached and the old practices and existing value network is abandoned in favor of the new one. Here I will discuss my experience as an entrepreneur and whether rehabilitation robotics has achieved its “tipping point.”",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0b0a5baa1a4e9e904715502f0505af1eb2687fd1,https://www.semanticscholar.org/paper/0b0a5baa1a4e9e904715502f0505af1eb2687fd1,Impact of artificial intelligence in healthcare,"Artificial intelligence (AI) is prepared to become a transformational force in healthcare. From chronic diseases and cancer to radiology and risk assessment, there are nearly endless opportunities to influence technology to install more precise, efficient, and impactful interventions at exactly the right moment in a patient’s care.AI offers a number of benefits over traditional analytics and clinical decision-making techniques.  Learning algorithms can become more specific and accurate as they interact with training data, allowing humans to gain unique insights into diagnostics, care processes, treatment variability, and patient outcomes (1).   
  
Using computers to communicate is not a new idea by any means, but creating direct interfaces between technology and the human mind without the need for keyboards, mice, and monitors is a cutting-edge area of research that has significant applications for some patients. Neurological diseases and trauma to the nervous system can take away some patients’ abilities to speak, move, and interact meaningfully with people and their environments.  Brain-computer interfaces (BCIs) backed by artificial intelligence could restore those fundamental experiences to those who feared them lost forever. Brain-computer interfaces could drastically improve quality of life for patients with ALS, strokes, or locked-in syndrome, as well as the 500,000 people worldwide who experience spinal cord injuries every year (2). 
  
Radiological images obtained by MRI machines, CT scanners, and x-rays offer non-invasive visibility into the inner workings of the human body.  But many diagnostic processes still rely on physical tissue samples obtained through biopsies, which carry risks including the potential for infection. AI will enable the next generation of radiology tools that are accurate and detailed enough to replace the need for tissue samples in some cases, experts predict. Diagnostic imaging team with the surgeon and the pathologist can be brought together which will be a big challenge (3). 
  
Succeeding in the pursuit may allow clinicians to develop a more accurate understanding of how tumours behave as a whole instead of basing treatment decisions on the properties of a small segment of the malignancy. Providers may also be able to better define the aggressiveness of cancers and target treatments more appropriately. Artificial intelligence is helping to enable “virtual biopsies” and advance the innovative field of radiomics, which focuses on harnessing image-based algorithms to characterize the phenotypes and genetic properties of tumours (1). 
  
Shortages of trained healthcare providers, including ultrasound technicians and radiologists can significantly limit access to life-saving care in developing nations around the world. AI could help mitigate the impacts of this severe deficit of qualified clinical staff by taking over some of the diagnostic duties typically allocated to humans (4). 
  
For example, AI imaging tools can screen chest x-rays for signs of tuberculosis, often achieving a level of accuracy comparable to humans.  This capability could be deployed through an app available to providers in low-resource areas, reducing the need for a trained diagnostic radiologist on site. 
  
However, algorithm developers must be careful to account for the fact that different ethnic groups or residents of different regions may have unique physiologies and environmental factors that will influence the presentation of disease.The course of a disease and population affected by the disease may look very different in India than in the US. As these algorithms are being developed,  it is very important to make sure that the data represents a diversity of disease presentations and populations. we cannot just develop an algorithm based on a single population and expect it to work as well on others (1). 
  
Electronic health records (EHRs) have played an instrumental role in the healthcare industry’s journey towards digitalization, but the switch has brought myriad problems associated with cognitive overload, endless documentation, and user burnout. EHR developers are now using AI to create more intuitive interfaces and automate some of the routine processes that consume so much of a user’s time. Users spend the majority of their time on three tasks: clinical documentation, order entry, and sorting through the in-basket (5). 
  
Voice recognition and dictation are helping to improve the clinical documentation process, but natural language processing (NLP) tools might not be going far enough. Video recording a clinical encounter would be helpful while using AI and machine learning to index those videos for future information retrieval. And it would be just like in the home, where we are using Siri and Alexa.  The future will bring virtual assistants to the bedside for clinicians to use with embedded intelligence for order entry(5). AI may also help to process routine requests from the inbox, like",Biomedicine,2021.0,10.51248/.v41i3.1190,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
7aca23cb1ed35b1efe203a52bac8f889b27b189b,https://www.semanticscholar.org/paper/7aca23cb1ed35b1efe203a52bac8f889b27b189b,AC 2011-795: PROJECT-BASED SERVICE LEARNING AND STUDENT MOTIVATION,"We know from motivation theory that enhanced motivation in students is positively correlated with engagement and active learning, interest, and value. We know less about the types of instructional strategies and curricular interventions that work to enhance student motivation in a typical engineering course. Grounded in motivation theory, the purpose of this research is to evaluate how the context of project-based service-learning affects aspects of student motivation (particularly interest and engagement) in a required undergraduate Mechanical Engineering course. Our research aims to answer: 1) How does project-based service learning affect students’ motivation as compared to conventional (non-service) project-based learning? 2) Do students find the context of project-based service-learning more interesting and/or valuable than conventional project-based learning? 3) How does project-based service-learning affect student engagement in the course as compared to conventional project-based learning? The research, which began in 2009, is being completed over a three-year period. The students and activities in Component Design, an existing junior-level course, will serve as the research focus. Specifically, project-based service-learning curriculum will be implemented into a required design and build activity for Component Design students. Using a conventional design project as the control, how the context of project-based service learning affects aspects of student motivation will be studied. A mixed-methods assessment strategy will be employed: quantitative data from preand postproject surveys and shorter surveys administered during the semester will be combined with qualitative data from student interviews and focus groups. This paper will discuss the research design, theoretical framework, and the results of a pilot survey administered in February 2010. Introduction Part of the theoretical framework for this research includes project-based service-learning (PBSL). PBSL is a form of active learning where students work on projects that benefit a real community or client while obtaining a rich learning experience (Duffy, et al., 2009). Many engineering educators are embracing alternative instructional strategies like PBSL in an attempt to respond to major shifts in the engineering profession and practice. Today’s world is a global market and a place of rapid technological change. Newly graduated engineers often find themselves working in teams with people very different from themselves, where they must engage in more entrepreneurship and integrative thinking. Although PBSL opportunities are expanding at educational institutions nationwide, much of the findings on their impacts are anecdotal and qualitative. Some faculty have begun to assess PBSL programs and have found that PBSL does, in fact, cultivate stronger learning outcomes, entrepreneurship, cultural awareness, and community-mindedness. However, comprehensive and rigorous assessment methods have not yet been implemented (Bielefeldt, et al., 2008). Also, given that the number of students participating in PBSL activities may be small or unrepresentative of the undergraduate engineering student population at large, it is difficult to draw conclusions that can be generalized about this promising instructional strategy. One example of incorporating PBSL into engineering curriculum is the SLICE (Service-Learning Integrated throughout the College of Engineering) program at UMass Lowell, where all engineering students are exposed to service-learning in every semester (Duffy, et al., 2009). Extracurricular programs like Engineers Without Borders, Engineers for a Sustainable World, and Engineering World Health provide other opportunities for engineering students to participate in PBSL while providing a direct benefit to a target community – most often a developing or underdeveloped community outside the U.S. A drawback to these extracurricular programs is that participation is difficult for many engineering students and faculty. Barriers to participation include cost and time of travel, difficulty in operating and maintaining projects, and language and cultural differences that must be understood before any design work can begin. Because it is typically easier for students and faculty to become involved with local communities, implementing PBSL into existing university courses makes the benefits of this instructional strategy immediately accessible to a broader audience. We have our own communities in need within the U.S., so it makes sense to apply our resources to help communities close to home. In either case, the benefits of PBSL should be similar. One of the main differences between project-based service-learning and conventional projectbased learning is the addition of a community as a full partner. This added authenticity adds “real world complexity”, causing the project outcomes to be less defined initially (Bielefeldt, et al., 2008). This challenges students to “use their functional skills related to technology along with their critical thinking and interpersonal skills to gain an understanding of the problems they must solve in their projects” (Brescia, et al., 2009). The integration of technical skills to dynamic environments challenges students to immediately apply and make sense of what they have learned in the classroom. This process has shown to promote four areas of outcome, including personal efficacy, awareness of the surrounding environment, personal value identification, and a greater engagement with the learning content (Astin, et al., 2000). Now let’s turn to motivation theory – the second leg of the theoretical framework for this research. Motivation is a theoretical construct to explain the reason or reasons we engage in a particular behavior (Barkley, 2010). According to Brophy, students enter a “state” of motivation to learn when their engagement in a particular activity is guided by the intention of acquiring the knowledge or mastering the skill that the activity is designed to teach. Motivation, then, is so highly valued because it produces. Hence, it is of paramount concern to educators, who are constantly tasked with inducing students to learn, perform, and persist. Fortunately, educators need not resign themselves to the role of passive observers to students’ motivational patterns. In fact, educators can be active socialization agents capable of stimulating the general development of student motivation and its activation in particular situations (Brophy, 1987). What is the connection between PBSL and student motivation? That, in a nutshell, is the driving question behind this study. Assessing the impact of any new instructional strategy on student motivation is a worthwhile endeavor. According to self-determination theory, people at their best have an innate inclination toward mastery, spontaneous interest, exploration, and curiosity. This “intrinsic motivation”, which is a type of motivation characterized by doing an activity for the inherent satisfaction of the activity itself, seems to be part of human nature. However, intrinsic motivation requires supportive conditions to persist (Ryan and Deci, 2000). Other theories emphasize different (although related) conditions that support or thwart motivation. But, in general, supportive conditions can include a person’s feelings of autonomy, relatedness, and competence, accompanied by a sense of interest and value. Hence, we see that motivation is not a single construct; rather, it is a synthesis of many constructs. The table below presents several of these constructs and their relationship to the learning context of PBSL, where some of these motivation constructs seem to emerge naturally. Table 1: Connections between motivation and PBSL Constructs of Motivation Characteristics of PBSL Autonomy: characterized by choice, acknowledgement of feelings, and opportunities for self-direction. A sense that one’s actions are selfdetermined, or self-authored (Ryan and Deci, 2000). As opposed to more traditional engineering projects that often spell out the design challenge and much of the required solution (i.e. “design a spring-powered machine to launch a tennis ball 50 yards”), PBSL is inherently more open-ended due to the “realworld” context. That there may be a number of feasible solutions to a service-learning project gives students greater freedom to pursue a design solution that resonates with their skills and interests, hence directing their own learning. Relatedness: caring for and being cared for by others, Preliminary research carried out by the authors showed that most students felt somewhat a part of their university community but having a sense of belongingness , both with other individuals, and one’s own community (Deci and Ryan, 2002). very little a part of a greater community. PBSL can help students see that their engineering talent is an essential aspect to improving people’s quality of life in the greater community, hence enhancing feelings of relatedness. Competence: feeling effective in one’s interactions with the social environment and experiencing opportunities to exercise and express one’s capacities (Deci and Ryan, 2002). PBSL requires a breadth of skills, including non-technical engineering skills (i.e. the ability to work with a client, the ability to present ideas to a non-technical audience) that may not be emphasized in traditional engineering projects. This gives students with strong non-technical skills (those who may take the back seat in traditional engineering group projects) the opportunity to further develop and demonstrate their competence. At the same time, PBSL can be just as technical as traditional engineering projects to ensure students with stronger technical skills will also feel effective. Value: the belief that the learning task is relevant to satisfying personal goals (Vanasupa, et al., 2009). Engineering students, like any other subset of people, have",,2011.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
dc7ae05bd6a4104aa96a2c59e92a390f99c24de5,https://www.semanticscholar.org/paper/dc7ae05bd6a4104aa96a2c59e92a390f99c24de5,Internet of things for health and well-being applications,"The Internet of Things (IoT) has become one of the most disruptive revolutions since the advent of the Internet. The IoT brings a shift from a network of personal computers towards a network of systems and devices of a diverse nature which touches upon many aspects of daily life and affects most industries globally. IoT has the capability of augmenting our lives by completely reshaping the world and our interactions with it as we know them. IoT arrives at a time where healthcare and wellbeing needs are a rising demand, with a growingly ageing society in seek of care. Given this demand, IoT technologies have been applied to this domain to increase the quality of health care and overall well-being while reducing related costs and overheads. Examples of this include: IoT-enabled residential environments to provide assisted living for dementia suffers, well-being monitoring and intervention powered by low-cost sensing devices, and quantification of the self. This special collection accepted eight articles submitted by authors from Chile, Mexico, Slovakia, Spain, and the United States of America after undergoing a rigorous peer-review process. These articles bring together the latest experiences, findings, and developments on IoT for the provision of personalised health and well-being services. IoT infrastructures are of great interest because some of them can facilitate obtaining data about potential users or patients unobtrusively. This is particularly true in settings where users must go by their day-to-day activities without much interference. In this direction, López-Nava and Muñoz-Meléndez proposed the use of wearable inertial sensors in combination with machine learning models to detect a set of activities of daily living, such as functional mobility, and instrumental activities of daily living, like preparing meals. These activities are performed by test subjects in their homes in naturalistic conditions, thus transcending from standard in-the-lab studies. González et al. developed and validated a wearable IoT infrastructure for characterising gait in older adults in elderly care homes, in which they used inertial sensors positioned on the upper back of older adults. They validated the proposed infrastructure by carrying out a cross-sectional study with 81 older adults in two nursing homes in Spain. This very problem is also approached by Kessler et al. through the use of similar sensors but embedded directly into the floor. Instead of measuring the inertia of the body, the authors characterised the walking patterns by measuring and analysing the vibrations generated on the floor by the users’ footsteps. López-Medina et al. produced a solution which aims to detect falls in at-risk populations. This involved the use of privacy-preserving, low-resolution, thermal vision sensors intended to be mounted to the ceiling of a domiciliary area. Data from these sensors were processed in real-time using a variety of convolutional neural network architectures which were turned to detect a representation of a fallen individual within a perceived area. This was evaluated and was shown to perform with a high level of accuracy. Smartphones stand out as possibly the richest IoT sensor ecosystems to date. These devices are standardly instrumented with a wide spectrum of hardware and software sensors that can be used in multiple applications. Remarkable efforts have been devoted in recent years to develop frameworks to facilitate the widespread use of smartphones in health and well-being studies as mobile sensing infrastructures. Felix et al. presented a novel tool that leverages mobile phones not only to collect data via their sensors but also to process them on the device as soon as they are gathered. The framework allows researchers to easily configure the required processing routines on mobile phones remotely. In doing so, this work proposes a new approach for rapid deployment of sensing campaigns targeted at scientists with basic technical knowledge and requiring low effort. One major goal of a relevant number of IoT-based health solutions is to change behaviour effectively. Rossel et al. devised, developed, and evaluated a wearable system which assists with the cessation of smoking particularly. The solution developed a low-cost device that may be worn on the body or affixed to the clothing. This device detects levels of atmospheric factors indicating smoke or secondhand smoke. The device is",Int. J. Distributed Sens. Networks,2021.0,10.1177/1550147721999986,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8224ca005f3671b88222e83ca4c62291f9bebce3,https://www.semanticscholar.org/paper/8224ca005f3671b88222e83ca4c62291f9bebce3,Technological Transformation Processes and Organizational Learning-Limits to Collaboration,"INTRODUCTION In the process of technical transformation, the management of technological learning is an important aspect of organizational change. For decades, neoclassic economic theory has treated technological change in organizations as a black box. A growing interest in technological change and economic growth has outlined a superficial functionalist view on the processes of technical change, perceiving business firms as following a specific technological trajectory defined by the set of routines and competences generated over the years (Nelson & Winter, 1982; Dosi, 1982). Organizational competences are to be conceptualized as institutionalized bodies of knowledge, or routines, determined by norms and values originating from professional training systems and institutions. Hence, future decisions concerning technological choices are constrained by organizational routines developed in the past. Therefore, we must view firms as embedded, or specialized, in certain technological repertories, or paths, that keep them relatively rigid in relation to the implementation of new technologies (Teece et al., 1990; Karnoe, 1995; Nicolini & Meznar, 1995). Which trajectory to follow is determined by external relations, i.e. formal and informal networks. Thus, the links between individuals, institutions and business firms are important analytical benchmarks, as individual behaviour and interaction form the institutional and industrial patterns that constitute a given technological trajectory. Therefore, we will emphasize social interaction, i.e. interaction binding individuals to individuals, individuals to institutions, and institutions to other institutions (Fruin, 1994; Granovetter, 1992). Emphasis should be given to the role of individuals or groups of actors, e.g. communities of practitioners in order to identify historical paths in the deployed strategies for search and learning (Constant, 1984; Teece et al., 1990; Rosenberg, 1994; Fouts & Brown, 1995). AN ACCIDENTAL MEETING WITH BIOTECHNOLOGY Since 1934, Rynkeby has been a product oriented firm with no formal research activities. Technological and engineering problems are solved through extensive network relationships with the Danish dairy sector and machine shops. Over the years, these relationships have evolved, partly due to careful recruitment of dairy technicians. In 1977, the technical director of Rynkeby, a trained engineer, met an old student acquaintance who worked at Novo Nordisk (1). Talking about their jobs, they also discussed the possibilities of 1 producing protein enriched foodstuffs through the traditional enzymatic process, hydrolyzation. Novo had developed an enzyme, alkalase, that could be used as a catalyst for protein enrichments. (2) The technical director convinced the owner of Rynkeby, Dagmar Andreasen, to initiate a development project aimed at creating a line of protein enriched fruit juices for the Danish health care sector. The project appeared promising, not only would a protein enriched juice address certain nutrition problems in the elderly care sector, but could also shorten hospital stays for patients, who had undergone surgery. Furthermore, the protein might have other applications (e.g., for pharmaceuticals and as an ingredient in a variety of foodstuffs). Finally, idealistically, the owner of the company believed that, in the long term perspective, the protein might help to solve some of the third world countries' hunger problems (Andreasen, 1984). (3) In developing the project, Rynkeby had to establish some research and scientific alike relationship to the world's largest single manufacturer of industrial enzymes, Novo Nordisk. Novo Nordisk was to assist Rynkeby technically in building an experimental plant. From this point, Rynkeby should be able to handle the development of a large scale production plant. Since the enzyme alkalase was a well known product, and the process of hydrolyzing soy protein were well described in scientific journals, both Novo Nordisk and Rynkeby thought that development project would only take a few months. …",,1997.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
924420707edd1e75b735b577b7dc4ff2a2cf1932,https://www.semanticscholar.org/paper/924420707edd1e75b735b577b7dc4ff2a2cf1932,Cybertrust: From Explainable to Actionable and Interpretable AI (AI2),"To benefit from AI advances, users and operators of AI systems must have reason to trust it. Trust arises from multiple interactions, where predictable and desirable behavior is reinforced over time. Providing the system’s users with some understanding of AI operations can support predictability, but forcing AI to explain itself risks constraining AI capabilities to only those reconcilable with human cognition. We argue that AI systems should be designed with features that build trust by bringing decision-analytic perspectives and formal tools into AI. Instead of trying to achieve explainable AI, we should develop interpretable and actionable AI. Actionable and Interpretable AI (AI2) will incorporate explicit quantifications and visualizations of user confidence in AI recommendations. In doing so, it will allow examining and testing of AI system predictions to establish a basis for trust in the systems’ decision making and ensure broad benefits from deploying and advancing its computational capabilities. Decision Making: Humans and Artificial Intelligence (AI) “Can I trust the recommendation of an AI agent?” This question is difficult to answer, especially if the decision at stake is complex and spans different spatial and temporal scales. Such difficulty is exacerbated when the outcomes of an AI-influenced decision may heighten existing risks to humans or introduce new risks altogether. Yet such high-stakes situations have become routine within the diverse systems that currently incorporate AI, like controls for chemical plants, defense systems, and health insurance rate determinations. Stakeholders must be prepared not only to configure AI and its enabling technologies for a given industry or activity, but also to have tools and methodologies to examine and recognize its failures, limitations, and needs for quality control at various stages of its development and implementation. The ultimate goal of AI is to provide users with actionable recommendations that meet both implicit and explicit goals of the decision makers and stakeholders. Recommendations generated from AI-based This is a preprint version of the paper by Igor Linkov, Stephanie Galaitsi, Benjamin D. Trump, Jeffrey M. Keisler, and Alexander Kott, ""Cybertrust: From Explainable to Actionable and Interpretable Artificial Intelligence,"" IEEE Computer, Sept. 2020, pp. 91-96, vol. 53 DOI Bookmark: 10.1109/MC.2020.2993623 ................................. approaches hold advantages over human decision makers through their ability to analyze vast bodies of information in limited time in an objective and logic-centered fashion. In many situations, these benefits are clear and already implemented in practice, such as machine learning systems for the detection of phishing attempts [Khonji et al. 2013]. AI applications are also capable of providing multistep and adaptable strategies, as demonstrated by programs that compete in chess or Go, as well as AI-based cybersecurity systems [Al-Shaer et al. 2019; Kott et al. 2019] However, AI recommendations may not account for decision maker values or specific mission needs. For example, following a cyberattack, an AI-generated decision engine may recommend disabling an application on the compromised computer system. Such an action may neutralize the threat posed by the compromised system, but could simultaneous endanger a mission, negatively impact a critical user, or enable the adversary to extend the duration or scope of the cyberattack. The broader scale impacts of the recommended path forward may not have been incorporated into the AI’s design or scope, causing the AI decision processes to omit critical conditions that a human operator would implicitly account for. Such incomplete scoping of AI-driven analysis is especially problematic when unspoken, unacknowledged, or subjective variables influence or shape what a successful outcome looks like. For example, an AI system may not account for the need for a particular asset to be available to achieve a mission later on, or for psychological impact on the system’s users. The AI solves the problem it is given, but it the human’s role to ensure the recommendation’s suitability in context. Similarly, the human users making this judgment will benefit from understanding the factors that produced the AI’s decision, especially when that understanding helps the users see the value of factors they themselves could have overlooked. While AI-driven analysis enhances our decision making ability, providing insight into AI’s shifts in its analysis of needs, expectations, and mission requirements will ensure its decisions’ relevance and credibility and make its expectations for the future explicit. If AI’s analytical outputs do not account for these and other broader and potentially subjective concerns, an overly myopic focus upon a tactical decision can derail strategic mission requirements. As such, a more effective deployment of AI into decision making must resolve the ‘black box’ concerns of AI – in that it is unclear how to explain, interpret, or act upon AI’s conclusions as its underlying algorithm and parameters are difficult to decipher. Inevitable Disagreements: The Challenge of Fusing Human and AI Decision Making Capabilities We can expect AI recommendations to differ, in some percentage of circumstances, from the choice the operator alone would have made. There are three possibilities on how this plays out for any yes/no decision: the AI is more risk-averse than the human, the AI is more risk-tolerant than the human, or the AI and the human agree (Table 1).",ArXiv,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
961cd39ccd64c0dabad1f4f2a1907f73f5fedb7c,https://www.semanticscholar.org/paper/961cd39ccd64c0dabad1f4f2a1907f73f5fedb7c,PhD Thesis Title: Vector Extrapolation and Guided Filtering Methods for Improving Photoacoustic and Microscopic Images,"Photoacoustic imaging is a non-invasive imaging methodology which combines the benefits of optical contrast and ultrasonic resolution. It is applied widely for monitoring tissue health conditions in the fields of cardiology, ophthalmology, oncology, dermatology, and neurosciences. The photoacoustic tomographic image reconstruction problem is typically ill-posed and requires model-based iterative algorithms. The microscopic image analysis of pathological slides is considered as a gold standard for medical diagnosis. To acquire good quality images, one needs to deploy high-cost microscopes, which leads to increase in the cost and hence becomes prohibitive to have utility in low-resource settings. The low-cost microscopic image has low quality due to its inability to acquire focused stacks. The thesis deploys methods based on vector extrapolation and guided filtering to improve photoacoustic and histopathology (microscopic) images. The limited data photoacoustic tomographic image reconstruction problem is known to be illposed and hence the iterative reconstruction methods were proven to be effective in terms of providing good quality initial pressure distribution. Often, these iterative methods require a large number of iterations to converge to a solution, in turn making the image reconstruction procedure computationally inefficient. Two variants of vector polynomial extrapolation techniques were proposed to accelerate two standard iterative photoacoustic image reconstruction algorithms, including regularized steepest descent and total variation regularization methods. It was shown using numerical and experimental phantom cases that the extrapolation methods, proposed in this thesis, can provide significant acceleration (as high as 4.7 times) along with added advantage of improving reconstructed image quality. Several algorithms exist to solve the photoacoustic image reconstruction problem depending on the expected reconstructed image features. These reconstruction algorithms promote typically one feature, such as being smooth or sharp, in the output image. Combining these features using a guided filtering approach was proposed, which requires an input and a guiding image. This approach acts as a postprocessing step to improve the commonly used Tikhonov or total variational regularization method. The result obtained from linear back projection was used as a guiding image to improve these results. Using both numerical and experimental cases, it was shown that the proposed guided filtering approach was able to improve (as high as 11.23 dB) the signal-to-noise ratio of the reconstructed images with added advantage while being computationally efficient. This approach was compared with state-of-the-art basis pursuit deconvolution as well as standard denoising methods and outperformed them. Microscopic analysis of pathological slide smears is the gold standard for medical diagnosis, therefore the research community is making efforts towards low-cost image acquisition and automated computational analysis equipment that is especially suitable for developing countries. However, the requirement of the images being very well in focus may not be met with these equipment and thus image enhancement methods that can compensate for this shortcoming gain critical importance. A guided filtering (GF) based approach was proposed for enhancement of outof-focus microscopic images of human blood smear slides containing healthy and malaria infected Red Blood Cells (h-RBCs and i-RBCs) and PAP smears. Comparisons have also been made with a histogram-equalization method for image enhancement (CLAHE), RIQMC-based optimal histogram matching (ROHIM), modified L0 based method and the proposed guided filtering method has been shown to outperform these methods. The guided filtering enhanced images lead to better segmentation accuracy and visual quality compared to the native ones. Both these traits are necessary to perform automated diagnosis via image processing and machine learning and hence the method proposed in this thesis work can play an important role towards the goal of universal healthcare. This thesis work aims at improving the photoacoustic tomography images as well as histopathological microscopic images, where quality of images is an important factor to provide correct diagnosis. The thesis work proposed fast and improved post-processing methods for photoacoustic and microscopic images, especially in cases these images tend to be noisy. The central theme of this thesis work was to improve the quality of photoacoustic/microscopic images obtained in limited/low-quality data scenarios. In microscopy, the low-cost apparatus used for obtaining the microscopic images are often corrupted with noise and provide very limited diagnostic accuracy, especially with automated algorithms. Various methods were proposed and systematically evaluated for performing post-processing of the data obtained using these limited data and low-quality data scenarios for photoacoustic and microscopic images. References to author publications that relate specifically to the dissertation: 1. Navchetan Awasthi, K. Ram Prabhakar, Sandeep Kumar Kalva, Manojit Pramanik, R. Venkatesh Babu, and Phaneendra K. Yalavarthy, ""PA-Fuse: A Deep Supervised Approach for Fusion of Photoacoustic Images with Distinct Reconstruction Characteristics,"" Biomedical Optics Express 10(5), 2227-2243 (2019). [doi: 10.1364/BOE.10.002227] 2. Navchetan Awasthi, Sandeep K. Kalva, Manojit Pramanik, and Phaneendra K. Yalavarthy, “Image Guided Filtering for Improving Photoacoustic Tomographic Image Reconstruction,” Journal of Biomedical Optics 23(9), 091413 (2018). [doi: 10.1117/1.JBO.23.9.091413] 3. Navchetan Awasthi, Sandeep K. Kalva, Manojit Pramanik, and Phaneendra K. Yalavarthy, “Vector Extrapolation Methods for Accelerating Iterative Reconstruction Methods in LimitedData Photoacoustic Tomography,” Journal of Biomedical Optics 23(7), 071204 (2018).[doi: 10.1117/1.JBO.23.7.071204] 4. Navchetan Awasthi, Prateek Katare, Sai Siva Gorthi, and Phaneendra K. Yalavarthy, “Guided filter based image enhancement for focal error compensation in low cost automated histopathology microscopic system,” Journal of Biophotonics (2020). [doi: 10.1002/jbio.202000123].",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b2ff8b7ee3502446e1893be17be01a9177822712,https://www.semanticscholar.org/paper/b2ff8b7ee3502446e1893be17be01a9177822712,"Remaining Useful Life Estimation for LFP Cells in Second Life Applications /Author=Sanz-Gorrachategui, Ivan; Pastor-Flores, Pablo; Pajovic, Milutin; Wang, Ye; Orlik, Philip V.; Bernal-Ruiz, Carlos; Bono-Nuez, Antonio; Artal-Sevil, JesÃos Sergio /CreationDate=April 4, 2021 /Subject=Machine Learning,","The increasing deployment of battery storage applications in both grid storage and electric vehicle fields is generating a vast used battery market. These batteries are typically recycled but could be reused in Second Life applications. One of the challenges is to obtain an accurate Remaining Useful Life (RUL) estimation algorithm, which determines whether a battery is suitable for reuse and estimates the number of second life cycles the battery will last. In this paper, the RUL estimation problem is considered. We propose several Health Indicators (HI), some of which have not been explored before, along with simple yet effective estimation and classification algorithms. These algorithms include classification techniques such as Regularized Logistic Regression (RLR), and regression techniques such as Multivariable Linear Regression (MLR) and Multi-Layer Perceptron (MLP). As a more advanced solution, a multiple expert system combining said techniques is proposed. The performance of the algorithms and features is evaluated on a recent Lithium Iron Phosphate (LFP) dataset from Toyota Research Institute. We obtain satisfactory results in the estimation of RUL cycles with errors down to 49 RMSE cycles for cells that live up to 1200 cycles, and 0.24% MRE for the prediction of the evolution of capacity. IEEE Transactions on Instrumentation and Measurement c © 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. Mitsubishi Electric Research Laboratories, Inc. 201 Broadway, Cambridge, Massachusetts 02139",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
64e29d129df83dc3c5bf699f6610ed0cb16fdaed,https://www.semanticscholar.org/paper/64e29d129df83dc3c5bf699f6610ed0cb16fdaed,A Framework for Enhancing the Query and Medical Record Representations for Patient Search,"This thesis focuses on enhancing the search of electronic medical records (EMRs), with the aim of identifying patients with medical histories relevant to the medical conditions stated in a text query. During retrieval, a healthcare practitioner indicates a number of inclusion criteria describing the medical conditions of the patients of interest. However, finding patients with particular medical conditions is challenging, due to the implicit knowledge inherent within the patients' medical records and queries - such knowledge may be known by medical practitioners, but may be hidden from an information retrieval (IR) system. For instance, the mention of a treatment such as a drug may indicate to a practitioner that a particular diagnosis has been made for the patient, but this diagnosis may not be explicitly mentioned in the patient's medical records. Moreover, the use of negated language (e.g. 'without', 'no') to describe a medical condition of a patient (e.g. the patient has no fever) may cause a search system to erroneously retrieve that patient for a query when searching for patients with that medical condition (e.g. find patients with fever). To attain effective retrieval performance, we hypothesise that, in a patient search system, both the information needs and patients' histories should be represented based upon the medical decision process. In particular, this thesis argues that since the medical decision process typically encompasses four aspects (symptom, diagnostic test, diagnosis and treatment), a patient search system should take into account these aspects and apply inferences to recover the possible implicit knowledge. We postulate that considering these aspects and their derived implicit knowledge at three different levels of the retrieval process (namely, sentence, medical record and interrecord levels) enhances the retrieval performance. Indeed, we propose a novel framework that can gain insights from EMRs and queries, by modelling and reasoning upon informationduring retrieval in terms of the four aforementioned aspects at the three levels of the retrieval process, and can use these insights to enhance patient search. Firstly, at the sentence level, we extract the medical conditions in the medical records and queries. In particular, we propose to represent only the medical conditions related to the four medical aspects in order to improve the accuracy of our search system. In addition, we identify the context (negative/positive) of terms, which leads to an accurate representation of the medical conditions both in the EMRs and queries. In particular, we aim to prevent patients whose EMRs state the medical conditions in the contexts different from the query from being ranked highly. For example, preventing patients whose EMRs state ""no history of dementia"" from being retrieved for a query searching for patients with dementia. Secondly, at the medical record level, using external knowledge-based resources (e.g. ontologies and health-related websites), we leverage the relationships between medical terms to infer the wider medical history of the patient in terms of the four medical aspects. In particular, we estimate the relevance of a patient to the query by exploiting association rules that we extract from the semantic relationships between medical terms using the four aspects of the medical process. For example, patients with a medical history involving a CABG surgery (treatment) can be inferred as relevant to a query searching for a patient suffering from heart disease (diagnosis), since a CABG surgery is a treatment of heart disease. Thirdly, at the inter-record level, we enhance the retrieval of patients in two different manners. First, we exploit knowledge about how the four medical aspects are handled by different hospital departments to gain a better understanding about the appropriateness of EMRs created by different departments for a given query. We propose to aggregate EMRs at the department level (i.e. inter-record level) to extract implicit knowledge (i.e. the expertise of each department) and model this department's expertise, while ranking patients. For instance, patients having EMRs from the cardiology department are likely to be relevant to a query searching for patients who suffered from a heart attack. Second, as a medical query typically contains several medical conditions that the relevant patients should satisfy, we propose to explicitly model the relevance towards multiple query medical conditions in the EMRs related to a particular patient during retrieval. In particular, we rank highly those patients that match all the stated medical conditions in the query by adapting coverage-based diversification approaches originally proposed for the web search domain. Finally, we examine the combination of our aforementioned approaches that exploit the implicit knowledge at the three levels of the retrieval process to further improve the retrieval performance by adapting techniques from the fields of data fusion and machine learning. In particular, data fusion techniques, such as CombSUM and CombMNZ, are used to combine the relevance scores computed by the different approaches of the proposed framework. On the other hand, we deploy state-of-the-art learning to rank approaches (e.g. LambdaMART and AdaRank) to learn from a set of training data an effective combination of the relevance scores computed by the approaches of the framework. In addition, we introduce a novel selective ranking approach that uses a classifier to effectively apply one of the approaches of the framework on a per-query basis. This thesis draws insights from a thorough evaluation and analysis of the proposed framework using a standard test collection provided by the TREC Medical Records track. The experimental results show the effectiveness of the framework. In particular, the results demonstrate the importance of dealing with the implicit knowledge in patient search by focusing on the medical decision criteria aspects at the three levels of the retrieval process.",SIGIR Forum,2015.0,10.1145/2795403.2795420,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
44895ec003ae7fa4675b25c1e5fede4cfcc7b3bd,https://www.semanticscholar.org/paper/44895ec003ae7fa4675b25c1e5fede4cfcc7b3bd,"Automated Clinical Coding: What, Why, and Where We Are?","Clinical coding is the task of transforming medical information in a patient’s health records into structured codes so that they can be used for statistical analysis. This is a cognitive and time-consuming task that follows a standard process in order to achieve a high level of consistency. Clinical coding could potentially be supported by an automated system to improve the efficiency and accuracy of the process. We introduce the idea of automated clinical coding and summarise its challenges from the perspective of Artificial Intelligence (AI) and Natural Language Processing (NLP), based on the literature, our project experience over the past two and half years (late 2019 early 2022), and discussions with clinical coding experts in Scotland and the UK. Our research reveals the gaps between the current deep learning-based approach applied to clinical coding and the need for explainability and consistency in real-world practice. Knowledge-based methods that represent and reason the standard, explainable process of a task may need to be incorporated into deep learning-based methods for clinical coding. Automated clinical coding is a promising task for AI, despite the technical and organisational challenges. Coders are needed to be involved in the development process. There is much to achieve to develop and deploy an AI-based automated system to support coding in the next five years and beyond. Figure 1. An example of clinical coding, manual and automated (linked with solid and dashed arrows, respectively), with ICD-9-CM codes from a clinical note in the MIMIC-III dataset [9] of ICU patients in 2001-2012 in a hospital in the US. Dashed arrows between clinical coders and the automated coding system suggest potential interactions between them, while this is yet to be considered in many clinical coding systems. Note that the format of data and clinical codes does not reflect the situation of other regions in the world for example, in the UK, where data may be less structured and there is no universal discharge summary available. 1 The icon of “Clinical Coders” was from Freepik in Flaticon, https://www.flaticon.com/free-icon/user_747376, under the Flaticon licence (attribution required). The icon of “Automated Coding System” was from https://iconlibrary.com/png/272370.html, under the Attribution 3.0 Unported (CC BY 3.0) licence. Introduction: what is (automated) clinical coding? Clinical coding is the task of transforming medical records, usually presented as free texts written by clinicians, into structured codes in a classification system like ICD-10 (International Classification of Diseases). For example, in Scotland, this means to apply a standard process to classify information about patients into appropriate diagnosis and procedure codes in ICD and OPCS, finally contributing to the Scottish Morbidity Records (SMR01) national dataset. The process of coding usually includes data abstraction or summarisation [1]. The purpose of clinical coding is to provide consistent and comparable clinical information across units of care and over time. The resulting national data are used to support areas, such as health improvement, inform healthcare planning and policy and add to the epidemiological understanding of a wide variety of conditions, so confidence in the data is essential. Also, codes are used for billing purposes in the US. For introductory slides about clinical coding in the UK provided by NHS Digital, see Clinical coding for non coders. Clinical coding is a non-trivial task for humans. An expert clinical coder is expected to decipher a large number of documents about a patient’s episode of care, and to select the most accurate codes from a large classification system (or an ontology), according to the contexts in the various documents and the regularly updated coding guidelines. For example, coding in the US adopts the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM), which has around 68,000 codes. There is a standard process for manual coding to ensure data consistency: textual analysis, summarisation, and clearly defined steps to classification into codes (or the four steps of analyse, locate, assign, and verify as suggested by the NHS digital in the coding standard of 2021 [2, p.11]). The process minimises the risk of introducing variations caused by artefacts (potentially leading to wrong decision making), thus collecting and analysing data and applying the standard is important. There are regularly updated guidelines and standards for coding (e.g., in Public Health Scotland). Usually, it can take months and longer to train an expert clinical coder in the NHS (National Health Service) in the UK. Automated clinical coding is the idea that clinical coding may be automated by computers using AI technologies [3]. It is a branch of computer-assisted coding (CAC) [4]. In recent years, AI has been considered as a promising approach to transforming healthcare by intelligently processing the increasing amount of data with machine learning and NLP techniques [5]. Automated clinical coding is a potential AI application to facilitate the administration and management of clinical records in the hospital and medical research. There has been a surge of articles for automated clinical coding with deep learning (as the current mainstream approach of AI) for the last few years, as reviewed in [6-8]. However, while there is some progress for automated clinical coding, the task is far from solved. For the last two years and more, we have been working on the task and discussing with practitioners of clinical coding and clinicians from Scotland and the UK. We illustrate the manual and automated clinical coding process, and their potential interactions, in Figure 1. In this paper, we aim to summarise the technical challenges of clinical coding, mainly related to deep learning, and propose directions for future research in this area. Why do we need automated clinical coding? There are some major reasons that automated clinical coding can be helpful. First, manual coding is time-consuming. A clinical coder in NHS Scotland usually codes about 60 cases a day (equivalent to 7-8min for each case) and an NHS coding department of around 25 to 30 coders usually codes over 20,000 cases per month. Even so, there is a backlog of cases to be coded, which can take several months or more (e.g., over a year [10]). Second, manual coding may be prone to errors. This may be due to incompleteness in a patient’s data, subjectivity in choosing the diagnosis codes, lack of coding expertise, or data entry errors [1]. The average accuracy of coding in the UK was around 83% with a large variance among studies (50-98%) [11]. In Scotland, the accuracy of coding is very high (e.g. in 2019-2020, achieved 92.5% for 3-digit code accuracy and 88.8% for 4-digit code accuracy of main conditions), yet still not perfect and under-coding occurs (for around 20% of the common conditions). On the other hand, computer-assisted coding could improve the accuracy, quality, and efficiency of manual coding, according to a recent, qualitative literature 2 https://www.ndc.scot.nhs.uk/National-Datasets/data.asp?SubID=5 3 https://www.aapc.com/medical-coding/medical-coding.aspx 4 https://hscic.kahootz.com/gf2.ti/f/762498/30719205.1/PPSX/-/Coding_for_non_coders_automaticnew.ppsx 5 https://www.isdscotland.org/Products-and-services/Terminology-services/Clinical-coding-guidelines/ 6 https://beta.isdscotland.org/media/7465/assessment-of-smr01-data-scotland-report-2019-v1.pdf review [4]. We believe that with recent AI technologies (for example, NLP), automated coding has the potential to better support clinical coders. We mostly focus on the case that AI directly contributes to clinical codes. Why is automated coding a complex problem to solve? While humans can achieve high accuracy in clinical coding, the standard procedure, text analysis, text summarisation, and classification into codes, poses immense challenges for computer-based systems. This requires Natural Language Understanding (NLU), one of the classical but largely unsolved areas of AI [12-13], and the linking of natural language to knowledge representations like the ICD-10 classification system. Also, this clinical task poses more specific challenges compared to common NLU tasks. From our experience, these relate mainly to the following difficulties: 1. Clinical documents are variously structured, notational, lengthy, and incomplete. Clinical coding requires the understanding of texts in clinical documents, which is usually different from other types of documents like publications or texts from social media. They have variable document structures, they can be lengthy (on average around 1500 words [14] in only the discharge summaries in a US intensive care dataset, MIMIC-III [9]), and use variable abbreviations (e.g., “a [xx] y/o M w/ Hep C, HTN, CKD, a/w HTN emergency” in a discharge summary in MIMICIII) and terse symbols (e.g., the use of “?” to denote uncertainty and “+” to denote a positive test). Coding also requires the understanding of the entirety of a patient’s records, which includes multiple types of documents (e.g. discharge summaries, radiology reports, pathology reports, etc.). These documents are not always in a structured format and are sometimes incomplete or missing. 2. Classification systems used for coding are complex and dynamic. The ICD-10-CM system has around 68,000 codes in a large hierarchy. The ICD-11 system (started in Jan 2022, but yet to be used in practice at the time of writing) introduces significant changes in chapter structure, diagnostic categories, diagnostic criteria, etc. [15] Besides, classification standards are updated regularly (e.g. usually every few months in Public Health Scotland). Automated clinical coding needs to work with dynamic and complex classification systems. 3. The social-technical issues with automated clinical coding systems ",ArXiv,2022.0,10.48550/arXiv.2203.11092,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
02c6278b0aa5ab8687ba02a68520e961343d2202,https://www.semanticscholar.org/paper/02c6278b0aa5ab8687ba02a68520e961343d2202,ARX Model of a Residential Heating System With Backpropagation Parameter Estimation Algorithm,"Model predictive control (MPC) strategies hold great potential for improving the performance and energy efficiency of building heating, ventilation, and air-conditioning (HVAC) systems. A challenge in the deployment of such predictive thermostatic control systems is the need to learn accurate models for the thermal characteristics of individual buildings. This necessitates the development of online and data-driven methods for system identification. In this paper, we propose an autoregressive with exogenous terms (ARX) model of a thermal zone within a building. To learn the model, we present a backpropagation approach for recursively estimating the parameters. Finally, we fit the linear model to data collected from a residential building with a forced-air heating and ventilation system and validate the accuracy of the trained model. INTRODUCTION Heating, ventilation, and air-conditioning (HVAC) account for 43% of commercial and 54% of residential energy consumption [1]. Space heating alone accounts for 45% of all residential energy use. HVAC systems are an integral part of buildings responsible for regulating temperature, humidity, carbon dioxide, and airflow, conditions which directly impact occupant health and comfort. Estimates suggest that component upgrades and advanced HVAC control systems could reduce building energy ∗Address all correspondence to this author. usage by up to 30% [2]. Such intelligent systems can improve the efficiency of building operations, better regulate indoor conditions to improve air quality and occupant comfort, and enable buildings to participate in demand response services to improve power grid stability and reduce energy related carbon emissions [3–8]. To effectively control the operation of an HVAC system, it is essential that a model predictive controller incorporate an accurate mathematical representation of a building’s thermal dynamics. The processes that determine the evolution of temperatures within a building are complex and uncertain. A reliable model improves the ability of a controller to forecast conditions and meet cost, efficiency, and/or comfort objectives [9, 10]. Simulation software, such as EnergyPlus and TRNSYS, is capable of high fidelity modeling of building HVAC systems. These mathematical models play a crucial role in the architectural and mechanical design of new buildings, however, due to high dimensionality and computational complexity, are not suitable for incorporation into HVAC control systems [9, 11]. The American Society of Heating, Refrigeration, and AirConditioning Engineers (ASHRAE) handbook [12] describes how to determine the thermal resistance values of a building surface given it materials and construction type. However, for existing buildings, details about the materials in and construction of walls and windows may be difficult to obtain or nonexistent [13]. Additionally, modifications to the building or changes brought about by time and use (e.g. cracks in windows 1 Copyright c © 2017 by ASME or walls) further diminish the potential for characterizing a building based on design or construction information. Therefore, an ideal control-oriented model would capture the predominant dynamics and disturbance patterns within a building, enable accurate forecasting, adapt to future changes in building use, provide a model structure suitable for optimization, and be amenable to real-time data-driven model identification methods. For these reasons, low order linear models are widely employed for control-oriented thermal building models [13–15]. Such models trade complexity and accuracy for simplicity and efficiency. In this paper, we present an autoregressive with exogenous terms (ARX) model for the thermostatic control of buildings and a recursive backpropagation method for parameter estimation. The structure of the linear model enables the approximate identification of unmodeled dynamics, in particular higher-order dynamics and time delays related to changes in the mechanical state of the system. By employing a recursive parameter estimation technique, we are able to perform online data-driven learning of the model. We do not model heating from solar gain, building occupants, or equipment. This does not restrict the applicability of this work because the model structure can be extended for such cases. By estimating these effects with a single time-varying gain, we produce a simpler model better suited for predictive control. This paper is organized as follows. Section 2 presents our autoregressive exogenous thermal model and Section 3 overviews the parameter estimation problem. Section 4 formulates our recursive parameter estimation approach employing backpropagation and stochastic gradient descent. Section 5 provides numerical examples of our proposed model and algorithm for the parameter estimation of an apartment with a forced-air heating and ventilation system. Finally, Section 6 summarizes key results. BUILDING THERMAL MODEL LINEAR THERMAL MODEL In this paper, we focus on the modeling of an apartment with a forced-air heating system. To begin, we consider a simple linear discrete time model [4, 5, 16, 17] T k+1 = θaT k +θbT k ∞ +θcm k +θd (1) where T k ∈ R, T k ∞ ∈ R, and mk ∈ {0,1} are the indoor air temperature (state, ◦C), outdoor air temperature (disturbance input, ◦C), and heater state (control input, On/Off), respectively, at time step k. The parameters θa and θb correspond to the thermal characteristics of the conditioned space as defined by θa = exp(−∆t/RC) and θb = 1−exp(−∆t/RC), θc to the energy transfer due to the system’s mechanical state as defined by θb = (1− exp(−∆t/RC))RP, and θd to an additive process accounting for energy gain or loss not directly modeled. The linear discrete time model (1) is a discretization of a RCequivalent continuous time model and thus derived from (very basic) concepts of heat transfer. As noted in [5, 17], the discrete time model implicitly assumes that all changes in mechanical state occur on the time steps of the simulation. In this paper, we assume that this behavior reflects the programming of the systems being modeled. In other words, we assume that the thermostat has a sampling frequency of 1/(3600∆t) Hz or once per minute. AUTOREGRESSIVE EXOGENOUS THERMAL MODEL The linear discrete time model (1) is capable of representing the predominant thermal dynamics within a conditioned space. Unfortunately, because it does not capture any higher-order dynamics or time delays related to changes in the mechanical state of the system, the model is fairly inaccurate in practice. Research into higher-order RC models, in particular multi-zone network models and the modeling of walls as 2R-1C or 3R-2C elements, have shown potential for producing higher fidelity building models [13–15]. However, this comes at the cost of increasing the model complexity and the need for temperature sensing (in particular, within interior and exterior walls). In this paper, we present an autoregressive exogenous (ARX) model capable of approximating dynamics related to trends in the ambient temperature and to changes in the mechanical state of the system. We note that the linear discrete time model (1) is, by definition, a first-order ARX model. The distinguishing characteristic of the ARX model presented below is that the model is higher-order with respect to the exogenous input terms. By increasing the number of exogenous input terms, we can better approximate observed dynamics in the systems. However, we will not pursue a physics-based justification for the number of exogenous terms and thus the ARX model represents a slight departure from the practice of increasing the model order through RC-equivalent circuit modeling. Our autoregressive exogenous (ARX) thermal model is given by T k+1 = θaT k + s−1 ∑ i=0 (θb,iT k−i ∞ +θc,im )+θd (2) where T k ∈ R, T k ∞ ∈ R, and mk ∈ {0,1} are the indoor air temperature (state, ◦C), outdoor air temperature (disturbance input, ◦C), and heater state (control input, On/Off), respectively, at time 2 Copyright c © 2017 by ASME step k. The order of the exogenous terms (and thus the number of θb and θc parameters) is given by s. The ARX model can be expressed more compactly as T k+1 = θaT k +θ T b T k ∞ +θ T c m k +θd (3) where T k ∈ R, T∞ ∈ Rs, and mk ∈ {0,1}s are the indoor air temperature (state, ◦C), previous outdoor air temperatures (disturbance input, ◦C), and previous heater states (control input, On/Off), respectively, at time step k. Lastly, θb ∈Rs and θc ∈Rs are the parameters of the exogenous terms. PARAMETER ESTIMATION BACKGROUND A fundamental machine learning problem involves the identification of a linear mapping",,2017.0,10.1115/DSCC2017-5315,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
119a547eecefb7ee65f0fb4d3a66ad0f32099987,https://www.semanticscholar.org/paper/119a547eecefb7ee65f0fb4d3a66ad0f32099987,Dissertation title : Data-Driven Resource Optimization Schemes for Edge Devices in Smart IoT Communications,"Internet of Things (IoT) has gained tremendous popularity with the recent fast-paced technological advances in embedded programmable electronic and electro-mechanical systems, miniaturization, and their networking ability. IoT is expected to change the way of human activities by extensively networked monitoring, automation, and control. However, widespread application of IoT is associated with numerous challenges on communication and storage requirements, energy sustainability, and security. Also, IoT service quality requirements are applicationspecific. In this dissertation, we have identified novel methodologies to exploit the data-driven IoT framework for optimization of resources and development of context-aware cognitive applications in a massive machine type communication context. Through practical case studies, IoT application specific unique approaches and optimization techniques are proposed to reduce the data handling footprint, leading to communication bandwidth, cloud storage, and energy saving, without compromising service quality, thereby making them viable for wideranging adoption. In the first part of dissertation, we introduce a novel data-driven framework for data pruning in wide area monitoring and control in smart grid, which is an emerging IoT application. Due to stringent latency constraints, packet losses and end-to-end transmission delay exceeding the permitted threshold values may jeopardize the stability of power grid. However, transient occurrences in the grid are relatively sparse, and much of the data is routine monitoring data having high redundancy. The proposed framework exploits the temporal correlatedness in the consecutive samples to dynamically prevent redundant PMU data from being transmitted without affecting the quality of power grid health monitoring. The missing samples are predicted at the receiving end using ε-support vector regression model. It is noted that though PMU data has high temporal correlation, it actually characterizes a non-stationary process. Consequently, hyper-parameters of the prediction model are recomputed as necessary to maintain the accuracy and robustness of prediction. Also, for low runtime complexity, some of the hyper-parameters are precomputed using empirical optimization of offline data characteristics. Appropriate performance indices are defined to quantify the performance of the proposed algorithm, and its computational latency is estimated via online execution using Simulink model. It is found that the proposed dynamic prediction algorithm selectively transmits the PMU data, thereby achieving up to 90% reduction in channel bandwidth requirement without affecting the quality of stability monitoring of the system. Further, comparison of the proposed algorithm with the closest competitive scheme demonstrates 73% and 60% better performance, respectively, in terms of power system health monitoring and bandwidth saving. Subsequently, in the next part intelligent data pruning is investigated for automated electric metering in smart cities, which, similar to PMU data, is expected to increase the volume of network traffic exponentially. However, it does not possess the same nature of dynamics as the PMU data, and is more relaxed in terms of delay tolerance. It may be noted that as the granularity of sampling average power consumption in smart meter increases, compressibility of the data reduces, owing to irregular load profile. Besides, the data appears incoherent in time domain, though it can actually be represented by a sparsifying basis. Thus, adaptively choosing the sparsity over optimum batch size before data transmission can be utilized for substantial reduction in data volume. To this end, considering high resolution data at the smart meter, the problem of smart meter data characterization and reduction is addressed to achieve higher compression gains and reduced bandwidth requirement for data transmission from smart meter to the data collector. A novel Gaussian mixture based model is proposed for the characterization of high frequency smart meter data, which is used in evaluating the quality of data reduction at the smart meter. Further, an adaptive data reduction scheme using compressive sampling is devised to operate at the smart meter which achieves about 40% bandwidth saving in data transmission to the nearest collection center without any appreciable loss of information. Performance comparison of the proposed data reduction scheme with an existing competitive approach demonstrates noise robustness during data transmission. Additionally, to achieve the same order of RMSE, bandwidth saving with the proposed scheme is 12:8% and 7:4% higher, respectively, for data sampled at 1 second and 30 seconds. Real-time implementation of the proposed system level design is tested on smart meters deployed at IIT Delhi campus. Finally, in the last part, channel-adaptive transmission strategies based on simple yet efficient channel prediction frameworks using stochastic modeling and data-driven learning of channel variability are proposed for sporadic but time-critical PMU data. The proposed channel prediction frameworks are accompanied with adaptive channel coding that assigns redundant symbols to the packet in accordance with the current channel state. A probing-based transmission scheme is also proposed which is considered as the benchmark for comparing the stochastic modelbased and learning-based approaches. Through large-scale simulations, the prediction and packet loss performance is analyzed at varying SNR and fading conditions. The results demonstrate that, for a given channel fading condition, packet loss probability of the proposed learning-based transmission closely matches with the benchmark scheme, while with the stochastic model-based prediction the loss probability is found to be 12:3% higher. However, the respective signaling overhead requirements are 38% and 98% lower with respect to the benchmark.",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cd51bbfd51cde0c089d9dfb7d30bfc124d9b7c55,https://www.semanticscholar.org/paper/cd51bbfd51cde0c089d9dfb7d30bfc124d9b7c55,"Summary for CIFE Seed Proposals for Academic Year 2020-21 Proposal number: 2020-04 Proposal title: Hybrid Physical-Digital Spaces: Transforming the Design, Operation, and Experience of Built Environments to Promote Health and Wellbeing","up to 150 words) Increasing evidence suggests built office features (e.g., lighting, materials, and ventilation) have substantial impacts on occupant wellbeing. A key next direction is field studies at industry partner sites to examine real-world workplaces. We propose to develop innovative Internet of Things (IoT) techniques that integrate data from building instrumentation, personal device sensors, and self-report interfaces and then deploy this platform in-the-wild to capture rich, longitudinal, ecologically-valid data about the status of office workers and the spaces they occupy. Insights will advance scientific knowledge of how buildings impact wellbeing as well as produce practical implications for building designers and operators. A timely component will explore how covid-19 has temporally or fundamentally changed occupant behaviors and operational decisions (e.g., physical distancing desks and ventilation settings that reduce pathogen spread). Overall, our proposed research has the potential to transform the industry’s thinking on how built environments can be designed, operated, and experienced. Hybrid Physical-Digital Spaces: Transforming the Design, Operation, and Experience of Built Environments to Promote Health and Wellbeing Problem and Significance Considering that people in the U.S. spend 87% of their time in indoor spaces , we assert that 1 buildings are powerful yet underleveraged loci for promoting human wellbeing. Imagine an intelligent office that could adapt soundscape systems to manage noise in open floor plans, optimize space reservation or utilization to foster collaborations and save energy, or provide digital information displays that promote employee connectedness and physical activity. Towards actualizing our vision of such hybrid physical-digital spaces, our proposal strives to develop, apply, and evaluate novel scientific and engineering approaches that will transform the industry’s thinking around how built environments can be designed, operated, and experienced. Increasingly, hypotheses suggest that built features of indoor environments (e.g., lighting, materials, and ventilation) have substantial impacts on occupants (e.g., employee recruitment and retention, absenteeism, cognition, creativity, productivity, social interactions, physical activity and health, and psychological wellbeing). In turn, these individual outcomes also drive pivotal organizational outcomes such as product innovation, workforce diversity, employee turnover, market share, and profitability. Examples illustrate how building interventions can have huge impacts : enhancing employee exposure to daylight can save businesses ~$2,000/yr per capita 2 , better air quality can raise cognitive scores of workers by 101% 3 , and increasing indoor access to biophilic elements could recoup $23 billion considering 10% of workplace absenteeism (a $226 billion dollar problem) is attributable to architecture that inadequately connects to nature 4 . However, few of these hypotheses have been tested at scale, over time, and in real world conditions . Instead, most prior efforts are small sample, short-term correlational studies based on potentially biased and sparse self-reported data. A more rigorous, scientific, and human-centered approach to study and engineer buildings that promote wellbeing can have major implications at individual, organizational, and societal levels (see Figure 1), offering both foundational theoretical knowledge as well as practical strategies for building designers and operators. Figure 1. Relations among building features and human outcomes at various levels. Further, “smart buildings” today typically focus on basic sensing and control for energy savings, thermal comfort, and security. Connecting to CIFE’s Vision for the Future of Building Users, we argue buildings of the future can go beyond such bottom line outcomes to be more interactive and human-centered: aware of and responsive to occupants’ cognitive, mental, and physical feelings and needs, while respecting privacy and promoting positive indoor experiences . 1 Klepeis, et al., 2001; 2 Heschong & Mahone, 2003; 3 Allen et al., 2016; 4 Elzeyadi, 2011. <Landay-Billington> < Hybrid Physical-Digital Spaces> 1 Theoretical and Practical Points of Departure It is imperative to increase understanding of exactly what built attributes have what impacts and on whom, in a scalable, longitudinal, and inclusive manner. Thus through technology-driven assessment and hybrid physical-digital interventions, we aim to (a) fundamentally advance the science on how built environments impact human wellbeing and, in turn, (b) generate guidelines that can revolutionize the way spaces are designed, operated, and experienced . Our current scope focuses on office spaces and workers; though an overarching goal is for our developed approaches and insights to establish a foundation that enables future research with additional populations and environments (e.g., physicians and patients in clinical settings, students and teachers in classrooms, and traditionally marginalized shift and temporary workers). In particular, our reusable platform will help others study this wider range of buildings and occupants; and combining these approaches with emerging endeavors such as biophilic design and precision interventions provides a novel opportunity to not only more deeply investigate but also address long-running public health challenges and systemic inequities facing society. In these ways, we hope to positively impact a broad cross-section of stakeholders at individual, organizational, and institutional levels. Moreover, this project will support interdisciplinary fertilization across engineering, computing, psychology, law, and medicine . Research Methods and Work Plan Our research agenda is to support the design and operation of built facilities that augment human capabilities and wellbeing — and have a fundamental positive change on the way indoor spaces are experienced by the people that occupy them. By introducing intelligent systems capable of gathering and interpreting building and occupant data as well as delivering adaptive interventions in response, novel roles will also emerge for managing buildings and the activities that take place inside them. To achieve these goals, our research will comprise three main activities: 1. Developing an extensible and secure data collection and machine learning platform . A key aim of this research is scientifically examining how built spaces impact human wellbeing. To pursue this investigation and develop methods that enable buildings to be more aware of occupants’ states and needs, we have been developing pattern detection software that integrates data from (a) personal devices (smartphones, smartwatches, fitness trackers), (b) building instrumentation or portable environmental sensors (light levels, air quality), and (c) experience sampling interfaces that prompt occupants for subjective information through quick, validated self-report techniques. Figure 2 illustrates examples of these assessment components. This work involves addressing a number of technical challenges, such as selecting sampling rates and window sizes to maximize efficiency, developing methods for analyzing asynchronous and sparse sensor data, and developing privacy-sensitive feature engineering strategies for detecting and predicting wellbeing outcomes of interest. We also plan to package our platform as a reusable toolkit that can be applied by other researchers and building operators. This work is ongoing and a basic version will be ready by summer. Once development is complete, CIFE support would allow us to move onto the next critical phase: moving out of the lab and into the field. <Landay-Billington> < Hybrid Physical-Digital Spaces> 2 Figure 2. Platform to integrate data from personal devices, building sensors, and subjective self-report. 2. Deploying the platform through a mixed-method study with industry partners . The next step in our research is to deploy this platform at field sites in partnership with View, Inc. (specifically, at TIAA offices in Manhattan, this summer/fall) to capture rich, longitudinal, ecologically-valid data about behavioral, psychological, and physiological states of occupants and their everyday work environments. Our plan is to recruit a sample of approximately 150 employees for a period of 18 weeks, which will involve a baseline phase followed by systematic variation of built features (Views/No Views, Plants/No Plants, and Diversity/No Diversity in artwork) and measurement of indicators hypothesized to promote both personal wellbeing and organizational performance, based on the literature and our formative online and lab studies, described below. In combination with the engineering-focused activities to implement and install the platform, deployment will occur in tandem with ethnographic work (e.g., observations, interviews, and surveys) to manually validate reliability of the system’s automated inferences as well as gain a more qualitative portrait of occupant experiences in various spaces. Privacy-centric engagements will additionally investigate stakeholders’ attitudes regarding the capture of various types of information to derive implications about informed consent and personal data management. Along similar lines, it will be critical to responsibly manage captured data, especially potentially sensitive and exploitable data about wellness or performance. Therefore all studies will be conducted with oversight and approval from the Stanford Institutional Review Board (IRB). In addition to obtaining participants’ informed consent, we will also design sensor and data collection mechanisms to use an opt-in model, including partial participation. Our data management systems can also allow individuals to view and delete their personal data, including if purging is desired in the event of study withdrawal. Our research team has exp",,2020.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8e2db36fc1de5c190338627c50d4d82cda5e664f,https://www.semanticscholar.org/paper/8e2db36fc1de5c190338627c50d4d82cda5e664f,Computational Models & Methods in Systems,"With the current emphasis on ‘big data’ marking a new stage in the advance of biomedical sciences, improvements in computational capability, together with the impact of high throughput techniques and genome-wide methods, mean that biological and medical fields are now data-rich to a degree that was unknown a few decades ago. Increased data availability has not only highlighted the complementarity needed between biology and computer science, but has served to emphasise interdisciplinary overlap with mathematical and physical sciences in the formulation of computational models, posing of hypotheses and statistical interpretation of results. Information derived from diverse sources means that linking system behaviour to changes at cellular and molecular scales has become a viable goal, facilitated by techniques such as network theory, stochastic processes and integrative data analysis. The studies of systems of biological components, their dynamic behaviour and reliance on wide-ranging data, together with translation to disease progression and treatment options, define systems biology and medicine. The IEEE International Conference on Bioinformatics and Biomedicine (IEEE BIBM) is a well-established research conference, providing a leading forum for disseminating the latest research in bioinformatics and health informatics. It attracts contributions from both academic and industrial scientists, which range from biology and medicine, to chemistry, computer science, mathematics and statistics. In particular, and in addition to its over-arching remit and general proceedings, IEEE BIBM provides an important platform for showcasing computational and mathematical modelling methods, together with the data integration, analysis and visualisation, which underpin these. Selected and extended papers from several of their important workshops thus provide the focus of this Special Issue. The papers deal with basic model formulation, data analysis and the incorporation of these analyses in the decision-making process for clinical treatment. The algorithms and methods include ant colony optimisation (Sapin et al.) of the interactions between a number of single-nucleotide polymorphisms (SNPs). Discriminatory performance of the algorithm is found to agree well with SNP identification from large-scale genome-wide association studies for Type II diabetes. Medical image analysis is the objective for applying both evolutionary and swarm intelligence algorithms. In the former case, data classification and monitoring in Parkinson’s disease in humans is considered, together with characterisation of genetic mutations in the fruit fly vector (Smith et al.). Deployment of swarm intelligence algorithms, such as stochastic diffusion search for CT scans and X-Rays, and learning vector quantisation for identification of abnormal tumour regions in MR segmentation (al-Rifaie et al.), also demonstrate the applicability of these methods. Wong-Lin & Cullen explore the importance of dopamine as a neurotransmitter for multiple brain functions using a computational model that spans multiple levels of function and different dynamics, and lay the foundation for an integrated approach to realistic in silico simulation of dopaminergic systems in neuropharmacology. Investigation, similarly, of the relative dynamics and structure of human intestinal crypts in malignant systems, provides the motivation for the formulation of an epigenetic model using the agent-based paradigm (Roznovat & Ruskin). Epigenetics, the additional layer of inherited genome regulation, together with epigenome-wide association studies, linking intra-individual epigenetic variation, are linked to the evolution of human diseases, such as cancer, and to autoimmune and neuropsychiatric disorders. The derived computational model enables comparative analysis on aberrant DNA methylation levels in cancer development and the investigation of the effect of potential methylation inhibitors during disease initiation. Inhibitors, both time-dependent and time-independent, merit important distinction in the characterisation of compound potency and drug-response. Reversibility properties for both are investigated by means of a simple kinetic model (Yue & You) and analysis of the outcomes and their contrast with supporting numerical studies. The complexity of the drug-receptor process in this case indicates the contribution that can be made by computational modelling, as well as the need to support formulation and parameterisation with good quality data. A further example of the flexibility and scope offered by the modelling approach is provided by studies of microtubule ordering and the way in which this is affected by collision and crossover. A 3-state model is used to determine the influence of spontaneous catastrophe, crossover and ketaninmediated severing on plant microtubule ordering across different temperatures (Mace & Wang). It is evident, however, that, while many dynamic biological systems share similar properties and constraints, model specification, particularly in the context of sparse or poor experimental data, is often anything but straightforward. Achieving an unambiguous estimation of the full set of parameters is frequently challenging and may be impossible. The identifiability in this context, of typical S-System models for dynamic biological systems, is discussed with respect to an application on yeast fermentation pathway determination (Li et al.). The authors note also that, even where data are available, these may be noisy or incomplete, which also affects the identification process. When analysing such data, a range of statistical and computational methods are available. These can be categorised by their level of automation, the sophistication of their algorithms, their data type and size and so on. Bioinformatics, often described as the intersection of mathematics, biology and computer science, typically involves processing large amounts of data, so methods are usually machine-based. The paper (by Akutekwe et al.) thus describes a two-stage optimisation process in the modelling of protein-protein networks. This is applied to complex diseases, such as colorectal cancer, and discusses the performance of machine learning methods and selected algorithms, such as particle swarm optimisation and differential evolution for parameter optimisation for classification and automatic discovery of biomarkers, with Bayesian network analysis used to predict their temporal linkage. Ultimately, systems modelling and simulation-optimisation, with appropriate data analysis, can play a major role in decision-support systems for biomedical applications. The Heartsearcher for patient risk classification is proposed by Park & Kang, while Bansal et al. describe a cardiac monitoring system which uses ECG signal analysis and pattern recognition provided through a mobile device, a remote server, and medical practitioner point-of-care communication. Evidently, the use of computational models and methods is widespread in Systems Biology and Medicine and, as datasets grow in size and complexity, biomedical systems increase in sophistication, and computing power escalates, this trend looks set to continue.",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
99f205fe60616b4f087ba895589b0894e7b9dbca,https://www.semanticscholar.org/paper/99f205fe60616b4f087ba895589b0894e7b9dbca,EDXL-LD and Architectural Tactics towards Information Sharing and Interoperability in Emergency Context,"s of Scientific Papers-WADEM Congress on Disaster and Emergency Medicine 2017 EDXL-LD and Architectural Tactics towards Information Sharing and Interoperability in Emergency Context Julia Kantorovitch, Jarmo Kalaoja, Ilkka Niskanen VTT Technical Research Center of Finland, Espoo/Finland Study/Objective: The objective of this study is to propose a new architectural approach supported by information models, to manage knowledge in the dynamic emergency context towards interoperable knowledge sharing and reuse. Background: The knowledge systems for emergency management are based on evolvable information provided by various actors, by diverse collections of sensors and information supplied by human volunteers. In order to achieve a common operational picture situation awareness, various knowledge, vocabulary and information models need to be aligned. This requires extendable time, application context architecture and models representing detailed evolvable knowledge about the types of adverse events, their potential impact and the means and resources that are best suited for response. The existing semantic research has a potential to address the identified needs, however the reported ontologies are rarely publically available, and they are also disconnected from widely used standard data models, data-exchange formats, and protocols related to emergency management. Methods: The literature review and the inputs provided by domain experts in the CONCORDE consortium and WHO, have facilitated the addressing of shortcomings and challenges identified above. Results: The Emergency Data Exchange Language (EDXL) based domain specific standards are taken as a base to create domain specific vocabularies. Vocabularies are published as a Linked Data (LD) and can be downloaded from GitHub software repository https://github.com/OntoRep/EDXL. The Model-View-Presentation (MVP) based architectural tactics as a software engineering pattern (see below) are exploited to achieve a desired extensibility and dynamicity of the system at its deployment stage. Conclusion: By keeping applications’ business logic separate from data and semantics, the underlying knowledge models can evolve without necessarily requiring changes to the interfaces and applications built on top of the models. Prehosp Disaster Med 2017;32(Suppl. 1):s228 doi:10.1017/S1049023X17005878 The J-SPEED: A Medical Relief Activities Reporting System for Emergency Medical Teams in Japan Tatsuhikiko Kubo, Hisayoshi Kondo, Yuichi Koido 1. Department Of Public Health, University of Occupational and Environmental Health, Kitakyusyu/Japan 2. National Disaster Medical Center, Tokyo/Japan Study/Objective: To introduce the J-SPEED; medical relief activities reporting system for Emergency Medical Teams (EMTs) of Japan. Background: During a disaster, information gathering and analysis are key elements for better coordination and timely response. Previous cases revealed that EMTs sometimes became the only capacity which could report medical, or more broadly health situations to a coordination body, and standardization of the reporting process from EMTs to the EMT Cortication Cell (EMTCC) will allow for better coordination, and for strengthening of the disease early warning system, since EMTs will act as additional sentinel reporting sites. One good existing model for this issue is the Surveillance in Post Extreme Emergencies and Disasters (SPEED) system employed in the Philippines. The SPEED was developed by Philippine’s Department of Health and the WHO in 2010. Based on the lessons learned from relief mission of the Japan Disaster Relief Medical Team against the super typhoon Yolanda in 2013, a Japanese version of the SPEED, so called J-SPEED has been developed and published in 2015. Methods: Field study. Results: The J-SPEED was first activated at the Kumamoto earthquake which occurred on April 14, 2016. During the 48 days of response, EMTs from various affiliation sent 1,828 daily reports to the EMTCC, which represented medical demand of 8,089 patients. Standardized information processing and quantitative information made communications among stakeholders efficient, and supported evidence, consensus based decision making by the local authority. Conclusion: Employment of the J-SPEED drastically changed the EMT coordination in Japan. Countries which don’t have a relevant system can easily set up a national reporting system utilizing the SPEED framework. Prehosp Disaster Med 2017;32(Suppl. 1):s228 doi:10.1017/S1049023X1700588X How do we Measure Severity? An Assessment of Five Indexes used in Sudden Onset Disasters and Complex Emergencies to Measure Severity and Risk Anneli Eriksson, Martin Gerdin, Thorkild Tylleskär, Johan Von Schreeb 1. Public Health Science, Karolinska Institutet, Stockholm/Sweden 2. Centre For International Health, Bergen University, Bergen/Norway 3. Department Of Public Health Sciences, Karolinska Institutet, Stockholm/Sweden SITUATIONAL AWARENESS SYSTEMS Prehospital and Disaster Medicine Vol. 32, Supplement 1 Study/Objective: The aim was to, 1) study the relation between disaster outcomes after earthquakes, expressed as number of dead and injured, and the performance of five preidentified severity, and risk-scoring indexes, 2) to inform a model that in an initial phase of a disaster can be used to predict severity and levels of need, and thereby guide toward the appropriate levels of response. Background: A disaster is as an event that overwhelms local capacity, necessitating national or international assistance. Disasters can be categorized, based on the type of hazard causing them. An earthquake is a hazard that can lead to a disaster. The disaster-severity depends on the magnitude of the hazard, underlying vulnerability, the level of exposure, coping capacity and the disaster response. While assistance should be based on needs, determined by the severity of a situation, there is no recognized way to compare severity between disaster contexts. Several initiatives have been developed to provide information on global severity and risks in disaster situations. In this study we compare five indexes and their ability to define severity: GDACs, GEO, KI’s 7-need, INFORM and ECHO’s Crisis index. Methods: We did a mapping of the existing indexes and indicators used. Index-scores were standardized and then compared with the number of dead and injured as an absolute outcome, in earthquakes with magnitude equal to or higher than 6,5 that occurred in populated areas, between year 2001 and November 2016. Results: The five indexes evaluated were all indicating the severity after the examined earthquakes. There was not one single index that gave an absolute correlation. Indexes built on higher numbers of indicators had several indicators that gave identical information. Conclusion: It is possible to predict the severity of a disaster through proxy indicators. The number of indicators used is not automatically increasing the preciseness or validity of the outcome. Prehosp Disaster Med 2017;32(Suppl. 1):s228–s229 doi:10.1017/S1049023X17005891 Enhanced Situational Awareness through a Decision Support Service for Optimal Allocation of Resources and Response Capacity Irene Christodoulou, George M. Milis, Panayiotis Kolios, Christos Panayiotou, Marios Polycarpou, Ilkka Niskanen 1. Kios Research Center For Intelligent Systems And Networks, University of Cyprus, Nicosia/Cyprus 2. VTT Technical Research Center of Finland, Espoo/Finland Study/Objective: We designed and developed e-services, aiming to support the decision makers during various contexts of medical emergency response, offering them machine-aided enhanced situational awareness. Background: Currently, decisions are being made by human experts with hands-on experience in emergency fields. However, in most cases, experts do not have the required computational capacity to process the relevant heterogeneous information and perform informed decisions. Evidently, time is a very critical parameter in emergency situations, especially in large-scale incidents with large number of casualties. Methods: Taking this into account the services we develop, are based on the mathematical modeling of optimization problems for timely resources’ allocation, addressing different phases of the response. The formulated problems address: i) the optimal allocation of Emergency Medical Services (EMS) units (in terms of demand satisfaction and time), to active emergency incident fields, ii) the optimal allocation (in terms of exploiting their capacities and response time) of EMS staff to tasks on the incident field such, as triage and retrieval running, transferring of patients to medical treatment area, offering medical treatment, and iii) the optimal allocation (in terms of profile matching, demand satisfaction and time) of patients to EMS vehicles and subsequently to first receivers (hospitals). The services are supported by semantic modeling of EMS vehicles, hospital, staff and patients profiles, as well as by machine learning tools that estimate demand for resources given historical emergency incident data. The services offer clear interfaces, so as to be interoperable with existing emergency management systems, as long as access to the necessary information is given. Results: Our solution achieves the recommendation on allocation of resources, based on real-time collected information from the emergency field. Conclusion: Further work will focus on modeling different cost functions in the optimization, so as to customize the recommendations based on incident and/or decisionmaker needs. Prehosp Disaster Med 2017;32(Suppl. 1):s229 doi:10.1017/S1049023X17005908 Comparison of UAV Technology vs No UAV Technology in Identification of Hazards at a MCI Scenario in Primary Care Paramedic Students Trevor N. Jain, Aaron Sibley, Henrik Stryhn, Ives Hubloue 1. Biology (paramedicine), University of Prince Edward Island/ Holland College, Charlottetown/PE/Canada 2. H",Prehospital and Disaster Medicine,2017.0,10.1017/S1049023X17005878,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2de7b6b2dc0f2a06a1d7ebaf2f9570150896f0fd,https://www.semanticscholar.org/paper/2de7b6b2dc0f2a06a1d7ebaf2f9570150896f0fd,and (2021) Surgical outcomes and EEG prognostic factors after stereotactic laser amygdalohippocampectomy for mesial temporal lobe epilepsy Frontiers in Neurology. Working with the neurosurgery and neurology teams this study examined the outcome following laser ablation for intractable epilepsy,"reporting Insights the liability This study found that physician reports of aripiprazole-induced gambling disorders significantly declined from 5.9% to 2.9% in the wake of a 2019 settlement (after which monetary damages could no longer be readily obtained). clinical trial shows that a new medication, brexpiprazole, may have effect on borderline personality disorder symptoms. unaddressed om OCD as how should exposure based be during how can we in In this health policy paper, we outline the status of research and treatment for disordered gambling in the UK (including funding issues) and key research that should be conducted to establish the magnitude of the problem, vulnerability and resilience factors, the underlying neurobiology, long-term consequences, and treatment opportunities. study the popular practice of microdosing, in a double-blind, placebo controlled study. Healthy volunteers ingested small doses of LSD over a two-week period. The drug had few effects on mood or cognition. H Neural correlates of inhibitory control are associated with stimulant-like effects of alcohol. Both poor inhibitory control and enhanced stimulant-like subjective effects of drugs have been linked to excessive use. Here, we present data that poor inhibitory control and alcohol reward are linked at the neural level. We present a heuristic model of suicide risk and resilience for African adolescents that their development a hegemonic the dynamic of stress exposure and has been hampered by differences in operational definitions of exposures and approaches to defining timing, leading to results that lack consistency and specificity. In the present study we derived trajectories that varied in type, timing and chronicity of stress exposure for Black and White females using prospectively collected data in the Pittsburgh Girls Study (PGS). Race and ethnic comparison of ecological risk factors and youth outcomes: A test of the desensitization hypothesis Child Family 2722-2733. This study found that associations between common risk factors (e.g., low family warmth, peer deviance),youth depression and delinquent behavior were consistently lower among youth of color, especially Black youth, in comparison to White youth. Posttraumatic stress symptom persistence across 24 years: association with brain structures. Brain Imaging and Behavior, 14, This study found that higher post-traumatic stress symptoms in male Vietnam veterans aged 38 to 62 were associated with lower hippocampal, amygdala, rostral middle frontal gyrus, and medial orbitofrontal cortex volumes. Further, increases in post-traumatic stress symptoms over time were associated with lower hippocampal volume at age 62. disparities found that were than were found in ~75% malingerers, indicating that malingering patients have This study found that physician reports of gambling disorders significantly declined from 5.9% to 2.9% in the wake of a al. An opportunity for primary prevention research in psychotic disorders. Schizophr Res 2021. Risk of a psychosis disorder can be predicted from psychophysiological and behavioral features that predate the onset of the psychotic disorders. The predictions have accuracy, sensitivity, and specificity of 78%, 85%, and 63% respectively. Although promising, further measurements are needed to yield clinically useful predictions. Parent strategies for expanding food variety: reflections of 19,260 adults with symptoms of Avoidant Restrictive Food Intake Disorder. Eat Disord Jan;55(1):108-119. This study used machine learning to analyze qualitative data on the perceived helpfulness of childhood feeding strategies in adults with a prolonged history of food avoidance/restriction. Results showed that positive and encouraging feeding strategies were perceived as helpful even if they did not result in behavior change, whereas strategies perceived as Wrist-worn alcohol biosensors: Applications and usability in behavioral research. Alcohol , 25-34. This paper, written in collaboration with colleagues from the University of Florida and Brown University, describes the latest advances in alcohol biosensor technology. We describe potential clinical and research applications of these devices, as well as results of three pilot studies deploying alcohol biosensors across a variety of settings. & (2021). Alcohol subjective responses in heavy drinkers: Measuring acute effects in the natural environment versus the controlled laboratory setting. Alcoholism: Clinical and Experimental Research , 45 (6), 1287-1297. This study of adult heavy drinkers was the first to assess the reliability and validity of using smartphones to capture alcohol responses during real-world heavy drinking episodes in drinkers’ natural environments. Participants’ responses to alcohol in the real world, as measured by smartphone, bore a fair-to-good correspondence with their responses during a controlled laboratory alcohol challenge. The results suggest that smartphones can be a valid way to collect data on real-world drinking experiences. Anorexia conduct disorder, and the juvenile justice system: a case of applying traditional treatment modalities in a non-traditional setting. Biopsychosoc Med . 2021 Dec 18;15(1):26. The paper details a case of an adolescent with anorexia and conduct disorder who was successfully managed by utilizing the structure of juvenile detention center. This paper focused on the use of targeted neuropsychological testing at inpatient children hospitals. examines poisoning in Pakistan, highlighting differences in various regions The on accessibility wheat poisoning, household This collaborative study investigated how COVID affected the child consult-liaison delivery services in the U.S. and Canada. These studies advance our program of research into the neuropsychological sequelae of electrical injury. The papers use our expanding database (the largest known dataset in the world with full neuropsychological characterization of electrical injury survivors) and demonstrate base rates of performance invalidity, characteristics of memory and processing speed impairments, and the influence of pain on neuropsychological performance.",,2022.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
c8bdec1dca2b54402ad431c2dfbbbb005c7ba7ac,https://www.semanticscholar.org/paper/c8bdec1dca2b54402ad431c2dfbbbb005c7ba7ac,"AS&T virtual collection: Toxicity of ambient particulate matter – impact of chemical composition, emission sources and atmospheric processes","An increasing number of studies in recent years have linked ambient particulate matter (PM) to diseases such as asthma (Fan et al. 2016), myocardial infarction (Madrigano et al. 2013), stroke (O’Donnell et al. 2011) and even Alzheimer’s (Shou et al. 2019). There have also been several epidemiological studies that predict a surge in global disease burden and mortality in the near future if the present trend in rising PM emissions continues (Burnett et al. 2018; Li et al. 2019; Apte et al. 2015). Most of these models use PM mass as a metric although a few complex models also include some of the key chemical species present in PM such as metals and organic compounds (Heo et al. 2014; Wang et al. 2022). However, these models still ignore the complexity of PM chemical composition, which is influenced not only by heterogeneous emission sources of PM but also by atmospheric processes (R€ onkk€ o et al. 2018). Moreover, these models ignore the interactions among various chemical components of PM which can alter the overall toxicity of PM as obtained by the simple summation of individual toxicities (Yu et al. 2018; Wang et al. 2020). Thus, the notion that higher PM mass implies higher mortality or prevalence of diseases is not completely true. It is clear that there is a necessity to search for alternative metric(s) than PM mass to represent PM toxicity in epidemiological models, which in turn requires clarity on the exact mechanisms underlying PM toxicity. Currently, some progress has been made in this regard in the past two decades and it has indicated that PM sources, atmospheric processes, chemical composition and pathology of diseases share a complex relationship with each other. Investigations for linking the PM toxicity with chemical composition have often shown varied and sometimes contradictory results and presently face several issues that need attention. For example, the traditional toxicity characterization methods are labor-intensive and time-consuming, and therefore, only a limited number of samples can be analyzed for the toxicity evaluation. Furthermore, there is also a range of toxicity endpoints that one could choose from, which has often led to debate on whether or not a single endpoint could adequately represent PM toxicity. Recently, oxidative potential (OP) has emerged as a proxy for PM toxicity, although currently there is a lack of consensus regarding the most appropriate method to measure PM OP (Yu, Puthussery, and Verma 2020). Moreover, there is a lack of standard protocols for the procedures of PM collection, extraction and exposure to lung cells, although these factors have been shown to heavily influence results (Daher et al. 2011), making comparison among different studies difficult. Overcoming the hurdles described in the previous paragraph would better equip us to answer some important questions that can be addressed by the aerosol community, and this is possible through focused research into certain areas. These include the development of methodologies that can better mimic physiological processes in the human body, leading to a more accurate assessment of the health impacts. Design of simple, inexpensive and high throughput methods to evaluate PM toxicity is needed to generate large datasets that can be incorporated into epidemiological models. Development of real-time instruments for field deployment could also greatly expand our capabilities to generate such large datasets. Investigations into spatiotemporal variations in PM toxicity and their correlations with chemical composition could refine our understanding of the role of emission sources and atmospheric processing in influencing PM toxicity. Such studies could also lead to development of machine learning based models to make predictions in data-sparse regions. Another research area that requires immediate attention is the interaction between various chemical components and their role in altering the overall toxicity of PM. Currently, little work has been undertaken in this area and, except for preliminary information regarding the interaction among a few prominent species, not much is known. We have collated a selection of articles published by AS&T to form a Virtual Collection as an attempt to highlight the efforts made by aerosol researchers so far to answer the questions posed here, addressing issues vital to further our understanding of PM toxicity. For example, Landreman et al. (2008) developed an assay to measure the PM OP in alveolar macrophages subjected to short-term exposure. This assay has been widely used in PM studies revealing important information regarding the spatiotemporal variations in OP. Yu, Puthussery, and Verma (2020) developed an instrument for measuring five commonly used OP endpoints to provide a rapid and comprehensive assessment of PM OP of a large number of PM samples. Such large-scale studies are necessary for understanding the relationship between",Aerosol Science and Technology,2022.0,10.1080/02786826.2022.2051960,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
05956c3c3b62c07e6726f7ef8a4b340ddcbe3f97,https://www.semanticscholar.org/paper/05956c3c3b62c07e6726f7ef8a4b340ddcbe3f97,Senior Design Instructors for 2021-2022 Contact Information,"In this project, we are creating a health equity dashboard for Connecticut. Our goal is the bring different data sources together and display to the users to show what types of programs or services should be provided in the different places in Connecticut. In order to accomplish this, we will be using Connecticut’s Census data along with datasets from Centers for Medicare & Medicaid Services. We hope our webpage will be informative of the services we should provide in the various towns and counties of Connecticut. The CT National Guard Cyber Range 2021 Project focuses on working with the ongoing project that was developed last year. This year, the goal was to move the cyber range to the cloud for remote access. Currently, the cyber range simulates two blue team scenarios: a ransomware attack and a vulnerable Active Directory access page. As cyber attacks–more specifically ransomware attacks–are rising in use, this cyber security project holds real world, practical applications. With this year’s team, each scenario is now remotely deployable, allowing CTNG trainees to practice National Guard battle plans from wherever. The project uses Amazon Web Services for cloud compute virtual machines, with Terraform for automating virtual machine deployment. Furthermore, practice scenarios are now easily addable due to the abstraction that was made possible through virtualization. The current scenarios are built with a variety of technologies, from Powershell scripts and Active Directory on Windows to Apache on Linux, but a wider variety is possible with ability to build and add any scenarios desired. Making the ongoing project more easily modifiable and adaptable allows the CTNG and any further teams to build quicker. This is essential as cyber security is now more important than ever, and any solutions in the field must be able to evolve quickly. and deprecated. Additional steps towards were taken by updating the protocol that certain tasks utilize from communicating with a SOAP to utilizing REST commands. by other the so-called Condition-Based Maintenance (CBM) where the maintenance is only conducted when it is really needed other than scheduled so that the maintenance cost is reduced and engine time-on-wing is extended; Doing the maintenance at the right place allows the needed facility and part inventory are in place to support the maintenance (for commercial airlines, this is usually the hubs). As an engine OEM, Pratt & Whitney is committed to provide dependable jet engine health management. The key to support doing the right maintenance at the right time and the right place is to identify a failure accurately and reliably at an early stage so that there will be ample time for the aircraft to get to the right place for maintenance. For most engine components, a failure is a state of the component that a fault is progressed to. By definition, a fault is a physical imperfection or impairment that is responsible for failure while a failure is a state of inability to perform a normal function. As shown in the P-F curve in Figure 1, the earlier a fault is detected, the less cost to repair would incur. It is well-known that the earlier a fault is detected, the more likely the detection is a false alarm. Excessive false alarms would defeat the propose of doing the right maintenance. Also, some of the fault may lead to safety critical failures, in which case, the recall rate of the detection has to be 100%. Overall, the goal for this project is to implement a machine learning algorithm which can accurately identify and diagnose engine faults. Battery powered IoT devices are a common tool in today’s jobsite. However, the downtime required to charge or replace dead batteries is costly at a large scale, so it is in a company’s best interest to optimize the battery life of their IoT devices. It is not uncommon to produce a noticeable decrease in the battery life of a device after even the slightest of updates to its firmware. Therefore, it is valuable to have the ability to run constant checks to ensure a device’s expected battery life stays within a tight range. Our project will provide companies and technology developers an easy means of testing firmware changes before finalizing device updates in order to catch these power-draining bugs. We have partnered with Triax Technologies to develop an open-source continuous integration (CI) testing platform for analyzing the change in power consumption of a device following any update. Our goal is to simplify the user experience by creating a modular and highly-configurable framework that allows developers to use the CI platform and power profiler of their choosing and have complete control of all aspects of the testing. The output to the user includes graphical interpretations of the analysis and readable results that can be sent via email or added as a comment on a pull request. The project is focused on creating and implementing two features on The Whelen Engineering Company’s web-based application: the Whelen Cloud Platform (WCP). WCP provides a real-time vehicle tracking service to emergency services with an interactive map that displays the locations and status of all vehicles. Our job was to implement two features for the the Live Map designed to be useful for coordinating fire fighting services during an emergency. While these features were originally specific to fire trucks, we designed them in such a way that they could be useful for any organization that Whelen provides services for, whether it be law enforcement, emergency medical services, or even the Department of Transportation. that A cyber range is a virtual environment in which users can simulate cyber attacks, test cybersecurity technology, host competitions, etc. In order to address the current limitations of cyber ranges, our team proposes that a domain specific language (DSL) should be used for cyber range development. A DSL within a cyber range would allow for customization of cyber range scenarios and standardization of scenario development. Our team will create a prototype of a DSL that could be implemented within a cyber range using Xtext, and write an NSF proposal supporting the use of DSLs in a cyber range. Our project also addresses the lack of accessibility with current cyber ranges. We suggest a hybrid licensing model, as well as more cost effective platforms to run our cyber range on (Raspberry Pi, existing cyber ranges, etc.). The team has created a prototype Google Chrome extension to adapt website content to be more accessible. The tool adjusts color schemes, font size, font family, and line and letter spacing to benefit users diagnosed with dyslexia and minor visual impairments. The resulting software will allow users to have equal opportunity to access and digest information online. The goal of our project is primarily about implementing three post-quantum signature verification algorithms to be run on the Xilinx ZCU102 development board and running performance tests on said algorithms. We seek to use the performance metrics in order to determine which algorithm has the best trade off between speed and security, especially in the context where the ARM processor must be reset and the boot time minimized. Our project develops software for a specific vibro-tactile biofeedback system. This system is designed to help firefighters navigate smoke filled buildings. Our vibro-tactile biofeedback system uses patterns of vibration felt on the body to provide new ways of perceiving direction. UWB radio based positioning system is used to determine the ranging values and location of a mobile unit. These systems are integrated together to create a prototype device that can be used to blind-navigate around an indoor environment. For this project, Sonalysts would like to have the students design and develop an AR application that interacts with static exhibits. Our project is an augmented reality mobile application that is able to render animated 3D holograms in real-time and geospatially anchor them on physical objects and/or tags in the real world. It is capable of image recognition, object detection, geolocation mapping, marker recognition, and it can support an augmented reality view that contains spatial awareness and AR sessions. In addition to this, our application is able to render animated 3D object models, retrieve and fetch them from a cloud database in real-time, contain a secure user authentication and authorization service, and should have a friendly and interactive user interface. When climate disasters occur and damage properties, insurance companies are expected to pay for losses covered by a client’s policy. The issue, however, is that many of these policies are determined by historical data. This historical data determines how much an insurance company is expected to pay if a claim is made and under what circumstances a claim is valid. This past data is rapidly becoming more and more dissimilar to what is happening today due to changes in the frequency and severity of climate disasters. It is vital that better solutions are developed in order to reflect the current circumstances. It is for these reasons that the project Climate Risk Strategy Analyzer (CRISTAL) was created. The purpose of CRISTAL is to act as a tool for broker agencies to evaluate their clients current insurance policies and determine what further coverage may be needed when the current climate situation is taken into consideration. By combining a climate risk analysis and a coverage gap analysis, CRISTAL will provide users with predictive and prescriptive analyses. Such analyses will include possible climate events that can affect a client’s business, automated recommendations related to their policies, and advisories about potential financial changes. In order to achieve this goal, our aim Students will provide a virtual reality experience where a remote user in a VR headset can peripherals can control a telepresence robot to",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
0878f21553a04ae10ed1a3e55ddf4091e6238df2,https://www.semanticscholar.org/paper/0878f21553a04ae10ed1a3e55ddf4091e6238df2,ICIN 2020 Program,"For nearly fifty years, beginning with Kleinrock's pioneering work on using queueing theory to model packet flows in communication networks, network modeling has adopted the individual packet as primary level of granularity for network modeling and analysis. With the advent of terabit-switching capabilities, information-centric networking, and data centers with complex workloads and hundreds of thousands of components, the time would seem ripe to raise the level of abstraction beyond the packet. In this talk, we identify higher-level modeling abstractions are already proving useful as well as new needed abstractions. But also we identify cases where packet-level models are still crucial in providing important insights. Wednesday, February 26 10:00 11:00 K2: Keynote 2 Softwarization and IoT evolution Lefteris Mamatas (University of Macedonia, Greece) Room: La Grande Scène Chair: Alex Galis (University College London (UCL), United Kingdom (Great Britain)) Abstract: The Internet of Things (IoT), a main enabler for Industry 4.0, is considered as a system connecting myriads of people, things and services. IoT enables new large-scale applications with diverse constraints (e.g., limited resource availability or mobility) and requirements (e.g., ultra low delays). A main challenge is the evolution beyond large networks of sensing devices to multiple cooperating network deployments that implement context-sensitive communication and cloud processing strategies, through the seamless adoption of Softwarization technologies. The talk includes the following aspects: (i) a motivation of the above vision with two novel use-cases on smart-city and maritime contexts; (ii) a discussion on the evolutionary and clean-slate approaches to the IoT Softwarization; (iii) the missing elements and open issues in Software-Defined IoT and Edge Cloud technologies; and (iv) insights from our practical experience in relevant implementations and real experiments. The Internet of Things (IoT), a main enabler for Industry 4.0, is considered as a system connecting myriads of people, things and services. IoT enables new large-scale applications with diverse constraints (e.g., limited resource availability or mobility) and requirements (e.g., ultra low delays). A main challenge is the evolution beyond large networks of sensing devices to multiple cooperating network deployments that implement context-sensitive communication and cloud processing strategies, through the seamless adoption of Softwarization technologies. The talk includes the following aspects: (i) a motivation of the above vision with two novel use-cases on smart-city and maritime contexts; (ii) a discussion on the evolutionary and clean-slate approaches to the IoT Softwarization; (iii) the missing elements and open issues in Software-Defined IoT and Edge Cloud technologies; and (iv) insights from our practical experience in relevant implementations and real experiments. Wednesday, February 26 11:30 12:30 TS3: Network Slicing Room: La Grande Scène Chair: Prosper Chemouil (Orange Labs (retired), France) TS3.1 A Lightweight Policy-aware Broker for Multi-domain Network Slice Composition Xuan-Thuy Dang (Technische Universität Berlin & DAI Labor, Germany); Fikret Sivrikaya (GT-ARC gGmbH & Technische Universität Berlin, Germany) TS3.2 Enhancing the performance of 5G slicing operations via multi-tier orchestration Miquel Puig Mena (i2cat Foundation, Spain); Apostolos Papageorgiou, Leonardo Ochoa-Aday and Muhammad Shuaib Siddiqui (Fundació i2CAT, Internet i Innovació Digital a Catalunya, Spain); Gabriele Baldoni (ADLINK Technology, France) TS3.3 An Efficient Online Heuristic for Mobile Network Slice Embedding Katja Ludwig (University of Augsburg, Germany); Andrea Fendt (Nokia Bell Labs & University of Augsburg, Germany); Bernhard Bauer (University of Augsburg, Germany) Wednesday, February 26 12:30 13:00 DPS: Demo/Poster ""Elevator Pitch"" Session Room: La Grande Scène Chair: Prosper Chemouil (Orange Labs (retired), France) DPS.1 A QUIC-based proxy architecture for an efficient hybrid backhaul transport Michele Luglio and Mattia Quadrini (University of Rome Tor Vergata Dip. Ing. Elettronica, Italy); Cesare Roseti and Francesco Zampognaro (University of Rome Tor Vergata, Italy); Simon Pietro Romano (University of Napoli Federico II, Italy) DPS.2 A Blockchain-based Brokerage Platform for Fog Computing Resource Federation Marco Savi, Daniele Santoro, Katarzyna Di Meo and Daniele Pizzolli (Fondazione Bruno Kessler, Italy); Miguel Pincheira (OpenIoT Research Area, FBK CREATE-NET & University of Trento, Italy); Raffaele Giaffreda (FBK CREATE-NET, Italy); Silvio Cretti (Fondazione Bruno Kessler, Italy); Seung-woo Kum (Korea Electronics Technology Institute, Korea (South)); Domenico Siracusa (Fondazione Bruno Kessler, Italy) DPS.3 Optimized Network Slicing Proof-of-Concept with Interactive Gaming Use Case José J Alves Esteves, Jr. (Orange Labs & Sorbonne Université, France); Amina Boubendir and Fabrice M. Guillemin (Orange Labs, France); Pierre Sens (Université de Paris 6, France) DPS.4 A Deployable Containerized 5G Core Solution for Time Critical Communication in Smart Grid Van Giang Nguyen, Karl-Johan Grinnemo, Javid Taheri and Anna Brunstrom (Karlstad University, Sweden) DPS.5 FogGuru: a Fog Computing platform based on Apache Flink Davaadorj Battulga (University of Rennes 1 & U-Hopper, Italy); Daniele Miorandi (U-Hopper, Italy); Cedric Tedeschi (University of Rennes I / INRIA, France) DPS.6 5G Experimentation Framework: Architecture Specifications, Design and Deployment Louiza Yala (Orange Labs, France); Sihem Cherrared (University of Rennes 1 & Orange Labs and INRIA, France); Grzegorz Panek (Orange Polska, Poland); Sofiane Imadali and Ayoub Bousselmi (Orange Labs, France) DPS.7 A New Service Management Framework for Vehicular Networks Jose Ramirez, Onyekachukwu Augustine Ezenwigbo, Gayathri Karthick and Ramona Trestian (Middlesex University, United Kingdom (Great Britain)); Glenford E Mapp (MIddlesex University & Cantego Limited, United Kingdom (Great Britain)) DPS.8 Creating trust in automation in intent-based mobile network management Ville Vartiainen (Aalto University, Finland); Dmitry Petrov and Vilho Räisänen (Nokia Bell Labs, Finland) DPS.9 Interoperable and discrete eHealth Data Exchange between Hospital and Patient Andreea Ancuta Corici, Olaf Rode, Ben Kraufmann, Andreas Billig, Jörg Caumanns and Markus Deglmann (Fraunhofer FOKUS, Germany); Viktoria Walter, Janina Rexin and Gunther Nolte (Vivantes Netzwerk für Gesundheit GmbH, Germany) Wednesday, February 26 14:00 15:00 K3: Keynote 3 Network Operations and AI Rafia Inam (Ericsson, Sweden) Room: La Grande Scène Chair: Diego Lopez (Telefonica I+D, Spain) Abstract: The Fifth Generation Mobile Networks (5G) are seen as a key enabler for diverse-natured industry verticals (such as automotive, manufacturing, mining, utility, health, etc.) by providing a platform to support heterogeneous sets of network quality requirements. The presentation will discuss how Artificial Intelligence and automation can support Telecom industry to manage the increased complexity, scalability, and diversity in its use cases. The work presents different aspects of the network operations of the future, done in an automated, proactive, and intent-driven fashion using different AI techniques. The Fifth Generation Mobile Networks (5G) are seen as a key enabler for diverse-natured industry verticals (such as automotive, manufacturing, mining, utility, health, etc.) by providing a platform to support heterogeneous sets of network quality requirements. The presentation will discuss how Artificial Intelligence and automation can support Telecom industry to manage the increased complexity, scalability, and diversity in its use cases. The work presents different aspects of the network operations of the future, done in an automated, proactive, and intent-driven fashion using different AI techniques. Wednesday, February 26 15:00 16:10 TS4: Improving Service Performance Room: La Grande Scène Chair: Amina Boubendir (Orange Labs, France) TS4.1 Multimedia Service Management with Virtualized Cache Migration Reza Shokri Kalan (Ege UniversityTurkey, Turkey); Muge Sayit (Ege University, Turkey); Stuart Clayman (University College London (UCL), United Kingdom (Great Britain)) TS4.2 Proposal of Profile and Event Sharing by Agent Communication Masafumi Katoh (Fujitsu Labotatories Ltd., Japan); Tomonori Kubota and Eiji Yoshida (Fujitsu Laboratories, Japan); Yuji Kojima (Fujitsu Limited, Japan); Yuuichi Yamagishi (FUJITSU LIMITED, Japan) TS4.3 Double Mask: An Efficient Rule Encoding for Software Defined Networking Ahmad Abboud (University of Lorraine, France); Abdelkader Lahmadi (INRIA Nancy Grand Est, France); Michael Rusinowitch (INRIA Nancy-Grand Est, France); Miguel Couceiro (University of Lorraine, France); Adel Bouhoula (Higher School of Communication of Tunis & University of Carthage, Tunisia); Mondher Ayadi (Numeryx, France) Wednesday, February 26 16:35 18:00 TS5: Network Security Room: La Grande Scène Chair: Ved P. Kafle (National Institute of Information and Communications Technology, Japan) TS5.1 Neural network based anomaly detection for SCADA systems Lenhard Reuter (AIT Austrian Institute of Technology, Austria); Oliver Jung (AIT Austrian Institute of Technology GmbH, Austria); Julian Magin (AIT Austrian Institute of Technology, Austria) TS5.2 DDoS Detection System Using Feature Selection and Machine Learning Algorithms in a Distributed System Amjad Alsirhani (Dalhousie University, Faculty of Computer Science & Canada, Canada); Geetanshu Grover and Srinivas Sampalli (Dalhousie University, Canada); Peter Bodorik (Dalhousie University, Faculty of Computer Science, Canada) TS5.3 Configuration of the Detection Function in a Distributed IDS Using Game Theory Clement Weill (Institut Polytechnique de Paris & CEA LIST, France); Alexis Olivereau (CEA, LIST, France); Djamal Zeghlache (Insti","2020 23rd Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN)",2020.0,10.1109/icin48450.2020.9059372,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
ded67de0581d3c8b410473e123a9ba0edd7237a7,https://www.semanticscholar.org/paper/ded67de0581d3c8b410473e123a9ba0edd7237a7,"Dry Rivers, Scary Strangers: Are Financial And Cyber Crises Alike?","The internet and the financial system show crucial affinities: both are tightly interconnected global networks whose orderly functioning is a prerequisite for economic prosperity. In financial and cyber crises alike, vulnerabilities are a consequence of distorted economic incentives, contagion is fast, and the most serious risk is loss of trust. Lessons learned from financial meltdowns translate to the cybersecurity world: stability cannot be achieved until policies are in place to address all of these issues. Steps have been taken to rectify incentives, as exemplified by recent European Union legislation. Data that helps identify weak nodes are still scarce, notwithstanding recent efforts. The preservation of trust is the hardest challenge: in the financial system, a global governance framework was put in place to help maintain and rebuild confidence at critical junctions, but conflicting national interests make it difficult to establish a cyber equivalent. 1 Please cite as: Biancotti, Claudia and Paolo Ciocca, “Dry Rivers, Scary Strangers: Are Financial and Cyber Crises Alike?,” in Demchak, Chris C. and Benjamin Schechter, eds. Military Cyber Affairs: Systemic Cyber Defense 3, no. 2 (2018). 2 Senior Economist at the Bank of Italy, the Italian central bank. The views here expressed are those of the authors and should not be attributed to the Bank of Italy. 3 Commissioner at Consob, the Italian Securities and Exchange Commission. The views here expressed are those of the authors and should not be attributed to Consob. 1 Biancotti and Ciocca: Are Financial And Cyber Crises Alike? Published by Scholar Commons, 2018 2 Advanced economies are immersed in cyberspace. In 2016, 95 percent of businesses in OECD countries had a broadband internet connection; 77 percent had a web presence. More than half of the adult population had purchased a product or service online, compared to 36 per cent in 2010. As digitalization progresses, a growing share of production and consumption activities depend on connectivity. From an economist’s point of view, there are evident analogies between the internet and the global financial system: both are tightly interconnected networks that provide lifeblood to the real economy, via transfers of information and funding, respectively. Indeed, a financial crisis and a cyber crisis look alike in three key dimensions: (i) vulnerabilities accumulate because of excessive risk-taking on the part of some agents, which eventually translates to systemic risk on account of interdependencies; (ii) disruption can start at a single weak point and spread to the whole system in a matter of days or even hours; (iii) the ultimate casualty is trust: once it is lost, transactions – and the whole economy – can grind to a halt as counterparties disconnect from each other. Policy responses can be deployed to address these problems so that crises can be prevented or at least managed effectively. In the financial system, safeguards have been established over time: examples are strict capital requirements for lenders, orderly resolution procedures for failing institutions, and collection of micro-level data aimed at identification of individual weak nodes. They are not all-encompassing, but they do help reduce the risk. Where cyberspace is concerned, this process is still in its infancy. Some results have been achieved with respect to (i) above. A small but insightful literature on the economics of cybersecurity points out that distorted economic incentives, rather than technically sophisticated attacks, are at the heart of the problem. Software is born vulnerable because of network externalities. For products such as operating systems and messaging platforms, the value increases with the size of the installed base; developers 4 OECD, OECD Digital Economy Outlook 2017, (Paris: OECD Publishing, 2017), 161-171. 5 European Central Bank, “The Eurosystem Household Finance and Consumption Survey: Results from the First Wave” , Statistics Papers Series no. 2 (April 2013): 7-8. 6 See among others: Ross Anderson, “Why Internet Security Is Hard – An Economic Perspective”, Proceedings of the 17 Annual Computer Security Applications Conference (December 2001). Hal Varian, “Managing Online Security Risks”, The New York Times, June 1, 2000. Tyler Moore and Ross Anderson, “Internet Security”, in The Oxford Handbook of the Internet Economy, ed. Martin Peitz and Joel Waldfogel (Oxford: Oxford University Press, 2011). 2 Military Cyber Affairs, Vol. 3 [2018], Iss. 2, Art. 7 https://scholarcommons.usf.edu/mca/vol3/iss2/7 DOI: https://doi.org/10.5038/2378-0789.3.2.1061 3 forego security as they scramble to get to the market first, attract a critical mass of users, and shut competition off. The absence of developer liability for buggy software does not help. The market for cyber defense is plagued by information asymmetries. Vendors know more than their customers: they may have an opportunity to push whatever solution maximizes their own profit, independent of how effective it is. Finally, the cost of cyber attacks in many cases is not fully internalized by the immediate victims: for example, the owner of a vulnerable IoT device that gets recruited into a botnet typically has no statutory liability (yet) for damage caused by the botnet. Some corrective measures have already been introduced, while others are being drafted. In the European Union, the General Data Protection Regulation (GDPR) – coming into force in May 2018 – imposes steep fines to businesses that put the confidentiality of personal data at risk and mandates disclosure of breaches to both authorities and data subjects. The Directive on Security of Networks and Information Systems (NIS), also coming into force this year, introduces cyber protection requirements and incident disclosure obligations for key players in sectors such as energy, finance, and healthcare. A regulation proposal put forth by the European Commission envisages an EU-wide framework for security certification of hardware and software, fashioned after the notoriously strict CE scheme for safety, health and environmental protection. These are necessary steps, but they are not enough; the effects of GDPR and NIS are confined to certain cases or sectors. More theoretical work is needed to define broader principles: generalized liability for damage caused to third parties may be a good idea, yet an ordinary citizen whose email account gets spoofed by phishers should probably not be forced to compensate victims. With respect to (ii), there is still a significant knowledge gap about the location and interconnections of weak nodes. As pointed out by the G7 Finance Ministers and Central Bank Governors in 2017, “reliable, impartial, comprehensive and widely accessible” data on the frequency and economic impact of cyber attacks are still rare. The same goes for information on network and economic connections, e.g. through digital and physical supply chains. Evidence from the Bank of Italy’s business surveys suggests that cyber risk may be concentrated among high-tech, non-ICT businesses, which are more exposed and interesting to attackers compared to low-tech ones, and less proficient at defense than the ICT sector. The data also suggest that mass adoption of relatively simple internet-based solutions, such as e-commerce 7 G7 Finance Ministers and Central Bank Governors, Bari Communiqué, May 12-13, 2017. 8 Claudia Biancotti, “The Price of Cyber (In)security: Evidence from the Italian Private Sector”, Bank of Italy Occasional Papers no. 407 (November 2017). 3 Biancotti and Ciocca: Are Financial And Cyber Crises Alike? Published by Scholar Commons, 2018 4 platforms, cloud computing services or IoT devices is a stronger risk factor than the selective adoption of advanced technologies, like machine learning or industrial robotics. These indications are vital in understanding which sectors of the economy need urgent intervention, be it in terms of awareness campaigns, dedicated incentives, or regulation. The problem sub (iii) is the hardest to solve. After the 2009 financial meltdown, trust was only restored after a series of large-scale, highly controversial injections of public money in the banking system, and substantial reinforcement of a global governance framework which encompasses broad-based organizations such as the Financial Stability Board, the Bank for International Settlements and the International Monetary Fund, regional institutions such as the European System of Financial Supervision, and national authorities. In a cyber crisis, there is no immediately evident equivalent of a public-sector backstop. Perhaps more importantly, a global governance framework is very hard to build because in cyberspace a crisis is generally triggered by an intentional act of aggression; an adversary is in the picture and may serve, directly or indirectly, the interests of a nation-state. In this sense, the right comparison might be with currency or trade wars; the problem is mostly one of political, diplomatic and military relations, especially in a world where the weight of authoritarian governments increases. This is where input from economics is not sufficient and must be complemented by scholarship in the various facets of international relations. 4 Military Cyber Affairs, Vol. 3 [2018], Iss. 2, Art. 7 https://scholarcommons.usf.edu/mca/vol3/iss2/7 DOI: https://doi.org/10.5038/2378-0789.3.2.1061",Military Cyber Affairs,2018.0,10.5038/2378-0789.3.2.1061,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
57b672bbd41fa4fae7b4307191978599513107f4,https://www.semanticscholar.org/paper/57b672bbd41fa4fae7b4307191978599513107f4,Data Engineering Project (Educating For The Future PhUSE WG),"With an expected 100% increase, over the next 3 years, of data from non-EDC sources (such as smartphones, wearables and custom apps) the traditional methods of managing data for clinical trials presents executives with a resourcing headache. As such, many companies are looking for lower cost strategies to sure up this shortfall in resourcing. However, citing case studies from other industries, there are new methodologies/technologies in data engineering which could enable automation of much of the “heavy-lifting” currently practiced in clinical data management and statistical programming. This paper discusses the Data Engineering Project within the PhUSE Computational Science (CS) Working Group, Educating For The Future, with a view to educate clinical data managers in data engineering principles so that they can be prepared, equipped and effective in dealing with the coming “data tsunami” heading to the shores of clinical research. INTRODUCTION Did you realise we are living in the age of the Fourth Industrial Revolution? Perhaps you have been busy downloading a myriad of “apps” designed to make your life easier or connecting on social media, uncovering relationships and associations you didn’t even know you had. Perhaps you have been shopping a global marketplace, comparing prices, quality and availability, all at your fingertips and in a minutes’ time. While this has been happening, the Fourth Industry Revolution has been evolving at exponential proportions ​. Just ask Siri! The term “Industrie 4.0”, was originated in Germany, as a government-led initiative, to transform manufacturing through advanced digital capability. Thus creating the concept of a “smart factory”, based on four key design principles ​: 1. Interconnection of machines, devices, sensor and people 2. Vast amounts of useful information (data) to drive decision making 3. Technical assistance to aid humans, for example to visualise data or to perform tasks that may be of safety concern for a human. 4. The use of cyber-physical systems to make decisions on their own and to perform tasks as autonomously as possible. Emerging from the premise of “Industrie 4.0” is the advent of the term “The Fourth Industrial Revolution” (also referred to as “4IR” or “I4.0”). This term originated in 2016 when described by Klaus Schwab (Founder and Executive Chairman of the World Economic Forum), as a “technological revolution that will fundamentally alter the way we live, work, and relate to one another”. Klaus goes on to describe it as a digital revolution with innovative uses of a combination of technologies that build upon the premise of the third revolution (i.e. electronics and information technology to automate production). As a result, emerging technologies have brought forth advancements in fields such as ​artificial intelligence, robotics, the Internet of Things, autonomous vehicles, 3D printing, nanotechnology, biotechnology, materials science, energy storage, and quantum computing. This rapid evolution will undoubtedly affect industries world-wide, already disrupting many industries, such as travel agencies, video rentals and bookstores​ . The pharmaceutical industry is also experiencing the impacts of I4.0. Digital and mobile technologies has brought on significant advancements in data acquisition and accessibility as it relates to health care and patient data. As reported in the Tufts-Veeva eClinical Landscape study in 2017, data coming from sources such as, smartphones, custom applications, and mobile health are expected to double in the next 3 years ​. Therefore requiring greater capabilities in handling large volumes of data, as well as data from coming in through various data streams and 1 PhUSE EU Connect 2018 formatting. As with other industries, data will become a critical asset to their business and the effective utilisation of this data can play a critical role in driving growth in the business and bringing novel therapies to the patients who need them. In this paper, we will focus on the works of the Data Engineering Project within the Educating For The Future Working Group. With the formation of the Working Group in early 2018, the team had taken on the mission to explore how data engineering techniques, successfully deployed in other industries, could be utilised in the pharmaceutical industry, with a goal to ​facilitate the education ​of the pharmaceutical industry on these techniques. We will share with you some introductory information about Data Engineering and Data Science and explore how embracing new data engineering techniques may affect the industry culture. You will learn about use cases of Data Engineering in other industries and how advances in digital capability have affected their business model. We will also share some of the many software packages and tools available to enable automation, commonly used in Data Engineering and Data Science. Finally we will reflect on the benefits that data standardisation has brought to the pharmaceutical industry and share our vision for disseminating information to facilitate your learning going forward. DATA ENGINEERING To start this learning journey, exploring the term “Data Engineering” opens the door to the vast opportunities and roles available today centered around data. In doing a simple search on the internet, ​“what is data engineering?​”, one will find many posts expressing their understanding of Data Engineering with some variation but also some similarity. However, what is clear is that Data Engineering encompasses the many considerations that need to be taken into account to optimally curate, transform, secure and disseminate data suitable for analysis. As technology and tools have become more advanced, building such a platform and infrastructure requires engineers and architects of both general and specific expertise. The Data Engineer combines knowledge in areas such as software development, infrastructure, data architecture, data warehousing, cloud technology and data cleaning in order to design, build and test solutions that define the pipelines of data throughout the enterprise, making the data accessible to the organisation.​ [5] [27] [31] Optimised Data Engineering appropriately balances the efficiency of an automated process against the cost of development and maintenance of that process, ensuring repetitive processes that require humans to write code, press keys, cut-and-paste and update documents are minimised or eliminated. DATA SCIENCE Often paired with the term “Data Engineering” is also the term “Data Science”. According to Kelle O’Neal and Charles Roe: “Data Science allows enterprises the ability to turn their data assets into a narrative. Data Science allows that narrative to be expanded across timelines, in different data spaces that trace from the past into the future, with much more involved questions and answers about an enterprise, different potential outcomes, and repercussions based on recommendations. Data Science employs a range of mathematical, business, and scientific techniques to solve complex problems about an organisation’s data assets.” ​ In contrast, the focus of the Data Engineer is on the process from data curation to dissemination and the focus of the Data Scientist is on the analytics of the data, thus extracting knowledge from the data. To achieve quality data capture, near-real-time accessibility and meaningful analytics, one cannot function without the other, and effective teamwork optimises the value of each role. As such, an analytics team would be composed of distinct roles/capabilities​ : ● Data Engineers (in areas such as database architecture, database development, machine learning architecture, ETL scripting , etc.) ● Data Scientists ● Business Analysts Data Engineering brings together the broad expertise, of these roles, to ensure the data are curated and accessible to the Data Scientist, and in our environment today, this process is becoming more and more complex. Therefore, 2 PhUSE EU Connect 2018 expertise in curating big-data and data of varying formats (structured and unstructured) is a critical core competency to optimise the potential impact of these digital assets (i.e. the data). The Data Scientist works deep in the data, utilizing various tools and techniques to discover patterns in the data that may drive decision making for the business. Optimising utilisation of the data to enable accurate conclusions can bear greater value to the organisation. As an example, per Tom Eunice’s post, “a fraud-detection algorithm may be very accurate when based on many months of historical data. However, months of historical data may not always be available. Designing a fraud-detection model that is still accurate using historical data from only a few days would be of more use and more practical to implement.” ​ The Business Analyst helps the Data Scientist understand the meaning of the data and the relevance of any discovered relationships. Initially, uncovering relationships in the data and upon further investigation, identifies meaningful patterns that may reveal information that otherwise may not have been known. ​ As you will see in the sections to follow, the full complement of the roles in an analytics team is what drives the business value. One discipline without the other (e.g. data engineering without data science) will result in missed opportunities. In the sections to follow, we often refer to Data Engineering, however, due to the close ties to Data Science, some examples elude to both Data Engineering and Data Science. USE CASES FROM OTHER INDUSTRIES In this section, we present three use cases from the transportation, retail, and agricultural industry. The use cases illustrate the importance and usage of Data Engineering. In each example the data collected, the consumer of the data, and the value of the organisation is reviewed. Similarities and potential applications to the pharmaceutical industry are discussed. UBER When",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
cc79c0fa6e39ea58910fe54bb9b966d333d76cb3,https://www.semanticscholar.org/paper/cc79c0fa6e39ea58910fe54bb9b966d333d76cb3,Data Engineering Project (Educating for the Future PhUSE Working Group),"With an expected 100% increase, over the next 3 years, of data from non-EDC sources (such as smartphones, wearables and custom apps) the traditional methods of managing data for clinical trials presents executives with a resourcing headache. As such, many companies are looking for lower cost strategies to mitigate this resourcing challenge. However, citing case studies from other industries, there are new methodologies/technologies in data engineering which could enable automation of much of the “heavy-lifting” currently practiced in clinical data management and statistical programming. This paper discusses the Data Engineering Project within the PhUSE Computational Science (CS) Working Group, Educating for the Future, with a view to educate clinical data managers in data engineering principles so that they can be prepared, equipped and effective in dealing with the coming “data tsunami” heading to the shores of clinical research. INTRODUCTION Did you realise we are living in the age of the Fourth Industrial Revolution? Perhaps you have been busy downloading a myriad of “apps” designed to make your life easier or connecting on social media, uncovering relationships and associations you didn’t even know you had. Perhaps you have been shopping a global marketplace, comparing prices, quality and availability, all at your fingertips and in a minutes’ time. While this has been happening, the Fourth Industry Revolution has been evolving at exponential proportions . Just ask Siri! The term “Industrie 4.0”, was originated in Germany, as a government-led initiative, to transform manufacturing through advanced digital capability. Thus creating the concept of a “smart factory”, based on four key design principles : 1. Interconnection of machines, devices, sensors and people 2. Vast amounts of useful information (data) to drive decision making 3. Technical assistance to aid humans, for example to visualise data or to perform tasks that may be a safety risk for a human. 4. The use of cyber-physical systems to make decisions on their own and to perform tasks as autonomously as possible. Emerging from the premise of “Industrie 4.0” is the advent of the term “The Fourth Industrial Revolution” (also referred to as “4IR” or “I4.0”). This term originated in 2016 when described by Klaus Schwab (Founder and Executive Chairman of the World Economic Forum), as a “technological revolution that will fundamentally alter the way we live, work, and relate to one another”. Klaus goes on to describe it as a digital revolution with innovative uses of a combination of technologies that build upon the premise of the third revolution (i.e. electronics and information technology to automate production). As a result, emerging technologies have brought forth advancements in fields such as artificial intelligence, robotics, the Internet of Things, autonomous vehicles, 3D printing, nanotechnology, biotechnology, materials science, energy storage, and quantum computing. This rapid evolution will undoubtedly affect industries world-wide, already disrupting many industries, such as travel agencies, video rentals and bookstores . The pharmaceutical industry is also experiencing the impacts of I4.0. Digital and mobile technologies have brought on significant advancements in data acquisition and accessibility as it relates to health care and patient data. A recent study, conducted in 2017, by Tufts University in collaboration with Veeva Systems, shows that close to 100% 2 of companies surveyed, estimate utilization of various electronic data sources in clinical studies. As shown in Figure 1. below, companies utilizing e-sources such as, smartphones, custom applications, and mobile health, will more than double in the next 3 years . Therefore, requiring greater capabilities in handling large volumes of data, data from multiple sources and data of varying formats. As with other industries, data will become a critical asset and the effective utilisation of this data can play a key role in driving growth in the business while bringing novel therapies to the patients who need them. source: Tufts – Veeva 2017 EClinical Landscape Study. Tufts University, 2018, pp. 11–13, Tufts – Veeva 2017 EClinical Landscape Study. In this paper, we will focus on the works of the Data Engineering Project within the Educating for the Future Working Group. With the formation of the Working Group in early 2018, the team had taken on the mission to explore how data engineering techniques, successfully deployed in other industries, could be utilised in the pharmaceutical industry, with a goal to facilitate the education of the pharmaceutical industry on these techniques. We will share with you some introductory information about Data Engineering and Data Science and explore how embracing new data engineering techniques may affect the industry culture. You will learn about use cases of Data Engineering in other industries and how advances in digital capability have affected their business model. We will also share some of the many software packages and tools available to enable automation, commonly used in Data Engineering and Data Science. Finally we will reflect on the benefits that data standardisation has brought to the pharmaceutical industry and share our vision for disseminating information to facilitate your learning going forward. DATA ENGINEERING To start this learning journey, exploring the term “Data Engineering” opens the door to the vast opportunities and roles available today with the overarching goal to optimise the use of data in day to day business operations. In doing a simple search on the internet, “what is data engineering?”, one will find many posts expressing their understanding of Data Engineering, with some variation. However, what is clear is that Data Engineering encompasses the many considerations that need to be taken into account to optimally curate, transform, secure and disseminate data suitable for analysis. As technology and tools have become more advanced, building such a platform and infrastructure requires engineers and architects of both general and specific expertise. The Data Engineer combines knowledge in areas such as software development, infrastructure, data architecture, data warehousing, cloud technology and data cleaning in order to design, build and 3 test solutions that define the pipelines of data throughout the enterprise, making the data accessible to the organisation. [5] [27] [31] Optimised Data Engineering appropriately balances the efficiency of an automated process against the cost of development and maintenance of that process, ensuring repetitive processes that require humans to write code, press keys, cut-and-paste and update documents are minimised or eliminated. DATA SCIENCE Often paired with the term “Data Engineering” is also the term “Data Science”. According to Kelle O’Neal and Charles Roe: “Data Science allows enterprises the ability to turn their data assets into a narrative. Data Science allows that narrative to be expanded across timelines, in different data spaces that trace from the past into the future, with much more involved questions and answers about an enterprise, different potential outcomes, and repercussions based on recommendations. Data Science employs a range of mathematical, business, and scientific techniques to solve complex problems about an organisation’s data assets.” [26] In contrast, the focus of the Data Engineer is on the process from data curation to dissemination and the focus of the Data Scientist is on the analytics of the data, thus extracting knowledge from the data. To achieve quality data capture, near-real-time accessibility and meaningful analytics, one cannot function without the other, and effective teamwork optimises the value of each role. As such, an analytics team would be composed of distinct roles/capabilities : ● Data Engineers (in areas such as database architecture, database development, machine learning architecture, ETL scripting, etc.) ● Data Scientists ● Business Analysts Data Engineering brings together the broad expertise, of these roles, to ensure the data are curated and accessible to the Data Scientist, and in our environment today, this process is becoming more and more complex. Therefore, expertise in curating big-data and data of varying formats (structured and unstructured) is a critical core competency to optimise the potential impact of these digital assets (i.e. the data). The Data Scientist works deep in the data, utilizing various tools and techniques to discover patterns in the data that may drive decision making for the business. Optimising utilisation of the data to enable accurate conclusions can bear greater value to the organisation. As an example, per Tom Eunice’s post, “a fraud-detection algorithm may be very accurate when based on many months of historical data. However, months of historical data may not always be available. Designing a fraud-detection model that is still accurate using historical data from only a few days would be of more use and more practical to implement.” [17] The Business Analyst helps the Data Scientist understand the meaning of the data and the relevance of any discovered relationships. Initially, uncovering relationships in the data and upon further investigation, identifies meaningful patterns that may reveal information that otherwise may not have been known. [17] As you will see in the sections to follow, the full complement of the roles in an analytics team is what drives the business value. One discipline without the other (e.g. data engineering without data science) will result in missed opportunities. In the sections to follow, we often refer to Data Engineering, however, due to the close ties to Data Science, some examples elude to both Data Engineering and Data Science. USE CASES FROM OTHER INDUSTRIES In this section, we present three use cases from the transportation, retail, and agricultural industries. T",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,https://www.semanticscholar.org/paper/8061d521fe7c62430e1ba2cb0b8f4d19f7366e6f,Multi Uav Cooperative Surveillance With Spatio Temporal,"Deep Learning for Unmanned SystemsMultiple Heterogeneous Unmanned Aerial VehiclesAdvanced Mobile RoboticsSafe Robot Navigation Among Moving and Steady ObstaclesComputer Safety, Reliability, and SecurityAdvances in Swarm IntelligenceHolonic and Multi-Agent Systems for ManufacturingAdvances in Artificial Intelligence and Applied Cognitive ComputingUnmanned Aircraft SystemsIntelligent Computing Theories and ApplicationAutonomous Airborne Wireless NetworksAd Hoc NetworksEnabling Blockchain Technology for Secure Networking and CommunicationsUAV Sensors for Environmental MonitoringUnmanned Aerial Vehicles: Breakthroughs in Research and PracticeComputational Collective IntelligenceTime-Critical Cooperative Control of Autonomous Air VehiclesAdvances in Cooperative Control and OptimizationCooperative Robots and Sensor Networks 2015Artificial Intelligence and SecurityPRICAI 2016: Trends in Artificial IntelligenceClosing the Gap Between Research and Field Applications for Multi-UAV Cooperative MissionsMulti-rotor Platform Based UAV SystemsProceedings of the Future Technologies Conference (FTC) 2020, Volume 1Unmanned Aerial SystemsAdvanced Distributed Consensus for Multiagent SystemsCooperative Control of MultiAgent SystemsMulti-UAV Planning and Task AllocationMobile Internet SecurityCooperative Control of Multiple Unmanned Aerial Vehicles with Application to Forest Fire Detection and FightingMulti UAV Systems with Motion and Communication ConstraintsIntelligent Autonomy of UAVsIntelligent and Fuzzy Techniques in Big Data Analytics and Decision MakingIntelligent Autonomy of UAVsUAV Cooperative Decision and ControlCooperative Localization and NavigationAdvances in Guidance, Navigation and ControlMachine Learning and Intelligent CommunicationsUnmanned Aerial VehiclesThe Cognitive Approach in Cloud Computing and Internet of Things Technologies for Surveillance Tracking Systems Ad hoc networks, which include a variety of autonomous networks for specific purposes, promise a broad range of civilian, commercial, and military applications. These networks were originally envisioned as collections of autonomous mobile or stationary nodes that dynamically auto-configure themselves into a wireless network without relying on any existing network infrastructure or centralized administration. With the significant advances in the last decade, the concept of ad hoc networks now covers an even broader scope, referring to the many types of autonomous wireless networks designed and deployed for a specific task or function, such as wireless sensor networks, vehicular networks, home networks, and so on. In contrast to the traditional wireless networking paradigm, such networks are all characterized by sporadic connections, highly error-prone communications, distributed autonomous operation, and fragile multi-hop relay paths. The new wireless networking paradigm necessitates reexamination of many established concepts and protocols, and calls for developing a new understanding of fundamental problems such as interference, mobility, connectivity, capacity, and security, among others. While it is essential to advance theoretical research on fundamental and practical research on efficient policies, algorithms and protocols, it is also critical to develop useful applications, experimental prototypes, and real-world deployments to achieve an immediate impact on society for the success of this wireless networking paradigm.A comprehensive review of the state of the art in the control of multi-agent systems theory and applications The superiority of multi-agent systems over single agents for the control of unmanned air, water and ground vehicles has been clearly demonstrated in a wide range of application areas. Their large-scale spatial distribution, robustness, high scalability and low cost enable multi-agent systems to achieve tasks that could not successfully be performed by even the most sophisticated single agent systems. Cooperative Control of Multi-Agent Systems: Theory and Applications provides a wide-ranging review of the latest developments in the cooperative control of multi-agent systems theory and applications. The applications described are mainly in the areas of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Throughout, the authors link basic theory to multi-agent cooperative control practice — illustrated within the context of highly-realistic scenarios of high-level missions — without losing site of the mathematical background needed to provide performance guarantees under general working conditions. Many of the problems and solutions considered involve combinations of both types of vehicles. Topics explored include target assignment, target tracking, consensus, stochastic game theory-based framework, event-triggered control, topology design and identification, coordination under uncertainty and coverage control. Establishes a bridge between fundamental cooperative control theory and specific problems of interest in a wide range of applications areas Includes example applications from the fields of space exploration, radiation shielding, site clearance, tracking/classification, surveillance, search-and-rescue and more Features detailed presentations of specific algorithms and application frameworks with relevant commercial and military applications Provides a comprehensive look at the latest developments in this rapidly evolving field, while offering informed speculation on future directions for collective control systems The use of multi-agent system technologies in both everyday commercial use and national defense is certain to increase tremendously in the years ahead, making this book a valuable resource for researchers, engineers, and applied mathematicians working in systems and controls, as well as advanced undergraduates and graduate students interested in those areas.Time-Critical Cooperative Control of Autonomous Air Vehicles presents, in an easy-to-read style, the latest research conducted in the industry, while also introducing a set of novel ideas that illuminate a new approach to problem-solving. The book is virtually self-contained, giving the reader a complete, integrated presentation of the different concepts, mathematical tools, and control solutions needed to tackle and solve a number of problems concerning time-critical cooperative control of UAVs. By including case studies of fixed-wing and multirotor UAVs, the book effectively broadens the scope of application of the methodologies developed. This theoretical presentation is complemented with the results of flight tests with real UAVs, and is an ideal reference for researchers and practitioners from academia, research labs, commercial companies, government workers, and those in the international aerospace industry. Addresses important topics related to time-critical cooperative control of UAVs Describes solutions to the problems rooted in solid dynamical systems theory Applies the solutions developed to fixed-wing and multirotor UAVs Includes the results of field tests with both classes of UAVsThis book provides the state-of-the-art intelligent methods and techniques for solving realworld problems along with a vision of the future research. The fifth 2020 Future Technologies Conference was organized virtually and received a total of 590 submissions from academic pioneering researchers, scientists, industrial engineers, and students from all over the world. The submitted papers covered a wide range of important topics including but not limited to computing, electronics, artificial intelligence, robotics, security and communications and their applications to the real world. After a double-blind peer review process, 210 submissions (including 6 poster papers) have been selected to be included in these proceedings. One of the meaningful and valuable dimensions of this conference is the way it brings together a large group of technology geniuses in one venue to not only present breakthrough research in future technologies, but also to promote discussions and debate of relevant issues, challenges, opportunities and research findings. The authors hope that readers find the book interesting, exciting and inspiringAdvanced Distributed Consensus for Multiagent Systems contributes to the further development of advanced distributed consensus methods for different classes of multiagent methods. The book expands the field of coordinated multiagent dynamic systems, including discussions on swarms, multi-vehicle and swarm robotics. In addition, it addresses advanced distributed methods for the important topic of multiagent systems, with a goal of providing a high-level treatment of consensus to different versions while preserving systematic analysis of the material and providing an accounting to math development in a unified way. This book is suitable for graduate courses in electrical, mechanical and computer science departments. Consensus control in multiagent systems is becoming increasingly popular among researchers due to its applicability in analyzing and designing coordination behaviors among agents in multiagent frameworks. Multiagent systems have been a fascinating subject amongst researchers as their practical applications span multiple fields ranging from robotics, control theory, systems biology, evolutionary biology, power systems, social and political systems to mention a few. Gathers together the theoretical preliminaries and fundamental issues related to multiagent systems and controls Provides coherent results on adopting a multiagent framework for critically examining problems in smart microgrid systems Presents advanced analysis of multiagent systems under cyberphysical attacks and develops resilient control strategies to guarantee safe operationComplete with online files and updates, this cutting-edge text looks at the next generation of unmanned flying machines. Aerial robots can be considered as an evolution of the Unmanned Aerial Vehicl",,2021.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
881da38df5ad2b71dcc500bf5041c6cec562b14f,https://www.semanticscholar.org/paper/881da38df5ad2b71dcc500bf5041c6cec562b14f,THE ROLE OF MULTIMODAL IN THE LEARNING SENSORIMOTOR INVOLVEMENT OF COGNITIVE SKILLS,"The existence and extent of effects of small-scale haptic involvement on recall performance in an explicit memory task were investigated in two related experiments involving a total of 40 subjects. The memory task was structured in such a way that it abstracts two of the fundamental activities encountered when interacting with realworld equipment through physical control interfaces: 1) the identification of the state of the system to be acted on; and 2) the recall of the series of actions which are to be taken when the system is in that state. Furthermore, the experiments were designed as training experiments. Haptic sensorimotor involvement is evaluated as an aid to training -it is used during practice and not used during performance. Results from Memory Experiment 1 show (i.e., Ho: p < 0.01 for 5 minute, 30 minute, and 24 hour examinations) that experimental group subjects performed approximately 2.5 times better when they trained with both visual stimuli (i.e., a keypad graphic) and haptic involvement than when they trained without these visual and haptic stimuli. Memory Experiment 2 shows (i.e., Ho: p < 0.05 for 5 and 30 minute examinations) that experimental group subjects performed approximately 1.5 times better when they trained with the keypad graphic and haptic interaction than when they trained with the keypad graphic only. These results were obtained even though the design of the experiments was such that independent variables affected the training of only the action part of sequences (i.e., the training of the sequence label was not affected by the independent variables) and experimental group examinations required recall of sequences memorized under two different conditions. The results of the two memory experiments suggest that: 1) small-scale haptic involvement can act as a training aid for a purely cognitive task; and 2) small-scale haptic involvement can compliment visual stimuli as an aid to training in a purely cognitive task. Thesis Supervisor : Nathaniel I. Durlach Title: Senior Scientist, Department of Electrical Engineering and Computer 1.0 Introduction The increased commercial availability of interface and computational devices supporting the development of multimodal, spatially-oriented, interactive human/machine interfaces has contributed to a burgeoning interest in the field of human/computer interaction (Biocca, 1992). Devices such as binocular stereoscopic helmet mounted displays, binaural stereophonic spatialization devices, haptic interaction devices, and unobtrusive position/orientation sensors are enabling the creation of human/machine interfaces for interaction with telerobots and computational models of a form and type which were previously found only in specialized research and military efforts (e.g., Freund, 1986; Shaker and Wise, 1988; Tachi, Arai, and Maeda, 1989; Aviles, Hughes, Everett, et. al., 1990). In their most extreme manifestations, systems utilizing these technologies are attempting to remove the boundaries associated with devices mediating interaction between humans and remote task environments (physical and computer generated) and, in some sense, project the human into these remote or virtual environments. Virtual environment (VE) systems in particular are experiencing a high degree of interest from the military, commercial, and private sectors. Current and foreseen application domains for VE systems include: (1) design, manufacturing, and marketing; (2) medicine and health care; (3) entertainment; and (4) training (Durlach and Mavor, 1995). This discussion will focus on research issues associated with using VE systems and technology for training. From a training perspective, some key features of virtual environments are that they are: 1) interactive and adaptive; 2) reconfigurable in software; 3) multimodal; and 4) can generate supernormal situations (Durlach, Pew, Aviles, DiZio, and Zeltzer, 1992). These features allow VE-based training systems to be developed which can be precisely tailored to specific tasks and individuals. In many ways, however, VE-based training systems may be viewed as natural outgrowths of previous simulation-based training systems (e.g., flight trainers). In some form, all four aforementioned key VE features apply to these ""classical"" trainers. In what ways, therefore, are VE-based systems unique? First of all, in contrast to classical simulation systems, VE-based systems can be highly reconfigurable for BOTH the far-field (i.e., objects and interactions out of reach) and the near-field (i.e., objects and interactions within reach). Classical flight simulators, for example, only reconfigure the scenery and environment outside of the airplane (i.e., the far-field) and do not easily allow flexibility in the airplane display and control layout (i.e., the near-field). In contrast, a VE-based training system can simulate a variety of nearand far-field configurations while utilizing the same human/machine interface devices. The second key characteristic of VE-based training systems is the potential for allowing multimodal (i.e., visual, auditory, and haptic) interactions. Unlike classical computer-based simulation systems, near-field simulations can be generated which may seen, felt, and heard in a spatially-oriented manner. Virtual environment systems, therefore, are unique in that they can generate reconfigurable multimodal sensorimotor near-field interactions. A large and growing percentage of the tasks encountered in military, commercial, and private enterprises, however, are predominantly cognitive in nature. For example, many of these tasks require mainly that the human operator control and monitor a system through the use of a control panel. Although the main interaction with such control panels is through the sensorimotor system, the requirement to know what controls to operate and when to operate them is largely a cognitive task. One viewpoint is that, given the aforementioned trends, training for manipulative skills is unimportant. Strong proponents of this view argue that the majority of IMPORTANT skills, independent of frequency of occurrence, are largely cognitive in nature (Welford, 1976). By extension, it is argued that, since sensorimotor skills are not the main skills which must be trained, sensorimotor involvement in VE-based training systems is not required or is of secondary importance. In other words, it is assumed that sensorimotor involvement is not needed for the training of cognitive skills. In the research described in this thesis, these assumptions were tested and the effect of multimodal sensorimotor involvement in the training of predominantly cognitive tasks was examined in a task which requires subjects to: 1) identify a discrete system state, and 2) identify a series of discrete actions which must be taken in response to that state. Training effectiveness is measured and compared between 1) ""classical"" textbased training methods and 2) training methods which provide visual stimuli and which require haptic sensorimotor involvement. 2.0 Background Intellectual or cognitive skills ""link perception and action and are concerned with translating perceptual input into a skilled response by using appropriate decisions."" Colley and Beach, 1989, p. 2 From a training research viewpoint, VE-based systems are interesting only to the extent that training efficiency, skill performance, or skill retention are influenced and/or psychophysical insight may be gained. From a practical viewpoint, issues of cost (e.g., training system cost, time/cost required to train to a certain level of proficiency, and resource use costs), safety (i.e., limiting trainee exposure to threatening situations), portability (i.e., ability to effect training at a variety of sites) and reconfigurability (i.e., ability to use the same system to train a variety of skills) are of import. Lower training effectiveness measures may be tolerable in certain situations if the system's practical factors evaluate positively for a given training system. Nonetheless, a crucial factor in the evaluation of any training methodology or system is its training effectiveness. To date, however, research relevant to assessing the quantitative impact of multimodal sensorimotor involvement in the training of predominantly cognitive tasks has been minimal. Current models that are directed towards the learning of cognitive skills often fail to consider the possible effects of sensorimotor involvement in the learning of these cognitive skills (e.g., Anderson 1990, Posner, 1989; Preece, Rogers, Sharp, Benyon, Holland, and Carey, 1994; Benyon and Murray, 1993; Frederiksen and White, 1993; Roberts, 1993). Most relevant research has occurred in the use of subject performed tasks (SPTs) and experimenter performed tasks (EPTs) in event/action recall memory experiments (e.g., Cohen, 1981; Cohen, Peterson, and Mantini-Atkinson, 1987; Koriat, Ben-Zur, and Nussbaum, 1990; McAndrews and Milner, 1991). These experiments, however, explore the effects of multimodal sensorimotor involvement on the recall of tasks which are inherently sensorimotor in nature. To the knowledge of the author, principled examination of the impact of multimodal sensorimotor involvement on the training of predominantly cognitive skills is non-existent. Why pursue work in this area? First of all, insight into the role of multimodal sensorimotor involvement in training will have strong implications for the practical design of VE-based training systems (e.g., assessing if the added complexity and cost of haptic and auditory components is worthwhile for a given training task). Second, experimental results may aid in extending current cognitive training theory to encompass sensorimotor involvement. The question still remains, however, as to what evidence or plausible mechanisms exist which indicate that multimodal sensorimotor involvement may have an effect on the training of cognitive tasks? Changes in training perform",,2008.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
2ff29ea3641c45e90157a04bd47ed6d497ccac14,https://www.semanticscholar.org/paper/2ff29ea3641c45e90157a04bd47ed6d497ccac14,Implementation of Data Mining from Social Media for Improved Public Health Care,"To improve public health care outcomes with reduced cost, this research proposed a framework which focuses on the positive and negative symptoms of illnesses and the side effects of treatments. However, previous studies have been limited as they neither identified influential users nor discussed how to model forms of relationships that affect network dynamics and determine the accurate ranking of certain end user’s feedbacks. In this research, a two-step analysis framework is proposed as the system. In the first level, the system utilized exploratory analysis and clustered users and their useful feedbacks through self-organizing maps (SOM). In the second level, the system developed three lists of negative and positive feedbacks and treatment symptoms caused by implanting the SOM that considered accurate ranking by calculating the frequency of each term of interests. The feasibility of the proposed solution is confirmed as performance evaluations of the system in terms of computational costs. The results showed that these solutions are reasonable computational costs relative to memory and processor usage. Keywords—Data mining; social media; medical data; end user feedbacks; positive terms; negative terms; symptoms I. RESEARCH MOTIVATIONS AND BACKGROUND Data mining from social media recently gained the attention of many important businesses and industries. Data mining is empowered by the recent advances in big data analysis as well as the network modeling of social media forums and websites, which are integrated to achieve knowledge discovery solutions and to extract useful information from various fields [1]. The health care industry is one of the most important fields that can be significantly enhanced by modern data mining techniques that allow the discovery of certain trend patterns as a product of the social media feedbacks generated dynamically from the experiences and opinions of end users [2]. These techniques can be applied to drug feedbacks in social media which can help manufacturers continuously enhance their products at reducedcosts. Successful data mining from social media can result in numerous benefits for business owners and manufacturers [3]; however, a number of challenges should be addressed first to reach the acceptable level and wide deployment of this new technology [4]. In addition, classical data mining techniques and algorithms should be empowered with an intelligent pattern recognition tool to predict and visualize the common trends of the data in general. Moreover, it should weigh certain descriptions or feedbacks based on their frequency and eliminate some neutral words as a filtration technique in the preprocessing stage. Different online forums contain feedbacks that should be network-modelled for a more convenient analysis. All these challenges are the main inspirations that motivated this research. The main contributions of this work can be considered as developing a feasible text data-mining solution that can partition different users with certain ID by modeling their existence in different web forums. Furthermore, the accurate clustering of negative and positive feedbacks and the visualization of the overall positive or negative feedback trends in a reasonable computational cost solution is another benefit from this research. The basic concepts are explained in this section as a background of the research field and the proposed solutions. First, the processes of data collection and mining are considered challenging tasks given a large number of networks studied, and this requires a complex representation of the social network structure. The complexity of such structure is derived from network density and levels of the parents and nodes clustering social media contents. Network clustering involves complex, big, and parallel data processing to cover the analysis of each networks’ nodes representing certain user communities. A part of the network usually as small as the sample size is used for data collection. Future Technologies Conference (FTC) 2017 29-30 November 2017| Vancouver, Canada 235 | P a g e Traditionally, structuring and modelling social networks can extract useful information as topic trends and the trends of opinions and the linguistics properties play an effective role in this study. At the beginning, certain word filtration techniques are used to remove unwanted words, such as stop and stemming words [5]. The concept of the self-organizing map (SOM) is utilized in particular research fields; in the simplest terms, SOM is a predefined wordlist used to correlate with the large data from the social networks under the tests to extract positive and negative words [6]. Importantly, certain algorithms are used to determine the frequency of certain positive or negative words, so that weighing the word (in another meaning its effectiveness among other words) can be determined. Finally, simple statistical tools are used to identify a positive or negative trend and the most common words describing the symptoms of drug use. Similar solutions in the literature on disease surveillance for the case of Influenza-related community who share fluposting online is utilized through the technique text and structural data mining of web and social media (WSM) [7] [8]. In the critical analysis of the SOM and WSM techniques in the literature [9], [10], it can be concluded that SOM techniques have more advantages in terms of the capability of investigating the positive and negative feedbacks of treatments. This advantage can be achieved by mapping large dimensional information onto a low dimensional space. II. METHODOLOGIES OF THE PROPOSED SYSTEM A two-step framework is proposed as an investigatory analysis to evaluate the correlations between user posts and positive/negative words under a drug name. The correlation is obtained by using SOM. Using a network-based approach, the system enabled users and their posts to find the possible partition using complete linkages. The two processes involved with inter-social dynamic maps for reviewing SOM results are described below:  The correlation between user and judgment.  The partition between users and their posts. Regarded as an unsupervised technique, Self-OrganizingMap (SOM) is used to explore the survey dataset based on the artificial neural network. The representation of the SOM data is in multidimensional data such as two or three dimension. Based on the data compression of the vector quantization technique, the SOM process is used to reduce the dimensionality of sectors. The information is stored as a topological relationship within the training sets in a network. Therefore, large data sets are visualized with high dimensionality using SOM. The competitive learning approach of SOM has one neuron unconnected to the input and output layers for each training phase. Although the connection between the neurons is absent, communication exists between each phase through a neighborhood function. The proposed SOM approach is used to summarize and visualize the profiles of individual patients. This visualization process helps determine domain experts. The two perspectives involved in the process of accurately obtaining results are computational and scientific perspectives [11]. By using SOM in the computational perspective, feasibility is examined by extracting useful information from questionnaires. In the scientific perspective, the different types of patient diseases such as type-I diabetes are collected to understand the responses in the diabetes survey and suggest about domain experts to clinicians. By contrast, clinicians are required to take a survey about their patients. The mean, skewness, variance, and frequency are the traditional descriptive statistical methods, but it provides simplified conclusions. Thus, data are analyzed based on statistical machine learning tools with black box by clinicians. The SOM algorithm is used for mining correlations and clustering similar responses within the surveys. If the dimension is higher for clustered responses, then the data is visualized in a two-dimensional grid to reduce data complexity. Complexity is reduced by revealing more meaningful relationships and by understanding the dependencies among the survey responses. Previously, SOM is used to visually explore data areas such as health, lifestyle, nutrition, financial, gene expression, marine safety, and linguistics. Recently, SOM is utilized to explore questionnaire-based loneliness survey data. The present research also focuses on improving data interpretation by revealing possible associations between the tendency of item nonresponse and the background variables of participants. The flaw conclusion is obtained by item nonresponse which is related to the background variables of respondents, such as age and gender nonresponses. Considering the undetected non-causative relationships between independent and dependent variables, the nonresponse factors affected patient satisfaction. In the present study, item nonresponse does not refer to participants who fail to return the survey, but to the ones who choose not to respond to all questions. In the proposed approach, the issues involved in this research are included for data analysis. Large surveys have demonstrated that although respondents and non-respondents in patient satisfaction surveys may differ according to several demographic and clinical characteristics, the differences in satisfaction between them tend to be relatively small and non-respondents do not constitute a homogenous group. Many highly sophisticated statistical methods are used as a standard technique to handle the problem of missing responses. In the existing link method, the idea that missing data are not just a statistical nuisance but also contain valuable information as such is tested simply by including the number of item nonresponses per respondent as an explanatory variable in the models. The expected predictors of pati",,2018.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
b5833291475084e893379f5d797753b366c61751,https://www.semanticscholar.org/paper/b5833291475084e893379f5d797753b366c61751,Privacy Literacy: Extending Information Literacy in the Age of Social Media and Big Data,"This paper argues that there is a need for extending the concept of information literacy to include privacy literacy, which we conceptualise as the awareness and tools needed to understand and navigate our contemporary world of connected information and synergistic technologies whilst also protecting ones personal information. The paper is based on an interview study of participants in combination with online ethnographic observations of social media, and a cognitive walkthrough of their social media use. Background In our information age, all of our lives are increasingly monitored and configured by digital technologies (Lupton, 2015) and this has implications on the goods and services we receive, including health, car, and home insurance (Pingo & Narayan, 2016). Google, Facebook, Twitter, and YouTube provide platforms for people to create a personal profile, share information, link to others, befriend strangers, connect with others, subscribe to channels, and follow people. This involves the sharing of personal information for verification that is later used to profile individuals for advertisements and other purposes (Buchman, 2013; Meikle, 2016). Such massively generated data from use of digital devices or applications is referred to as “big data” (Agnellutti, 2014), with a huge trend in data mining and machine learning in order to understand users’ preferences, and behaviour patterns. Such personal information can potentially be used beyond intended purposes (Pierson, 2012), and has sparked discussions on how they simultaneously empower and disempower users in various ways, creating opportunities and exposing users to vulnerabilities (Christiansen, 2011; Pierson, 2012; Rosenblat, Kneese, & Boyd, 2014). They also point to a shift in the responsiility of privacy to the user as is evident from the messaging from the Office of the Australian Information Commissioner, which says ‘privacy in your hands.’ (OAIC, 2016). This raises the question of whether users have the awareness, knowledge, and tools to take privacy in their hands. Therefore, the research question this study addresses is: Do everyday users of social media understand its implications for personal information privacy, and what measures do they take to protect their privacy? Conceptual framework Westin (1967) defined privacy as ‘the claim of individuals, groups or institutions to determine for themselves when, how, and to what extent information about them is communicated to others’. The process of regulating privacy is a dynamic process of optimizing two psychological needs: the need to preserve one’s privacy and control access to and distribution of personal information, and the need to interact socially, where one has to disclose personal information (Altman, 1975). Hence, privacy is constructed and negotiated in social processes (Solove, 2002). Information privacy is often considered a technical design problem in information systems research (Cavoukian & Jonas, 2012, p. 863; Lehikoinen, 2008). Rather than this system-centred approach, Debatin (2011, p. 57) recommends that people need to develop an understanding of technology and its unintended consequences. In other words, users of digital technologies need to develop an informed concern about their privacy, avoiding both moral panic and ignorant or naïve indifference towards information technologies (Debatin, 2011, p. 57). Christiansen (2011) notes two distinct information sharing practices which users of technologies need to know or understand: voluntary sharing and involuntary disclosures. Debatin (2011) defines privacy literacy as ‘an informed concern for individuals privacy and effective strategies to protect it’. From an information literacy perspective, privacy literacy is proposed as one’s level of understanding and awareness of how personal information is tracked and used in online environments, and how information can retain or lose its private nature (Givens, 2015, p. 53). Möllers and Hälterlein’s (2013) argue that people need to exhibit active participation in negotiating for their privacy through understanding what is at stake when using digital technologies. When people use digital devices or applications, they need to decide on whether to give personal information by consciously considering the terms and conditions of the service (Debatin, 2011), which often requires high-level cognitive effort, which users hardly have the time or the tools for (Gindin, 2009; Solove, 2012), and hence avoid engaging with it. This information avoidance is a stress and coping method deployed by humans to deal with cognitive dissonance or is a result of cognitive bias (Case, Andrews, Johnson, & Allard, 2005). Narayan, Case, and Edwards (2011) note that ‘people tend to seek out information that agrees with their pre-existing world-view and cognitive skill levels rather than acknowledge or seek new information that may cause an uncomfortable conflict in their minds’. The negotiated nature and commodification of privacy (Barnes, 2006; Thrift, 2005) causes such a cognitive dissonance and hence attracts information behaviour perspectives. The reason people avoid this information is not deliberate, but due to the sheer amount of time needed to read the privacy terms and the complexity of the language [and the interfaces] used (Potter, 2015). Methodology Perik, de Ruyter, and Markopoulos (2005) noted that there is a methodological problem especially in the domain of privacy in computer-mediated communication research. In a study of people’s information privacy perceptions though observations of actual use of a system, many respondents demonstrate risk-taking behaviours compared to interview responses (van de Garde-Perik, 2009, p. 21). To address these issues, a triangulation of methods was used in our study (Yin, 2013); we used a combination of online observations or digital ethnography (Talip, Narayan, Edwards, & Watson, 2015) and cognitive walkthroughs (Blackmon, 2004) alongside interviews with participants about their perceptions, awareness, and use of social media. Six university students participated in this study. Findings Findings show that privacy is a negotiated process wherein users decide on how much personal information they want to disclose online, and for what returns. Participants also exhibited various information behaviours such as information avoidance, due to information overload and the lack of cognitive tools to process the information. The cognitive walkthrough revealed that the interface of social media sites was a huge issue also — they are designed to be seamless which also means that most users did not know how to work the privacy settings. That said, we found two distinct groups amongst the participants. Those who, when there are two competing needs, choose to ignore their need for privacy over the immediate gains they can get from a transaction or interaction, while others were so paranoid about their privacy that it inhibited their online social interactions. We believe that both of these groups can benefit from privacy literacy that helps them engage with the online world without compromising their personal information. This calls for a need to incorporate privacy literacy as an essential complement to information literacy.",,2017.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
adbc8aa0ad677ec0b81955425fb888b4e2743a3a,https://www.semanticscholar.org/paper/adbc8aa0ad677ec0b81955425fb888b4e2743a3a,An hybrid platform for remote health monitoring: From concept to deployment,"This paper presents experimental results from a platform consisting of multiple wearable body area networks (BAN) connected to a wireless mesh network. The proposed platform collects, processes and wirelessly transmits medical data from multiple wearable BAN to a medical control center (MCC) through a solar-powered and multi-hop mesh network. This proof-of-concept platform encompasses several innovations. In the BAN, a dynamic TDMA MAC layer has been implemented over a 802.15.4 physical layer as well as 2 lightweight protocols. To reduce the number of packet sent by sensors and the size of packet sent by the gateway, a similarity-based filter and a polynomial interpolation technique respectively are used. In the solar-powered mesh network, a machine learning algorithm has been implemented to predict battery depletion and ensure continuity of service.","2015 7th International Conference on New Technologies, Mobility and Security (NTMS)",2015.0,10.1109/NTMS.2015.7266472,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
d5b014e55d39682ede47cf248d3c0a7d6973577b,https://www.semanticscholar.org/paper/d5b014e55d39682ede47cf248d3c0a7d6973577b,Beyond 5G Challenges: White Paper,"This white paper was prepared as an output from the highly successful EPSRC sponsored CommNet 5G workshop on 13 March 2014. The objective of the paper is to describe some of the major research challenges as perceived by the research community, where successful solutions ought to be implemented in future wireless systems in the next ten years. Introduction – Beyond 5G Wireless Standards Though the most recent fourth generation (4G) standard for cellular mobile communication systems, termed Long Term Evolution Advanced (LTE-A), targets downlink and uplink peak data rates of 1 Gbit/s and 500 Mbit/s, respectively, attention has already turned to a future 5G system where not only higher data rates are sought but also significant increases in throughput area efficiency (i.e. bit/s/km 2 ) to meet exponentially growing data demands. 5G will see a stronger interplay between communications, computing and control communities 1 . Rates at the wireless edge will be on a par with wireline connectivity, largely guaranteed by the heavy “densification” of access points and heavily liberated spectral resources. We will see the operators’ core network thinned and flattened further, due to e.g. a heavily reduced number of packet-gateways; many more direct Internet Protocol (IP)-injection points; the X2 interface carrying more traffic than just control messages; virtualization and cloudification being core to the design; etc. The Internet will be strictly software defined network (SDN)-enabled with many competing connectivity protocols offering a truly deregulated end-to-end connectivity to achieve a high Quality of Experience (QoE). For standards Beyond 5G (B5G) there are important challenges which require radical new solutions:  Ever-Growing Rate. Cisco forecasts 16 Exabytes of data sent through mobile networks in 2018, equivalent to 1.8 million years of HD video every month 2 , threatening a ‘radio frequency spectrum crunch’ in wireless communications. This trend is fuelled by new wireless paradigms such as the Internet-of-Everything (IoE), where devices rather than people wirelessly communicate over the Internet. The expectation is that by 2020, there will be over 1000 wireless devices per person on the planet. This will result in over 500 billion sensors being connected to the Internet in 2030. The IoE, a more general term for a wider range of applications than the Internet of Things (which envisages predominantly low data rate sensors), is heavily based on machine-to-machine (M2M) technology and facilitates markets such as the smart grid, home automation, e-health, and intelligent transportation. 1 See D. Soldani, ""Report on the 5G European Summit (5G ES), Munich, on Feb 10th,"" Next Generation Network Infrastructures, EIF Breakfast Debate, European Parliament, Feb. 19th, 2014. 2 See http://tinyurl.com/mokcut3  Architecture Deficiencies. Current network architectures lack the waveforms and signalling strategies and are too rigid to accommodate new and yet unforeseen services/functionalities and also inflexible in supporting a wide range of expected services of IoE, M2M and mobile broadband in general.  Energy Usage. Lastly, the operation of existing wireless networks requires an unsustainable amount of energy which is equivalent to the entire air-traffic network. In the year 2020, when B5G network designs are likely to commence, we expect to see a superstandard emerge which will orchestrate efforts of the 3GPP, the IETF, the IEEE, and other related standards development organisations. For the UK to take a leading role in research B5G systems there needs to be a solid University research base. Given the EPSRC typically funds such projects, an early lead with strong proposals will have a strong impact onto B5G developments globally. The following sections outline the technical challenges, as viewed by our academic community. Beyond 5G Architecture & Orchestration Any B5G communications architecture will necessitate a quantum-leap in design to cope with the predicted information tsunami, with inherent network scalability, intelligence and orchestration being core to the design. Scalability can only be achieved with a complete flattening, and thus complete removal, of the Core network. A flat architecture allows any IP-enabled system, whether incumbent or emerging, to offer seamless data delivery. This however poses significant research challenges related to core properties of mobile networks, such as mobility and billing. To this end, device-centric mobility solutions will likely emerge which will redefine our notion of cellular deployments. Furthermore, virtualized escrow-like control entities, completely decoupled from data bearers, will ensure appropriate billing and control. To cope with the exponentially increasing data and control flux, the fairly simple (in operation) network routers will need to be replaced by highly intelligent, individually as well as systememergent, entities which are able to curb traffic at the source as well as on the fly. Unprecedented research challenges lay ahead with self-learning middleware able to understand and interpret traffic injected from unknown systems, advanced data science methods understanding traffic content and thus facilitating best delivery mechanisms, quantumalgorithmic routers able to find (close-to) optimal delivery routes in shortest time, etc, all will be the norm in a B5G system. Ultra Dense Cell Networks Small cells, heterogeneous networks or Hetnets (which comprise multiple radio standards, e.g. cellular and Wi-Fi) and massive MIMO (multiple-in multiple-out) antenna technologies have been investigated separately, whereas significant benefits may be derived by integration of these technologies. A massive MIMO system scales up conventional MIMO by seeking to adopt possibly hundreds of antenna elements at a base station to simultaneously serve tens of high data rate users within the same frequency band. Aggressive spatial multiplexing and large array gain offers large increases in capacity combined with a reduction in transmission power per user. The high density deployment of small cells also offers high capacity gains in a cost and energy efficient manner through the intense reuse of the frequency spectrum. The shorter distances between the base station and user result in reduced path-loss and total network transmit power. By combining small and large cells in a heterogeneous network, an efficient architecture is achieved whereby small cells meet the needs of traffic hot spots while large cells provide reliable coverage for high mobility users. However, the dense deployment of small cells necessitates wideband backhaul connections. There is significant merit in combining these technologies such that the large cell massive MIMO technique is applied as both a backhaul connection to the network and as fronthaul to serve, via wireless, multiple small cell basestations with direct user support. Wireless backhaul is considerably easier to set-up than a cable backhaul and it enables simpler reconfiguration and upgrading. As massive MIMO must support a number of users directly as well as the small cells, the choice of frequency (in-band or out-band) has important implications for inter-cell interference management. In general, out-band signalling requires a less complex interference management regime but at the expense of failing to realise the largest possible capacity. Further options, in terms of time vs frequency division duplex operation, provide additional opportunities for system optimization. The following research is key to achieving the above goals:  New waveforms that allow scalability from ultra high density cells/high capacity to large coverage (100% coverage availability) and low data rates per device expected for IoE;  Interference management in ultra dense cells and in hetnets;  Hyper transceivers for cooperative ultra dense cells;  Co-existence between license and license-exempt bands;  Full duplex radio technologies;  Exploitation of different antenna polarizations as new degrees of freedom for data transmission. Reconfigurable Hardware design challenges from RF to THz It is inevitable fact that future spectrum is going to be highly fragmented, ranging from frequencies below 6 GHz to the millimeter(mm)-band and THz. New hardware design and manufacturing paradigms are key to the exploitation of such a fragmented spectrum and in particular for the mm-wave part of the spectrum, essential for achieving the data rates required for B5G systems. Electronically-steered high-gain 3D antennas and high levels of RF/DSP integration are essential, as demonstrated in Samsung’s 28 GHz 64-antenna system 3 . With unprecedented aggregate data rates in the backbone network, fibre connections and wireless backhaul at E/W-bands and beyond will be required. It is an immense challenge to realise hardware (transceivers, filters, power amplifiers, antennas) at frequencies from 28 GHz to 300 GHz, and beyond, with the low manufacturing costs demanded by network operators. Silicon RFIC technology is the key enabler, potentially even up to 1 THz, but considerable advances in RF design techniques are required to realise complete B5G subsystems, with research required in:  Concurrent and switchable multi-band mm-wave power amplifiers that are ultra linear and power efficient; 3 See: http://www.commnet.ac.uk/documents/comment_5g_workshop_130314/2_Samsung_5G.pdf  Reconfigurable and ultra broadband transceivers for all-spectrum access;  Tuneable filters and multiplexers with very high selectivity and linearity;  Steerable and multiband antennas integrated with RF transceivers and DSP with advanced new packaging solutions;  mm-wave phase-locked loops with fast switching and low spurious;  New transceiver architectures, working hand-in-hand with DSP researchers;  Low loss mm-wave to optical conversion. Furthermore, while mm-waves are key to providing the expected > 10 Gbit/s B5G sy",,2014.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
f0181da3c6618177bce90173afdd6eb352f4e22e,https://www.semanticscholar.org/paper/f0181da3c6618177bce90173afdd6eb352f4e22e,Guest Editorial: Computer Vision for Animal Biometrics,"Biometric Computer Vision that detects, tracks, identifies, describes, and classifies animal life from captured image and video data, is an emerging subject in machine vision. It is an exciting moment for this field of study. For the first time a myriad of realworld systems and applications are becoming integrated into the practice of the biological sciences. Indeed, Computer Vision systems have also started to assist work in a variety of allied scientific areas including field ecology, agricultural research, animal welfare, conservation, public health and the behavioural sciences. This Special Issue brings together a selection of eight timely papers in this field, submitted by researchers of institutions from across four continents. The works presented here include the analysis of animals ranging from insects and fish, to birds and mammals, but also life during embryonic development. The presented papers showcase some of the current diversity in this research domain: methods span the whole spectrum from traditional feature-based approaches to Deep Learning solutions. Psota et al. in their paper “Tracking of group-housed pigs using multi-ellipsoid expectation maximization” describe a system that utilises depth images accurately to estimate the position and orientation of individual pigs in a group-housed environment over significant periods of time. By applying expectation maximization as a policy for ellipse fitting, their method is able to exploit consistent shape and fixed target numbers to aid tracking. Practical results demonstrate that the system can track 15 group-housed pigs for an average of 19.7 minutes between failure events. Xie et al. in their paper “A novel open snake model based on global guidance field for embryo vessel location” present a framework for blood vessel region extraction and accurate snakebased localisation in imagery of animal embryos. Their open snake model utilises a global guidance field and is initialised by a deformation template. Experimental results on a specific embryo vessel database demonstrate that the proposed algorithm can robustly locate the embryo's blood vessels and obtain orientations of the vessel branches. Comparisons with traditional methods illustrate the effectiveness and competitiveness of their proposed model. Bakkay et al. in their paper “Automatic detection of individual and touching insects from trap images by combining contour-based and region-based segmentation” introduce a method for the detection of insects from camera trap images in difficult conditions by employing an innovative region merging algorithm and an adaptive k-means clustering approach, operating on the object contour's convex hull. Quantitative evaluations show that the proposed method can detect insects with higher accuracy than most widely used approaches. Eerola et al. in their paper “Automatic individual identification of Saimaa ringed seals” describe a method for the automatic image-based individual identification of endangered Saimaa ringed seals (Phoca hispida saimensis) that exploits the species’ permanent and individually unique visual pelage patterns. The proposed framework performs segmentation of the seals from the background, as well as post-processing and classification steps required for identification. Two existing individual identification methods are compared to the presented work using a challenging data set of Saimaa ringed seal images. The results show that the proposed segmentation and post-processing steps are effective and can provide increased identification performance against a generic baseline. Akkaya et al. in their paper “Mouse face tracking using a convolutional neural network” present a convolutional neural network (CNN) tracker called MFTN for following a mouse's face in video footage. Notably, in the proposed architecture, target information is extracted from a combination of lowand high-level features by a particular sub-network to achieve a more robust and accurate tracker. Experiments show that the particular MFTN/c tracker achieved an accuracy of 0.8, a robustness of 0.67, and a throughput of 213 fps on the GPU-powered testing workstation. Beyan et al. in their paper “Extracting statistically significant behaviour from noisy fish tracking data” describe an approach to the cleaning of a large and noisy visual tracking dataset to allow for the extraction of statistically sound results from the underlying image data. In particular, the paper presents an analysis of a dataset of 3.6 million underwater trajectories of a species of fish, which are also labelled with the water temperature at the time of acquisition. By a combination of data binning and robust estimation methods, the authors demonstrate reliable evidence for an increase in fish speed as water temperature increases. Several statistical tests applied to the data confirm that results are statistically significant. Ardo et al. in their paper “A CNN-based cow interaction watchdog” introduce an automated video analysis system for the processing of cow footage that can select or discard recorded video material based on user-defined criteria commonly required in behavioural research to reduce the amount of time experts have to spend on watching video. A CNN architecture is proposed and then evaluated in a pilot study. It is shown that 38% (50% with additional filter parameters) of the recordings in the test dataset could be correctly and successfully removed, while only losing 1% (4%) of the potentially interesting video frames. Finally, Silla Junior et al. in their paper “Bird and whale identification using sound images” describe a novel approach for the automated identification of birds and whales from calls. The visual features of audio used are constructed from different spectrograms and from harmonic and percussion images. These images are then divided into sub-windows from which sets of texture descriptors are extracted for classification. The experiments reported in this paper use a dataset of bird vocalizations targeted for species recognition and a dataset of right whale calls targeted for whale detection, as well as three well-known benchmarks for music genre classification. The authors demonstrate that the fusion of different texture features, as well as texture and audio features together can enhance performance. As is clear from the above content, this Special Issue highlights the great breadth of research in Visual Animal Biometrics today, and the even greater potential for this area of Computer Vision in the future. One may argue that the field is indeed on its way to realising another facet of Jim Gray's 4th scientific paradigm, ever more intricately binding together biological research questions with Computer Vision engineering. In any case, we hope that readers will find the papers put forward here inspiring and informative; and we would like to extend our sincere thanks to all authors and reviewers of the works before us.",IET Comput. Vis.,2018.0,10.1049/iet-cvi.2018.0019,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
e0ff1e95e940e29e7cdc99a84492a37e3a051786,https://www.semanticscholar.org/paper/e0ff1e95e940e29e7cdc99a84492a37e3a051786,RIACS FY2001 Annual Report,"Recently, there has been shift from consideration of optimal decisions in games to a consideration of optimal decision-making programs for dynamic, inaccessible, complex environments such as the real world. Perfect rationality is impossible in these environments, because of prohibiting deliberation complexity. Anytime algorithms attempt to trade off result quality for the time or memory needed to generate results. Bounded rational agents are ones that always take the actions that are expected to optimize their performance measure, given the percept sequence they have seen so far and limited resources they have. Process algebras, with basic programming operators, has been used to study the behaviors of interactive multi-agent systems and leading to more expressive models than Turing Machines, e.g., Interaction Machines. By extending process algebra operators with von Neumann/Morgenstern’s costs/utilities, anytime algorithms can be viewed as a basis for a general theory of computation. As the result we shift a computational paradigm from the design of agents achieving one-time goals, to the agents who persistently attempt to optimize their happiness. We call this approach $-calculus (pronounced “cost-calculus”), which is a higher-order polyadic process algebra with a utility (cost) allowing to capture bounded optimization and metareasoning in distributed interactive AI systems. $-calculus extends performance measures beyond time to include answer quality and uncertainty, using k Omega-optimization to deal with spatial and temporal constraints in a flexible way. This is a very general model, just as neural networks or genetic algorithms, leading to a new programming paradigm (cost languages) and a new class of computer architectures (cost-driven computers). The NSERC supported project on $-calculus aims at investigation, design and implementation of a wide class of adaptive real-time distributed complex systems exhibiting meta-computation and optimization. It has also been applied to the Office of Naval Research SAMON robotics testbed to derive GBML (Generic Behavior Message-passing Language) for behavior planning, control and communication of heterogeneous Autonomous Underwater Vehicles (AUVs). Some preliminary ideas have also been utilized in the 5th Generation ESPRIT SPAN project on integration of objectoriented, logic, procedural and functional styles of programming in parallel architectures. It appears that $-calculus can be useful for the NASA Information Power Grid (IPG) Project. The IPG testbed provides access to a widely distributed network of high performance computers. $calculus resource-bounded optimization allows for flexible allocation of resources and scalability needed to tackle hard computation problems, thus $-calculus could provide a unifying metasystem framework for the Information Power Grid. Biosketch: Dr. Eberbach is a Professor at School of Computer Science, Acadia University and an Adjunct Professor at Faculty of Graduate Studies, Dalhousie University, Canada. Previously he was Senior Scientist at Applied Research Lab, The Pennsylvania State University, Visiting Professor at The University of Memphis, USA, Research Scientist at University College London, U.K., Assistant Professor in Poland, and he also has industrial experience. Professor Eberbach’s current work is in the areas of process algebras, resource bounded optimization, autonomous agents and mobile RIACS FY2001 Annual Report October 2000 through September 2001 -135robotics. General topics of interest are new computing paradigms, languages and architectures, distributed computing, concurrency and interaction, evolutionary computing and neural nets. More information about projects, publications, courses taught can be found at http://cs.acadiau.ca/~eberbach October 27, 2000: Feng Zhao, Ph.D.,Principal Scientist, Xerox PARC “Smart Sensors, Collaborative Sensemaking” Imagine a world in which we live where smart roads would be able to tell us when they need repair and which is the best direction to get to the Giants game, smart factories would stock up just enough inventory, ... The rapid advances in micro-electro-mechanical systems (MEMS) and lower-power wireless networking have enabled a new generation of tiny, cheap, networked sensors that can be “sprayed” on roads, across machines, and on walls. However, these massively distributed sensor networks must overcome a set of technological hurdles before they become widely deployable. Keeping up with the constant onslaught of sensory data from say 100,000 sensors is akin to drinking from a fire hose. The Xerox PARC Smart Matter Diagnostics and Collaborative Sensing Project studies the fundamental problems of distilling high-level, humaninterpretable knowledge from distributed heterogeneous sensor signals in a rapid and scalable manner. We are developing powerful algorithms and software systems to enable a wide range of applications, from sensor-rich health monitoring of electro-mechanical equipment to human-aware environments that leverage sensors to support synergistic interactions with the physical world. Biosketch: Feng Zhao is a Principal Scientist in the Systems and Practices Laboratory at Xerox PARC. Dr. Zhao leads the Smart Matter Diagnostics Project that investigates how sensors and networking technology can change the way we build and interact with physical devices and environments. His research interest includes distributed sensor data analysis, diagnostics, qualitative reasoning, and control of dynamical systems. Dr. Zhao received his PhD in Electrical Engineering and Computer Science from MIT in 1992, where he developed one of the first algorithms for fast N-body computation and phase-space nonlinear control synthesis. From 1992 to 1999, he was Assistant and Associate Professor of Computer and Information Science at Ohio State University. His INSIGHT Group developed the SAL software tool for rapid prototyping of spatio-temporal data analysis applications; the tool is currently used by a number of other research groups. Currently, he is also Consulting Associate Professor of Computer Science at Stanford. Dr. Zhao was National Science Foundation and Office of Naval Research Young Investigator, and an Alfred P. Sloan Research Fellow in Computer Science. He has authored or co-authored about 50 peer-reviewed technical papers in the areas of smart matter, artificial intelligence, nonlinear control, and programming tools. October 12, 2000: Irem Tumer, Intelligent Health and Safety Group NASA/Ames “Influence of Variations on Systems’ Performance And Safety” High-risk aerospace components have to meet very stringent quality, performance, and safety requirements. Any source of variation is of concern, as it may result in scrap or rework (translating into production delays), poor performance (translating into customer dissatisfaction), and potentially unsafe flying conditions (translating into catastrophic failures). As part of the Intelligent RIACS FY2001 Annual Report October 2000 through September 2001 -136Health and Safety group, we have been designing controlled experiments to understand various sources of variations in helicopter transmissions, collecting vibration data, and analyzing the data for indicators of the variations. We are looking for normal and abnormal sources of variation that affect performance and indicators of these variations to provide warning about potential failures during flight. The experiments include: • Flight tests using an AH-1 and an OH-58 helicopter, to determine the variations introduced due to regular maneuvering and the covariance with environmental conditions, engine torque, etc.; • OH-58 transmission test-rig tests to determine the effect of variations due to different levels of torque, mast bending, and mast lifting forces, as well as pinion reinstallation effects; • Machinery Fault Simulator tests to test the effect of prefabricated defects and inherent design and manufacturing variations on gears, bearings, etc. In this talk, I will present an overview of our group’s research goals, discuss the experiments and go over some of the results from the data analyses conducted so far. I will then discuss the current work and future directions in developing formalized methods for design and manufacturing engineers, using the variation information from empirical and analytical studies. RIACS FY2001 Annual Report October 2000 through September 2001 -137III.B RIACS-Supported Workshops As part of its mission of fostering ties with the academic community in IT, RIACS provides financial, administrative, and technical support for selected workshops involving RIACS scientists. The following workshops were supported during this reporting year: Workshop on Verification and Validation of Software The RIACS Workshop on the Verification and Validation of Autonomous and Adaptive Systems took place at Asilomar Conference Center, Pacific Grove, CA, 5-7 Dec 2000. Discussions included: V&V of Intelligent Systems: How to verify and validate systems featuring some form of AI-based technique, such as model-based, rule-based or knowledge-based systems. V&V of Adaptive Systems: How to verify and validate systems featuring adaptive behavior, either in the form of parametric adaptation (e.g. neural nets, reinforcement learning) or control adaptation (e.g. genetic programming). V&V of Complex Systems: How to verify and validate systems with different interacting parts, either within a given location (e.g. layered control architectures) and among several locations (homogenous or heterogeneous multi-agent systems). Workshop on Model-based Validation of Intelligence Lina Khatib (Kestrel) and Charles Pecheur co-organized a symposium on “Model-based Validation of Intelligence” as part of the AAAI Spring Symposium Series in March 2001. We provided the technical content (announcement, reviews and selection of articles, final program) while AAAI provided the logistics (rooms, registra",,2001.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
50c1184569211e62e320bdea1d87b285e6cd1466,https://www.semanticscholar.org/paper/50c1184569211e62e320bdea1d87b285e6cd1466,Towards a New Safety Assurance Method for Complex Safety-Critical Systems,"Know your enemy and know yourself and you can fight a hundred battles without disaster. Sun Tzu, The Art of War This essay investigates the making of timely and acceptable safety assurance decision throughout a safety-critical system’s lifecycle in a complex environment. This ‘battle’ of assuring a safety-critical system is safe enough to avoid the ‘disaster’ of accident is a long and treacherous journey. It demands a structured and persistent method to support safety analysis despite challenges from the non-deterministic and non-linear environment throughout the system lifecycle. Learning from Sun Tzu, this journey begins by searching for clarity regarding the two important questions: ‘know yourself’ by understanding the current way of conducting safety management throughout a system lifecycle; and ‘know the enemy’ by examining the potential risk and hazards cause by the unique characteristics of complexity. This is followed by a survey of possible methods that can be used to analyse and mitigate the risk under a complex system. Systems Engineering Essay Competition 2015 Page 2 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS The literature reviews make three observations. First, while there are established safety management processes to analyse safety at specific milestones of the system lifecycle, there is a lack of continuity in managing and utilising the system knowledge regarding safety throughout the system lifecycle. Secondly, safety assessment must adapt to changing social-technical context especially when a system acquisition lifecycle comprises multiple distinct phases that introduce different constraints to safety assessment. Lastly, uncertainty in the complex environment can never be eliminated but there should be more efforts to minimise the surprises due to incomplete and imperfect information so as to create the confidence in the safety analysis. The paper concludes by providing a preliminary approach to develop a safety assurance method that aims to be applied throughout the system lifecycle to provide a structured and continual way to support decision making. Introduction: Where are the Hazards? As technology advances, more and more systems in domains like defence, air traffic management, railway transport, nuclear power plant, offshore drilling and health care are becoming highly networked and complex. These are described as safety-critical systems as any failure can potentially lead to the loss of life and damage to property or environment. For example, in the defence industry, networked of large-scale safety-critical systems (often refers to as Network Centric Warfare or System-of-Systems 1 [1]) have been revolutionising the applications of military technology as machines and computers are used to carry out complex and time-critical tasks. These machines are inter-connected to form larger inter-dependent systems and continuing to expand in numbers and complexity as the armed forces attempt to accomplish more challenging missions. Unfortunately, while there are established safety management processes, accidents that led to the loss of Systems Engineering Essay Competition 2015 Page 3 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS life and damage to properties continue to surface from such highly complex safety-critical systems. Some of the most notable accidents and incidents in recent years include:  (Space) NASA space shuttle Challenger (1986) [2] and Columbia (2003) [3] disasters  (Military Operation) B-1B Lancer bomber friendly fire on coalition soldiers in Afghanistan (2014) [4]  (Drilling) Piper Alpha offshore oil production explosion (1988) [5]  (Maintenance) F-111 (Fuel Tank) De-seal/Reseal program leading to chemical exposure (2001) [6]  (Health-care) Overdose of radiation during Therac-25 radiation therapy (1985) [7]  (Rail) Wenzhou high speed railway collision (2011) [8] While the faults for each of these disasters are unique, one common observation is that it is extremely difficult to narrow down to a specific failure mode. Unlike complicated but linear systems where traditional safety analysis method is capable of using linear reductionist approach to deduce the root causes, the failure modes in complex safety-critical systems are different. Reiman [9] observes that effects from a complex system have “several parallel contributing factors, instead of one or few causal chains 2 as in linear systems”. Dekker [10] also believes that “the behaviour of such complex system cannot be reduced to an aggregate of the behaviour of its constituent components”. Hence, even if one root cause has been identified, decision makers may face the frustrating but real challenge of not being able to fully comprehend the full casual chains of complex relations. One good example of a complex safety-critical system is Air Traffic Control (ATC). On 12 Dec 2014, an air traffic disruption at the Swanwick ATC resulted in numerous flight cancellations across Heathrow, Gatwick and London City [11]. The System Flight Servers failed when more workstations were being brought online during the transition between 1 The System-of-Systems (SoS) refers to a set of systems that are cooperating for a common purpose while simultaneously working as independent entities. 2 A causal chain refers to the path or sequence of events that runs from a root cause to problem symptoms in the real world. Systems Engineering Essay Competition 2015 Page 4 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS normal and standby operation [12]. This affected air traffic control as it was impossible for controllers to access aircraft flight plans. While the final report has yet to be released, NATS has announced that the failure is unprecedented in its 13 years of operations. The incident highlights the difficulties in managing system safety in complex environment. There will be intense pressure when failures occur and rightfully so since safety-critical systems are utilised in critical situations (e.g. ATC keeping the airspace safe) where there are severe consequences (e.g. disruption to commercial flights and passengers’ safety) when the systems fail. It is also possible that certain failures may never manifest themselves during system development as it is impossible to predict and conduct safety assessment on all operational scenarios (e.g. overloading of the ATC System Flight Servers). Active sharing of knowledge regarding safety throughout the system lifecycle can help to better anticipate and identify such ‘blind-spots’ during operation. In terms of managing safety-critical projects, social, technical and organisation tensions continue to pose safety challenges when it comes to acquiring a system in such complex environment. The following shows a sample of such concerns highlighted by Atkinson [13] and Saunders [14] from their surveys on managing project uncertainty of complex safety-critical system:  Novelty of design and technology  Diverse and conflicting stakeholders expectations and belief  Failure to anticipate concurrency of activities and capture dependency relationships  Ineffective communication and knowledge management with changing stakeholders throughout system lifecycle  Lack of continuity in personal and responsibilities when managing different interoperating systems  Incomplete and imperfect information  Lack of systematic process to capture corporate knowledge and lessons learned While the list represents uncertainty in managing projects, it is equally relevant to safety management and highlights the diversity of social-technical context that would affect the Systems Engineering Essay Competition 2015 Page 5 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS effectiveness of any safety analysis. Most safety-critical systems comprise human-machine interactions and it will be important to consider explicitly the impact of changing socio-technical context during safety analysis so as to create attention to potential hazards in such circumstances. The System Lifecycle – where it begins One approach to appreciate the safety hazards facing a safety-critical system is to consider its lifecycle. A system can be considered as a “combination, with defined boundaries, of elements that are used together in a defined operating environment to perform a given task or achieve a specific purpose”[15]. Taking reference from the military, a system is realised by following the system acquisition lifecycle. A full-scale system acquisition lifecycle includes multiple stages, milestones and decision points that shape the development of a system till its operationalisation. Two examples of military acquisition lifecycles are shown in Figure 1. They are the UK MoD CADMID 3 acquisition cycle and the US DoD Defence Acquisition Process. Figure 1 Categorisation of System Acquisition Lifecycle in defence A system lifecycle has two distinct phases: development and operation. Both phases are subjected to risk and safety hazards in the complex environment but exhibit different system characteristics. The following table provides a comparison of the two phases. Characteristics System Development System Operation 3 CADMID refers to the six phases of acquisition lifecycle: Concept, Assessment, Demonstration, Manufacture, In-service and Disposal. Systems Engineering Essay Competition 2015 Page 6 of 25 Jointly organised by Temasek Defence Systems Institute Department of Industrial and Systems Engineering, Faculty of Engineering, NUS Characteristics System Development System Operation Type of processes Design, plan, production, testing, and deployment Operation, maintenance and support, ret",,2015.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
a40cc32b94e828b64707aca8f026cd46a4fa7cfe,https://www.semanticscholar.org/paper/a40cc32b94e828b64707aca8f026cd46a4fa7cfe,Proceedings of First International Conference on Advanced Trends in ICT and Management (ICAITM),"S.No. Paper Title Author Name Page No. 1 Using A Remote Training Model For Technical / Vocational Education And Apprenticeship Enhancement Mr. Emmanuel Fon Tata 1 2 Challenges In Application Of ELearning To Extension In Kenya: A Case Of South Western Kenya Prof. Anakalo Shitandi 2 3 Cloud Computing And Its Related Technologies: Issues And Challenges Mr. Sulaimon Mr. Hakeem Adewale 2 4 A Unified Customer Service Model Optimizing Customer Service Quality for the Nigeria Electric Power Industry through the Implementation of an ITIL Based Service Management Paradigm Mr. Femi Akin-Laguda 3 5 Analysis Of Train Energy Consumption Reduction By Passing Low Passenger Flow Stations In Off-Peak Hour For Addis Ababa LRT Mr. Eshetu Shewalema 4 6 Higher Performance And Cloud Computing Mr. Foldestine Paye 5 7 Multitemporal Remote Sensing Of Landscape Dynamics And Pattern Change In Dire District, Southern Ethiopia Mr. Berhanu Keno 5 8 Assessing Governance Practices Among Micro-Finance Organisations: A Case Study Of Selected Firms In The MicroFinance Industry In Ghana Mr. Justice Paul Donkor 6 9 M-Commerce The New Phase Of Doing Business In The 21St Century Opportunities And Challenges Mr. Darko-Ampem A. Emmanuel 7 10 Influnce of Digital Audio Technicals on research and production in the music Industry in Africa : A case of CoTE D'ivoire, Dr. Anoha Clokou 7 11 Small And Medium Enterprises: A Survival Strategy For Nigeria Youth Empowerment Mr. Agboje Egbonimali Shadrack 8 12 Development Programmes And Follow-Up Procedures For Nigeria Colleges Of Education Trainers Using Cloud Computing Dr. A.A.Ladan 9 13 Work Place Violence, Aggressive Behaviour And Organizational Productivity Mr. Abdulsabur Hassan 9 14 Electricity Challenges On Small Business Enterprises In Nigeria Mr. Sidi Jelani 10 15 E-Commerce And Consumer Rights: Applicability Of Consumer Protection Laws In Online Transactions In East Africa. Mr. Sadat Mulongo Lunani 11 S.No. Paper Title Author Name Page No. 16 Change Management And Organizational Performance Measures Mr. Agboje Chukwuma 12 17 The Leadership And Funding Challenges Of University Information Technology Centres: A Case Study Dr. O. Osunade 13 18 The Impact Of Digital Divide On Cloud Migration In Africa: A Case Ke ya’S Te h ologi al State. Mr. Mainye Marcella Moraa 14 19 MOOCs In Nigeria: Awareness And Adoption Mr. Shamsuddeen H. Muhammad 14 20 Applying Rough Set Theory To Yorùbá Language Translation Mr. Fagbolu O O, Obalalu B S, Udoh S.S 15 21 Enterprise Resource Planning In Africa: A Case Study Of University Of Ibadan O.Osunade,O.Oladele, O.Omolola. 16 22 A Frame Work for Implementation of an E-Classroom System Mr. Shamsuddeen H. Muhammad 16 23 The Need To Fasten Cloud Adoption In Developing Countries Of Africa Mr. Shamsuddeen H. Muhammad 17 24 Usi g Co puter Ga es To I prove First Year Stude ts’ Learning Of Computer Programming Ms. Esther Gyimah 17 25 Impact Of Stakeholder Consultation On The Success Of Road Construction Project Ghana. Mr. Kwame Ofori 18 26 Security Issues Associated with Cloud Computing Mr. Mustapha Muhammad Sani 19 27 The Myths And Facts About Cloud Computing – Examining The Positions Of Start-Ups/SMEs Mr. Edward Daniels 20 28 The Impact Of Employee Empowerment On Service Quality Delivery And Customer Satisfaction At Chicken Republic . Mr. Daniel Adjei 20 29 The Influence Of Television Advertisement On The Youth Purchasing Behaviour Mr.Daniel Adjei Ms. Eunice Akorfa 21 30 Ethical Issues In Business Conduct Mr. Daniel Adjei Ms. Eunice Akorfa 22 31 Adolescent Socialization Environment As Predictors Of Unsafe Internet Behaviour Among Secondary School Students In Ibadan North Local Government Area Of Oyo State, Nigeria Mr. Ruth Ochanya Adio-Moses 23 32 Cloud Computing, An Avenue For Enhancing E-Procurement For Sustainable Development. Mr. Omane Kofi Wilson 23 33 The Introduction Of Human Resource Management In Ghana: Public Universities And Private Sector Perspectives Mr. Abdul-Kahar Adam 25 34 Statistical Analysis Of Knowledge And Utilization Of Cloud Computing By Smart Phone Users – A Case Study Of MTN Data Shop Customers Mr. Akpor-Mensah Edmund ,Mr. Dzivor Nelson Doe 26 35 Statistical Modelling Of Cloud Computing Utility In Tertiary Institutions In Accra (Ghana) Mr. Akpor-Mensah Edmund, Mr. Dzivor Nelson Doe 26 S.No. Paper Title Author Name Page No. 36 Adoption Of Cloud Computing As A Key Strategic Tool For Business Sustainability Mr. Akpor-Mensah Edmund, Mr. Dzivor Nelson Doe 27 37 Web Based Housing Management System Mr. Paul Adeoye Omosebi 27 38 Politics In the Cloud : An Argument for Cloud Based Software in Politics Mr. Nana Amankwah Peprah Mr. Kamal Kant Hiran 28 39 Mobile Assemblages and Development (maendeleo) in Marakwet Kenya Dr. Leah Jerop Komen 30 40 Investigating the Impact of ICT on the Enhancement of Learning amongst Special Needs Students Mr. Emmanuel Fon Tata 30 41 A Remote Training Model: A New Paradigm For Technical and Vocational Apprenticeship In Ghana Mr. Emmanuel Fon Tata 31 42 Cloud Computing as a Suitable Alternative to The Traditional On-Premise ERP And Massive Data Storage Mr. Mbanzabugabo Jean Baptiste 32 43 Gha a’s ICT4AD Poli y Do u e t – A Diminishing Significance Mr. Kubuga, Kumangkem Kennedy Mr. J. Kok Konjaang 33 44 Improving Health Care Delivery in Ghana: A Need of Urgency for NHIS Card Upgrade Mr. Mensah Sitti 33 45 Cloud Computing: A Catalyst in the Agenda of Education for All Prof. Patrick E. Eya, Dr. Samson Sunday Afolabi 34 46 For better or for worse: Effect of technological revolution on family communication Mr. Albert AnaniBossman 35 47 Application of the Excellent Principles of Public Relations in a Different Cultural Context: The Case Study of Ghana Mr. Albert AnaniBossman 36 48 Social Networking and Interpersonal Communication: how online identities impact on off line relationships Mr. Albert AnaniBossman 38 49 The Adoption and Deployment of Technology in Inventory Management Systems of Public Institutions. A Case Study of Electoral Commission of Ghana (EC) Ms. Priscilla Hanson 41 50 Effective use of Cloud Computing Services in Higher Education Mr. Sujith Jayaprakash 41 51 Antecedents of Employee Job Stress: Evidence from the Insurance Industry in Ghana Ms. Evelyn Twumasi 42 52 Analysis of Elman Neural Networks for Wavelet Transforms Based Feature Extraction in the Classification of Epilepsy Risk Levels from EEG Signals Dr. Vijayakumar T and Prof. T. Harikumar 43 53 An analysis of Challenges and opportunities for using Electronic Commerce in Ethiopia. Dr. S. Anbarasu 44 54 Paper Title Author Name Page No. S.No. Internet Use among Senior High School Students in Ghana: A Study of La Presbyterian Senior High School Mr. Philip Dornyo, Ms. Eunice Akorfa Adiko 44 55 Management of Technology and InnovationPerspectives on the Indian Banking Industry Dr. M. Thanikaivel 45 56 Cloud Computing – The Pathway and the Future Hope for Afri a’s sustai a le edu atio Ms. Eva Esther Shalin Mr. Samual Edem 46 57 Botnet Detection Using Data mining Techniques in Cloud networks Mr. S. Nagendra prabhu Dr. D. Shanthi 46 58 Online Password Protection Using Persuasive Cued Click Point Method Dr. Ra. Parivallal Dr. V. S. Prakash Mr. Manikandan 47 59 Knowledge Based Analysis of Microarray Gene Expression Data in Oncology Dr. W. Jai Singh Ms. N. Nivetha Rani Ms. S. Nivitha 47 60 Network On Chip: A New Frontier For Highly Scalable And Energy Efficient Multicore Systems Mr. Charles Saah 48 61 Auto Recovery Of Virtual Machine In A Cloud Based System After Memory Error Attack Mr. Charles Saah 49 62 A Study On Security Issues In Cloud Computing Mr. Vijesh Krishnamoorthy 49",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
76519b32542a93d949c903c14c7cdf8e81f40e24,https://www.semanticscholar.org/paper/76519b32542a93d949c903c14c7cdf8e81f40e24,Session 1 : Intelligent Transportation and Urban Planning,"Activities of Daily Living (ADLs), or a person’s routine activities of selfcare, are important factors influencing the feasibility of home health care or aging in place for many individuals. Automated, sensor-based recognition of such activities affords home stay, greater independence and privacy, and improved quality of life to individuals who would require stay in a supervised or medical facility. This paper describes a data-driven framework for the design and deployment of such an automated system for activity recognition using simple, unobtrusive, and privacy-friendly binary sensors. It presents the results of an experimental study, with both numerical and qualitative observations, of this framework on a publicly available real dataset. Machine Learning on Cataracts Classification Using SqueezeNet Author(s): Xingzhi Qian, Evan W. Patton, Justin Swaney, Qian Xing, Tingying(Helen) Zeng Abstract: Cataracts is a serious eye disease, affecting over 20 million people worldwide. It is the clouding of the lens, which blocks the light to go through the lens and project on the retina. As a result, the nerve cannot transfer the whole image to the brain, leading to blindness. A vast majority of cataracts patients are people who are over 50 years old. To classify different areas of cataracts in lens, we use supervised training of convolutional neural network to train 420 images of cataracts on the lens taken from slit-lamps. The experiment can make the future of classifying cataracts more easily and ophthalmologists can apply operations to different categories of cataracts within a shorter time to cure patients with cataracts. For those people in the countryside, even not so experienced doctors can take the photo of lens and use the program to classify cataracts correctly. A Study on Multidimensional Medical Data Processing Based on Random Forest Author(s): Lifeng Zhang, Hongyan Cui, Roy E.Welsch Abstract: In the field of medical research, when researchers use physical examination indicators to diagnose diseases, it is often difficult to make decisions because of the large number of data dimensions. It is also tough to make effective decisions on whether or not to be ill according to relatively important attributes. Under such circumstances, this paper proposes a feature extraction method based on random forest, which extracts features from multidimensional data. With validation of the UCI diabetic retinopathy data, we designed a method to calculate the impact score of multi-dimensional attributes to the presence or absence of disease. Then, by selecting two groups of data with higher impact score and lower impact score. Last, we used neural network algorithm to make comparative verification. The experimental results show that the high-impact score data calculated by the random forest has certain advantages over the lowscore data in disease diagnosis, both on the accuracy of the diagnosis model and the diagnosis. We choose to use this method to select fewer features with higher scores to diagnose diseases, and also achieve good results. Plant Disease Identification Using Convolutional Neural Networks Author(s): Kevin Zeng Qi, Justin Mark Swaney, Evan W. Patton Abstract: Plant diseases are a major threat to food security for public health. The goal of this research is to develop an effective system that can detect these diseases before they become widespread. We combat this by innovatively training a convolutional neural network to detect and identify diseases from the RGB images of plant leaves. The architecture of the network is based on the Alexnet architecture. The dataset consisted of corn, tomato and apple leaf images. The results were to be very promising with a 92.22% accuracy when trained and tested on the specific labels of each disease and species. First-Aid system desig Author(s): Haoran Ma, Yang Liu, Yajuan Fang, Berthold K.P.Horn Abstract: For the new upgrade of an existing first-aid system, the method of combining mobile device with Internet is adopted to realize the real-time feedback of patients' location information, query the corresponding first-aid methods and call nearby resources, so as to shorten the time of first-aid for patients and save their lives. Session 3a: Intelligent Communities Time: 8:00am-10:30am, October 24th Location: W20-306 Chair(s): Gilly Leshed UniWifi, A Smart Network System Author(s): Harry Zhou, Bruce Wang Abstract: As people become more and more reliant on wifi to complete day to day tasks, individuals also become increasingly restricted to their homes or places that provide it. We propose an Intelligent Network System that could provide constant wifi connection to the masses so that anyone could roam anywhere within an urban area and remain connected to the internet. Our concept revolves around using the contemporary ‘mesh zone’ technology. In phase one, we believe that by having small yet powerful routers installed everywhere, mesh zones that be created to effectively cover areas small and large. In phase two, the potential of having routers moved to the skies becomes probable when combined with high performance drones. The goal is global connectivity. We envision for a future where every device around the globe is connected to one or many central network databases. This is important because all internet traffic could be monitored and therefore greatly eliminating most if not all potential intrusions to civilian safety all around the globe. There are three checkpoints that we would like to accomplish. First, to test the connectivity range of a mesh router with a commercial drone. Then to successfully build our own beta prototype flyer. And at last, to test our beta flyers with multiple mesh routers to complete a working mesh zone. Wifi routers today are not being used to their full potential as they ironically work independently to connect collective devices to the web. By implementing mesh, one could connect to secure and fast connection while having mobility freedom. One could truly stay connected anywhere and everywhere. CoDAS, a Method for Envisioning Larger-Scaled Computational Artifacts Connecting Communities Author(s): Carlos Araujo de Aguiar, Gilly Leshed, Alexander Bernard, John McKenzie, Camille Andrews, Keith Evan Green Abstract: Information Technologies are increasingly embedded into artifacts of the physical world—furniture, rooms, buildings, and urban infrastructure—making communities around-the-globe more connected and, arguably, more intelligent. However, such larger-scaled, social computing artifacts arrive with critical concerns of cost, material choice, design requirements, fabrication means, robust and safe use, power, and resistance to vandalism and the elements. Given the complexity of realizing larger-scaled, computational artifacts, conventional design methods prove inadequate and potentially costly and dangerous if researchers move too quickly to full-scale prototyping. In this paper, we present CoDAS, a hybrid methodological approach that combines elements of well-known HCI methods to effectively develop larger-scale social computing artifacts. A survey of Multi-controllers Consistency on SDN Author(s): Tao Yu, Yang Hong, Hongyan Cui, Hongxiang Jiang Abstract: Software-Defined Network (SDN) is developing rapidly for its benefit of programmability. However, new challenges also appear. One of them is while we are applying distributed controllers in SDN networks, we must consider the consistency problem. In SDN networks, especially in a multi-controller architecture, it is a great challenge to maintain a global view consistency of the networks among all controllers, which is also key to issue flow regulations. Lacking of consistency in packets, flows, and networks level may result in serious errors. Besides, consistency problem also exists in data plane. How to keep all switches executing a same set of rules to avoid errors is often discussed. In this paper we’ll conclude the different situations of consistency problems and provide the related research solutions. The methods in the paper not only regard to consistency of control plane, but also data plane. At last, we also introduced the two methods to evaluate the performance of consistency, those are strong consistency and final consistency. Anonymous network communication based on SDN Author(s): Taiyu Wong, Hongyan Cui, Yuepeng Shen, Wenqi Lin, Tao Yu Abstract: As more and more personal information is used in network services, network anonymity has received more and more attention. Attackers could endanger the victims’ privacy by attacking or eavesdropping nodes during the networks routing. For example, attackers could retrieve the IP and MAC address of victims from network traffics, and use it to correlate the network behavior to individuals. The emerging Software Defined Network (SDN) technique provides a pretty flexible platform that can control the whole network by software programming, which propose a new solution to realize the network anonymity problem. In this paper, we propose a solution based on SDN to anonymize both MAC and IP addresses of network traffics in order to mitigate the privacy threats, and programing it. Furthermore, we test the anonymity function on our SDN Testbed. Our solution supports two working modes: a two-way anonymous mode which anonymizes the IP and MAC addresses of all data packets, and an one-way anonymous mode which anonymizes MAC and IP addresses of senders. Friendly Acoustic Technology Enhance Neighborhood and Friendship Author(s): Zhang Xiangdong, Kuang Zheng, Yang Jun Abstract: It is estimated that there are currently 80 million to 100 million square dance crowds in China. Due to noise pollution, there are often quarrels and conflicts between the square dance crowd and their neighbors. Even in order to compete for the venue, there will be disputes between different square dance teams. The directional sound product based on local sound field control technolog",,2019.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
aecb51cdeb26b104fed164f67081bedb08003429,https://www.semanticscholar.org/paper/aecb51cdeb26b104fed164f67081bedb08003429,Ambient Networks : toward a Future Internet embracing the Wireless World,"The mobile phone is becoming a trusted personal device with fundamental new capabilities. New form factors of mobile device and their user interfaces require new concepts for transformable mechanics. Integration of electronics and user interface functions into structural components will be necessary. Modular architecture will enable use of optimal technology for any particular functionality and optimization of power consumption. Nanomaterials, new manufacturing solutions and energy sources together with increased memory and computing capacity will enhance the capabilities of mobile devices. Nanotechnologies will also enable embedding of intelligence into human everyday environments and body area networks. We have presented a concept device called the Morph that illustrates use and bene_ts of nanotechnologies in real life applications. 1. Transformation of mobile communication During the following ten years mobile communication and the Internet will converge into a global information platform. Mobile phones have already become an enabling platform for digital services and applications. Mobile phones are powerful multimedia computers with wide range of functionality, e.g., imaging, navigation, music, content management, browsing, email, and time management. Increasingly they will have advanced multi-access communication, information processing, multimedia, mass storage and multimodal user interface capabilities. In the continuation these trusted personal devices will also have new capabilities: Interacting with local environment via embed-ded short range radios, sensors, cameras, and audio functionality; Functioning both as servers for global and local internet services and as clients for global internet services; Serving as gateways that connect local information and global internet based services; Carrying the digital identity of the user and enabling easy-to-use secure communication and controlled privacy in future smart spaces; Sensing local context and the behaviour of its user. Context awareness, including location, is the fundamental underlying capability of the future mobile devices. These context sensitive devices will open wide range of solutions for Internet services and mobile communication. Sensors, positioning and powerful signal processing embedded in mobile devices make it possible to detect, observe and follow different events and patterns in user's behavior and surrounding environments with precise location. Mobile device becomes a cognitive user interface that is continuously connected to the local environment and to the Internet Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES services. Context awareness has also profound inuence on the development of future communication and computing solutions by enabling intelligent allocation and sharing of resources. Form factors and user interface concepts of mobile multimedia computers will vary according to the usage scenario. The tendency towards smaller and thinner structures as well as towards reliable transformable mechanics will continue. The desire to have curved, flexible, compliant, stretchable structures and more freedom for industrial design sets demanding requirements for displays, keyboard, antennas, batteries, electromagnetic shielding and electronics integration technologies. A possibility to integrate electronics and user interface functions into structural components, such as covers, will be necessary. Modular device architecture of mobile multimedia computers will consist of several functional subsystems that are connected together via very high speed asynchronous serial interfaces [5, 6]. The modular approach enables the use of optimal technology for any particular functionality, optimization of power consumption, and the modular development of device technologies and software. The same modular architecture can be extended from one device to a distributed system of devices that shares the same key content, e.g., a remote mass storage, display or a printer. Nanoscience means capabilities to image, measure and manipulate physical and chemical processes at molecular level. These capabilities convert into nanotechnologies that are based on physical and chemical phenomena that emerge at nanoscale. Thus nanotechnologies are not just a continuation of the miniaturization roadmap but offer new capabilities to create solutions for health care, information technologies, materials and manufacturing. These pervasive capabilities will affect mobile communication [2]. Nanotechnologies for sensing, computing, radios, displays, structural and surface materials will enable creative design of future mobile devices and services. Mobile communication and the Internet are converging: wireless communication will nd optimal solutions based on both regulated mobile communication (3GPP track) and unregulated local access (IEEE track) solutions. Flexible and efficient local access will support sensing, computing and actuation in mobile devices that are continuously onnected to the Internet services. Implementation of sensors and multi-modal user interface features together with energy efficient local connectivity will enable new mobile services and new paradigms of communication, e.g., ad hoc social networking. Context awareness and machine learning will create the user experience seamless connectivity and information access but require powerful embedded computing solutions. Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES 2. Sensing and signal processing Sensors can already be found as key features of various battery powered, handheld devices. Especially, location, motion and gesture recognition are new pervasive elements of applications, user interfaces and services. One of the enablers of this rapid development has been microelectromechanical systems (MEMS) based on micromachining of silicon (see a review in [4]). The need for low cost, reliable sensors for automotive applications initiated the mass manufacture of silicon MEMS sensors. The requirements of consumer electronics, especially of sport gadgets, mobile phones and game controllers, have driven further the miniaturization of MEMS devices. Today MEMS and CMOS technologies provide a solid basis for large scale deployment of sensor applications. The opportunity to connect locally measured information to Internet services and to incorporate this local information into structured global information might be even more significant. Example of benefits include real time tracking of the spread of a disease or epidemic or interpretation of changes in traffic patterns on roads through a combination of local sensors and the Internet. The Internet is becoming a massive store of heterogeneous data and linked information. Extremely efficient search and data mining technologies are creating a dynamic and real time map of the physical world with its various economical and social networks. Nanotechnologies may not revolutionize sensor technologies and applications. Existing sensor technologies based on MEMS and CMOS platforms have not yet fully met their potential to provide sensor applications and networks that improve the human everyday environment. However, nanotechnologies, i.e., different nanoscale building blocks and fabrication processes, will affect the development of sensors, their signal processing and actuators. Nanotechnologies will extend the applications of sensors to new potential fields, such as smart spaces, body area networks, remote health care, and pervasive environmental monitoring (see a review in [7, 8]). Many nanoscale sensors are related to chemical and biochemical sensing where nanoscale transducers create a possibility to derive more detailed information on observed phenomena. Nanotechnologies offer a new possibility to create nanoscale transducers, memory and computing elements and to merge these elements together to form an intelligent sensor system. The same technology, e.g., silicon or ZnO nanowires or carbon nanotubes, can be used to create various functional elements for these systems. Several possible architectures, e.g., coupled resonator arrays, nanowire crossbars, plasmonics, and spiking neuron networks can be used for both sensing and signal processing. Simposio Internacional: Las telecomunicaciones del futuro International Symposium: The future telecommunications F UNDA CIÓN RA MÓN AR EC ES 3. Morph Nanotechnologies in future mobile devices Transformation of the device can essentially happen in many levels: transformation of graphical user interface, mechanical configuration, available applications and services. The Morph device [1] is transformable in many different ways. The user interface of the device can adapt to the context of the user in terms of functionality but also its appearance. Transformability can be used to enable the ease of use of the device, applications and services. The Morph device is transformable in its form and conformation. The Morph is a cognitive user interface, capable of sensing both the user and the environment, making decisions based on this information, adapting to the context and give feedback to the user. The Morph learns about its user and becomes a trusted personal companion. The last forty years of development in electronics have targeted to ever increasing integration of functionality, i.e., very large scale integration. There is no doubt that this development will continue to build even more efficient solutions for sensing, computing and communication. However, interfaces of future devices with the physical world and their users require new type of intelligent and energy efficient sensors and actuators that can benefit of development of low cost electronics manufacturing and functional materials. Printed electronics creates capabilities to integrate functio",,2010.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
1089c3d2e5c1eb4fff1a91595d93ba635ee041bc,https://www.semanticscholar.org/paper/1089c3d2e5c1eb4fff1a91595d93ba635ee041bc,Rapidly Deployable Internet-of-Things Body Area Network Platform for Medical Devices,"Biomedical devices in the past provided limited capability for the data acquisition and presented the data in the form of user interface for a care provider to observe. Now, what is required for biomedical devices has fundamentally changed. Many devices must now support secure networking and include a network of sensors to enable machine learning-based sensor fusion for accurate inference of the subject’s state.This thesis introduces an Internet-of-Things (IoT) body area network (BAN) platform for medical devices that will provide rapid development capability with the assurance of security, networking, and the ability to host computationally intensive processes that are now required by medical devices. The BAN platform consists of seven wearable sensor nodes on the chest, wrists, upper legs, and ankles. Each sensor node includes sixteen general-purpose input/output (GPIO) pins, an analog-to-digital converter (ADC), two inter-integrated circuit (I2C) controllers, a serial peripheral interface (SPI), two universal asynchronous receiver transmitters (UART), and a universal serial bus (USB) on-the-go (OTG) to interface with sensors. The platform base model includes 9 degree-of-freedom inertial measurement unit (9DOF IMU) motion sensors, an electrocardiogram (ECG) sensor, a microphone, and a heart rate sensor. With its flexible interfaces, the platform is highly customizable and more sensors can be easily added.Each sensor node features an IoT computer-on-module called the Intel Edison. The device can connect to expansion boards for rapid development. Although it has two official expansion options, the BAN platform uses boards from a third party manufacturer due to their small size. Intel provides a library to access the external interfaces. The library is fully compatible only if the Arduino breakout is used. A C library that abstracts /sys/class/gpio interface was developed to access the GPIO. The ADC device used in the platform is an I2C device. A C library was developed that abstracts the I2C communication between the Intel Edison and the ADC to provide an intuitive application program interface (API). The UART interface is accessible via /dev/ttyMFD2. A Python package called PySerial is used to interface the serial port. These interfaces in addition to the Intel’s official breakouts and library enable many more applications.One of the most powerful features of the Intel Edison is its integrated WiFi module, enabling connection within the BAN and to the Internet. Since the BAN platform collects the user’s private health and activity data, the connection is secured by transport layer security (TLS). The networking among sensor nodes allows time synchronization with network time protocol (NTP) to have accurate sensor fusion.Powered by its Intel Atom dual-core processors, the BAN platform can host neural network-based classifiers to monitor users’ states. From experiments, the performance of the neural network hosted on the platform was found to be on par with that of neural network implemented in Matlab.The BAN platform was successfully distributed to freshmen, senior, and graduate IoT courses with exceptional assessment records. The IoT courses have shown that the students were able to rapidly develop fully functioning biomedical devices on the BAN platform.",,2016.0,,semantic_scholar,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
