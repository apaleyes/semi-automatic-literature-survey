contentType,identifier,title,publicationName,doi,publisher,publicationDate,abstract,url,database,query_name,query_value
Chapter ConferencePaper,doi:10.1007/978-981-19-0095-2_18,Traffic Sign Detection and Recognition,Information and Communication Technology for Competitive Strategies (ICTCS 2021),10.1007/978-981-19-0095-2_18,Springer,2023-01-01,"Surge in the amount of automobiles on street imposes the consumption of automatic systems for driver aid. These structures form significant instruments of self-driving automobiles as well. Traffic Sign Recognition remains such an automatic structure which affords the relative responsiveness aimed at self-driving automobile. In this work we are able to perceive and identify traffic signs in video classifications detailed by an onboard automobile camera. Traffic Sign Recognition (TSR) stands used to control traffic signs, inform a driver and facility or proscribe definite actions. A debauched real-time and vigorous instinctive traffic sign finding and recognition can upkeep and disburden the driver and ominously upsurge heavy protection and ease. Instinctive recognition of traffic signs is also important for automated intellectual driving automobile or driver backing structures. This paper presents a study to identify traffic sign via OpenCV procedure and also convert the detected sign into text and audio signal. The pictures are mined, perceived and recognized by preprocessing through numerous image processing methods. At that time, the phases are accomplished to identify and identify the traffic sign arrangements. The structure is trained and endorsed to find the finest network architecture. Aimed at the network exercise and assessment we have generated a dataset containing of 1012 images of 8 diverse classes. The tentative results demonstrate the exceedingly accurate groupings of traffic sign patterns with composite contextual images and the computational price of the planned system. Though, numerous features make the road sign recognition tricky and problematic such as lighting state changes, occlusion of signs due to hitches, distortion of signs, gesture blur in video images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-0095-2_18,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-1142-2_10,Explainable Artificial Intelligence (XAI): Connecting Artificial Decision-Making and Human Trust in Autonomous Vehicles,"Proceedings of Third International Conference on Computing, Communications, and Cyber-Security",10.1007/978-981-19-1142-2_10,Springer,2023-01-01,"Automated navigation technology has established itself as an integral facet of intelligent transportation and smart city systems. Several international technological organizations have realized the immense potential of autonomous vehicular systems and are currently working towards their complete development for mainstream application. From deep learning algorithms for road object detection to intrusion detection systems for CAN bus monitoring, the functioning of a self-driving vehicle is powered by the simultaneous working of multiple inner vehicle module systems that perform proper vehicle navigation while ensuring the physical safety and digital privacy of the user. Transparency of the vehicle’s thought processes can assure the user of its credibility and reliability. This paper introduces explainable artificial intelligence, which aims to converge the decision-making processes of Autonomous Vehicle Systems (AVS). Here, the domain of Explainable AI (XAI) provides clear insights into the role of explainable AI in autonomous vehicles and increase human trust for AI based solutions in the same sector. This paper exhibits the trajectories of transportation advancements and the current scenario of the industry. A comparative quantitative and qualitative analysis is performed to compare the simulations of XAI and vehicular smart systems to showcase the significant developments achieved. Visual explanatory methods and an intrusion detection classifier were created as part of this research and achieved significant results over extant works.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-1142-2_10,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13177-022-00304-6,Implementation of a Compact Traffic Signs Recognition System Using a New Squeezed YOLO,International Journal of Intelligent Transportation Systems Research,10.1007/s13177-022-00304-6,Springer,2022-08-01,"The importance of traffic signs cannot be overstated when it comes to road safety. The necessity for rapid and precise Traffic Sign classifier remains a challenge due to the complexity of traffic signs shapes and forms. In this paper, a real-time detector is presented for the German Traffic Sign Recognition Benchmark (GTSRB). GTSRB has 43 different classes with various shapes, forms, and colours. Their similarity is useful for object localisation but not for sign classification. In this article, a real-time detector for GTSRB is created using an upgraded compact YOLO-V4 Technique and implemented on the new NVIDIA Jetson Nano. To find and detect GTSRB pictures, a compact and efficient classifier is introduced. For the first time, this paper compares the detection and categorization of traffic signs using YOLO-V3 and 4, both regular and tiny. Because most of real-time identification algorithms require a lot of processing power, the suggested compact classifier, which is based on the new YOLO-V4 Tiny, can recognize all 43 traffic signals with an average accuracy of 95.44% percent and a YOLO model size of just 9 MB. The GTSRB test dataset was used to validate this approach, which was then tested on the new Jetson Nano. In comparison to existing algorithms such as CNN, YOLO-V3, YOLO-V4, and Faster R-CNN, the suggested technique may successfully save more computational power and processing time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13177-022-00304-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06523-4,Extraction of landslide features in UAV remote sensing images based on machine vision and image enhancement technology,Neural Computing and Applications,10.1007/s00521-021-06523-4,Springer,2022-08-01,"To improve the effect of landslide feature extraction, this paper improves the remote sensing image recognition algorithm with the support of a machine learning algorithm. Moreover, this paper combines UAV remote sensing images to extract landslide features, classifies and introduces the evaluation criteria for target detection and several representative target detectors. This paper also constructs the functional structure of the system according to the landslide feature extraction requirements and designs a set of optimization schemes for landslide feature data collection and control measurement suitable for field operations. In addition, this paper analyses the system kernel algorithm process and analyses the system function realization through simulation research. Finally, this paper designs an experiment to evaluate the practicability of the system constructed in this paper. From the results of experimental statistics, we can see that the system constructed in this paper has good practicability.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06523-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-021-03434-w,Intelligent ubiquitous computing for future UAV-enabled MEC network systems,Cluster Computing,10.1007/s10586-021-03434-w,Springer,2022-08-01,"In this paper, we investigate intelligent ubiquitous computing for future unmanned aerial vehicle (UAV)-enabled mobile edge computing network (MEC) systems, where multiple users process some computational tasks with the help of one computational access point (CAP), under the jamming from a UAV attack. Taking into account that the system may operate in a dynamic varying scenario, we optimize the system performance by using the reinforcement learning and transfer learning algorithms in order to reduce the latency and energy consumption. Specifically, we firstly use the reinforcement learning to devise the offloading strategy that meets the latency and energy consumption constraints as well as to alleviate the effect caused by jamming attack. We then propose to use the transfer learning to speed up the training process and improve the performance of reinforcement learning. Simulation results are provided to reveal that the proposed offloading strategy can outperform the conventional ones, and using transfer learning can achieve a better system performance while reducing the training time significantly.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10586-021-03434-w,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03961-y,Vehicle trajectory prediction on highways using bird eye view representations and deep learning,Applied Intelligence,10.1007/s10489-022-03961-y,Springer,2022-07-20,"This work presents a novel method for predicting vehicle trajectories in highway scenarios using efficient bird’s eye view representations and convolutional neural networks. Vehicle positions, motion histories, road configuration, and vehicle interactions are easily included in the prediction model using basic visual representations. The U-net model has been selected as the prediction kernel to generate future visual representations of the scene using an image-to-image regression approach. A method has been implemented to extract vehicle positions from the generated graphical representations to achieve subpixel resolution. The method has been trained and evaluated using the PREVENTION dataset, an on-board sensor dataset. Different network configurations and scene representations have been evaluated. This study found that U-net with 6 depth levels using a linear terminal layer and a Gaussian representation of the vehicles is the best performing configuration. The use of lane markings was found to produce no improvement in prediction performance. The average prediction error is 0.47 and 0.38 meters and the final prediction error is 0.76 and 0.53 meters for longitudinal and lateral coordinates, respectively, for a predicted trajectory length of 2.0 seconds. The prediction error is up to 50% lower compared to the baseline method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03961-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01538-4,Cyclists and autonomous vehicles at odds,AI & SOCIETY,10.1007/s00146-022-01538-4,Springer,2022-07-19,"Consequential historical decisions that shaped transportation systems and their influence on society have many valuable lessons. The decisions we learn from and choose to make going forward will play a key role in shaping the mobility landscape of the future. This is especially pertinent as artificial intelligence (AI) becomes more prevalent in the form of autonomous vehicles (AVs). Throughout urban history, there have been cyclical transport oppressions of previous-generation transportation methods to make way for novel transport methods. These cyclical oppressions can be identified in the baroque and modernist periods, and a third oppression may occur in the contemporary period. To explore the idea of a third oppression , we focus on the bicycle and outline the history of cycling to understand how historical mode oppression unfolded. We then present several social and political factors that contributed to the oppression of cycling and share recommendations for how to avoid future oppressions including political, social, and design actions for researchers and policymakers to take. This paper argues that priorities for AI-enabled mobility and cyclist needs be advanced in proportion to the extent that they contribute to societal goals of urban containment, public realm, and proximal cities. Additionally, future mobility evolutions should prioritise mobility justice and mode choice over inducing a singular transportation method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-022-01538-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01677-2,Anticipating Autonomous Vehicle Driving based on Multi-Modal Multiple Motion Tasks Network,Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01677-2,Springer,2022-07-15,"Recently, research concerning autonomous self-driving vehicles has become very popular. In autonomous vehicles (AVs), different decision-making and learning architectures have been proposed to predict multiple tasks (MTs) or MTs from various datasets or to improve performance among different MTs. In this paper, a novel and unified multitask learning framework, called Multi-Modal DenseNet ( M ^2-DenseNet), is proposed to predict MTs in a single network in which three long short-term memory units act as the output (MTs). Accordingly, the proposed M ^2-DenseNet can predict three different motion decision-making tasks, i.e., the steering angle, speed, and throttle, to control AV driving. Moreover, M ^2-DenseNet can greatly reduce the time complexity (e.g., to less than 5 ms) because the different prediction tasks can be predicted simultaneously. We conduct comprehensive experiments with the lane-keeping task based on two control mechanisms using the proposed M ^2-DenseNet and other existing methods to evaluate the performance. The experiments demonstrate that M ^2-DenseNet significantly outperforms other state-of-the-art methods with the accuracies of the three control tasks being approximately 98%, 99%, and 98%, respectively. The mean squared error between the predicted value and the ground truth is reported in the experiments, with values for the steering angle, speed, and throttle of 0.0250, 0.0210, and 0.0242, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01677-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11119-022-09932-0,Deep convolutional neural networks for estimating maize above-ground biomass using multi-source UAV images: a comparison with traditional machine learning algorithms,Precision Agriculture,10.1007/s11119-022-09932-0,Springer,2022-07-02,"Accurate estimation of above-ground biomass (AGB) plays a significant role in characterizing crop growth status. In precision agriculture area, a widely-used method for measuring AGB is to develop regression relationships between AGB and agronomic traits extracted from multi-source remotely sensed images based on unmanned aerial vehicle (UAV) systems. However, such approach requires expert knowledges and causes the information loss of raw images. The objectives of this study are to (i) determine how multi-source images contribute to AGB estimation in single and whole growth stages; (ii) evaluate the robustness and adaptability of deep convolutional neural networks (DCNN) and other machine learning algorithms regarding AGB estimation. To establish multi-source image datasets, this study collected UAV red-green-blue (RGB), multispectral (MS) images and constructed the raster data for crop surface models (CSMs). Agronomic features were derived from the above-mentioned images and interpreted by the multiple linear regression, random forest, and support vector machine models. Then, a DCNN model was developed via an image-fusion architecture. Results show that the DCNN model provides the best estimation of maize AGB when a single type of image is considered, while the performance of DCNN degrades when sufficient agronomic features are used. Besides, the information of above three image datasets changes with various growth stages. The structure information derived from CSM images are more valuable than spectrum information derived from RGB and MS images in the vegetative stage, but less useful in the reproductive stage. Finally, a data fusion strategy was proposed according to the onboard sensors (or cost).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11119-022-09932-0,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07015-9,High-performance intrusion detection system for networked UAVs via deep learning,Neural Computing and Applications,10.1007/s00521-022-07015-9,Springer,2022-07-01,"Recently, Unmanned Aerial Vehicles (UAVs) have become a widely popular technology with remarkable growth and unprecedented attention. However, UAV communication networks are susceptible to various cyber-intrusions/threats due to their limited computation and communication capabilities. Such intrusions/misbehaviors tend to be processed as normal packets through the UAV communication networks. In this work, we present an autonomous intrusion detection system that can efficiently detect the malicious threats invading UAV using deep convolutional neural networks (UAV-IDS-ConvNet). Specifically, the proposed system considers encrypted Wi-Fi traffic data records of three types of commonly used UAVs: Parrot Bebop UAVs, DBPower UDI UAVs, and DJI Spark UAVs. To evaluate the developed system, we employed the UAV-IDS-2020 dataset which includes various attacks on UAV networks in unidirectional and bidirectional communication flow modes. Moreover, we emulate the context of homogeneous and heterogeneous networked UAVs. Our best experimental outcomes exhibited a victorious intrusion detection accuracy of 99.50% for the two-class classifier model (normal UAV vs. anomaly) with 2.77 ms prediction time. Besides, the proposed system was evaluated using other performance metrics including confusion matrix parameters, false alarm rate, detection precision, detection sensitivity, and prediction overhead. The performance analysis showed that our UAV-IDS-ConvNet system outperforms several recent existing intrusion detection systems developed to secure the UAV communication networks by (6–23) %.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-022-07015-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-021-0419-z,Optimization of Emergency Braking Pedestrian Collision Avoidance for Autonomous Vehicle Fusing the Fuzzy Neural Network with the Genetic Algorithm,"International Journal of Control, Automation and Systems",10.1007/s12555-021-0419-z,Springer,2022-07-01,"In order to improve braking performance of the intelligent vehicle, a pedestrian collision avoidance control model for autonomous emergency braking pedestrian (AEB-P) system based on the fuzzy neural network (FNN) and genetic algorithm (GA) theory is proposed. In this research, we construct a backpropagation (BP) feed-forward FNN-GA model for the AEB-P system. Aiming to solve the problem that initial training parameters of the FNN model generate randomly, they are optimized by fusing the fuzzy neural network with GA. Simulation results show that training epochs reduce from 800 to 60 and training error changes from [−0.06, +0.06] to [−0.04, +0.04] after optimization. Moreover, the maximum model error lessens from 0.058 to 0.0351 and sample total error decreases from 0.0179 to 0.0068. At last, the proposed scheme is applied to the China New Car Assessment Program (C-NCAP) simulation test scenarios. Output curves of vehicle distance, velocity, and deceleration become smoother and the maximum error decreases from 0.51 m/s^2 to 0.26 m/s^2, which verifies the proposed FNN-GA control strategy for AEB-P system is effective and reliable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-021-0419-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-022-00422-w,Multi-scale graph-transformer network for trajectory prediction of the autonomous vehicles,Intelligent Service Robotics,10.1007/s11370-022-00422-w,Springer,2022-07-01,"The accurate trajectory prediction is a crucial task for the autonomous vehicles that help to plan and fast decision making capability of the system to reach their destination in the complex road scenario with abiding by the traffic rules. For this, autonomous vehicles should have more attention to their goal without affecting the other’s task and maintain their safety from road accidents. With this motivation, we proposed a multi-scale graph-transformer-based attention mechanism that provides the interaction between the road agents with different time instances, because from time to time, few new agents may enter the frame scene, and few may leave the frame scene. Each dynamic obstacles trajectory can be defined as state sequences within an interval of time, where spatial coordinates of dynamic obstacles represented by the each state under the world coordinate frame. We have presented graph-based Multi-scale spatial features with transformer network that achieves significant prediction results compared to other existing methods, and we provide an in-depth analysis of the trained weights for different highways scenarios with transformer and the Long-Short Term Memory. We evaluate our model with three publicly available datasets and achieve state-of-the-art performances as presented in the manuscript. The performance balance is more in favour of our model for sparser datasets compared to the dense datasets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-022-00422-w,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01517-9,Two-stage approach to solve ethical morality problem in self-driving cars,AI & SOCIETY,10.1007/s00146-022-01517-9,Springer,2022-06-27,"Ethical morality is one of the significant issues in self-driving cars. The paper provides a newer approach to solve the ethical decision problems in self-driving cars until there is no concrete ethical decision to all problems. This paper gives a two-way approach to solve a problem, with first being the mapping of problem to the solution already known or which has a fixed set of solutions and action priorities defined to a problem previously. Now, if no solution is found or mapping is unsuccessful, then the second stage activates, where the solution from Deep Q -learning model is calculated. It estimates the best Q value and returns that solution or action which maximizes the reward at that instance. The reward function is designed with decreasing priorities and acts accordingly, where the users can change or define their priorities if needed. The case study and results show that the solution that is present in the paper will lead to solving ethical morality problems in self-driving cars up to a great extent.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-022-01517-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10723-022-09610-5,An Efficient Deep Learning Approach Using Improved Generative Adversarial Networks for Incomplete Information Completion of Self-driving Vehicles,Journal of Grid Computing,10.1007/s10723-022-09610-5,Springer,2022-06-22,"Autonomous driving is a key technology for intelligent logistics in the Industrial Internet of Things (IIoT). In autonomous driving, the appearance of incomplete point clouds that lose geometric and semantic information is inevitable due to the limitations of occlusion, sensor resolution, and viewing angle when Light Detection And Ranging (LiDAR) is applied. The existence of incomplete point clouds, especially incomplete vehicle point clouds, would lead to a reduction in the accuracy of object detection, traffic alerts, and collision avoidance for autonomous driving vehicles. Existing point cloud completion networks, such as the Point Fractal Network (PF-Net), focus on the accuracy of point cloud completion without considering the efficiency of the inference process, which makes it difficult for them to be deployed for vehicle point cloud repair in autonomous driving. To address this problem, in this paper, we propose an efficient deep learning approach to repair incomplete vehicle point clouds in autonomous driving accurately and efficiently. In the proposed method, an efficient downsampling algorithm that combines incremental sampling and one-time sampling is presented to improve the inference speed of the PF-Net based on Generative Adversarial Network (GAN). To evaluate the performance of the proposed method, a real dataset is used, and autonomous driving scenes are created, where three incomplete vehicle point clouds with 5 different sizes are used for three autonomous driving situations. The improved PF-Net can achieve speedups of over 19x with almost the same accuracy when compared to the original PF-Net. Experimental results demonstrate that the improved PF-Net can be applied to efficiently complete vehicle point clouds in autonomous driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10723-022-09610-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03840-6,Weighted mean field reinforcement learning for large-scale UAV swarm confrontation,Applied Intelligence,10.1007/s10489-022-03840-6,Springer,2022-06-21,"Finding the optimal game strategy is a difficult problem in unmanned aerial vehicle (UAV) swarm confrontation. As an effective solution to the sequential decision-making problem, multi-agent reinforcement learning (MARL) provides a promising way to realize intelligent countermeasures. However, there are two challenges in applying MARL to large-scale UAV swarm confrontation: i) the curse of dimensionality caused by the excessive scale of UAV clusters and ii) the generalization problem caused by the dynamically changing UAV cluster size. To address these problems, we propose a novel MARL paradigm, called Weighted Mean Field Reinforcement Learning , where the pairwise communication between any UAV and its neighbors is modeled as that between a central UAV and the virtual UAV, which is abstracted from the weighted mean effect of neighboring UAVs. This approach reduces the multi-agent problem to a two-agent problem, which can reduce the input dimension of the agent and adapt to the changing cluster size. The communication content between UAVs includes actions and local observations. Actions can enhance the cooperation between UAVs and alleviate the non-stationarity of the environment, while local observations can expand the perception range of the central UAV so that it can obtain more useful information about the environment. The attention mechanism is leveraged to enable UAVs to select more valuable information flexibly, making our method more scalable than other algorithms. Combining this paradigm with double Q-learning and actor-critic algorithms, we propose weighted mean field Q-learning (WMFQ) and weighted mean field actor-critic (WMFAC) algorithms. Experiments on our constructed UAV swarm confrontation environment verify the effectiveness and scalability of our algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03840-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-022-06980-6,U19-Net: a deep learning approach for obstacle detection in self-driving cars,Soft Computing,10.1007/s00500-022-06980-6,Springer,2022-06-01,"Development of self-driving cars aims to drive safely from one point to another in a coordinated system where an on-board system should react and possibly alert drivers about the driving environments and possible collisions that may arise between drivers and obstacles. There are many deep learning approaches available for obstacle detection especially convolutional neural networks (CNNs) with improvement accuracy, and encoder–decoder networks are CNNs with a current attraction for researchers mainly because these models provide better results than classical statistical models for image segmentation and object classification tasks. This work proposes U19-Net an encoder–decoder deep model that explores the deep layers of a VGG19 model as an encoder following a symmetrical approach with an U-Net decoder designed for pixel-wise classifications. The U19-Net has end-to-end learning successfully effectiveness for the vehicle and pedestrian detection within the open-source Udacity dataset showing an IoU score of 87.08 and 78.18%, respectively. The proposed U19-Net is compared with five recent CNN networks using the AP metric, obtaining near results (less than 5%) for the faster R-CNN, one of the most commonly used networks for object detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-022-06980-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07104-9,Deep learning techniques to classify agricultural crops through UAV imagery: a review,Neural Computing and Applications,10.1007/s00521-022-07104-9,Springer,2022-06-01,"During the last few years, Unmanned Aerial Vehicles (UAVs) technologies are widely used to improve agriculture productivity while reducing drudgery, inspection time, and crop management cost. Moreover, they are able to cover large areas in a matter of a few minutes. Due to the impressive technological advancement, UAV-based remote sensing technologies are increasingly used to collect valuable data that could be used to achieve many precision agriculture applications, including crop/plant classification. In order to process these data accurately, we need powerful tools and algorithms such as Deep Learning approaches. Recently, Convolutional Neural Network (CNN) has emerged as a powerful tool for image processing tasks achieving remarkable results making it the state-of-the-art technique for vision applications. In the present study, we reviewed the recent CNN-based methods applied to the UAV-based remote sensing image analysis for crop/plant classification to help researchers and farmers to decide what algorithms they should use accordingly to their studied crops and the used hardware. Fusing different UAV-based data and deep learning approaches have emerged as a powerful tool to classify different crop types accurately. The readers of the present review could acquire the most challenging issues facing researchers to classify different crop types from UAV imagery and their potential solutions to improve the performance of deep learning-based algorithms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-022-07104-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43657-022-00048-z,A Comprehensive Review of High Throughput Phenotyping and Machine Learning for Plant Stress Phenotyping,Phenomics,10.1007/s43657-022-00048-z,Springer,2022-06-01,"During the last decade, there has been rapid adoption of ground and aerial platforms with multiple sensors for phenotyping various biotic and abiotic stresses throughout the developmental stages of the crop plant. High throughput phenotyping (HTP) involves the application of these tools to phenotype the plants and can vary from ground-based imaging to aerial phenotyping to remote sensing. Adoption of these HTP tools has tried to reduce the phenotyping bottleneck in breeding programs and help to increase the pace of genetic gain. More specifically, several root phenotyping tools are discussed to study the plant’s hidden half and an area long neglected. However, the use of these HTP technologies produces big data sets that impede the inference from those datasets. Machine learning and deep learning provide an alternative opportunity for the extraction of useful information for making conclusions. These are interdisciplinary approaches for data analysis using probability, statistics, classification, regression, decision theory, data visualization, and neural networks to relate information extracted with the phenotypes obtained. These techniques use feature extraction, identification, classification, and prediction criteria to identify pertinent data for use in plant breeding and pathology activities. This review focuses on the recent findings where machine learning and deep learning approaches have been used for plant stress phenotyping with data being collected using various HTP platforms. We have provided a comprehensive overview of different machine learning and deep learning tools available with their potential advantages and pitfalls. Overall, this review provides an avenue for studying various HTP platforms with particular emphasis on using the machine learning and deep learning tools for drawing legitimate conclusions. Finally, we propose the conceptual challenges being faced and provide insights on future perspectives for managing those issues.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43657-022-00048-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1134/S0005117922060054,Simultaneous Learning and Planning in a Hierarchical Control System for a Cognitive Agent,Automation and Remote Control,10.1134/S0005117922060054,Springer,2022-06-01,"Abstract The tasks of behavior planning and decision-making learning in a dynamic environment are usually divided and considered separately in control systems for intelligent agents. A new unified hierarchical formulation of the problem of simultaneous learning and planning (SLAP) is proposed in the context of object-oriented reinforcement learning, and an architecture of a cognitive agent that solves this problem is described. A new algorithm for learning actions in a partially observed external environment is proposed using a reward signal, an object-oriented subject description of the states of the external environment, and dynamically updated action plans. The main properties and advantages of the proposed algorithm are considered, including the lack of a fixed cognitive cycle necessitating the separation of planning and learning subsystems in earlier algorithms and the ability to construct and update the model of interaction with the environment, thus increasing the learning efficiency. A theoretical justification of some provisions of this approach is given, a model example is proposed, and the principle of operation of a SLAP agent when driving an unmanned vehicle is demonstrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1134/S0005117922060054,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01334-6,Social implications of autonomous vehicles: a focus on time,AI & SOCIETY,10.1007/s00146-021-01334-6,Springer,2022-06-01,"The urban environment is increasingly engaging with artificial intelligence, a focus on the automation of urban processes, whether it be singular artefacts or city-wide systems. The impact of such technological innovation on the social dynamics of the urban environment is an ever changing and multi-faceted field of research. In this paper, the space and time defined by the autonomous vehicle is used as a window to view the way in which a shift in urban transport dynamics can impact the temporal experience of an individual. Using the finite window of time created by an autonomous vehicle, a theoretical framework is put forward that seeks to show how contrasting narratives exist regarding the experience of the window of time within the autonomous vehicle. By taking a theoretical approach informed by social theory, the dissolution of barriers between separate spheres of life is explored to highlight the increased commodification of time. In focusing on both the space and time created by the autonomous vehicle this approach seeks to highlight how artificial intelligence can provide a contemporary space in the urban environment while also opening a new window of time. The cognitive dissonance observed when comparing the narratives of autonomous vehicle stakeholders and the historical shift in time use leads to a belief that technology makes the user more free in terms of time. With this paper the autonomous vehicle is shown to be an ideal space and time to view the way in which the use of such technology does not increase free-time, but further dissolves the boundaries between what is and what is not work-time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01334-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-022-03897-8,Deep learning-based face detection and recognition on drones,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-022-03897-8,Springer,2022-05-29,"Unmanned aerial vehicles as known as drones, are aircraft that can comfortably search locations which are excessively dangerous or difficult for humans and take data from bird's-eye view. Enabling unmanned aerial vehicles to detect and recognize humans on the ground is essential for various applications, such as remote monitoring, people search, and surveillance. The current face detection and recognition models are able to detect or recognize faces on unmanned aerial vehicles using various limits in height, angle and distance, mainly where drones take images from high altitude or long distance. In the present paper, we proposed a novel face detection and recognition model on drones for improving the performance of face recognition when query images are taken from high altitudes or long distances that do not show much facial information of the humans. Moreover, we aim to employ deep neural network to perform these tasks and reach an enhanced top performance. Experimental evaluation of the proposed framework compared to state-of-the-art models over the DroneFace dataset demonstrates that our method can attain competitive accuracy on both the recognition and detection protocols.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-022-03897-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13563-022-00317-3,Breakthrough technologies for mineral exploration,Mineral Economics,10.1007/s13563-022-00317-3,Springer,2022-05-19,"Breakthrough technologies for mineral exploration are discussed from two perspectives. The first perspective is intended to discuss the important factors required for exploration technologies, derived deductively from a review of the role and expectations of exploration in the mining industry and the current situation of the mining industry. The second perspective is intended to discuss the common characteristics of breakthrough technologies for mineral exploration derived inductively from a review of specific examples of technological breakthroughs that actually brought about innovation to exploration: e.g. induced polarization (IP); airborne electromagnetics (EM); airborne gravity gradiometry (AGG); spectroscopic methods; global navigation satellite system (GNSS); unmanned survey platform; and neural networks/deep learning. The specific issues to be solved as breakthroughs in exploration technology in the near future are summarized as follows: (1) Significant improvement in economic efficiency, namely: labor-saving, automated or unmanned operation, e.g. unmanned aerial vehicle (UAV)-based exploration and automatic spectroscopic scanning of drill cores; higher accessing capability, e.g. improvement of various airborne exploration techniques including airborne EM, AGG, and especially airborne IP; higher work efficiency and productivity, e.g. automatic data processing by neural networks/deep learning; and lower cost to implement, e.g. less expensive platforms such as UAVs. (2) To obtain information that is really needed for exploration, specifically: IP effect of sulfide minerals associated with mineralization, i.e. practical spectral IP (SIP); geophysical characterization of the deep underground, e.g. enhancement of superconducting quantum interference device (SQUID)-based time-domain electromagnetic (TDEM); and removal of effects of the surface layer, e.g. very conductive deeply-weathered overburden and younger volcanics rich in magnetic minerals. (3) To obtain information that could not be obtained by the conventional methods, specifically: distribution of endmember minerals related to mineralization, i.e. hyperspectral mapping with high spatial resolution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13563-022-00317-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-022-01461-8,How virtue signalling makes us better: moral preferences with respect to autonomous vehicle type choices,AI & SOCIETY,10.1007/s00146-022-01461-8,Springer,2022-05-12,"One of the moral questions concerning autonomous vehicles (henceforth AVs) is the choice between types that differ in their built-in algorithms for dealing with rare situations of unavoidable lethal collision. It does not appear to be possible to avoid questions about how these algorithms should be designed. We present the results of our study of moral preferences ( N  = 2769) with respect to three types of AVs: (1) selfish, which protects the lives of passenger(s) over any number of bystanders; (2) altruistic, which minimizes the number of casualties, even if this leads to death of passenger(s); and (3) conservative, which abstains from interfering in such situations. We differentiate between scenarios in which participants are to make their decisions privately or publicly, and for themselves or for their offspring. We aim to answer two research questions: (1) whether the public visibility of the choice of an AV type choice make this choice more altruistic and (2) which type of situation makes it more difficult to choose altruistically: when choosing for society as a whole, when choosing only for oneself, or when choosing only for one’s offspring. Our results show that respondents exhibit a preference for an altruistic strategy for AVs and that it is reinforced when signaled to others. The altruistic preference is strongest when applies to everybody else, weaker when it reflects a solely personal choice, and weakest when choosing for one’s own child. We conclude that a public choice is considerably more likely to pressure consumers into accepting a more socially beneficial solution.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-022-01461-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03357-y,Decision making for autonomous vehicles in highway scenarios using Harmonic SK Deep SARSA,Applied Intelligence,10.1007/s10489-022-03357-y,Springer,2022-05-10,"The complexity of taking decisions for an autonomous vehicle (AV) to avoid road accident fatalities, provide safety, comfort, and reduce traffic raises the need for improvements in the field of decision making. To solve these challenges, many algorithms and techniques were applied, and the most common ones were reinforcement learning (RL) algorithms combined with deep learning techniques. Therefore, in this paper we proposed a novel extension of the popular “SARSA” (State-Action-Reward-State-Action) RL technique called “Harmonic SK Deep SARSA” that takes advantage of the stability which SARSA algorithm provides and uses the notion of similar and cumulative states saved in an alternative memory to enhance the stability of the algorithm and achieve remarkable performance that SARSA could not accomplish due to its on policy nature. Through the investigation of our novel extension the adaptability of the algorithm to unexpected situations during learning and to unforeseen changes in the environment was proved while reducing the computational load in the learning process and increasing the convergence rate that plays a key role in upgrading decision making application that require numerous real time consecutive decisions, including autonomous vehicles, industrial robots, gaming, aerial navigation... The novel algorithm was tested in a gym environment simulator called “Highway-env” with multiple highway situations (multiple lanes configurations, highway with dynamic number of lanes (from 4-lane to 2-lane, from 4-lane to 6-lane), merge) with numerous dynamic obstacles. For the purpose of comparison, we used a benchmark of cutting edge algorithms known for their prominent performance. The experimental results showed that the proposed algorithm outperformed the comparison algorithms in learning stability and performance that were validated by the following metrics: average loss value per episode, average accuracy per episode, maximum speed value reached per episode, average speed per episode, and the total reward per episode.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03357-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-022-03468-6,Improving environmental awareness for autonomous vehicles,Applied Intelligence,10.1007/s10489-022-03468-6,Springer,2022-05-03,"Autonomous vehicles (AVs) have multiple tasks with different priorities and safety levels where classic supervised learning techniques are no longer applicable. Thus, reinforcement learning (RL) algorithms become increasingly appropriate for this domain as the RL algorithms can act on complex problems and adapt their responses in the face of unforeseen situations and environments. The RL agent aims to perform the action that guarantees the optimal reward with the best score. The problem with this approach is if the agent finds a possible optimal action with a reasonable premium and gets stuck in this mediocre strategy, which at the same time is neither the best nor the worst solution. Therefore, the agent avoids performing a more extensive exploration to find new paths and learn alternatives to generate a higher reward. To alleviate this problem, we research the behavior of two types of noise in AVs training. We analyze the results and point out the noise method that most stimulates exploration. A vast exploration of the environment is highly relevant to AVs because they know more about the environment and learn alternative ways of acting in the face of uncertainties. With that, AVs can expect more reliable actions in front of sudden changes in the environment. According to our experiments’ results in a simulator, we can see that noise allows the autonomous vehicle to improve its exploration and increase the reward.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-022-03468-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07278-2,Enhanced decision making in multi-scenarios for autonomous vehicles using alternative bidirectional Q network,Neural Computing and Applications,10.1007/s00521-022-07278-2,Springer,2022-05-02,"To further enhance decision making in autonomous vehicles field, grant more safety, comfort, reduce traffic, and accidents, learning approaches were adopted, mainly reinforcement learning. However, possibility in upgrading these algorithms is still available due to many limitations including : convergence rate, stability, handling multiple dynamic environments, raw performance, robustness, and complexity of algorithms. To tackle these problems, we propose a novel extension of the well-known deep Q network called “alternative bidirectional Q network” that aims mainly to enhance stability and performance with improving exploration and Q values update policies, to overcome the literature gap that generally focuses on only one policy to handle decision making in multiple scenarios (avoiding obstacles, goal-oriented environments, etc.). In “alternative bidirectional Q network,” data about previous, current, and upcoming states are used to update the Q values where the actions are selected according to the relation between these data to handle several scenarios: highways, merges, roundabouts, and parking. This concept provides reinforcement learning agents with more balance between exploration and exploitation and enhances stability during learning. A gym simulator was adopted for training and testing the proposed algorithm’s outcome, while various state-of-the-art algorithms were used as benchmark models. The performance of the proposed extension was evaluated using several metrics being: loss, accuracy, speed, and reward values, where the results of comparison showed the superiority of the novel extension in all scenarios for most of the exploited metrics. The experiment results were confirmed using the complexity and the robustness aspects.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-022-07278-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-022-01160-7,iDrone: IoT-Enabled Unmanned Aerial Vehicles for Detecting Wildfires Using Convolutional Neural Networks,SN Computer Science,10.1007/s42979-022-01160-7,Nature,2022-04-25,"The rise of global temperatures, over the past few decades, has disrupted the usual balance of nature. As a result of increasing temperatures, wildfires have destroyed millions of acres of land, thousands of structures, and homes. The pollution and toxic gases produced by the wildfires are carried out to thousands of miles, thus threatening the lives all around the world. Most wildfires occur due to anthropogenic factors, which cannot be predicted solely based on climate conditions. Henceforth, to detect wildfires before escalating, we propose iDrone, which is a wildfire detection system equipped with an end-to-end CNN image classification model: XtinguishNet, trained on a wildfire imagery dataset to detect the possible flames or smokes in an image. In addition, our approach also acquires the weather data and the intensity of the fire. Contrasting with existing wildfire detection systems, our proposed solution is a fusion of the Internet of Things (IoT) and Deep Learning, aiming to provide a one-stop solution for all the needs required to minimize the damage caused by wildfires. When validated and tested using various benchmark datasets, video surveillance, iDrone acquired a high accuracy of 98.36% with the least computational power.",https://www.nature.com/articles/s42979-022-01160-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01603-6,"Continual Learning for Real-World Autonomous Systems: Algorithms, Challenges and Frameworks",Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01603-6,Springer,2022-04-23,"Continual learning is essential for all real-world applications, as frozen pre-trained models cannot effectively deal with non-stationary data distributions. The purpose of this study is to review the state-of-the-art methods that allow continuous learning of computational models over time. We primarily focus on the learning algorithms that perform continuous learning in an online fashion from considerably large (or infinite) sequential data and require substantially low computational and memory resources. We critically analyze the key challenges associated with continual learning for autonomous real-world systems and compare current methods in terms of computations, memory, and network/model complexity. We also briefly describe the implementations of continuous learning algorithms under three main autonomous systems, i.e., self-driving vehicles, unmanned aerial vehicles, and urban robots. The learning methods of these autonomous systems and their strengths and limitations are extensively explored in this article.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01603-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-022-10802-z,Conditional Variational Autoencoder Networks for Autonomous Vehicle Path Prediction,Neural Processing Letters,10.1007/s11063-022-10802-z,Springer,2022-04-02,"Mobility of autonomous vehicles is a challenging task to implement. Under the given traffic circumstances, all agent vehicles’ behavior is to be understood and their paths for a short future needs to be predicted to decide upon the maneuver of the ego vehicle. We explore variational autoencoder networks to get multimodal predictions of agents. In our work, we condition the network on past trajectories of agents and traffic scenes as well. The latent space representation of traffic scenes is achieved by using another variational autoencoder network. The proposed networks are trained for varied prediction horizon. The performance of a network is compared with other networks trained on the dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-022-10802-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42461-022-00548-6,A High-Precision Road Network Construction Method Based on Deep Learning for Unmanned Vehicle in Open Pit,"Mining, Metallurgy & Exploration",10.1007/s42461-022-00548-6,Springer,2022-04-01,"To solve the problem of time-consuming and low precision in updating the open-pit vehicle transportation network, a high precision road network model construction method for unmanned vehicles in open-pit mines is proposed. This method can be divided into two steps. In the first step, an improved deep learning image processing model named DeepLabv3 + C (DeepLabv3 + Concat) is presented. Then, the road information extracted by the DeepLabv3 + C network is used to construct a three-dimensional model of the open-pit mine road network. In the second step, aiming at the time-consuming problem of unmanned vehicle meeting in open-pit mines, a vehicle meeting strategy was proposed. This strategy is used to guide the navigation of unmanned vehicles in open-pit mines. Besides, the DeepLabv3 + C network is verified by comparing the mIOU (means Intersection Over Union), accuracy, and continuity of road image extraction with the mainstream networks. The road network model constructed in the first step is quantitatively analyzed, and its performance is compared with GPS trajectory clustering methods. At the end of the paper, vehicle running simulation is carried out on the road network model by using Unity (a 3D visualization simulation software). The results show that the road network model constructed by this method can meet the navigation requirements of unmanned vehicles in open-pit mines, and the feasibility of the vehicle meeting strategy is proved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42461-022-00548-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12555-021-0729-1,Multiclass Classification Fault Diagnosis of Multirotor UAVs Utilizing a Deep Neural Network,"International Journal of Control, Automation and Systems",10.1007/s12555-021-0729-1,Springer,2022-04-01,"A fault diagnosis algorithm using a deep neural network for an octocopter Unmanned Aerial Vehicle (UAV) is proposed. All eight rotors are considered in the multiclass classification fault diagnosis problem. The latest angle time history is fed to the proposed algorithm to determine rotor failure in real time. The normal case and fault case of each rotor are considered with appropriate output pairs to form a dataset. The proposed classifier can distinguish a failed rotor from the others with the help of different patterns of Euler angles during the training process. Two hidden layers are constructed using sigmoid and softmax activation functions. A generalized delta rule is adopted, and a stochastic gradient descent scheme is used to calculate the weight update of the neural network. The proposed fault diagnosis algorithm can be augmented to a fault-tolerant controller to construct an integrated system that involves solving a convex optimization problem. Numerical simulations are conducted to validate the performance of the proposed diagnostic algorithm. It is demonstrated that the performance can be adjusted by controlling the design parameters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12555-021-0729-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06762-5,RIECNN: real-time image enhanced CNN for traffic sign recognition,Neural Computing and Applications,10.1007/s00521-021-06762-5,Springer,2022-04-01,"Traffic sign recognition plays a crucial role in the development of autonomous cars to reduce the accident rate and promote road safety. It has been a necessity to address traffic signs that are affected significantly by the environment as well as poor real-time performance for deep-learning state-of-the-art algorithms. In this paper, we introduce Real-Time Image Enhanced CNN (RIECNN) for Traffic Sign Recognition. RIECNN is a real-time, novel approach that tackles multiple, diverse traffic sign datasets, and out-performs the state-of-the-art architectures in terms of recognition rate and execution time. Experiments are conducted using the German Traffic Sign Benchmark (GTSRB), the Belgium Traffic Sign Classification (BTSC), and the Croatian Traffic Sign (rMASTIF) benchmark. Experimental results show that our approach has achieved the highest recognition rate for all Benchmarks, achieving a recognition accuracy of 99.75% for GTSRB, 99.25% for BTSC and 99.55% for rMASTIF. In terms of latency and meeting the real-time constraint, the pre-processing time and inference time together do not exceed 1.3 ms per image. Not only have our proposed approach achieved remarkably high accuracy with real-time performance, but it also demonstrated robustness against traffic sign recognition challenges such as brightness and contrast variations in the environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06762-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-06101-8,Path-tracking control for autonomous vehicles using double-hidden-layer output feedback neural network fast nonsingular terminal sliding mode,Neural Computing and Applications,10.1007/s00521-021-06101-8,Springer,2022-04-01,"In this paper, a double-hidden-layer output feedback neural network fast nonsingular terminal sliding mode control strategy is developed for path-tracking tasks of autonomous vehicles. First, a vehicle kinematic-and-dynamic model is established to describe the vehicle’s fundamental lateral dynamics in path-tracking behavior. Afterwards, detailed design procedure of the proposed controller is shown, where the control system’s stability is verified in the Lyapunov sense. Finally, MATLAB-Carsim co-simulations are executed for the aim of testing the control performance. Simulation results illustrate that the designed control algorithm possesses remarkable superiority reflected in higher tracking precision, faster convergence rate and firmer robustness in comparison with a conventional sliding mode controller and a nonsingular terminal sliding mode controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-06101-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-12447-5,Road object detection: a comparative study of deep learning-based algorithms,Multimedia Tools and Applications,10.1007/s11042-022-12447-5,Springer,2022-04-01,"Deep learning field has progressed the vision-based surround perception and has become the most trending area in the field of Intelligent Transportation System (ITS). Many deep learning-based algorithms using two-dimensional images have become an essential tool for autonomous vehicles with object detection, tracking, and segmentation for road target detection, primarily including pedestrians, vehicles, traffic lights, and traffic signs. Autonomous vehicles rely heavily on visual data to classify and generalize target objects which can satisfy pedestrians’ and other vehicles’ safety requirements in their environment. In real-time, outstanding results are obtained by deep learning-based algorithms for object detection. While several studies have thoroughly examined different types of deep learning-based object detection methods, there are a few comparable studies that either test the detection speed or accuracy of the object detection algorithms. In addition to speed and accuracy, autonomous driving also depends on model size and energy efficiency. However, there is a lack of comparison on various such metrics among existing deep learning-based methods. This article aims to provide a detailed and systematic comparative analysis of five independent mainstream deep learning-based algorithms for road object detection, namely the R-FCN, Mask R-CNN, SSD, RetinaNet, and YOLOv4 on a large-scale Berkeley DeepDrive (BDD100K) dataset. The experimental results are analyzed using the mean Average Precision (mAP) value and inference time. Additionally, various practical metrics, such as model size, computational complexity, and energy efficiency of deep learning-based models are precisely computed. Furthermore, the performance of each algorithm is evaluated under different road environmental conditions at various times of day and night. The comparison presented in this article helps to gain insight into the strengths and limitations of the popular deep learning-based algorithms under practical constraints with their real-time deployment feasibility. Code is publicly available at: https://github.com/bharatmahaur/ComparativeStudy",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-022-12447-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11044-022-09816-1,End-to-end learning for off-road terrain navigation using the Chrono open-source simulation platform,Multibody System Dynamics,10.1007/s11044-022-09816-1,Springer,2022-04-01,"This contribution ( i $i$ ) describes an open-source, physics-based simulation infrastructure that can be used to learn and test control policies in off-road navigation; and ( i i $ii$ ) demonstrates the use of the simulation platform in an end-to-end learning exercise that relies on simulated sensor data fusion (camera, GPS and IMU). For ( i $i$ ), the 0.5 million lines of open-source code support vehicle dynamics (wheeled/tracked vehicles, rovers), deformable & non-deformable terrains, and virtual sensing. The library has a Python API for interfacing with existing Machine Learning frameworks. For ( i i ) $(ii)$ , we use a Gator off-road vehicle to demonstrate how a policy learned on non-deformable terrain performs when used in hilly conditions while navigating around a course of randomly placed obstacles on deformable terrain. The hilly terrain covers an 80×80 m patch and the soil can be controlled by the user to assume various behavior, e.g. non-deformable, deformable hard (silt-like), deformable soft (snow-like), etc. To the best of our knowledge, there is no other open-source, physics-based engine that can be used to simulate off-road mobility of autonomous agents operating on deformable terrains. The results reported herein can be reproduced with models and data available in a public repository (UW-Madison Simulation Based Engineering Laboratory, Supporting models, scripts, data, https://go.wisc.edu/arflqq , 2021 ). Animations associated with the tests run are available online (UW-Madison Simulation Based Engineering Laboratory, Supporting simulations, https://go.wisc.edu/256xb9 , 2021 ).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11044-022-09816-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-022-01601-8,Autonomous Obstacle Avoidance and Target Tracking of UAV Based on Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-022-01601-8,Springer,2022-03-19,"When using deep reinforcement learning algorithm to complete Unmanned Aerial Vehicle (UAV) autonomous obstacle avoidance and target tracking tasks, there are often some problems such as slow convergence speed and low success rate. Therefore, this paper proposes a new deep reinforcement learning algorithm, namely Multiple Pools Twin Delay Deep Deterministic Policy Gradient (MPTD3) algorithm. Firstly, the state space and action space of UAV are established as continuous models, which is closer to engineering practice than discrete models. Then, multiple experience pools mechanism and gradient truncation are designed to improve the convergence of the algorithm. Furthermore, the generalization ability of the algorithm is obtained by giving UAV environmental perception ability. Experimental results verify the effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-022-01601-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10681-022-02992-3,Deep learning: as the new frontier in high-throughput plant phenotyping,Euphytica,10.1007/s10681-022-02992-3,Springer,2022-03-18,"With climate change and ever-increasing population growth, the pace of varietal development needs to be accelerated in order to feed a population of 10 billion by 2050. Non-invasive high-throughput plant phenotyping (HTP) using advanced imaging technology has capabilities to boost the varietal development process. The tremendous data generated with sensor aided HTP have created the big data and problem in the downstream data analysis pipeline. The higher-level abstraction achieved on high dimensional data by multiple hidden layers for function approximation have made deep learning applications in HTP of significant interest. Application of deep learning models to enhance image-based throughput in phenotyping is an emerging and dynamic area of research in plant phenomics. In this comprehensive review we highlighted the recent developments in the field of deep learning application for HTP. The deep learning principles are described and contextualized relative to machine learning and conventional computer vision algorithms. Novel and emerging deep learning applications are identified. Recommendations are provided with the intent of choosing the most suitable models and training strategy for the capturing and predicting sensor-based phenotyping traits. It also includes steps and suggestions for the development and eventual deployment of such models for multi-task phenotyping. Public datasets have been identified and these datasets are reported which can be used for model training and benchmarking. Overall, this study provided a comprehensive overview of deep learning, it’s application in plant phenomics, potential barriers and scope of improvement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10681-022-02992-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-03029-3,A spatiotemporal attention-based neural network to evaluate the route risk for unmanned aerial vehicles,Applied Intelligence,10.1007/s10489-021-03029-3,Springer,2022-03-18,"Route risk evaluation is crucial for planning safe routes when unmanned aerial vehicles (UAVs) perform missions in hostile environments. The purpose of route risk evaluation is to fuse the intents, capabilities, and opportunities of the enemy to predict the damage to UAV in the future. Opportunities depend on the current as well as historical situation of the battlefield and are difficult to estimate effectively for the existing risk evaluation models. We propose a novel spatiotemporal attention-based evaluation network (STAEN) to automatically evaluate the route risk. In particular, the spatiotemporal attention values provided by the STAEN can reflect the opportunities of the enemy to threaten the UAV, which helps to understand the spatiotemporal evolutions of the situations on different routes. In addition, the network can automatically focus on the key route segments and defense subsystems in different evolution stages, to evaluate the route risk more accurately. The validity and interpretability of the evaluation network are verified by simulation experiments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-021-03029-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43684-022-00023-5,Multi-agent reinforcement learning for cooperative lane changing of connected and autonomous vehicles in mixed traffic,Autonomous Intelligent Systems,10.1007/s43684-022-00023-5,Springer,2022-03-16,"Autonomous driving has attracted significant research interests in the past two decades as it offers many potential benefits, including releasing drivers from exhausting driving and mitigating traffic congestion, among others. Despite promising progress, lane-changing remains a great challenge for autonomous vehicles (AV), especially in mixed and dynamic traffic scenarios. Recently, reinforcement learning (RL) has been widely explored for lane-changing decision makings in AVs with encouraging results demonstrated. However, the majority of those studies are focused on a single-vehicle setting, and lane-changing in the context of multiple AVs coexisting with human-driven vehicles (HDVs) have received scarce attention. In this paper, we formulate the lane-changing decision-making of multiple AVs in a mixed-traffic highway environment as a multi-agent reinforcement learning (MARL) problem, where each AV makes lane-changing decisions based on the motions of both neighboring AVs and HDVs. Specifically, a multi-agent advantage actor-critic (MA2C) method is proposed with a novel local reward design and a parameter sharing scheme. In particular, a multi-objective reward function is designed to incorporate fuel efficiency, driving comfort, and the safety of autonomous driving. A comprehensive experimental study is made that our proposed MARL framework consistently outperforms several state-of-the-art benchmarks in terms of efficiency, safety, and driver comfort.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43684-022-00023-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13007-022-00861-7,Estimation of plant height and yield based on UAV imagery in faba bean (Vicia faba L.),Plant Methods,10.1186/s13007-022-00861-7,BioMed Central,2022-03-05,"Background Faba bean is an important legume crop in the world. Plant height and yield are important traits for crop improvement. The traditional plant height and yield measurement are labor intensive and time consuming. Therefore, it is essential to estimate these two parameters rapidly and efficiently. The purpose of this study was to provide an alternative way to accurately identify and evaluate faba bean germplasm and breeding materials. Results The results showed that 80% of the maximum plant height extracted from two-dimensional red–green–blue (2D-RGB) images had the best fitting degree with the ground measured values, with the coefficient of determination (R^2), root-mean-square error (RMSE), and normalized root-mean-square error (NRMSE) were 0.9915, 1.4411 cm and 5.02%, respectively. In terms of yield estimation, support vector machines (SVM) showed the best performance (R^2 = 0.7238, RMSE = 823.54 kg ha^−1, NRMSE = 18.38%), followed by random forests (RF) and decision trees (DT). Conclusion The results of this study indicated that it is feasible to monitor the plant height of faba bean during the whole growth period based on UAV imagery. Furthermore, the machine learning algorithms can estimate the yield of faba bean reasonably with the multiple time points data of plant height.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-022-00861-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12369-021-00790-w,Designing AI for Explainability and Verifiability: A Value Sensitive Design Approach to Avoid Artificial Stupidity in Autonomous Vehicles,International Journal of Social Robotics,10.1007/s12369-021-00790-w,Springer,2022-03-01,"One of the primary, if not most critical, difficulties in the design and implementation of autonomous systems is the black-boxed nature of the decision-making structures and logical pathways. How human values are embodied and actualised in situ may ultimately prove to be harmful if not outright recalcitrant. For this reason, the values of stakeholders become of particular significance given the risks posed by opaque structures of intelligent agents. This paper explores how decision matrix algorithms, via the belief-desire-intention model for autonomous vehicles, can be designed to minimize the risks of opaque architectures. Primarily through an explicit orientation towards designing for the values of explainability and verifiability. In doing so, this research adopts the Value Sensitive Design (VSD) approach as a principled framework for the incorporation of such values within design. VSD is recognized as a potential starting point that offers a systematic way for engineering teams to formally incorporate existing technical solutions within ethical design, while simultaneously remaining pliable to emerging issues and needs. It is concluded that the VSD methodology offers at least a strong enough foundation from which designers can begin to anticipate design needs and formulate salient design flows that can be adapted to the changing ethical landscapes required for utilisation in autonomous vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12369-021-00790-w,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S1060992X22010064,Neural Network Nonlinear Adaptive Fault Tolerant Motion Control for Unmanned Aerial Vehicles,Optical Memory and Neural Networks,10.3103/S1060992X22010064,Springer,2022-03-01,"Abstract The problem of motion control for an unmanned aerial vehicle (UAV) is considered. We solve this problem in a nonlinear formulation under uncertainties due to failures in the UAV systems and damages to its structure. The required quality of control in these conditions is provided by using adaptive fault-tolerant control schemes in MRAC (Model Reference Adaptive Control) and MPC (Model Predictive Control) variants. Implementing such schemes, which are increasingly used in UAVs, requires, as a rule, first forming a model of the controlled object. One of the most promising approaches to solving modeling and control problems concerning a nonlinear dynamic object is the approach based on neural network technologies. We implemented the required control object model and MRAC and MPC adaptive fault-tolerant control schemes with these technologies. The capabilities of the proposed approach are demonstrated in the example of solving the problem of adaptive fault-tolerant control of longitudinal angular motion for two classes of UAVs. The results of the computational experiments for these UAVs are presented, confirming the efficiency and potential of the considered approach.",http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1060992X22010064,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00607-021-00953-7,Cloud-backed mobile cognition,Computing,10.1007/s00607-021-00953-7,Springer,2022-03-01,"Low-power embedded technology offers a roadmap for enabling deep learning (DL) applications in mobile scenarios, like future autonomous vehicles. However, the lack of breakthrough power efficiency improvements can jeopardize the realization of truly “cognitive” mobile systems that meet real-time deadlines. This work focuses on the new generation cloud-backed mobile cognition system architecture where vehicles execute DL applications with dynamic assistance from the cloud. We unveil opportunities for power-efficient inferencing at the edge through a technique that balances inference execution across the cloud and the vehicle. This level of adaptation results in significant power efficiency improvements compared to all or nothing solutions, where inferences execute either completely on the vehicle or completely in the cloud. In addition, the cloud can have an active role in helping the vehicle to improve its DL capabilities by communicating relevant model updates, with up to 63% bandwidth savings and negligible accuracy degradation when the proposed relevance-driven federated learning technique is used. Finally, the cloud-backed mobile cognition concept is extended to the case of “flying clouds” where vehicles connect to flying drones that provide services while in flight. Although their capabilities are not on par with the stationary cloud, the flying cloud reduces services’ latency significantly and enables critical functionalities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00607-021-00953-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-021-03120-9,Graph Neural Network with RNNs based trajectory prediction of dynamic agents for autonomous vehicle,Applied Intelligence,10.1007/s10489-021-03120-9,Springer,2022-02-15,"Trajectory prediction is an essential ability for the intelligent transportation system to navigate through complex traffic scenes. In recent times, trajectory prediction has become an important task, especially in crowded scenes, because of the great demands of emerging artificial intelligence applications like service bots and autonomous cars. As autonomous vehicles travel in interactive and highly uncertain environments shared with other dynamic road agents like other vehicles or pedestrians, predicting the trajectories of the surrounding agents is essential for an autonomous driving system (ADS) to plan safe motion, fast reaction time and comfortable maneuvers. The trajectory for each dynamic object (or road agent) is described as a sequence of states within a time interval, with each state representing the object’s spatial coordinates under the world coordinate frame. In the trajectory prediction (TP) problem, given the trajectory of each object between intervals of time, we predict their trajectories between these intervals of time. We plan to design a Multi-Scale Graph Neural Network (GNN) with temporal features architecture for this prediction problem. Experiments show that our model effectively captures comprehensive Spatio-temporal correlations through modeling GNN with temporal features for TP and consistently surpasses the existing state-of-the-art methods on three real-world datasets for trajectory. Compared to prior methods, our model’s performance is more for the sparse datasets than for the dense datasets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-021-03120-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11116-021-10263-8,Neural network model for predicting variation in walking dynamics of pedestrians in social groups,Transportation,10.1007/s11116-021-10263-8,Springer,2022-02-13,"Pedestrian spaces are increasingly becoming popular locations for shopping, recreation, festivities, and other social activities. Therefore, an improved understanding of the factors that make walking environments enjoyable and safe is essential. Most existing studies focus on modelling walking behaviours of individual pedestrians. However, most people participate in these activities as parts of social groups. Although the movement and choice behaviours of pedestrians in social groups differ from those of individuals, a model featuring group movements has not been developed. This study uses neural networks to analyse the effects of variables influencing pedestrian movements of social groups and predict the variation in walking dynamics. A top-view video was used to extract the trajectories of pedestrian groups. After identifying the social groups in a crowd, the movement characteristics, pedestrian–environment interaction, inter-pedestrian interaction, intra-group relationship, and inter-group relationship of all group members were calculated and considered in the model. After a variable selection process using neural networks, a neural network model was developed featuring variables that are strongly related to the lateral or longitudinal changes in the individual’s walking speed. The current movement condition, presence of obstacles nearby, impending collisions, current position and velocity of other group members, and following behaviour were found to impact a pedestrian’s walking dynamics. The proposed model can predict the pedestrian density and distribution according to a space function, contributing to better crowd management and efficient design and renovation of pedestrian spaces. Furthermore, the variable selection method can optimise and simplify other pedestrian behaviour prediction models.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11116-021-10263-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01548-2,Solving Reward-Collecting Problems with UAVs: A Comparison of Online Optimization and Q-Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01548-2,Springer,2022-02-09,"Uncrewed autonomous vehicles (UAVs) have made significant contributions to reconnaissance and surveillance missions in past US military campaigns. As the prevalence of UAVs increases, there has also been improvements in counter-UAV technology that makes it difficult for them to successfully obtain valuable intelligence within an area of interest. Hence, it has become important that modern UAVs can accomplish their missions while maximizing their chances of survival. In this work, we specifically study the problem of identifying a short path from a designated start to a goal, while collecting all rewards and avoiding adversaries that move randomly on the grid. We also provide a possible application of the framework in a military setting, that of autonomous casualty evacuation . We present a comparison of three methods to solve this problem: namely we implement a Deep Q -Learning model, an $$\varepsilon$$ ε -greedy tabular Q -Learning model, and an online optimization framework. Our computational experiments, designed using simple grid-world environments with random adversaries showcase how these approaches work and compare them in terms of performance, accuracy, and computational time.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01548-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11356-022-18985-7,Unmanned aerial vehicle images in the machine learning for agave detection,Environmental Science and Pollution Research,10.1007/s11356-022-18985-7,Springer,2022-02-02,"In this study, six supervised classification algorithms were compared. The algorithms were based on cluster analysis, distance, deep learning, and object-based image analysis. Our objective was to determine which of these algorithms has the highest overall accuracy in both detection and automated estimation of agave cover in a given area to help growers manage their plantations. An orthomosaic with a spatial resolution of 2.5 cm was derived from 300 images obtained with a DJI Inspire 1 unmanned aerial system. Two training classes were defined: (1) sites where the presence of agaves was identified and (2) “absence” where there were no agaves but other plants were present. The object-oriented algorithm was found to have the highest overall accuracy (0.963), followed by the support-vector machine with 0.928 accuracy and the neural network with 0.914. The algorithms with statistical criteria for classification were the least accurate: Mahalanobis distance = 0.752 accuracy and minimum distance = 0.421. We further recommend that the object-oriented algorithm be used, because in addition to having the highest overall accuracy for the image segmentation process, it yields parameters that are useful for estimating the coverage area, size, and shapes, which can aid in better selection of agave individuals for harvest.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11356-022-18985-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-11933-0,Flexible neural network for fast and accurate road scene perception,Multimedia Tools and Applications,10.1007/s11042-022-11933-0,Springer,2022-02-01,"Accurate object detection on the road is the most important requirement of autonomous vehicles. Extensive work has been accomplished for car, pedestrian, and cyclist detection; however, comparatively, very few efforts have been put into 2D object detection. In this article, a dynamic approach is investigated to design a perfect unified neural network that could achieve the best results based on our available hardware. The proposed architecture is based on CSPNet for feature extraction in an end-to-end way. The net extracts visual features by using backbone subnet, visual object detection is based on a feature pyramid network (FPN). In order to increase the net flexibility, an auto-anchor generating method is applied to the detection layer that makes the net suitable for any datasets. For fine-tuning the net, activation, optimization, and loss functions are considered along with multiple check points. The proposed net is trained and tested based on the benchmark KITTI dataset. Our extensive experiments show that the proposed model for visual object detection is superior to others, where other nets output very low accuracy for pedestrian and cyclist detection, our proposed model achieves 99.3% recall rate based on our dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-022-11933-0,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12206-022-0105-y,A personalized lane keeping system for autonomous vehicles based on recurrent neural network with temporal dependencies,Journal of Mechanical Science and Technology,10.1007/s12206-022-0105-y,Springer,2022-02-01,This paper presents a personalized lane keeping system for an autonomous vehicle using recurrent neural network (RNN) with long short term memory (LSTM) cell. The proposed algorithm is trained by datasets collected by manual driving of three drivers. The collected driving data is analyzed for the target lane offset and responsiveness to the road curvature of each driver. 178744 and 76605 datasets are used to train and validate the LSTM-RNN based model. An encoder is used to standardize the input feature to improve the accuracy of network training. The proposed lane keeping algorithm for each driver has been evaluated through prediction accuracy analysis and simulation study using MATLAB/Simulink and Carsim. 99.7 % of the prediction error of steering wheel angle was bounded between −0.87 deg to 0.89 deg with mean of 0.01 deg. The simulation results show that the proposed algorithm precisely modeled the lane keeping characteristics of three drivers.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12206-022-0105-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-021-00088-7,God does not play dice but self-driving cars should,AI and Ethics,10.1007/s43681-021-00088-7,Springer,2022-02-01,"Advances and improvements in computing power and processing have led to a clear upward progression in the degree to which autonomous vehicles can operate freely without human involvement. Advances in autonomous vehicle technology may reduce the incidence of vehicle accidents born from human error and would be a general benefit if widely used and properly regulated. However, with increases in machine agency comes the corresponding challenge of machine ethics that must keep pace with the increasing number of decisions autonomous cars need to make. In this paper, I explore and advance a view on how autonomous vehicles ought to respond in a particular tragic choice scenario under a specific set of constraints where any one person needs to die for the sake of many more. I argue that in such cases autonomous vehicles ought to randomly select who to sacrifice and that such random selection ought to be blind to particulars that set people apart from each other, including whether a potential sacrifice is a passenger or owner of the self-driving car in question.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00088-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-11924-1,Robust dual-modal image quality assessment aware deep learning network for traffic targets detection of autonomous vehicles,Multimedia Tools and Applications,10.1007/s11042-022-11924-1,Springer,2022-02-01,"The multi-spectral image pairs composed of LIDAR and RGB images demonstrates more effective detection performance in complex traffic environments, such as low illumination, motion blur and strong noise, etc. However, there is still a lack of relevant research on how to better fuse the two modalities to improve the robustness and detection accuracy of the perception system for autonomous vehicles under the condition of low visible light image quality. In this paper, we proposed a dual-modal image quality aware deep neural network (DMIQADNN). We comprehensively compared and analyzed the adaptions of fusion architectures in the early, middle, late, and score stages. By comprehensively considering the detection accuracy and detection speed, the fusion architecture in the middle stage was selected. Besides, we developed an image quality assessment network (IQAN) to evaluate the image quality score for RGB images. The corresponding fusion weights for RGB sub-network and LIDAR sub-network were adaptively assigned by using the proposed fusion weight assignment function. Then based on the calculated fusion weights, the RGB and LIDAR sub-networks were adaptively merged via a data fusion sub-network. The RGB images in the KITTI dataset were processed by reducing illumination and adding motion blur and Gaussian noises to produce a modified dataset containing 7481 RBG-LIDAR image pairs, and the DNIQADNN was trained and tested by semi-automatic annotation. The experimental results on modified KITTI Benchmark and dataset collected by using our own developed autonomous vehicle validate the robustness and effectiveness of proposed method. The ultimate FPS and AP values of the DNIQADNN reach 27 and 39.1, which are superior to those of the state-of-the-art instance segmentation networks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-022-11924-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-021-03988-x,Automatic lane marking prediction using convolutional neural network and S-Shaped Binary Butterfly Optimization,The Journal of Supercomputing,10.1007/s11227-021-03988-x,Springer,2022-02-01,"Lane detection is a technique that uses geometric features as an input to the autonomous vehicle to automatically distinguish lane markings. To process the intricate features present in the lane images, traditional computer vision (CV) techniques are typically time-consuming, need more computing resources, and use complex algorithms. To address this problem, this paper presents a deep convolutional neural network (CNN) architecture that prevents the complexities of traditional CV techniques. CNN is regarded as a reasonable method for lane marking prediction, while improved performance requires hyperparameter tuning. To enhance the initial parameter setting of the CNN, an S-Shaped Binary Butterfly Optimization Algorithm (SBBOA) is utilized in this paper. In this way, the relative parameters of CNN are selected for accurate lane marking. To evaluate the performance of the proposed SBBOA-CNN model, extensive experiments are conducted using the TUSimple and CULane datasets. The experimental results obtained show that the proposed approach outperforms other state-of-the-art techniques in terms of classification accuracy, precision, F 1-score, and recall. The proposed model also considerably outperforms the CNN in terms of classification accuracy, average elapsed time, and receiver operating characteristics curve measure. This result demonstrates that the SBBOA optimized CNN exhibits higher robustness and stability than CNN.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-021-03988-x,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01568-y,Double Critic Deep Reinforcement Learning for Mapless 3D Navigation of Unmanned Aerial Vehicles,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01568-y,Springer,2022-01-31,"This paper presents a novel deep reinforcement learning-based system for 3D mapless navigation for Unmanned Aerial Vehicles (UAVs). Instead of using an image-based sensing approach, we propose a simple learning system that uses only a few sparse range data from a distance sensor to train a learning agent. We based our approaches on two state-of-art double critics Deep-RL models: Twin Delayed Deep Deterministic Policy Gradient (TD3) and Soft Actor-Critic (SAC). We show that our two approaches manage to outperform an approach based on the Deep Deterministic Policy Gradient (DDPG) technique and the BUG2 algorithm. Also, our new Deep-RL structure based on Recurrent Neural Networks (RNNs) outperforms the current structure used to perform mapless navigation of mobile robots. Overall, we conclude that Deep-RL approaches based on double critic with Recurrent Neural Networks (RNNs) are better suited to perform mapless navigation and obstacle avoidance of UAVs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01568-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-022-01030-2,Implementation of Genetic Algorithm for Path Estimation in Self Driving Car,SN Computer Science,10.1007/s42979-022-01030-2,Nature,2022-01-31,"With the recent advancement in artificial intelligence, autonomous vehicles have been a significant area of reach. Companies like Tesla and Waymo by Google are leading examples in this area. This paper focuses on path allocation and trajectory mapping research by creating the 3D environment and implementing a genetic algorithm. The work presented in this paper has three significant contributions: the first step is to develop a simulation of a real-world environment for self-driving cars using the Unity3D Engine, a real-time creation tool. The second step is to implement genetic algorithms to perform training related to path allocation and obstacle avoidance. In the last step, performance analysis for the algorithm in the simulation environment is described, and the benefits are explored later in this work. The novelty in the approach lies in checkpoints and crash penalties as fitness functions. Moreover, it includes two separate training, one for consistency and one for efficiency. The model was trained for 330 generations with 75 agents of genetic algorithm in both modes of training. The study presented in this work helps to decide the optimal path in the most diminutive time frame for self-driving cars.",https://www.nature.com/articles/s42979-022-01030-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92054-8_5,"Artificial Intelligence: Need, Evolution, and Applications for Transportation Systems",Intelligent Cyber-Physical Systems for Autonomous Transportation,10.1007/978-3-030-92054-8_5,Springer,2022-01-01,"Artificial intelligence (AI) is a concept in which entities and systems have the ability to learning and decision-making by imitating biological processes. In this chapter, we first introduce the evolution of AI to give the reader a good grasp of artificial intelligence (AI) and then introduce the existing machine learning (ML) with three typical classifications: unsupervised learning, supervised learning, and reinforcement learning. Supervised learning makes decision based on the output labels provided in training. Unsupervised learning works based on pattern discovery without having the pre-knowledge of output labels. The third machine learning paradigm is reinforcement learning (RL), which takes sequential actions rooted in Markov Decision Process (MDP) with a rewarding or penalizing criterion. Some other kinds of ML algorithms such as federated learning and transfer learning are also introduced in the first subsection. The future transportation network aims to develop a highly dynamic and intelligent system, which enables the networks to change the environment to satisfy various requirements and service types. Cellular-V2X, vehicular edge network, and unmanned aerial vehicle (UAV) are recently attacking network architecture to enable the future transportation. In the second section, we introduce how to integrate AI into cellular-V2X, vehicular edge network, and UAV. Leveraging AI into transportation helps the sector increase passenger safety, reduce traffic congestion and accidents, lessen carbon emissions, and also minimize the overall financial expenses. Finally, we review some existing research that uses AI to enable autonomous driving, traffic control and prediction, and path planning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92054-8_5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98012-2_63,Application of Lane Navigation and Object Detection in a Deep-Learning Self-driving Car,Advances in Information and Communication,10.1007/978-3-030-98012-2_63,Springer,2022-01-01,"This project develops lane navigation and object detection functions using an RC car and a basic CNN Deep learning algorithm, which shows a great potential for object detection. In addition, it discusses what effects the different dataset size and the presence of obstacles have on the performance through the various case studies. The self-driving car is one of the technologies with the highest potential to become commercialized in the near future, but currently a great technological barrier prevents the existence of fully self-driving cars, allowing for partial self-driving and limited assistance to the driver. When considering this technological trend of self-driving cars, even if this project cannot overcome all of the technical limitations and barriers, it is very significant from a pedagogical aspect by expanding the scope of internship and offering the opportunity to create a practical application.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98012-2_63,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95502-1_30,ReLearner: A Reinforcement Learning-Based Self Driving Car Model Using Gym Environment,Advanced Computing,10.1007/978-3-030-95502-1_30,Springer,2022-01-01,"In the recent past, Artificial intelligence and its sister technology such as Machine Learning, Deep Learning, and Reinforcement learning have grown rapidly in several applications. The self-driving car is one of the applications, which is the need of the hour. In this paper, we describe the trends in autonomous vehicle technology for the self-driving car. There are many different approaches to mathematically formulate a design for the self-driving car such as deep Q-learning, Q-learning, and machine learning. However, in this paper, we propose a very basic and less compute-intensive simplistic self-driving car model called “ReLearner” using the Gym environment. To simulate the self-driving car model, we preferred to create a simple small environment OpenAi gym which is a deterministic environment. The OpenAi gym provides the virtual simulation environment and parameter tuning to train and test the model. We have focused on two methods to test our model. The basic approach is to compare the performance of the car when tested using Q-Learning and another using a random action agent, i.e., No reinforcement learning. We have derived a theoretical model and analyzed how to use Q-learning to train cars to drive. We have carried out a simulation and on evaluating the performance and found that Q-learning is a more optimal approach to solve the issue of a self-driving car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95502-1_30,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91581-0_41,Semantic Image Segmentation as a Tool for Situational Awareness in Unmanned Vehicle Control Tasks,"Advances in Neural Computation, Machine Learning, and Cognitive Research V",10.1007/978-3-030-91581-0_41,Springer,2022-01-01,"We consider in this paper situational awareness formation, which is essential for controlling the behavior of unmanned aerial vehicles (UAVs). We propose an approach to forming one of the elements of situational awareness by identifying objects in the environment and tracking their movements using computer vision tools. The convolutional neural networks, which perform semantic segmentation of the image obtained by UAV video surveillance tools, are used as the primary tool for solving these tasks. Several architectures of such networks are compared, and a comparative analysis of their effectiveness from the problem’s point of view is performed. Finally, as a demonstration example, the task of selecting a site in unfamiliar terrain for landing the UAV, satisfying the conditions of safety of performance of this operation is considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91581-0_41,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90639-9_58,End-to-End Deep Learning for Autonomous Vehicles Lateral Control Using CNN,Advanced Intelligent Systems for Sustainable Development (AI2SD’2020),10.1007/978-3-030-90639-9_58,Springer,2022-01-01,"Self-driving cars are set to become the main mode of transportation for future generations. They are highly reliable, very safe and always improving as they never stop learning. A key requirement in the development of self-driving cars is steering angle computation for efficient navigation. Steering angle calculation plays an important role in maintaining the vehicle in the center of the road or within the boundary lanes to meet safety critical requirements. In this paper, we trained a convolutional neural network (CNN) with images generated by Udacity self-driving car simulator to drive the car autonomously. Our end-to-end approach was tested on Udacity simulator with different driving scenes with or without lane markings and was found to give the lowest error when compared to the other existing approaches in the literature. An overview of future research direction and applications is also given.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90639-9_58,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97113-7_2,Implementation of Machine Learning Techniques in Unmanned Aerial Vehicle Control and Its Various Applications,Computational Intelligence for Unmanned Aerial Vehicles Communication Networks,10.1007/978-3-030-97113-7_2,Springer,2022-01-01,"An unmanned aerial vehicle (UAV), sometimes known as a drone, is an aircraft or airborne system that is controlled remotely by an onboard computer or a human operator. The ground control station, aircraft components, and various types of sensors make up the UAV system. UAVs are categorized depending on their endurance, weight and altitude range. They can be used for multiple commercial and military applications. UAV intelligence and performance entirely depend on their ability to sense and comprehend new and unfamiliar environments and conditions. Numerous Machine Learning (ML) algorithms have recently been developed and implemented in the UAV system for this purpose. The integration of machine learning and unmanned aerial vehicles has resulted in outputs that are both fast and reliable. It will also lessen the number of real-time obstacles that UAVs confront while simultaneously boosting their capabilities. Additionally, it will pave the way for the application of UAVs in a number of different fields. The current chapter discusses in detail machine learning approaches and their integration with unmanned aerial vehicles. Additionally, it discusses the application of UAVs in various domains and their effectiveness.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97113-7_2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-09331-9_10,Application of k-out-of-n:G System and Machine Learning Techniques on Reliability Analysis of Tethered Unmanned Aerial Vehicle,Information Technologies and Mathematical Modelling. Queueing Theory and Applications,10.1007/978-3-031-09331-9_10,Springer,2022-01-01,"The purpose of the article is to investigate the reliability of an unmanned high-altitude module based on a mathematical model of the k -out-of- n :G system. An analytical model of the k -out-of- n :G system under two system failure scenarios is considered. In the first case, the system failure occurs after $$(n - k + 1)$$ ( n - k + 1 ) elements failure. The second one examines the system failure depending on the location of the failed elements. The sensitivity analysis of system reliability characteristics to the shape of the lifetime distribution function of the components has been carried out. The impact of the coefficient of variation of the system elements lifetime on its operating probability without failure is investigated. Several machine learning methods are used to calculate reliability characteristics for arbitrary input data based on practically significant parameters. The accuracy of the trained models is expressed in terms of estimated mean values.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-09331-9_10,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91581-0_35,Real-Time Approach to Neural Network-Based Disparity Map Generation from Stereo Images,"Advances in Neural Computation, Machine Learning, and Cognitive Research V",10.1007/978-3-030-91581-0_35,Springer,2022-01-01,"Generating depth maps using mono- or stereo- images is a topic of active research. This paper is dedicated to study of different methods of depth and disparity maps generating. It includes analysis of existing methods of depth maps generating and investigation and improvement of the real-time neural-network based method AnyNet. Our approach AnyNet-M related to the models which are make prediction stage-by-stage and increase quality of disparity estimation over time. Firstly, proposed method was tested on KITTI Stereo Dataset and custom OpenTaganrog dataset with images of 1242 × 375 resolution. The method was proved to be real-time with approximately 38 FPS using one TeslaV100 GPU. Secondly, quality of proposed model was tested and reached 5% of Average 3-Pixel Error on KITTI dataset. Finally, it was integrated to Robotic operation system for further use as part of the navigation systems of unmanned vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91581-0_35,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-11633-9_23,Self Driving Car in a Constrained Environment,"Computer, Communication, and Signal Processing",10.1007/978-3-031-11633-9_23,Springer,2022-01-01,"The purpose of the research is to build a machine learning model which can drive a car on the tracks of Udacity’s Car simulator without any human intervention. This is achieved by mimicking the human driving behaviour in the training mode on a track. A dataset is generated by the simulator based on the human driving behaviour in the training mode and a deep learning model is built using this dataset which is then used to drive the car autonomously on any unseen track. Initially the model performed well only on the already seen track and failed to perform well on new unseen tracks. The simulator track in which the car was trained with didn’t consist of any sharp turns or elevations or any other road barriers, but the real world tracks do contain them, so in order to overcome this problem image processing techniques like zooming, changing brightness, flipping images, panning were used and in order to avoid over-fitting problem more dataset was generated using data augmentation techniques. Finally a model was built which was able to generalise the tracks and drive the car autonomously on the unseen track of the simulator.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-11633-9_23,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4597-3_80,Rain Classification for Autonomous Vehicle Navigation Using Machine Learning,Recent Trends in Mechatronics Towards Industry 4.0,10.1007/978-981-33-4597-3_80,Springer,2022-01-01,"Autonomous vehicles (AV) has gained popularity in research and development in many countries due to the advancement of sensor technology that is used in the AV system. Despite that, sensing and perceiving in harsh weather conditions has been an issue in this modern sensor technology as it needs the ability to adapt to human behaviour in various situations. This paper aims to classify clear and rainy weather using a physical-based simulator to imitate the real-world environment which consists of roads, vehicles, and buildings. The real-world environment was constructed in a physical-based simulator to publish the data logging and testing using the ROS network. Point cloud data generated from LiDAR with a different frame of different weather are to be coupled with three machine learning models namely Naïve Bayes (NB), Random Forest (RF), and k-Nearest Neighbour (kNN) as classifiers. The preliminary analysis demonstrated that with the proposed methodology, the RF machine learning model attained a test classification accuracy (CA) of 99.9% on the test dataset, followed by kNN with a test CA of 99.4% and NB at 92.4%. Therefore, the proposed strategy has the potential to classify clear and rainy weather that provides objective-based judgement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4597-3_80,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9492-9_318,Trajectory-Predicting Network: A Deep Learning Method Enhancing Feasibility of Path Planning,Proceedings of 2021 International Conference on Autonomous Unmanned Systems (ICAUS 2021),10.1007/978-981-16-9492-9_318,Springer,2022-01-01,"Feasibility of planned path represents the viability and accuracy for unmanned aerial vehicles (UAVs) to track. It is a bridge between UAV path planning and tracking, and also an important guarantee for the safe and efficient completion of the mission of UAV. At present, most researchers only take account of the simplified model and UAV state constraints when considering the path planning, but do not further consider the dynamics constraints of the UAV itself and the performance of the designed path tracking controller, which results in a certain distance error between the planned path and the actual trajectory. When UAVs perform missions in complex and dense areas, the actual trajectory generated by the planned path command even collides with obstacles, which is difficult to guarantee mission safety. This paper proposes a trajectory-predicting network (TPN) based on the deep learning, which characterize the complex nonlinear relation between the planning command and the actual trajectory considering nonlinear model and controller of the closed-loop system. In time of path planning, the predicted trajectory obtained by TPN corresponding to the planning command is evaluated to find the optimal planning command. The optimal trajectory is regarded as a planning path, and its corresponding command as path tracking control input of the control system. Simulation results verify the viability and effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9492-9_318,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-07012-9_29,Deep Learning Application of Image Recognition Based on Self-driving Vehicle,Emerging Technologies in Computer Engineering: Cognitive Computing and Intelligent IoT,10.1007/978-3-031-07012-9_29,Springer,2022-01-01,"A CNN (Convolutional Neural Network) is an artificial neural network used to evaluate visual pictures. It is used for visual image processing and is categorised as a deep neural network in deep learning. So, using real-time image processing, an AI autonomous driving model was built using a road crossing picture as an impediment. Based on the CNN model, we created a low-cost approach that can realistically perform autonomous driving. An end-to-end model is applied to the most widely used deep neural network technology for autonomous driving. It was shown that viable lane identification and maintaining techniques may be used to train and self-drive on a virtual road.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-07012-9_29,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4177-0_26,Smart UAV Framework for Multi-Assistance,ICT with Intelligent Applications,10.1007/978-981-16-4177-0_26,Springer,2022-01-01,"Unmanned aerial vehicles, which are also familiar as drones, play an important role in military and national emergency. Our motive in this project is to present the real-time possibilities of using UAVs in rescue operations. UAVs can be practically used to transport goods on demand, provide medical support in urban areas, save people stuck during floods, analyze the scale of damages, monitor large performance inspection activities, human gatherings, ORS, deliver food and other necessary material, supply automated external defibrillators, support rescue operations and for emergency transport activities.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4177-0_26,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93247-3_5,Efficient Traffic Signs Recognition Based on CNN Model for Self-Driving Cars,Intelligent Computing & Optimization,10.1007/978-3-030-93247-3_5,Springer,2022-01-01,"Self-Driving Cars or Autonomous Cars provide many benefits for humanity, such as reduction of deaths and injuries in road accidents, reduction of air pollution, increasing the quality of car control. For this purpose, some cameras or sensors are placed on the car, and an efficient control system must be set up, this system allows to receive images from different cameras and/or sensors in real-time especially those representing traffic signs, and process them to allows high autonomous control and driving of the car. Among the most promising algorithms used in this field, we find convolutional neural networks CNN. In the present work, we have proposed a CNN model composed of many convolutional layers, max-pooling layers, and fully connected layers. As programming tools, we have used python, Tensorflow, and Keras which are currently the most used in the field.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93247-3_5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1866-6_42,Obstacle Avoidance and Ranging Using LIDAR,Mobile Computing and Sustainable Informatics,10.1007/978-981-16-1866-6_42,Springer,2022-01-01,"For many years, engineers are searching solutions for car accidents that are caused by human error due to drowsiness or by a person who comes out of nowhere in front of the vehicle. In such a situation, vehicle accident may occur. So, there is a need to develop a vehicle that saves human life from a dangerous accident. Autonomous vehicle have emerged with cameras and sensors to avoid the strategic accidents of human error. Autonomous vehicle systems get information about other vehicles, pedestrians, and other immediate surroundings that is necessary to detect the presence of pedestrians, vehicles and other related entity objects. In this paper, novel LIDAR technologies for automotive applications and the perception algorithms based on field of view (FOV) are used for obstacle avoidance, and ranging of object or vehicle nearby to avoid collision of data in crucial conditions is discussed. This paper is structured based on a vehicle detection and processing of 2D LIDAR sensor to avoid traffic accidents and save life of the people with the help of deep learning algorithm concept. The LIDAR serves as image sensor, and the output response is a steering response, based on the image decisions taken either stop or turn the vehicle depending on the object in front of the vehicle based on road boundary detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1866-6_42,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-84760-9_55,Traffic Sign Detection and Recognition for Hazy Images: ADAS,Second International Conference on Image Processing and Capsule Networks,10.1007/978-3-030-84760-9_55,Springer,2022-01-01,"Self driving cars are picking up pace and thus serves as a challenging research domain. One of the most crucial functions in an autonomous vehicle is accurately detecting and recognising the traffic signs. Traffic sign detection is a crucial task in traffic sign recognition systems. Deep neural networks are proven powerful in traffic sign classification. As traffic sign violation leads to law and order disruption, posing a threat to human life, there is a need for robust algorithms with efficient actuation to perform the delegated task. Thus, this paper proposes a robust algorithm which addresses challenges like haze, fog, unclear images due to improper condition of roads to efficiently detect and recognize traffic signs using Image manipulation, Optical Character Recognition (OCR) algorithm and You Only Look Once (YOLOv3) detection algorithm. The proposed algorithm in this paper for hazy images that aids in ADAS applications has an accuracy of 87.29%. This contributes to the emerging research domains of autonomous vehicles and self-driving cars.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-84760-9_55,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97113-7_11,Investigation on Challenges of Big Data Analytics in UAV Surveillance,Computational Intelligence for Unmanned Aerial Vehicles Communication Networks,10.1007/978-3-030-97113-7_11,Springer,2022-01-01,"In today’s world, there is a tremendous need for UAV surveillance to maintain safety and security purposes. The abbreviation for UAV is an Unmanned Aerial Vehicle, which is frequently known as drones. A drone is an airship without any human being pilot. UAVs are a component of unmanned airship systems (UAS), that includes an additional ground-based controller. Initially, UAV has developed the De Havilland DH. 82B Queen Bee airship, which is applied for a low-price radio-controlled drone. This chapter mainly focuses on applications of drones, the significance of big data in UAV surveillance, challenges of big data in UAV surveillance, conclusion, and Future work of UAV surveillance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97113-7_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93479-8_16,Connected Autonomous Vehicle Platoon Control Through Multi-agent Deep Reinforcement Learning,"Broadband Communications, Networks, and Systems",10.1007/978-3-030-93479-8_16,Springer,2022-01-01,"The rise of the artificial intelligence (AI) brings golden opportunity to accelerate the development of the intelligent transportation system (ITS). The platoon control of connected autonomous vehicle (CAV) as the key technology exhibits superior for improving traffic system. However, there still exist some challenges in multi-objective platoon control and multi-agent interaction. Therefore, this paper proposed a connected autonomous vehicle latoon control approach with multi-agent deep reinforcement learning (MADRL). Finally, the results in stochastic mixed traffic flow based on SUMO (simulation of urban mobility) platform demonstrate that the proposed method is feasible, effective and advanced.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93479-8_16,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-79766-9_1,Security Challenges in 5G and IoT Networks: A Review,Secure Communication for 5G and IoT Networks,10.1007/978-3-030-79766-9_1,Springer,2022-01-01,"5G networks are poised to satisfy the anticipated growth in Internet of Technology (IoT) devices and their related systems. The invasion of 5G networks brings along with it an accelerated need for security and privacy. The need for tailor-made security solutions has become the need of the hour to ensure data integrity, confidentiality, and authentication in 5G-based IoT networks. Since IoT initiates sensors and actuators in a totally smart environment, IoT security will involve protecting the total deployment architecture of IoT from internal and external attacks. Integration of cryptographical algorithms and quantum cryptography has been used effectively to secure data in 5G networks. Privacy and identity management has been a mandatory requirement in networks carrying delicate data involved in retail shops, traffic services, and health monitoring systems. Securing data in 5G and IoT networks and detection of trustworthy and rogue nodes, proper monitoring, logging, and broadcasting are the vital necessities of any security system. The exhaustive survey on the security issues in the 5G-IoT scenario, highlights the application of the latest technologies, incorporation of hybrid methodologies in securing them, and also emphasizes on the open issues yet to be addressed and research challenges that are to be explored.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79766-9_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-8052-6_12,Implementation of Traffic Sign Recognition System on Raspberry Pi,Frontier Computing,10.1007/978-981-16-8052-6_12,Springer,2022-01-01,"In this paper we intent to design and develop an intelligent traffic sign recognition system on Raspberry Pi. In the real situation, we could find the fact that drivers are often drive the car tiredly and cause dangerous situation. In order to avoid the dangerous accidents, automatic drive applications are appeared to assist drivers. However, the automatic driving car does not recognize the traffic sign correctly in real-time and depend on non-real time traffic sign information so that the dangerous accidents are appeared. So, in this paper we will implement a system that have recognition mechanism based on deep learning to distinguish the traffic signs. With the developing application, we would not depend on the map updating frequently to know the traffic sign situation. This mechanism also helps drivers to have secure driving behavior. On the other hand, we also design a prototype of automatic car based on Raspberry pi development board to evaluate our proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-8052-6_12,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-10525-8_29,An Evaluation of Autonomous Car Simulators and Their Applicability for Supervised and Reinforcement Learning,Intelligent Technologies and Applications,10.1007/978-3-031-10525-8_29,Springer,2022-01-01,"Recent advancements in the field of Machine Learning have sprouted a renewed interest in the area of autonomous cars. Companies use different techniques to develop autonomous cars, including buying several vehicles to develop Advanced Driver Assistance Systems (ADAS), while others use car simulators. Simulators for autonomous cars include a wide variety of different sensors. Some simulators come free or even open-source, while others require to pay for the simulator itself, server time, or each sensor. The quality and focus of each of these vary, with some having LIDAR scanned roads for highly realistic roads, while others have entirely natural and realistic vehicle dynamics. This paper gives an overview of available simulators for supervised and reinforcement learning as well as their use cases.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-10525-8_29,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87178-9_5,Neural Network Adaptation of the Kalman Filter for Odometry Fusion,Proceedings of the Fifth International Scientific Conference “Intelligent Information Technologies for Industry” (IITI’21),10.1007/978-3-030-87178-9_5,Springer,2022-01-01,"In navigation systems for unmanned vehicles, an important task is fusion of the pose estimations (odometry and localization) obtained from different sensors: cameras, LiDARs, wheel encoders, inertial measurement modules, etc. To solve this task, it is necessary to know the covariance matrices for each of the odometry sources, which characterize the prediction accuracy of the corresponding pose. In this paper we propose a neural network adaptation of noise covariances in Kalman filter for odometry fusion task. Instead of specifying process and measurement noise covariances manually, we use optimization technique and neural network on input time series data to automatically predict values of these covariance matrices. Our approach fuses the vehicle 3D position and orientation obtained using visual and LiDAR-based methods for simultaneously localization and mapping. The experiments were conducted on a dataset from unmanned ground robot Clearpath Husky. Comparing to Kalman filter without adaptation, our method is more precise. We made a software implementation of the proposed approach based on PyTorch deep learning framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87178-9_5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-8484-5_9,The Future of Car Automation Field with Smart Driverless Technologies,Computational Intelligence in Machine Learning,10.1007/978-981-16-8484-5_9,Springer,2022-01-01,"This study investigates the challenges and opportunities particularly in current transportation policies that may arise to change existing mobility systems with the help of intelligent autonomous vehicle (IAV) technologies. India is already one of the highest levels of population, so all this leading to a massive increase in road traffic which leads to serious issues such as permanent traffic jams increased air pollution at harmful levels, accidents, or even human losses. Hence, technology and transportation infrastructure providers are needed to provide safer, large scalable, better flexible, and low-cost effective solutions to all these problems. This paper provides a comprehensive review of the relevant literature and explores intelligent transportation systems (ITS) which is one of the best solutions, and this offers traffic monitoring, guidance, or alerting by communication capabilities in between vehicles to avoid any accidents in terms of safety elements (Litman in Autonomous vehicle implementation predictions implications for transport planning, 2018; Pino et al. in IEEE Access 6:17527–17532, 2018; Bagloee et al. in J Mod Transp 24(4):284–303, 2016; Aazam et al. in IEEE Commun Mag, 2018 (in press); Gong et al. in IEEE Trans Intell Transp Syst 19:390–401, 2017; Miettinen in Evolutionary algorithms in engineering and computer science: recent advances in genetic algorithms, evolution strategies, evolutionary programming, GE. Wiley, New York, 1999; Making Innov E-J, makingofinnovation.com, Oct 2015; Campioni et al. in IEEE Trans Veh Technol J Latex Class Files 14(8), 2015; El Zoghby et al. in IEEE 68(2) ITVTAB, 2019; IEEE International symposium on technology in society (ISTAS) proceedings, 2015; NCSL—National conference of state legislatures, database on autonomous vehicles legislation; Cai et al. in An empirical air-to-ground channel model based on passive measurements in LTE, 1140; Qin et al. in IEEE Trans Veh Technol; Meng et al. in IEEE Trans Control Syst Technol 25:1480–1487, 2017; Zeng et al. in Joint communication and control for wireless autonomous vehicular platoon systems. CoRR, 2018) [ 1 – 15 ]. So it is important to do the improvement in new vehicular automation methods. It must have its organizations, specialists, and foundations to the center for their safe and successive journey under enhancing street security and traveling comfort which is the prime need of nowadays (Lian et al. in Channel models a non-stationary 3-D wideband GBSM for HAP-MIMO communication systems, 1128; Du et al. in Resource allocation in vehicular networks based on dual-side cost minimization, 1079; Gonzalez-Martín et al. in Analytical models of the performance of C-V2X mode 4 vehicular communications, 1155; Wei et al. in IEEE Trans Veh Technol; Wang et al. in Optimizing content dissemination for real-time traffic management in large-scale internet of vehicle systems, 1093; Jo et al. in Image-to-image learning to predict traffic speeds by considering area-wide spatio-temporal dependencies; Vehicle automation IEEE 2019: collision avoidance intelligent vehicles system vehicle-to-everything; Du et al. in Design and assessment of an electric vehicle power train model based on real-world driving and charging cycles, 1178; Peng et al. in Connected vehicle series vehicular communications: a network layer perspective, 1064; Wei et al. in An integrated longitudinal and lateral vehicle following control system with radar and vehicle-to-vehicle communication, 1116) [ 16 – 25 ]. All over the world, currently automobile manufacturers are mainly focusing on developing, exhibiting, producing, and promoting new vehicle features with advance controlled strategies that could make possible the exchange of information with self-organized robotics and try to interfaces with new algorithms into the smart automobile world (Self-driving cars: the next revolution kpmg.com | cargroup.org CAR (car centre for automotive research); Hasan et al. in IEEE Access 6:20371–20389, 2018; Guerrero-ibanez et al. in IEEE Wirel Commun 22:122–128, 2015; Li et al. in IEEE Trans Veh Technol, 2017; Abdelhamid et al. in IEEE Trans Intell Transp Syst 99:1–14, 2017; Jo et al. in Image-to-image learning to predict traffic speeds by considering area-wide spatio-temporal dependencies, 1188; Tan and Hu in IEEE Trans Veh Technol; Garcia-Garcia et al. in Appl Soft Comput 70:41–65, 2018; Xiao et al. in Inf Sci 432:543–558, 2018; Favarò et al. in Presented at PSAM Topical 2017 on human reliability, quantitative human factors, and risk management, Munich, Germany, 7th–9th June 2017) [ 26 – 35 ]. The vision of this paper is to provide a multimodal transportation system that could overview all the recent research work in the field of interconnected transportation environment giving help to millions of vehicles that are facing traffic problems and safety issues. To this end, we propose smart automated connected vehicles with the help of intelligent transport systems (ITS) and can provide various application services to improve the safety, efficiency, reliability, and comfort of the driving system (Autonomous cars: past, present and future—a review of the developments in the last century, the present scenario and the expected future of autonomous vehicle technology, Jan 2015 with 15,903; Autonomous vehicles UF: automated guided vehicles autonomous cars autonomous driving autonomous trucks unmanned autonomous vehicle BT: autonomous systems intelligent vehicles RT: artificial intelligence mechatronics multi-agent systems vehicular automation NT: unmanned autonomous vehicles, by The Institute of Electrical and Electronics Engineers (IEEE), 2019; Int J Inf Commun Comput Technol, Jagan Institute of Management Studies, New Delhi Article, Jan 2016; Proceedings of 2014 RAECS UIET, Panjab University Chandigarh, 06–08 Mar 2014; Future Internet J, Published: 24 Jan 2019; Martin-Vega et al. in IEEE Trans Veh Technol 67:3069–3084, 2018; Bazzi et al. in IEEE Trans Wirel Commun 17:2402–2416, 2018; Noor-A-Rahim et al. in IEEE Access 6:23786–23799, 2018;Technical report, IEEE, Piscataway, NJ, USA, 2006; Bazzi et al. in IEEE Access 6:71685–71698, 2018) [ 36 – 45 ].",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-8484-5_9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-10986-7_32,Designing a Model of Driving Scenarios for Autonomous Vehicles,"Knowledge Science, Engineering and Management",10.1007/978-3-031-10986-7_32,Springer,2022-01-01,"Advanced Driver Assistance Systems (ADAS) must undergo an extensive testing before they are put into production. But, testing on real vehicles is long, expensive, difficult to replicate and risky. In the future, it will always be necessary to use real vehicles for testing. But, this is not enough to meet all the requirements of reliability and safety. The self-driving will continue to make driving easier and safer. Nevertheless, the final question remains: what is the best evaluation method that will be able to verify the expected behavior and performance of the on-board systems in smart and autonomous cars? To do this, this article proposes several solutions, distributed in three parts. The first part “object detection architecture” depicts an approach for object detection based on YOLO with a good accuracy. The second “Lane detection architecture” is dedicated to detailed detection approach guidelines based on OpenCV. The last and third part “Traffic sign architecture” is dedicated to a detailed ConvNet approach to detection of signs based on CNN formed at OpenCV using the reverse propagation method. We achieved remarkable results, a real-time detection accuracy of 99.98%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-10986-7_32,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97004-8_10,Hierarchical Population Game Models of Machine Learning in Control Problems Under Conflict and Uncertainty,Smart Electromechanical Systems,10.1007/978-3-030-97004-8_10,Springer,2022-01-01,"Problem statement : Currently, the Machine Learning Control (MLC) methodology is rapidly developing, using machine learning methods to solve problems of complex dynamic systems control. One of the main paradigms of MLC is the technology of neuroevolutionary synthesis of control and decision-making models, which is considered as a promising means of on-board implementation of intelligent control algorithms for autonomous systems under environmental uncertainty. At the same time, when using the neuroevolutionary approach to solve multi-criteria control problems for dynamic systems under conflict, the following problems arise. First, the problem of training an artificial neural network (ANN) should be formalized in the form of a multi-criteria optimization problem under uncertainty (MOU), for the solution of which it is necessary to use approaches that generalize the well-known principle of guaranteed result of Hermeyer Yu., and take into account the conflict nature of the MOU problem. Secondly, when forming models of dynamic systems neuro-control, the training set has a complex structure and can include components that are themselves sets represented in a continuous form. The need to solve these problems determines the high computational complexity of the task of training the ANN and the need to develop a more efficient computing technology compatible with promising computing architectures, coevolutionary models and methods of distributed computing. Purpose of research : Development, software implementation based on distributed computing and research of the effectiveness of hierarchical population game models of coevolutionary algorithms for solving the ANN training problem, formalized as a MOU problem. Results : A methodics of ANN training based on hierarchical population game models of coevolutionary algorithms for solving the MOU problem using the principles of vector minimax and vector minimax risk is developed. Practical significance : The developed hierarchical population-based game models of coevolutionary training algorithms for ANN can be used in the design of SEMS neural control systems under conflict and environmental uncertainty. The problem of multi-criteria synthesis of an ANN, which is an integral part of a hierarchical neural network ensemble and implements algorithms for optimal robust neurostabilization of an unmanned aerial vehicle in a wide range of changes in environmental conditions, is solved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97004-8_10,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91877-4_147,Towards Automated Detection of Cracked Concrete,Proceedings of the 1st Conference of the European Association on Quality Control of Bridges and Structures,10.1007/978-3-030-91877-4_147,Springer,2022-01-01,"When inspecting bridges, unmanned aerial vehicles or drones can provide eyes that can be used even without traffic closures, which is a significant issue for bridge owners. Their impact on direct and indirect costs can be even more valuable when inspecting high bridges with large spans. If a drone carries high definition lenses with a long focal length that can capture images of cracked concrete from a distance, and if the process of automated detection of cracked concrete can be applied, its scope for monitoring the progress of damaged bridges can be significantly extended. This article presents the concept and some results of a study on using drones for such a purpose. The investigations were initially performed under controlled laboratory conditions to simulate cracks in the reinforced concrete block. The analysis showed that in a photogrammetry 3D model, cracks of 0.2 mm and wider could be measured with reasonable accuracy. Crack detection efficiency was demonstrated on a concrete sample using deep convolutional neural networks, and an 80% accuracy rate was achieved. The validation procedure applied only a small number of real-world images; therefore, its performance, as also stated by other studies, can be additionally improved when a larger dataset is considered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91877-4_147,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92022-7_9,"Innovative Digital Technologies to Monitor and Control Pest and Disease Threats in Root, Tuber, and Banana (RT&B) Cropping Systems: Progress and Prospects","Root, Tuber and Banana Food System Innovations",10.1007/978-3-030-92022-7_9,Springer,2022-01-01,"This chapter provides the first comprehensive review of digital tools and technologies available for the identification, monitoring, and control of pests and diseases, with an emphasis on root, tuber, and banana (RT&B) crops. These tools include systems based on identification keys, human and artificial intelligence-based identification based on smart applications, web interfaces, short messages services (SMS), or combinations thereof. We also present ideas on the use of image recognition from smartphones or unmanned aerial vehicles (UAVs) for pest and disease monitoring and data processing for modeling, predictions, and forecasting regarding climate change. These topics will be presented in the context of their current development and future potential but also the challenges, limitations, and innovative approaches taken to reach end users, particularly smallholder farmers, and achieve impacts at scale. Finally, the scope and limitation of private sector involvement demonstrates the need of publicly funded initiatives to maximize sharing of data and resources to ensure sustainability of unbiased advice to farmers through information and communication technology (ICT) systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92022-7_9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8155-7_108,Reinforcement Learning Based Robust Attitude Control of a Tilt Trirotor Unmanned Aerial Vehicle,"Advances in Guidance, Navigation and Control",10.1007/978-981-15-8155-7_108,Springer,2022-01-01,"A new control structure is proposed to solve the problem of the attitude stabilization of a tilt trirotor unmanned aerial vehicle (UAV) with the effects of the modeling uncertainties and external disturbances. An actor-critic (AC) networks structure is introduced to deal with the modeling uncertainties of the tilt trirotor UAV. To restrain the external disturbances, the sliding mode controller (SMC) is utilized. Then the stability analysis is included based on Lyapunov methodology to verify the fact that the attitude states converge to the equilibrium points asymptotically. In the final part, numerical simulation is conducted and the performance of the control structure is validated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8155-7_108,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-2027-1_7,UAV Multispectral Remote Sensing for Yellow Rust Mapping: Opportunities and Challenges,Unmanned Aerial Systems in Precision Agriculture,10.1007/978-981-19-2027-1_7,Springer,2022-01-01,"Wheat is threatened by various crop stresses in its life-cycle, where yellow rust is a severe disease significantly impacting wheat yield. This work aims to investigate the use of Unmanned Aerial Vehicle based multispectral remote sensing for winter wheat stress mapping caused by yellow rust disease. A simple unsupervised wheat yellow rust mapping framework is initially proposed by integrating Spectral Vegetation Indices generation, mutual information analysis and Otsu’s thresholding. A field experiment is carefully designed by infecting winter wheat with different levels of yellow rust inoculum, where UAV multispectral images are collected at the diseased stage with visible symptoms. Experimental results on the labelled dataset initially show the effectiveness of the proposed unsupervised framework for yellow rust disease mapping. Limitations of the proposed algorithm and challenges of yellow rust detection for real-life applications are also discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-2027-1_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92054-8_2,Future Autonomous Transportation: Challenges and Prospective Dimensions,Intelligent Cyber-Physical Systems for Autonomous Transportation,10.1007/978-3-030-92054-8_2,Springer,2022-01-01,"Transportation is an integral and fundamental part of human beings’ lives. On Earth, we need transportation in the form of cars, buses, trains, etc. We need aircraft in the air and ships at sea for long-distance transportation. We need space shuttles in space to travel beyond the air. The main desire of human beings is to complete tasks with less energy, effort, time, and more security. The whole paradigm of humanity’s lifestyle can be shifted by autonomous transport (AT), which is already deployed in different technologically advanced countries. The Autonomous Transport System (ATS) is more secure and reliable than the current system of conventional transportation. With the aid of machine learning (ML), artificial intelligence (AI), and blockchain technologies, ultra-fast processing computers can make autonomous vehicles smarter, safer, and more secure than ever before. Connecting vehicles can communicate with the infrastructure to alert the driver about events such as when a train is coming, when a driver cannot see or hear the approaching train, etc. ATS can have a tremendous effect on all we do. However, there are certain challenges involved with every technology, and once we overcome these problems, these ATS can make life simpler, smarter, and safer. Furthermore, we discuss the challenges and future directions for the ATS.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92054-8_2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-7220-0_10,Autonomous Navigation of Drones Using Reinforcement Learning,Advances in Augmented Reality and Virtual Reality,10.1007/978-981-16-7220-0_10,Springer,2022-01-01,"An UAV is a small hovering machine that can be remotely guided or flown autonomously through software-controlled flight plans in its embedded systems, operating in combination with onboard sensors and GPS. UAVs have demonstrated their versatility during the COVID-19 pandemic. Medicines and personal protection equipment were airlifted to the remote locations using UAVs. In future, transportation of drugs using UAV will be cost-effective and efficient. However, using human resources to operate these UAVs need a lot of time and investment in training. Most UAVs use GPS technology to travel to their destination from the start point. Many UAVs in the airspace generate a need for a drone traffic management system to mitigate collision risk. The drone traffic management system again demands human experts and massive expenditures. To overlook this challenge, we propose to model UAVs’ autonomous navigation using the already available infrastructures present in highways like bike lanes and walking lanes. This research suggests a framework by using reinforcement learning and GPS way-points to allow the UAV to operate successfully from the origin location to the end location by following the bike lanes present on the roads.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7220-0_10,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97774-0_38,Multi-agent Computation Offloading in UAV Assisted MEC via Deep Reinforcement Learning,Smart Computing and Communication,10.1007/978-3-030-97774-0_38,Springer,2022-01-01,"Due to its high maneuverability and flexibility, there have been a growing popularity to adopt Unmanned Aerial Vehicles (UAVs) on Mobile Edge Computing (MEC), serving as edge platforms in infrastructure- unavailable scenarios, e.g., disaster rescue, field operation. Owing to the weak workload, UAVs are typically equipped with limited computing and energy resources. Hence, it is crucial to design efficient edge computation offloading algorithms which could achieve high edge computing performance while keeping low energy consumption. A variety of UAV assisted computation offloading algorithms have been proposed, most of which focus on the scheduling of computation offloading in a centralized way and could become infeasible when the network size increases greatly. To address the issue, we propose a semi-distributed computation offloading framework based on Multi-Agent Twin Delayed (MATD3) deep deterministic policy gradient to minimize the average system cost of the MEC network. We adopt the actor-critic reinforcement learning framework to learn an offloading decision model for each User Equipment (UE), so that each UE could make near-optimal computation offloading decisions by its own and does not suffer from the booming of the network size. Extensive experiments are carried out via numerical simulation and the experimental results verify the effectiveness of the proposed algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97774-0_38,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-021-11437-3,Deep reinforcement learning based control for Autonomous Vehicles in CARLA,Multimedia Tools and Applications,10.1007/s11042-021-11437-3,Springer,2022-01-01,"Nowadays, Artificial Intelligence (AI) is growing by leaps and bounds in almost all fields of technology, and Autonomous Vehicles (AV) research is one more of them. This paper proposes the using of algorithms based on Deep Learning (DL) in the control layer of an autonomous vehicle. More specifically, Deep Reinforcement Learning (DRL) algorithms such as Deep Q-Network (DQN) and Deep Deterministic Policy Gradient (DDPG) are implemented in order to compare results between them. The aim of this work is to obtain a trained model, applying a DRL algorithm, able of sending control commands to the vehicle to navigate properly and efficiently following a determined route. In addition, for each of the algorithms, several agents are presented as a solution, so that each of these agents uses different data sources to achieve the vehicle control commands. For this purpose, an open-source simulator such as CARLA is used, providing to the system with the ability to perform a multitude of tests without any risk into an hyper-realistic urban simulation environment, something that is unthinkable in the real world. The results obtained show that both DQN and DDPG reach the goal, but DDPG obtains a better performance. DDPG perfoms trajectories very similar to classic controller as LQR. In both cases RMSE is lower than 0.1m following trajectories with a range 180-700m. To conclude, some conclusions and future works are commented.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-021-11437-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-05230-9_79,Object Detection and Reinforcement Learning Approach for Intelligent Control of UAV,"New Technologies, Development and Application V",10.1007/978-3-031-05230-9_79,Springer,2022-01-01,"In recent years, the development of deep learning models that can generate more accurate predictions and operate in real-time has brought both opportunities and challenges across the various domains of robotic vision. This breakthrough enables researchers to design and deploy more challenging tasks on intelligent mobile robots, which require emphasized abilities of learning and reasoning. In this paper, a new method for intelligent robot control, based on deep learning and reinforcement learning is proposed. The fundamental idea of this work is how the UAV equipped with a monocular camera can learn significant information about the object of interest in the context of its localization and navigation. For such purpose, the object detection system based on Tiny YOLOv2 architecture is employed. Furthermore, bounding box data generated by a convolution neural network is utilized for depth estimation and determining object boundaries. This information has shown how the state-space dimensions can be significantly reduced, which was essential for further implementation of the Q-learning algorithm. In order to test the proposed framework, a model is developed in MATLAB Simulink. The simulation, which covered different scenarios, was carried out on the UAV within the 3D scene rendered by Unreal Engine. The obtained results have demonstrated the applicability of the proposed methodology for depth estimation, gathering information about the object, object-driven navigation, and autonomous localization and navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-05230-9_79,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2406-3_70,Autonomous Lane Navigation: Using Hand-Coded Method and Deep Learning Method,Proceedings of the 12th National Technical Seminar on Unmanned System Technology 2020,10.1007/978-981-16-2406-3_70,Springer,2022-01-01,"Autonomous vehicle is known as a vehicle that requires no or little human decision while in motion because it’s capable of sensing its environment, it has been a continuous field of research and falls under autonomous navigation system (ANS). Autonomous navigation depicts that a vehicle is capable to plot its path and achieve its plan without human interference remote navigation aids are used in the planning process. In this project, the navigation aid is a front-facing camera mounted and images from the camera are used to compute steering commands. This work made use of two methods which are the handcrafted method for lane navigation and the end to end learning scheme developed by Nvidia cooperation to train a model to compute steering command from a front-facing camera. The deep learning model is compared with the handcraft method of computing steering angle. The difference between these two methods is presented in this work as the navigation of a modelled car which navigates through the designed lanes using both methods, the accuracy of the car following the lanes is used to determine the better method for lane navigation. Which turns out to be the end to end learning method for lane navigation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2406-3_70,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4016-2_65,The Mythical or Realistic Implementation of AI-powered Driverless Cars in Africa: A Review of Challenges and Risks,Smart Trends in Computing and Communications,10.1007/978-981-16-4016-2_65,Springer,2022-01-01,"In recent times, African nations have been mostly absent in discussions concerning artificial intelligence (AI)-powered driverless cars. Additionally, it was also discovered that several global surveys and other studies on driverless car acceptance, popularity and confidence excluded Africa. This is in the light of its immense benefits which include the reduction of road accidents, an effectual car-sharing and transport structure and accurate navigation with less consideration of distractions. Therefore, we examined the challenges and risks attendant to the deployment of self-driving cars in a developing region such as Africa. Several challenges were identified, and they include lack of needed infrastructure, absence of law and order, cost, absence of image detection and recognition projects, absence of practical artificial intelligence courseware, need for an advanced AI-based algorithm, weak legal framework and other ethical issues, criminalization, security and privacy and high tendency to cause more unemployment. The paper highlights several risks attendant to such forms of advancement in Africa.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4016-2_65,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97113-7_15,Multi-sensor Fusion Methods for Unmanned Aerial Vehicles to Detect Environment Using Deep Learning Techniques,Computational Intelligence for Unmanned Aerial Vehicles Communication Networks,10.1007/978-3-030-97113-7_15,Springer,2022-01-01,"Sensor fusion is the ability to merge the inputs of multiple sensors like radars and cameras to form a single image of the environment around a vehicle. The output model brings an accurate image since it compares the strengths of the different sensors. Deep learning provides some networks and techniques to avail sensor fusion capability. Deep learning is the branch of Machine learning. Deep learning is based on learning and improving on its own by examining computer algorithms. Sensor fusion is possible through deep learning since sensors need to merge themselves to get a clear and accurate output of the surrounding of a vehicle. In this study, I have put together some techniques of deep learning based sensor fusion for detecting environments around Unmanned Aerial vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97113-7_15,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5429-9_45,Real-time Trajectory Prediction of Unmanned Aircraft Vehicles Based on Gated Recurrent Unit,Green Connected Automated Transportation and Safety,10.1007/978-981-16-5429-9_45,Springer,2022-01-01,"In view of the increasing number of unmanned aircraft vehicles (UAVs) in low altitude airspace, which leads to the increasing difficulty of surveillance, a real-time trajectory prediction method based on the gated recurrent unit (GRU) is proposed. The parameters of the GRU model are determined including the number of hidden layers, the cell sizes of a single hidden layer and the time step. Historical trajectory data are used to train and test the model. The result shows that the mean absolute errors (MAE) of altitude, longitude, and latitude predicted by the GRU model are 0.86 m, 2.85 m, and 3.65 m, respectively. The prediction results of the GRU model are compared with the long and short-term memory (LSTM), the support vector regression (SVR) and the autoregressive integrated moving average model (ARIMA). It is found that the GRU and LSTM outperform the two other models. The LSTM prediction accuracy is slightly higher than that of the GRU model. However, the space complexity of the LSTM model is much larger than that of the GRU model, and its training time is much longer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5429-9_45,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95467-3_38,Deep Learning Detection of GPS Spoofing,"Machine Learning, Optimization, and Data Science",10.1007/978-3-030-95467-3_38,Springer,2022-01-01,"Unmanned aerial vehicles (UAVs) are widely deployed in air navigation, where numerous applications use them for safety-of-life and positioning, navigation, and timing tasks. Consequently, GPS spoofing attacks are more and more frequent. The aim of this work is to enhance GPS systems of UAVs, by providing the ability of detecting and preventing spoofing attacks. The proposed solution is based on a multilayer perceptron neural network, which processes the flight parameters and the GPS signals to generate alarms signalling GPS spoofing attacks. The obtained accuracy lies between 83.23% for TEXBAT dataset and 99.93% for MAVLINK dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95467-3_38,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-9991-7_3,A Deep Learning-Based Detection System of Multi-class Crops and Orchards Using a UAV,"Computer Vision and Machine Learning in Agriculture, Volume 2",10.1007/978-981-16-9991-7_3,Springer,2022-01-01,"Agriculture is vital to the country’s economy. A 70% increase in agricultural consumption is expected by 2050 as the world’s population approaches 9 billion people. However, obtaining this figure is difficult due to weather and natural disasters. Modernizing this field’s technologies can help achieve the desired outcome. Precision agriculture is a type of ICT-based technology that has significantly increased global productivity. Since their introduction in agriculture, unmanned aerial vehicles (UAVs) and other robots have also offered the potential to be used in various PA applications such as health monitoring, yield estimation, and spraying. In this context, a real-time deep learning detection system based on an improved faster-RCNN is proposed to detect multi-class crops and orchards accurately. The proposed framework was implemented and evaluated in two different croplands (garlic and coriander) and two different orchards (loquat and peach). The developed system outperformed its competitors with 91.3% mean average precision (mAP) and a processing time of 0.235 s. Thus, the proposed framework provided an excellent potential to be deployed on autonomous systems (UAVs, robots, etc.) for various PA applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9991-7_3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-92084-5_2,The Technological Revolution: The Rise of Machines,Making the Global Economy Work for Everyone,10.1007/978-3-030-92084-5_2,Springer,2022-01-01,"We are living in the most innovative period in all of human history. On the one hand, the technological and scientific revolution opens up unprecedented opportunities: accelerating human progress, improving the quality of life and overcoming many constraints. From an economic point of view, technology and science can increase productivity and expand the economy generating wealth, relieve humans from heavy and dangerous activities, and increase labour flexibility. On the other hand, some technologies can be used for criminal activities, terrorism, sabotage, restriction of personal freedoms, repression and other ethically controversial objectives. The risks also affect the sustainability of economic growth, the fabric of society and the future of labour, humanity as a whole and its role. Simply witnessing technological development as a mere spectator is not possible. New technologies influence the way we live, think, produce and work. Beyond the technical aspects, they introduce new mental, cultural and strategic models. The upcoming wave of innovation affects everyone. To ride this wave instead of being overwhelmed by it, one must grasp the main innovations and understand how they work and are connected to one another.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-92084-5_2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-85540-6_1,"Human and Machine Trust Considerations, Concerns and Constraints for Lethal Autonomous Weapon Systems (LAWS)","Human Interaction, Emerging Technologies and Future Systems V",10.1007/978-3-030-85540-6_1,Springer,2022-01-01,"Trust and autonomous systems, especially weapon systems, could be the most difficult technological challenge facing defense industries, militaries, politicians, and the public because the algorithms have to be trusted. Furthermore, the operator, the military, defense industry, politicians and the public need to trust the system to also follow ethical and legal rules. This paper briefly describes the trust considerations, concerns and constraints regarding autonomous weapons systems and concludes with a brief description of the current development programs and projects by the various US military services.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-85540-6_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-97113-7_3,Machine Learning Techniques for UAV Trajectory Optimization—A Survey,Computational Intelligence for Unmanned Aerial Vehicles Communication Networks,10.1007/978-3-030-97113-7_3,Springer,2022-01-01,"Unmanned Aerial Vehicles (UAVs), generally known as drone are utilized in various genuine applications like payload conveyance, traffic observing, moving articles in apparently risky climate, and observation. When utilized in mechanical scenery, UAVs can shape a center piece of modern automation alongside IoT gadgets. With regard to the traditional applications, their trend of getting in similar domains is expected to have enhanced outputs, inspite of many new challenges. To meet out the issues in this scenario, the Artificial Intelligence support is needed to play a vital role when UAVs are applied. A deep study is made and presented in this work with a keen study of all Machine Learning techniques utilized for UAV linked changes, for example, channel displaying, asset the board, situating, and security.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97113-7_3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9492-9_176,Improved Model Reference Adaptive Controller with RBF Neural Network Approximation for UAV,Proceedings of 2021 International Conference on Autonomous Unmanned Systems (ICAUS 2021),10.1007/978-981-16-9492-9_176,Springer,2022-01-01,"This paper presents an improved model reference adaptive controller (I-MRAC) with RBF neural network approximation to deal with the model uncertainties, unknown actuator dynamics and input saturation of the unmanned aerial vehicle (UAV). On the one hand, the output of the RBF neural network (NN) is used as the compensator to eliminate the uncertainties of the system. On the other hand, the reference model is modified to deal with the unknown actuator dynamics and input saturation, improve stability and robustness, and prevent the high frequency oscillations. Meanwhile, the stability of the whole closed-loop system is proved by the Lyapunov analysis. The numerical simulation results of UAV attitude control demonstrate the effectiveness of the proposed method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9492-9_176,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-10388-9_25,Deep Learning for Acoustic Pattern Recognition in Wind Turbines Aerial Inspections,Proceedings of the Sixteenth International Conference on Management Science and Engineering Management – Volume 1,10.1007/978-3-031-10388-9_25,Springer,2022-01-01,"Wind turbine maintenance management requires new condition monitoring systems and robust algorithms for fault detection. Acoustic inspection can detect anomalies in rotatory components through the analysis of acoustic data with advanced pattern recognition algorithms. Unmanned Aerial Vehicles can carry large sensors and technologies, being one of the most relevant techniques for non-destructive inspections. This article presents a new approach to analyze the acoustic data acquired by the condition monitoring system developed in previous research studies, formed by an acoustic sensor embedded in an unmanned aerial vehicle. This approach develops different deep learning methods for acoustic signal analysis to detect abnormal patterns. One of the most suitable tools for this purpose is the Recurrent Neural Network, concretely the Long Short-Term Memory neuronal network commonly employed in sound pattern recognition. It is presented a real case study, obtaining a sound pattern classification based on the trained networks achieving 87% accuracy. This methodology aims to develop a future integrated system capable of detecting wind farms anomalies with acoustic datasets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-10388-9_25,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96040-7_45,Lane Detection for Autonomous Vehicle in Hazy Environment with Optimized Deep Learning Techniques,Advanced Network Technologies and Intelligent Computing,10.1007/978-3-030-96040-7_45,Springer,2022-01-01,"In this technological era, the devices are getting more intelligent and smarter with the advent of artificial intelligence and related technologies. The autonomous vehicle is one of the emerging and important example using the same machine intelligence for effective and efficient vehicle driving experience. However to make the working of autonomous vehicle in a smooth and responsive, the accurate lane detection is a crucial aspects and other co-variate like weather condition also place an important role in it. The present work explores lane detection in foggy or hazy environment on time series data of a continuous driving scene. The proposed methodology uses Dark Channel Prior (DCP) to make images un-hazy and this is passed as an input to the proposed hybrid architecture by connecting a convolutional neural network (CNN) architecture with a recurrent neural network architecture (RNN). The model uses Long-Short Term Memory (LSTM) for time-series data analysis as it captures and process the time series data well in advance. In this model, the CNN block first extracts the feature maps from each frame which is given as input of the time series data and after this these feature maps are provided to LSTM to obtain the final prediction. The model also uses dark channel prior (Image enhancing technique) to enhance image in case of foggy or hazy environment and then detecting lane with the help of enhanced images. Finally, the accuracy of the model is shown in terms of standard performance metrics like precision, recall and F1 score.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96040-7_45,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96040-7_45,Lane Detection for Autonomous Vehicle in Hazy Environment with Optimized Deep Learning Techniques,Advanced Network Technologies and Intelligent Computing,10.1007/978-3-030-96040-7_45,Springer,2022-01-01,"In this technological era, the devices are getting more intelligent and smarter with the advent of artificial intelligence and related technologies. The autonomous vehicle is one of the emerging and important example using the same machine intelligence for effective and efficient vehicle driving experience. However to make the working of autonomous vehicle in a smooth and responsive, the accurate lane detection is a crucial aspects and other co-variate like weather condition also place an important role in it. The present work explores lane detection in foggy or hazy environment on time series data of a continuous driving scene. The proposed methodology uses Dark Channel Prior (DCP) to make images un-hazy and this is passed as an input to the proposed hybrid architecture by connecting a convolutional neural network (CNN) architecture with a recurrent neural network architecture (RNN). The model uses Long-Short Term Memory (LSTM) for time-series data analysis as it captures and process the time series data well in advance. In this model, the CNN block first extracts the feature maps from each frame which is given as input of the time series data and after this these feature maps are provided to LSTM to obtain the final prediction. The model also uses dark channel prior (Image enhancing technique) to enhance image in case of foggy or hazy environment and then detecting lane with the help of enhanced images. Finally, the accuracy of the model is shown in terms of standard performance metrics like precision, recall and F1 score.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96040-7_45,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-1292-4_6,UAV Trajectory Optimization and Choice for UAV Placement for Data Collection in Beyond 5G Networks,Intelligent Unmanned Air Vehicles Communications for Public Safety Networks,10.1007/978-981-19-1292-4_6,Springer,2022-01-01,"Unmanned aerial vehicles (UAVs) evolution has shown potential in many applications of wireless communication because of their high coverage, promising rates, and flexible installation. Owing to the drastic increase of this technology, one of the major challenges is the availability of on-board energy levels to UAVs to stay aloft for a prolonged time. Due to their limited on-board energy, many of the UAVs can go down, and as a result, many associated ground users can face coverage issues etc. Considering this problem, in this study, we give an idea of collecting the uplink traffic from these disaster-points (where active UAVs were serving previously) with the objective of minimizing the Age-of-Information (AoI) of the entire network. Specifically, we address the optimum trajectory of a UAV for collecting data so that the timely delivery of information to the destination can be possible, which will ultimately reduce the overall AoI. We use three different kinds of trajectories namely, random trajectory , travelling salesman problem (TSP) -based trajectory, and proposed trajectory . Simulations show that the proposed trajectory outperforms in the scenario, where disaster-points are less. Additionally, unsupervised learning-based UAVs distribution helps in reducing the AoI as compared to Matern type-I hard-core process-based UAVs distribution. Furthermore, the proposed trajectory is computationally less expensive than TSP -based trajectory; thus, it can be viable in many applications, e.g., Internet of Things (IoT).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-1292-4_6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-021-02900-y,Simultaneous detection and tracking using deep learning and integrated channel feature for ambint traffic light recognition,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-021-02900-y,Springer,2022-01-01,"Perceiving the information about ambient traffic lights is an inevitable task for autonomous vehicles. To deal with the issue, this work develops an accurate and fast traffic light recognition strategy for autonomous vehicles by an onboard camera. In this paper, deep learning based detection and object tracking is synthesized to determine the position and color of traffic lights. First, the mechanism of simultaneous detection and tracking is founded, wherein the video reading module, convolutional neural network (CNN) module, integrated channel feature tracking (ICFT) module are run simultaneously. Then, the respective modules of detection and tracking are introduced. CNN model is designed and trained to obtain the position of traffic lights utilized as initial information for tracking. ICFT is applied to continually track the traffic light targets and determine the light color. Finally, the effectiveness of the presented method is validated via comparing with the state of art. Experiments results indicate that the proposed technique can improve the accuracy and speed of recognition. Our contributions are: (1) Establish a mechanism for simultaneous detection and tracking of traffic lights; (2) Carefully design the CNN architecture and ICFT features; (3)The precision and recall rates on traffic lights recognition reached 0.962 and 0.909, respectively, and the recognition speed reached 21.4FPS (GPU: Nvidia Titan Xp).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-021-02900-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-95459-8_30,A Unified Pipeline for 3D Detection and Velocity Estimation of Vehicles,Robotics Research,10.1007/978-3-030-95459-8_30,Springer,2022-01-01,"3D object detection and velocity estimation are useful for situation awareness and decision making for autonomous vehicles. However much of the current research focuses on 2D detection and does not support velocity estimation. In this paper, we propose a unified pipeline that is able to detect vehicles in 3D space and estimate their velocities simultaneously. The pipeline consists of a 2D detection net, a 3D proposal generation process, a fusion net and an association net. The 2D detection net provides initial information for the 3D proposal generation process, which is able to generate high quality 3D box proposals in the point cloud. The fusion net, with inputs from multiple views, classifies and refines the 3D box proposals. The association net tracks the detected vehicles and estimates their velocities based on the 3D information. The pipeline is tested on the KITTI dataset for both 3D detection and tracking tasks. Our algorithm achieves performance for combined detection of 3D objects and estimation of their velocities that is comparable to the state of the art of 3D detection and the state of the art of object tracking. It is the first pipeline that combines these tasks through deep learning framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-95459-8_30,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-9247-5_19,A Multi-frame Lane Detection Method Based on Deep Learning,Cognitive Systems and Information Processing,10.1007/978-981-16-9247-5_19,Springer,2022-01-01,"In recent years, many lane detection methods have been proposed. However, most of them lead to unsatisfactory performance in handling some extreme difficult driving scenes such as shadows, wireless and dark night. Aiming at this problem, a multi-frame lane detection method based on UNET_CLB was proposed. This method introduced multi-frame information of continuous driving scenes for lane detection on the basis of traditional deep learning. Convolutional neural network (CNN) is combined with convolutional long short-term memory network (CONVLSTM) and deep densely connected convolutional networks (DENSE_NET), a deep advanced semantic extraction network was proposed. The experimental results on the public datasets show that this method achieves an F1-score of 92.391% on the TuSimple dataset, and the F1-score on the CULane dataset is up to 13.6% higher than the existing method. The simulation results based on the Webots platform also show that the method proposed in this paper has a good effect on lane detection in wireless, shadow and shadow environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9247-5_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-19-2184-1_1,Role of AI and IoT Techniques in Autonomous Transport Vehicles,AI Enabled IoT for Electrification and Connected Transportation,10.1007/978-981-19-2184-1_1,Springer,2022-01-01,"Artificial Intelligence (AI) is computer technology with enormous possibilities for smart industrial transformation. The Internet of Things (IoT) is the 4:0 revolution industrial idea that comprises a worldwide knowledge gathering and direct maintenance for storage, transmission, sensing, enhanced services, and technology development. The combination of high-speed, durable, low-latency intercoms and AI and IoT contributing to significant the move toward a full-smart independent (AV) transport electrifier that demonstrates how physical and virtual transport information complement one another. This chapter discusses how the recent AI and IoT techniques may help the quest for autonomous transport vehicles. It was demonstrated that 90% of automobile crises are caused by human mistakes, and 10 times the median driver is safer. Autonomous vehicle safety is important and users need an acceptable level of risk 1000 times lower. AVs have some unbelievable benefits such as (i) enhancing the safety of vehicles, (ii) cutting back on accidents, (iii) reducing fuel usage, (iv) opening up drivers’ time and commercial prospects, (v) AVs must, however, utilize vast knowledge from their wearable sensing.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-2184-1_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-97672-9_30,Revisiting Self-supervised Monocular Depth Estimation,Robot Intelligence Technology and Applications 6,10.1007/978-3-030-97672-9_30,Springer,2022-01-01,"Self-supervised learning of depth map prediction and motion estimation from monocular video sequences is of vital importance—since it realizes a broad range of tasks in robotics and autonomous vehicles. A large number of research efforts have enhanced the performance by tackling illumination variation, occlusions, and dynamic objects, to name a few. However, each of those efforts targets individual goals and endures as separate works. Moreover, most of previous works have adopted the same CNN weights for initialization, not reaping recent advances in self-supervised feature learning. Therefore, the need to investigate the inter-dependency of the previous methods and the effect of different initial features remains. To achieve these objectives, we revisit numerous previously proposed self-supervised methods for joint learning of depth and motion, perform a comprehensive empirical study, and unveil multiple crucial insights.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-97672-9_30,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-91892-7_53,Application of MobileNet-SSD Deep Neural Network for Real-Time Object Detection and Lane Tracking on an Autonomous Vehicle,Advances in Asian Mechanism and Machine Science,10.1007/978-3-030-91892-7_53,Springer,2022-01-01,"Recent development in perception of autonomous vehicle is mainly originated by deep learning. To apply in real-time application, the object detector of learning model is required to run on a high-end GPU platform. Therefore, there is always a great challenge to process deep learning algorithm on an embedded system. In this study, we present an application of recent lightweight network, namely MobileNet – SSD, to detect and classify objects of an autonomous vehicle. The vehicle is self-piloted along a lane using an image processing algorithm. We employ the neural network on small power consumption NVIDIA Jetson Nano Development Kit platform. The accuracy of detection is up to 96% at the 42 fps, while the model can archive 26.7 ms timing latency and 74% mAP (mean average precision) via input dataset of 800 Full-HD resolution pictures. The prototype vehicle is capable of upgrading to large-scale autonomous vehicles which are required to work in special conditions such as quarantined or lockdown areas, poisonous and dangerous area, warehouse, factory, airport, etc.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-91892-7_53,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2937-2_14,Enhanced Behavioral Cloning-Based Self-driving Car Using Transfer Learning,"Data Management, Analytics and Innovation",10.1007/978-981-16-2937-2_14,Springer,2022-01-01,"Sumanth, Uppala Punn, Narinder Singh Sonbhadra, Sanjay Kumar Agarwal, Sonali With the growing phase of artificial intelligence and autonomous learning, the self-driving car is one of the promising areas of research and emerging as a center of focus for automobile industries. Behavioral cloning is the process of replicating human behavior via visuomotor policies by means of machine learning algorithms. In recent years, several deep learning-based behavioral cloning approaches have been developed in the context of self-driving cars specifically based on the concept of transfer learning. Concerning the same, the present paper proposes a transfer learning approach using VGG16 architecture, which is fine-tuned by retraining the last block while keeping other blocks as non-trainable. The performance of proposed architecture is further compared with existing NVIDIA’s architecture and its pruned variants (pruned by 22.2 and 33.85% using $$1\times 1$$ 1 × 1 filter to decrease the total number of parameters). Experimental results show that the VGG16 with transfer learning architecture has outperformed other discussed approaches with faster convergence.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2937-2_14,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-98832-6_37,Experience in Design of Artificial Neural Network for Object Detection on Monochromatic Images,System Analysis in Engineering and Control,10.1007/978-3-030-98832-6_37,Springer,2022-01-01,"The paper considers the design of artificial neural networks (ANN) for the detection and classification of vehicles on monochrome images obtained from unmanned aerial vehicles (UAV). The main problem based on the existence of miscellaneous images, which are obtained for various distances and different object profiles. The aim of this paper is an estimation of the efficiency of artificial neural networks as a function of different metrics. A mathematical statement of the problem in the context of binary decision is given. The results were evaluated using simulation in Matlab2020, where images were marked, and a neural network was implemented based on the YOLO technology. The average precision archives 48% in terms of detection and classification of vehicles for various profiles of objects and distance. As a way to improve the accuracy of vehicle detection, it recommends increasing the volume of the training sample. It is advisable to use the entire number of object profiles in order to achieve the upper limit of recognition. As a way to improve the accuracy of vehicle detection, it recommends increasing the volume of the training sample. It is advisable to use the entire number of object profiles in order to achieve the upper limit of recognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-98832-6_37,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3368-3_27,Autonomous Ground Vehicle for Off-the-Road Applications Based on Neural Network,Proceedings of International Conference on Computational Intelligence and Computing,10.1007/978-981-16-3368-3_27,Springer,2022-01-01,"The technology for autonomy in vehicles has a momentous advancement. Autonomous ground vehicles (AGV) for off-the-road applications will aid various sectors of the society such as mining, constructions, forest path maneuvering, and defense. This project demonstrates a working prototype of a 1/10th scale autonomous car that has been developed using a custom neural network model. The prototype uses Raspberry pi-4 as the core processor to compute real-time images collected from the camera as the key input. The results illustrate the optimized capability of path planning for the AGV using the custom convolutional neural network model with data augmentation. This paper summarizes the results derived and compares the accuracy of the steering in AGV which can be translated for off-road applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3368-3_27,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1866-6_8,Advancing e-Government Using Internet of Things,Mobile Computing and Sustainable Informatics,10.1007/978-981-16-1866-6_8,Springer,2022-01-01,"Internet of Things (IoT) is the most revolutionary and attractive technology of today without which it is nearly impossible to imagine the future due to its applications in numerous fields such as smart cities, home automation, wearable devices, etc., and its ability to make human life much easier via integration with other technologies such as cloud computing and artificial intelligence. In this paper, we have conducted a survey on the ways IoT can be utilized in various sectors of an e-Government such as pollution control, health care and voting. We have also described a six-layer IoT-based model for smart agriculture and studied the benefits of using unmanned aerial vehicles in smart agriculture. This paper further introduces the concept of a “smart” government and its realization via integration of fog computing with IoT leading to a Fog-of-Things (FoT) architecture.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1866-6_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94426-1_22,Towards a FOSS Automatic Classification of Defects for Bridges Structural Health Monitoring,Geomatics and Geospatial Technologies,10.1007/978-3-030-94426-1_22,Springer,2022-01-01,"Bridges are among the most important structures of any road network. During their service life, they are subject to deterioration which may reduce their safety and functionality. The detection of bridge damage is necessary for proper maintenance activities. To date, assessing the health status of the bridge and all its elements is carried out by identifying a series of data obtained from visual inspections, which allows the mapping of the deterioration situation of the work and its conservation status. There are, however, situations where visual inspection may be difficult or impossible, especially in critical areas of bridges, such as the ceiling and corners. In this contribution, the authors acquire images using a prototype drone with a low-cost camera mounted upward over the body of the drone. The proposed solution was tested on a bridge in the city of Turin (Italy). The captured data was processed via photogrammetric process using the open-source Micmac solution. Subsequently, a procedure was developed with FOSS tools for the segmentation of the orthophoto of the intrados of the bridge and the automatic classification of some defects found on the analyzed structure. The paper describes the adopted approach showing the effectiveness of the proposed methodology.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94426-1_22,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7996-4_40,Multi-sensor Fusion-Based Object Detection Implemented on ROS,Machine Learning and Autonomous Systems,10.1007/978-981-16-7996-4_40,Springer,2022-01-01,"Mathur, Pranay Kumar, Ravish Jain, Rahul 3D Perception of the environment in real-time is a critical aspect for object detection, obstacle avoidance, and classification in autonomous vehicles. This paper proposes a novel 3D object classifier that can exploit data from a LIDAR, a RADAR, and a monocular camera image after orthogonal projection. To achieve this, a learnable architecture is designed end-to-end, which fuses the detection results from multiple sensor modalities initially and exploits continuous convolution subsequently to achieve the desired levels of accuracy. An adaptive algorithm for prediction in real-time is used to automatically increase weightage to prediction results from a particular sensor modality which aids in keeping accuracy invariant to scene changes. To prevent the bias, we are using a training strategy which provides attention to the specific type of sensor. This strategy is inspired by dropout. The entire algorithm has been implemented on the Robot Operating System to make it easier to deploy and transfer. We have experimentally evaluated our method on the NuScenes dataset.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7996-4_40,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96308-8_60,Deep Residual Network for Autonomous Vehicles Obstacle Avoidance,Intelligent Systems Design and Applications,10.1007/978-3-030-96308-8_60,Springer,2022-01-01,"With the advancement of artificial intelligence and machine learning, autonomous automobiles are emerging as a lucrative subject of study and a source of interest for car companies. This framework contains our research. The fundamental purpose of this research is to propose an obstacle avoidance strategy for self-driving vehicles. We are looking at developing a model for high-quality obstacle avoidance prediction for autonomous cars that is based on images generated by our virtual simulation platform and then utilized with a ResNet50 deep learning technique. The primary challenge for an autonomous car is to move without collision. For autonomous vehicle simulation research, the suggested technique is feasible, efficient, and trustworthy. The performance of the proposed design is then compared to that of current architectures. The experimental results suggest that the ResNet50 design outperforms the other approaches tested.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96308-8_60,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-94102-4_3,Autonomous Vehicle Assisted by Heads up Display (HUD) with Augmented Reality Based on Machine Learning Techniques,Virtual and Augmented Reality for Automobile Industry: Innovation Vision and Applications,10.1007/978-3-030-94102-4_3,Springer,2022-01-01,"The safety in driving is improved and driving workload is minimized, the provided information is understandably and the cognitive load on the driver is low. For the autonomous vehicle, machine learning-based AR-HUD (augmented reality based Head-up display) is used. In this paper the machine learning-based AR-HUD has been used for autonomous vehicles. The process of object detection and collected HUD data classification has been done by the proposed model. Determining the present state of vehicle has been validated based on the AR environment. The process of test and validation is an integral portion of a development cycle. Machine learning and deep neural network are used in this paper for lab & real-world T&V for ARHUD and autonomous vehicles. The results of simulation obtain the data gathered from the implementation of human and machine interface (HMI) to detect the object and to classify the objects in motion. Accuracy, precision, recall and F-1 score are the analyzed parameters for machine learning-based ARHUD. The simulation results obtained are accuracy of 98%, precision 94%, recall 92.3% and F-1 score 86% in comparison with CNN, ANN and SVM.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94102-4_3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-60016-7_50,"Role of Digital Technologies, Robotics, and Augmented Realities",Handbook of Cultural Heritage Analysis,10.1007/978-3-030-60016-7_50,Springer,2022-01-01,"Several examples testify how the evolution in applied technologies to cultural heritage has improved significantly in the last decades in terms of accuracy and reliability of measurement, restitution, and management of the acquired data. This evolution is not always accompanied by the simplification of procedures, lowering of costs, and, more importantly, awareness-raising of the identity value of the investigated asset. In this article, some case studies where different types of technologies have been used are presented together with a recent study of applied robotics in cultural heritage. The aim is to construct an exhaustive picture of the technologies currently in use within the complex conservation process. To follow, a series of urgent reflections are introduced in order to stimulate, contribute, and increase the necessary interdisciplinary and intercultural debate on the issue of safeguarding cultural assets as a driving force for civil progress, paying particular attention to 3D digital survey. Above all, the paper expands the issue to a wider analysis of the general and progressive anthropological transformations produced on human society by the speed of technological innovation. Finally, the paper will attempt to verify how much and what role the identity values expressed by cultural heritage will still exercise on technologically globalized cities and societies of the twenty-first century.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60016-7_50,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-08545-1_43,A Strategy of Potential Fields and Neural Networks in the Control of an Autonomous Vehicle Within Dangerous Environments,Proceedings of the 7th Brazilian Technology Symposium (BTSym’21),10.1007/978-3-031-08545-1_43,Springer,2022-01-01,"This article focuses on the development of an autonomous navigation system by generating real-time 3D maps of different urban environments with different properties within simulation software. This system used the Pioneer 3-DX vehicle, a LiDAR sensor, GPS, and a gyroscope. For the elaboration of the trajectory, the mathematical tool of artificial potential fields was used, which will generate an attractive field to a dynamic goal identified by the robot and repulsive to the obstacles present in the environment, recognized with great precision thanks to the use of a neural network. The topology neural network 8–16–32 was developed using forward propagation, reverse propagation, and gradient descent algorithms. By combining the tools of potential fields and neural networks, a path was traced through which the robotic system will be able to move freely under an off-center point kinematic control algorithm. Finally, a 3D map of the environment was obtained to provide information on the morphology and most outstanding characteristics of the deployment environment to users who use the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-08545-1_43,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3880-0_20,Machine Learning-Based Imaging in Connected Vehicles Environment,Proceedings of 2021 International Conference on Medical Imaging and Computer-Aided Diagnosis (MICAD 2021),10.1007/978-981-16-3880-0_20,Springer,2022-01-01,"Intelligent algorithms greatly influence imaging. Machine learning techniques find applicability in correcting and highlighting medical images generated by X-rays, Computed Tomography (CT) scan, Positron Emission Tomography (PET) scan, Magnetic Resonance Imaging (MRI). Such techniques increase the reliability and quality of diagnosis to aid the doctors in devising an effective treatment. These systems have found wide applicability under clinical settings. Imaging is also an essential task in autonomous vehicle development and Connected Vehicles. Research on Connected Vehicles is evolving at a staggering rate with an objective to reduce road accidents significantly and replace drivers with fully autonomous self-driving vehicles. Driver monitoring system (DMS) is a new area of research where drivers are monitored using cameras and other medical sensor networks to detect the drivers’ medical state, mental state as well as cognitive state. Objective biomarkers allow such systems to predict these states. Imaging plays an essential role in the diagnosis aided by the state of the art machine learning algorithms. This paper addresses the challenges posed by imaging under driving environments for diagnosis of medical and cognition of drivers.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3880-0_20,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-87178-9_58,Analysis of the Possibility of Intellectualization of Algorithms for Estimating the Parameters of Dynamic Systems Based on Adaptive Model of Motion,Proceedings of the Fifth International Scientific Conference “Intelligent Information Technologies for Industry” (IITI’21),10.1007/978-3-030-87178-9_58,Springer,2022-01-01,"Existing onboard systems for processing measurement information do not always provide the necessary accuracy in estimating the parameters of movement of unmanned aerial vehicles. These errors are due to the use of kinematic motion models based on filtering algorithms, which does not allow to take into account the action of external forces on the control object. The possibility of intellectualizing the adaptive algorithms for estimating the parameters of dynamic systems is considered. The proposed adaptive motion model with an intelligent system to determine the adaptation parameter as a part of the angular position estimation filter makes it possible to increase the estimation accuracy in comparison with the classical Kalman filter. The effectiveness of the proposed approach is confirmed by the comparative analysis of the results of numerical modeling of the process of estimation of the roll angle of the unmanned aerial vehicle model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-87178-9_58,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-9991-7_2,Drone-Based Weed Detection Architectures Using Deep Learning Algorithms and Real-Time Analytics,"Computer Vision and Machine Learning in Agriculture, Volume 2",10.1007/978-981-16-9991-7_2,Springer,2022-01-01,"Drones are constantly evolving and are set to provide cost-effective solutions to crucial real-world problems. The remote-controlled drones which were previously used for military purposes are now being equipped with sophisticated sensorial devices for data acquisition, and algorithms are being developed for autonomous flights. In parallel to the upgrades on drones, other fields such as real-time analytics and deep learning algorithms are also experiencing drastic and positive enhancements. The combination of these technologies opens the doors to potential novel architectures and provides solutions for unsolved problems to date. This chapter focuses on the weed detection branch of precision agriculture, and four different architectures are proposed. These architectures are geared towards real-time imaging data acquisition from agricultural fields, processing of the images, analytics, extraction, detection and relaying of insights. The main contribution of this work is the proposal of an in-flight hybrid architecture based on that of Apache Spark platform to support the components of the deep learning algorithm. Battery lifetime is a well-known constraint of UAVs. However, the speed of operation of Spark’s framework enables the smooth implementation of the proposed in-flight hybrid architecture with a reduced impact on battery life and flight time. The proposed architectures have the potential to facilitate large-scale farming and decrease the use of herbicides.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-9991-7_2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96383-5_105,The Problem of Determination of Guilt in Traffic Accidents with Intelligent Agent,International Scientific Siberian Transport Forum TransSiberia - 2021,10.1007/978-3-030-96383-5_105,Springer,2022-01-01,"Uncrewed vehicles have entered the streets of several cities worldwide in a test mode. In accidents with unmanned vehicles, they cause damage to the life, property, and health of citizens; these cases aren’t rare. Such cases have already happened. The purpose of this article is to analyze various points of view on the problems of criminal liability for offenses committed with the participation of uncrewed vehicles. Legal, ethical and moral ambiguity in matters of responsibility is becoming an obstacle to the development of unmanned transport. Using artificial intelligence requires a comprehensive analysis by the scientific community (politicians, psychologists, lawyers, representatives of the law enforcement sphere). Applying general scientific methods of cognition, the authors raise the question of determining the culpability of participants in road accidents involving unmanned vehicles. Its correct solution will ensure a more effective and balanced distribution of responsibility, which is fundamentally significant for law enforcement practice. Researchers propose to put on uncrewed vehicles with a specific status, which implies the acquisition of the rights and obligations of a legal entity. The authors of this scientific work categorically deny the possibility of personal responsibility of the artificial intelligence itself. The authors propose to include “indirect participants” in the number of potential defendants in traffic accidents involving artificial intelligence, including software developers, manufacturers, sellers, owners, users of an uncrewed vehicle. The authors believe that in the field of civil liability for offenses, it is necessary to recognize uncrewed vehicles as a source of increased danger, applying the institute of responsibility without fault.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96383-5_105,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-81166-2_50,PyChrono and gym-chrono: A Deep Reinforcement Learning Framework Leveraging Multibody Dynamics to Control Autonomous Vehicles and Robots,Advances in Nonlinear Dynamics,10.1007/978-3-030-81166-2_50,Springer,2022-01-01,"gym-chrono is a set of simulated environments for Deep Reinforcement Learning (DRL) extending OpenAI Gym (Brockman et al., Openai gym, 2016) with robotics and autonomous driving tasks. The physics of these environments is simulated thanks to Project Chrono (Tasora et al., Chrono: An open source multi-physics dynamics engine, 2016), an open-source multi-physics simulation engine capable of simulating Multibody Dynamics with constraints and smooth or non-smooth contacts. The most used Deep Learning frameworks (such as PyTorch and Tensorflow) have Python API, and thus using Python to implement DRL algorithms is the most convenient option. For this reason, a condition for the creation of these environments has been the development of PyChrono, a Python module consisting of the Python bindings to Project Chrono C++ API, to effectively interface the simulation capabilities of Project Chrono with Deep Learning frameworks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81166-2_50,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7167-8_68,Convolutional Neural Network Based on Self-Driving Autonomous Vehicle (CNN),Innovative Data Communication Technologies and Application,10.1007/978-981-16-7167-8_68,Springer,2022-01-01,"The development of artificial intelligence has functioned as a trigger in the technological world. Things that were previously simply a figment of our imagination are now becoming a reality. A good example is the creation makes self-driving automobile. There are days when you can work or even sleep in your car and yet arrive safely at your destination without touching the steering wheel or accelerator. This research presents a practical model of a self-driving car that can travel from one location to another or on a variety of tracks, including curved, straight, and curved tracks directly followed by curved tracks. Images from the real environment are sent to convolutional neural network via a camera module positioned on the top of the automobile, which can predict any of the following guidelines: right or left, forward or stop, after which an Arduino signal is sent to the remote-controlled car's controller, and the automobile goes to required destination without help of human participation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7167-8_68,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-96305-7_4,Blockchain Integrated Machine Learning for Training Autonomous Cars,Hybrid Intelligent Systems,10.1007/978-3-030-96305-7_4,Springer,2022-01-01,"Autonomous cars have always been fascinating towards the coming generation of we techies and since then training them has also been an important concern. That’s when we can consider Machine Learning integrated with Blockchain to provide high security to build this model. Machine Learning and Blockchain are two very innovative domains of computing. There has been a constant improvement in neural networks in past years. Since Artificial Intelligence-based learning algorithms are taken into account and a drive towards the training of autonomous cars is seen. Here, we are going to train a single car with great precision and accuracy, and then this alone trained car will share the data with all the other cars in its network. Hence, all of them will be sharing a particular network and the data will be exchanged. Now, when it comes to the learning of cars, we will be creating a blockchain network that will connect every car for that particular company. In this way, while in a dynamic condition also, the cars will stay connected with each and every one and the data will be exchanged. So, the training will be done using Deep Neural Networks and since the data transfer and weights update requires high security, we will be using Blockchain. For example, if any car gets hit by an accident or due to any possible fatal breakdown or due to any changes in the route or signals (government laws), this data will be transmitted to each other car in this network. Hence every car will get its weight updated to avoid or tackle the situation. This in the end will decrease the computational time and increase the measure of safety and well-being.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96305-7_4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-5685-9_53,Milestones in Autonomous Vehicle and Evaluation Using Computer Vision,Advances in Data Science and Management,10.1007/978-981-16-5685-9_53,Springer,2022-01-01,"This research work depicts different improvements done on self-sufficient vehicles and assessment is done dependent on instruments accessible through PC vision. To improve the vehicle's reaction and driving calculations, it ought to be given a similar viewpoint as an individual, with the goal that they can abstain from hitting into objects or smashing. Current days self-driving vehicles have accomplished various achievements to improve driving wellbeing and moving. Individuals rely upon their optical vision to recognize any approaching snags. By giving different boundaries, for example, path checking identification, traffic signals, approaching vehicles, and furthermore, the person on foot framework can be improved to expand the productivity of the accessible framework. Different OpenCV libraries have been created to give designers to make or redesign a current framework.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-5685-9_53,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-3923-5_12,Prediction of Occupant’s Head Movement During Slalom Driving via Artificial Neural Network with Multiple Training Algorithms,"Control, Instrumentation and Mechatronics: Theory and Practice",10.1007/978-981-19-3923-5_12,Springer,2022-01-01,"Autonomous vehicles are one of the future transportation technologies across the globe. However, autonomous vehicles have some setbacks and one of the setbacks is motion sickness. Occupant’s comfort level plays a vital role in the development of an autonomous vehicle. The motion sickness occurs due to the head movement of the driver tends to tilt against lateral acceleration but towards centripetal force; the head movement of the passenger tends to tilt against centripetal force but towards lateral acceleration. In addition, the method to develop and increase the comfort level is to monitor the head movement of the occupants during slalom driving. Nevertheless, it is inappropriate to attach sensors on occupants while traveling due to discomfort and dissatisfaction of driving experience. Hence, this study proposes prediction model of occupant’s head movement via Artificial Neural Networks. The data is taken from previous work from research. The experiment is carried out to collect the response data of lateral acceleration and the head movements of the occupants. This research also presents the model developed in MATLAB by implementing experimental data as parameter into two different training algorithms, Levenberg-Marquardt algorithm and Bayesian Regularization algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-19-3923-5_12,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-04987-3_7,Towards Scenario-Based and Question-Driven Explanations in Autonomous Vehicles,"HCI in Mobility, Transport, and Automotive Systems",10.1007/978-3-031-04987-3_7,Springer,2022-01-01,"Benefit from the progress in the field of explainable artificial intelligence (XAI), explanations have been increasingly prospective in the autonomous vehicle (AV) context. Providing explanations has been proved to be vital for human-AV interaction, but what and how to explain are still to be addressed. This study seeks to bridge the areas of XAI and human-AV interaction by combining perspectives of both users and researchers. In this paper, a conceptual framework of explanation models was proposed to indicate what aspects to explain in human-AV interaction. Based on the framework, we introduced a scenario-based and question-driven method, i.e., the SQX-canvas, to guide the workflow of generating explanations from users’ demands in a certain AV scenario. To make an initial validation of the method, a co-design workshop involving researchers and users was conducted with four AV scenarios provided in forms of video clips. Participants produced explanation concepts and expressed their attitudes towards the AV scenarios following the “scenario, question and explanation” process. It was apparent that users’ demands of explanations varied across scenarios, and findings as well as limitations were discussed. This method could provide implications for research and practice on facilitating transparent human-AV interaction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-04987-3_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-8542-2_20,Nature-Inspired AI Techniques in Intelligent Transportation System,International Conference on Artificial Intelligence and Sustainable Engineering,10.1007/978-981-16-8542-2_20,Springer,2022-01-01,"Efficient transportation is vital for smart cities. An intelligent transportation system (ITS) involves dealing with increasing travel demand, travelers’ safety concerns, efficient route planning, seamless traffic management, and much more. Due to the high complexity of such problems, researchers have used nature-inspired artificial intelligence (AI) techniques to propose various solutions for an ITS. This paper provides a review of such nature-inspired AI techniques used in specific applications in four components of ITS viz., road freight transport, route planning, vehicle control system, and safety and security. Upon witnessing their ample use in various applications in these components, it is observed that these techniques are principally utilized for planning, management, forecasting, and prediction-related tasks. Further, we provide a discussion on the future scope and challenges involved in using these techniques for ITS.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-8542-2_20,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7136-4_17,AI Approach for Autonomous Vehicles to Defend from Adversarial Attacks,Proceedings of International Conference on Intelligent Cyber-Physical Systems,10.1007/978-981-16-7136-4_17,Springer,2022-01-01,"Neural Networks are really impeccable sometimes, but when it comes to adversarial attacks, their performance falls off swiftly. Moreover, considerations to build more robust models that would be resilient to adversarial attacks are ignored frequently. Here, we aim to design a model that is robust and can handle multiple types of adversarial attacks on traffic signs. Despite those attacks, the model should not be fooled and identify the sign correctly. Simple input transformations can help defend against adversarial attacks. We used the German Traffic Sign Recognition Benchmark (GTSRB) dataset to generate adversarial samples by Fast Gradient Sign Method [ 1 ] and Projected Gradient Descent Method [ 1 ]. In this paper, we focus on training a model with a defense mechanism to remove the adversarial noise, to make the model Anti-Spoof for Traffic Sign Recognition.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7136-4_17,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-1-4842-7480-4_17,AI and Blockchain Monitoring Autonomous Vehicles Management Project,Introducing Blockchain Applications,10.1007/978-1-4842-7480-4_17,Springer,2022-01-01,"The autonomous vehicle management system is the subject of this chapter. This entails operating a vehicle or system in a distributed environment. Artificial intelligence and message exchanges (blockchain) are both present in this scenario. Simultaneously, we must prevent catastrophic collapse when it comes to autonomous vehicle management.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-1-4842-7480-4_17,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-96507-5_2,MEC-Assisted Vehicular Networking,Intelligent Resource Management in Vehicular Networks,10.1007/978-3-030-96507-5_2,Springer,2022-01-01,"In this chapter, an MVNET architecture is proposed to support vehicular applications. Most AV applications are usually with stringent delays and intensive computing requirements, which can be regarded as typical emerging vehicular applications. Thus, in this chapter, designing the MVNET architecture is mainly motivated from the AVs’ perspectives yet can be easily extended to general vehicular networks. Improving navigation safety by enabling HD-map-assisted cooperative driving among AVs is of great importance to the market perspective of AVs but confronts technical challenges due to increased communication, computing, and caching tasks generated by AVs for supporting different applications. To address these challenges, an MEC-assisted ADVNET architecture is proposed in this chapter. Specifically, an MEC-assisted ADVNET architecture that incorporates both SDN and NFV technologies is proposed in Sect. 2.1, in which a joint multi-resource management scheme is presented and some future research issues are discussed. Then, we take the intelligent resource allocation in an aerial-assisted vehicular network as a case study in Sect. 2.3. In this section, AI-based resource management schemes are developed such that terrestrial and aerial spectrum, computing, and storage resources can be cooperatively allocated for guaranteeing the quality of service requirements from different applications. Also, the joint management of the spectrum and computing resources is presented to demonstrate the effectiveness of the AI-based resource management schemes. Finally, we draw concluding remarks in Sect. 2.4.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-96507-5_2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94191-8_89,The Proposed Self-defense Mechanism Against Security Attacks for Autonomous Vehicles,Innovations in Smart Cities Applications Volume 5,10.1007/978-3-030-94191-8_89,Springer,2022-01-01,"The objective of this work is the use of artificial intelligence to improve the safety of connected autonomous vehicles, in this project, we will propose the architecture and validation of a self-defense system for the detection, classification, prediction, and decision-making at the level of control system on the connected autonomous vehicle in the presence of security attacks or risk of attacks. A system that can be integrated into all connected autonomous vehicles and admits improvements to follow the evolution of attacks and transport systems. In this project we will propose a self-defense system consists three treatment blocks; the first block has the role of the permanent scanning of the various connected interfaces to detect any intrusions or security attacks. The second block will collect the information from the first block; it will analyze them and classify the attack according to its impact on the operation of the vehicle or on its connected environment. The result will be communicated to the third block which must predict the impact of the attack for decision-making.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-94191-8_89,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-4016-2_38,Analysing and Identifying Harm Propagation of Cyber Threats in Autonomous Vehicles and Mitigation Through ANN,Smart Trends in Computing and Communications,10.1007/978-981-16-4016-2_38,Springer,2022-01-01,"Connected and autonomous vehicle industry is fostering advancements in technologies such as artificial intelligence, machine learning, Internet of Things and Big data applications. Connected and autonomous vehicles rely on a variety of electronics, sensors and computer systems. They require strong cyber security mitigations to ensure that these systems work reliable and to reduce security risks. While the possibilities for integrating devices and vehicles seem endless, new threats and dangers arise every day. Due to their connectivity, there are also security risks to the networks they are connected to, such as road network sensors, electrical infrastructure or vehicle control features and so on. Systems should be created in order to reduce all the possible threats and vulnerabilities. In the study, we will analyse the various cyber security vulnerabilities and threats which are possible in autonomous vehicles by constructing graph from observing harm propagation of the cyber threats and propose a mitigation model for the same.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-4016-2_38,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7996-4_14,Lane Detection for Autonomous Cars Using Neural Networks,Machine Learning and Autonomous Systems,10.1007/978-981-16-7996-4_14,Springer,2022-01-01,"Advancements in lane detection algorithms lead to realizing autonomous driving technology and improving the real-time use of deep learning algorithms that are currently being studied for their various vision-based applications . In this paper, we propose an efficient and accurate algorithm to detect lanes and lane lines for autonomous vehicles. First, an OpenCV lane detection model was built to improve the understanding of lane detection algorithms. Using this knowledge, a CNN solution was adopted for the lane detection algorithm to train more data, work on curved lanes, and improve accuracy. The shortcomings of this model were identified and to solve these shortcomings, a Fully Convolutional Neural Network approach based on SegNet’s architecture was adopted. The accuracy of the models implemented was found to be as: OpenCV: 91%, CNN: 94.49%, and FCN: 96.12%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7996-4_14,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-08333-4_14,An Efficient Method for Addressing COVID-19 Proximity Related Issues in Autonomous Shuttles Public Transportation,Artificial Intelligence Applications and Innovations,10.1007/978-3-031-08333-4_14,Springer,2022-01-01,"The COVID-19 pandemic has created significant restrictions to passenger mobility through public transportation. Several proximity rules have been applied to ensure sufficient distance between passengers and mitigate contamination. In conventional transportation, abiding by the rules can be ensured by the driver of the vehicle. However, this is not obvious in Autonomous Vehicles (AVs) public transportation systems, since there is no driver to monitor these special circumstances. Since, AVs constitute an emerging mobility infrastructure, it is obvious that creating a system that can provide a sense of safety to the passenger, when the driver is absent, is a challenging task. Several studies employ computer vision and deep learning techniques to increase safety in unsupervised environments. In this work, an image-based approach, supported by novel AI algorithms, is proposed as a service to increase the COVID-19 safety rules adherence of the passengers inside an autonomous shuttle. The proposed real-time service, can detect deviations from proximity rules and notify the authorized personnel, while it is possible to be further extended in other application domains, where automated proximity assessment is critical.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-031-08333-4_14,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11432-020-3170-2,Reinforcement learning based energy efficient robot relay for unmanned aerial vehicles against smart jamming,Science China Information Sciences,10.1007/s11432-020-3170-2,Springer,2021-12-27,"Unmanned aerial vehicles (UAVs) with limited energy resources, severe path loss, and shadowing to the ground base stations are vulnerable to smart jammers that aim to degrade the UAV communication performance and exhaust the UAV energy. The UAV anti-jamming communication performance, such as the outage probability, degrades if the robot relay is not aware of the jamming policies and the UAV network topology. In this paper, we propose a robot relay scheme for UAVs against smart jamming, which combines reinforcement learning with a function approximation approach named tile coding, to jointly optimize the robot moving distance and relay power with the unknown jamming channel states and locations. The robot mobility and relay policy are chosen based on the received jamming power, the robot received signal quality, location and energy consumption, and the bit error rate of the UAV messages. We also present a deep reinforcement learning version for the robot with sufficient computing resources. It uses three deep neural networks to choose the robot mobility and relay policy with reduced sample complexity, so as to avoid exploring dangerous policies that lead to the high outage probability of the UAV messages. The network architecture of the three networks is designed with fully connected layers instead of convolutional layers to reduce the computational complexity, which is analyzed by theoretical analyses. We provide the performance bound of the proposed schemes in terms of the bit error rate, robot energy consumption and utility based on a game-theoretic study. Simulation results show that the performance of our proposed relay schemes, including the bit error rate, the outage probability, and the robot energy consumption outperforms the existing schemes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11432-020-3170-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13198-021-01127-6,Deep learning using computer vision in self driving cars for lane and traffic sign detection,International Journal of System Assurance Engineering and Management,10.1007/s13198-021-01127-6,Springer,2021-12-01,"Recently, the amount of research in the field of self-driving cars has grown significantly with autonomous vehicles having clocked in more than 10 million miles, providing a substantial amount of data for use in training and testing. The most complex part of training is the use of computer vision for feature extraction and object detection in real-time. Much relevant research has been done on improving the algorithms in the area of image segmentation. The proposed idea presents the use of Convoluted Neural Networks using Spatial Transformer Networks and lane detection in real time to increase the efficiency of autonomous vehicles. The depth of the neural network will help in training vehicles and during the testing phase, the vehicles will learn to make decisions based on the training data. In case of sudden changes to the environment, the vehicle will be able to make decisions quickly to prevent damage or danger to lives. Along with lane detection, a self-driving car must also be able to detect traffic signs. The proposed approach uses the Adam Optimizer which runs on top of the LeNet-5 architecture. The LeNet-5 architecture is analyzed and compared with the Feed Forward Neural Network approach. The accuracy of the LeNet-5 architecture was found to be 97% while the accuracy of the Feed Forward Neural Network was 94%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13198-021-01127-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12596-021-00770-3,UAV detection in airborne optic videos using dilated convolutions,Journal of Optics,10.1007/s12596-021-00770-3,Springer,2021-12-01,"In this paper, a real-time unmanned aerial vehicles (UAVs) detection framework is proposed for GPU embedded applications. To achieve this, this paper proposed a new modified model based on You Only Look Once (YOLO) to detect multi-UAV in aerial images with a complex background. The proposed CNN architecture uses five inception module and dilated convolution with two different factors to increase detection accuracy of YOLOv3 tiny, while preserving its computational time. To further improve the detection accuracy, Generalized Intersection over Union loss is replaced with the bounding box regression loss in the original YOLOv3 tiny loss function. To obtain higher frame rate, scalable kernel correlation filter (sKCF) algorithm is integrated to the detection model. More specifically, the proposed UAV detection method is used to initialize the sKCF tracker at every $$n\mathrm{th}$$ n th frame. Thus, the detected UAVs can be detected in intermediate frames with a low memory footprint. The proposed model and compared models are trained and tested on a variety of training and test airborne videos, captured under different outdoor scenarios. The average precision of the proposed model is 0.8265 and achieves 32 FPS performance on Jetson-TX2. The results show that the proposed model which is widened with inception module using  dilated convolutions has a very high performance in terms of accuracy and speed even when it is compared with deep CNN architectures such as Darknet 53.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12596-021-00770-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-021-06460-3,Quantum neural network-based multilabel image classification in high-resolution unmanned aerial vehicle imagery,Soft Computing,10.1007/s00500-021-06460-3,Springer,2021-12-01,"Latest advancements in real-time remote sensing sensors and platform lead to the development of unmanned aerial vehicles (UAV) which enable the accessibility of high-resolution imaging data. Since image classification appears like a basic interconnection among aerial images and the corresponding applications, it intends to categorize images into semantic classes. Several earlier works have concentrated on the classification of an image into a single semantic label, whereas in the real world, an aerial image is commonly interrelated to many class labels, for instance, multiple object-level labels. Moreover, a broad image of present objects in provided high-resolution aerial image offers an extensive interpretation of the investigated area. To attain this, this paper presents a new quantum neural network based multilabeled aerial image classification (QNN-MLAIC) model. The proposed QNN-MLAIC model involves different processes, namely image acquisition, preprocessing, object detection, feature extraction, and classification. Initially, the aerial images are acquired by wireless UAVs and are preprocessed. Then, the Faster RCNN technique with Inception with Residual Network-v2 model as the baseline model is applied as an object detector, which detects the existence of multiple objects in the aerial image and generates a helpful set of feature vectors. Finally, QNN is employed as classifier, which categorizes the aerial images into multiple class labels. In order to tune the parameters involved in QNN model, the beetle antenna search algorithm is employed. Detailed performance analysis of the proposed QNN-MLAIC model takes place using the UC Merced dataset (UCM) aerial dataset, and the outcomes are investigated under many dimensions. The experimental outcome ensured the goodness of the presented QNN-MLAIC method on the applied UCM aerial dataset over the compared methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-021-06460-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-021-03609-8,Development of a deep learning model for recognising traffic sings focused on difficult cases,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-021-03609-8,Springer,2021-12-01,"The automotive industry is expanding its efforts to develop new techniques for increasing the level of intelligent driving and create new autonomous cars capable of driving with more intelligent capabilities. Thus, companies in this sector are turning to the development of autonomous cars and more specifically developing software along with more artificial intelligent algorithms. However, to be able to trust these systems, they must be developed very carefully, and use techniques that can increase the level of recognition that will consequently improve the level of safety. One of the most important components in this respect for road users is the correct interpretation of traffic sings. This paper presents a deep learning model based on convolutional neural networks and image processing that can be used to improve the recognition of traffic sings autonomously. The results are focused on difficult cases such as images with lighting problems, blurry traffic sings, hidden traffic sings, and small images. Hence, real cases are used in this study for identifying the existing problems and achieving good performance in traffic signal recognition. Finally, as a result, the configuration of the neural architecture based on three phases of convolutions proposed shows a validation accuracy of 99.3% during the data training. Another comparison carried out with the model ResNet-50 obtained an accuracy of 88.5%. Thus, for this type of application, a high validation accuracy is required as the results of our model demonstrated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12652-021-03609-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42853-021-00119-5,Design and Performance Evaluation of Air Induction (AI) Nozzles to Reduce Drift Potential for Agricultural Unmanned Aerial Vehicles (UAVs),Journal of Biosystems Engineering,10.1007/s42853-021-00119-5,Springer,2021-12-01,"Purpose This study aims to develop a low-drift air induction (AI) nozzle that meets the requirements of agricultural control unmanned aerial vehicles (UAVs). An AI nozzle was designed and manufactured to satisfy the design goals. The performance of the developed AI nozzle was quantitatively evaluated in terms of injection flow rate, air-to-liquid ratio (ALR), spray angle, and droplet size. Methods The average value of the injection flow rate and the variation over time were measured using a gear-type positive displacement precision flow meter. The spray structure and spray angle were obtained at very high temporal resolution using the single image acquisition function of a two-dimensional particle image velocimetry (PIV) system. The droplet size of the spray was measured using a laser diffraction technique. Results The injection flow rate of the AI nozzle changes with the pressure recovery characteristics inside the nozzle mixing chamber and affects the dynamic stability of the AI nozzle. The spray angle of the AI nozzle with a flat-fan nozzle tip increases linearly with the injection pressure, and if there is additional consideration for the two-phase flow effect, the prediction equation for the single-phase flow can be applied to estimate the spray angle. The generation of air bubble-containing droplets in AI nozzles is formed by large-diameter ligament disintegration caused by a rolled-up liquid sheet and is larger than that of single-phase flow nozzles. The droplet size (Dv0.5) of the developed AI nozzle was 384 μm, which was smaller than that of a similar commercial AI nozzle. Conclusions AI nozzle design, manufacturing and performance evaluation technology that satisfies the requirements of agricultural control UAVs, was established through this study.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42853-021-00119-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01491-2,Quadrotor Path Following and Reactive Obstacle Avoidance with Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01491-2,Springer,2021-11-10,"A deep reinforcement learning approach for solving the quadrotor path following and obstacle avoidance problem is proposed in this paper. The problem is solved with two agents: one for the path following task and another one for the obstacle avoidance task. A novel structure is proposed, where the action computed by the obstacle avoidance agent becomes the state of the path following agent. Compared to traditional deep reinforcement learning approaches, the proposed method allows to interpret the training process outcomes, is faster and can be safely trained on the real quadrotor. Both agents implement the Deep Deterministic Policy Gradient algorithm. The path following agent was developed in a previous work. The obstacle avoidance agent uses the information provided by a low-cost LIDAR to detect obstacles around the vehicle. Since LIDAR has a narrow field-of-view, an approach for providing the agent with a memory of the previously seen obstacles is developed. A detailed description of the process of defining the state vector, the reward function and the action of this agent is given. The agents are programmed in python/tensorflow and are trained and tested in the RotorS/gazebo platform. Simulations results prove the validity of the proposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01491-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01481-4,Multi-Sound-Source Localization Using Machine Learning for Small Autonomous Unmanned Vehicles with a Self-Rotating Bi-Microphone Array,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01481-4,Springer,2021-10-27,"While vision-based localization techniques have been widely studied for small autonomous unmanned vehicles (SAUVs), sound-source localization capabilities have not been fully enabled for SAUVs. This paper presents two novel approaches for SAUVs to perform three-dimensional (3D) multi-sound-sources localization (MSSL) using only the inter-channel time difference (ICTD) signal generated by a self-rotating bi-microphone array. The proposed two approaches are based on two machine learning techniques viz., Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Random Sample Consensus (RANSAC) algorithms, respectively, whose performances were tested and compared in both simulations and experiments. The results show that both approaches are capable of correctly identifying the number of sound sources along with their 3D orientations in a reverberant environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01481-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11276-021-02789-7,Energy-efficient UAV-enabled computation offloading for industrial internet of things: a deep reinforcement learning approach,Wireless Networks,10.1007/s11276-021-02789-7,Springer,2021-10-12,"Industrial Internet of Things (IIoT) has been envisioned as a killer application of 5G and beyond. However, due to the shortness of computation ablility and batery capacity, it is challenging for IIoT devices to process latency-sensitive and resource-sensitive tasks. Moblie Edge Computing (MEC), as a promising paradigm for handling tasks with high quality of service (QoS) requirement and for energy-constrained IIoT devices, allows IIoT devices to offload their tasks to MEC servers, which can significantly reduce the task process delay and energy consumptions. However, the deployment of the MEC servers rely heavily on communication infrastructure, which greatly reduce the flexibility. Toward this end, in this paper, we consider multiple Unmanned Aerial Vehicles (UAV) eqqipped with transceivers as aerial MEC servers to provide IIoT devices computation offloading opportunities due to their high controbility. IIoT devices can choose to offload the tasks to UAVs through air-ground links, or to offload the tasks to the remote cloud center through ground cellular network, or to process the tasks locally. We formulate the multi-UAV-Enabled computation offloading problem as a mixed integer non-linear programming (MINLP) problem and prove its NP-hardness. To obtain the energy-efficient and low complexity solution, we propose an intelligent computation offloading algorithm called multi-agent deep Q-learning with stochastic prioritized replay (MDSPR). Numerical results show that the proposed MDSPR converges fast and outperforms the benchmark algorithms, including random method, deep Q-learning method and double deep Q-learning method in terms of energy efficiency and task successful rate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11276-021-02789-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11676-020-01245-0,Tree species classification using deep learning and RGB optical images obtained by an unmanned aerial vehicle,Journal of Forestry Research,10.1007/s11676-020-01245-0,Springer,2021-10-01,"The diversity of tree species and the complexity of land use in cities create challenging issues for tree species classification. The combination of deep learning methods and RGB optical images obtained by unmanned aerial vehicles (UAVs) provides a new research direction for urban tree species classification. We proposed an RGB optical image dataset with 10 urban tree species, termed TCC10, which is a benchmark for tree canopy classification (TCC). TCC10 dataset contains two types of data: tree canopy images with simple backgrounds and those with complex backgrounds. The objective was to examine the possibility of using deep learning methods (AlexNet, VGG-16, and ResNet-50) for individual tree species classification. The results of convolutional neural networks (CNNs) were compared with those of K-nearest neighbor (KNN) and BP neural network. Our results demonstrated: (1) ResNet-50 achieved an overall accuracy (OA) of 92.6% and a kappa coefficient of 0.91 for tree species classification on TCC10 and outperformed AlexNet and VGG-16. (2) The classification accuracy of KNN and BP neural network was less than 70%, while the accuracy of CNNs was relatively higher. (3) The classification accuracy of tree canopy images with complex backgrounds was lower than that for images with simple backgrounds. For the deciduous tree species in TCC10, the classification accuracy of ResNet-50 was higher in summer than that in autumn. Therefore, the deep learning is effective for urban tree species classification using RGB optical images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11676-020-01245-0,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13369-021-05522-w,Power Transmission Line Fault Detection and Diagnosis Based on Artificial Intelligence Approach and its Development in UAV: A Review,Arabian Journal for Science and Engineering,10.1007/s13369-021-05522-w,Springer,2021-10-01,"This paper provides a systematic, comprehensive, up-to-date study of the various artificial intelligence (AI) techniques on the detection and classification of faults on power transmission line. We review the latest start of the art of various intelligent approaches and even discuss the differences and outcomes of implementing intelligent methods in the protection scheme and the integrated protection scheme. Besides, there has been an increase in demand and interest for the application of AI approaches in drone to aid in detection and classification of faults. However, there are not many surveys pertaining to the development of the unmanned aerial vehicle (UAV) for the application of intelligent methods in this field. Thus, we also include in this paper the literature relevant to the implementation of various intelligent approaches in the unmanned aerial vehicle (UAV) for the fault detection and classification on power transmission line. Finally, we discuss the challenges and limitations faced in the implementation and propose ways to bridge the gap in the field for further research. This comprehensive study can act as a platform for new researchers to assess the possible different intelligent methods in detecting and classifying faults on power transmission line with a set of references that were dedicated to the attentive contributions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s13369-021-05522-w,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11063-021-10544-4,A Neural Network Based System for Efficient Semantic Segmentation of Radar Point Clouds,Neural Processing Letters,10.1007/s11063-021-10544-4,Springer,2021-10-01,"The last decade has witnessed important advancements in the field of computer vision and scene understanding, enabling applications such us autonomous vehicles. Radar is a commonly adopted sensor in automotive industry, but its suitability to machine learning techniques still remains an open question. In this work, we propose a neural network (NN) based solution to efficiently process radar data. We introduce RadarPCNN, an architecture specifically designed for performing semantic segmentation on radar point clouds. It uses PointNet $$++$$ + + as a building-block—enhancing the sampling stage with mean-shift—and an attention mechanism to fuse information. Additionally, we propose a machine learning radar pre-processing module that confers the network the ability to learn from radar features. We show that our solutions are effective, yielding superior performance than the state-of-the-art.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11063-021-10544-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13007-021-00796-5,Improving the estimation of alpine grassland fractional vegetation cover using optimized algorithms and multi-dimensional features,Plant Methods,10.1186/s13007-021-00796-5,BioMed Central,2021-09-17,"Background Fractional vegetation cover (FVC) is an important basic parameter for the quantitative monitoring of the alpine grassland ecosystem on the Qinghai-Tibetan Plateau. Based on unmanned aerial vehicle (UAV) acquisition of measured data and matching it with satellite remote sensing images at the pixel scale, the proper selection of driving data and inversion algorithms can be determined and is crucial for generating high-precision alpine grassland FVC products. Methods This study presents estimations of alpine grassland FVC using optimized algorithms and multi-dimensional features. The multi-dimensional feature set (using original spectral bands, 22 vegetation indices, and topographical factors) was constructed from many sources of information, then the optimal feature subset was determined based on different feature selection algorithms as the driving data for optimized machine learning algorithms. Finally, the inversion accuracy, sensitivity to sample size, and computational efficiency of the four machine learning algorithms were evaluated. Results (1) The random forest (RF) algorithm (R^2: 0.861, RMSE: 9.5%) performed the best for FVC inversion among the four machine learning algorithms driven by the four typical vegetation indices. (2) Compared with the four typical vegetation indices, using multi-dimensional feature sets as driving data obviously improved the FVC inversion accuracy of the four machine learning algorithms (R^2 of the RF algorithm increased to 0.890). (3) Among the three variable selection algorithms (Boruta, sequential forward selection [SFS], and permutation importance-recursive feature elimination [PI-RFE]), the constructed PI-RFE feature selection algorithm had the best dimensionality reduction effect on the multi-dimensional feature set. (4) The hyper-parameter optimization of the machine learning algorithms and feature selection of the multi-dimensional feature set further improved FVC inversion accuracy (R^2: 0.917 and RMSE: 7.9% in the optimized RF algorithm). Conclusion This study provides a highly precise, optimized algorithm with an optimal multi-dimensional feature set for FVC inversion, which is vital for the quantitative monitoring of the ecological environment of alpine grassland.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-021-00796-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01489-w,End-to-End Probabilistic Depth Perception and 3D Obstacle Avoidance using POMDP,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01489-w,Springer,2021-09-17,"In most real world applications, noisy and incomplete information about the robot proximity is inevitable due to imperfections coupled with the onboard sensors. The perception and control problems go hand in hand in order to efficiently plan safe robot maneuvers. This paper proposes a method to generate robot actions directly from a sequence of depth images. The notion of Artificial Potential Field (APF) approach is used where a robot action is obtained by combining the attractive and repulsive actions generated by the goal and the obstacles respectively. This article assumes environment perception uncertainty that relates to the estimation of an obstacle’s location relative to the robot. The repulsive action generation is formulated as a Partially Observable Markov Decision Process (POMDP). A Particle Filter (PF) approach is used to estimate and track valid scene points in the robot sensing horizon from an imperfect depth image stream. The most probable candidates for an occupied region are used to generate a velocity action that minimizes the repulsive potential at each time instant. Approximately optimal solutions to the POMDP are obtained using the QMDP technique which enables us to perform computationally expensive operations prior to a robot run. Consequently, suitable repulsive actions are generated onboard the robot, each time an image is received, in a computationally feasible way. An attractive action, obtained by solving for the negative gradient of the attractive potential is finally added to the repulsive action to generate a final robot action at every time step. Lastly, the robustness and reliability of this approach is demonstrated close-loop on a quadrotor UAV equipped with a depth camera. The experiments also demonstrate that the method is very computationally efficient and can be run on a variety of platforms that have limited resources on-board.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01489-w,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43681-021-00091-y,Coarse ethics: how to ethically assess explainable artificial intelligence,AI and Ethics,10.1007/s43681-021-00091-y,Springer,2021-09-12,"The integration of artificial intelligence (AI) into human society mandates that their decision-making process is explicable to users, as exemplified in Asimov’s Three Laws of Robotics. Such human interpretability calls for explainable AI (XAI), of which this paper cites various models. However, the transaction between computable accuracy and human interpretability can be a trade-off, requiring answers to questions about the negotiable conditions and the degrees of AI prediction accuracy that may be sacrificed to enable user-interpretability. The extant research has focussed on technical issues, but it is also desirable to apply a branch of ethics to deal with the trade-off problem. This scholarly domain is labelled coarse ethics in this study, which discusses two issues vis-à-vis AI prediction as a type of evaluation. First, which formal conditions would allow trade-offs? The study posits two minimal requisites: adequately high coverage and order-preservation. The second issue concerns conditions that could justify the trade-off between computable accuracy and human interpretability, to which the study suggests two justification methods: impracticability and adjustment of perspective from machine-computable to human-interpretable. This study contributes by connecting ethics to autonomous systems for future regulation by formally assessing the adequacy of AI rationales.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s43681-021-00091-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-021-01277-y,"Morals, ethics, and the technology capabilities and limitations of automated and self-driving vehicles",AI & SOCIETY,10.1007/s00146-021-01277-y,Springer,2021-09-10,"We motivate the desire for self-driving and explain its potential and limitations, and explore the need for—and potential implementation of—morals, ethics, and other value systems as complementary “capabilities” to the Deep Technologies behind self-driving. We consider how the incorporation of such systems may drive or slow adoption of high automation within vehicles. First, we explore the role for morals, ethics, and other value systems in self-driving through a representative hypothetical dilemma faced by a self-driving car. Through the lens of engineering, we explain in simple terms common moral and ethical frameworks including utilitarianism, deontology, and virtue ethics before characterizing their relationship to the fundamental algorithms enabling self-driving. The concepts of behavior cloning, state-based modeling, and reinforcement learning are introduced, with some algorithms being more suitable for the implementation of value systems than others. We touch upon the contemporary cross-disciplinary landscape of morals and ethics in self-driving systems from a joint philosophical and technical perspective, and close with considerations for practitioners and the public, particularly as individuals may not appreciate the nuance and complexity of using imperfect information to navigate diverse scenarios and tough-to-quantify value systems, while “typical” software development reduces complex problems to black and white decision-making.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-021-01277-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-020-05001-7,A hybrid approach for search and rescue using 3DCNN and PSO,Neural Computing and Applications,10.1007/s00521-020-05001-7,Springer,2021-09-01,"Search and rescue are essential applications of disaster management in which people are evacuated from the disaster-prone area to a safer place. This overall process of search and rescue can be more efficient if an automated system can quickly locate the human or area where rescue is required. To provide a faster and accurate search of those places, this paper proposes a novel approach to search and rescue using automated drone surveillance. In this paper, a complex scene classification problem is solved using the proposed 3DCNN model. The proposed model uses spatial as well as temporal features of the video for the classification of the scene as help or non-help in the natural disaster. Due to the unavailability of such kind of dataset, it is impossible to train the model. Therefore, it is essential to develop a dataset for search and rescue. The proposed dataset is a first and unique dataset for scene classification using drone surveillance. The major contribution of this paper is (1) a novel 3DCNN powered model for scene classification in drone surveillance, (2) to develop the required dataset for the training of scene classification model, and (3) particular swarm optimization (PSO)-based hyper-parameter tuning for getting the best value of multiple parameters used for training the model. Our hybridization of parameter tuning with PSO helps for the convergence of parameter values of proposed 3DCNN model, and the proposed scene classification model (3DCNN+PSO) is applied to the dataset. The proposed model gives an impressive performance to help situation identification with 98% training and 99% validation accuracy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-020-05001-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-021-00383-6,Leveraging single-shot detection and random sample consensus for wind turbine blade inspection,Intelligent Service Robotics,10.1007/s11370-021-00383-6,Springer,2021-09-01,"Wind turbines require periodic inspection to ensure efficient power generation and a prolonged lifetime. Traditionally, inspection involves the risk of a person falling while abseiling from the top of the nacelle. To avoid this, drones have been controlled by operators to inspect the blades. However, this task requires expert pilots, who experience fatigue quickly. Alternatively, autonomous drones are not subject to human tiredness and can follow trajectories in a repeatable manner. Motivated by the latter, we introduce a vision-based blade detector capable of recognizing their orientation and relative position to generate a flight plan that allows it to safely collect image data. The proposed blade detector extracts line features with the camera, which are filtered to reduce the search space by using bounding boxes. They are obtained with a single-shot detector based on a convolutional neural network. Finally, a random sample consensus procedure finds the lines that best fit a geometrical model of the wind turbine. We compare our deep learning approach against a color segmentation method, showing that it is up to 6 times faster. We also compare against guided search during random sampling, which exploits the separate boxes detected by the network, seeking to reduce the number of outliers. We conclude with an illustrative example of how our proposed detector could be used for autonomous wind turbine inspection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-021-00383-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40435-020-00722-y,Adaptive nonlinear robust control of an underactuated micro UAV,International Journal of Dynamics and Control,10.1007/s40435-020-00722-y,Springer,2021-09-01,"In this article, we investigate a robust nonlinear control strategy to solve the trajectory tracking for a micro unmanned aerial vehicle, the quadrotor. The control technique is the computed torque control (CTC), this technique is widely used in the robot manipulators control. The CTC technique needs a strong knowledge of the model. In this regard, the complete dynamic model of the quadrotor has been established by the Euler–Lagrange formalism. After that, a robust nonlinear H_∞ controller has been designed to stabilize the system with robustness. The proposed controller takes into account the underactuation characteristic of the quadrotor, so the controller is designed for the actuated degrees of freedom (DOF) with their coupling with the underactuated DOF. For the position tracking, we propose the backstepping controller. In both controllers, nonlinear H_∞ and backstepping, the integral action is considered to get a null steady-state error. In order to improve performance quality, the control law has been reinforced by an adaptive action. This last has been performed by the linear parameterization property and the neural networks. The results show efficiency in the parametric uncertainties.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-020-00722-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00146-020-01089-6,Making moral machines: why we need artificial moral agents,AI & SOCIETY,10.1007/s00146-020-01089-6,Springer,2021-09-01,"As robots and Artificial Intelligences become more enmeshed in rich social contexts, it seems inevitable that we will have to make them into moral machines equipped with moral skills. Apart from the technical difficulties of how we could achieve this goal, we can also ask the ethical question of whether we should seek to create such Artificial Moral Agents (AMAs). Recently, several papers have argued that we have strong reasons not to develop AMAs. In response, we develop a comprehensive analysis of the relevant arguments for and against creating AMAs, and we argue that all things considered we have strong reasons to continue to responsibly develop AMAs. The key contributions of this paper are threefold. First, to provide the first comprehensive response to the important arguments made against AMAs by Wynsberghe and Robbins (in “Critiquing the Reasons for Making Artificial Moral Agents”, Science and Engineering Ethics 25, 2019) and to introduce several novel lines of argument in the process. Second, to collate and thematise for the first time the key arguments for and against AMAs in a single paper. Third, to recast the debate away from blanket arguments for or against AMAs in general, to a more nuanced discussion about the use of what sort of AMAs, in what sort of contexts, and for what sort of purposes is morally appropriate.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00146-020-01089-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-021-05614-7,An intelligent energy management and traffic predictive model for autonomous vehicle systems,Soft Computing,10.1007/s00500-021-05614-7,Springer,2021-09-01,"In recent times, the utilization of autonomous vehicles (AVs) has been significantly increased over the globe. It is because of the tremendous rise in familiarity and the usage of artificial intelligence approaches in distinct application areas. Though AVs offer several benefits like congestion control, accident prevention, and so on, energy management and traffic flow prediction (TFP) remain a challenging issue. This paper concentrates on the design of intelligent energy management and TFP (IEMTFP) technique for AVs using multi-objective reinforced whale optimization algorithm (RWOA) and deep learning (DL). The proposed model involves an energy management module using fuzzy logic system to reach the specified engine torque with respect to different measures. For optimal tuning of the variables involved in the fuzzy logic membership functions (MFs), RWOA is employed to further reduce the energy utilization. Besides, the proposed model uses a DL-based bidirectional long short-term memory (Bi-LSTM) technique to perform TFP. For validating the efficacy of the IEMTFP technique, an extensive experimental validation is carried out. The resultant values ensured the goodness of the IEMTFP model in terms of energy management and TFP.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-021-05614-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12083-021-01073-x,Blockchain-based Secure and Intelligent Sensing Scheme for Autonomous Vehicles Activity Tracking Beyond 5G Networks,Peer-to-Peer Networking and Applications,10.1007/s12083-021-01073-x,Springer,2021-09-01,"For the past few years, the automation of transportation becomes a hot research topic for smart cities. Intelligent Transportation System (ITS) aims to manage and optimize the traffic congestion, road accidents, parking allocation using Autonomous Vehicles (AV) system, where the AVs are internally connected for message passing and critical decision making in time-sensitive applications. The data security in such applications can be offered using Blockchain (BC) technology. But, as per the existing literature, there exists no system which can call AVs automatically based on the situation, i.e., call an ambulance in case of an accident, call logistic service in case of home transfer, and call the traffic department in case of traffic jam. Motivated from the aforementioned reasons, in this article, we propose a BC-based secure and intelligent sensing and tracking architecture for AV system using beyond 5G communication network. Recently, AVs are facing issues with sensing and tracking technology as well as the data thefts. AV system contains sensitive information and transfers it through a communication channel to Connected AVs (CAVs), where the corrupted information or delay of a fraction of a second can lead to a critical situation. So, here we present possib the attacks and safety countermeasures using BC technology to protect the AV system. The proposed architecture ensures secure sensing and tracking of an object through BC by deploying AI algorithms at the edge servers. Also, the beyond 5G network enables communications with low latency and high reliability to meet the desires of the aforementioned time-sensitive applications. The proposed system is evaluated by considering the parameters as mobility and data transfer time against the traditional LTE-A and 5G communication networks. The proposed system outperforms traditional systems and can be suitable for diverse applications where latency, reliability, and security are the prime concerns.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12083-021-01073-x,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s10033-021-00598-9,ML-ANet: A Transfer Learning Approach Using Adaptation Network for Multi-label Image Classification in Autonomous Driving,Chinese Journal of Mechanical Engineering,10.1186/s10033-021-00598-9,Springer,2021-08-23,"To reduce the discrepancy between the source and target domains, a new multi-label adaptation network (ML-ANet) based on multiple kernel variants with maximum mean discrepancies is proposed in this paper. The hidden representations of the task-specific layers in ML-ANet are embedded in the reproducing kernel Hilbert space (RKHS) so that the mean-embeddings of specific features in different domains could be precisely matched. Multiple kernel functions are used to improve feature distribution efficiency for explicit mean embedding matching, which can further reduce domain discrepancy. Adverse weather and cross-camera adaptation examinations are conducted to verify the effectiveness of our proposed ML-ANet. The results show that our proposed ML-ANet achieves higher accuracies than the compared state-of-the-art methods for multi-label image classification in both the adverse weather adaptation and cross-camera adaptation experiments. These results indicate that ML-ANet can alleviate the reliance on fully labeled training data and improve the accuracy of multi-label image classification in various domain shift scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s10033-021-00598-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-021-05764-7,A dynamic discarding technique to increase speed and preserve accuracy for YOLOv3,Neural Computing and Applications,10.1007/s00521-021-05764-7,Springer,2021-08-01,"This paper proposes an acceleration technique to minimise the unnecessary operations on a state-of-the-art machine learning model and thus to improve the processing speed while maintaining the accuracy. After the study of the main bottlenecks that negatively affect the performance of convolutional neural networks, this paper designs and implements a discarding technique for YOLOv3-based algorithms to increase the speed and maintain accuracy. After applying the discarding technique, YOLOv3 can achieve a 22% of improvement in terms of speed. Moreover, the results of this new discarding technique were tested on Tiny-YOLOv3 with three output layers on an autonomous vehicle for pedestrian detection and it achieved an improvement of 48.7% in speed. The dynamic discarding technique just needs one training process to create the model and thus execute the approach, which preserves accuracy. The improved detector based on the discarding technique is able to readily alert the operator of the autonomous vehicle to take the emergency brake of the vehicle in order to avoid collision and consequently save lives.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-021-05764-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s10033-021-00568-1,Deep Learning Based Data Fusion for Sensor Fault Diagnosis and Tolerance in Autonomous Vehicles,Chinese Journal of Mechanical Engineering,10.1186/s10033-021-00568-1,Springer,2021-07-20,"Environmental perception is one of the key technologies to realize autonomous vehicles. Autonomous vehicles are often equipped with multiple sensors to form a multi-source environmental perception system. Those sensors are very sensitive to light or background conditions, which will introduce a variety of global and local fault signals that bring great safety risks to autonomous driving system during long-term running. In this paper, a real-time data fusion network with fault diagnosis and fault tolerance mechanism is designed. By introducing prior features to realize the lightweight network, the features of the input data can be extracted in real time. A new sensor reliability evaluation method is proposed by calculating the global and local confidence of sensors. Through the temporal and spatial correlation between sensor data, the sensor redundancy is utilized to diagnose the local and global confidence level of sensor data in real time, eliminate the fault data, and ensure the accuracy and reliability of data fusion. Experiments show that the network achieves state-of-the-art results in speed and accuracy, and can accurately detect the location of the target when some sensors are out of focus or out of order. The fusion framework proposed in this paper is proved to be effective for intelligent vehicles in terms of real-time performance and reliability.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s10033-021-00568-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13007-021-00761-2,Prediction of plant-level tomato biomass and yield using machine learning with unmanned aerial vehicle imagery,Plant Methods,10.1186/s13007-021-00761-2,BioMed Central,2021-07-15,"Background The objective of this study is twofold. First, ascertain the important variables that predict tomato yields from plant height (PH) and vegetation index (VI) maps. The maps were derived from images taken by unmanned aerial vehicles (UAVs). Second, examine the accuracy of predictions of tomato fresh shoot masses (SM), fruit weights (FW), and the number of fruits (FN) from multiple machine learning algorithms using selected variable sets. To realize our objective, ultra-high-resolution RGB and multispectral images were collected by a UAV on ten days in 2020’s tomato growing season. From these images, 756 total variables, including first- (e.g., average, standard deviation, skewness, range, and maximum) and second-order (e.g., gray-level co-occurrence matrix features and growth rates of PH and VIs) statistics for each plant, were extracted. Several selection algorithms (i.e., Boruta, DALEX, genetic algorithm, least absolute shrinkage and selection operator, and recursive feature elimination) were used to select the variable sets useful for predicting SM, FW, and FN. Random forests, ridge regressions, and support vector machines were used to predict the yield using the top five selected variable sets. Results First-order statistics of PH and VIs collected during the early to mid-fruit formation periods, about one month prior to harvest, were important variables for predicting SM. Similar to the case for SM, variables collected approximately one month prior to harvest were important for predicting FW and FN. Furthermore, variables related to PH were unimportant for prediction. Compared with predictions obtained using only first-order statistics, those obtained using the second-order statistics of VIs were more accurate for FW and FN. The prediction accuracy of SM, FW, and FN by models constructed from all variables (rRMSE = 8.8–28.1%) was better than that from first-order statistics (rRMSE = 10.0–50.1%). Conclusions In addition to basic statistics (e.g., average and standard deviation), we derived second-order statistics of PH and VIs at the plant level using the ultra-high resolution UAV images. Our findings indicated that our variable selection method reduced the number variables needed for tomato yield prediction, improving the efficiency of phenotypic data collection and assisting with the selection of high-yield lines within breeding programs.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-021-00761-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10664-021-09982-4,Can Offline Testing of Deep Neural Networks Replace Their Online Testing?,Empirical Software Engineering,10.1007/s10664-021-09982-4,Springer,2021-07-05,"We distinguish two general modes of testing for Deep Neural Networks (DNNs): Offline testing where DNNs are tested as individual units based on test datasets obtained without involving the DNNs under test, and online testing where DNNs are embedded into a specific application environment and tested in a closed-loop mode in interaction with the application environment. Typically, DNNs are subjected to both types of testing during their development life cycle where offline testing is applied immediately after DNN training and online testing follows after offline testing and once a DNN is deployed within a specific application environment. In this paper, we study the relationship between offline and online testing. Our goal is to determine how offline testing and online testing differ or complement one another and if offline testing results can be used to help reduce the cost of online testing? Though these questions are generally relevant to all autonomous systems, we study them in the context of automated driving systems where, as study subjects, we use DNNs automating end-to-end controls of steering functions of self-driving vehicles. Our results show that offline testing is less effective than online testing as many safety violations identified by online testing could not be identified by offline testing, while large prediction errors generated by offline testing always led to severe safety violations detectable by online testing. Further, we cannot exploit offline testing results to reduce the cost of online testing in practice since we are not able to identify specific situations where offline testing could be as accurate as online testing in identifying safety requirement violations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10664-021-09982-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1134/S1054661821030068,Using Machine Learning Techniques to Detect Defects in Images of Metal Structures,Pattern Recognition and Image Analysis,10.1134/S1054661821030068,Springer,2021-07-01,"Abstract This paper is devoted to studying the capabilities of modern neural networks in image processing for solving the problem of monitoring the state of steel and reinforced concrete structures. The article presents a method for solving monitoring problems based on the use of a combination of several neural networks focused on recognizing a fragment of a structure and parts of a structure. Methods for training neural networks on small training samples are proposed. The results of the operation of the algorithms on real images are presented, showing the consistency and efficiency of the proposed solution.",http://link.springer.com/openurl/fulltext?id=doi:10.1134/S1054661821030068,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1134/S1054661821030238,Memory Consumption and Computation Efficiency Improvements of Viola–Jones Object Detection Method for Remote Sensing Applications,Pattern Recognition and Image Analysis,10.1134/S1054661821030238,Springer,2021-07-01,"Abstract In this paper, we consider object classification and detection problems. We propose an algorithm that is effective from the point of view of computational complexity and memory consumption. The proposed algorithm can be successfully used as a basic tool for building different remote sensing systems which are, in general, installed on UAVs. The algorithm is based on the Viola–Jones method. It is shown in the paper, that the Viola–Jones method is the most preferable approach to detect objects on-board UAVs, because it needs the least amount of memory and the number of computational operations to solve the object detection problem. To ensure sufficient accuracy, we use a modified feature: rectangular Haar-like features, calculated over the magnitude of the image gradient. To increase computational efficiency, the L1 norm was used to calculate the magnitude of the image gradient. To train orientation-independent complex classifier we use a more generic decision tree form of complex classifier instead of a cascade scheme. All mentioned improvements were evaluated during detection of the following objects: the PSN-10 inflatable life raft (an example of an object that is detected during rescue operations using UAVs), oil tank storage (such kind of objects are usually detected during the inspection of industrial infrastructure), and aircraft on an area of hardstand. The performance of the trained detectors was estimated on real data (including data obtained during the rescue operation of the trawler Dalniy Vostok and a subset of real images from the DOTA dataset).",http://link.springer.com/openurl/fulltext?id=doi:10.1134/S1054661821030238,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10677-021-10190-8,The Relativistic Car: Applying Metaethics to the Debate about Self-Driving Vehicles,Ethical Theory and Moral Practice,10.1007/s10677-021-10190-8,Springer,2021-07-01,"Almost all participants in the debate about the ethics of accidents with self-driving cars have so far assumed moral universalism. However, universalism may be philosophically more controversial than is commonly thought, and may lead to undesirable results in terms of non-moral consequences and feasibility. There thus seems to be a need to also start considering what I refer to as the “relativistic car” — a car that is programmed under the assumption that what is morally right, wrong, good, bad, etc. is determined by the moral beliefs of one’s society or culture. My investigation of this idea involves six steps. First, I explain why and how the moral universalism/relativism debate is relevant to the issue of self-driving cars. Second, I argue that there are good reasons to consider accident algorithms that assume relativism. Third, I outline how a relativistic car would be programmed to behave. Fourth, I address what advantages such a car would have, both in terms of its non-moral consequences and feasibility. Fifth, I address the relativistic car’s disadvantages. Finally, I qualify and conclude my considerations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-021-10190-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12144-021-01956-5,Plenty of blame to go around: Attributions of responsibility in a fatal autonomous vehicle accident,Current Psychology,10.1007/s12144-021-01956-5,Nature,2021-06-26,"Autonomous vehicles (AV) promise a reduction in the number of deadly traffic accidents. However, should accidents occur, attributions of responsibility are complicated by the fact that there is a human agent (driver) and a non-human agent (AV), and thus responsibility is likely shared between parties. In two studies, participants ( n  = 310 and n  = 260) read a vignette modeled after an actual lethal AV accident. Across four experimental conditions, participants were told that the human driver either needed to maintain oversight of the AV; did not need to maintain oversight of the AV; did not specify whether the human needed to maintain oversight of the AV; or the artificial intelligence was turned off and the human driver was fully in control. Participants assigned responsibility to the human driver, the AV company, the pedestrian, and an act of God, and determined whether the human driver and company CEO should be held criminally responsible in court. Consistent with previous research, the human driver was held most responsible regardless of oversight condition. However, companies were not absolved of responsibility, even when they required the human driver to maintain oversight of the AV. Implications of these findings for the introduction and legal regulation of AVs are discussed.",https://www.nature.com/articles/s12144-021-01956-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-021-01387-1,Improving Control Performance of Unmanned Aerial Vehicles through Shared Experience,Journal of Intelligent & Robotic Systems,10.1007/s10846-021-01387-1,Springer,2021-06-25,"This work proposes a novel approach for improving the control performance of Unmanned Aerial Vehicles (UAVs) through cooperative reinforcement learning. By sharing their experience, it is shown that multiple UAVs can work together to converge on a set of optimal Model Predictive Control (MPC) parameters faster than when working on their own. In order to benefit from this shared experience, the UAVs must coordinate their learning strategies. Here, we proposed a Leader-Follower approach, whereby the Leader ensures all trials are drawn from the same distribution and contribute to a common payoff game of Learning Automata. Experimental results show that this approach results in faster learning without any loss of performance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-021-01387-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13677-021-00246-6,Computation offloading strategy based on deep reinforcement learning for connected and autonomous vehicle in vehicular edge computing,Journal of Cloud Computing,10.1186/s13677-021-00246-6,Springer,2021-06-08,"Connected and Automated Vehicle (CAV) is a transformative technology that has great potential to improve urban traffic and driving safety. Electric Vehicle (EV) is becoming the key subject of next-generation CAVs by virtue of its advantages in energy saving. Due to the limited endurance and computing capacity of EVs, it is challenging to meet the surging demand for computing-intensive and delay-sensitive in-vehicle intelligent applications. Therefore, computation offloading has been employed to extend a single vehicle’s computing capacity. Although various offloading strategies have been proposed to achieve good computing performace in the Vehicular Edge Computing (VEC) environment, it remains challenging to jointly optimize the offloading failure rate and the total energy consumption of the offloading process. To address this challenge, in this paper, we establish a computation offloading model based on Markov Decision Process (MDP), taking into consideration task dependencies, vehicle mobility, and different computing resources for task offloading. We then design a computation offloading strategy based on deep reinforcement learning, and leverage the Deep Q-Network based on Simulated Annealing (SA-DQN) algorithm to optimize the joint objectives. Experimental results show that the proposed strategy effectively reduces the offloading failure rate and the total energy consumption for application offloading.",https://www.biomedcentral.com/openurl?doi=10.1186/s13677-021-00246-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11760-020-01800-6,Human activity recognition-based path planning for autonomous vehicles,"Signal, Image and Video Processing",10.1007/s11760-020-01800-6,Springer,2021-06-01,"Human activity recognition (HAR) is a wide research topic in a field of computer science. Improving HAR can lead to massive breakthrough in humanoid robotics, robots used in medicine and in the field of autonomous vehicles. The system that is able to recognise human and its activity without any errors and anomalies would lead to safer and more empathetic autonomous systems. During this research work, multiple neural networks models, with different complexity, are being investigated. Each model is re-trained on the proposed unique data set, gathered on automated guided vehicle (AGV) with the latest and the modest sensors used commonly on autonomous vehicles. The best model is picked out based on the final accuracy for action recognition. Best models pipeline is fused with YOLOv3, to enhance the human detection. In addition to pipeline improvement, multiple action direction estimation methods are proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11760-020-01800-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12665-021-09695-3,Predicting sediment deposition rate in check-dams using machine learning techniques and high-resolution DEMs,Environmental Earth Sciences,10.1007/s12665-021-09695-3,Springer,2021-05-14,"Sediments accumulated in check dams are a valuable measure to estimate soil erosion rates. Here, geographic information systems (GIS) and three machine learning techniques (MARS-multivariate adaptive regression splines, RF-random forest and SVM-support vector machine) were used, for the first time, to predict sediment deposition rate ( SR ) in check-dams located in six watersheds in SW Spain. There, 160 dry-stone check dams (~ 77.8 check-dams km^−2), accumulated sediments during a period that varied from 11 to 23 years. The SR was estimated in former research using a topographical method and a high-resolution Digital Elevation Model (DEM) (average of 0.14 m^3 ha^−1 year^−1). Nine environmental-topographic parameters were calculated and employed as predictors of the SR . The ability of MARS, RF and SVM was evaluated by using a five-fold cross-validation, considering the entire area (ALL), the check dams on the hillslope (HILL) and the valley-bottoms (VALLEY), as well as the three catchments (B, C and D) with the highest number of check dams. The accuracy of the models was assessed by the relative root mean square error ( RRMSE ) and the mean absolute error ( MAE ). The results revealed that RF and SVM are able to predict SR with higher and more stable accuracy than MARS. This is evident for the datasets ALL, VALLEY and D, where errors of prediction exhibited by MARS were from 44 to 77% ( RRMSE ) and from 37 to 62% ( MAE ) higher than those achieved by RF and SVM, but it also held for the datasets HILL and B where the difference of RRMSE and MAE was 7–10% and 12–17%, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12665-021-09695-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s13007-021-00750-5,Leaf area index estimation model for UAV image hyperspectral data based on wavelength variable selection and machine learning methods,Plant Methods,10.1186/s13007-021-00750-5,BioMed Central,2021-05-03,"Background To accurately estimate winter wheat leaf area index (LAI) using unmanned aerial vehicle (UAV) hyperspectral imagery is crucial for crop growth monitoring, fertilization management, and development of precision agriculture. Methods The UAV hyperspectral imaging data, Analytical Spectral Devices (ASD) data, and LAI were simultaneously obtained at main growth stages (jointing stage, booting stage, and filling stage) of various winter wheat varieties under various nitrogen fertilizer treatments. The characteristic bands related to LAI were extracted from UAV hyperspectral data with different algorithms including first derivative (FD), successive projections algorithm (SPA), competitive adaptive reweighed sampling (CARS), and competitive adaptive reweighed sampling combined with successive projections algorithm (CARS_SPA). Furthermore, three modeling machine learning methods including partial least squares regression (PLSR), support vector machine regression (SVR), and extreme gradient boosting (Xgboost) were used to build LAI estimation models. Results The results show that the correlation coefficient between UAV and ASD hyperspectral data is greater than 0.99, indicating the UAV data can be used for estimation of wheat growth information. The LAI bands selected by using different algorithms were slightly different among the 15 models built in this study. The Xgboost model using nine consecutive characteristic bands selected by CARS_SPA algorithm as input was proved to have the best performance. This model yielded identical results of coefficient of determination (0.89) for both calibration set and validation set, indicating a high accuracy of this model. Conclusions The Xgboost modeling method in combine with CARS_SPA algorithm can reduce input variables and improve the efficiency of model operation. The results provide reference and technical support for nondestructive and rapid estimation of winter wheat LAI by using UAV.",https://www.biomedcentral.com/openurl?doi=10.1186/s13007-021-00750-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/FITEE.1900637,Pre-training with asynchronous supervised learning for reinforcement learning based autonomous driving,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1900637,Springer,2021-05-01,"基于人定规则所设计的自动驾驶系统可能会因大规模相互耦合的规则而变得越来越复杂, 因此许多研究人员致力于探索基于学习的解决方案. 强化学习 (reinforcement learning, RL) 因其在各种顺序控制问题上的出色表现而被应用于自动驾驶系统设计. 然而, 基于RL的自动驾驶系统落地应用所面临的主要挑战是其初始性能不佳. 强化学习训练需要大量训练数据, 然后模型才能达到合理的性能要求, 这使得基于强化学习的模型不适用于现实环境, 尤其在数据昂贵的情况下. 本文为基于强化学习的端到端自动驾驶模型提出一种异步监督学习 (asynchronous supervised learning, ASL) 方法, 以解决在实际环境中训练基于强化学习模型时初始性能差的问题. 具体而言, 通过在多个驾驶演示数据集上并行且异步执行多个监督学习过程, 在异步监督学习预训练阶段引入先验知识。经过预训练后, 模型将被部署到真实车辆上进一步开展强化学习训练, 以适应实际环境并不断突破性能极限. 本文在赛车模拟器TORCS (The Open Racing Car Simulator) 上对所提出的预训练方法进行评估, 以验证该方法在改善强化学习训练阶段端到端自动驾驶模型的初始性能和收敛速度方面足够可靠. 此外, 建立一个实车验证系统, 以验证所提预训练方法在实车部署中的可行性. 仿真结果表明, 在有监督的预训练阶段使用一些演示, 可以显著提高强化学习训练阶段的初始性能和收敛速度. Rule-based autonomous driving systems may suffer from increased complexity with large-scale intercoupled rules, so many researchers are exploring learning-based approaches. Reinforcement learning (RL) has been applied in designing autonomous driving systems because of its outstanding performance on a wide variety of sequential control problems. However, poor initial performance is a major challenge to the practical implementation of an RL-based autonomous driving system. RL training requires extensive training data before the model achieves reasonable performance, making an RL-based model inapplicable in a real-world setting, particularly when data are expensive. We propose an asynchronous supervised learning (ASL) method for the RL-based end-to-end autonomous driving model to address the problem of poor initial performance before training this RL-based model in real-world settings. Specifically, prior knowledge is introduced in the ASL pre-training stage by asynchronously executing multiple supervised learning processes in parallel, on multiple driving demonstration data sets. After pre-training, the model is deployed on a real vehicle to be further trained by RL to adapt to the real environment and continuously break the performance limit. The presented pre-training method is evaluated on the race car simulator, TORCS (The Open Racing Car Simulator), to verify that it can be sufficiently reliable in improving the initial performance and convergence speed of an end-to-end autonomous driving model in the RL training stage. In addition, a real-vehicle verification system is built to verify the feasibility of the proposed pre-training method in a real-vehicle deployment. Simulations results show that using some demonstrations during a supervised pre-training stage allows significant improvements in initial performance and convergence speed in the RL training stage.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/FITEE.1900637,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42421-021-00038-z,Model Free Identification of Traffic Conditions Using Unmanned Aerial Vehicles and Deep Learning,Journal of Big Data Analytics in Transportation,10.1007/s42421-021-00038-z,Springer,2021-04-01,"The purpose of this paper is to provide a methodological framework to identify traffic conditions based on non-calibrated video recordings captured from unmanned aerial vehicles (UAV) using deep learning. To this end, we propose two complementary to each other approaches: (i) identify in real time, with minimal computational cost, traffic conditions, (ii) localize, classify vehicles and approximate traffic variables (volume, speed, density) on a road segment from video captured by UAVs. Both problems are formulated as classification problems and tackled using Convolutional Neural Networks (CNN). The use of pre-trained CNNs is also investigated. Both approaches are, then, analysed based on their accuracy and feasibility in implementation. Findings indicate that all models developed achieve a detection accuracy of 89% and higher. The CNN with the best performance can classify traffic conditions between constrained and unconstrained traffic with 91% accuracy higher than what a pretrained model achieved and with significantly faster training times. Furthermore, findings indicated that pretrained neural network for traffic localization was able to predict the position and type of vehicles with a precision of 0.91. Based on the fundamental traffic diagram, it was shown that the two approaches provide compatible results and a feasible representation of traffic on the study area. Finally, possible applications in the field of transportation and traffic monitoring are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42421-021-00038-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-020-03399-4,Improving the learning of self-driving vehicles based on real driving behavior using deep neural network techniques,The Journal of Supercomputing,10.1007/s11227-020-03399-4,Springer,2021-04-01,"Considering the significant advancements in autonomous vehicle technology, research in this field is of interest to researchers. To drive vehicles autonomously, controlling steer angle, gas hatch, and brakes needs to be learned. The behavioral cloning method is used to imitate humans’ driving behavior. We created a dataset of driving in different routes and conditions, and using the designed model, the output used for controlling the vehicle is obtained. In this paper, the learning of self-driving vehicles based on real driving behavior using deep neural network techniques (LSV-DNN) is proposed. We designed a convolutional network which uses the real driving data obtained through the vehicle’s camera and computer. The response of the driver during driving is recorded in different situations, and by converting the real driver’s driving video to images and transferring the data to an Excel file, obstacle detection is carried out with the best accuracy and speed using the Yolo algorithm version 3. This way, the network learns the response of the driver to obstacles in different locations and the network is trained with the Yolo algorithm version 3 and the output of obstacle detection. Then, it outputs the steer angle and amount of brake, gas, and vehicle acceleration. This study focuses on designing a convolutional network using behavioral cloning and motion planning of autonomous vehicle using a deep learning framework. Neural networks are effective systems for finding relationships between data, modeling, and predict new data or classify data. As a result Neural networks with input real data predict steer angle and speed for autonomous driving. The LSV-DNN is evaluated here via extensive simulations carried out in Python and TensorFlow environment. We evaluated the network error using the loss function. The results confirmed that our scheme is capable of exhibiting high prediction accuracy (exceeding 92.93%). In addition, our proposed scheme has high speed (more than 64.41%), low FPR (less than 6.89%), and low FNR (less than 3.95%), in comparison with the other approaches currently being employed. By comparing other methods which were conducted on the simulator’s data, we obtained good performance results for the designed network on the data from KITTI benchmark, the data collected using a private vehicle, and the data we collected.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-020-03399-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00542-019-04695-7,Machine learning based null allocation design for adaptive beamforming in unmanned aerial vehicle communications,Microsystem Technologies,10.1007/s00542-019-04695-7,Springer,2021-04-01,"In order to communicate with target unmanned aerial vehicles (UAVs), ground control stations (GCSs) typically adopt adaptive beamforming with high antenna gain and co-channel interference rejection. Multiple interfering signals arriving from different directions arise from other UAVs and other GCSs, and the beamformer installed in the home GCS will usually attempt to null unwanted signals from all these directions of arrival (DoAs) without analyzing the distribution of the angles of arrival. Consequently, the beamformer will fail to allocate nulls in some directions, and the signal-to-interference-plus-noise (SINR) performance of the home GCS is impaired. In this paper, a new approach to null allocation is proposed, based on machine learning using k -means clustering. The design first involves the collection of information about the DoAs and the corresponding received signal strengths of all the interfering signals into a two-dimensional dataset. Secondly, this dataset is broken down into clusters by using k -means clustering, and the cluster centroids are calculated. In each cluster, the interfering signal that has the shortest Euclidean distance to the centroid is identified as the approximated centroid. Only the approximated centroids are selected as input to the beamformer, with the aim that each complete cluster of interference sources can be nulled by allocating one null per cluster. To optimize the number of clusters k used in the null allocation process, the design adopts the particle swarm optimization technique to adaptively update the value of k to maximize the SINR at the home GCS. Simulation results show that our design yields a maximum SINR improvement of about 12 dB when compared to cases where no null allocation is considered. Moreover, our design also outperforms null steering in the UAV scenarios. Advantageously, this enhanced performance is obtained without the need for additional power amplification or hardware modification to the beamformer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00542-019-04695-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10657-020-09671-5,Grounding the case for a European approach to the regulation of automated driving: the technology-selection effect of liability rules,European Journal of Law and Economics,10.1007/s10657-020-09671-5,Springer,2021-04-01,"In the current paper, we discuss the need for regulation at EU level of Connected and Automated Driving solutions (henceforth CAD) based on multiple considerations, namely (i) the need for uniformity of criteria across European Member States, and (ii) the impact that regulation—or the absence of it—has on the proliferation of specific technological solutions. The analysis is grounded on legal and economic considerations of possible interactions between vehicles with different levels of automation, and shows how the existing framework delays innovation. A Risk-Management Approach, identifying one sole responsible party ex ante (one-stop-shop), liable under all circumstances—pursuant to a strict, if not absolute liability rule—is to be preferred. We analyse the solution adopted by some Member States in light of those considerations and conclude that none truly corresponds to a RMA approach, and differences will also cause market fragmentation. We conclude that because legal rules determine what kind of technological application is favoured over others—and thence they are not technology-neutral—uniformity across MSs is of essential relevance, and discuss possible policy approaches to be adopted at European level.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10657-020-09671-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11370-020-00343-6,RCNet: road classification convolutional neural networks for intelligent vehicle system,Intelligent Service Robotics,10.1007/s11370-020-00343-6,Springer,2021-04-01,"Vision-based techniques for intelligent vehicles in heterogeneous road environments are gaining significant attention from researchers and industrialists. Unfortunately, the mechanisms in this domain suffer from limited performance due to scene complexity, varying road structure, and improper illumination conditions. These challenging situations may lead an intelligent vehicle into dangerous situations such as collisions or road accidents and may cause higher mortality. The application of intelligent methods and other machine learning techniques for road surface classification is little explored in the existing literature. Thus, we propose a convolutional neural network-based road classification network (RCNet) for the accurate classification of road surfaces. This procedure includes the classification of five major categories of road surfaces: curvy, dry, ice, rough, and wet roads. The experimental results reveal the behavior of the proposed RCNet under various optimizer techniques. The standard performance evaluation measures have been used to test and validate the proposed method on the Oxford RobotCar dataset. RCNet achieves classification accuracy, precision, and sensitivity of 99.90%, and 99.97% of specificity. Results of implemented work are significantly higher than available state-of-the-art techniques and show accurate and effective performance in the complex road environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11370-020-00343-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12524-020-01231-3,Deep Learning Based Supervised Image Classification Using UAV Images for Forest Areas Classification,Journal of the Indian Society of Remote Sensing,10.1007/s12524-020-01231-3,Springer,2021-03-01,"Applications of unmanned aerial vehicles (UAVs) based remote sensing is increasing rapidly due to their advanced accessibility, capability for fast and easy deployment, capability for miniaturization of sensors and efficient collection of remotely-sensed data from relatively low altitudes. Recently, UAV data sets have been found to be quite useful for forest feature identification due to their relatively high spatial resolution. Several machine learning algorithms have been broadly used for remotely-sensed image classification. In remote sensing image classification, deep learning based methods can be considered quite effective techniques as they have achieved promising results. In this study, we have used deep learning based supervised image classification algorithm and images collected using UAV for classification of forest areas. The deep learning algorithm stacked Auto-encoder has been found to have tremendous potential regarding image classification and the assessment of forest coverage area. Our experimental results show that deep learning method provides better accuracy compared to other machine learning algorithms. Cross-validation showed that the overall accuracy of the deep learning method is about 93%. This study highlights the essential role that UAV observations and deep learning could play in the planning and management of forest areas which are often under the threat of deforestation and forest encroachment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12524-020-01231-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12667-020-00414-8,Application of AI in image recognition technology for power line inspection,Energy Systems,10.1007/s12667-020-00414-8,Springer,2021-02-04,"Artificial Intelligence (AI) is an energetic consideration in the electric power company for the scrutiny of the power lines in the forest area. The inspection is escorted to reduce input resources, less cost, rehabilitate electricity, and avoid overhead transmission and distribution lines. The imperfection in the electric companies is deliberate outage management, safety hazards, and diversified system, expensive and not flexible, which disturb the inspection in the forest areas. To recognize the images and status of the power lines, the Naïve Bayesian classifier with Automatic Classification (NBC-AC) algorithms is implemented to classify the observed probabilistic variables of inspection accurately. To monitor the images in long-distance, an Unmanned Aerial Vehicle–Hunter (UAV-H) is proposed to predict the different features of power lines. Hence NBC-AC algorithms with UAV-H systems are used to recognize and classify the characteristics of the power line images with 95% accuracy in the forest area for the electric power company. This encouraging technique contributes to high efficiency and accuracy with the best quality of images and the results were obtained for many AI applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12667-020-00414-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s43545-020-00043-z,In support of “no-fault” civil liability rules for artificial intelligence,SN Social Sciences,10.1007/s43545-020-00043-z,Nature,2021-01-11,"Civil liability is traditionally understood as indirect market regulation, since the risk of incurring liability for damages gives incentives to invest in safety. Such an approach, however, is inappropriate in the markets of artificial intelligence devices. In fact, according to the current paradigm of civil liability, compensation is allowed only to the extent that “someone” is identified as a debtor. However, in many cases it would not be useful to impose the obligation to pay such compensation to producers and programmers: the algorithms, in fact, can “behave” far independently from the instructions initially provided by programmers so that they can err despite no flaw in design or implementation. Therefore, application of “traditional” civil liability to AI may represent a disincentive to new technologies based on artificial intelligence. This is why I think artificial intelligence requires that the law evolves, on this matter, from an issue of civil liability into one of financial management of losses. No-fault redress schemes could be an interesting and worthy regulatory strategy in order to enable this evolution. Of course, such schemes should apply only in cases where there is no evidence that producers and programmers have acted under conditions of negligence, imprudence or unskillfulness and their activity is adequately compliant with scientifically validated standards.",https://www.nature.com/articles/s43545-020-00043-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-9774-9_58,Self-driving Car in Virtual Simulation: A Non-AI Approach,Emerging Technologies in Data Mining and Information Security,10.1007/978-981-15-9774-9_58,Springer,2021-01-01,"Over the last few decades, the self-driving car industry has come a long way and is going toward a future where human drivers might no longer exist. Researchers and engineers in motor companies are trying to innovate new ways to make and train self-driving cars to reduce the number of collisions. So, a lot of progress has been made but the cost of making them grew up with them. In this paper, we propose a simpler version of making and training a self-driving car in a simulated environment using a non-AI approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9774-9_58,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6546-9_39,The Categorization of Artificial Intelligence (AI) Based on the Autonomous Vehicles and Its Other Applications,Proceedings of International Conference on Communication and Artificial Intelligence,10.1007/978-981-33-6546-9_39,Springer,2021-01-01,"The artificial intelligence (AI) is creating the great impacts and revolution in the technological world, education world, industry world, and business world. The concepts in artificial intelligence are improving themselves day by day, and it is becoming a part of human’s everyday activities. It plays a major role in the human life, and the situation becomes the people cannot live without this AI. In this book chapter, the categorization of artificial intelligence based on the autonomous vehicles and its other applications is to be discussed in brief. The artificial intelligence technique is based on the artificial neural network (ANN), machine learning (ML), deep neural network (DNN), recurrent neural network (RNN), and convolution neural network (CNN). To implement these types of neural network, the system should use the programming languages like MATLAB programming, Python programming, R programming, etc.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6546-9_39,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-3383-9_19,Traffic Sign Recognition for Self-driving Cars with Deep Learning,Advanced Machine Learning Technologies and Applications,10.1007/978-981-15-3383-9_19,Springer,2021-01-01,"The purpose of this research was to create a model for an autonomous car in traffic sign recognition. A high-accuracy model is needed to analyze the signs. Previous studies have mainly been centered on European countries, and the models created in Europe are not applicable to American autonomous cars. The contributions of this paper are twofold. First, this study generated a dataset that was collected and annotated in order to establish a suitable model for the USA. The dataset was custom made and acquired by using camera footage that was converted into individual frames. The dataset was named Cyber Identity and Biometrics Lab Traffic Sign Dataset Version 1 (CIB TS V1). Then, it was annotated into different classes and labels with LabelIMG. With a customized program, we used the annotations to crop out images and categorized them. Second, the data was run through a deep learning algorithm called modified AlexNet. A lighter version of the AlexNet was used for our experiments. Results showed that the model achieved above 99% accuracy on the validation set.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-3383-9_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-76426-5_13,Neuroevolution vs Reinforcement Learning for Training Non Player Characters in Games: The Case of a Self Driving Car,Intelligent Technologies for Interactive Entertainment,10.1007/978-3-030-76426-5_13,Springer,2021-01-01,"The aim of this project is to compare two popular machine learning methods, a non-gradient-based algorithm such as neuro-evolution with a gradient-based reinforcement learning on an irregular task of training a car to self-drive around 3D circuits with varying complexity. A series of 3D circuits with a physics based car model were modeled using the Unity game engine. The data collected during evaluation show that neuro-evolution converges faster to a solution when compared to the reinforcement learning approach. However, when the reinforcement learning approach is allowed to train for long enough, it outperforms the neuro-evolution in terms of car speed and lap times achieved by the trained model of the car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-76426-5_13,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_11,Design of a Machine Learning-Based Self-driving Car,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_11,Springer,2021-01-01,"In this work, an algorithm of machine learning for self-driving car using udacity and unity self-driving car simulation software has been presented. Using the software, the car is driven on the simulated circuit having three cameras mounted on car hood which generate three images simultaneously and acceleration and de-acceleration of the car steering angle and brake. This method includes a behavior cloning approach and tries to replicate a behavior of human driver. For training the model, approximately, 18,000 training samples are required, and by using image augmentation technique, an increase in the data sample with few times is obtained, which leads to little robust simulated self-driving car.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4572-0_114,Artificial Intelligence in the Field of Driverless Cars,Big Data Analytics for Cyber-Physical System in Smart City,10.1007/978-981-33-4572-0_114,Springer,2021-01-01,"Nowadays, new technologies led by artificial intelligence and big data are booming, and have been widely used in many fields such as medical, transportation, military, and industrial. Automobile driving is one of the main application directions of artificial intelligence in the field of transportation. The purpose of this article is to explore the application of artificial intelligence technology in the field of driverless cars, with a view to bringing precision and real-time improvement to pedestrian detection in driverless systems. In this paper, based on the verification model and the pedestrian recognition algorithm based on the recognition model, a new recognition algorithm combining two types of models is proposed. After optimization and testing on the Market1501 pedestrian re-identification data set, it is concluded that the multi-camera test mAP of this algorithm is 72.55%, which greatly improves the detection accuracy compared with other mainstream re-identification algorithms. The research in this paper basically solves the problems of low accuracy, poor real-time performance and discontinuous cross-camera detection, which is beneficial to the successful application of pedestrian detection in unmanned driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4572-0_114,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-2712-5_6,Low-Altitude Unmanned Aerial Vehicle for Real-Time Greenhouse Plant Disease Monitoring Using Convolutional Neural Network,Soft Computing for Problem Solving,10.1007/978-981-16-2712-5_6,Springer,2021-01-01,"This study presents a novel approach to real-time plant infection detection and automatic pesticide spraying using an unmanned aerial vehicle (UAV) inside greenhouses. Greenhouse maintains controlled environments for plant growth, which is presently achieved by using conventional labor-driven methods that are proven to be inefficient causing lower yields. To overcome such difficulties and improve the yields, a multipurpose unmanned aerial vehicle capable of capturing vision data has been developed to detect infected areas and automatically spray useful chemicals based on the detection. Onboard the UAV is an edge device connected to environmental parameters sensors continuously uploading data to ThingSpeak. The IOT cloud platform provides real-time temperature and humidity of the precise location. In this research work, a fast-semantic segmentation algorithm called LinkNet-34 is employed for real-time segmentation of the infected region. The experimental results during manual flights indicate a detection accuracy of 0.922 (MIoU) with LinkNet-34. The UAV can achieve 14 min of flight-time while spraying 500 mm of pesticide over 42 m^2 area, during which time, a field map highlighting the infected regions is automatically generated and uploaded to the cloud for future analysis.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-2712-5_6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-68154-8_91,AutoMove: An End-to-End Deep Learning System for Self-driving Vehicles,Intelligent Computing and Optimization,10.1007/978-3-030-68154-8_91,Springer,2021-01-01,"End to End learning is a deep learning approach that has been used to solve complex problems that would usually be carried out by humans with great effect. A deep structure was designed within this study to simulate humans’ steering patterns in highway driving situations. The architecture of the network was based on image processing algorithm which is integrated with deep learning convolutional neural network (CNN). There are five aspects in this work, which enables the vehicle to detect the lanes, detect the speed of the vehicle, detect the angle of the road, recognize the objects on the road and predict the steering angle of the vehicle. A self-derived mathematical model is used to calculate the road angles for the prediction of vehicle’s steering angles. The model is trained on 2937 video frame samples and validated on 1259 samples with 30 epochs. The video of the local road was set as the output which will show the difference between actual steering angles and predicted steering angle. The experiments have been carried out in a newly built industrial park with suitable industry 4.0 standard design of urban smart development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-68154-8_91,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-77939-9_1,Deep Learning for Unmanned Autonomous Vehicles: A Comprehensive Review,Deep Learning for Unmanned Systems,10.1007/978-3-030-77939-9_1,Springer,2021-01-01,"In recent years, deep learning as a subfield of machine learning has gained increasing attention due to its potential advantages in empowering autonomous systems with the ability to automatically learn underlying features in data at different levels of abstractions, to build complex concepts out of simpler ones and to get better with experience without being explicitly programmed. This book chapter provides a comprehensive review on the applications of deep learning in unmanned autonomous vehicles. We focus on particular research efforts that employ deep learning techniques to endow autonomous vehicles with different cognitive functionality, following the cognitive cycle of autonomous vehicles. This cognitive cycle of Sense-Aware-Decide-Act-Adapt-Learn extends the deliberative cycle of Sense-Decide-Act by adding situation awareness, adaptation and learning capabilities to autonomous vehicles. Potential applications of deep learning and major challenges are highlighted in this chapter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77939-9_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-52624-5_14,"Precision Agriculture Using Advanced Technology of IoT, Unmanned Aerial Vehicle, Augmented Reality, and Machine Learning",Smart Sensors for Industrial Internet of Things,10.1007/978-3-030-52624-5_14,Springer,2021-01-01,"Agriculture is one of the primary processes for quality food production in the globe. Unfortunately, the productivity of agriculture is very low, and many factors affect the yield level of it. Precision agriculture (PA) is one of the solutions for the above problem. PA uses site-specific crop management concept based on measured data using sensors and data analytics to find the root cause of yield reduction. Precision agriculture automates farming which involves the collection of data and analysis of them for better decision-making to gain high yield and quality of the agricultural product. The agriculture system integrated with data analytics and machine learning is called as smart farming or smart agriculture The goal of smart agriculture is to develop a decision-making support system for farming management. The precision smart agriculture can be enhanced with the help of latest technologies of Internet of Technology (IoT), unmanned aerial vehicle (UAV), augmented reality (AR) system, and machine learning (ML) algorithms. This chapter focuses on the illustration and utilization of those advanced technologies for smart farming.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-52624-5_14,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60577-3_14,Providing Situational Awareness in the Control of Unmanned Vehicles,"Advances in Neural Computation, Machine Learning, and Cognitive Research IV",10.1007/978-3-030-60577-3_14,Springer,2021-01-01,"The article considers one of the aspects of the situational awareness problem for control systems of unmanned vehicles. We interpret this problem as getting information about the current situation in which, for example, an unmanned aerial vehicle (UAV) is operating. This information is required as source data for decision-making in the UAV behavior control process. One possible component of situational awareness is information about objects in the space surrounding the UAV. At the same time, it is important to know along which trajectories these objects move. Also, we need to predict the motion of the observed objects. We consider this task in the article as a formation example for one of the elements of situational awareness. To solve this problem, we prepare a data set using the FlightGear flight simulator. We extract from this set the training, validation, and test sets required to obtain a neural network that predicts the trajectory of the object being tracked. Then, based on the collected data that characterize the behavior of the desired object, we design a neural network model based on recurrent neural networks to solve the problem of predicting the trajectory of a dynamic object.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60577-3_14,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1483-5_23,A Deep Learning Approach for Autonomous Navigation of UAV,Futuristic Trends in Network and Communication Technologies,10.1007/978-981-16-1483-5_23,Springer,2021-01-01,"Unmanned Aerial Vehicle is an aircraft that operates and flies without a human pilot. It can reach at places where humans may not reach easily, such as search and rescue operations, earthquake mapping and flood mapping. It is additionally valuable for autonomous tasks such as the delivery of any item and target tracking which requires self-governing navigation. Motivated by the mentioned applications, in this paper we present a deep learning model for self-governing navigation of UAV. Our model exploits transfer learning from a well-known network architecture called MobileNet and it is trained on a dataset of images, collected from the various indoor environments. From an image, the model classifies actions such as either to go forward or to stop. Furthermore, after some experiments and results, we infer that among all Convolution Neural Network (CNN) architectures, the MobileNet architecture is ideal and appropriate for our purposed approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1483-5_23,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60577-3_19,Deep Neural Networks for Ortophoto-Based Vehicle Localization,"Advances in Neural Computation, Machine Learning, and Cognitive Research IV",10.1007/978-3-030-60577-3_19,Springer,2021-01-01,"Navigation of unmanned vehicle especially using orthophoto is a topic of active research. This paper is dedicated to study of different methods of orthophoto-based localization methods. For this task new dataset was created. It consists of pairs of ground level and bird’s eye view images collected on vehicle test site of the technology contest Up Great “Winter City”. Different deep network approaches to localization were used: 1) embedding-based, 2) based on synthesis of bird’s eye view using Pix2pix conditional generative adversarial network and masked cross-correlation in map subwindow. The second approach has demonstrated good applicability for the proposed dataset. Mean absolute error of localization on known scenes reached 1 m. The average total time of bird’s eye view generation and subsequent localization is from 0.1 s to 0.2 s. This is an acceptable quality for the task solution and its further use as part of the navigation systems of unmanned vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60577-3_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-8377-3_18,Behavioral Cloning for Self-driving Cars Using Deep Learning,"Proceedings of International Conference on Big Data, Machine Learning and their Applications",10.1007/978-981-15-8377-3_18,Springer,2021-01-01,"We are presenting a model for self-driving car simulator provided by Udacity as an open-source simulator. We will then use the simulator to create our own training data for our model which will be driving a car through training mode on its track in the simulator. We are taking images at each instance of the drive. These images are used as a training dataset, and the labels are steering angle for each specific image at that instance. We will then input all those images to our Nvidia’s convolutional neural network model and allow it to learn how to drive autonomously by learning from our behavior as the manual driver. Our main variable is the steering angle which our model learns to adjust at any given instance. Now, as our model is perfectly trained, we use autonomous mode to find the performance of our model by driving the car autonomously.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-8377-3_18,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5329-5_30,Object and Obstacle Detection for Self-Driving Cars Using GoogLeNet and Deep Learning,Artificial Intelligence Techniques for Advanced Computing Applications,10.1007/978-981-15-5329-5_30,Springer,2021-01-01,"Self-driving cars are the latest innovation in which the car runs by itself. The self-driving cars can be called as autonomous cars. This involves many technologies like artificial intelligence, machine learning and deep learning. When coming to the self-driving cars, the main aspect which it needed to be taken care of is the obstacle detection and the object detection. The object detection by a car in more simpler words object recognition process done by a machine which involves the concepts of machine learning and deep learning. Deep learning helps in achieving the object and the obstacle detection. There are various algorithms which help in the object detection like artificial neural network, convolutional neural network, AlexNet, VGG Net, GoogleNet, etc. GoogleNet is the CNN architecture which makes the image recognition an easier task. For the self-driving cars, obstacle and object detection GoogLeNet are not much addressed in the recent works. So, it can be considered as a latest technology. In this paper, the recent works about the self-driving cars and object detection and obstacle detection and the future scope of it are discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5329-5_30,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65661-4_4,Enhanced End-to-End System for Autonomous Driving Using Deep Convolutional Networks,Deep Learning and Big Data for Intelligent Transportation,10.1007/978-3-030-65661-4_4,Springer,2021-01-01,"The emergence of autonomous cars in today’s world makes it imperative to develop superlative steering algorithms. Deep convolutional neural networks are widely adopted in vision problems for their adept nature to classify images. End-to-end models have acted as an excellent substitute for handcrafted feature extraction. This chapter’s proposed system, which comprises of steering angle prediction, road detection, road centering, and object detection, is a facilitated version of an autonomous steering system over just considering a single-blind end-to-end architecture. The benefits of proposing such an algorithm for the makeover of existing cars include reduced costs, increased safety, and increased mobility.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65661-4_4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-65283-8_22,Detection of Scenes Features for Path Following on a Local Map of a Mobile Robot Using Neural Networks,Recent Research in Control Engineering and Decision Making,10.1007/978-3-030-65283-8_22,Springer,2021-01-01,"This article describes a software package for analyzing images from the camera of a mobile robot using neural networks. A key feature of the proposed solution is the model that generates recommendations for the robot about the direction of the further movement. This model receives raw video frames from the camera and generates a target rotation angle for the robot relative to the central axis of the robot, which must be followed at the next time in the control loop. Such a control loop is executed with a certain frequency in order to achieve the continuous adjustment of the robot’s driving direction to avoid collision with obstacles. A key feature of the proposed method is the high processing speed of video frames and acceptable quality. These characteristics are achieved due to the simple architecture of the neural network, without reinforcement learning, which is commonly used in robotics. The designed module can be used in addition to the existing navigation systems of a mobile robot.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65283-8_22,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6984-9_40,Attitude Control in Unmanned Aerial Vehicles Using Reinforcement Learning—A Survey,Congress on Intelligent Systems,10.1007/978-981-33-6984-9_40,Springer,2021-01-01,"Agarwal, Varun Ranjan Tewari, Rajiv Unmanned Aerial Vehicles (UAVs) have great potential in various fields. With ongoing research, the day is not far when they would be directly impacting our lives. The promise of deep learning techniques like reinforcement learning has created a window of opportunity for their use in a plethora of tasks, like the attitude control problem of UAVs. Attitude of a UAV is the angle at which it is flying relative to the ground. Attitude control is the management of the orientation of a UAV with respect to the inertial frame. In this paper, we have surveyed reinforcement learning algorithms to learn attitude control of UAVs and be able to take decisions in unforeseen circumstances. Reinforcement learning is the branch of deep learning where there is no human intervention in training the model. Instead, the system learns over time by trial and error. Since navigation in the air presents scenarios that may be new and unexpected for a UAV, reinforcement learning presents a viable option for their use in attitude control in them.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6984-9_40,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70665-4_96,Semantic 3D Scene Classification Based on Holoscopic 3D Camera for Autonomous Vehicles,"Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery",10.1007/978-3-030-70665-4_96,Springer,2021-01-01,"An autonomous vehicle navigates by perceiving the environment through the sensors and acting on the received data by making sense of the surroundings. In this paper, innovative holoscopic 3D scene classification based on the single aperture holoscopic 3D camera is proposed to recognise continuous 3D scene of environment. The deep learning network AlexNet is used to evaluate the proposed approach, and the outcome exhibits promising results compared to 2D images.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70665-4_96,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1244-2_29,Obstacle Avoidance for Aerial Vehicles in Autonomous Navigation,International Virtual Conference on Industry 4.0,10.1007/978-981-16-1244-2_29,Springer,2021-01-01,"Obstacle avoidance is the back bone of autonomous navigation as it enables vehicles to reach desired location avoiding hurdles in the path. It is one of the ongoing challenging researches in the arena of cyber physical systems. In this article, comparison of various obstacle avoidance algorithms such as Artificial Potential Field (APF) approach, Vector Field Histogram (VFH) approach, Bubble Band approach, Mounted Sonar approach, Dist-Bug approach, bug-1 and bug-2 approach and Tangent Bug approach has been addressed. The main objective is obstacle avoidance, where obstacle can be in the form of radars or any other type of equipment. A novel obstacle avoidance procedure for low-altitude flying vehicles (Static Obstacle Avoidance) and high-altitude flying vehicle (Dynamic Obstacle Avoidance) has been proposed using A-Star and Deep Q-Network Reinforcement Learning techniques, respectively. Test bed has been created considering object model, sensor model, obstacle environment and controller. Implementation of the same has been done through visualization using Pygame for A-Star approach and Director for Deep Q-Network Reinforcement Learning.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1244-2_29,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-70665-4_119,Machine Learning Based Approach for Weed Detection in Chilli Field Using RGB Images,"Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery",10.1007/978-3-030-70665-4_119,Springer,2021-01-01,"Smart farming has become imperative these days due to competition, and use of Unmanned Aerial Vehicle (UAV) imagery is becoming an integral part of the process. Machine learning techniques have been successfully applied to capture UAV imagery of various spectral bands to identify weed infestations. Identification of weeds in chilli crop is a challenging task. In this paper, RGB images captured by drones have been used to detect weed in chilli field. This task has been addressed through orthomasaicking of images, feature extraction, labelling of images to train machine learning algorithms, and use of unsupervised learning with random forest for classification. MATLAB has been used for all computations and out-of-bag accuracy achieved for identifying weeds is 96 $$\%$$ % .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-70665-4_119,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-0041-8_16,It is not a Driverless Car!—A Framework for Interacting with the AI in Autonomous Vehicles,Design for Tomorrow—Volume 1,10.1007/978-981-16-0041-8_16,Springer,2021-01-01,"With autonomous vehicles (AV) fast becoming a reality, in the not so distant future, streets are expected to be populated with these intelligent autonomous beings ferrying passengers alongside human-driven vehicles and pedestrians. The bulk of research today seems to focus on setting up the required software and hardware systems, alongside policies and transportation infrastructure. A gap is seen to exist within the realm where the passengers and vehicle AI interface. This calls for research in developing capabilities for the AI in AVs a form of social transactions that are more familiar to human beings, taking cues from natural conversations and body language signals. The reason for this is that autonomous vehicles not only need to perform navigational duties, but also need to communicate, respond, and reciprocate in a social manner. This would give the AI the dignity they deserve when performing their functions, as performing these activities accords with the capabilities of a self-aware, intelligent being. This paper proposes a framework for future communication between autonomous vehicles and humans, focusing on the working relationship between the vehicle and its passengers taking references of the communications theory related to human-to-human interactions, extrapolating to human-to-AI interaction within the AV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0041-8_16,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-7502-7_7,Anti Intelligent Mine Unmanned Ground Vehicle Based on Reinforcement Learning,Data Mining and Big Data,10.1007/978-981-16-7502-7_7,Springer,2021-01-01,"In recent years, with the rapid development of military technology and the evolution of battlefield mines, intelligent mines are the important embodiment of active attack mines. In the future, unmanned vehicles need to chase and capture intelligent mines, improve the efficiency of mine clearance, and reduce the casualties of soldiers. Therefore, it is necessary to study how to improve the efficiency of unmanned ground vehicle pursuit. Among them, the game method of pursuit and evasion between intelligent mines and unmanned ground vehicles based on reinforcement learning in the 2D simulation environment can effectively achieve this goal. The trained intelligent mines have active attack ability, unmanned ground vehicles have basic mine clearance ability, and the success rate of intelligent mine blasting is as high as 90%. In addition, unmanned ground vehicles can also effectively defend against the active attack of intelligent mines, and the defense success rate is also as high as 90%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-7502-7_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71187-0_40,In-Car State Classification with RGB Images,Intelligent Systems Design and Applications,10.1007/978-3-030-71187-0_40,Springer,2021-01-01,"In the next years, shared autonomous vehicles are going to be a new reality. The absence of the human driver is going to create a new paradigm for in-car safety. This paper addresses this problematic by presenting a monitoring system capable of classifying the state of the vehicle interior, i.e. good or bad condition. We propose the use of classifiers, with RGB images, to infer the in-car cleanliness state. Moreover, 18 state-of-the-art classifiers were trained and evaluated, using pre-trained models. To be able to train and evaluate these approaches an in-car dataset was created with 3488 samples from 135 cars, and then split in 2439 train, 351 validation and 689 test RGB images. From all the evaluated, ResNet-18 showed the best results, achieving an average accuracy of 91.24% 123 Hz.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71187-0_40,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-1086-8_42,Crop Classification from UAV-Based Multi-spectral Images Using Deep Learning,Computer Vision and Image Processing,10.1007/978-981-16-1086-8_42,Springer,2021-01-01,"This work explores the suitability of various deep convolutional neural network (CNN) architectures for semantic segmentation of agricultural crops such as cotton, maize etc. from multi-spectral UAV (unmanned aerial vehicle) data. Initially, the UAV data were preprocessed and training samples for each crop type were manually annotated from multiple UAV scenes. Different CNN architectures such as U-Net, SegNet and PSPNet (Pyramid Scene Parsing Network) were trained with various combinations of input spectral bands along with select band derived indices such as NDVI (Normalized Difference Vegetation Index) and EVI (Enhanced Vegetation Index) as additional features. The experimental results indicated that inclusion of NIR (near-infrared) band and NDVI in the input data yielded high segmentation accuracy of more than 90%. U-Net proved to be the best among the three architectures with 97% overall accuracy while dealing with three classes separation problem. This study demonstrated the scope of deep neural network based semantic segmentation techniques in crop classification from multi-spectral UAV data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-1086-8_42,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-93420-0_16,Construction of Brazilian Regulatory Traffic Sign Recognition Dataset,"Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications",10.1007/978-3-030-93420-0_16,Springer,2021-01-01,"In this article, we present the Brazilian Regulatory Traffic Sign Recognition Dataset, following the style of the CIFAR10 dataset. A convolutional neural network is also proposed to recognize and identify these traffic signs as a possible aid for ADAS (Advanced Driver Assistance Systems). The developed architecture has thirteen layers, selected after attempts to search for a sufficiently efficient organization. CNN used the RMSProp optimizer, a variant of the stochastic gradient descent technique (SGD), reaching 99.31% accuracy in training and 93.73% in the validation set. This document covers the dataset development process, convolutional neural network architecture, discussions about operation and results.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-93420-0_16,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10489-020-01827-9,Deep learning and control algorithms of direct perception for autonomous driving,Applied Intelligence,10.1007/s10489-020-01827-9,Springer,2021-01-01,"We propose an end-to-end machine learning model that integrates multi-task (MT) learning, convolutional neural networks (CNNs), and control algorithms to achieve efficient inference and stable driving for self-driving cars. The CNN-MT model can simultaneously perform regression and classification tasks for estimating perception indicators and driving decisions, respectively, based on the direct perception paradigm of autonomous driving. The model can also be used to evaluate the inference efficiency and driving stability of different CNNs on the metrics of CNN’s size, complexity, accuracy, processing speed, and collision number, respectively, in a dynamic traffic. We also propose new algorithms for controllers to drive a car using the indicators and its short-range sensory data to avoid collisions in real-time testing. We collect a set of images from a camera of The Open Racing Car Simulator in various driving scenarios, train the model using this dataset, test it in unseen traffics, and find that it outperforms earlier models in highway traffic. The stability of end-to-end learning and self driving depends crucially on the dynamic interplay between CNN and control algorithms. The source code and data of this work are available on our website, which can be used as a simulation platform to evaluate different learning models on equal footing and quantify collisions precisely for further studies on autonomous driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10489-020-01827-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51992-6_24,Priority Levels and Danger in Usage of Artificial Intelligence in the World of Autonomous Vehicle,Soft Computing Applications,10.1007/978-3-030-51992-6_24,Springer,2021-01-01,"Nowadays more and more vehicles are on the road wherein driver assistance functions are available but there are some which are capable for self-driving in special conditions. At the same time, autonomous vehicles have been developing in numerous country, so, in a latter part of the development, these vehicles will show up on the roads en masse. In 10 years, autonomous vehicles will spread on roads, because numerous producer works on its developing and testing. The common is that they all use, as base of the system, Artificial Intelligence. Some kind of priority needed by situations in traffic for example, cars should provide a clear way for ambulance in case of emergency. A recommendation had been made for this hierarchy in the article to make safer the transport. Behaviour of AI depends on its teaching method – that was used when it had been programmed – and it could be a major risk for human in the vehicle. The article highlights teaching methods, which could rush people into danger. Before integrity of AI into the vehicle, its behaviour and teaching method should be widely tested. Considering development of this area lately, vehicle of state leaders and its escort could be autonomous also, in the future. The article contains an analysis about this theme to point out its disadvantages and suggest to avoid usage of fully autonomous vehicles in case of state leaders.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51992-6_24,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77626-8_35,Drone-Based AI and 3D Reconstruction for Digital Twin Augmentation,Social Computing and Social Media: Experience Design and Social Network Analysis,10.1007/978-3-030-77626-8_35,Springer,2021-01-01,"Digital Twin is an emerging technology at the forefront of Industry 4.0, with the ultimate goal of combining the physical space and the virtual space. To date, the Digital Twin concept has been applied in many engineering fields, providing useful insights in the areas of engineering design, manufacturing, automation, and construction industry. While the nexus of various technologies opens up new opportunities with Digital Twin, the technology requires a framework to integrate the different technologies, such as the Building Information Model used in the Building and Construction industry. In this work, an Information Fusion framework is proposed to seamlessly fuse heterogeneous components in a Digital Twin framework from the variety of technologies involved. This study aims to augment Digital Twin in buildings with the use of AI and 3D reconstruction empowered by unmanned aviation vehicles. We proposed a drone-based Digital Twin augmentation framework with reusable and customisable components. A proof of concept is also developed, and extensive evaluation is conducted for 3D reconstruction and applications of AI for defect detection.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77626-8_35,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-72065-0_18,Artificial Intelligence Techniques in Smart Cities Surveillance Using UAVs: A Survey,Machine Intelligence and Data Analytics for Sustainable Future Smart Cities,10.1007/978-3-030-72065-0_18,Springer,2021-01-01,"The security and urbanization challenge is expected to rise to 90% by 2050, and to leverage existing resources, technology is the solitary means to cope with this anticipated raise in entail. The Smart City is focused on the smooth convergence of Information and Communication Technology with the most technological innovations like well-connected home and equipment. Smart city augments the lifestyle of its residents by providing efficacious infrastructure and enhanced security. Surveillance is a recurring and monotonous assignment that descends the performance of human guards when continued for a longer period of time. Unmanned Aerial Vehicles (UAVs) or Drones can be deployed as security cameras to augment human guards. It can be deployed to track intruders, monitor unusual activities such as theft, violence and unprecedented corona-virus pandemic scenarios. UAV based visual surveillance in Smart cities, produces a huge amount of multimedia data. The need to process and analyze the data automatically in real-time is critical. Artificial Intelligence and Deep learning imitates human intelligence and provides excellent analytical capabilities to learn about complex data obtained in real environments. The integrated solution of Deep learning technology with the UAVs an electronic eye-in-the-sky has leveraged the capability of detection, recognition and deterrence in a scalable surveillance system. A comprehensive review on the potential benefits of UAVs and its applications for surveillance in smart cities has been presented. This chapter elaborates seamless integration of UAVs and Deep Learning technologies solutions for smart city surveillance. The paper concludes with a description of main challenges for the application of UAVs in deep learning solutions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-72065-0_18,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-53980-1_112,3D Modeling System of Lidar Point Cloud Processing Algorithm Based on Artificial Intelligence,2020 International Conference on Applications and Techniques in Cyber Intelligence,10.1007/978-3-030-53980-1_112,Springer,2021-01-01,"With the continuous expansion of the application field of artificial intelligence-based unmanned vehicles and the rapid development of lidar scanning technology, the application of lidar gradually spread to many artificial intelligence-based unmanned vehicles such as environmental perception, augmented reality, and environmental modeling Technology area. Therefore, the research of lidar in the application of artificial intelligence-based unmanned vehicles has become an inevitable trend in the field of unmanned vehicles. At the same time, the research of lidar data processing technology is of great significance to the development of artificial intelligence unmanned vehicles. This article is based on the research of lidar-based 3D environment modeling technology based on lidar. The research content mainly involves vehicle lidar point cloud 3D environment modeling method, adaptive lidar point cloud data matching algorithm, lidar point cloud-based 3D map modeling application. Through theoretical research and experimental verification of related technical issues, an in-depth study of the three-dimensional terrain modeling technology of unmanned vehicles based on artificial intelligence based on lidar is carried out. This paper proposes a three-dimensional environment modeling method for vehicle lidar point cloud. First, preprocessing processes such as data filtering and terrain segmentation are performed on the original lidar data, and then a three-dimensional geometric model of the environment including surface obstacles and terrain is established through data interpolation and gridding. The verification of the measured data on the typical environment shows the effectiveness of the method.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53980-1_112,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-54173-6_11,Designing Robots for the Battlefield: State of the Art,"Robotics, AI, and Humanity",10.1007/978-3-030-54173-6_11,Springer,2021-01-01,"There is currently a global arms race for the development of artificial intelligence (AI) and unmanned robotic systems that are empowered by AI (AI-robots). This paper examines the current use of AI-robots on the battlefield and offers a framework for understanding AI and AI-robots. It examines the limitations and risks of AI-robots on the battlefield and posits the future direction of battlefield AI-robots. It then presents research performed at the Johns Hopkins University Applied Physics Laboratory (JHU/APL) related to the development, testing, and control of AI-robots, as well as JHU/APL work on human trust of autonomy and developing self-regulating and ethical robotic systems. Finally, it examines multiple possible future paths for the relationship between humans and AI-robots.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-54173-6_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-69069-4_36,Collaborative Interference Source Search and Localization Based on Reinforcement Learning and Two-Stage Clustering,Wireless and Satellite Systems,10.1007/978-3-030-69069-4_36,Springer,2021-01-01,"Exploiting unmanned aerial vehicles (UAVs) to locate the position of interferences has attracted intensive research interests, due to UAVs’ flexibility and the feature of suffering less multi-path interference. However, in order to find the position of an interference source, off-the-shelf Q-learning-based schemes require the UAV to keep searching until it arrives at the target. This obviously degrades time efficiency of localization. To balance the accuracy and the efficiency of searching and localization, this paper proposes a collaborative search and localization approach, where search and remote localization are iteratively performed with a swarm of UAVs. For searching, a low-complexity reinforcement learning algorithm is proposed to decide the direction of flight (in every time interval) for each UAV. In the following remote localization phase, a two-stage clustering algorithm is proposed to estimate the position of the interference source, by processing intersections of the extensions of UAVs’ trajectories. Numerical results reveal that in the proposed collaborative search and localization scheme, the proposed reinforcement-learning-based searching can benefit the collaborative localization, in terms of the accuracy of localization. Moreover, compared to the Q-learning-based approach, the proposed approach enables remote localization and can well balance accuracy, the robustness and time efficiency of localization.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69069-4_36,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-66042-0_12,The Deep Learning Method for Image Segmentation to Improve the Efficiency of Data Processing Without Compromising the Accuracy of an Autonomous Driving Country-Road Pilot System After Image Classification,Towards Connected and Autonomous Vehicle Highways,10.1007/978-3-030-66042-0_12,Springer,2021-01-01,"Autonomous driving requires object recognition for vehicles to automatically generate a path according to their recognised environment, the conditions of which have different dims of light, from daylight to night. High-resolution images require high amounts of expensive storage as automated driving moves from urban to rural areas, where driving at night and recognising traffic signs and lights are necessary for all light conditions. Therefore, a reliable source of input, allowing for the intended performance of an autonomous driving system such as the country or rural road pilot, is necessary for adequate deployment of its functionality in its target environment. For quality criteria such as intended performance, functional reliability, safety, and correct driving behaviour are to be ensured; accuracy metrics can be a substantial contribution to the product quality criteria. Furthermore, since autonomous technology faces the challenge of being costly, thus any new innovative methods for saving costs, without comprising quality, would help to develop and enhance the chance of this developing technology being installed into more advanced automated or autonomous driving vehicles once the product safety as quality criteria can be validated on target roads. Part of this work’s limitation was that only a simulation environment was used for testing the image processing and autonomous driving accuracy models. Through research, certain algorithms were found that may be used in storage size minimisation for taking a high-resolution image; its size had to be reduced for use without compromising accuracy in the classification process. Further research in their validation may be necessary.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-66042-0_12,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-71998-2_8,Location Intelligence Powered by Machine Learning Automation for Mapping Malaria Mosquito Habitats Employing an Unmanned Aerial Vehicle (UAV) for Implementing “Seek and Destroy” for Commercial Roadside Ditch Foci and Real Time Larviciding Rock Pit Quarry Habitats in Peri-Domestic Agro-Pastureland Ecosystems in Northern Uganda,Sensemaking for Security,10.1007/978-3-030-71998-2_8,Springer,2021-01-01,"Public health emergencies stemming from infectious disease outbreaks is creating a serious threat to global health security. For example, climate change and extreme weather events threaten to alter and affect geographic areas pertaining to disease vulnerability, such as greater risks of mosquito-borne diseases (dengue, malaria, yellow fever and Zika). The emergence of these disease outbreaks and their influence globally has sparked a renewed attention on global health security and the application of location intelligence. Persistent outbreaks characterize a ‘new normal’ that points to major deficiencies in preparedness, response and recovery initiatives. Malaria mosquito An. gambiae s.l., arabiensis s.s. and funestus s.s represent the main malaria mosquito vectors in sub-Saharan Africa. As reported in WHO (Jacob et al. in Open Remote Sensing 17:11–24, [ 1 ]), Malaria is a life-threatening disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes. It is preventable and curable. In 2019, there were an estimated 229 million cases of malaria worldwide. The estimated number of malaria deaths stood at 409,000 in 2019. Children aged under 5 years are the most vulnerable group affected by malaria; in 2019, they accounted for 67% (274,000) of all malaria deaths worldwide. The WHO African Region carries a disproportionately high share of the global malaria burden. In 2019, the region was home to 94% of malaria cases and deaths. Sensemaking lies at the heart of location intelligence. Location intelligence is defined as the collection and analysis of geospatial data that are transformed into strategic insights to support operations. Weick (Krizhevsky et al. in Advances in Neural Information Processing Systems, pp 1097–1105, [ 2 ]) refers to sensemaking in terms of ‘…how we structure the unknown so as to be able to act in it. Sensemaking involves coming up with a plausible understanding—a map—of a shifting world; testing this map with others through data collection, action, and conversation; and then refining, or abandoning, the map depending on how credible it is’ (Lin et al. in Proceedings of the IEEE International Conference on Computer Vision 2017, pp. 2980–2988, [ 3 ]). The application of machine learning algorithms are emerging as key public health intelligence approaches to support tactical, operational and strategic sensemaking. Recent advances that identify the reflective signatures of active mosquito breeding sites, and their temporal evolution, have made predictive algorithms possible to search and identify previously unidentified larval habitats from a Unmanned Aerial Vehicle (UAV), and monitor their activity in real time. Spectral signature is the variation of reflectance of a material (i.e., emittance as a function of wavelength) ( www.esri.com ). These real time aerial surveys can provide spatiotemporal data for targeting interventions to eliminate vectors before they become adult airborne biting mosquitoes, to reduce malaria transmission. Reference capture point habitats for Anopheles gambiae s.l., An. arabiensis s.s. and An. funestus s.s, the main malaria mosquito vectors in sub- Saharan Africa [ www.who.int ], may also be separately identified with this methodology. This chapter points to the application of predictive algorithms coupled with drone surveillance to support sensemaking in support of spatiotemporal data for targeting interventions to eliminate vectors before they become adult airborne biting mosquitoes, to reduce malaria transmission. The sensemaking applies not only to the targeted interventions to eliminate vectors, but also strategic sensemaking that contextualizes this intervention as part of a more holistic/systemic and strategic intervention encompassing a myriad of coordinated interventions across the disaster management spectrum (mitigation, preparedness, response, recovery).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71998-2_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-7106-0_53,Autonomous Vehicle Simulation Using Deep Reinforcement Learning,Machine Learning for Predictive Analysis,10.1007/978-981-15-7106-0_53,Springer,2021-01-01,"The reinforcement learning algorithms have been proven to be extremely accurate in performing a variety of tasks. These algorithms have outperformed humans in traditional games. This paper proposes a reinforcement learning based approach to autonomous driving. The autonomous vehicles must be able to deal with all external situations to ensure safety and to avoid undesired circumstances such as collisions. Thus, we propose the use of deep deterministic policy gradient (DDPG) algorithm which is able to work in a complex and continuous domain. To avoid physical damage and reduce costs, we choose to use a simulator to test the proposed approach. The CARLA simulator would be used as the environment. To fit the DDPG algorithm to the CARLA environment, our network architecture consists of critic and actor networks. The performance would be evaluated based on rewards generated by the agent while driving in the simulated environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-7106-0_53,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-78459-1_18,Smart UAV Monitoring System for Parking Supervision,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,10.1007/978-3-030-78459-1_18,Springer,2021-01-01,"Unmanned Aerial Vehicles (UAVs), or drones, are used in the field of remote collection of images at the time of flight. They can also detect irregularities in vehicle parking and issue fines in case of parking violations. The parking monitoring system uses real-time visual information. In this paper, the proposed solution is for real-time monitoring of areas and detecting irregularities in-vehicle parking using a fleet of drones. In this study, a camera mounted on UAVs applies for taking pictures of public areas at predetermined points. For monitoring of area will be used Observer UAVs while for detection will be used, Inspector UAVs. Visual information collected with UAVs is used to detect irregularities in vehicle parking, while the processing of collected data is performed by an artificial neural network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-78459-1_18,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86534-4_11,Contextual and Behavior Factors Extraction from Pedestrian Encounter Scenes Using Deep Language Models,Big Data Analytics and Knowledge Discovery,10.1007/978-3-030-86534-4_11,Springer,2021-01-01,"This study introduces an NLP framework including deep language models to automate the contextual and behavior factors extraction from a narrative text that describes the environment and pedestrian behaviors at the pedestrian encounter scenes. The performance is compared against a baseline BiLSTM-CRF model trained for each factor separately. The evaluation results show that the proposed NLP framework outperforms the baseline model. We show that the proposed framework can successfully extract nested, overlapping, and flat factors from sentences through the case studies. This model can also be applied to other descriptions when physical context and human behaviors need to be extracted from the narrative content to understand the behavioral interaction between subjects further.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86534-4_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51295-8_76,Unmanned Aerial Vehicles and Digital Image Processing with Deep Learning for the Detection of Pathological Manifestations on Facades,Proceedings of the 18th International Conference on Computing in Civil and Building Engineering,10.1007/978-3-030-51295-8_76,Springer,2021-01-01,"In the diagnosis phase of pathological manifestations in facades, the visual inspection stage deserves special attention due to its inherent complexity (height, size, access difficulties and exposure conditions). In recent years, the use of deep learning techniques to detect and classify specific features in images and videos has been increasing, which when combined with the use of Unmanned Aerial Vehicles (UAVs) for capturing images, is a potential useful tool that can assist and automate the visual inspection procedure of facades. This paper aimed to perform the analysis of Digital Image Processing (DIP) for automatic detection of cracks in building ceramic tiles, associated with UAV, which would potentially result in benefits (time, cost and safety) with respect to diagnosis. Thus, the research results showed the technical feasibility of detection of cracks by DIP techniques, however, the main limitation for this purpose is the lack of a dataset of images of pathological manifestations in facades publicly available, restricting the computer learning process and consequently compromising the recognition capacity. Still, the project was able to develop a simple and efficient methodology to what was proposed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51295-8_76,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-16-0598-7_12,Prediction of Traffic Movement for Autonomous Vehicles,Machine Learning for Robotics Applications,10.1007/978-981-16-0598-7_12,Springer,2021-01-01,"Living in the twenty-first century, there has been a massive growth in the number of autonomous vehicles present on the streets. Technology which once seemed impossible is being used in increasing number of vehicles day-by-day. With the technical advancement also comes challenges, it is not at all easy to develop and safely deploy these self-driving vehicles. So, in this chapter, a particular problem is being tackled, which is to predict future coordinates of all agents like cars, pedestrians, cyclists, etc., around AV. The main motive of this particular chapter is to measure the result efficiency of different deep learning models by evaluating the root mean square error (MSE) score. The models take as input the present state of the surroundings and based on that predicts the movement of the agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-0598-7_12,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-88081-1_44,Semantic Segmentation of Small Region of Interest for Agricultural Research Applications,Computational Collective Intelligence,10.1007/978-3-030-88081-1_44,Springer,2021-01-01,"The artificial intelligence and, in particular, the artificial neural networks proved to be useful tools in the field of computer vision, with promising results of applications in various domains, such as: industry, agriculture, medicine, transport, and environment. Detecting and locating crops using images received from aerial robots can make a positive contribution to assessing possible damage, reducing losses and minimizing analysis time. The paper proposed different implementation of the conditional generative adversarial network to better accomplish the task of semantic segmentation the agricultural region of interest. To this end the images were acquired by unmanned aerial vehicles. The network consists of a generator built using the U-Net architecture model and a discriminator that provides a probability matrix for each prediction, the elements of the matrix corresponding to portions of the input image. The resulting model, implemented with GPU processors provided by Google, performs a binary segmentation of images to determine the areas containing crops. The results of five experiments obtained, in the best configuration of hyper-parameters tested, an average accuracy of 97.93% in relation to reference (manual) segmentation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-88081-1_44,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1275-9_44,Autonomous Cars: Technical Challenges and a Solution to Blind Spot,Advances in Computational Intelligence and Communication Technology,10.1007/978-981-15-1275-9_44,Springer,2021-01-01,"Automotive industry is progressing forward toward the future, where the role of driver is becoming smaller and leading to become ideally driverless. Designing a fully driverless car (DC) or self-driving car is a most challenging automation project, since we are trying to automate complex processing and decision-making of driving a heavy and fast-moving vehicle in public. There are many scenarios where self-driving cars are not able to perform like human drivers. There are a lot of technical, non-technical, ethical and moral challenges to be addressed. Furthermore, two recent accidents caused by self-driving cars of Uber [ 1 ] and Tesla [ 2 ] have raised a concern toward the readiness and safety of using these cars. Therefore, it is necessary to address these challenges and issues of DC’s. In this paper, we have surveyed various technical challenges and scenarios where DCs are still facing issues. We have also addressed an issue of blind spots and proposed a systematic solution to tackle the issue. Before self-driving cars go live on road, we have to overcome these challenges and work on technology barriers so that we can make the DCs safe and trustworthy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1275-9_44,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-6403-1_20,The Importance of Applying Artificial Intelligence on Unmanned Aerial Vehicle,Proceedings of the 4th International Conference on Electrical Engineering and Control Applications,10.1007/978-981-15-6403-1_20,Springer,2021-01-01,"Unmanned Aerial Vehicles (UAVs) are used in several applications and they are growing in popularity. Recent progress in unmanned aerial vehicles and artificial intelligence constitutes a new chance for an autonomous operation and flight. Nowadays, artificial intelligence and deep learning are driving the evolution of UAVs and fueling their autonomous future. Computer vision achieved very important progress in image classification and segmentation, and object detection, which make it very attractive research field when it is applied on unmanned aerial vehicle. Artificial intelligence is not only important and benefic, but can be rather, dangerous and serious matter since the UAVs learns through algorithms, and use that for future decision making. This work is a survey, where we present works, challenges and dangerous part of using artificial intelligence on UAVs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6403-1_20,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79157-5_19,A Multimodal AI-Leveraged Counter-UAV Framework for Diverse Environments,Artificial Intelligence Applications and Innovations. AIAI 2021 IFIP WG 12.5 International Workshops,10.1007/978-3-030-79157-5_19,Springer,2021-01-01,"Unmanned Aerial Vehicles (UAVs) have become a major part of everyday life, as well as an emerging research field, by establishing their versatility in a variety of applications. Nevertheless, this rapid spread of UAVs reputation has provoked serious security issues that can probably affect homeland security. Defence communities have started to investigate large field-of-view sensor-based methods to enable various civil protection applications, including the detection and localisation of flying threat objects. Counter-UAV (c-UAV) detection challenges may be granted from a fusion of sensors to enhance the confidence of flying threats identification. The real-time monitoring of the environment is absolutely rigorous and demands accurate methods to detect promptly the occurrence of harmful conditions. Deep learning (DL) based techniques are capable of tackling the challenges that are associated with generic objects detection and explicitly UAV identification. In this paper, we present a novel multimodal DL methodology that combines data from individual unimodal approaches that are associated with UAV detection. Specifically, this work aims to identify and classify potential targets of UAVs based on fusion methods in two different cases of operational environments, i.e. rural and urban scenarios. A dedicated architecture is designed based on the development of deep neural networks (DNNs) frameworks that has been trained and validated employing real UAV flights scenarios. The proposed approach has achieved prominent detection accuracies over different background environments, exhibiting potential employment even in major defence applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79157-5_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-6759-9_10,Vehicular Localisation at High and Low Estimation Rates During GNSS Outages: A Deep Learning Approach,"Deep Learning Applications, Volume 2",10.1007/978-981-15-6759-9_10,Springer,2021-01-01,"Road localisation of autonomous vehicles is reliant on consistent accurate GNSS (Global Navigation Satellite System) positioning information. Commercial GNSS receivers usually sample at 1 Hz, which is not sufficient to robustly and accurately track a vehicle in certain scenarios, such as driving on the highway, where the vehicle could travel at medium to high speeds, or in safety-critical scenarios. In addition, the GNSS relies on a number of satellites to perform triangulation and may experience signal loss around tall buildings, bridges, tunnels and trees. An approach to overcoming this problem involves integrating the GNSS with a vehicle-mounted Inertial Navigation Sensor (INS) system to provide a continuous and more reliable high rate positioning solution. INSs are however plagued by unbounded exponential error drifts during the double integration of the acceleration to displacement. Several deep learning algorithms have been employed to learn the error drift for a better positioning prediction. We therefore investigate in this chapter the performance of Long Short-Term Memory (LSTM), Input Delay Neural Network (IDNN), Multi-Layer Neural Network (MLNN) and Kalman Filter (KF) for high data rate positioning. We show that Deep Neural Network-based solutions can exhibit better performances for high data rate positioning of vehicles in comparison to commonly used approaches like the Kalman filter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-6759-9_10,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79997-7_6,Lethal Autonomous Weapon Systems: An Advocacy Paper,"Advances in Human Factors in Robots, Unmanned Systems and Cybersecurity",10.1007/978-3-030-79997-7_6,Springer,2021-01-01,"Some countries, human rights organizations, artificial intelligence experts and academics have expressed doubts about the moral, ethical, and legal development and use of Lethal Autonomous Weapon Systems (LAWS). The United States, United Kingdom, Israel, Russia and many other countries have disagreed with these concerns. This paper will argue that (1) LAWS already exist and are in use by many countries for both defensive and offensive purposes and (2) LAWS cannot be legislated away; the technology is pervasive from smart cars and autonomous ships to military self-protection systems. As long as countries and their respective militaries follow internationally accepted norms when using LAWS such as the Laws of War, principles of war, and have a systematic legal review process, militaries will have the sufficient and necessary controls to address those who criticize and oppose their development and use.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79997-7_6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-53669-5_16,UAV Autonomous Navigation by Image Processing with Uncertainty Trajectory Estimation,Proceedings of the 5th International Symposium on Uncertainty Quantification and Stochastic Modelling,10.1007/978-3-030-53669-5_16,Springer,2021-01-01,"Unmanned Aerial Vehicles (UAV) is a technology under strong development, with application on several fields. For the UAV autonomous navigation, a standard scheme is to use signal from a Global Navigation System by Satellite (GNSS) onboard. However, such signal can suffer natural or human interference. Our approach applies image processing procedure for the UAV positioning: image edge extraction and correlation between drone image and georeferenced satellite image. A data fusion is also applied, for combining the inertial sensor data and positioning by image. The data fusion is performed by using neural network. The output from the data fusion neural network is the correction for the UAV trajectory. Here, the variance of the trajectory error is also predicted to quantify the uncertainty.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53669-5_16,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-59897-6_8,Artificial Intelligence and Sensor Technology in the Automotive Industry: An Overview,Automotive Embedded Systems,10.1007/978-3-030-59897-6_8,Springer,2021-01-01,"Recently, artificial intelligence (AI) has contributed a key role in the field of automotive industry in the form of self-driving cars or automated vehicles (AV) with innovative features. The automotive industry is driven by various potential technologies such as sensor technology, communication techniques, machine learning and deep learning algorithms. Using AI, a lot of innovative products and applications have been developed in the automotive industry and they have reduced most of the human errors such as aggressive driving, accidents and traffic collisions, etc. This article explores AI-based applications in the automotive industry and also discusses relevant algorithms behind this new era of AV. Moreover, this article investigates the role of sensors and actuators which are the prime requisite of building an AV. This also discusses the challenges involved in the AV.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59897-6_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-73280-6_37,UAV On-Board Emergency Safe Landing Spot Detection System Combining Classical and Deep Learning-Based Segmentation Methods,Intelligent Information and Database Systems,10.1007/978-3-030-73280-6_37,Springer,2021-01-01,This article proposes the system designed for automatic detection of emergency landing sites for horizontally landing unmanned aerial vehicles (UAV). The presented solution combines the classic computer vision algorithms and novel segmentation methods based on deep learning techniques using the U-Net inspired network architecture. The presented system uses a single nadir camera mounted on a UAV and the energy-efficient compute module capable of highly-parallelized calculations.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-73280-6_37,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6912-2_46,Electric Vehicle Steering Design and Automated Control Using CNN and Reinforcement Learning,Soft Computing and Signal Processing,10.1007/978-981-33-6912-2_46,Springer,2021-01-01,"Autonomous vehicles are one of the engrossing technological trends in the present automotive industry. These vehicles enticed substantial attention in industry as well as in academia. With the rising trend in research and development of autonomous vehicles, it is important to keep in mind the safety, control, and cost effectiveness of the system. The cost and implementation of self-driving technologies hinder the development of similar systems in academia and research. In this paper, we are mainly focused on developing a vision system, an automated steering system in an electric vehicle platform for academia and research. The developed system has a provision to incorporate deep learning—Convolutional neural network (CNN) and reinforcement learning (RL) for automated steering control. The proposed automated steering model uses end-to-end learning and reinforcement learning for predicting the steering angles with at most 85% accuracy and control the steering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6912-2_46,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-75762-5_11,Autonomous Vehicle Path Prediction Using Conditional Variational Autoencoder Networks,Advances in Knowledge Discovery and Data Mining,10.1007/978-3-030-75762-5_11,Springer,2021-01-01,"Path prediction of autonomous vehicles is an essential requirement under any given traffic scenario. Trajectory of several agent vehicles in the vicinity of ego vehicle, at least for a short future, is needed to be predicted in order to decide upon the maneuver of the ego vehicle. We explore variational autoencoder networks to obtain multimodal trajectories of agent vehicles. In our work, we condition the network on past trajectories of agents and traffic scenes as well. The latent space representation of traffic scenes is achieved by using another variational autoencoder network. The performance of the proposed networks is compared against a residual baseline model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-75762-5_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-33-6726-5_3,Reinforcement Learning Based Communication Security for Unmanned Aerial Vehicles,Cyber Security Meets Machine Learning,10.1007/978-981-33-6726-5_3,Springer,2021-01-01,"With the rapid development of unmanned aerial vehicles (UAVs) in communications, networking, and sensing applications, UAVs have gained considerable research interest in the last decade. Although UAV applications have been widely applied in many different fields, especially the military surveillance and environment monitoring, UAV communication process is not sufficiently safe due to jamming attacks. By imposing jamming signals on the controller during the communication process of the drones, a jammer can interfere with the sensing data reception of the controller, exhaust the drone battery, or keep the drone from following the specified sensing mission waypoint.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6726-5_3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10514-020-09951-8,Deep reinforcement learning for quadrotor path following with adaptive velocity,Autonomous Robots,10.1007/s10514-020-09951-8,Springer,2021-01-01,"This paper proposes a solution for the path following problem of a quadrotor vehicle based on deep reinforcement learning theory. Three different approaches implementing the Deep Deterministic Policy Gradient algorithm are presented. Each approach emerges as an improved version of the preceding one. The first approach uses only instantaneous information of the path for solving the problem. The second approach includes a structure that allows the agent to anticipate to the curves. The third agent is capable to compute the optimal velocity according to the path’s shape. A training framework that combines the tensorflow-python environment with Gazebo-ROS using the RotorS simulator is built. The three agents are tested in RotorS and experimentally with the Asctec Hummingbird quadrotor. Experimental results prove the validity of the agents, which are able to achieve a generalized solution for the path following problem.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10514-020-09951-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-69066-3_22,Delay Minimization in Multi-UAV Assisted Wireless Networks: A Reinforcement Learning Approach,Artificial Intelligence for Communications and Networks,10.1007/978-3-030-69066-3_22,Springer,2021-01-01,"Unmanned Aerial Vehicles (UAVs) assisted communications are promising technology for meeting the demand of unprecedented demands for wireless services. In this paper, we propose a novel framework for delay minimization driven deployment of multiple UAVs. The problem of joint non-convex three dimensional (3D) deployment for minimizing average delay is formulated and solved by Deep Q network (DQN), which is a reinforcement learning based algorithm. Firstly, we obtain the cell partition by K-means algorithm. Then, we find the optimal 3D position for each UAV in each cluster to provide low delay service. Finally, when users are roaming, the UAVs are still able to track the real-time users. Numerical results show that the proposed DQN-based delay algorithm shows a fast convergence after a small number of iterations. Additionally, the proposed deployment algorithm outperforms several benchmarks in terms of average delay.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69066-3_22,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-80083-3_7,The Governance of AI and Its Legal Context-Dependency,The 2020 Yearbook of the Digital Ethics Lab,10.1007/978-3-030-80083-3_7,Springer,2021-01-01,"The paper examines today’s debate on the legal governance of AI. Scholars have recommended models of monitored self-regulation, new internal accountability structures for the industry and the implementation of independent monitoring and transparency efforts, down to new forms of co-regulation, such as the model of data governance set up by the EU legislators with the 2016 general data protection regulation, i.e. the GDPR. As shown by current regulations on self-driving cars, drones, e-health, etc., most legal systems, however, already govern the field of AI in a context-dependent way. The aim of this paper is to stress that such context-dependency does not preclude an all-embracing structure of legal regulation. The adaptability, modularity and flexibility of the regulatory system suggest a sort of middle ground between traditional top-down approaches and bottom-up solutions, between legislators and stakeholders. By fleshing out the legal constraints for every model of AI governance, the context-dependency of the law makes clear some of the features that such models should ultimately incorporate in the governance of AI.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-80083-3_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-16-3264-8_19,2D Autonomous Robot Localization Using Fast SLAM 2.0 and YOLO in Long Corridors,Human Centred Intelligent Systems,10.1007/978-981-16-3264-8_19,Springer,2021-01-01,"Autonomous navigation is one of the main areas of research in mobile robots and intelligent connected vehicles. In this context, we are interested in presenting a general view on robotics, the progress of research, and advanced methods related to this field to improve autonomous robots’ localization. We seek to evaluate algorithms and techniques that give robots the ability to move safely and autonomously in a complex and dynamic environment. Under these constraints, we focused our work in the paper on a specific problem: to evaluate a simple, fast and light SLAM algorithm that can minimize localization errors. We presented and validated a FastSLAM 2.0 system combining scan matching and loop closure detection. To allow the robot to perceive the environment and detect objects, we have studied one of the best deep learning technique using convolutional neural networks (CNN). We validate our testing using the YOLOv3 algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-16-3264-8_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-59897-6_11,Internet of Things and Artificial Intelligence-Enabled Secure Autonomous Vehicles for Smart Cities,Automotive Embedded Systems,10.1007/978-3-030-59897-6_11,Springer,2021-01-01,"The ever-increasing count of vehicles wrecks several cities in the global scenario. Smart cities have evolved as a winning strategy that helps to cope up with this issue and overcome the urban problems such as pollution, traffic, waste management, optimization of energy consumption, and so on. Technologies such as machine learning (ML), Internet of Things (IoT), artificial intelligence (AI), big data analytics, cloud computing, and smart sensors serve as tools that provide enormous possibilities in the smart revolution. Several researchers are working on developing a complete system that performs information gathering, alternate identification, smart predictions, review of choices, decision-making, and taking suitable actions. These systems impose various challenges in terms of governance, economy, mobility, environment, people, and living. This chapter provides an in-depth analysis of these challenges in smart cities with respect to autonomous vehicles and also offers real-time solutions to overcome these challenges. A comparative analysis of the existing algorithms is done, and the optimal algorithms that can help in implementation of the system with a user-friendly approach and linguistic flexibility are proposed. Factors such as use of unmanned aerial vehicles (UAV), vehicle-to-vehicle and vehicle-to-infrastructure communication, deployment of location and path planning, data routing, dynamic coordination, data transmission, privacy, and cybersecurity are also considered while designing the system.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59897-6_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-86702-7_9,Heterogeneous Acoustic Features Space for Automatic Classification of Drone Audio Signals,Applied Computer Sciences in Engineering,10.1007/978-3-030-86702-7_9,Springer,2021-01-01,"The incremented use of unmanned aerial vehicles (UAV) in recent years, have leaded to security flaws that demand a solution oriented to UAV monitoring. An attractive solution to this problem is based on the analysis of UAV audio signals. Such approach aims to extract a set of acoustic features and to use them as inputs of machine learning algorithms. Current works on this topic are mainly focused in using a specific set of acoustic features, such as linear prediction and cepstral metrics. However, relevant UAV acoustic information may be missing by considering a single type of features. In this work, we propose a heterogenous acoustic features space for solving UAV automatic classification problems. Temporal, spectral and time-frequency analysis are implemented to extract features from UAV audio signals and thus building a high dimensional features space. By applying features selection techniques, the most relevant acoustic features are identified and they are used to train machine learning algorithms. Our results show that, the heterogeneous features space yields high performance in automatic UAV classification tasks of binary and multiclass type. The classification results outperform the overall classification performance of other studies using set of homogeneous features. Furthermore, the metrics extracted using the wavelet packet transform are the most prevalent in the features spaces that yield the best classification results for the binary and muticlass classification tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-86702-7_9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-6862-0_28,Object Detection for Autonomous Vehicles Using Deep Learning Algorithm,Computational Vision and Bio-Inspired Computing,10.1007/978-981-33-6862-0_28,Springer,2021-01-01,"Self-driving cars is recently gaining an increasing interest from the people across the globe. Over 33,000 Americans are killed in car accidents every year and lots of those accidents are often avoided by implementing the autonomous vehicle detection. Different ways are developed to manage and detect the road obstacles with the help of the techniques like machine learning and artificial intelligence. To resolve the issues associated with the existing vehicle detection like vehicle type recognition, low detection accuracy, and slow speed, many algorithms like the fast and faster region-based convolutional neural networks (RCNNs) are implemented but those were not supportive in real time because of the speed at which they compute and its two-step architecture with the faster RCNN, which is the enhanced version of RCNNs that runs at a speed of 7 frames per second. As it is observed that the CNN family has two steps (object detection and classification), which can reduce the response time in real time with good accuracy and high image resolution. So, the vehicle detection model like YOLOv2 and YOLOv3 is taken into consideration in this paper as they are very useful in real-time detection with a comparatively higher frame rate. As YOLO family of algorithms will mostly use the single step detection and classification. YOLO has an FPS rate of 45 which is pretty good in the real-time scenarios. We had an average of 90.4 using the taken algorithm for each image in this paper with a lower resolution image alone.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-6862-0_28,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-33-4501-0_47,Robustness Analysis of Behavioral Cloning-Based Deep Learning Models for Obstacle Mitigation in Autonomous Vehicles,Proceedings of 6th International Conference on Recent Trends in Computing,10.1007/978-981-33-4501-0_47,Springer,2021-01-01,Maneuvering a steady on-road obstacle at high speed involves taking multiple decisions in split seconds. An inaccurate decision may result in a crash. One of the key decisions that need to be taken is can the on-road steady obstacle be surpassed. The model learns to clone the driver’s behavior of maneuvering a non-surpass-able obstacle and pass through a surpass-able obstacle. No data with labels of “surpass-able” and “non-surpass-able” was provided during training. We have developed an array of test cases to verify the robustness of CNN models used in autonomous driving. Experimenting between activation functions and dropouts the model achieves an accuracy of 87.33% and run time of 4478 s with input of only 4881 images (training + testing). The model is trained for limited on-road steady obstacles. This paper provides a unique method to verify the robustness of CNN models for obstacle mitigation in autonomous vehicles.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-33-4501-0_47,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-15145-4_65-2,Deep Learning for LiDAR-Based Autonomous Vehicles in Smart Cities,Handbook of Smart Cities,10.1007/978-3-030-15145-4_65-2,Springer,2021-01-01,"Autonomous vehicles and deep learning are an integral part of smart cities. They interact and communicate with their surroundings, requiring high computer vision accuracy to maintain driver and pedestrian safety. Many autonomous vehicles leverage deep learning for detection and utilize a suite of sensors that are specific to their environment or use case. In such deep learning environment, sensor data is used as input to neural networks that make decisions regarding the vehicle’s response or reaction to its environment. These sensors in autonomous vehicles provide details regarding the vehicle’s surroundings and potential obstacles. Many sensor suites are starting to contain light detection and ranging (LiDAR) sensors, as the cost of the technology decreases and becomes more widely available. LiDAR technology uses focused light to detect distance, providing an accurate description of the sensor’s surroundings, such precise account is crucial for autonomous driving in ever-changing smart city environments. This chapter covers different applications of LiDAR technology and the use of the sensor data in deep learning applications for smart cities. A case study is also featured to illustrate a potential implementation, which is followed by discussion of future research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-15145-4_65-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ReferenceWorkEntry,doi:10.1007/978-3-030-69698-6_65,Deep Learning for LiDAR-Based Autonomous Vehicles in Smart Cities,Handbook of Smart Cities,10.1007/978-3-030-69698-6_65,Springer,2021-01-01,"Autonomous vehicles and deep learning are an integral part of smart cities. They interact and communicate with their surroundings, requiring high computer vision accuracy to maintain driver and pedestrian safety. Many autonomous vehicles leverage deep learning for detection and utilize a suite of sensors that are specific to their environment or use case. In such deep learning environment, sensor data is used as input to neural networks that make decisions regarding the vehicle’s response or reaction to its environment. These sensors in autonomous vehicles provide details regarding the vehicle’s surroundings and potential obstacles. Many sensor suites are starting to contain light detection and ranging (LiDAR) sensors, as the cost of the technology decreases and becomes more widely available. LiDAR technology uses focused light to detect distance, providing an accurate description of the sensor’s surroundings, such precise account is crucial for autonomous driving in ever-changing smart city environments. This chapter covers different applications of LiDAR technology and the use of the sensor data in deep learning applications for smart cities. A case study is also featured to illustrate a potential implementation, which is followed by discussion of future research directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-69698-6_65,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-71187-0_88,Transfer Learning for Autonomous Vehicles Obstacle Avoidance with Virtual Simulation Platform,Intelligent Systems Design and Applications,10.1007/978-3-030-71187-0_88,Springer,2021-01-01,"Over the last few years, autonomous vehicles have expanded considerably. Autonomous driving systems are getting more complex and must be tested successfully prior to implementation. We are exploring a model for high quality prediction of obstacle avoidance for autonomous vehicles based on images created by a virtual simulation platform and then using a VGG 16 deep learning technique, including transfer learning. This paper proposes a transfer of learning strategy using the VGG16 architecture, while the output of the proposed architecture is further compared to the existing NVIDIA architecture. Experimental results indicate that the VGG16 with the transfer learning architecture has surpassed other tested methods.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-71187-0_88,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-58728-4_5,Evaluation of Deep Learning Algorithms for Traffic Sign Detection to Implement on Embedded Systems,Recent Advances of Hybrid Intelligent Systems Based on Soft Computing,10.1007/978-3-030-58728-4_5,Springer,2021-01-01,"Nowadays, machine learning algorithms are trendy and are used to solve different problems of autonomous vehicles obtaining good results. Among these algorithms, deep learning has emerged as an excellent alternative to improve the results of the state-of-the-art in machine vision applications. An essential task in autonomous vehicles is the detection of traffic signs. Some metrics used for these detectors focus on assessing precision and recall. However, it is necessary to consider other factors, such as the implementation of these models on an embedded system. In this work, we implement deep learning algorithms on an embedded system to evaluate two different detection algorithms: Faster R-CNN and Single Shot Multibox Detector (SSD) with two feature extractors, ResNet V1 101 and MobileNet V1 to determine the location of traffic signs within the observed scenario. The contribution of this work focuses on evaluating the implementation of traffic sign detection systems based on deep learning algorithms on embedded systems. The experiments were achieved on the experimental embedded system board Nvidia Jetson Nano. The inference time and memory consumption of these detection systems were evaluated; they delivered good performance (81–98%) measure by average precision for each superclass (prohibitory, warning, and mandatory).",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-58728-4_5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-5113-0_40,Tweets About Self-Driving Cars: Deep Sentiment Analysis Using Long Short-Term Memory Network (LSTM),International Conference on Innovative Computing and Communications,10.1007/978-981-15-5113-0_40,Springer,2021-01-01,"Due to the extensive growth of social media usage, sentiment analysis using social media data such as Twitter is an important task. The current study presents an empirical investigation of consumer sentiment toward self-driving cars or autonomous vehicles (AVs) based on the acquired self-driving car-related tweets. Information retrieval in social media is a complex task that requires technical insights. We used a hierarchical attention-based long short-term memory network (LSTM), a popular deep learning tool, to classify sentiment-specific document representations. The findings show that favorable attitudes toward AVs are associated with technological advantages and safety improvements, while more negative attitudes are associated with self-driving car-related crashes, media coverage, and deployment uncertainty. The results show that the estimated accuracy of LSTM is 85%. Our study indicates the necessity of examining big social media data in understanding the perceptions of end-users toward autonomous vehicles.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-5113-0_40,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-67369-7_15,Deep Anomaly Detector Based on Spatio-Temporal Clustering for Connected Autonomous Vehicles,Ad Hoc Networks,10.1007/978-3-030-67369-7_15,Springer,2021-01-01,"Connected Autonomous Vehicles (CAV) are expected to revolutionize the transportation sector. However, given that CAV are connected to internet, they face a principal challenge to ensure security, safety and confidentiality. It is highly valuable to provide a real-time and proactive anomaly detection approach for Vehicular Ad hoc Network (VANET) exchanged data since such an approach helps to trigger prompt countermeasures to be undertaken allowing the damage avoidance. Recent machine learning methods show great efficiency, especially due to their capacity to handle nonlinear problems. However, an accurate anomaly detection in a space–time series is a challenging problem because of the heterogeneity of space–time data and the spatio-temporal correlations. An anomalous behavior can be seen as normal in different context. Thus, using one deep learning model to classify the observations into normal and abnormal or to identify the type of the anomaly is usually not efficient for large high-dimensional multi-variate time-series datasets. In this paper, we propose a stepwise method in which the time-series data are clustered on spatio-temporal clusters using Long Short Term Memory (LSTM) auto-encoder for dimension reduction and Grey Wolf Optimizer based clustering. Then, the anomaly detection is performed on each cluster apart using a hybrid method consisting of Auto-Encoder for feature extraction and Convolution Neural Network for classification. The results shows an increase in the accuracy by $$2\%$$ 2 % in average and in the precision by approximately $$1.5\%$$ 1.5 % .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-67369-7_15,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63128-4_22,"The Impact of Artificial Intelligence on Work, Education, Mobility and Economy","Proceedings of the Future Technologies Conference (FTC) 2020, Volume 1",10.1007/978-3-030-63128-4_22,Springer,2021-01-01,"This article studies artificial intelligence, its possible influence on how people work, move and study. Artificial intelligence may create technology-based industries, transforming daily life across the world. It also shows the potential role of artificial intelligence in the world economy. IT industry, in which AI is sourced, is currently estimated at about 5 trillion USD. Despite economic ups and downs, including the recent financial and economic crisis, AI solutions remain at a healthy level and its consumers enjoy the benefits of economic value creation. This will increase production efficiency through automation in different sectors of the economy. AI-related patent applications are on the rise worldwide. Companies developing AI solutions will be the ones that benefit from it in the future. Its economic impact will be visible over time, resulting in autonomous cars, a transformation of worker skills and how education is delivered.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63128-4_22,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-60188-1_4,"Digital Transformation and Emerging Technologies for COVID-19 Pandemic: Social, Global, and Industry Perspectives",Artificial Intelligence and Machine Learning for COVID-19,10.1007/978-3-030-60188-1_4,Springer,2021-01-01,"COVID-19 disease pandemic is affecting the lives of millions of people in one or another manner. To handle the COVID-19 pandemic situation, technological aspects play a vital role in parallel to medical and healthcare facilities. With the use of existing infrastructure, technologies such as artificial intelligence, neural network, blockchain technology, cloud computing, drone-based monitoring, etc. have given the important observations and awareness to many. It is observed that with the combined efforts of technology and healthcare system, recognition of the outbreak is much faster compared to earlier infections. However, many are working continuously to collect and analyze the available COVID-19-related data and introspect the future. The whole of this work is performed to maximize the use of technology and reduce the risk of a continuous outbreak. This work has discussed the recent work done over the use of technologies in handling the COVID-19 scenario. Here, a comparative analysis of various parameters in each technological aspect is discussed to have an understanding of the preferred approaches in different places. Further, brief surveys are conducted in each technological aspect for a better understanding of technological advantage in handling pandemic.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60188-1_4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-81907-1_19,Autonomous Vehicles: From Whether and When to Where and How,"Ethics, Governance, and Policies in Artificial Intelligence",10.1007/978-3-030-81907-1_19,Springer,2021-01-01,"Mobility is an essential component of life in any society, so a transformation of mobility will affect the foundations of any society, and it is hard to imagine a more profound transformation of mobility than autonomous driving. This is why understanding attitudes towards the benefits and shortcomings of autonomous vehicles means being able to address societal welfare and individual well-being more successfully. In this chapter I argue that digital technologies have made it possible to detach the journey from the trip. It seems that, in the near future, we may be increasingly able to enjoy trips rather than journeys, with more freedom to choose to travel because we want to rather than because we need to.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-81907-1_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-78459-1_19,Object Detection and Mapping with Unmanned Aerial Vehicles Using Convolutional Neural Networks,Future Access Enablers for Ubiquitous and Intelligent Infrastructures,10.1007/978-3-030-78459-1_19,Springer,2021-01-01,"Significant progress has been made in the field of deep learning through intensive research over the last decade. So-called convolutional neural networks are an essential component of this research. In this type of neural network, the mathematical convolution operator is used to extract characteristics or anomalies. The purpose of this work is to investigate the extent to which it is possible in certain initial settings to input aerial recordings and flight data of Unmanned Aerial Vehicles (UAVs) in the architecture of a neural network and to detect and map an object. Using the calculated contours or dimensions of the so-called bounding boxes, the position of the objects can be determined relative to the current UAV location.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-78459-1_19,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-60467-7_7,Intelligent and Autonomous Guidance Through a Geometric Model for Conventional Vehicles,Innovation and Research,10.1007/978-3-030-60467-7_7,Springer,2021-01-01,"Cyber-physical systems (CPS) in the automobile industry are facing major challenges related to the use and validation of these CPS, which entails high costs in the implementation and training tests in the physical world, thus limiting research. Therefore, there is a need to shorten the validation times of these CPS with the use of 3D simulation software. This research article proposes to simulate a CPS in the simulation software Webots, with the aim of emulating the autonomous movement of conventional vehicles by integrating a GPS sensor and a compass sensor which provide information on location and orientation, these data are used for the implementation of a geometric model by vectors, the same one that is developed in a controller that allows to take actions on the vehicles in the simulation software in order to emulate an urban traffic. Finally, a series of configurations have been made to evaluate the geometric model, managing to maintain the default speed of 94.194% with curves greater than 90 degrees. In addition, the validation of this system in a real environment through the instrumentation in land vehicles is drawn as future lines.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-60467-7_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-53532-2_1,Challenges in the Realm of Embedded Real-Time Image Processing,Towards Ubiquitous Low-power Image Processing Platforms,10.1007/978-3-030-53532-2_1,Springer,2021-01-01,"The development of power-efficient solutions gives new embedded products the ability to analyse images and thereby brings more intelligence to embedded systems—providing more and better services of higher quality as well as advanced capabilities such as self-adaptation and autonomy. This will allow cars to drive safer, medical devices to assist surgeons, and autonomous drones to find people that have gotten lost. For small-series products, one needs to find an embedded platform that provides enough performance, does not exceed the target price, and has sufficiently low-power consumption. As these requirements are typically conflicting, image processing engineers spend considerable time identifying the best possible trade-off for their algorithm implementation on the chosen platform. Providing a common platform that allows the efficient implementation of image processing systems across diverse application domains—a key objective of our Tulipp project—requires a solid understanding of the constraints and challenges of each domain. In this paper, we report the key challenges we identified within the medical, Unmanned Aerial Vehicle (UAV), and automotive domains to aid the community in developing the next generation of embedded image processing systems.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-53532-2_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-55180-3_44,Drone-Based Cattle Detection Using Deep Neural Networks,Intelligent Systems and Applications,10.1007/978-3-030-55180-3_44,Springer,2021-01-01,"Cattle form an important source of farming in many countries. In literature, several attempts have been conducted to detect farm animals for different applications and purposes. However, these approaches have been based on detecting animals from images captured from ground level and most approaches use traditional machine learning approaches for their automated detection. In this modern era, Drones facilitate accessing images in challenging environments and scanning large-scale areas with minimum time, which enables many new applications to be established. Considering the fact that drones typically are flown at high altitude to facilitate coverage of large areas within a short time, the captured object size tend to be small and hence this significantly challenges the possible use of traditional machine learning algorithms for object detection. This research proposes a novel methodology to detect cattle in farms established in desert areas using Deep Neural Networks. We propose to detect animals based on a ‘group-of-animals’ concept and associated features in which different group sizes and animal density distribution are used. Two state-of-the-art Convolutional Neural Network (CNN ) architectures, SSD-500 and YOLO V-3, are effectively configured, trained and used for the purpose and their performance efficiencies are compared. The results demonstrate the capability of the two generated CNN models to detect groups-of-animals in which the highest accuracy recorded was when using SSD-500 giving a F-score of 0.93, accuracy of 0.89 and mAP rate of 84.7.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-55180-3_44,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74728-2_3,Palm Tree Detection in Drone Images Using Deep Convolutional Neural Networks: Investigating the Effective Use of YOLO V3,Digital Interaction and Machine Intelligence,10.1007/978-3-030-74728-2_3,Springer,2021-01-01,"Owing to the agricultural and economic importance to many countries, computer based automated palm-tree detection from aerial images, has been an area of research significance to the computer vision research community worldwide. Most previous approaches have applied traditional machine learning algorithms for palm-tree detection. However, in the recent past, deep neural network based learning has been proven to be a far more superior approach for general object detection and recognition tasks in many application areas. Alongside this technological development lightweight UAVs, e.g. Drones , have been widely accepted as having great practical potential and economic benefit in the surveillance of large areas of land, in significantly higher resolution, as compared to the traditional use of satellite images or more expensive large UAVs. This research presents a novel methodology based on the latest YOLO Version-3 Convolutional Neural Network object detector for detecting palm-trees in drone images captured in a desert area that includes palm-trees of different sizes, resolution, ground spread, degree of overlap, etc. In particular, we discuss the specific training strategy adopted and hyper-parameter optimisations carried out to improve the accuracy from a modest 0.78 to 0.96.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74728-2_3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-74893-7_24,LiDAR Localization and Mapping for Autonomous Vehicles: Recent Solutions and Trends,"Automation 2021: Recent Achievements in Automation, Robotics and Measurement Techniques",10.1007/978-3-030-74893-7_24,Springer,2021-01-01,"This paper presents a brief survey of the current achievements in LiDAR SLAM and discusses some recent trends and new ideas in this area. The focus is on LiDAR SLAM applied to autonomous vehicles, which still strugle with real-world complexity. We identify the challenges in efficient environment representation, robust estimation over large state spaces, and real-time handling of the scene dynamics and diversified semantics. Some of these issues are illustrated by preliminary results of our recent research in LiDAR SLAM.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-74893-7_24,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-981-15-9255-3_1,Challenges for and with Autonomous Vehicles: An Introduction,Autonomous Vehicles,10.1007/978-981-15-9255-3_1,Springer,2021-01-01,"The deployment of autonomous vehicles has been announced for years. Yet, full autonomous vehicles are not on public roads. Elon Musk Elon Musk , speaking at an event during the first half of 2020, stated that his firm will be able to present a fully autonomous vehicle technology by the end of the year. This statement is met with skepticism, especially because several of the challenges that existed have not been solved. Road traffic laws have not been adjusted to face the reality of driving by an autonomous machine. The only way that full autonomous vehicles can hit public roads is through test procedures. There also exists quite some uncertainty on who should be liable for accidents with autonomous vehicles. Accidents may occur, and this is something that adversarial machine learning Adversarial machine learning is showing. Even with the best set of sensors, the interpretation of the sensed environment may be misinterpreted. Connectivity Connectivity is being suggested as a possible solution to several of the problems autonomous vehicles are facing. Deploying autonomous vehicles will also challenge business organization, as car manufacturers Manufacturer may turn their business vehicles into mobility service providers. This may require a different type of organization within the firm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-9255-3_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-65661-4_11,"Synergy of Internet of Things with Cloud, Artificial Intelligence and Blockchain for Empowering Autonomous Vehicles",Deep Learning and Big Data for Intelligent Transportation,10.1007/978-3-030-65661-4_11,Springer,2021-01-01,"Out of the advancements in Information Technology, the Internet of Things (IoT) plays an important and major role as it metamorphose the object from real world Scenario to intelligent virtual form. The term Internet of Things is coined from two phrases such as Internet and Thing which states that the physical objects such as computing devices acts through the network of connection. This technological ecosystem allows the object or thing to collect and transfer the data through the internet, without any physical assistance. It includes four major processes such as collect, communicate, analyse and act. The main purpose of IoT is making the human life smart thereby reducing the human effort. The cloud is an environment that seems to be a reinforcement of booming technology. It provides everything as service, right from storage to computing power through internet. It seems to be a flexible computing model that has intensified the growth of information technology. It enchanted the sprout of IoT as it needs more storage for the data that are acquired from the objects. Another booming technology is artificial intelligence where the intelligence of machine is used for enabling smart tasks than using the human intelligence. It is in existence since 1950 s but the resurgence of it happens during twenty-first century with the advances in computing power and storage of voluminous data. The main purpose of AI is to achieve accurate interpretation of voluminous data and extract valuable learning from the data thereby achieving the appropriate goals in a flexible manner. The IoT with this gleaming AI allows the physical objects to collect the valuable data through continuous streaming and allows it to perceive its tasks and domains for greatest chance of prosperous goal achievement. Blockchain is another revolution of the information technology. The blockchain or Distributed Ledger Technology is a promising technology where the digital assets of myriad users are managed by maintaining the transparency and evading the undesirable alterations. It stores and manages the data in the form of multiple blocks with respective cryptographic hashing. It is a distributed and decentralized model where the digital form of transactions are recorded in multiple devices, this allows the system to do any alterations or changes in each and every blocks so as to make changes in the record. This model avoids the precarious changes that may occur in the digital world. The IoT with this blockchain technology or the blockchain of thing may allow the digital environment to create a permanent, verifiable and secure method of managing the valuable data through intelligent machines. It will enable humanless interventions for decision making through proper environment interactions. This chapter elaborates all the four technologies such as IoT, AI, Cloud and Blockchain with regard to the autonomous vehicles. The need for these flickering technologies are explored and exposed so as to understand these technologies. The synergies of IoT with other three technologies are discussed for better understanding and upgradation of the technology. It also scrutinizes the recent developments with all these technological synergies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-65661-4_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90966-6_20,Bibliometric Analysis on the Safety of Autonomous Vehicles with Artificial Intelligence,"HCI International 2021 - Late Breaking Papers: HCI Applications in Health, Transport, and Industry",10.1007/978-3-030-90966-6_20,Springer,2021-01-01,"The objective of the study was to look at the trend and advancement of Artificial Intelligence, Transportation, and Safety research through bibliometric analysis. The review retrieved data in Web of Science using specific terms related to Artificial Intelligence, Transportation, and Safety. VOSViewer, CiteSpace, and MAXQDA were utilized to conduct the citation analysis and content analysis of the Web of Science data set and 8 selected documents including 6 research articles and 2 chapters from the textbook Occupational Safety and Health for Technologists, Engineers, and Managers. Articles from GoogleScholar using Harzing’s Publish or Perish software and Web of Science database were used. The citation analysis creating a co-occurrence map discovered several keywords within clusters that were suggested to be subtopics of the general topic. Performing content analysis using the 8 selected documents has shown the most occurring keywords to be similar to those discovered in the citation analysis. The articles utilized bibliometric analysis tools to have further insight on the contributing journals and keywords drawn from multiple sources and methods of Artificial Intelligence and Transportation research. Articles from the Citespace citation burst and VOSViewer co-citation analysis were used to further support the necessity of automation and safety in artificial intelligence and transportation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90966-6_20,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90963-5_36,Applying Human Cognition to Assured Autonomy,"HCI International 2021 - Late Breaking Papers: Multimodality, eXtended Reality, and Artificial Intelligence",10.1007/978-3-030-90963-5_36,Springer,2021-01-01,"The scaled deployment of semi- and fully autonomous systems undeniably depends on assured autonomy. This reality, however, has become far more complex than expected because it necessarily demands an integrated tripartite solution not yet achieved: consensus-based standards and compliance across industry, scientific innovation within artificial intelligence R&D of explainability, and robust end-user education. In this is paper I present my human-centered approach to the design, development, and deployment of autonomous systems and break down how human factors such as cognitive and behavioral insights into how we think, feel, act, plan, make decisions, and problem-solve are foundational to assuring autonomy.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90963-5_36,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-90966-6_38,Safety Management and Challenges Associated with Industry 4.0 on Transportation and Logistics: A Systematic Literature Review,"HCI International 2021 - Late Breaking Papers: HCI Applications in Health, Transport, and Industry",10.1007/978-3-030-90966-6_38,Springer,2021-01-01,"“Industry 4.0” has become the most significant subject of the emerging fields in manufacturing and industrial practices over the decade. It leverages the new smart technologies, including Artificial Intelligence, the Internet of Things, Autonomous Vehicles, Advanced Robots, etc. for the high involvement of automation. Such highly automated processes may raise different concerns from the traditional industry. They should have impacts on the safety management with adaption to the current development. Here we narrow down to the role of Industry 4.0 in the aspects of transformation and logistics and conducted a systematic literature review of the associated topics. We used various tools, such as CiteSpace and VOSviewer to analyze the metadata as well as several collected articles from the databases for trend, co-citation, and content analyses. We found that there is still an apparent lack of studies to incorporate the safety issues in Industry 4.0. And we suggest that safety management for Industry 4.0 on transportation and logistics should consider system design, data communication (as cybersecurity), and integration of intelligent technologies. Subjects of health and sustainability should be also included as challenges related to safety. Though many challenges are needed to be handled, emerging technologies can play significant roles to improve the safety of the work environment in the era of Industry 4.0.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-90966-6_38,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-77626-8_13,Human-Machine Interaction for Autonomous Vehicles: A Review,Social Computing and Social Media: Experience Design and Social Network Analysis,10.1007/978-3-030-77626-8_13,Springer,2021-01-01,"The rate of advancement in autonomous systems has been increasing and humans rely on such systems for every aspect of daily life. This is especially true in the area of autonomous vehicles, where new techniques and discoveries have been uncovered and Society of Automotive Engineers (SAE) Level 5 self-driving might be a reality in a few years. Despite the significant body of work on self driving technology, many people are still sceptical about the idea of riding in a fully autonomous vehicle (AV). There is a need to build trust between humans and vehicles for successful adoption of AVs. In this paper we complement existing surveys by describing 3 active research areas that are key for enhancing trust in autonomous vehicles, namely 1) Trust in Autonomous Vehicles, 2) Human Machine Interfaces, and 3) Driver Activity Detection. We discuss and highlight the key ideas and techniques in recent research works of each field, and discuss potential future directions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-77626-8_13,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-79150-6_12,Enhanced Security Framework for Enabling Facial Recognition in Autonomous Shuttles Public Transportation During COVID-19,Artificial Intelligence Applications and Innovations,10.1007/978-3-030-79150-6_12,Springer,2021-01-01,"Autonomous Vehicles (AVs) can potentially reduce the accident risk while a human is driving. They can also improve the public transportation by connecting city centers with main mass transit systems. The development of technologies that can provide a sense of security to the passenger when the driver is missing remains a challenging task. Moreover, such technologies are forced to adopt to the new reality formed by the COVID-19 pandemic, as it has created significant restrictions to passenger mobility through public transportation. In this work, an image-based approach, supported by novel AI algorithms, is proposed as a service to increase autonomy of non-fully autonomous people such as kids, grandparents and disabled people. The proposed real-time service, can identify family members via facial characteristics and efficiently ignore face masks, while providing notifications for their condition to their supervisor relatives. The envisioned AI-supported security framework, apart from enhancing the trust to autonomous mobility, could be advantageous in other applications also related to domestic security and defense.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-79150-6_12,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01295-w,Controlling Draft Interactions Between Quadcopter Unmanned Aerial Vehicles with Physics-aware Modeling,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01295-w,Springer,2020-12-15,"In this paper, we address the problem of multiple quadcopter control, where the quadcopters maneuver in close proximity resulting in interference due to air-drafts. We use sparse experimental data to estimate the interference area between palm sized quadcopters and to derive physics-infused models that describe how the air-draft generated by two quadcopters (flying one above the other) affect each other. The observed significant altitude deviations due to airdraft interactions, mainly in the lower quadcopter, is adequately captured by our physics infused machine learning model. We use two strategies to mitigate these effects. First, we propose non-invasive, online and offline trajectory re-planning strategies that allow avoiding the interference zone while reducing the deviations from desired minimum snap trajectories. Second, we propose invasive strategies that re-design control algorithms by incorporating the interference model. We demonstrate how to modify the standard quadcopter PID controller, and how to formulate a model predictive control approach when considering the interference model. Both invasive and non-invasive strategies show significant reduction in tracking error and control signal energy as compared to the case where the interference area is ignored.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01295-w,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01274-1,A Dynamically Feasible Fast Replanning Strategy with Deep Reinforcement Learning,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01274-1,Springer,2020-12-11,"In this work, we aim to develop a fast trajectory replanning methodology enabling highly agile aerial vehicles to navigate in cluttered environments. By focusing on reducing complexity and accelerating the replanning problem under strict dynamical constraints, we employ the b-spline theory with local support property for defining the high dimensional agile flight trajectories. We utilize the differential flatness model of an aerial vehicle, allowing us to directly map the desired output trajectory into input states to track a high dimensional trajectory. Dynamically feasible replanning problem is addressed through regenerating the local b-splines with control point reallocation. As the geometric form of the trajectory based on the location of the control points and the knot intervals, the control point reallocation for fast replanning with dynamical constraints is turned into a constrained optimization problem and solved through deep reinforcement learning. The proposed methodology enables generating dynamically feasible local trajectory segments, which are continuous to the existing, hence provides fast local replanning for collision avoidance. The DRL agent is trained with different environmental complexities, and through the batch simulations, it is shown that the proposed methodology allows to solve fast trajectory replanning problem under given or hard dynamical constraints and provide real-time applicability for such collision avoidance applications in agile unmanned aerial vehicles. Hardware implementation tests of the algorithm with the agile trajectory tracker to a small UAV can bee seen in the following video link: https://youtu.be/8IiLQFQ3V0E .",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01274-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01284-z,Deep Learning-based Monocular Obstacle Avoidance for Unmanned Aerial Vehicle Navigation in Tree Plantations,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01284-z,Springer,2020-12-08,"In recent years, Unmanned Aerial Vehicles (UAVs) are widely utilized in precision agriculture, such as tree plantations. Due to limited intelligence, these UAVs can only operate at high altitudes, leading to the use of expensive and heavy sensors for obtaining important health information of the plants. To fly at low altitudes, these UAVs must possess the capability of obstacle avoidance to prevent crashes. However, most current obstacle avoidance systems with active sensors are not applicable to small aerial vehicles due to the cost, weight, and power consumption constraints. To this end, this paper presents a novel approach to the autonomous navigation of a small UAV in tree plantations only using a single camera. As the monocular vision does not provide depth information, a machine learning model, Faster Region-based Convolutional Neural Network (Faster R-CNN), was trained for the tree trunk detection. A control strategy was implemented to avoid the collision with trees. The detection model uses image heights of detected trees to indicate their distances from the UAV and image widths between trees to find the widest obstacle-free space. The control strategy allows the UAV to navigate until any approaching obstacle is detected and to turn to the safest area before continuing its flight. This paper demonstrates the feasibility and performance of the proposed algorithms by carrying out 11 flight tests in real tree plantation environments at two different locations, one of which is a new place. All the successful results indicate that the proposed method is accurate and robust for autonomous navigation in tree plantations.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01284-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11227-020-03251-9,Secure decentralized peer-to-peer training of deep neural networks based on distributed ledger technology,The Journal of Supercomputing,10.1007/s11227-020-03251-9,Springer,2020-12-01,"The accuracy and performance of deep neural network models become important issues as the applications of deep learning increase. For example, the navigation system of autonomous self-driving vehicles requires very accurate deep learning models. If a self-driving car fails to detect a pedestrian in bad weather, the result can be devastating. If we can increase the model accuracy by increasing the training data, the probability of avoiding such scenarios increases significantly. However, the problem of privacy for consumers and lack of enthusiasm for sharing their personal data, e.g., the recordings of their self-driving car, is an obstacle for using this valuable data. In Blockchain technology, many entities which cannot trust each other in normal conditions can join together to achieve a mutual goal. In this paper, a secure decentralized peer-to-peer framework for training the deep neural network models based on the distributed ledger technology in Blockchain ecosystem is proposed. The proposed framework anonymizes the identity of data providers and therefore can be used as an incentive for consumers to share their private data for training deep learning models. The proposed framework uses the Stellar Blockchain infrastructure for secure decentralized training of the deep models. A deep learning coin is proposed for Blockchain compensation.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11227-020-03251-9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12008-020-00717-1,Explainable navigation system using fuzzy reinforcement learning,International Journal on Interactive Design and Manufacturing (IJIDeM),10.1007/s12008-020-00717-1,Springer,2020-12-01,"Abstract Explainable outcomes in autonomous navigation have become crucial for drivers, other vehicles, as well as for pedestrians. Creating trustworthy strategies is mandatory for the integration of self-driving cars into quotidian environments. This paper presents the successful implementation of an explainable Fuzzy Deep Reinforcement Learning approach for autonomous vehicles based on the AWS DeepRacer $$^{\mathrm{TM}}$$ TM platform. A model of the environment is created by transforming crisp values into linguistic variables. A fuzzy inference system is used to define the reward of the vehicle depending on its current state. Guidelines to define the actions and to improve performance of the reinforcement learning agent are given based on the characteristics of the existing hardware. The performance of the models is tested on tracks with distinctive properties using agents with different policies and action spaces, and shows explainable and successful navigation of the agent on diverse scenarios. Graphic Abstract ",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12008-020-00717-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01254-5,Autonomous UAV Trail Navigation with Obstacle Avoidance Using Deep Neural Networks,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01254-5,Springer,2020-12-01,"This paper proposes a vision-based bike trail following approach with obstacle avoidance using CNN (Convolutional Neural Network) for the UAV (Unmanned Aerial Vehicle). The UAV is controlled to follow a given trail while keeping its position near the center of the trail using the CNN. Also, to return to the original path when the UAV goes out of the path or the camera misses the trail due to disturbances such as wind, the control commands from the CNN are stored for a certain duration of time and used for recovering from such disturbances. To avoid obstacles during the trail navigation, the optical flow computed with another CNN is used to determine the safe maneuver. By combining these methods of i) trail following, ii) disturbance recovery, and iii) obstacle avoidance, the UAV deals with various situations encountered when traveling on the trail. The feasibility and performance of the proposed approach are verified through realistic simulations and flight experiments in real-world environments.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01254-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-020-01227-8,UAV Model-based Flight Control with Artificial Neural Networks: A Survey,Journal of Intelligent & Robotic Systems,10.1007/s10846-020-01227-8,Springer,2020-12-01,"Model-Based Control (MBC) techniques have dominated flight controller designs for Unmanned Aerial Vehicles (UAVs). Despite their success, MBC-based designs rely heavily on the accuracy of the mathematical model of the real plant and they suffer from the explosion of complexity problem. These two challenges may be mitigated by Artificial Neural Networks (ANNs) that have been widely studied due to their unique features and advantages in system identification and controller design. Viewed from this perspective, this survey provides a comprehensive literature review on combined MBC-ANN techniques that are suitable for UAV flight control, i.e., low-level control. The objective is to pave the way and establish a foundation for efficient controller designs with performance guarantees. A reference template is used throughout the survey as a common basis for comparative studies to fairly determine capabilities and limitations of existing research. The end-result offers supported information for advantages, disadvantages and applicability of a family of relevant controllers to UAV prototypes.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-020-01227-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42154-020-00113-1,Deep Reinforcement Learning Enabled Decision-Making for Autonomous Driving at Intersections,Automotive Innovation,10.1007/s42154-020-00113-1,Springer,2020-12-01,"Road intersection is one of the most complex and accident-prone traffic scenarios, so it’s challenging for autonomous vehicles (AVs) to make safe and efficient decisions at the intersections. Most of the related studies focus on the solution to a single scenario or only guarantee safety without considering driving efficiency. To address these problems, this study proposed a deep reinforcement learning enabled decision-making framework for AVs to drive through intersections automatically, safely and efficiently. The mapping relationship between traffic images and vehicle operations was obtained by an end-to-end decision-making framework established by convolutional neural networks. Traffic images collected at two timesteps were used to calculate the relative velocity between vehicles. Markov decision process was employed to model the interaction between AVs and other vehicles, and the deep Q-network algorithm was utilized to obtain the optimal driving policy regarding safety and efficiency. To verify the effectiveness of the proposed decision-making framework, the top three accident-prone crossing path crash scenarios at intersections were simulated, when different initial vehicle states were adopted for better generalization capability. The results showed that the developed method could make AVs drive safely and efficiently through intersections in all of the tested scenarios.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42154-020-00113-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11569-020-00374-4,Programming Away Human Rights and Responsibilities? “The Moral Machine Experiment” and the Need for a More “Humane” AV Future,NanoEthics,10.1007/s11569-020-00374-4,Springer,2020-12-01,"Dilemma situations involving the choice of which human life to save in the case of unavoidable accidents are expected to arise only rarely in the context of autonomous vehicles (AVs). Nonetheless, the scientific community has devoted significant attention to finding appropriate and (socially) acceptable automated decisions in the event that AVs or drivers of AVs were indeed to face such situations. Awad and colleagues, in their now famous paper “The Moral Machine Experiment”, used a “multilingual online ‘serious game’ for collecting large-scale data on how citizens would want AVs to solve moral dilemmas in the context of unavoidable accidents.” Awad and colleagues undoubtedly collected an impressive and philosophically useful data set of armchair intuitions. However, we argue that applying their findings to the development of “global, socially acceptable principles for machine learning” would violate basic tenets of human rights law and fundamental principles of human dignity. To make its arguments, our paper cites principles of tort law, relevant case law, provisions from the Universal Declaration of Human Rights, and rules from the German Ethics Code for Autonomous and Connected Driving.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11569-020-00374-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10670-020-00331-3,"Robot Ethics 2.0. From Autonomous Cars to Artificial Intelligence—Edited by Patrick Lin, Keith Abney, Ryan Jenkins. New York: Oxford University Press, 2017. Pp xiii + 421",Erkenntnis,10.1007/s10670-020-00331-3,Springer,2020-10-22,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10670-020-00331-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1134/S2075108720040100,UAV Navigation System Autonomous Correction Algorithm Based on Road and River Network Recognition,Gyroscopy and Navigation,10.1134/S2075108720040100,Springer,2020-10-01,Abstract —The paper considers an original autonomous correction algorithm for UAV navigation system based on comparison between terrain images obtained by onboard machine vision system and vector topographic map images. Comparison is performed by calculating the homography of vision system images segmented using the convolutional neural network and the vector map images. The presented results of mathematical and flight experiments confirm the algorithm effectiveness for navigation applications.,http://link.springer.com/openurl/fulltext?id=doi:10.1134/S2075108720040100,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-020-00242-0,Toward Implementing the ADC Model of Moral Judgment in Autonomous Vehicles,Science and Engineering Ethics,10.1007/s11948-020-00242-0,Springer,2020-10-01,"Autonomous vehicles (AVs)—and accidents they are involved in—attest to the urgent need to consider the ethics of artificial intelligence (AI). The question dominating the discussion so far has been whether we want AVs to behave in a ‘selfish’ or utilitarian manner. Rather than considering modeling self-driving cars on a single moral system like utilitarianism, one possible way to approach programming for AI would be to reflect recent work in neuroethics. The agent–deed–consequence (ADC) model (Dubljević and Racine in AJOB Neurosci 5(4):3–20, 2014a, Behav Brain Sci 37(5):487–488, 2014b) provides a promising descriptive and normative account while also lending itself well to implementation in AI. The ADC model explains moral judgments by breaking them down into positive or negative intuitive evaluations of the agent, deed, and consequence in any given situation. These intuitive evaluations combine to produce a positive or negative judgment of moral acceptability. For example, the overall judgment of moral acceptability in a situation in which someone committed a deed that is judged as negative (e.g., breaking a law) would be mitigated if the agent had good intentions and the action had a good consequence. This explains the considerable flexibility and stability of human moral judgment that has yet to be replicated in AI. This paper examines the advantages and disadvantages of implementing the ADC model and how the model could inform future work on ethics of AI in general.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-020-00242-0,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-020-00323-8,Theoretical Understanding of Deep Learning in UAV Biomedical Engineering Technologies Analysis,SN Computer Science,10.1007/s42979-020-00323-8,Nature,2020-09-24,"The unmanned aerial vehicles (UAVs) emerged into a promising research trend within the recurrent year where current and future networks are to use enhanced connectivity in these digital immigrations in different fields like medical, communication, search, and rescue operations among others. The current technologies are using fixed base stations to operate on-site and off-site in the fixed position with its associated problems like poor connectivity. This opens gates for the UAVs technology to be used as a mobile alternative to increase accessibility with a fifth-generation (5G) connectivity that focuses on increased availability and connectivity. There has been less usage of wireless technologies in the medical field. This paper first presents a study on deep learning to medical field application in general, and provides detailed steps that are involved in the multi-armed bandit approach in solving UAV biomedical engineering technologies devices and medical exploration to exploitation dilemma. The paper further presents a detailed description of the bandit network applicability to achieve close optimal medical engineered devices’ performance and efficiency. The simulated results depicted that a multi-armed bandit problem approach can be applied in optimizing the performance of any medical networked device issue compared to the Thompson sampling, Bayesian algorithm, and ε-greedy algorithm. The results obtained further illustrated the optimized utilization of biomedical engineering technologies systems achieving thus close optimal performance on the average period through deep learning of realistic medical situations.",https://www.nature.com/articles/s42979-020-00323-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42421-020-00021-0,Automated Vehicle Control at Freeway Lane-drops: a Deep Reinforcement Learning Approach,Journal of Big Data Analytics in Transportation,10.1007/s42421-020-00021-0,Springer,2020-08-01,"This study develops an optimal, real-time and adaptive control algorithm for helping a Connected and Automated Vehicle (CAV), navigate a freeway lane-drop site (e.g. work zones). The proposed traffic control strategy is based on the Deep Q-Network (DQN) Reinforcement Learning (RL) algorithm, and is designed to determine the driving speed and lane-change maneuvers that would enable the CAV to go through the bottleneck, with the least amount of delay. The DQN RL agent was trained using the microscopic traffic simulator VISSIM, where the learning focused on how the CAV may be able to optimally maneuver the lane drop site while driving as close as possible to the freeway speed limit. VISSIM was also used to compare the performance of the DQN-controlled AV, as opposed to a human-driven vehicle with no intelligent control, in terms of the driving speed or travel time needed to traverse the lane drop site, under a congested, real life-like traffic scenario. The research findings demonstrate the promise of DQN RL in allowing the CAV to intelligently, and optimally navigate, through the lane drop site. Specifically, for the scenario for which the agent was trained, the reduction in the CAV travel time was around 96 percent, compared to the base case. The robustness of the RL agent was further tested on various scenarios different from the training case. For those cases, the mean and standard deviation of the reductions in the travel of the DQN-controlled CAV travel times, compared to the base case, were around 31% and 61%, respectively.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42421-020-00021-0,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-019-04653-4,An unmanned aerial vehicle-aided node localization using an efficient multilayer perceptron neural network in wireless sensor networks,Neural Computing and Applications,10.1007/s00521-019-04653-4,Springer,2020-08-01,"Localization of sensor node is decisive for many localization-based scenarios of wireless sensor networks (WSNs). Node localization using fixed terrestrial anchor nodes (ANs) equipped with global positioning system (GPS) modules suffers from high deployment cost and poor localization accuracy, because the terrestrial AN propagates signals to the unknown nodes (UNs) through unreliable ground-to-ground channel. However, the ANs deployed in unmanned aerial vehicles (UAVs) with a single GPS module communicate over reliable air-to-ground channel, where almost clear line-of-sight path exists. Thus, the localization accuracy and deployment cost are better with aerial anchors than terrestrial anchors. However, still the nonlinear distortions imposed in propagation channel limit the performance of classical RSSI and least square localization schemes. So, the neural network (NN) models can become good alternative for node localization under such nonlinear conditions as they can do complex nonlinear mapping between input and output. Since the multilayer perceptron (MLP) is a robust tool in the assembly of NNs, MLP-based localization scheme is proposed for UN localization in UAV-aided WSNs. The detailed simulation analysis provided in this paper prefers the MLP localization scheme as they exhibit improved localization accuracy and deployment cost.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-019-04653-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s12544-020-00438-2,Towards behaviour based testing to understand the black box of autonomous cars,European Transport Research Review,10.1186/s12544-020-00438-2,Springer,2020-07-29,"Background Autonomous cars could make traffic safer, more convenient, efficient and sustainable. They promise the convenience of a personal taxi, without the need for a human driver. Artificial intelligence would operate the vehicle instead. Especially deep neural networks (DNNs) offer a way towards this vision due to their exceptional performance particularly in perception. DNNs excel in identifying objects in sensor data which is essential for autonomous driving. These networks build their decision logic through training instead of explicit programming. A drawback of this technology is that the source code cannot be reviewed to assess the safety of a system. This leads to a situation where currently used methods for regulatory approval do not work to validate a promising new piece of technology. Objective In this paper four approaches are highlighted that might help understanding black box technical systems for autonomous cars by focusing on its behaviour instead. The method of experimental psychology is proposed to model the inner workings of DNNs by observing its behaviour in specific situations. It is argued that penetration testing can be applied to identify weaknesses of the system. Both can be applied to improve autonomous driving systems. The shadowing method reveals behaviour in a naturalistic setting while ensuring safety. It can be seen as a theoretical driving exam. The supervised driving method can be utilised to decide if the technology is safe enough. It has potential to be developed into a practical driving exam.",http://link.springer.com/openurl/fulltext?id=doi:10.1186/s12544-020-00438-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-019-04574-3,A passive detection algorithm for low-altitude small target based on a wavelet neural network,Soft Computing,10.1007/s00500-019-04574-3,Springer,2020-07-01,"A passive detection algorithm is presented for multiple low-altitude small targets, which employs a wavelet neural network (WNN). The slope, kurtosis, and skewness are employed as the features for low-altitude small target detection, and an algorithm is given to determine the number of targets. A WNN is used to establish a relationship between signal classes and the signal characteristics using training signals. Then, signals are classified as either target present or target not present using the WNN. Indoor data from a research laboratory and outdoor data from a bridge in the Jimo District, Qingdao, were used for training and evaluation. The performance results show that the error rate with the proposed WNN-based algorithm is better than those based on the slope, skewness, and kurtosis of signal. Furthermore, the proposed algorithm is better than those based on other neural networks such as BPNN, RBFNN, SOMNN, and SVM. At a distance of 3 km, the recognition rate is greater than 84%, which is better than other techniques such as visual recognition, acoustic, and active radar.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00500-019-04574-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-019-00130-2,"The Future of Transportation: Ethical, Legal, Social and Economic Impacts of Self-driving Vehicles in the Year 2025",Science and Engineering Ethics,10.1007/s11948-019-00130-2,Springer,2020-06-01,"Self-driving vehicles (SDVs) offer great potential to improve efficiency on roads, reduce traffic accidents, increase productivity, and minimise our environmental impact in the process. However, they have also seen resistance from different groups claiming that they are unsafe, pose a risk of being hacked, will threaten jobs, and increase environmental pollution from increased driving as a result of their convenience. In order to reap the benefits of SDVs, while avoiding some of the many pitfalls, it is important to effectively determine what challenges we will face in the future and what steps need to be taken now to avoid them. The approach taken in this paper is the construction of a likely future (the year 2025), through the process of a policy scenario methodology, if we continue certain trajectories over the coming years. The purpose of this is to articulate issues we currently face and the construction of a foresight analysis of how these may develop in the next 6 years. It will highlight many of the key facilitators and inhibitors behind this change and the societal impacts caused as a result. This paper will synthesise the wide range of ethical, legal, social and economic impacts that may result from SDV use and implementation by 2025, such as issues of autonomy, privacy, liability, security, data protection, and safety. It will conclude with providing steps that we need to take to avoid these pitfalls, while ensuring we reap the benefits that SDVs bring.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-019-00130-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12205-020-2074-y,UAV-RFID Integration for Construction Resource Localization,KSCE Journal of Civil Engineering,10.1007/s12205-020-2074-y,Springer,2020-06-01,"Location data of construction resources are important in understanding on the context of a construction site, yet most sites still rely on people’s observations to localize their resources. Among then various localization technologies, radio frequency identification (RFID) is considered as a good solution. However, RFID either provides limited location data when fixed receivers are used, or it requires considerable manpower for scanning the tagged resources when hand-held receivers are used. These requirements result in inefficiency and impractical demands on time and cost, particularly in the case of complex or large-scale sites. This study attempted to overcome the limitations by proposing an integrated unmanned aerial vehicle-RFID (UAV-RFID) platform to replace the considerable manpower with the UAV and to enable identifying tags on a site. It applies deep learning algorithms to localize an RFID tag position within an acceptable range of accuracy, thereby demonstrating the feasibility of the integrated platform for construction resource localization.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12205-020-2074-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10812-020-01001-6,Desertification Glassland Classification and Three-Dimensional Convolution Neural Network Model for Identifying Desert Grassland Landforms with Unmanned Aerial Vehicle Hyperspectral Remote Sensing Images,Journal of Applied Spectroscopy,10.1007/s10812-020-01001-6,Springer,2020-05-01,"Based on deep learning, a desertification grassland classification (DGC) and three-dimensional convolution neural network (3D-CNN) model is established. The F-norm^ 2 paradigm is used to reduce the data; the data volume was effectively reduced while ensuring the integrity of the spatial information. Through structure and parameter optimization, the accuracy of the model is further improved by 9.8%, with an overall recognition accuracy of the optimized model greater than 96.16%. Accordingly, high-precision classification of desert grassland features is achieved, informing continued grassland remote sensing research.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10812-020-01001-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01073-3,Towards Real-Time Path Planning through Deep Reinforcement Learning for a UAV in Dynamic Environments,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01073-3,Springer,2020-05-01,"Path planning remains a challenge for Unmanned Aerial Vehicles (UAVs) in dynamic environments with potential threats. In this paper, we have proposed a Deep Reinforcement Learning (DRL) approach for UAV path planning based on the global situation information. We have chosen the STAGE Scenario software to provide the simulation environment where a situation assessment model is developed with consideration of the UAV survival probability under enemy radar detection and missile attack. We have employed the dueling double deep Q-networks (D3QN) algorithm that takes a set of situation maps as input to approximate the Q-values corresponding to all candidate actions. In addition, the ε-greedy strategy is combined with heuristic search rules to select an action. We have demonstrated the performance of the proposed method under both static and dynamic task settings.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01073-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11053-019-09573-7,Prediction of Blast-Induced Ground Vibration Intensity in Open-Pit Mines Using Unmanned Aerial Vehicle and a Novel Intelligence System,Natural Resources Research,10.1007/s11053-019-09573-7,Springer,2020-04-01,"Predicting and reducing blast-induced ground vibrations is a common concern among engineers and mining enterprises. Dealing with these vibrations is a challenging issue as they may result in the instability of the surrounding structures, highways, water pipes, railways, and residential areas. In this study, the effects of blasting in a quarry mine in Vietnam were examined. A total of 25 blasting events were investigated with the help of an unmanned aerial vehicle, micromate instruments, and blast patterns, and 83 observations were recorded. Subsequently, the fuzzy C-means clustering (FCM) algorithm was applied to classify the 83 observations based on the blast parameters. Finally, based on the classification of the blasts, quantile regression neural network (QRNN) models were developed. The combination of FCM and QRNN models resulted in a novel, hybrid model (FCM-QRNN) for predicting blast-induced ground vibration. The US Bureau of Mines (USBM), random forest (RF), QRNN (without clustering), and artificial neural network (ANN) models were also considered and compared with the FCM-QRNN model to obtain a comprehensive assessment of the proposed model. The results indicate that the proposed FCM-QRNN model has a higher accuracy than the other models: USBM, QRNN, RF, and ANN. The proposed model can be used to control the undesirable effects of blast-induced ground vibration. Although this study and the proposed FCM-QRNN model are original works with positive results, the performance of this model in other locations still needs to be considered as a case study for further scientific information.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11053-019-09573-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40435-018-0478-z,Novel SMC control design for path following of autonomous vehicles with uncertainties and mismatched disturbances,International Journal of Dynamics and Control,10.1007/s40435-018-0478-z,Springer,2020-03-01,"The article propose a novel robust, accurate, and fast control strategy with uncertainties/mismatched disturbances for path following control of autonomous vehicles using an innovative sliding mode control (SMC).The molded SMC is based on gain scheduling with fuzzy system, the algorithm of a radial basis function neural networks (RBFNN) and disturbance observer (DOB). The fuzzy system provide an automatic adjustment of the gain of SMC in order to compensate variations of system parameters; the use of DOB is to estimate the mismatched disturbances, and the RBFNN is for assessing the uncertainties. In addition, the stability of the closed-loop system is proved by the Lyapunov stability theorem. The proposed controller is applied to the path following of autonomous vehicle in extreme driving condition at high speed and under different road adhesion conditions. To show the effectiveness of our controller, simulation results have been compared with other robust strategies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40435-018-0478-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-019-01031-z,An Intelligent Hybrid Artificial Neural Network-Based Approach for Control of Aerial Robots,Journal of Intelligent & Robotic Systems,10.1007/s10846-019-01031-z,Springer,2020-02-01,"In this work, a learning model-free control method is proposed for accurate trajectory tracking and safe landing of unmanned aerial vehicles (UAVs). A realistic scenario is considered where the UAV commutes between stations at high-speeds, experiences a single motor failure while surveying an area, and thus requires to land safely at a designated secure location. The proposed challenge is viewed solely as a control problem. A hybrid control architecture – an artificial neural network (ANN)-assisted proportional-derivative controller – is able to learn the system dynamics online and compensate for the error generated during different phases of the considered scenario: fast and agile flight, motor failure, and safe landing. Firstly, it deals with unmodelled dynamics and operational uncertainties and demonstrates superior performance compared to a conventional proportional-integral-derivative controller during fast and agile flight. Secondly, it behaves as a fault-tolerant controller for a single motor failure case in a coaxial hexacopter thanks to its proposed sliding mode control theory-based learning architecture. Lastly, it yields reliable performance for a safe landing at a secure location in case of an emergency condition. The tuning of weights is not required as the structure of the ANN controller starts to learn online, each time it is initialised, even when the scenario changes – thus, making it completely model-free. Moreover, the simplicity of the neural network-based controller allows for the implementation on a low-cost low-power onboard computer. Overall, the real-time experiments show that the proposed controller outperforms the conventional controller.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-019-01031-z,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_75,Distance Measurement for Self-driving Vehicles Using Data Fusion and Machine Learning,"Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_75,Springer,2020-01-01,"For certain mobile robots and self driving vehicles, accurate measurement of distance ahead of them is indispensable. Several sensors are utilized to achieve this. This work is on fusing the obtained data from two sensors namely Leddar M-16 and RPLidar 360. A comparison of the accuracy of the distance measured from the vehicle to obstacle using Leddar M-16 and RPLidar 360 is being done. Also these results are being compared to the improved accuracy of the resultant from both sensors after the data is fused together to produce a different set of values. Analysis on the data is done using a tool named Weka. Test bed and experiments were designed for collection of data. A machine learning technique, linear regression is used for improving accuracy of the measurement.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_75,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-44289-7_50,Path Planning of a Self Driving Vehicle Using Artificial Intelligence Techniques and Machine Vision,Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020),10.1007/978-3-030-44289-7_50,Springer,2020-01-01,"This paper aims to implement an efficient model of the most optimum path to follow an object on a Self Driving Vehicle (SDV). The path of the vehicle is predicted by using Machine Vision (MV) and Neural networks (NN) model. The NN model uses numerous amounts of training data. First the system works by using the MV algorithms to detect objects with predefined colors. Then, the location of the object is fed to the trained NN to get the speeds of the motors needed to reach the object. The training data are obtained from the manual driving of the vehicle in different experiment settings. In this paper, the neural model is compared with two other methods: object detection using MV model and fuzzy logic (FL) model to prove the efficiency of the neural model. All the three models depend on the live record of the camera board and its fast detection of objects using MV algorithms. The three models showed quite similar results; however, the NN model was much more stable and closer to the optimum path.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-44289-7_50,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-63486-5_16,Deep Learning-Based Decision Making for Autonomous Vehicle at Roundabout,Towards Autonomous Robotic Systems,10.1007/978-3-030-63486-5_16,Springer,2020-01-01,"This study looks at the facilitation of computer vision and machine learning, which helps Autonomous vehicles (AVs) make pertinent decisions before entering a roundabout. A deep learning-based decision-making system (DBDM) is proposed in order to make a correct “Enter” or “Wait” decision when an AV enters a roundabout. In this regard, videos of human drivers negotiating different normal roundabouts, differing in terms of size, are employed alongside a range of different learning algorithms (e.g. VGG-16, Resnet-50 and Xception). In total, 130 videos captured at normal roundabouts were used to test the models, and VGG-16 performed best with an accuracy rate of 92.57% comparing with pervious work (GBIPA-SC-NR), thus suggesting that the proposed DBDM method can be applied effectively for AVs.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-63486-5_16,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-4301-2_17,Steering Angle Estimation for Self-driving Car Using Deep Learning,"Machine Learning and Metaheuristics Algorithms, and Applications",10.1007/978-981-15-4301-2_17,Springer,2020-01-01,"The contemporary age has seen a tremendous increase in the number of road accidents. Traffic accidents are commonly caused by driver error, mobile phone usage, in-car audio and video entertainment systems, and extensive traffic. The road accident in India causes one death every four minutes. Imagine if everyone can easily and safely get around while driving is not tired, drunk or distracted. Self-driving means of transport are those in which drivers are never required to drive the vehicle. In self-driving car, time spent on travel may well be time spent doing what one needs, because all driving is handled by the car. Also referred to as autonomous or “driverless” cars, they mix sensors and code to manage, navigate, and drive the vehicle. The self-driving cars have huge potential to alter the means of transportation. We have proposed an end-to-end method based on deep learning for estimating the steering angle and the accuracy obtained is 98.6%.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-4301-2_17,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-1081-6_5,End-to-End Reinforcement Learning for Self-driving Car,Advanced Computing and Intelligent Engineering,10.1007/978-981-15-1081-6_5,Springer,2020-01-01,"Most of the current self-driving cars make use of multiple algorithms to drive. Furthermore, most of the approaches use supervised learning to train a model to drive the car autonomously. This approach leads to human bias being incorporated into the model. We implement the Deep Q -Learning algorithm to control a simulated car, end-to-end, autonomously. The algorithm is based on reinforcement learning which teaches machines what to do through interactions with the environment. The application of reinforcement learning for driving is of high relevance as it is highly dependent on interactions with the environment. Our model incorporates a CNN as the deep Q network. The system was tested on an open-source car-racing simulator called TORCS. The Deep Q -Learning approach allows the system to be more efficient and robust than a system that has been trained solely through supervised training. Our simulation results show that the system is able to drive autonomously and maneuver complex curves.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-1081-6_5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30425-6_34,Automated Determination of Forest-Vegetation Characteristics with the Use of a Neural Network of Deep Learning,"Advances in Neural Computation, Machine Learning, and Cognitive Research III",10.1007/978-3-030-30425-6_34,Springer,2020-01-01,"The article proposes a method of automated solution for determining the species composition, stock coefficient and other characteristics of forest plantations with the use of deep learning. The analysis of existing approaches and ways of forest inventory, which include the use of LiDAR systems and machine learning methods, is carried out. An algorithm is proposed for solving this problem and features of its implementation are given. The problem of combining the data of a “dense cloud” and a lidar survey is considered, a possible solution is proposed. The problem of segmentation of tree crowns among many other objects in this data is also considered. For the segmentation of crowns, it is proposed to use the PointNet neural network of deep learning, which allows segmentation of objects by submitting a point cloud to the input. The description of the architecture and the main features of the neural network use are briefly given. The path of further research is determined.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30425-6_34,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-15-0633-8_102,Image Processing for UAV Using Deep Convolutional Encoder–Decoder Networks with Symmetric Skip Connections on a System on Chip (SoC),International Conference on Intelligent Computing and Smart Communication 2019,10.1007/978-981-15-0633-8_102,Springer,2020-01-01,"Unmanned Aerial Vehicle (UAV) applications require capturing and analysis of aerial images and thus necessitate identification of obstacles, recognition of objects from a given set within images, and analogous tasks. In situations where the navigation or further action depends on the results of the analysis there exist time constraints. Ground based analysis is not feasible due to latency, connectivity or bandwidth constraints. A possible approach is to use a System on Chip (SoC) having GPU with their substantial parallel analysis capability for onboard image analysis. Developments in the domain of Deep Neural Networks have enabled a mechanism to design efficient and tailored solutions for image analysis. This research proposes the use of Deep Convolutional Encoder–Decoder Networks with Symmetric Skip Connections on a SoC having GPU to perform image analysis. The outlined trained network successfully completes the task of image segmentation using the SpaceNet dataset on a NVIDIA Jetson TX2 embedded computer.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-15-0633-8_102,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-59535-7_6,Navigating Autonomous Vehicle at the Road Intersection Simulator with Reinforcement Learning,Artificial Intelligence,10.1007/978-3-030-59535-7_6,Springer,2020-01-01,"In this paper, we consider the problem of controlling an agent that simulates the behavior of an self-driving car when passing a road intersection together with other vehicles. We consider the case of using smart city systems, which allow the agent to get full information about what is happening at the intersection in the form of video frames from surveillance cameras. The paper proposes the implementation of a control system based on a trainable behavior generation module. The agent’s model is implemented using reinforcement learning (RL) methods. In our work, we analyze various RL methods (PPO, Rainbow, TD3), and variants of the computer vision subsystem of the agent. Also, we present our results of the best implementation of the agent when driving together with other participants in compliance with traffic rules.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-59535-7_6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-39512-4_8,The Future of User Experience Design in the Interior of Autonomous Car Driven by AI,Intelligent Human Systems Integration 2020,10.1007/978-3-030-39512-4_8,Springer,2020-01-01,"Today it is not easy to imagine what would be the future of user experience (UX) design in the world of Artificial Intelligence (AI). Referring to the sector of autonomous vehicles the paper aims to explore the changes that will be brought by artificial intelligence to the innovative sector of the self-driving car. According to these transformation car interiors and passengers experiences will become very different from the actual one. The aim of the research is, starting from different kind of passengers needs (Human Centered Design approach) individuating essential factors to design autonomous cars interiors and in particular to design innovative interfaces for a better communication with the passengers and a high level of living experience for different kind of users.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-39512-4_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-38040-3_11,Lane Keep Assist System for an Autonomous Vehicle Using Support Vector Machine Learning Algorithm,Innovative Data Communication Technologies and Application,10.1007/978-3-030-38040-3_11,Springer,2020-01-01,"Autonomous self driving vehicles are getting greater attention and this would be the future requirement in Automotive domain. However, Fail proof driving is the only solution to reduce the rate of accidents and that makes the driverless vehicles as a possible one. In man handled vehicles, by using Advance Driver Authorization System (ADAS), accident free driving can be ensured. This paper focuses on one of the ways to contribute towards accident free driving of autonomous vehicles by deploying a novel Lane Keep Assist (LKA) system. A Machine Learning algorithm has been used in proposed LKA system for tracking the lane of the autonomous vehicles by providing the required inputs. Proposed LKA system has been demonstrated in Matlab/Simulink platform and the results have been presented in this paper.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-38040-3_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-30465-2_11,Object Detection for Autonomous Vehicle Using TensorFlow,"Intelligent Computing, Information and Control Systems",10.1007/978-3-030-30465-2_11,Springer,2020-01-01,"The area of computer vision is emerging continually with the increasing interaction and development to provide a comfortable interaction between human and machines. One of the key aspects in the process of computer vision is object detection. Either objects can be identified partially or close to the original objects. The accuracy in detecting the objects can be improved by using state-of-the-art deep learning models like faster-Regional Convoluted Neural Network (faster-RCNN), You Only Look Once model (YOLO), Single Shot Detector (SSD) etc. Traditional algorithms can’t recognize objects as efficiently due to its limitations. Whereas the deep learning models require large amount of data for training the dataset, which has more resource and labour intensive in nature. The selection of algorithm determines its precision in object detection as well as its reliability. The recognition and classification of object begins with preparing dataset followed by splitting the dataset into training dataset and test dataset. The task of training the dataset can be assisted by both traditional as well as modern deep neural networks. The loss per step or epoch is calculated on the training dataset to signify the efficiency and accuracy of the model. In this model, the loss per step is 2.73. We have achieved a maximum accuracy of about 85.18% after training the dataset used.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-30465-2_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-51935-3_9,Vine Disease Detection by Deep Learning Method Combined with 3D Depth Information,Image and Signal Processing,10.1007/978-3-030-51935-3_9,Springer,2020-01-01,"Vine disease detection (VDD) is an important asset to predict a probable contagion of virus or fungi. Diseases that spreads through the vineyard has a huge economic impact, therefore it is considered as a challenge for viticulture. Automatic detection and mapping of vine disease in earlier stage can help to limit its impact and reduces the use of chemicals. This study deals with the problem of locating symptomatic areas in images from an unmanned aerial vehicle (UAV) using the visible and infrared domains. This paper, proposes a new method, based on segmentation by a convolutional neuron network SegNet and a depth map (DM), to delineate the asymptomatic regions in the vine canopy. The results obtained showed that SegNet combined with the depth information give better accuracy than a SegNet segmentation alone.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-51935-3_9,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-31280-0_1,Learning a Behavior Model of Hybrid Systems Through Combining Model-Based Testing and Machine Learning,Testing Software and Systems,10.1007/978-3-030-31280-0_1,Springer,2019-01-01,"Models play an essential role in the design process of cyber-physical systems. They form the basis for simulation and analysis and help in identifying design problems as early as possible. However, the construction of models that comprise physical and digital behavior is challenging. Therefore, there is considerable interest in learning such hybrid behavior by means of machine learning which requires sufficient and representative training data covering the behavior of the physical system adequately. In this work, we exploit a combination of automata learning and model-based testing to generate sufficient training data fully automatically. Experimental results on a platooning scenario show that recurrent neural networks learned with this data achieved significantly better results compared to models learned from randomly generated data. In particular, the classification error for crash detection is reduced by a factor of five and a similar F1-score is obtained with up to three orders of magnitude fewer training samples.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-31280-0_1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-8506-2_56,End-to-End Adaptive Cruise Control Based on Timing Network,Proceedings of the 19th Asia Pacific Automotive Engineering Conference & SAE-China Congress 2017: Selected Papers,10.1007/978-981-10-8506-2_56,Springer,2019-01-01,"In recent years, driverless vehicle technology receives more attention because of its excellent performance on safety and efficiency. On the other hand, driverless vehicle calls for high-precision environmental perception and expert-like control strategies, which needs both lots of costly sensors and complex algorithms, and makes it difficult to achieve. Machine learning provides a new theoretical basis to solve this problem with big data, while most of data has not been calibrated yet. To solve these problems partly, a machine learning model based on a temporal neural network is described in this paper to achieve “end-to-end” self-driving from uncalibrated monocular images to control signals. The proposed approach is designed for adaptive cruise control situation. The approach is implemented in a simulation platform which has the control signal data from “expert.” According to the experiment in simulation platform, it shows that the proposed approach achieves “end-to-end” self-driving and has good performance on the prediction of desired acceleration.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-8506-2_56,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-98923-5_7,Sustainable Interdependent Networks from Smart Autonomous Vehicle to Intelligent Transportation Networks,Sustainable Interdependent Networks II,10.1007/978-3-319-98923-5_7,Springer,2019-01-01,"The next step to the evolution of human transportation is the replacement of human driver by the artificial-intelligence-capable machine (i.e., autonomous vehicle). The prospect of improving aspects of lives including better utilization of cost, increased mobility, and independence as well as futuristic urban planning are some of the foreseen benefits. Regardless, the challenges remain especially to convince the consumers to trust the machines in exchange for their safety and ultimately their lives. This chapter seeks to highlight the ethical implications of the autonomous technology as a prerequisite to establishing trust between man and machine. Recent studies on the technology are cited in this chapter in order to give an overall outlook of the current discussion on the topic including on the issue of ethics. The objectives of the ethical consideration have to be grounded to the main objective of benefitting the society as a whole. As such, individual rights to access of information, system configuration, and education regarding autonomous technology should be upheld. In the end, it is important to integrate the autonomous systems into larger, interdependent transportation network systems in planning the future urban infrastructure and realize the full benefits of the technologies.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98923-5_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-13-9917-6_36,Tiny Vehicle Detection from UAV Imagery,Image and Graphics Technologies and Applications,10.1007/978-981-13-9917-6_36,Springer,2019-01-01,"In the past decade, great progress has been made in general object detection based on deep convolutional neural networks. However, object detection from Unmanned Aerial Vehicles (UAV) imagery received not so much concern. In this paper, a densely connected feature mining network is proposed for high accuracy detection. Specifically, multi-scale predictions are used to enhance the feature representation of the tiny vehicles. Furthermore, a streamlined one-stage detection network is used to achieve satisfactory trade-off between speed and accuracy. Finally, a improved distance metric function is integrated into the priors clustering process, which can lead to a better preliminary location before training. The proposed architecture is evaluated on the highly competitive UAV benchmark (UAVDT). The experimental results show that the proposed dense-darknet network has achieved a competitive performance of 42.03% mAP (mean Average Precision) and good generalization ability on the other UAV benchmarks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-13-9917-6_36,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-23538-3_10,A Method to Automatic Measuring Riding Comfort of Autonomous Vehicles: Based on Passenger Subjective Rating and Vehicle Parameters,"Design, User Experience, and Usability. Application Domains",10.1007/978-3-030-23538-3_10,Springer,2019-01-01,"As a milestone product of the AI era, the autonomous vehicle has attracted tremendous attention from the whole society. When autonomous vehicles (AV) provide transportation services as passenger vehicles in the future, a comfortable riding experience will be the fundamental element of usability. In such a case, it is necessary to establish an objective and sound evaluation system to evaluate the comfort level of autonomous vehicles. We hereby develop the comfort level model of autonomous vehicles with the following three steps: (a) Explore subjective evaluation indicators: Invite passengers to test autonomous vehicles and collect their ratings of the comfort level; (b) Establish the subjective comfort evaluation model: classify the evaluation indicators, continuously collect the evaluation data of the comfort level from the passengers during the testing process, and then use the structural modelling method to form a subjective evaluation model of the comfort level; (c) Develop the automatic scoring tool: collect subjective and objective data through data collection apps, form a calculation function with machine learning algorithm that fits the subjective and objective data, and develop an automatic scoring tool based on it. This precisely developed evaluation system and the empirical data-based scoring tool can be used to guide technological development, optimize algorithms, and improve strategies within the AV corporate. On the other hand, it can help to unify evaluation standard for AV industry, improving the experience of autonomous vehicle rides.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-23538-3_10,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-26250-1_34,The Moral Machine: Is It Moral?,"Computer Safety, Reliability, and Security",10.1007/978-3-030-26250-1_34,Springer,2019-01-01,"Many recent studies have been proposing, discussing and investigating moral decisions in scenarios of imminent accident involving Autonomous Vehicles (AV). Those studies investigate people’s expectations about the best decisions the AVs should make when some life needs to be sacrificed to save other ones. A recent research found those preferences have strong ties to the respondents’ cultural traits. The present position paper questions the importance and the real value of those discussions. It also argues about their morality. Finally, an approach based on risk-oriented decision making is discussed as an alternative way to tackle those situations framed as “moral dilemmas” under the light of safety engineering.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-26250-1_34,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s41018-018-0045-4,Search and rescue with autonomous flying robots through behavior-based cooperative intelligence,Journal of International Humanitarian Action,10.1186/s41018-018-0045-4,Springer,2018-12-05,"A swarm of autonomous flying robots is implemented in simulation to cooperatively gather situational awareness data during the first few hours after a major natural disaster. In computer simulations, the swarm is successful in locating over 90% of survivors in less than an hour. The swarm is controlled by new sets of reactive behaviors which are presented and evaluated. The reactive behaviors integrate collision avoidance, battery recharge, formation control, altitude maintenance, and a variety of search methods to optimize the coverage area of camera and heart-beat locator sensors mounted on the robots. The behaviors are implemented in simulation on swarms of sizes from 1 to 20 robots. The simulation uses actual location data, including post-disaster satellite imagery, real locations of damaged and inundated buildings, and realistic victim locations based on personal interviews and accounts. The results demonstrate the value of using behavior-based swarming algorithms to control autonomous unmanned aerial vehicles for post-disaster search and assessment. Three examples of algorithms that have been effective in simulation are presented .",https://www.biomedcentral.com/openurl?doi=10.1186/s41018-018-0045-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42405-018-0091-6,Self-Tuning Proportional Double Derivative-Like Neural Network Controller for a Quadrotor,International Journal of Aeronautical and Space Sciences,10.1007/s42405-018-0091-6,Springer,2018-12-01,"In this paper, a self-tuning proportional double derivative-like neural network nonlinear adaptive controller for attitude tracking control of an unmanned aerial vehicle (UAV) is presented. The proposed scheme consists of neural networks with two neural nodes in the hidden layer and includes activation feedback. The error between the desired angle set-point and the output as well as the change of error is selected as the controller input. The optimal initial weight parameters are obtained by employing an adaptive ant colony optimization. The proposed controller can online tune the weight parameters of the hidden layer with a stable learning rate based on the controller input. The effect of the learning rates on the stability of the neural network controller was analyzed. The designed controller was developed based on a nonlinear model of an UAV with quaternion representation in the presence of parametric uncertainties and external disturbances. Simulation results demonstrate the validity and effectiveness of the proposed algorithm with different reference attitude signals.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s42405-018-0091-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40860-018-0070-5,A survey on verification strategies for intelligent transportation systems,Journal of Reliable Intelligent Environments,10.1007/s40860-018-0070-5,Springer,2018-12-01,"As intelligent systems are increasingly entering everyday life, in domains such as transportation, resource distribution, health care, or retail, developing suitable verification mechanisms for such systems becomes vital. From a formal point of view, the employed intelligent sensor actuator systems (ISAS) constituting such intelligent systems combine three different technologies: control systems, distributed systems, and learning and reasoning. While each of the parent domains features tested and proven verification methods, simply combining the tasks unfortunately leads to a combinatorial explosion of complexity. This paper presents an overview and classification of currently employed techniques for handling ISAS in terms of: cyber-physical systems, intelligent autonomous robots, or intelligent agents. The article argues that each of the three classical perspectives misses one important characteristic of ISAS and proposes to combine the three for a full solution. The paper argues that in particular two mechanisms are promising: an intelligent environments perspective that verifies local safety and techniques for context-aware monitoring that allow a mobile system to leverage context-awareness to reduce complexity for self-monitoring tasks.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s40860-018-0070-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12559-018-9559-8,Distributed Drone Base Station Positioning for Emergency Cellular Networks Using Reinforcement Learning,Cognitive Computation,10.1007/s12559-018-9559-8,Springer,2018-10-01,"Due to the unpredictability of natural disasters, whenever a catastrophe happens, it is vital that not only emergency rescue teams are prepared, but also that there is a functional communication network infrastructure. Hence, in order to prevent additional losses of human lives, it is crucial that network operators are able to deploy an emergency infrastructure as fast as possible. In this sense, the deployment of an intelligent, mobile, and adaptable network, through the usage of drones—unmanned aerial vehicles—is being considered as one possible alternative for emergency situations. In this paper, an intelligent solution based on reinforcement learning is proposed in order to find the best position of multiple drone small cells (DSCs) in an emergency scenario. The proposed solution’s main goal is to maximize the amount of users covered by the system, while drones are limited by both backhaul and radio access network constraints. Results show that the proposed Q -learning solution largely outperforms all other approaches with respect to all metrics considered. Hence, intelligent DSCs are considered a good alternative in order to enable the rapid and efficient deployment of an emergency communication network.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12559-018-9559-8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.3103/S1068798X18100118,Smart Design of Driverless-Vehicle Routes in the Arctic and Far North,Russian Engineering Research,10.3103/S1068798X18100118,Springer,2018-10-01,Abstract An approach to the design of routes for driverless vehicles in the Arctic and Far North is discussed. The proposed approach employs artificial intelligence and drones.,http://link.springer.com/openurl/fulltext?id=doi:10.3103/S1068798X18100118,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41650-018-0029-y,Reinforcement Learning-Based Control for Unmanned Aerial Vehicles,Journal of Communications and Information Networks,10.1007/s41650-018-0029-y,Springer,2018-09-01,"Estates, especially those of public securityrelated companies and institutes, have to protect their privacy from adversary unmanned aerial vehicles (UAVs). In this paper, we propose a reinforcement learning-based control framework to prevent unauthorized UAVs from entering a target area in a dynamic game without being aware of the UAV attack model. This UAV control scheme enables a target estate to choose the optimal control policy, such as jamming the global positioning system signals, hacking, and laser shooting, to expel nearby UAVs. A deep reinforcement learning technique, called neural episodic control, is used to accelerate the learning speed to achieve the optimal UAV control policy, especially for estates with a large area, against complicated UAV attack policies. We analyze the computational complexity for the proposed UAV control scheme and provide its performance bound, including the risk level of the estate and its utility. Our simulation results show that the proposed scheme can reduce the risk level of the target estate and improve its utility against malicious UAVs compared with the selected benchmark scheme.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s41650-018-0029-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12524-018-0756-4,"Tree Crown Detection, Delineation and Counting in UAV Remote Sensed Images: A Neural Network Based Spectral–Spatial Method",Journal of the Indian Society of Remote Sensing,10.1007/s12524-018-0756-4,Springer,2018-06-01,"UAVs are fast emerging as a remote sensing platform to complement satellite based remote sensing. Agriculture and ecology is one of the important applications of UAV remote sensing, also known as low altitude remote sensing (LARS). This work demonstrates the use and potential of LARS in agriculture, particularly small holder open field agriculture. Two UAVs are used for remote sensing. The first UAV is a fixed wing aircraft with a high spatial resolution visible spectrum also known as RGB camera as a payload. The second UAV is a quadrotor UAV with an RGB camera interfaced to an on-board single board computer as the payload. LARS was carried out to acquire aerial high spatial resolution RGB images of different farms. Spectral–spatial classification of high spatial resolution RGB images for detection, delineation and counting of tree crowns in the image is presented. Supervised classification is carried out using extreme learning machine (ELM), a single hidden layer feed forward network neural network classifier. ELM was modelled for RGB values as input feature vectors and binary (tree and non-tree pixels) output class. Due to similarities in spectral intensities, some of the non-tree pixels were classified as tree pixels and in order to remove them, spatial classification was performed on the image. Spatial classification was carried out using thresholded geometrical property filtering techniques. Threshold values chosen for carrying out spatial classification were analysed to obtain optimal values. Finally in the delineation and counting, the connected tree crowns were segmented using Watershed algorithm performed on the image after marking individual tree crowns using Distance Transform method. Five representative UAV images captured at different altitudes with different crowns of banana plant, mango trees and coconut trees were used to demonstrate the performance of the proposed method. The performance was compared with the traditional KMeans spectral–spatial method of clustering. Results and comparison of performance parameters of KMeans spectral–spatial and ELM spectral–spatial classification methods are presented. Results indicate that ELM performed better than KMeans.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12524-018-0756-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10677-018-9909-3,"Lin, P., Abney, K., & Jenkins, R. (Eds.): Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence",Ethical Theory and Moral Practice,10.1007/s10677-018-9909-3,Springer,2018-06-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-018-9909-3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-66379-1_11,A Drone-Based Building Inspection System Using Software-Agents,Intelligent Distributed Computing XI,10.1007/978-3-319-66379-1_11,Springer,2018-01-01,"Regular building inspections are a key means of identifying defects before getting worse or causing a building failure. As a tool for building condition inspections, Unmanned Aerial Vehicles (UAVs) or drones offer considerable potential allowing especially high-rise buildings to be visually assessed with economic and risk-related benefits. One of the critical problems encountered in automating the system is that the whole process involves a very complicated and significant amount of computational tasks, such as UAV control, localisation, image acquisition and abnormality analysis using machine learning techniques. Distributed software agents interact and collaborate each other in complicated systems and improve the reliability, availability and scalability. This research introduces a ubiquitous concept of software-agents to a drone-based building inspection system that is applied to crack-detection on concrete surfaces. The architecture and new features of the proposed system will be discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-66379-1_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-60591-3_3,Automated Situation Analysis as Next Level of Unmanned Aerial Vehicle Artificial Intelligence,Advances in Human Factors in Simulation and Modeling,10.1007/978-3-319-60591-3_3,Springer,2018-01-01,"In this paper automated situation analysis is discussed together with already accessible advantages of artificial intelligence and control systems of unmanned aerial vehicle. Based on previous researches some new solutions are proposed to fulfill safety tasks in case of traffic, fire and criminal threats. Mostly connected with existing solutions, owing to artificial intelligence and hybrid systems they move to next level and provide better results and guideline for further development.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-60591-3_3,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-89656-4_44,Decision Assist for Self-driving Cars,Advances in Artificial Intelligence,10.1007/978-3-319-89656-4_44,Springer,2018-01-01,"Research into self-driving cars has grown enormously in the last decade primarily due to the advances in the fields of machine intelligence and image processing. An under-appreciated aspect of self-driving cars is actively avoiding high traffic zones, low visibility zones, and routes with rough weather conditions by learning different conditions and making decisions based on trained experiences. This paper addresses this challenge by introducing a novel hierarchical structure for dynamic path planning and experiential learning for vehicles. A multistage system is proposed for detecting and compensating for weather, lighting, and traffic conditions as well as a novel adaptive path planning algorithm named Checked State A3C . This algorithm improves upon the existing A3C Reinforcement Learning (RL) algorithm by adding state memory which provides the ability to learn an adaptive model of the best decisions to take from experience.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-89656-4_44,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99229-7_42,Concerns on the Differences Between AI and System Safety Mindsets Impacting Autonomous Vehicles Safety,"Computer Safety, Reliability, and Security",10.1007/978-3-319-99229-7_42,Springer,2018-01-01,"The inflection point in the development of some core technologies enabled the Autonomous Vehicles (AV). The unprecedented growth rate in Artificial Intelligence (AI) and Machine Learning (ML) capabilities, focusing only on AVs, is expected to shift the transportation paradigm and bring relevant benefits to the society, such as accidents reduction. However, recent AVs accidents resulted in life losses. This paper presents a viewpoint discussion based on findings from a preliminary exploratory literature review. It was identified an important misalignment between AI and Safety research communities regarding the impact of AI on the safety risks in AV. This paper promotes this discussion, raises concerns on the potential consequences and suggests research topics to reduce the differences between AI and system safety mindsets.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99229-7_42,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-99229-7_41,Could We Issue Driving Licenses to Autonomous Vehicles?,"Computer Safety, Reliability, and Security",10.1007/978-3-319-99229-7_41,Springer,2018-01-01,"Many companies are studying autonomous vehicles. One trend in the development of control algorithms for autonomous vehicles is the use of deep-learning approaches. The general idea is to simulate a human driver’s decision-making and behavior in various scenarios without necessarily knowing why the decision is made. In this position paper, we first argue that traditional safety analysis methods need to be extended to verify deep-learning-based autonomous vehicles. Then, we propose borrowing ideas from the process of issuing driving licenses to human drivers to verify autonomous vehicles. Verification of autonomous vehicles could focus on sufficient training as well as mental and physical health checks. Based on this position, we list several challenges that need to be addressed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-99229-7_41,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-00692-1_35,Embedded Vision System for Automated Drone Landing Site Detection,Computer Vision and Graphics,10.1007/978-3-030-00692-1_35,Springer,2018-01-01,"This paper presents an embedded video subsystem used to classify the terrain, based on an image from a camera located under the drone, for the purpose of an automatic landing system. Colour and texture features, as well as decision trees and support vector machine classifiers were analysed and evaluated. The algorithm was supported with a shadow detection module. It was evaluated on 100 test cases and achieved over 80% performance. The designed video system was implemented on two embedded platforms – a Zynq SoC (System on Chip – Field Programmable Gate Array + ARM processor system) and a Jetson GPU (Graphic Processing Unit + ARM processor system). The performance achieved on both architectures is compared and discussed.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-00692-1_35,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-98131-4_8,Explainable Deep Driving by Visualizing Causal Attention,Explainable and Interpretable Models in Computer Vision and Machine Learning,10.1007/978-3-319-98131-4_8,Springer,2018-01-01,"Deep neural perception and control networks are likely to be a key component of self-driving vehicles. These models need to be explainable—they should provide easy-to-interpret rationales for their behavior—so that passengers, insurance companies, law enforcement, developers etc., can understand what triggered a particular behavior. Here, we explore the use of visual explanations. These explanations take the form of real-time highlighted regions of an image that causally influence the network’s output (steering control). Our approach is two-stage. In the first stage, we use a visual attention model to train a convolutional network end-to-end from images to steering angle. The attention model highlights image regions that potentially influence the network’s output. Some of these are true influences, but some are spurious. We then apply a causal filtering step to determine which input regions actually influence the output. This produces more succinct visual explanations and more accurately exposes the network’s behavior. We demonstrate the effectiveness of our model on three datasets totaling 16 h of driving. We first show that training with attention does not degrade the performance of the end-to-end network. Then we show that the network highlights interpretable features that are used by humans while driving, and causal filtering achieves a useful reduction in explanation complexity by removing features which do not significantly affect the output.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-98131-4_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-96728-8_13,Extending Deep Neural Network Trail Navigation for Unmanned Aerial Vehicle Operation Within the Forest Canopy,Towards Autonomous Robotic Systems,10.1007/978-3-319-96728-8_13,Springer,2018-01-01,"Autonomous flight within a forest canopy represents a key challenge for generalised scene understanding on-board a future Unmanned Aerial Vehicle (UAV) platforms. Here we present an approach for automatic trail navigation within such an unstructured environment that successfully generalises across differing image resolutions - allowing UAV with varying sensor payload capabilities to operate equally in such challenging environmental conditions. Specifically, this work presents an optimised deep neural network architecture, capable of state-of-the-art performance across varying resolution aerial UAV imagery, that improves forest trail detection for UAV guidance even when using significantly low resolution images that are representative of low-cost search and rescue capable UAV platforms.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-96728-8_13,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-74805-4_7,Robocopter,Satellite-Based Earth Observation,10.1007/978-3-319-74805-4_7,Springer,2018-01-01,"In this paper about robocopters the author discusses the challenges of the integration of robotics, artificial intelligence, digitalisation, virtualisation and multicopter aviation technologies driven by the consumer market. After a linguistic decomposition of the word robocopter the robocopter will be defined as a “flying tool” or “flying robot” using, as a multicopter, the typical aviation technologies of a helicopter. A comparison shows the current differences between helicopters and typical unmanned multicopters. From an economic perspective, the quadcopter is most successful as a camera drone, driven by hobbyists like drone racers and photographers. With the use of first-person-view (FPV) glasses during a flight a philosophical dimension occurs, because, in our consciousness, the idea arises that “I am flying” instead of the drone. In Austria, a license from the Austro Control agency is necessary to legally store pictures and videos on a microchip on a drone; therefore, the legal regulations for drones are discussed in a short overview. Robocopters as flying tools with an extended level on autonomy are the next step in automation. But there is also a danger, especially in military applications discussed and shown in various video examples.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-74805-4_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-92537-0_78,Task Assignment Based on a Dual Neural Network,Advances in Neural Networks – ISNN 2018,10.1007/978-3-319-92537-0_78,Springer,2018-01-01,"In this paper, task assignment, such as target assignment and parcel dispatching, for multi-agent systems is addressed. The problems are formulated as the linear assignment problem and its extensions. A dual neural network is used for solving them. Simulation results are reported on assigning multiple agents to multiple targets and dispatching parcels to given destinations using multiple agents.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-92537-0_78,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-94180-6_16,D2TFRS: An Object Recognition Method for Autonomous Vehicles Based on RGB and Spatial Values of Pixels,"Smart Societies, Infrastructure, Technologies and Applications",10.1007/978-3-319-94180-6_16,Springer,2018-01-01,"Autonomous driving is now near future reality which will transform our world due to its numerous benefits. The foremost challenge to this task is to correctly identify the objects in the driving environment. In this work, we propose an object recognition method known as Decision Tree and Decision Fusion based Recognition System (D2TFRS) for autonomous driving. We combined two separate feature sets, which are RGB pixel values and spatial points X,Y of each pixel to form our dataset. The D2TFRS is based on our intuition that reclassification of pre-identified misclassified objects in a driving environment can give better prediction accuracy. Results showed that D2TFRS outperformed AdaBoost classifier and performed better than C5.0 classifier in terms of the classification accuracy and Kappa. In terms of speed, C5.0 outperforms both AdaBoost and D2TFRS. However, D2TFRS outperformed AdaBoost with respect to speed. We strongly believe that D2TFRS will have better parallelization performance compared to the other two methods and it will be investigated in our future work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-94180-6_16,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-03769-7_23,Evaluating Perception Systems for Autonomous Vehicles Using Quality Temporal Logic,Runtime Verification,10.1007/978-3-030-03769-7_23,Springer,2018-01-01,"For reliable situation awareness in autonomous vehicle applications, we need to develop robust and reliable image processing and machine learning algorithms. Currently, there is no general framework for reasoning about the performance of perception systems. This paper introduces Timed Quality Temporal Logic (TQTL) as a formal language for monitoring and testing the performance of object detection and situation awareness algorithms for autonomous vehicle applications. We demonstrate that it is possible to describe interesting properties as TQTL formulas and detect cases where the properties are violated.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-03769-7_23,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-01258-8_25,End-to-End Deep Structured Models for Drawing Crosswalks,Computer Vision – ECCV 2018,10.1007/978-3-030-01258-8_25,Springer,2018-01-01,"In this paper we address the problem of detecting crosswalks from LiDAR and camera imagery. Towards this goal, given multiple LiDAR sweeps and the corresponding imagery, we project both inputs onto the ground surface to produce a top down view of the scene. We then leverage convolutional neural networks to extract semantic cues about the location of the crosswalks. These are then used in combination with road centerlines from freely available maps (e.g., OpenStreetMaps) to solve a structured optimization problem which draws the final crosswalk boundaries. Our experiments over crosswalks in a large city area show that 96.6% automation can be achieved.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-01258-8_25,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10892-017-9252-2,Incorporating Ethics into Artificial Intelligence,The Journal of Ethics,10.1007/s10892-017-9252-2,Springer,2017-12-01,"This article reviews the reasons scholars hold that driverless cars and many other AI equipped machines must be able to make ethical decisions, and the difficulties this approach faces. It then shows that cars have no moral agency, and that the term ‘autonomous’, commonly applied to these machines, is misleading, and leads to invalid conclusions about the ways these machines can be kept ethical. The article’s most important claim is that a significant part of the challenge posed by AI-equipped machines can be addressed by the kind of ethical choices made by human beings for millennia. Ergo, there is little need to teach machines ethics even if this could be done in the first place. Finally, the article points out that it is a grievous error to draw on extreme outlier scenarios—such as the Trolley narratives—as a basis for conceptualizing the ethical issues at hand.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10892-017-9252-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-016-4043-5,Vehicle detection from high-resolution aerial images using spatial pyramid pooling-based deep convolutional neural networks,Multimedia Tools and Applications,10.1007/s11042-016-4043-5,Springer,2017-10-01,"In recent years, vehicle detection from aerial images obtained using unmanned aerial vehicles (UAVs) has become a research focus in image processing as remote sensing platforms on UAVs are rapidly popularised. This study proposes a detection algorithm using a deep convolutional neural network (DCNN) based on multi-scale spatial pyramid pooling (SPP). By using multi-scale SPP models to sample characteristic patterns with different sizes, feature vectors with a fixed length are generated. This avoids the stretching- or cropping-induced deformation of input images of different sizes, thus improving the detection effect. In addition, an imaging pre-processing algorithm based on maximum normed gradient (NG) with multiple thresholds is proposed. By using this algorithm, this research restores the edges of objects disturbed by clutter in the environment. Meanwhile, the raised candidate object extraction algorithm based on the maximum binarized NG entails fewer computations as it generates fewer candidate windows. Experimental results indicate that the multi-scale SPP based DCNN can better adapt to input images of different sizes to learn of the multi-scale characteristics of objects, thus further improving the detection effect.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11042-016-4043-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11948-016-9833-7,Who Should Decide How Machines Make Morally Laden Decisions?,Science and Engineering Ethics,10.1007/s11948-016-9833-7,Springer,2017-08-01,"Who should decide how a machine will decide what to do when it is driving a car, performing a medical procedure, or, more generally, when it is facing any kind of morally laden decision? More and more, machines are making complex decisions with a considerable level of autonomy. We should be much more preoccupied by this problem than we currently are. After a series of preliminary remarks, this paper will go over four possible answers to the question raised above. First, we may claim that it is the maker of a machine that gets to decide how it will behave in morally laden scenarios. Second, we may claim that the users of a machine should decide. Third, that decision may have to be made collectively or, fourth, by other machines built for this special purpose. The paper argues that each of these approaches suffers from its own shortcomings, and it concludes by showing, among other things, which approaches should be emphasized for different types of machines, situations, and/or morally laden decisions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11948-016-9833-7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11771-017-3551-4,Driving decision-making analysis of car-following for autonomous vehicle under complex urban environment,Journal of Central South University,10.1007/s11771-017-3551-4,Springer,2017-06-01,"The decision-making under complex urban environment become one of the key issues that restricts the rapid development of the autonomous vehicles. The difficulty in making timely and accurate decisions like human beings under highly dynamic traffic environment is a major challenge for autonomous driving. Car-following has been regarded as the simplest but essential driving behavior among driving tasks and has received extensive attention from researchers around the world. This work addresses this problem and proposes a novel method RSAN (rough-set artificial neural network) to learn the decisions from excellent human drivers. A virtual urban traffic environment was built by PreScan and driving simulation was conducted to obtain a broad set of relevant data such as experienced drivers’ behavior data and surrounding vehicles’ motion data. Then, rough set was used to preprocess these data to extract the key influential factors on decision and reduce the impact of uncertain data and noise data. And the car-following decision was learned by neural network in which key factor was the input and acceleration was the output. The result shows the better convergence speed and the better decision accuracy of RSAN than ANN. Findings of this work contributes to the empirical understanding of driver’s decision-making process and it provides a theoretical basis for the study of car-following decision-making under complex and dynamic environment.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11771-017-3551-4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11629-016-3950-2,Cultivated land information extraction in UAV imagery based on deep convolutional neural network and transfer learning,Journal of Mountain Science,10.1007/s11629-016-3950-2,Springer,2017-04-01,"The development of precision agriculture demands high accuracy and efficiency of cultivated land information extraction. As a new means of monitoring the ground in recent years, unmanned aerial vehicle (UAV) low-height remote sensing technique, which is flexible, efficient with low cost and with high resolution, is widely applied to investing various resources. Based on this, a novel extraction method for cultivated land information based on Deep Convolutional Neural Network and Transfer Learning (DTCLE) was proposed. First, linear features (roads and ridges etc.) were excluded based on Deep Convolutional Neural Network (DCNN). Next, feature extraction method learned from DCNN was used to cultivated land information extraction by introducing transfer learning mechanism. Last, cultivated land information extraction results were completed by the DTCLE and eCognition for cultivated land information extraction (ECLE). The location of the Pengzhou County and Guanghan County, Sichuan Province were selected for the experimental purpose. The experimental results showed that the overall precision for the experimental image 1, 2 and 3 (of extracting cultivated land) with the DTCLE method was 91.7%, 88.1% and 88.2% respectively, and the overall precision of ECLE is 90.7%, 90.5% and 87.0%, respectively. Accuracy of DTCLE was equivalent to that of ECLE, and also outperformed ECLE in terms of integrity and continuity.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11629-016-3950-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11518-016-5325-1,The Sputnik of servgoods: Autonomous vehicles,Journal of Systems Science and Systems Engineering,10.1007/s11518-016-5325-1,Springer,2017-04-01,"In an earlier paper (Tien 2015), the author defined the concept of a servgood, which can be thought of as a physical good or product enveloped by a services-oriented layer that makes the good smarter or more adaptable and customizable for a particular use. Adding another layer of physical sensors could then enhance its smartness and intelligence, especially if it were to be connected with each other or with other servgoods through the Internet of Things. Such sensed servgoods are becoming the products of the future. Indeed, autonomous vehicles can be considered the exemplar servgoods of the future; it is about decision informatics and embraces the advanced technologies of sensing (i.e., Big Data), processing (i.e., real-time analytics), reacting (i.e., real-time decision-making), and learning (i.e., deep learning). Since autonomous vehicles constitute a huge quality-of-life disruption, it is also critical to consider its policy impact on privacy and security, regulations and standards, and liability and insurance. Finally, just as the Soviet Union inaugurated the space age on October 4, 1957, with the launch of Sputnik, the first man-made object to orbit the Earth, the U. S. has inaugurated an age of automata or autonomous vehicles that can be considered to be the U. S. Sputnik of servgoods, with the full support of the U. S. government, the U. S. auto industry, the U. S. electronic industry, and the U.S. higher educational enterprise.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11518-016-5325-1,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11071-016-3206-2,Adaptive neural-network sliding mode cascade architecture of longitudinal tracking control for unmanned vehicles,Nonlinear Dynamics,10.1007/s11071-016-3206-2,Springer,2017-03-01,"Unmanned vehicles have drawn wide attention due to their intrinsic capacity of performing routine tasks for industry, conducting military missions and improving traffic safety. However, since the longitudinal dynamic system of unmanned vehicles inherently has the uncertain nonlinearities and time-varying behavior, longitudinal tracking control is reviewed as a challenging work in the exploitation of unmanned vehicles to deal with the features of uncertain nonlinearities and parametric time varying. In this paper, an adaptive nonlinear cascade control architecture is presented to design the longitudinal speed tracking control for unmanned vehicle, which is a nonholonomic system. Firstly, a upper-level model predictive control law is presented to produce a desired and smooth acceleration in real time, and the saturation characteristic is introduced to limit the accelerations within the range of given values. Then, a lower-level adaptive neuro-network sliding mode control (ANN-SMC) law is presented for dynamically tracking the desired acceleration, in which the uncertain term and the variable structure control term are adaptively adjusted by the neuro-networks, and the stability of proposed ANN-SMC control system is proved by the Lyapunov theory. Finally, simulation and experimental results demonstrate the feasibility and effectiveness of proposed control approach.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11071-016-3206-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-49073-1_11,A Novel Framework Based on Deep Learning and Unmanned Aerial Vehicles to Assess the Quality of Rice Fields,Advances in Information and Communication Technology,10.1007/978-3-319-49073-1_11,Springer,2017-01-01,"In the past few decades, boosting crop yield has been extensively regarded in many agricultural countries, especially Vietnam. Due to food demands and impossibility of crop-field area increasing, precision farming is essential to improve agricultural production and productivity. In this paper, we propose a novel framework based on some advanced techniques including deep learning, unmanned aerial vehicles (UAVs) to assess the quality of Vietnamese rice fields. UAVs are responsible for taking images of the rice fields at low or very low altitudes. Then, these images with high resolution will be processed by the deep neural networks on high performance computing systems. The main task of deep neural networks is to classify the images into many classes corresponding to low and high qualities of the rice fields. To conduct experimental results, the rice fields located in Tay Ninh province are chosen as a case study. The experimental results indicate that this approach is quite appropriate for agricultural Vietnamese practice since its accuracy is approximately 0.72.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-49073-1_11,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-10-7299-4_57,Traffic Sign Recognition Based on Deep Convolutional Neural Network,Computer Vision,10.1007/978-981-10-7299-4_57,Springer,2017-01-01,"Traffic sign recognition (TSR) is an important component of automated driving system. It is a rather challenging task to design a high-performance classifier for the TSR system. In this paper, we proposed a new method for TSR system based on deep convolutional neural network. In order to enhance the expression of the network, a novel structure (dubbed block-layer below) which combines Network-in-Network and residual connection was designed. Our network has 10 layers with parameters (block-layer be seen as a single layer); the first seven are alternate convolutional layers and block-layers, and the remaining three are fully-connected layers. We trained our TSR network on the German Traffic Sign Recognition Benchmark (GTSRB) dataset. To reduce overfitting, we did data augmentation on the training images and employed a regularization method named dropout. We also employed a mechanism called Batch Normalization which has been proved to be efficient for accelerating the training of deep neural networks. To speed up the training, we used an efficient GPU to accelerate the convolutional operation. On the test dataset of GTSRB, we achieve the accuracy rate of 98.96%, exceeding the human average raters.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-981-10-7299-4_57,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1631/FITEE.1601650,Current trends in the development of intelligent unmanned autonomous systems,Frontiers of Information Technology & Electronic Engineering,10.1631/FITEE.1601650,Springer,2017-01-01,"Intelligent unmanned autonomous systems are some of the most important applications of artificial intelligence (AI). The development of such systems can significantly promote innovation in AI technologies. This paper introduces the trends in the development of intelligent unmanned autonomous systems by summarizing the main achievements in each technological platform. Furthermore, we classify the relevant technologies into seven areas, including AI technologies, unmanned vehicles, unmanned aerial vehicles, service robots, space robots, marine robots, and unmanned workshops/intelligent plants. Current trends and developments in each area are introduced.",http://link.springer.com/openurl/fulltext?id=doi:10.1631/FITEE.1601650,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-64107-2_37,Drivers’ Manoeuvre Classification for Safe HRI,Towards Autonomous Robotic Systems,10.1007/978-3-319-64107-2_37,Springer,2017-01-01,"Ever increasing autonomy of machines and the need to interact with them creates challenges to ensure safe operation. Recent technical and commercial interest in increasing autonomy of vehicles has led to the integration of more sensors and actuators inside the vehicle, making them more like robots. For interaction with semi-autonomous cars, the use of these sensors could help to create new safety mechanisms. This work explores the concept of using motion tracking (i.e. skeletal tracking) data gathered from the driver whilst driving to learn to classify the manoeuvre being performed. A kernel-based classifier is trained with empirically selected features based on data gathered from a Kinect V2 sensor in a controlled environment. This method shows that skeletal tracking data can be used in a driving scenario to classify manoeuvres and sets a background for further work.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-64107-2_37,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-015-0324-x,An Integrated System for UAV Control Using a Neural Network Implemented in a Prototyping Board,Journal of Intelligent & Robotic Systems,10.1007/s10846-015-0324-x,Springer,2016-12-01,"Modern aerospace vehicles are expected to have non-conventional flight envelopes and then, in order to operate in uncertain environments, they must guarantee a high level of robustness and adaptability. A Neural Network (NN) controller, with real-time learning capability, can be used in applications with manned or unmanned aerial vehicles. In this paper a novel real-time control system, based on a NN model, in order to control the trajectories of a hexacopter is proposed. The proposed NN is optimized by the analytical calculation of the embedding parameters. The paper shows a performance evaluation, through a real experimental testbed, of the proposed approach in terms of error measures and computation of the angular velocities of the hexacopter.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-015-0324-x,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10676-016-9400-6,AI assisted ethics,Ethics and Information Technology,10.1007/s10676-016-9400-6,Springer,2016-06-01,"The growing number of ‘smart’ instruments, those equipped with AI, has raised concerns because these instruments make autonomous decisions; that is, they act beyond the guidelines provided them by programmers. Hence, the question the makers and users of smart instrument (e.g., driver-less cars) face is how to ensure that these instruments will not engage in unethical conduct (not to be conflated with illegal conduct). The article suggests that to proceed we need a new kind of AI program—oversight programs—that will monitor, audit, and hold operational AI programs accountable.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10676-016-9400-6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-34111-8_17,Neural Network-POMDP-Based Traffic Sign Classification Under Weather Conditions,Advances in Artificial Intelligence,10.1007/978-3-319-34111-8_17,Springer,2016-01-01,"Despite their initial success in operating autonomously, self-driving cars are still unable to navigate under severe weather conditions. In the proposed system, a multi-layer perceptron (MLP) performs initial traffic sign classification. The classification is input as an observation into a partially observable Markov decision process (POMDP) in order to determine whether taking another picture of the sign, or accepting the classification determined by the MLP is the more optimal action. The synergistic combination of the MLP with the POMDP was shown to have a greater functionality than the sum of the MLP and POMDP operating in isolation. The results demonstrate the MLP-POMDP system is capable of training faster and more accurately classifying traffic sign images obscured by fog than a MLP. With further development of this model, one of the greatest shortcomings of autonomous driving may be overcome by accurately classifying signs despite obstruction by weather.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-34111-8_17,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10677-015-9563-y,"Autonomous Machines, Moral Judgment, and Acting for the Right Reasons",Ethical Theory and Moral Practice,10.1007/s10677-015-9563-y,Springer,2015-08-01,,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10677-015-9563-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10115-014-0754-y,Online data-driven anomaly detection in autonomous robots,Knowledge and Information Systems,10.1007/s10115-014-0754-y,Springer,2015-06-01,"The use of autonomous robots is appealing for tasks, which are dangerous to humans. Autonomous robots might fail to perform their tasks since they are susceptible to varied sorts of faults such as point and contextual faults. Not all faults can be known in advance, and hence, anomaly detection is required. In this paper, we present an online data-driven anomaly detection approach ( ODDAD ) for autonomous robots. ODDAD is suitable for the dynamic nature of autonomous robots since it declares a fault based only on data collected online. In addition, it is unsupervised, model free and domain independent. ODDAD proceeds in three steps: data filtering, attributes grouping based on dependency between attributes and outliers detection for each group. Above a calculated threshold, an anomaly is declared. We empirically evaluate ODDAD in different domains: commercial unmanned aerial vehicles (UAVs), a vacuum-cleaning robot, a high-fidelity flight simulator and an electrical power system of a spacecraft. We show the significance and impact of each component of ODDAD . By comparing ODDAD to other state-of-the-art competing anomaly detection algorithms, we show its advantages.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10115-014-0754-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-19719-7_29,Adaptive Neural Control-Oriented Models of Unmanned Aerial Vehicles,10th International Conference on Soft Computing Models in Industrial and Environmental Applications,10.1007/978-3-319-19719-7_29,Springer,2015-01-01,"From real input/output data, different models of an unmanned aerial vehicle are obtained by applying adaptive neural networks. These models are control-oriented; their main objective is to help us to design, implement and simulate different intelligent controllers and to test them on real systems. The influence of the selected training data on the final model is also discussed. They have been compared to off-line learning neural models with satisfactory results in terms of accuracy and computational cost.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-19719-7_29,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-24069-5_6,Combining Machine Learning and Multi-agent Approach for Controlling Traffic at Intersections,Computational Collective Intelligence,10.1007/978-3-319-24069-5_6,Springer,2015-01-01,"Increasing volume of traffic in urban areas causes great costs and has negative effect on citizens’ life and health. The main cause of decreasing traffic fluency is intersections. Many methods for increasing bandwidth of junctions exist, but they are still insufficient. At the same time intelligent, autonomous cars are being created, what opens up new possibilities for controlling traffic at intersections. In this article a new approach for crossing an isolated junction is proposed - cars are given total autonomy and to avoid collisions they have to change speed. Several methods for adjusting speed based on machine learning (ML) are described, including new methods combining different ML algorithms (hybrid methods). The approach and methods were tested using a specially designed platform MABICS. Conducted experiments revealed some deficiencies of the methods - ideas for addressing them are proposed. Results of experiments made it possible to verify the proposed idea as promising.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-24069-5_6,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-20294-5_70,ROBOG Autonomously Navigating Outdoor Robo-Guide,"Swarm, Evolutionary, and Memetic Computing",10.1007/978-3-319-20294-5_70,Springer,2015-01-01,ROBO G : The Robo-Guide is an autonomously navigating vehicle capable of learning the navigational directions of a locality by using Artificial Neural Networks. The main task of ROBO G is to guide people from one location to any other location in a trained region. The prime feature of ROBO G is its simplicity of implementation and working. The map information is learned by Artificial Neural Network using the proposed concept of branch and node. The Multi-Layered Perceptron is trained using the standard Error Back Propagation Algorithm. Road Detection & Tracking and Destination Identification are employed to achieve autonomous navigation. All the Image Processing techniques used are computationally inexpensive. The ROBO G is tested successfully in the outdoor environment for autonomous navigation and due to the simplicity in implementation it can be easily trained for any region.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-20294-5_70,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-012-1242-5,Intelligent control system design for UAV using a recurrent wavelet neural network,Neural Computing and Applications,10.1007/s00521-012-1242-5,Springer,2014-02-01,"This paper aims to propose an efficient control algorithm for the unmanned aerial vehicle (UAV) motion control. An intelligent control system is proposed by using a recurrent wavelet neural network (RWNN). The developed RWNN is used to mimic an ideal controller. Moreover, based on sliding-mode approach, the adaptive tuning laws of RWNN can be derived. Then, the developed RWNN control system is applied to an UAV motion control for achieving desired trajectory tracking. From the simulation results, the control scheme has been shown to achieve favorable control performance for the UAV motion control even it is subjected to control effort deterioration and crosswind disturbance.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s00521-012-1242-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-07596-9_8,UAVs Applied to the Counting and Monitoring of Animals,Ambient Intelligence - Software and Applications,10.1007/978-3-319-07596-9_8,Springer,2014-01-01,The advantages of intelligent approaches such as the conjunction of artificial vision and the use of Unmanned Aerial Vehicles (UAVs) have been recently emerging. This paper presents a focused on obtaining scans of large areas of livestock system. Counting and monitoring of animal species can be performed with video recordings taken from UAVs. Moreover the system keeps track of the number of animals detected by analyzing the images taken with the UAVs cameras. Several tests have been performed to evaluate this system and preliminary results and the conclusions are presented in this paper.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-07596-9_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-319-08087-1_4,Design of Real-Time Transition from Driving Assistance to Automation Function: Bayesian Artificial Intelligence Approach,Advanced Microsystems for Automotive Applications 2014,10.1007/978-3-319-08087-1_4,Springer,2014-01-01,"Forecasts of automation in driving suggest that wide spread market penetration of fully autonomous vehicles will be decades away and that before such vehicles will gain acceptance by all stake holders, there will be a need for driving assistance in key driving tasks, supplemented by automated active safety capability. This paper advances a Bayesian Artificial Intelligence model for the design of real time transition from assisted driving to automated driving under conditions of high probability of a collision if no action is taken to avoid the collision. Systems can be designed to feature collision warnings as well as automated active safety capabilities. In addition to the high level architecture of the Bayesian transition model, example scenarios illustrate the function of the real-time transition model.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-08087-1_4,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/2193-1801-2-188,Neuro-fuzzy controller to navigate an unmanned vehicle,SpringerPlus,10.1186/2193-1801-2-188,Springer,2013-04-27,"A Neuro-fuzzy control method for an Unmanned Vehicle (UV) simulation is described. The objective is guiding an autonomous vehicle to a desired destination along a desired path in an environment characterized by a terrain and a set of distinct objects, such as obstacles like donkey traffic lights and cars circulating in the trajectory. The autonomous navigate ability and road following precision are mainly influenced by its control strategy and real-time control performance. Fuzzy Logic Controller can very well describe the desired system behavior with simple “if-then” relations owing the designer to derive “if-then” rules manually by trial and error. On the other hand, Neural Networks perform function approximation of a system but cannot interpret the solution obtained neither check if its solution is plausible. The two approaches are complementary. Combining them, Neural Networks will allow learning capability while Fuzzy-Logic will bring knowledge representation (Neuro-Fuzzy). In this paper, an artificial neural network fuzzy inference system (ANFIS) controller is described and implemented to navigate the autonomous vehicle. Results show several improvements in the control system adjusted by neuro-fuzzy techniques in comparison to the previous methods like Artificial Neural Network (ANN).",https://www.biomedcentral.com/openurl?doi=10.1186/2193-1801-2-188,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12239-013-0030-2,Neural-network multiple models filter (NMM)-based position estimation system for autonomous vehicles,International Journal of Automotive Technology,10.1007/s12239-013-0030-2,Springer,2013-04-01,"A highly accurate and reliable vehicle position estimation system is an important component of an autonomous driving system. In generally, a global positioning system (GPS) receiver is employed for the vehicle position estimation of autonomous vehicles. However, a stand-alone GPS does not always provide accurate and reliable information of the vehicle position due to frequent GPS blockages and multipath errors. In order to overcome these problems, a sensor fusion scheme that combines the data from the GPS receiver and several on-board sensors has been studied. In previous researches, a single model filter-based sensor fusion algorithm was used to integrate information from the GPS and on-board sensors. However, an estimate obtained from a single model is difficult to cover the various driving environments, including urban areas, off-road areas, and highways. Thus, a multiple models filter (MMF) has been introduced to address this limitation by adapting multiple models to a wide range of driving conditions. An adaptation of the multiple model is achieved through the use of the model probability. The MMF combines several vehicle models using the model probabilities, which indicate the suitability of the current driving condition. In this paper, we propose a vehicle position estimation algorithm for an autonomous vehicle that is based on a neural network (NN)-based MMF. The model probabilities are determined through the NN. The proposed position estimation system was evaluated through simulations and experiments. The experimental results show that the proposed position estimation algorithm is suitable for application in an autonomous driving system over a wide range of driving conditions.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s12239-013-0030-2,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-319-01168-4_8,Discussion and Conclusion,TEXPLORE: Temporal Difference Reinforcement Learning for Robots and Time-Constrained Domains,10.1007/978-3-319-01168-4_8,Springer,2013-01-01,"This chapter concludes the book. First I summarize the texplore algorithm presented in this book and the book itself. Next, I summarize the contributions of this book. Then, in Section 8.3, I discuss the limitations and applicability of the texplore algorithm and some aspects of the exploration problem. In the following section, I present some directions for future work, before concluding the book in Section 8.5.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-319-01168-4_8,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-642-22619-9_7,Neural Network Based Lane Change Trajectory Prediction in Autonomous Vehicles,Transactions on Computational Science XIII,10.1007/978-3-642-22619-9_7,Springer,2011-01-01,"During a lane change, vehicle collision warning systems detect the likelihood of collision and time to collision to warn vehicles of an imminent collision. In autonomous systems, a vehicle utilizes data obtained by its own sensors to predict future state of traffic. The data from on board sensors are limited by line of sight, measurement noise and motion parameters of the vehicle which affect the accuracy of prediction. Alternatively, in cooperative driving, vehicles transmit their parameters continuously. This is also beset by communication delays and message loss. To avoid these limitations, a vehicle should estimate its future state and broadcast it to others vehicles in the neighborhood. This necessitates vehicles to predict their future trajectories based entirely on its past. Since, low cost global positioning systems are becoming an integral part of vehicles; a vehicle knows its own position. This can be utilized by the vehicle for prediction of its future trajectory. In this paper, the effectiveness of lane change trajectory prediction on the basis of past positions is studied. The lane change trajectory of a vehicle is modeled as a time series and back propagation neural network is trained using real field data and its efficacy for short range and long range prediction is benchmarked. Simulation results using NGSIM data indicate that future lane change trajectory cannot be predicted with sufficient accuracy. The most important reason seemed to be the influence of other neighboring vehicles on the trajectory on the lane changing vehicle in addition to noise and complex dependence of future on the past values. The results also indicate that a vehicle changes its motion parameters during the entire lane change process. This confirms the active intervention of the driver in adjusting the trajectory on the basis of his assessment of the future state of its surrounding vehicles and entails the consideration of the state of surrounding vehicle for accurate prediction.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-22619-9_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-90-481-3658-2_22,Contextual Data Rule Generation For Autonomous Vehicle Control,Innovations and Advances in Computer Sciences and Engineering,10.1007/978-90-481-3658-2_22,Springer,2010-01-01,"Autonomous vehicles are often called upon to deal with complex and varied situations. This requires analyzing input from sensor arrays to get as accurate a description of the environment as possible. These ad-hoc descriptions are then compared against existing rule sets generated from decision trees that decide upon a course of action. However, with so many environmental conditions it is often difficult to create decision trees that can account for every possible situation, so techniques to limit the size of the decision tree are used. Unfortunately, this can obscure data which is sparse, but also important to the decision process. This paper presents an algorithm to analyze a decision tree and develops a set of metrics to determine whether or not sparse data is relevant and should be include. An example demonstrating the use of this technique is shown.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-90-481-3658-2_22,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10846-008-9287-5,An Adaptable Oscillator-Based Controller for Autonomous Robots,Journal of Intelligent and Robotic Systems,10.1007/s10846-008-9287-5,Springer,2009-05-01,"This paper proposes a unique oscillator-based robot controller with learning abilities to effectively guide a team of robots operating in uncertain environments. To verify this, we designed four separate controllers and compared their performance in a series of tests in several different environments. The experiments used a team of three robots to explore arenas with variable lighting and different obstacle patterns, with a goal of having the team as a whole absorb as much light as possible. The four controllers were: a reactive controller, an oscillator with fixed parameters, an oscillator whose parameters changed based on the pattern of sensor information received, and an oscillator-based controller that used reinforcement learning. Experiments confirmed that the proposed method outperforms the others in all environments tested.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/s10846-008-9287-5,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-642-01507-6_101,Neural Network Algorithm for Installation Error Identification Based on Bearing-only Target Motion Analyses,Advances in Neural Networks – ISNN 2009,10.1007/978-3-642-01507-6_101,Springer,2009-01-01,"It is quite strict with the degree of installation precision of photo-electricity device (PED) carried by unmanned aerial vehicle (UAV) when conducting bearing-only target motion analyses (BTMA), because of the existence of the installation error of PED, the precision of target location is bound to be affected. In order to solve this problem mentioned above, a neural network algorithm for installation error identification based on BTMA is put forward in this paper, consulting the target surveillance technology of PED to identify the installation error thought neural network algorithm, which is worthy to be put into practical applications.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-642-01507-6_101,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-007-0071-y,Neural network based feedback linearization control of an unmanned aerial vehicle,International Journal of Automation and Computing,10.1007/s11633-007-0071-y,Springer,2007-01-01,This paper presents a flight control design for an unmanned aerial vehicle (UAV) using a nonlinear autoregressive moving average (NARMA-L2) neural network based feedback linearization and output redefinition technique. The UAV investigated is non-minimum phase. The output redefinition technique is used in such a way that the resulting system to be inverted is a minimum phase system. The NARMA-L2 neural network is trained off-line for forward dynamics of the UAV model with redefined output and is then inverted to force the real output to approximately track a command input. Simulation results show that the proposed approaches have good performance.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/s11633-007-0071-y,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-540-72393-6_7,An Improved Extremum Seeking Algorithm Based on the Chaotic Annealing Recurrent Neural Network and Its Application,Advances in Neural Networks – ISNN 2007,10.1007/978-3-540-72393-6_7,Springer,2007-01-01,"The application of sinusoidal periodic search signals into the general extremum seeking algorithm(ESA) results in the “chatter” problem of the output and the switching of the control law and incapability of escaping from the local minima. An improved chaotic annealing recurrent neural network (CARNN) is proposed for ESA to solve those problems in the general ESA and improve the global searching capability. The paper converts ESA into seeking the global extreme point where the slope of Cost Function is zero, and applies a CARNN to finding the global point and stabilizing the plant at that point. ESA combined with CARNN doesn’t make use of search signals such as sinusoidal periodic signals, which solves those problems in previous ESA and improves the dynamic performance of the controlled system greatly. During the process of optimization, chaotic annealing is realized by decaying the amplitude of the chaos noise and the probability of accepting continuously. The process of optimization was divided into two phases: the coarse search based on chaos and the elaborate search based on ARNN. At last, CARNN will stabilize the system to the global extreme point. At the same time, it can be simplified by the proposed method to analyze the stability of ESA. The simulation results of a simplified UAV tight formation flight model and a typical Schaffer function validate the advantages mentioned above.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-540-72393-6_7,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11759966_70,Self-organizing Neural Architecture for Reinforcement Learning,Advances in Neural Networks - ISNN 2006,10.1007/11759966_70,Springer,2006-01-01,"Self-organizing neural networks are typically associated with unsupervised learning. This paper presents a self-organizing neural architecture, known as TD-FALCON, that learns cognitive codes across multi-modal pattern spaces, involving states, actions, and rewards, and is capable of adapting and functioning in a dynamic environment with external evaluative feedback signals. We present a case study of TD-FALCON on a mine avoidance and navigation cognitive task, and illustrate its performance by comparing with a state-of-the-art reinforcement learning approach based on gradient descent backpropagation algorithm.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11759966_70,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/11510888_40,Autonomous Vehicle Steering Based on Evaluative Feedback by Reinforcement Learning,Machine Learning and Data Mining in Pattern Recognition,10.1007/11510888_40,Springer,2005-01-01,"Steering an autonomous vehicle requires the permanent adaptation of behavior in relation to the various situations the vehicle is in. This paper describes a research which implements such adaptation and optimization based on Reinforcement Learning (RL) which in detail purely learns from evaluative feedback in contrast to instructive feedback. Convergence of the learning process has been achieved at various experimental results revealing the impact of the different RL parameters. While using RL for autonomous steering is in itself already a novelty, additional attention has been given to new proposals for post-processing and interpreting the experimental data.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/11510888_40,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1014394117908,Soft Computing Based Pattern Classifiers for the Obstacle Avoidance Behavior of Intelligent Autonomous Vehicles (IAV),Applied Intelligence,10.1023/A:1014394117908,Springer,2002-05-01,"To ensure more autonomy and intelligence with real-time processing capabilities for the obstacle avoidance behavior of Intelligent Autonomous Vehicles (IAV), the use of soft computing is necessary to bring this behavior near to that of humans in the recognition, learning, adaptation, generalization, reasoning and decision-making, and action. In this paper, pattern classifiers of spatial obstacle avoidance situations using Neural Networks (NN), Fuzzy Logic (FL), Genetic Algorithms (GA) and Adaptive Resonance Theory (ART) individually or in combination are suggested. These classifiers are based on supervised learning and adaptation paradigms as Gradient Back-Propagation (GBP), FL, GA and Simplified Fuzzy ArtMap (SFAM) resulting in NN/GBP and FL as Intelligent Systems (IS) and in NN/GA, NN/GA-GBP, NN-FL/GBP and NN-FL-ART/SFAM as Hybrid Intelligent Systems (HIS). Afterwards, a synthesis of the suggested pattern classifiers is presented where their results and performances are discussed as well as the Field Programmable Gate Array (FPGA) architectures, characterized by their high flexibility and compactness, for their implementation.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1014394117908,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/3-540-48774-3_38,A Neural Approach for Detection of Road Direction in Autonomous Navigation,Computational Intelligence,10.1007/3-540-48774-3_38,Springer,1999-01-01,"The paper presents an original approach for visual identification of road direction of an autonomous vehicle using an improved Radial Basis Function (RBF) neural network. We present the results of designing, software implementation, training, and testing of our RBF model for automatic road direction detection as a function of the input image. The path to be identified was quantified in 5 output directions. For training and testing the neural model, we used two lots of real road scenes: 50 images for training and other 50 images for test. The score of correct road recognition was of 100% both for estimation lot and also for the test lot. We have also designed a driving simulator to evaluate the performances of the neural road follower.",http://link.springer.com/openurl/fulltext?id=doi:10.1007/3-540-48774-3_38,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1023/A:1008216400353,Neural Navigation Approach for Intelligent Autonomous Vehicles (IAV) in Partially Structured Environments,Applied Intelligence,10.1023/A:1008216400353,Springer,1998-05-01,"The use of Neural Networks (NN) is necessary to bring the behavior of Intelligent Autonomous Vehicles (IAV) near the human one in recognition, learning, decision-making, and action. First, current navigation approaches based on NN are discussed. Indeed, these current approaches remedy insufficiencies of classical approaches related to real-time , autonomy , and intelligence . Second, a neural navigation approach essentially based on pattern classification to acquire target localization and obstacle avoidance behaviors is suggested. This approach must provide vehicles with capability, after supervised Gradient Backpropagation learning, to recognize both six (06) target location and thirty (30) obstacle avoidance situations using NN1 and NN2 classifiers , respectively. Afterwards, the decision-making and action consist of two association stages, carried out by reinforcement Trial and Error learning, and their coordination using a NN3. Then, NN3 allows to decide among five (05) actions (move towards 30°, move towards 60°, move towards 90°, move towards 120°, and move towards 150°). Third, simulation results which display the ability of the neural approach to provide IAV with capability to intelligently navigate in partially structured environments are presented. Finally, a discussion dealing with the suggested approach and how it relates to some other works is given.",http://link.springer.com/openurl/fulltext?id=doi:10.1023/A:1008216400353,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/BF00426025,A reinforcement learning approach based on the fuzzy min-max neural network,Neural Processing Letters,10.1007/BF00426025,Springer,1996-12-01,The fuzzy min-max neural network constitutes a neural architecture that is based on hyperbox fuzzy sets and can be incrementally trained by appropriately adjusting the number of hyperboxes and their corresponding volumes. Two versions have been proposed: for supervised and unsupervised learning. In this paper a modified approach is presented that is appropriate for reinforcement learning problems with discrete action space and is applied to the difficult task of autonomous vehicle navigation when no a priori knowledge of the enivronment is available. Experimental results indicate that the proposed reinforcement learning network exhibits superior learning behavior compared to conventional reinforcement schemes.,http://link.springer.com/openurl/fulltext?id=doi:10.1007/BF00426025,springer,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
