id,updated,published,title,summary,database,query_name,query_value
http://arxiv.org/abs/2207.05403v1,2022-07-12T09:07:25Z,2022-07-12T09:07:25Z,"Design of Dynamics Invariant LSTM for Touch Based Human-UAV Interaction
  Detection","The field of Unmanned Aerial Vehicles (UAVs) has reached a high level of
maturity in the last few years. Hence, bringing such platforms from closed
labs, to day-to-day interactions with humans is important for commercialization
of UAVs. One particular human-UAV scenario of interest for this paper is the
payload handover scheme, where a UAV hands over a payload to a human upon their
request. In this scope, this paper presents a novel real-time human-UAV
interaction detection approach, where Long short-term memory (LSTM) based
neural network is developed to detect state profiles resulting from human
interaction dynamics. A novel data pre-processing technique is presented; this
technique leverages estimated process parameters of training and testing UAVs
to build dynamics invariant testing data. The proposed detection algorithm is
lightweight and thus can be deployed in real-time using off the shelf UAV
platforms; in addition, it depends solely on inertial and position measurements
present on any classical UAV platform. The proposed approach is demonstrated on
a payload handover task between multirotor UAVs and humans. Training and
testing data were collected using real-time experiments. The detection approach
has achieved an accuracy of 96\%, giving no false positives even in the
presence of external wind disturbances, and when deployed and tested on two
different UAVs.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.02162v1,2022-07-05T16:33:20Z,2022-07-05T16:33:20Z,Tackling Real-World Autonomous Driving using Deep Reinforcement Learning,"In the typical autonomous driving stack, planning and control systems
represent two of the most crucial components in which data retrieved by sensors
and processed by perception algorithms are used to implement a safe and
comfortable self-driving behavior. In particular, the planning module predicts
the path the autonomous car should follow taking the correct high-level
maneuver, while control systems perform a sequence of low-level actions,
controlling steering angle, throttle and brake. In this work, we propose a
model-free Deep Reinforcement Learning Planner training a neural network that
predicts both acceleration and steering angle, thus obtaining a single module
able to drive the vehicle using the data processed by localization and
perception algorithms on board of the self-driving car. In particular, the
system that was fully trained in simulation is able to drive smoothly and
safely in obstacle-free environments both in simulation and in a real-world
urban area of the city of Parma, proving that the system features good
generalization capabilities also driving in those parts outside the training
scenarios. Moreover, in order to deploy the system on board of the real
self-driving car and to reduce the gap between simulated and real-world
performances, we also develop a module represented by a tiny neural network
able to reproduce the real vehicle dynamic behavior during the training in
simulation.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.00191v1,2022-07-01T03:42:33Z,2022-07-01T03:42:33Z,"Data generation using simulation technology to improve perception
  mechanism of autonomous vehicles","Recent advancements in computer graphics technology allow more realistic
ren-dering of car driving environments. They have enabled self-driving car
simulators such as DeepGTA-V and CARLA (Car Learning to Act) to generate large
amounts of synthetic data that can complement the existing real-world dataset
in training autonomous car perception. Furthermore, since self-driving car
simulators allow full control of the environment, they can generate dangerous
driving scenarios that the real-world dataset lacks such as bad weather and
accident scenarios. In this paper, we will demonstrate the effectiveness of
combining data gathered from the real world with data generated in the
simulated world to train perception systems on object detection and
localization task. We will also propose a multi-level deep learning perception
framework that aims to emulate a human learning experience in which a series of
tasks from the simple to more difficult ones are learned in a certain domain.
The autonomous car perceptron can learn from easy-to-drive scenarios to more
challenging ones customized by simulation software.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.14195v1,2022-06-28T17:59:45Z,2022-06-28T17:59:45Z,Pedestrian 3D Bounding Box Prediction,"Safety is still the main issue of autonomous driving, and in order to be
globally deployed, they need to predict pedestrians' motions sufficiently in
advance. While there is a lot of research on coarse-grained (human center
prediction) and fine-grained predictions (human body keypoints prediction), we
focus on 3D bounding boxes, which are reasonable estimates of humans without
modeling complex motion details for autonomous vehicles. This gives the
flexibility to predict in longer horizons in real-world settings. We suggest
this new problem and present a simple yet effective model for pedestrians' 3D
bounding box prediction. This method follows an encoder-decoder architecture
based on recurrent neural networks, and our experiments show its effectiveness
in both the synthetic (JTA) and real-world (NuScenes) datasets. The learned
representation has useful information to enhance the performance of other
tasks, such as action anticipation. Our code is available online:
https://github.com/vita-epfl/bounding-box-prediction",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.14608v1,2022-06-28T02:46:20Z,2022-06-28T02:46:20Z,"Traffic Management of Autonomous Vehicles using Policy Based Deep
  Reinforcement Learning and Intelligent Routing","Deep Reinforcement Learning (DRL) uses diverse, unstructured data and makes
RL capable of learning complex policies in high dimensional environments.
Intelligent Transportation System (ITS) based on Autonomous Vehicles (AVs)
offers an excellent playground for policy-based DRL. Deep learning
architectures solve computational challenges of traditional algorithms while
helping in real-world adoption and deployment of AVs. One of the main
challenges in AVs implementation is that it can worsen traffic congestion on
roads if not reliably and efficiently managed. Considering each vehicle's
holistic effect and using efficient and reliable techniques could genuinely
help optimise traffic flow management and congestion reduction. For this
purpose, we proposed a intelligent traffic control system that deals with
complex traffic congestion scenarios at intersections and behind the
intersections. We proposed a DRL-based signal control system that dynamically
adjusts traffic signals according to the current congestion situation on
intersections. To deal with the congestion on roads behind the intersection, we
used re-routing technique to load balance the vehicles on road networks. To
achieve the actual benefits of the proposed approach, we break down the data
silos and use all the data coming from sensors, detectors, vehicles and roads
in combination to achieve sustainable results. We used SUMO micro-simulator for
our simulations. The significance of our proposed approach is manifested from
the results.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.13034v1,2022-06-27T03:55:23Z,2022-06-27T03:55:23Z,Monitoring Shortcut Learning using Mutual Information,"The failure of deep neural networks to generalize to out-of-distribution data
is a well-known problem and raises concerns about the deployment of trained
networks in safety-critical domains such as healthcare, finance and autonomous
vehicles. We study a particular kind of distribution shift $\unicode{x2013}$
shortcuts or spurious correlations in the training data. Shortcut learning is
often only exposed when models are evaluated on real-world data that does not
contain the same spurious correlations, posing a serious dilemma for AI
practitioners to properly assess the effectiveness of a trained model for
real-world applications. In this work, we propose to use the mutual information
(MI) between the learned representation and the input as a metric to find where
in training, the network latches onto shortcuts. Experiments demonstrate that
MI can be used as a domain-agnostic metric for monitoring shortcut learning.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.11981v1,2022-06-23T21:13:10Z,2022-06-23T21:13:10Z,"Never trust, always verify : a roadmap for Trustworthy AI?","Artificial Intelligence (AI) is becoming the corner stone of many systems
used in our daily lives such as autonomous vehicles, healthcare systems, and
unmanned aircraft systems. Machine Learning is a field of AI that enables
systems to learn from data and make decisions on new data based on models to
achieve a given goal. The stochastic nature of AI models makes verification and
validation tasks challenging. Moreover, there are intrinsic biaises in AI
models such as reproductibility bias, selection bias (e.g., races, genders,
color), and reporting bias (i.e., results that do not reflect the reality).
Increasingly, there is also a particular attention to the ethical, legal, and
societal impacts of AI. AI systems are difficult to audit and certify because
of their black-box nature. They also appear to be vulnerable to threats; AI
systems can misbehave when untrusted data are given, making them insecure and
unsafe. Governments, national and international organizations have proposed
several principles to overcome these challenges but their applications in
practice are limited and there are different interpretations in the principles
that can bias implementations. In this paper, we examine trust in the context
of AI-based systems to understand what it means for an AI system to be
trustworthy and identify actions that need to be undertaken to ensure that AI
systems are trustworthy. To achieve this goal, we first review existing
approaches proposed for ensuring the trustworthiness of AI systems, in order to
identify potential conceptual gaps in understanding what trustworthy AI is.
Then, we suggest a trust (resp. zero-trust) model for AI and suggest a set of
properties that should be satisfied to ensure the trustworthiness of AI
systems.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.10620v1,2022-06-21T14:10:22Z,2022-06-21T14:10:22Z,CoCoPIE XGen: A Full-Stack AI-Oriented Optimizing Framework,"There is a growing demand for shifting the delivery of AI capability from
data centers on the cloud to edge or end devices, exemplified by the fast
emerging real-time AI-based apps running on smartphones, AR/VR devices,
autonomous vehicles, and various IoT devices. The shift has however been
seriously hampered by the large growing gap between DNN computing demands and
the computing power on edge or end devices. This article presents the design of
XGen, an optimizing framework for DNN designed to bridge the gap. XGen takes
cross-cutting co-design as its first-order consideration. Its full-stack
AI-oriented optimizations consist of a number of innovative optimizations at
every layer of the DNN software stack, all designed in a cooperative manner.
The unique technology makes XGen able to optimize various DNNs, including those
with an extreme depth (e.g., BERT, GPT, other transformers), and generate code
that runs several times faster than those from existing DNN frameworks, while
delivering the same level of accuracy.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.09742v1,2022-06-20T12:43:33Z,2022-06-20T12:43:33Z,"Developing a Free and Open-source Automated Building Exterior Crack
  Inspection Software for Construction and Facility Managers","Inspection of cracks is an important process for properly monitoring and
maintaining a building. However, manual crack inspection is time-consuming,
inconsistent, and dangerous (e.g., in tall buildings). Due to the development
of open-source AI technologies, the increase in available Unmanned Aerial
Vehicles (UAVs) and the availability of smartphone cameras, it has become
possible to automate the building crack inspection process. This study presents
the development of an easy-to-use, free and open-source Automated Building
Exterior Crack Inspection Software (ABECIS) for construction and facility
managers, using state-of-the-art segmentation algorithms to identify concrete
cracks and generate a quantitative and qualitative report. ABECIS was tested
using images collected from a UAV and smartphone cameras in real-world
conditions and a controlled laboratory environment. From the raw output of the
algorithm, the median Intersection over Unions for the test experiments is (1)
0.686 for indoor crack detection experiment in a controlled lab environment
using a commercial drone, (2) 0.186 for indoor crack detection at a
construction site using a smartphone and (3) 0.958 for outdoor crack detection
on university campus using a commercial drone. These IoU results can be
improved significantly to over 0.8 when a human operator selectively removes
the false positives. In general, ABECIS performs best for outdoor drone images,
and combining the algorithm predictions with human verification/intervention
offers very accurate crack detection results. The software is available
publicly and can be downloaded for out-of-the-box use at:
https://github.com/SMART-NYUAD/ABECIS",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.08209v1,2022-06-16T14:26:45Z,2022-06-16T14:26:45Z,"Improved Gaussian-Bernoulli Restricted Boltzmann Machines for UAV-Ground
  Communication Systems","Unmanned aerial vehicle (UAV) is steadily growing as a promising technology
for next-generation communication systems due to their appealing features such
as wide coverage with high altitude, on-demand low-cost deployment, and fast
responses. UAV communications are fundamentally different from the conventional
terrestrial and satellite communications owing to the high mobility and the
unique channel characteristics of air-ground links. However, obtaining
effective channel state information (CSI) is challenging because of the dynamic
propagation environment and variable transmission delay. In this paper, a deep
learning (DL)-based CSI prediction framework is proposed to address channel
aging problem by extracting the most discriminative features from the UAV
wireless signals. Specifically, we develop a procedure of multiple Gaussian
Bernoulli restricted Boltzmann machines (GBRBM) for dimension reduction and
pre-training utilization incorporated with an autoencoder-based deep neural
networks (DNNs). To evaluate the proposed approach, real data measurements from
an UAV communicating with base-stations within a commercial cellular network
are obtained and used for training and validation. Numerical results
demonstrate that the proposed method is accurate in channel acquisition for
various UAV flying scenarios and outperforms the conventional DNNs.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.07690v1,2022-05-16T13:55:16Z,2022-05-16T13:55:16Z,"Real-time semantic segmentation on FPGAs for autonomous vehicles with
  hls4ml","In this paper, we investigate how field programmable gate arrays can serve as
hardware accelerators for real-time semantic segmentation tasks relevant for
autonomous driving. Considering compressed versions of the ENet convolutional
neural network architecture, we demonstrate a fully-on-chip deployment with a
latency of 4.9 ms per image, using less than 30% of the available resources on
a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when
increasing the batch size to ten, corresponding to the use case where the
autonomous vehicle receives inputs from multiple cameras simultaneously. We
show, through aggressive filter reduction and heterogeneous quantization-aware
training, and an optimized implementation of convolutional layers, that the
power consumption and resource utilization can be significantly reduced while
maintaining accuracy on the Cityscapes dataset.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.04281v1,2022-05-09T13:53:34Z,2022-05-09T13:53:34Z,"Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and
  Comprehensive Analysis","Unmanned aerial vehicle (UAV)-based visual object tracking has enabled a wide
range of applications and attracted increasing attention in the field of remote
sensing because of its versatility and effectiveness. As a new force in the
revolutionary trend of deep learning, Siamese networks shine in visual object
tracking with their promising balance of accuracy, robustness, and speed.
Thanks to the development of embedded processors and the gradual optimization
of deep neural networks, Siamese trackers receive extensive research and
realize preliminary combinations with UAVs. However, due to the UAV's limited
onboard computational resources and the complex real-world circumstances,
aerial tracking with Siamese networks still faces severe obstacles in many
aspects. To further explore the deployment of Siamese networks in UAV tracking,
this work presents a comprehensive review of leading-edge Siamese trackers,
along with an exhaustive UAV-specific analysis based on the evaluation using a
typical UAV onboard processor. Then, the onboard tests are conducted to
validate the feasibility and efficacy of representative Siamese trackers in
real-world UAV deployment. Furthermore, to better promote the development of
the tracking community, this work analyzes the limitations of existing Siamese
trackers and conducts additional experiments represented by low-illumination
evaluations. In the end, prospects for the development of Siamese UAV tracking
in the remote sensing field are discussed. The unified framework of
leading-edge Siamese trackers, i.e., code library, and the results of their
experimental evaluations are available at
https://github.com/vision4robotics/SiameseTracking4UAV .",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.01419v1,2022-05-03T11:12:29Z,2022-05-03T11:12:29Z,"An Empirical Analysis of the Use of Real-Time Reachability for the
  Safety Assurance of Autonomous Vehicles","Recent advances in machine learning technologies and sensing have paved the
way for the belief that safe, accessible, and convenient autonomous vehicles
may be realized in the near future. Despite tremendous advances within this
context, fundamental challenges around safety and reliability are limiting
their arrival and comprehensive adoption. Autonomous vehicles are often tasked
with operating in dynamic and uncertain environments. As a result, they often
make use of highly complex components, such as machine learning approaches, to
handle the nuances of sensing, actuation, and control. While these methods are
highly effective, they are notoriously difficult to assure. Moreover, within
uncertain and dynamic environments, design time assurance analyses may not be
sufficient to guarantee safety. Thus, it is critical to monitor the correctness
of these systems at runtime. One approach for providing runtime assurance of
systems with components that may not be amenable to formal analysis is the
simplex architecture, where an unverified component is wrapped with a safety
controller and a switching logic designed to prevent dangerous behavior. In
this paper, we propose using a real-time reachability algorithm for the
implementation of the simplex architecture to assure the safety of a 1/10 scale
open source autonomous vehicle platform known as F1/10. The reachability
algorithm that we leverage (a) provides provable guarantees of safety, and (b)
is used to detect potentially unsafe scenarios. In our approach, the need to
analyze an underlying controller is abstracted away, instead focusing on the
effects of the controller's decisions on the system's future states. We
demonstrate the efficacy of our architecture through a vast set of experiments
conducted both in simulation and on an embedded hardware platform.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.13343v1,2022-04-28T08:28:25Z,2022-04-28T08:28:25Z,"Actor-Critic Scheduling for Path-Aware Air-to-Ground Multipath
  Multimedia Delivery","Reinforcement Learning (RL) has recently found wide applications in network
traffic management and control because some of its variants do not require
prior knowledge of network models. In this paper, we present a novel scheduler
for real-time multimedia delivery in multipath systems based on an Actor-Critic
(AC) RL algorithm. We focus on a challenging scenario of real-time video
streaming from an Unmanned Aerial Vehicle (UAV) using multiple wireless paths.
The scheduler acting as an RL agent learns in real-time the optimal policy for
path selection, path rate allocation and redundancy estimation for flow
protection. The scheduler, implemented as a module of the GStreamer framework,
can be used in real or simulated settings. The simulation results show that our
scheduler can target a very low loss rate at the receiver by dynamically
adapting in real-time the scheduling policy to the path conditions without
performing training or relying on prior knowledge of network channel models.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.11511v1,2022-04-25T08:42:47Z,2022-04-25T08:42:47Z,A Spatio-Temporal Multilayer Perceptron for Gesture Recognition,"Gesture recognition is essential for the interaction of autonomous vehicles
with humans. While the current approaches focus on combining several modalities
like image features, keypoints and bone vectors, we present neural network
architecture that delivers state-of-the-art results only with body skeleton
input data. We propose the spatio-temporal multilayer perceptron for gesture
recognition in the context of autonomous vehicles. Given 3D body poses over
time, we define temporal and spatial mixing operations to extract features in
both domains. Additionally, the importance of each time step is re-weighted
with Squeeze-and-Excitation layers. An extensive evaluation of the TCG and
Drive&Act datasets is provided to showcase the promising performance of our
approach. Furthermore, we deploy our model to our autonomous vehicle to show
its real-time capability and stable execution.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.11216v1,2022-04-24T08:35:55Z,2022-04-24T08:35:55Z,"RealNet: Combining Optimized Object Detection with Information Fusion
  Depth Estimation Co-Design Method on IoT","Depth Estimation and Object Detection Recognition play an important role in
autonomous driving technology under the guidance of deep learning artificial
intelligence. We propose a hybrid structure called RealNet: a co-design method
combining the model-streamlined recognition algorithm, the depth estimation
algorithm with information fusion, and deploying them on the Jetson-Nano for
unmanned vehicles with monocular vision sensors. We use ROS for experiment. The
method proposed in this paper is suitable for mobile platforms with high
real-time request. Innovation of our method is using information fusion to
compensate the problem of insufficient frame rate of output image, and improve
the robustness of target detection and depth estimation under monocular
vision.Object Detection is based on YOLO-v5. We have simplified the network
structure of its DarkNet53 and realized a prediction speed up to 0.01s. Depth
Estimation is based on the VNL Depth Estimation, which considers multiple
geometric constraints in 3D global space. It calculates the loss function by
calculating the deviation of the virtual normal vector VN and the label, which
can obtain deeper depth information. We use PnP fusion algorithm to solve the
problem of insufficient frame rate of depth map output. It solves the motion
estimation depth from three-dimensional target to two-dimensional point based
on corner feature matching, which is faster than VNL calculation. We
interpolate VNL output and PnP output to achieve information fusion.
Experiments show that this can effectively eliminate the jitter of depth
information and improve robustness. At the control end, this method combines
the results of target detection and depth estimation to calculate the target
position, and uses a pure tracking control algorithm to track it.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.07932v1,2022-04-17T05:15:51Z,2022-04-17T05:15:51Z,"Towards Comprehensive Testing on the Robustness of Cooperative
  Multi-agent Reinforcement Learning","While deep neural networks (DNNs) have strengthened the performance of
cooperative multi-agent reinforcement learning (c-MARL), the agent policy can
be easily perturbed by adversarial examples. Considering the safety critical
applications of c-MARL, such as traffic management, power management and
unmanned aerial vehicle control, it is crucial to test the robustness of c-MARL
algorithm before it was deployed in reality. Existing adversarial attacks for
MARL could be used for testing, but is limited to one robustness aspects (e.g.,
reward, state, action), while c-MARL model could be attacked from any aspect.
To overcome the challenge, we propose MARLSafe, the first robustness testing
framework for c-MARL algorithms. First, motivated by Markov Decision Process
(MDP), MARLSafe consider the robustness of c-MARL algorithms comprehensively
from three aspects, namely state robustness, action robustness and reward
robustness. Any c-MARL algorithm must simultaneously satisfy these robustness
aspects to be considered secure. Second, due to the scarceness of c-MARL
attack, we propose c-MARL attacks as robustness testing algorithms from
multiple aspects. Experiments on \textit{SMAC} environment reveals that many
state-of-the-art c-MARL algorithms are of low robustness in all aspect,
pointing out the urgent need to test and enhance robustness of c-MARL
algorithms.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.07521v1,2022-03-14T22:06:48Z,2022-03-14T22:06:48Z,"Automatic lane change scenario extraction and generation of scenarios in
  OpenX format from real-world data","Autonomous Vehicles (AV)'s wide-scale deployment appears imminent despite
many safety challenges yet to be resolved. The modern autonomous vehicles will
undoubtedly include machine learning and probabilistic techniques that add
significant complexity to the traditional verification and validation methods.
Road testing is essential before the deployment, but scenarios are repeatable,
and it's hard to collect challenging events. Exploring numerous, diverse and
crucial scenarios is a time-consuming and expensive approach. The research
community and industry have widely accepted scenario-based testing in the last
few years. As it is focused directly on the relevant critical road situations,
it can reduce the effort required in testing. The scenario-based testing in
simulation requires the realistic behaviour of the traffic participants to
assess the System Under Test (SUT). It is essential to capture the scenarios
from the real world to encode the behaviour of actual traffic participants.
This paper proposes a novel scenario extraction method to capture the lane
change scenarios using point-cloud data and object tracking information. This
method enables fully automatic scenario extraction compared to similar
approaches in this area. The generated scenarios are represented in OpenX
format to reuse them in the SUT evaluation easily. The motivation of this
framework is to build a validation dataset to generate many critical concrete
scenarios. The code is available online at
https://github.com/dkarunakaran/scenario_extraction_framework.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.01642v1,2022-03-03T11:03:28Z,2022-03-03T11:03:28Z,"Adaptive Path Planning for UAVs for Multi-Resolution Semantic
  Segmentation","Efficient data collection methods play a major role in helping us better
understand the Earth and its ecosystems. In many applications, the usage of
unmanned aerial vehicles (UAVs) for monitoring and remote sensing is rapidly
gaining momentum due to their high mobility, low cost, and flexible deployment.
A key challenge is planning missions to maximize the value of acquired data in
large environments given flight time limitations. This is, for example,
relevant for monitoring agricultural fields. This paper addresses the problem
of adaptive path planning for accurate semantic segmentation of using UAVs. We
propose an online planning algorithm which adapts the UAV paths to obtain
high-resolution semantic segmentations necessary in areas with fine details as
they are detected in incoming images. This enables us to perform close
inspections at low altitudes only where required, without wasting energy on
exhaustive mapping at maximum image resolution. A key feature of our approach
is a new accuracy model for deep learning-based architectures that captures the
relationship between UAV altitude and semantic segmentation accuracy. We
evaluate our approach on different domains using real-world data, proving the
efficacy and generability of our solution.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.00938v1,2022-03-02T08:40:01Z,2022-03-02T08:40:01Z,Neuro-Symbolic Verification of Deep Neural Networks,"Formal verification has emerged as a powerful approach to ensure the safety
and reliability of deep neural networks. However, current verification tools
are limited to only a handful of properties that can be expressed as
first-order constraints over the inputs and output of a network. While
adversarial robustness and fairness fall under this category, many real-world
properties (e.g., ""an autonomous vehicle has to stop in front of a stop sign"")
remain outside the scope of existing verification technology. To mitigate this
severe practical restriction, we introduce a novel framework for verifying
neural networks, named neuro-symbolic verification. The key idea is to use
neural networks as part of the otherwise logical specification, enabling the
verification of a wide variety of complex, real-world properties, including the
one above. Moreover, we demonstrate how neuro-symbolic verification can be
implemented on top of existing verification infrastructure for neural networks,
making our framework easily accessible to researchers and practitioners alike.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.00080v1,2022-02-28T20:30:37Z,2022-02-28T20:30:37Z,Deep Camera Pose Regression Using Pseudo-LiDAR,"An accurate and robust large-scale localization system is an integral
component for active areas of research such as autonomous vehicles and
augmented reality. To this end, many learning algorithms have been proposed
that predict 6DOF camera pose from RGB or RGB-D images. However, previous
methods that incorporate depth typically treat the data the same way as RGB
images, often adding depth maps as additional channels to RGB images and
passing them through convolutional neural networks (CNNs). In this paper, we
show that converting depth maps into pseudo-LiDAR signals, previously shown to
be useful for 3D object detection, is a better representation for camera
localization tasks by projecting point clouds that can accurately determine
6DOF camera pose. This is demonstrated by first comparing localization
accuracies of a network operating exclusively on pseudo-LiDAR representations,
with networks operating exclusively on depth maps. We then propose FusionLoc, a
novel architecture that uses pseudo-LiDAR to regress a 6DOF camera pose.
FusionLoc is a dual stream neural network, which aims to remedy common issues
with typical 2D CNNs operating on RGB-D images. The results from this
architecture are compared against various other state-of-the-art deep pose
regression implementations using the 7 Scenes dataset. The findings are that
FusionLoc performs better than a number of other camera localization methods,
with a notable improvement being, on average, 0.33m and 4.35{\deg} more
accurate than RGB-D PoseNet. By proving the validity of using pseudo-LiDAR
signals over depth maps for localization, there are new considerations when
implementing large-scale localization systems.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.04224v1,2022-02-09T01:45:12Z,2022-02-09T01:45:12Z,Intelligent Autonomous Intersection Management,"Connected Autonomous Vehicles will make autonomous intersection management a
reality replacing traditional traffic signal control. Autonomous intersection
management requires time and speed adjustment of vehicles arriving at an
intersection for collision-free passing through the intersection. Due to its
computational complexity, this problem has been studied only when vehicle
arrival times towards the vicinity of the intersection are known beforehand,
which limits the applicability of these solutions for real-time deployment. To
solve the real-time autonomous traffic intersection management problem, we
propose a reinforcement learning (RL) based multiagent architecture and a novel
RL algorithm coined multi-discount Q-learning. In multi-discount Q-learning, we
introduce a simple yet effective way to solve a Markov Decision Process by
preserving both short-term and long-term goals, which is crucial for
collision-free speed control. Our empirical results show that our RL-based
multiagent solution can achieve near-optimal performance efficiently when
minimizing the travel time through an intersection.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.02352v2,2022-05-15T21:24:49Z,2022-02-04T19:20:58Z,"Learning Interpretable, High-Performing Policies for Autonomous Driving","Gradient-based approaches in reinforcement learning (RL) have achieved
tremendous success in learning policies for autonomous vehicles. While the
performance of these approaches warrants real-world adoption, these policies
lack interpretability, limiting deployability in the safety-critical and
legally-regulated domain of autonomous driving (AD). AD requires interpretable
and verifiable control policies that maintain high performance. We propose
Interpretable Continuous Control Trees (ICCTs), a tree-based model that can be
optimized via modern, gradient-based, RL approaches to produce high-performing,
interpretable policies. The key to our approach is a procedure for allowing
direct optimization in a sparse decision-tree-like representation. We validate
ICCTs against baselines across six domains, showing that ICCTs are capable of
learning interpretable policy representations that parity or outperform
baselines by up to 33% in AD scenarios while achieving a 300x-600x reduction in
the number of policy parameters against deep learning baselines. Furthermore,
we demonstrate the interpretability and utility of our ICCTs through a 14-car
physical robot demonstration.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.00091v1,2022-01-31T21:10:47Z,2022-01-31T21:10:47Z,"Query Efficient Decision Based Sparse Attacks Against Black-Box Deep
  Learning Models","Despite our best efforts, deep learning models remain highly vulnerable to
even tiny adversarial perturbations applied to the inputs. The ability to
extract information from solely the output of a machine learning model to craft
adversarial perturbations to black-box models is a practical threat against
real-world systems, such as autonomous cars or machine learning models exposed
as a service (MLaaS). Of particular interest are sparse attacks. The
realization of sparse attacks in black-box models demonstrates that machine
learning models are more vulnerable than we believe. Because these attacks aim
to minimize the number of perturbed pixels measured by l_0 norm-required to
mislead a model by solely observing the decision (the predicted label) returned
to a model query; the so-called decision-based attack setting. But, such an
attack leads to an NP-hard optimization problem. We develop an evolution-based
algorithm-SparseEvo-for the problem and evaluate against both convolutional
deep neural networks and vision transformers. Notably, vision transformers are
yet to be investigated under a decision-based attack setting. SparseEvo
requires significantly fewer model queries than the state-of-the-art sparse
attack Pointwise for both untargeted and targeted attacks. The attack
algorithm, although conceptually simple, is also competitive with only a
limited query budget against the state-of-the-art gradient-based whitebox
attacks in standard computer vision tasks such as ImageNet. Importantly, the
query efficient SparseEvo, along with decision-based attacks, in general, raise
new questions regarding the safety of deployed systems and poses new directions
to study and understand the robustness of machine learning models.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.05797v1,2022-01-15T09:05:22Z,2022-01-15T09:05:22Z,"Finding Label and Model Errors in Perception Data With Learned
  Observation Assertions","ML is being deployed in complex, real-world scenarios where errors have
impactful consequences. In these systems, thorough testing of the ML pipelines
is critical. A key component in ML deployment pipelines is the curation of
labeled training data. Common practice in the ML literature assumes that labels
are the ground truth. However, in our experience in a large autonomous vehicle
development center, we have found that vendors can often provide erroneous
labels, which can lead to downstream safety risks in trained models.
  To address these issues, we propose a new abstraction, learned observation
assertions, and implement it in a system called Fixy. Fixy leverages existing
organizational resources, such as existing (possibly noisy) labeled datasets or
previously trained ML models, to learn a probabilistic model for finding errors
in human- or model-generated labels. Given user-provided features and these
existing resources, Fixy learns feature distributions that specify likely and
unlikely values (e.g., that a speed of 30mph is likely but 300mph is unlikely).
It then uses these feature distributions to score labels for potential errors.
We show that FIxy can automatically rank potential errors in real datasets with
up to 2$\times$ higher precision compared to recent work on model assertions
and standard techniques such as uncertainty sampling.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.05518v1,2022-01-14T15:41:05Z,2022-01-14T15:41:05Z,UGV-UAV Object Geolocation in Unstructured Environments,"A robotic system of multiple unmanned ground vehicles (UGVs) and unmanned
aerial vehicles (UAVs) has the potential for advancing autonomous object
geolocation performance. Much research has focused on algorithmic improvements
on individual components, such as navigation, motion planning, and perception.
In this paper, we present a UGV-UAV object detection and geolocation system,
which performs perception, navigation, and planning autonomously in real scale
in unstructured environment. We designed novel sensor pods equipped with
multispectral (visible, near-infrared, thermal), high resolution (181.6 Mega
Pixels), stereo (near-infrared pair), wide field of view (192 degree HFOV)
array. We developed a novel on-board software-hardware architecture to process
the high volume sensor data in real-time, and we built a custom AI subsystem
composed of detection, tracking, navigation, and planning for autonomous
objects geolocation in real-time.
  This research is the first real scale demonstration of such high speed data
processing capability. Our novel modular sensor pod can boost relevant computer
vision and machine learning research. Our novel hardware-software architecture
is a solid foundation for system-level and component-level research. Our system
is validated through data-driven offline tests as well as a series of field
tests in unstructured environments. We present quantitative results as well as
discussions on key robotic system level challenges which manifest when we build
and test the system. This system is the first step toward a UGV-UAV cooperative
reconnaissance system in the future.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.11561v2,2022-04-27T07:25:54Z,2021-12-21T22:51:37Z,"Explainable artificial intelligence for autonomous driving: An overview
  and guide for future research directions","Autonomous driving has achieved a significant milestone in research and
development over the last decade. There is increasing interest in the field as
the deployment of self-operating vehicles promises safer and more ecologically
friendly transportation systems. With the rise of computationally powerful
artificial intelligence (AI) techniques, autonomous vehicles can sense their
environment with high precision, make safe real-time decisions, and operate
reliably without human intervention. However, intelligent decision-making in
autonomous cars is not generally understandable by humans in the current state
of the art, and such deficiency hinders this technology from being socially
acceptable. Hence, aside from making safe real-time decisions, the AI systems
of autonomous vehicles also need to explain how their decisions are constructed
in order to be regulatory compliant across many jurisdictions. Our study sheds
a comprehensive light on the development of explainable artificial intelligence
(XAI) approaches for autonomous vehicles. In particular, we make the following
contributions. First, we provide a thorough overview of the state-of-the-art
studies on XAI for autonomous driving. We then propose an XAI framework that
considers all the societal and legal requirements for explainability of
autonomous driving systems. Finally, as future research directions, we provide
a guide to XAI approaches that can improve operational safety and transparency
to support public approval of autonomous driving technology by regulators,
manufacturers, and all engaged stakeholders.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.14243v1,2021-11-28T21:32:31Z,2021-11-28T21:32:31Z,"EffCNet: An Efficient CondenseNet for Image Classification on NXP
  BlueBox","Intelligent edge devices with built-in processors vary widely in terms of
capability and physical form to perform advanced Computer Vision (CV) tasks
such as image classification and object detection, for example. With constant
advances in the field of autonomous cars and UAVs, embedded systems and mobile
devices, there has been an ever-growing demand for extremely efficient
Artificial Neural Networks (ANN) for real-time inference on these smart edge
devices with constrained computational resources. With unreliable network
connections in remote regions and an added complexity of data transmission, it
is of an utmost importance to capture and process data locally instead of
sending the data to cloud servers for remote processing. Edge devices on the
other hand, offer limited processing power due to their inexpensive hardware,
and limited cooling and computational resources. In this paper, we propose a
novel deep convolutional neural network architecture called EffCNet which is an
improved and an efficient version of CondenseNet Convolutional Neural Network
(CNN) for edge devices utilizing self-querying data augmentation and depthwise
separable convolutional strategies to improve real-time inference performance
as well as reduce the final trained model size, trainable parameters, and
Floating-Point Operations (FLOPs) of EffCNet CNN. Furthermore, extensive
supervised image classification analyses are conducted on two benchmarking
datasets: CIFAR-10 and CIFAR-100, to verify real-time inference performance of
our proposed CNN. Finally, we deploy these trained weights on NXP BlueBox which
is an intelligent edge development platform designed for self-driving vehicles
and UAVs, and conclusions will be extrapolated accordingly.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.14176v1,2021-11-28T15:28:31Z,2021-11-28T15:28:31Z,UAV-based Crowd Surveillance in Post COVID-19 Era,"To cope with the current pandemic situation and reinstate pseudo-normal daily
life, several measures have been deployed and maintained, such as mask wearing,
social distancing, hands sanitizing, etc. Since outdoor cultural events,
concerts, and picnics, are gradually allowed, a close monitoring of the crowd
activity is needed to avoid undesired contact and disease transmission. In this
context, intelligent unmanned aerial vehicles (UAVs) can be occasionally
deployed to ensure the surveillance of these activities, that health
restriction measures are applied, and to trigger alerts when the latter are not
respected. Consequently, we propose in this paper a complete UAV framework for
intelligent monitoring of post COVID-19 outdoor activities. Specifically, we
propose a three steps approach. In the first step, captured images by a UAV are
analyzed using machine learning to detect and locate individuals. The second
step consists of a novel coordinates mapping approach to evaluate distances
among individuals, then cluster them, while the third step provides an
energy-efficient and/or reliable UAV trajectory to inspect clusters for
restrictions violation such as mask wearing. Obtained results provide the
following insights: 1) Efficient detection of individuals depends on the angle
from which the image was captured, 2) coordinates mapping is very sensitive to
the estimation error in individuals' bounding boxes, and 3) UAV trajectory
design algorithm 2-Opt is recommended for practical real-time deployments due
to its low-complexity and near-optimal performance.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.06123v1,2021-11-11T10:01:01Z,2021-11-11T10:01:01Z,"Spatio-Temporal Scene-Graph Embedding for Autonomous Vehicle Collision
  Prediction","In autonomous vehicles (AVs), early warning systems rely on collision
prediction to ensure occupant safety. However, state-of-the-art methods using
deep convolutional networks either fail at modeling collisions or are too
expensive/slow, making them less suitable for deployment on AV edge hardware.
To address these limitations, we propose sg2vec, a spatio-temporal scene-graph
embedding methodology that uses Graph Neural Network (GNN) and Long Short-Term
Memory (LSTM) layers to predict future collisions via visual scene perception.
We demonstrate that sg2vec predicts collisions 8.11% more accurately and 39.07%
earlier than the state-of-the-art method on synthesized datasets, and 29.47%
more accurately on a challenging real-world collision dataset. We also show
that sg2vec is better than the state-of-the-art at transferring knowledge from
synthetic datasets to real-world driving datasets. Finally, we demonstrate that
sg2vec performs inference 9.3x faster with an 88.0% smaller model, 32.4% less
power, and 92.8% less energy than the state-of-the-art method on the
industry-standard Nvidia DRIVE PX 2 platform, making it more suitable for
implementation on the edge.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.03201v2,2021-11-09T08:02:35Z,2021-11-05T00:16:06Z,"Compressing Sensor Data for Remote Assistance of Autonomous Vehicles
  using Deep Generative Models","In the foreseeable future, autonomous vehicles will require human assistance
in situations they can not resolve on their own. In such scenarios, remote
assistance from a human can provide the required input for the vehicle to
continue its operation. Typical sensors used in autonomous vehicles include
camera and lidar sensors. Due to the massive volume of sensor data that must be
sent in real-time, highly efficient data compression is elementary to prevent
an overload of network infrastructure. Sensor data compression using deep
generative neural networks has been shown to outperform traditional compression
approaches for both image and lidar data, regarding compression rate as well as
reconstruction quality. However, there is a lack of research about the
performance of generative-neural-network-based compression algorithms for
remote assistance. In order to gain insights into the feasibility of deep
generative models for usage in remote assistance, we evaluate state-of-the-art
algorithms regarding their applicability and identify potential weaknesses.
Further, we implement an online pipeline for processing sensor data and
demonstrate its performance for remote assistance using the CARLA simulator.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.07742v1,2021-10-14T21:53:03Z,2021-10-14T21:53:03Z,"Beyond Classification: Directly Training Spiking Neural Networks for
  Semantic Segmentation","Spiking Neural Networks (SNNs) have recently emerged as the low-power
alternative to Artificial Neural Networks (ANNs) because of their sparse,
asynchronous, and binary event-driven processing. Due to their energy
efficiency, SNNs have a high possibility of being deployed for real-world,
resource-constrained systems such as autonomous vehicles and drones. However,
owing to their non-differentiable and complex neuronal dynamics, most previous
SNN optimization methods have been limited to image recognition. In this paper,
we explore the SNN applications beyond classification and present semantic
segmentation networks configured with spiking neurons. Specifically, we first
investigate two representative SNN optimization techniques for recognition
tasks (i.e., ANN-SNN conversion and surrogate gradient learning) on semantic
segmentation datasets. We observe that, when converted from ANNs, SNNs suffer
from high latency and low performance due to the spatial variance of features.
Therefore, we directly train networks with surrogate gradient learning,
resulting in lower latency and higher performance than ANN-SNN conversion.
Moreover, we redesign two fundamental ANN segmentation architectures (i.e.,
Fully Convolutional Networks and DeepLab) for the SNN domain. We conduct
experiments on two public semantic segmentation benchmarks including the PASCAL
VOC2012 dataset and the DDD17 event-based dataset. In addition to showing the
feasibility of SNNs for semantic segmentation, we show that SNNs can be more
robust and energy-efficient compared to their ANN counterparts in this domain.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.15286v2,2022-02-28T16:30:54Z,2021-09-30T17:30:43Z,Unsupervised Domain Adaptation for LiDAR Panoptic Segmentation,"Scene understanding is a pivotal task for autonomous vehicles to safely
navigate in the environment. Recent advances in deep learning enable accurate
semantic reconstruction of the surroundings from LiDAR data. However, these
models encounter a large domain gap while deploying them on vehicles equipped
with different LiDAR setups which drastically decreases their performance.
Fine-tuning the model for every new setup is infeasible due to the expensive
and cumbersome process of recording and manually labeling new data.
Unsupervised Domain Adaptation (UDA) techniques are thus essential to fill this
domain gap and retain the performance of models on new sensor setups without
the need for additional data labeling. In this paper, we propose AdaptLPS, a
novel UDA approach for LiDAR panoptic segmentation that leverages task-specific
knowledge and accounts for variation in the number of scan lines, mounting
position, intensity distribution, and environmental conditions. We tackle the
UDA task by employing two complementary domain adaptation strategies,
data-based and model-based. While data-based adaptations reduce the domain gap
by processing the raw LiDAR scans to resemble the scans in the target domain,
model-based techniques guide the network in extracting features that are
representative for both domains. Extensive evaluations on three pairs of
real-world autonomous driving datasets demonstrate that AdaptLPS outperforms
existing UDA approaches by up to 6.41 pp in terms of the PQ score.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.13751v2,2021-11-25T14:01:38Z,2021-09-28T14:11:36Z,StereoSpike: Depth Learning with a Spiking Neural Network,"Depth estimation is an important computer vision task, useful in particular
for navigation in autonomous vehicles, or for object manipulation in robotics.
Here we solved it using an end-to-end neuromorphic approach, combining two
event-based cameras and a Spiking Neural Network (SNN) with a slightly modified
U-Net-like encoder-decoder architecture, that we named StereoSpike. More
specifically, we used the Multi Vehicle Stereo Event Camera Dataset (MVSEC). It
provides a depth ground-truth, which was used to train StereoSpike in a
supervised manner, using surrogate gradient descent. We propose a novel readout
paradigm to obtain a dense analog prediction -- the depth of each pixel -- from
the spikes of the decoder. We demonstrate that this architecture generalizes
very well, even better than its non-spiking counterparts, leading to
state-of-the-art test accuracy. To the best of our knowledge, it is the first
time that such a large-scale regression problem is solved by a fully spiking
network. Finally, we show that low firing rates (<10%) can be obtained via
regularization, with a minimal cost in accuracy. This means that StereoSpike
could be efficiently implemented on neuromorphic chips, opening the door for
low power and real time embedded systems.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.11661v3,2022-05-04T14:37:45Z,2021-09-23T21:55:12Z,"Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking
  for Smart Cities","In this paper, to reduce the congestion rate at the city center and increase
the quality of experience (QoE) of each user, the framework of long-range
autonomous valet parking (LAVP) is presented, where an Autonomous Vehicle (AV)
is deployed in the city, which can pick up, drop off users at their required
spots, and then drive to the car park out of city center autonomously. In this
framework, we aim to minimize the overall distance of the AV, while guarantee
all users are served, i.e., picking up, and dropping off users at their
required spots through optimizing the path planning of the AV and number of
serving time slots. To this end, we first propose a learning based algorithm,
which is named as Double-Layer Ant Colony Optimization (DL-ACO) algorithm to
solve the above problem in an iterative way. Then, to make the real-time
decision, while consider the dynamic environment (i.e., the AV may pick up and
drop off users from different locations), we further present a deep
reinforcement learning (DRL) based algorithm, which is known as deep Q network
(DQN). The experimental results show that the DL-ACO and DQN-based algorithms
both achieve the considerable performance.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.06668v4,2022-07-12T18:27:19Z,2021-09-14T13:16:33Z,Exploration in Deep Reinforcement Learning: A Comprehensive Survey,"Deep Reinforcement Learning (DRL) and Deep Multi-agent Reinforcement Learning
(MARL) have achieved significant successes across a wide range of domains,
including game AI, autonomous vehicles, robotics, and so on. However, DRL and
deep MARL agents are widely known to be sample inefficient that millions of
interactions are usually needed even for relatively simple problem settings,
thus preventing the wide application and deployment in real-industry scenarios.
One bottleneck challenge behind is the well-known exploration problem, i.e.,
how efficiently exploring the environment and collecting informative
experiences that could benefit policy learning towards the optimal ones. This
problem becomes more challenging in complex environments with sparse rewards,
noisy distractions, long horizons, and non-stationary co-learners. In this
paper, we conduct a comprehensive survey on existing exploration methods for
both single-agent and multi-agent RL. We start the survey by identifying
several key challenges to efficient exploration. Beyond the above two main
branches, we also include other notable exploration methods with different
ideas and techniques. In addition to algorithmic analysis, we provide a
comprehensive and unified empirical comparison of different exploration methods
for DRL on a set of commonly used benchmarks. According to our algorithmic and
empirical investigation, we finally summarize the open problems of exploration
in DRL and deep MARL and point out a few future directions.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.06126v4,2022-07-21T15:48:43Z,2021-09-13T17:05:43Z,"Neural Network Guided Evolutionary Fuzzing for Finding Traffic
  Violations of Autonomous Vehicles","Self-driving cars and trucks, autonomous vehicles (AVs), should not be
accepted by regulatory bodies and the public until they have much higher
confidence in their safety and reliability -- which can most practically and
convincingly be achieved by testing. But existing testing methods are
inadequate for checking the end-to-end behaviors of AV controllers against
complex, real-world corner cases involving interactions with multiple
independent agents such as pedestrians and human-driven vehicles. While
test-driving AVs on streets and highways fails to capture many rare events,
existing simulation-based testing methods mainly focus on simple scenarios and
do not scale well for complex driving situations that require sophisticated
awareness of the surroundings. To address these limitations, we propose a new
fuzz testing technique, called AutoFuzz, which can leverage widely-used AV
simulators' API grammars to generate semantically and temporally valid complex
driving scenarios (sequences of scenes). To efficiently search for traffic
violations-inducing scenarios in a large search space, we propose a constrained
neural network (NN) evolutionary search method to optimize AutoFuzz. Evaluation
of our prototype on one state-of-the-art learning-based controller, two
rule-based controllers, and one industrial-grade controller in five scenarios
shows that AutoFuzz efficiently finds hundreds of traffic violations in
high-fidelity simulation environments. For each scenario, AutoFuzz can find on
average 10-39% more unique traffic violations than the best-performing baseline
method. Further, fine-tuning the learning-based controller with the traffic
violations found by AutoFuzz successfully reduced the traffic violations found
in the new version of the AV controller software.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.02529v2,2021-09-07T04:46:01Z,2021-09-06T15:12:17Z,"ViSTA: a Framework for Virtual Scenario-based Testing of Autonomous
  Vehicles","In this paper, we present ViSTA, a framework for Virtual Scenario-based
Testing of Autonomous Vehicles (AV), developed as part of the 2021 IEEE
Autonomous Test Driving AI Test Challenge. Scenario-based virtual testing aims
to construct specific challenges posed for the AV to overcome, albeit in
virtual test environments that may not necessarily resemble the real world.
This approach is aimed at identifying specific issues that arise safety
concerns before an actual deployment of the AV on the road. In this paper, we
describe a comprehensive test case generation approach that facilitates the
design of special-purpose scenarios with meaningful parameters to form test
cases, both in automated and manual ways, leveraging the strength and
weaknesses of either. Furthermore, we describe how to automate the execution of
test cases, and analyze the performance of the AV under these test cases.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.01896v5,2022-03-18T04:24:39Z,2021-09-04T16:26:31Z,"GamePlan: Game-Theoretic Multi-Agent Planning with Human Drivers at
  Intersections, Roundabouts, and Merging","We present a new method for multi-agent planning involving human drivers and
autonomous vehicles (AVs) in unsignaled intersections, roundabouts, and during
merging. In multi-agent planning, the main challenge is to predict the actions
of other agents, especially human drivers, as their intentions are hidden from
other agents. Our algorithm uses game theory to develop a new auction, called
GamePlan, that directly determines the optimal action for each agent based on
their driving style (which is observable via commonly available sensors).
GamePlan assigns a higher priority to more aggressive or impatient drivers and
a lower priority to more conservative or patient drivers; we theoretically
prove that such an approach is game-theoretically optimal prevents collisions
and deadlocks. We compare our approach with prior state-of-the-art auction
techniques including economic auctions, time-based auctions (first-in
first-out), and random bidding and show that each of these methods result in
collisions among agents when taking into account driver behavior. We compare
with methods based on DRL, deep learning, and game theory and present our
benefits over these approaches. Finally, we show that our approach can be
implemented in the real-world with human drivers.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.10617v1,2021-08-24T10:06:53Z,2021-08-24T10:06:53Z,Image-free single-pixel segmentation,"The existing segmentation techniques require high-fidelity images as input to
perform semantic segmentation. Since the segmentation results contain most of
edge information that is much less than the acquired images, the throughput gap
leads to both hardware and software waste. In this letter, we report an
image-free single-pixel segmentation technique. The technique combines
structured illumination and single-pixel detection together, to efficiently
samples and multiplexes scene's segmentation information into compressed
one-dimensional measurements. The illumination patterns are optimized together
with the subsequent reconstruction neural network, which directly infers
segmentation maps from the single-pixel measurements. The end-to-end
encoding-and-decoding learning framework enables optimized illumination with
corresponding network, which provides both high acquisition and segmentation
efficiency. Both simulation and experimental results validate that accurate
segmentation can be achieved using two-order-of-magnitude less input data. When
the sampling ratio is 1%, the Dice coefficient reaches above 80% and the pixel
accuracy reaches above 96%. We envision that this image-free segmentation
technique can be widely applied in various resource-limited platforms such as
UAV and unmanned vehicle that require real-time sensing.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.01884v1,2021-08-04T07:30:04Z,2021-08-04T07:30:04Z,"Adaptive Path Planning for UAV-based Multi-Resolution Semantic
  Segmentation","In this paper, we address the problem of adaptive path planning for accurate
semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The
usage of UAVs for terrain monitoring and remote sensing is rapidly gaining
momentum due to their high mobility, low cost, and flexible deployment.
However, a key challenge is planning missions to maximize the value of acquired
data in large environments given flight time limitations. To address this, we
propose an online planning algorithm which adapts the UAV paths to obtain
high-resolution semantic segmentations necessary in areas on the terrain with
fine details as they are detected in incoming images. This enables us to
perform close inspections at low altitudes only where required, without wasting
energy on exhaustive mapping at maximum resolution. A key feature of our
approach is a new accuracy model for deep learning-based architectures that
captures the relationship between UAV altitude and semantic segmentation
accuracy. We evaluate our approach on the application of crop/weed segmentation
in precision agriculture using real-world field data.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.14389v2,2022-03-27T07:09:17Z,2021-07-30T01:37:24Z,DarkLighter: Light Up the Darkness for UAV Tracking,"Recent years have witnessed the fast evolution and promising performance of
the convolutional neural network (CNN)-based trackers, which aim at imitating
biological visual systems. However, current CNN-based trackers can hardly
generalize well to low-light scenes that are commonly lacked in the existing
training set. In indistinguishable night scenarios frequently encountered in
unmanned aerial vehicle (UAV) tracking-based applications, the robustness of
the state-of-the-art (SOTA) trackers drops significantly. To facilitate aerial
tracking in the dark through a general fashion, this work proposes a low-light
image enhancer namely DarkLighter, which dedicates to alleviate the impact of
poor illumination and noise iteratively. A lightweight map estimation network,
i.e., ME-Net, is trained to efficiently estimate illumination maps and noise
maps jointly. Experiments are conducted with several SOTA trackers on numerous
UAV dark tracking scenes. Exhaustive evaluations demonstrate the reliability
and universality of DarkLighter, with high efficiency. Moreover, DarkLighter
has further been implemented on a typical UAV system. Real-world tests at night
scenes have verified its practicability and dependability.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.13869v4,2022-04-11T10:54:43Z,2021-07-29T10:11:36Z,"Autonomous UAV Base Stations for Next Generation Wireless Networks: A
  Deep Learning Approach","To address the ever-growing connectivity demands of wireless communications,
the adoption of ingenious solutions, such as Unmanned Aerial Vehicles (UAVs) as
mobile Base Stations (BSs), is imperative. In general, the location of a UAV
Base Station (UAV-BS) is determined by optimization algorithms, which have high
computationally complexities and place heavy demands on UAV resources. In this
paper, we show that a Convolutional Neural Network (CNN) model can be trained
to infer the location of a UAV-BS in real time. In so doing, we create a
framework to determine the UAV locations that considers the deployment of
Mobile Users (MUs) to generate labels by using the data obtained from an
optimization algorithm. Performance evaluations reveal that once the CNN model
is trained with the given labels and locations of MUs, the proposed approach is
capable of approximating the results given by the adopted optimization
algorithm with high fidelity, outperforming Reinforcement Learning (RL)-based
approaches. We also explore future research challenges and highlight key
issues.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.12137v2,2021-08-11T06:54:54Z,2021-07-26T12:18:23Z,AA3DNet: Attention Augmented Real Time 3D Object Detection,"In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
> 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.08325v1,2021-07-18T00:00:48Z,2021-07-18T00:00:48Z,"Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement
  Learning","Autonomous car racing is a challenging task in the robotic control area.
Traditional modular methods require accurate mapping, localization and
planning, which makes them computationally inefficient and sensitive to
environmental changes. Recently, deep-learning-based end-to-end systems have
shown promising results for autonomous driving/racing. However, they are
commonly implemented by supervised imitation learning (IL), which suffers from
the distribution mismatch problem, or by reinforcement learning (RL), which
requires a huge amount of risky interaction data. In this work, we present a
general deep imitative reinforcement learning approach (DIRL), which
successfully achieves agile autonomous racing using visual inputs. The driving
knowledge is acquired from both IL and model-based RL, where the agent can
learn from human teachers as well as perform self-improvement by safely
interacting with an offline world model. We validate our algorithm both in a
high-fidelity driving simulation and on a real-world 1/20-scale RC-car with
limited onboard computation. The evaluation results demonstrate that our method
outperforms previous IL and RL methods in terms of sample efficiency and task
performance. Demonstration videos are available at
https://caipeide.github.io/autorace-dirl/",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.01784v1,2021-07-05T04:34:51Z,2021-07-05T04:34:51Z,"Learning a Model for Inferring a Spatial Road Lane Network Graph using
  Self-Supervision","Interconnected road lanes are a central concept for navigating urban roads.
Currently, most autonomous vehicles rely on preconstructed lane maps as
designing an algorithmic model is difficult. However, the generation and
maintenance of such maps is costly and hinders large-scale adoption of
autonomous vehicle technology. This paper presents the first self-supervised
learning method to train a model to infer a spatially grounded lane-level road
network graph based on a dense segmented representation of the road scene
generated from onboard sensors. A formal road lane network model is presented
and proves that any structured road scene can be represented by a directed
acyclic graph of at most depth three while retaining the notion of intersection
regions, and that this is the most compressed representation. The formal model
is implemented by a hybrid neural and search-based model, utilizing a novel
barrier function loss formulation for robust learning from partial labels.
Experiments are conducted for all common road intersection layouts. Results
show that the model can generalize to new road layouts, unlike previous
approaches, demonstrating its potential for real-world application as a
practical learning-based lane-level map generator.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.01581v2,2022-02-08T16:41:28Z,2021-07-04T09:37:45Z,"Noise Tolerant Identification and Tuning Approach Using Deep Neural
  Networks For Visual Servoing Applications","Vision based control of Unmanned Aerial Vehicles (UAVs) has been adopted by a
wide range of applications due to the availability of low-cost on-board sensors
and computers. Tuning such systems to work properly requires extensive domain
specific experience, which limits the growth of emerging applications.
Moreover, obtaining performance limits of UAV based visual servoing is
difficult due to the complexity of the models used. In this paper, we propose a
novel noise tolerant approach for real-time identification and tuning of visual
servoing systems, based on deep neural networks (DNN) classification of system
response generated by the modified relay feedback test (MRFT). The proposed
method, called DNN with noise protected MRFT (DNN-NP-MRFT), can be used with a
multitude of vision sensors and estimation algorithms despite the high levels
of sensor's noise. Response of DNN-NP-MRFT to noise perturbations is
investigated and its effect on identification and tuning performance is
analyzed. The proposed DNN-NP-MRFT is able to detect performance changes due to
the use of high latency vision sensors, or due to the integration of inertial
measurement unit (IMU) measurements in the UAV states estimation. Experimental
identification closely matches simulation results, which can be used to explain
system behaviour and predict the closed loop performance limits for a given
hardware and software setup. We also demonstrate the ability of DNN-NP-MRFT
tuned UAVs to reject external disturbances like wind, or human push and pull.
Finally, we discuss the advantages of the proposed DNN-NP-MRFT visual servoing
design approach compared with other approaches in literature.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.11716v3,2022-01-09T00:49:50Z,2021-06-22T12:33:07Z,Robust EMRAN-aided Coupled Controller for Autonomous Vehicles,"This paper presents a coupled, neural network-aided longitudinal cruise and
lateral path-tracking controller for an autonomous vehicle with model
uncertainties and experiencing unknown external disturbances. Using a feedback
error learning mechanism, an inverse vehicle dynamics learning scheme utilizing
an adaptive Radial Basis Function (RBF) neural network, referred to as the
Extended Minimal Resource Allocating Network (EMRAN) is employed. EMRAN uses an
extended Kalman filter for online learning and weight updates, and also
incorporates a growing/pruning strategy for maintaining a compact network for
easier real-time implementation. The online learning algorithm handles the
parametric uncertainties and eliminates the effect of unknown disturbances on
the road. Combined with a self-regulating learning scheme for improving
generalization performance, the proposed EMRAN-aided control architecture aids
a basic PID cruise and Stanley path-tracking controllers in a coupled form. Its
performance and robustness to various disturbances and uncertainties are
compared with the conventional PID and Stanley controllers, along with a
comparison with a fuzzy-based PID controller and an active disturbance
rejection control (ADRC) scheme. Simulation results are presented for both slow
and high speed scenarios. The root mean square (RMS) and maximum tracking
errors clearly indicate the effectiveness of the proposed control scheme in
achieving better tracking performance in autonomous vehicles under unknown
environments.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.06369v1,2021-06-11T13:16:48Z,2021-06-11T13:16:48Z,"Courteous Behavior of Automated Vehicles at Unsignalized Intersections
  via Reinforcement Learning","The transition from today's mostly human-driven traffic to a purely automated
one will be a gradual evolution, with the effect that we will likely experience
mixed traffic in the near future. Connected and automated vehicles can benefit
human-driven ones and the whole traffic system in different ways, for example
by improving collision avoidance and reducing traffic waves. Many studies have
been carried out to improve intersection management, a significant bottleneck
in traffic, with intelligent traffic signals or exclusively automated vehicles.
However, the problem of how to improve mixed traffic at unsignalized
intersections has received less attention. In this paper, we propose a novel
approach to optimizing traffic flow at intersections in mixed traffic
situations using deep reinforcement learning. Our reinforcement learning agent
learns a policy for a centralized controller to let connected autonomous
vehicles at unsignalized intersections give up their right of way and yield to
other vehicles to optimize traffic flow. We implemented our approach and tested
it in the traffic simulator SUMO based on simulated and real traffic data. The
experimental evaluation demonstrates that our method significantly improves
traffic flow through unsignalized intersections in mixed traffic settings and
also provides better performance on a wide range of traffic situations compared
to the state-of-the-art traffic signal controller for the corresponding
signalized intersection.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.14052v1,2021-05-28T18:37:12Z,2021-05-28T18:37:12Z,"Targeted Deep Learning: Framework, Methods, and Applications","Deep learning systems are typically designed to perform for a wide range of
test inputs. For example, deep learning systems in autonomous cars are supposed
to deal with traffic situations for which they were not specifically trained.
In general, the ability to cope with a broad spectrum of unseen test inputs is
called generalization. Generalization is definitely important in applications
where the possible test inputs are known but plentiful or simply unknown, but
there are also cases where the possible inputs are few and unlabeled but known
beforehand. For example, medicine is currently interested in targeting
treatments to individual patients; the number of patients at any given time is
usually small (typically one), their diagnoses/responses/... are still unknown,
but their general characteristics (such as genome information, protein levels
in the blood, and so forth) are known before the treatment. We propose to call
deep learning in such applications targeted deep learning. In this paper, we
introduce a framework for targeted deep learning, and we devise and test an
approach for adapting standard pipelines to the requirements of targeted deep
learning. The approach is very general yet easy to use: it can be implemented
as a simple data-preprocessing step. We demonstrate on a variety of real-world
data that our approach can indeed render standard deep learning faster and more
accurate when the test inputs are known beforehand.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.13289v1,2021-05-26T17:36:35Z,2021-05-26T17:36:35Z,"MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet
  of Vehicles","Modern vehicles, including connected vehicles and autonomous vehicles,
nowadays involve many electronic control units connected through intra-vehicle
networks to implement various functionalities and perform actions. Modern
vehicles are also connected to external networks through vehicle-to-everything
technologies, enabling their communications with other vehicles,
infrastructures, and smart devices. However, the improving functionality and
connectivity of modern vehicles also increase their vulnerabilities to
cyber-attacks targeting both intra-vehicle and external networks due to the
large attack surfaces. To secure vehicular networks, many researchers have
focused on developing intrusion detection systems (IDSs) that capitalize on
machine learning methods to detect malicious cyber-attacks. In this paper, the
vulnerabilities of intra-vehicle and external networks are discussed, and a
multi-tiered hybrid IDS that incorporates a signature-based IDS and an
anomaly-based IDS is proposed to detect both known and unknown attacks on
vehicular networks. Experimental results illustrate that the proposed system
can detect various types of known attacks with 99.99% accuracy on the
CAN-intrusion-dataset representing the intra-vehicle network data and 99.88%
accuracy on the CICIDS2017 dataset illustrating the external vehicular network
data. For the zero-day attack detection, the proposed system achieves high
F1-scores of 0.963 and 0.800 on the above two datasets, respectively. The
average processing time of each data packet on a vehicle-level machine is less
than 0.6 ms, which shows the feasibility of implementing the proposed system in
real-time vehicle systems. This emphasizes the effectiveness and efficiency of
the proposed IDS.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.14190v1,2021-05-20T01:38:45Z,2021-05-20T01:38:45Z,RaspberryPI for mosquito neutralization by power laser,"In this article for the first time, comprehensive studies of mosquito
neutralization using machine vision and a 1 W power laser are considered.
Developed laser installation with Raspberry Pi that changing the direction of
the laser with a galvanometer. We developed a program for mosquito tracking in
real. The possibility of using deep neural networks, Haar cascades, machine
learning for mosquito recognition was considered. We considered in detail the
classification problems of mosquitoes in images. A recommendation is given for
the implementation of this device based on a microcontroller for subsequent use
as part of an unmanned aerial vehicle. Any harmful insects in the fields can be
used as objects for control.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.02613v1,2021-05-06T12:40:28Z,2021-05-06T12:40:28Z,"Challenges and Obstacles Towards Deploying Deep Learning Models on
  Mobile Devices","From computer vision and speech recognition to forecasting trajectories in
autonomous vehicles, deep learning approaches are at the forefront of so many
domains. Deep learning models are developed using plethora of high-level,
generic frameworks and libraries. Running those models on the mobile devices
require hardware-aware optimizations and in most cases converting the models to
other formats or using a third-party framework. In reality, most of the
developed models need to undergo a process of conversion, adaptation, and, in
some cases, full retraining to match the requirements and features of the
framework that is deploying the model on the target platform. Variety of
hardware platforms with heterogeneous computing elements, from wearable devices
to high-performance GPU clusters are used to run deep learning models. In this
paper, we present the existing challenges, obstacles, and practical solutions
towards deploying deep learning models on mobile devices.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.14006v1,2021-04-28T20:24:10Z,2021-04-28T20:24:10Z,"EmergencyNet: Efficient Aerial Image Classification for Drone-Based
  Emergency Monitoring Using Atrous Convolutional Feature Fusion","Deep learning-based algorithms can provide state-of-the-art accuracy for
remote sensing technologies such as unmanned aerial vehicles (UAVs)/drones,
potentially enhancing their remote sensing capabilities for many emergency
response and disaster management applications. In particular, UAVs equipped
with camera sensors can operating in remote and difficult to access
disaster-stricken areas, analyze the image and alert in the presence of various
calamities such as collapsed buildings, flood, or fire in order to faster
mitigate their effects on the environment and on human population. However, the
integration of deep learning introduces heavy computational requirements,
preventing the deployment of such deep neural networks in many scenarios that
impose low-latency constraints on inference, in order to make mission-critical
decisions in real time. To this end, this article focuses on the efficient
aerial image classification from on-board a UAV for emergency
response/monitoring applications. Specifically, a dedicated Aerial Image
Database for Emergency Response applications is introduced and a comparative
analysis of existing approaches is performed. Through this analysis a
lightweight convolutional neural network architecture is proposed, referred to
as EmergencyNet, based on atrous convolutions to process multiresolution
features and capable of running efficiently on low-power embedded platforms
achieving upto 20x higher performance compared to existing models with minimal
memory requirements with less than 1% accuracy drop compared to
state-of-the-art models.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.13617v2,2021-05-01T07:17:36Z,2021-04-28T07:54:40Z,"End-to-End Intersection Handling using Multi-Agent Deep Reinforcement
  Learning","Navigating through intersections is one of the main challenging tasks for an
autonomous vehicle. However, for the majority of intersections regulated by
traffic lights, the problem could be solved by a simple rule-based method in
which the autonomous vehicle behavior is closely related to the traffic light
states. In this work, we focus on the implementation of a system able to
navigate through intersections where only traffic signs are provided. We
propose a multi-agent system using a continuous, model-free Deep Reinforcement
Learning algorithm used to train a neural network for predicting both the
acceleration and the steering angle at each time step. We demonstrate that
agents learn both the basic rules needed to handle intersections by
understanding the priorities of other learners inside the environment, and to
drive safely along their paths. Moreover, a comparison between our system and a
rule-based method proves that our model achieves better results especially with
dense traffic conditions. Finally, we test our system on real world scenarios
using real recorded traffic data, proving that our module is able to generalize
both to unseen environments and to different traffic conditions.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.02108v1,2021-04-05T18:35:11Z,2021-04-05T18:35:11Z,Control of a Tail-Sitter VTOL UAV Based on Recurrent Neural Networks,"Tail-sitter vertical takeoff and landing (VTOL) unmanned aerial vehicles
(UAVs) have the capability of hovering and performing efficient level flight
with compact mechanical structures. We present a unified controller design for
such UAVs, based on recurrent neural networks. An advantage of this design
method is that the various flight modes (i.e., hovering, transition and level
flight) of a VTOL UAV are controlled in a unified manner, as opposed to
treating them separately and in the runtime switching one from another. The
proposed controller consists of an outer-loop position controller and an
inner-loop attitude controller. The inner-loop controller is composed of a
proportional attitude controller and a loop-shaping linear angular rate
controller. For the outer-loop controller, we propose a nonlinear solver to
compute the desired attitude and thrust, based on the UAV dynamics and an
aerodynamic model, in addition to a cascaded PID controller for the position
and velocity tracking. We employ a recurrent neural network (RNN) to
approximate the behavior of the nonlinear solver, which suffers from high
computational complexity. The proposed RNN has negligible approximation errors,
and can be implemented in real-time (e.g., 50 Hz). Moreover, the RNN generates
much smoother outputs than the nonlinear solver. We provide an analysis of the
stability and robustness of the overall closed-loop system. Simulation and
experiments are also presented to demonstrate the effectiveness of the proposed
method.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.14225v1,2021-03-26T02:25:42Z,2021-03-26T02:25:42Z,SD-VEC: Software-Defined Vehicular Edge Computing with Ultra-Low Latency,"New paradigm shifts and 6G technological revolution in vehicular services
have emerged toward unmanned driving, automated transportation, and
self-driving vehicles. As the technology for autonomous vehicles becomes
mature, real challenges come from reliable, safe, real-time connected
transportation operations to achieve ubiquitous and prompt information
exchanges with massive connected and autonomous vehicles. This article aims at
introducing novel wireless distributed architectures that embed the edge
computing capability inside software-defined vehicular networking
infrastructure. Such edge networks consist of open-loop grant-free
communications and computing-based control frameworks, which enable dynamic
eco-routing with ultra-low latency and mobile data-driven orchestration. Thus,
this work advances the frontiers of machine learning potentials and
next-generation mobile system realization in vehicular networking applications.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.10873v1,2021-03-19T15:56:58Z,2021-03-19T15:56:58Z,"Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power
  Autonomous Flying Nano-UAVs","Artificial intelligence-powered pocket-sized air robots have the potential to
revolutionize the Internet-of-Things ecosystem, acting as autonomous,
unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor,
nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor
human-drone interaction missions, as the pose estimation task we address in
this work. However, this scenario is challenged by the nano-UAVs' limited
payload and computational power that severely relegates the onboard brain to
the sub-100 mW microcontroller unit-class. Our work stands at the intersection
of the novel parallel ultra-low-power (PULP) architectural paradigm and our
general development methodology for deep neural network (DNN) visual pipelines,
i.e., covering from perception to control. Addressing the DNN model design,
from training and dataset augmentation to 8-bit quantization and deployment, we
demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for
the real-time execution (up to 135 frame/s) of our novel DNN, called
PULP-Frontnet. We showcase how, scaling our model's memory and computational
requirement, we can significantly improve the onboard inference (top energy
efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a
resource-unconstrained baseline (i.e., full-precision DNN). Field experiments
demonstrate a closed-loop top-notch autonomous navigation capability, with a
heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared
against the control performance achieved using an ideal sensing setup, onboard
relative pose inference yields excellent drone behavior in terms of median
absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular
(onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.13253v1,2021-02-26T01:31:28Z,2021-02-26T01:31:28Z,"On the Visual-based Safe Landing of UAVs in Populated Areas: a Crucial
  Aspect for Urban Deployment","Autonomous landing of Unmanned Aerial Vehicles (UAVs) in crowded scenarios is
crucial for successful deployment of UAVs in populated areas, particularly in
emergency landing situations where the highest priority is to avoid hurting
people. In this work, a new visual-based algorithm for identifying Safe Landing
Zones (SLZ) in crowded scenarios is proposed, considering a camera mounted on
an UAV, where the people in the scene move with unknown dynamics. To do so, a
density map is generated for each image frame using a Deep Neural Network, from
where a binary occupancy map is obtained aiming to overestimate the people's
location for security reasons. Then, the occupancy map is projected to the
head's plane, and the SLZ candidates are obtained as circular regions in the
head's plane with a minimum security radius. Finally, to keep track of the SLZ
candidates, a multiple instance tracking algorithm is implemented using Kalman
Filters along with the Hungarian algorithm for data association. Several
scenarios were studied to prove the validity of the proposed strategy,
including public datasets and real uncontrolled scenarios with people moving in
public squares, taken from an UAV in flight. The study showed promising results
in the search of preventing the UAV from hurting people during emergency
landing.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.12967v3,2022-03-31T09:29:13Z,2021-02-25T16:14:47Z,"A statistical framework for efficient out of distribution detection in
  deep neural networks","Background. Commonly, Deep Neural Networks (DNNs) generalize well on samples
drawn from a distribution similar to that of the training set. However, DNNs'
predictions are brittle and unreliable when the test samples are drawn from a
dissimilar distribution. This is a major concern for deployment in real-world
applications, where such behavior may come at a considerable cost, such as
industrial production lines, autonomous vehicles, or healthcare applications.
Contributions. We frame Out Of Distribution (OOD) detection in DNNs as a
statistical hypothesis testing problem. Tests generated within our proposed
framework combine evidence from the entire network. Unlike previous OOD
detection heuristics, this framework returns a $p$-value for each test sample.
It is guaranteed to maintain the Type I Error (T1E - incorrectly predicting OOD
for an actual in-distribution sample) for test data. Moreover, this allows to
combine several detectors while maintaining the T1E. Building on this
framework, we suggest a novel OOD procedure based on low-order statistics. Our
method achieves comparable or better results than state-of-the-art methods on
well-accepted OOD benchmarks, without retraining the network parameters or
assuming prior knowledge on the test distribution -- and at a fraction of the
computational cost.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.10398v3,2021-02-28T00:47:42Z,2021-02-20T17:35:23Z,All-Chalcogenide Programmable All-Optical Deep Neural Networks,"Deeplearning algorithms are revolutionising many aspects of modern life.
Typically, they are implemented in CMOS-based hardware with severely limited
memory access times and inefficient data-routing. All-optical neural networks
without any electro-optic conversions could alleviate these shortcomings.
However, an all-optical nonlinear activation function, which is a vital
building block for optical neural networks, needs to be developed efficiently
on-chip. Here, we introduce and demonstrate both optical synapse weighting and
all-optical nonlinear thresholding using two different effects in a
chalcogenide material photonic platform. We show how the structural phase
transitions in a wide-bandgap phase-change material enables storing the neural
network weights via non-volatile photonic memory, whilst resonant bond
destabilisation is used as a nonlinear activation threshold without changing
the material. These two different transitions within chalcogenides enable
programmable neural networks with near-zero static power consumption once
trained, in addition to picosecond delays performing inference tasks not
limited by wire charging that limit electrical circuits; for instance, we show
that nanosecond-order weight programming and near-instantaneous weight updates
enable accurate inference tasks within 20 picoseconds in a 3-layer all-optical
neural network. Optical neural networks that bypass electro-optic conversion
altogether hold promise for network-edge machine learning applications where
decision-making in real-time are critical, such as for autonomous vehicles or
navigation systems such as signal pre-processing of LIDAR systems.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.03326v1,2021-02-05T18:14:36Z,2021-02-05T18:14:36Z,"Fusion of neural networks, for LIDAR-based evidential road mapping","LIDAR sensors are usually used to provide autonomous vehicles with 3D
representations of their environment. In ideal conditions, geometrical models
could detect the road in LIDAR scans, at the cost of a manual tuning of
numerical constraints, and a lack of flexibility. We instead propose an
evidential pipeline, to accumulate road detection results obtained from neural
networks. First, we introduce RoadSeg, a new convolutional architecture that is
optimized for road detection in LIDAR scans. RoadSeg is used to classify
individual LIDAR points as either belonging to the road, or not. Yet, such
point-level classification results need to be converted into a dense
representation, that can be used by an autonomous vehicle. We thus secondly
present an evidential road mapping algorithm, that fuses consecutive road
detection results. We benefitted from a reinterpretation of logistic
classifiers, which can be seen as generating a collection of simple evidential
mass functions. An evidential grid map that depicts the road can then be
obtained, by projecting the classification results from RoadSeg into grid
cells, and by handling moving objects via conflict analysis. The system was
trained and evaluated on real-life data. A python implementation maintains a 10
Hz framerate. Since road labels were needed for training, a soft labelling
procedure, relying lane-level HD maps, was used to generate coarse training and
validation sets. An additional test set was manually labelled for evaluation
purposes. So as to reach satisfactory results, the system fuses road detection
results obtained from three variants of RoadSeg, processing different LIDAR
features.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.10463v2,2021-01-27T02:22:33Z,2021-01-25T22:34:06Z,"RTGPU: Real-Time GPU Scheduling of Hard Deadline Parallel Tasks with
  Fine-Grain Utilization","Many emerging cyber-physical systems, such as autonomous vehicles and robots,
rely heavily on artificial intelligence and machine learning algorithms to
perform important system operations. Since these highly parallel applications
are computationally intensive, they need to be accelerated by graphics
processing units (GPUs) to meet stringent timing constraints. However, despite
the wide adoption of GPUs, efficiently scheduling multiple GPU applications
while providing rigorous real-time guarantees remains a challenge. In this
paper, we propose RTGPU, which can schedule the execution of multiple GPU
applications in real-time to meet hard deadlines. Each GPU application can have
multiple CPU execution and memory copy segments, as well as GPU kernels. We
start with a model to explicitly account for the CPU and memory copy segments
of these applications. We then consider the GPU architecture in the development
of a precise timing model for the GPU kernels and leverage a technique known as
persistent threads to implement fine-grained kernel scheduling with improved
performance through interleaved execution. Next, we propose a general method
for scheduling parallel GPU applications in real time. Finally, to schedule
multiple parallel GPU applications, we propose a practical real-time scheduling
algorithm based on federated scheduling and grid search (for GPU kernel
segments) with uniprocessor fixed priority scheduling (for multiple CPU and
memory copy segments). Our approach provides superior schedulability compared
with previous work, and gives real-time guarantees to meet hard deadlines for
multiple GPU applications according to comprehensive validation and evaluation
on a real NVIDIA GTX1080Ti GPU system.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.06409v1,2021-01-16T09:00:34Z,2021-01-16T09:00:34Z,Shape Back-Projection In 3D Scenes,"In this work, we propose a novel framework shape back-projection for
computationally efficient point cloud processing in a probabilistic manner. The
primary component of the technique is shape histogram and a back-projection
procedure. The technique measures similarity between 3D surfaces, by analyzing
their geometrical properties. It is analogous to color back-projection which
measures similarity between images, simply by looking at their color
distributions. In the overall process, first, shape histogram of a sample
surface (e.g. planar) is computed, which captures the profile of surface
normals around a point in form of a probability distribution. Later, the
histogram is back-projected onto a test surface and a likelihood score is
obtained. The score depicts that how likely a point in the test surface behaves
similar to the sample surface, geometrically. Shape back-projection finds its
application in binary surface classification, high curvature edge detection in
unorganized point cloud, automated point cloud labeling for 3D-CNNs
(convolutional neural network) etc. The algorithm can also be used for
real-time robotic operations such as autonomous object picking in warehouse
automation, ground plane extraction for autonomous vehicles and can be deployed
easily on computationally limited platforms (UAVs).",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.06175v1,2021-01-15T15:36:22Z,2021-01-15T15:36:22Z,PaddleSeg: A High-Efficient Development Toolkit for Image Segmentation,"Image Segmentation plays an essential role in computer vision and image
processing with various applications from medical diagnosis to autonomous car
driving. A lot of segmentation algorithms have been proposed for addressing
specific problems. In recent years, the success of deep learning techniques has
tremendously influenced a wide range of computer vision areas, and the modern
approaches of image segmentation based on deep learning are becoming prevalent.
In this article, we introduce a high-efficient development toolkit for image
segmentation, named PaddleSeg. The toolkit aims to help both developers and
researchers in the whole process of designing segmentation models, training
models, optimizing performance and inference speed, and deploying models.
Currently, PaddleSeg supports around 20 popular segmentation models and more
than 50 pre-trained models from real-time and high-accuracy levels. With
modular components and backbone networks, users can easily build over one
hundred models for different requirements. Furthermore, we provide
comprehensive benchmarks and evaluations to show that these segmentation
algorithms trained on our toolkit have more competitive accuracy. Also, we
provide various real industrial applications and practical cases based on
PaddleSeg. All codes and examples of PaddleSeg are available at
https://github.com/PaddlePaddle/PaddleSeg.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.04319v1,2021-01-12T06:42:45Z,2021-01-12T06:42:45Z,"DeepiSign: Invisible Fragile Watermark to Protect the Integrityand
  Authenticity of CNN","Convolutional Neural Networks (CNNs) deployed in real-life applications such
as autonomous vehicles have shown to be vulnerable to manipulation attacks,
such as poisoning attacks and fine-tuning. Hence, it is essential to ensure the
integrity and authenticity of CNNs because compromised models can produce
incorrect outputs and behave maliciously. In this paper, we propose a
self-contained tamper-proofing method, called DeepiSign, to ensure the
integrity and authenticity of CNN models against such manipulation attacks.
DeepiSign applies the idea of fragile invisible watermarking to securely embed
a secret and its hash value into a CNN model. To verify the integrity and
authenticity of the model, we retrieve the secret from the model, compute the
hash value of the secret, and compare it with the embedded hash value. To
minimize the effects of the embedded secret on the CNN model, we use a
wavelet-based technique to transform weights into the frequency domain and
embed the secret into less significant coefficients. Our theoretical analysis
shows that DeepiSign can hide up to 1KB secret in each layer with minimal loss
of the model's accuracy. To evaluate the security and performance of DeepiSign,
we performed experiments on four pre-trained models (ResNet18, VGG16, AlexNet,
and MobileNet) using three datasets (MNIST, CIFAR-10, and Imagenet) against
three types of manipulation attacks (targeted input poisoning, output
poisoning, and fine-tuning). The results demonstrate that DeepiSign is
verifiable without degrading the classification accuracy, and robust against
representative CNN manipulation attacks.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.02780v1,2021-01-07T22:01:30Z,2021-01-07T22:01:30Z,"SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things
  and Cyber-Physical Systems based on Machine Learning","Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are
increasingly being deployed across multiple functionalities, ranging from
healthcare devices and wearables to critical infrastructures, e.g., nuclear
power plants, autonomous vehicles, smart cities, and smart homes. These devices
are inherently not secure across their comprehensive software, hardware, and
network stacks, thus presenting a large attack surface that can be exploited by
hackers. In this article, we present an innovative technique for detecting
unknown system vulnerabilities, managing these vulnerabilities, and improving
incident response when such vulnerabilities are exploited. The novelty of this
approach lies in extracting intelligence from known real-world CPS/IoT attacks,
representing them in the form of regular expressions, and employing machine
learning (ML) techniques on this ensemble of regular expressions to generate
new attack vectors and security vulnerabilities. Our results show that 10 new
attack vectors and 122 new vulnerability exploits can be successfully generated
that have the potential to exploit a CPS or an IoT ecosystem. The ML
methodology achieves an accuracy of 97.4% and enables us to predict these
attacks efficiently with an 87.2% reduction in the search space. We demonstrate
the application of our method to the hacking of the in-vehicle network of a
connected car. To defend against the known attacks and possible novel exploits,
we discuss a defense-in-depth mechanism for various classes of attacks and the
classification of data targeted by such attacks. This defense mechanism
optimizes the cost of security measures based on the sensitivity of the
protected resource, thus incentivizing its adoption in real-world CPS/IoT by
cybersecurity practitioners.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.15717v2,2021-11-07T05:23:47Z,2020-12-31T17:15:09Z,"FGraDA: A Dataset and Benchmark for Fine-Grained Domain Adaptation in
  Machine Translation","Previous research for adapting a general neural machine translation (NMT)
model into a specific domain usually neglects the diversity in translation
within the same domain, which is a core problem for domain adaptation in
real-world scenarios. One representative of such challenging scenarios is to
deploy a translation system for a conference with a specific topic, e.g.,
global warming or coronavirus, where there are usually extremely less resources
due to the limited schedule. To motivate wider investigation in such a
scenario, we present a real-world fine-grained domain adaptation task in
machine translation (FGraDA). The FGraDA dataset consists of Chinese-English
translation task for four sub-domains of information technology: autonomous
vehicles, AI education, real-time networks, and smart phone. Each sub-domain is
equipped with a development set and test set for evaluation purposes. To be
closer to reality, FGraDA does not employ any in-domain bilingual training data
but provides bilingual dictionaries and wiki knowledge base, which can be
easier obtained within a short time. We benchmark the fine-grained domain
adaptation task and present in-depth analyses showing that there are still
challenging problems to further improve the performance with heterogeneous
resources.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.10706v4,2021-07-30T13:36:36Z,2020-12-19T14:53:56Z,Siamese Anchor Proposal Network for High-Speed Aerial Tracking,"In the domain of visual tracking, most deep learning-based trackers highlight
the accuracy but casting aside efficiency. Therefore, their real-world
deployment on mobile platforms like the unmanned aerial vehicle (UAV) is
impeded. In this work, a novel two-stage Siamese network-based method is
proposed for aerial tracking, \textit{i.e.}, stage-1 for high-quality anchor
proposal generation, stage-2 for refining the anchor proposal. Different from
anchor-based methods with numerous pre-defined fixed-sized anchors, our
no-prior method can 1) increase the robustness and generalization to different
objects with various sizes, especially to small, occluded, and fast-moving
objects, under complex scenarios in light of the adaptive anchor generation, 2)
make calculation feasible due to the substantial decrease of anchor numbers. In
addition, compared to anchor-free methods, our framework has better performance
owing to refinement at stage-2. Comprehensive experiments on three benchmarks
have proven the superior performance of our approach, with a speed of around
200 frames/s.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.06992v1,2020-12-13T07:28:18Z,2020-12-13T07:28:18Z,"Edge Intelligence for Autonomous Driving in 6G Wireless System: Design
  Challenges and Solutions","In a level-5 autonomous driving system, the autonomous driving vehicles (AVs)
are expected to sense the surroundings via analyzing a large amount of data
captured by a variety of onboard sensors in near-real-time. As a result,
enormous computing costs will be introduced to the AVs for processing the tasks
with the deployed machine learning (ML) model, while the inference accuracy may
not be guaranteed. In this context, the advent of edge intelligence (EI) and
sixth-generation (6G) wireless networking are expected to pave the way to more
reliable and safer autonomous driving by providing multi-access edge computing
(MEC) together with ML to AVs in close proximity. To realize this goal, we
propose a two-tier EI-empowered autonomous driving framework. In the
autonomous-vehicles tier, the autonomous vehicles are deployed with the shallow
layers by splitting the trained deep neural network model. In the
edge-intelligence tier, an edge server is implemented with the remaining layers
(also deep layers) and an appropriately trained multi-task learning (MTL)
model. In particular, obtaining the optimal offloading strategy (including the
binary offloading decision and the computational resources allocation) can be
formulated as a mixed-integer nonlinear programming (MINLP) problem, which is
solved via MTL in near-real-time with high accuracy. On another note, an
edge-vehicle joint inference is proposed through neural network segmentation to
achieve efficient online inference with data privacy-preserving and less
communication delay. Experiments demonstrate the effectiveness of the proposed
framework, and open research topics are finally listed.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.05410v1,2020-12-10T02:08:47Z,2020-12-10T02:08:47Z,Artificial Intelligence at the Edge,"The Internet of Things (IoT) and edge computing applications aim to support a
variety of societal needs, including the global pandemic situation that the
entire world is currently experiencing and responses to natural disasters.
  The need for real-time interactive applications such as immersive video
conferencing, augmented/virtual reality, and autonomous vehicles, in education,
healthcare, disaster recovery and other domains, has never been higher. At the
same time, there have been recent technological breakthroughs in highly
relevant fields such as artificial intelligence (AI)/machine learning (ML),
advanced communication systems (5G and beyond), privacy-preserving
computations, and hardware accelerators. 5G mobile communication networks
increase communication capacity, reduce transmission latency and error, and
save energy -- capabilities that are essential for new applications. The
envisioned future 6G technology will integrate many more technologies,
including for example visible light communication, to support groundbreaking
applications, such as holographic communications and high precision
manufacturing. Many of these applications require computations and analytics
close to application end-points: that is, at the edge of the network, rather
than in a centralized cloud. AI techniques applied at the edge have tremendous
potential both to power new applications and to need more efficient operation
of edge infrastructure. However, it is critical to understand where to deploy
AI systems within complex ecosystems consisting of advanced applications and
the specific real-time requirements towards AI systems.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.07699v1,2020-11-16T02:56:13Z,2020-11-16T02:56:13Z,"Efficient falsification approach for autonomous vehicle validation using
  a parameter optimisation technique based on reinforcement learning","The widescale deployment of Autonomous Vehicles (AV) appears to be imminent
despite many safety challenges that are yet to be resolved. It is well-known
that there are no universally agreed Verification and Validation (VV)
methodologies guarantee absolute safety, which is crucial for the acceptance of
this technology. The uncertainties in the behaviour of the traffic participants
and the dynamic world cause stochastic reactions in advanced autonomous
systems. The addition of ML algorithms and probabilistic techniques adds
significant complexity to the process for real-world testing when compared to
traditional methods. Most research in this area focuses on generating
challenging concrete scenarios or test cases to evaluate the system performance
by looking at the frequency distribution of extracted parameters as collected
from the real-world data. These approaches generally employ Monte-Carlo
simulation and importance sampling to generate critical cases. This paper
presents an efficient falsification method to evaluate the System Under Test.
The approach is based on a parameter optimisation problem to search for
challenging scenarios. The optimisation process aims at finding the challenging
case that has maximum return. The method applies policy-gradient reinforcement
learning algorithm to enable the learning. The riskiness of the scenario is
measured by the well established RSS safety metric, euclidean distance, and
instance of a collision. We demonstrate that by using the proposed method, we
can more efficiently search for challenging scenarios which could cause the
system to fail in order to satisfy the safety requirements.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.01840v1,2020-11-03T16:50:37Z,2020-11-03T16:50:37Z,"Distributional Reinforcement Learning for mmWave Communications with
  Intelligent Reflectors on a UAV","In this paper, a novel communication framework that uses an unmanned aerial
vehicle (UAV)-carried intelligent reflector (IR) is proposed to enhance
multi-user downlink transmissions over millimeter wave (mmWave) frequencies. In
order to maximize the downlink sum-rate, the optimal precoding matrix (at the
base station) and reflection coefficient (at the IR) are jointly derived. Next,
to address the uncertainty of mmWave channels and maintain line-of-sight links
in a real-time manner, a distributional reinforcement learning approach, based
on quantile regression optimization, is proposed to learn the propagation
environment of mmWave communications, and, then, optimize the location of the
UAV-IR so as to maximize the long-term downlink communication capacity.
Simulation results show that the proposed learning-based deployment of the
UAV-IR yields a significant advantage, compared to a non-learning UAV-IR, a
static IR, and a direct transmission schemes, in terms of the average data rate
and the achievable line-of-sight probability of downlink mmWave communications.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.06626v2,2020-12-29T01:09:57Z,2020-10-13T18:37:38Z,"On Deep Learning Techniques to Boost Monocular Depth Estimation for
  Autonomous Navigation","Inferring the depth of images is a fundamental inverse problem within the
field of Computer Vision since depth information is obtained through 2D images,
which can be generated from infinite possibilities of observed real scenes.
Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore
structural features and spatial image information, Single Image Depth
Estimation (SIDE) is often highlighted in scopes of scientific and
technological innovation, as this concept provides advantages related to its
low implementation cost and robustness to environmental conditions. In the
context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by
producing high-quality depth maps, which are essential during the autonomous
navigation process in different locations. However, such networks are usually
supervised by sparse and noisy depth data, from Light Detection and Ranging
(LiDAR) laser scans, and are carried out at high computational cost, requiring
high-performance Graphic Processing Units (GPUs). Therefore, we propose a new
lightweight and fast supervised CNN architecture combined with novel feature
extraction models which are designed for real-world autonomous navigation. We
also introduce an efficient surface normals module, jointly with a simple
geometric 2.5D loss function, to solve SIDE problems. We also innovate by
incorporating multiple Deep Learning techniques, such as the use of
densification algorithms and additional semantic, surface normals and depth
information to train our framework. The method introduced in this work focuses
on robotic applications in indoor and outdoor environments and its results are
evaluated on the competitive and publicly available NYU Depth V2 and KITTI
Depth datasets.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.02663v1,2020-10-06T12:23:05Z,2020-10-06T12:23:05Z,"Heterogeneous Multi-Agent Reinforcement Learning for Unknown Environment
  Mapping","Reinforcement learning in heterogeneous multi-agent scenarios is important
for real-world applications but presents challenges beyond those seen in
homogeneous settings and simple benchmarks. In this work, we present an
actor-critic algorithm that allows a team of heterogeneous agents to learn
decentralized control policies for covering an unknown environment. This task
is of interest to national security and emergency response organizations that
would like to enhance situational awareness in hazardous areas by deploying
teams of unmanned aerial vehicles. To solve this multi-agent coverage path
planning problem in unknown environments, we augment a multi-agent actor-critic
architecture with a new state encoding structure and triplet learning loss to
support heterogeneous agent learning. We developed a simulation environment
that includes real-world environmental factors such as turbulence, delayed
communication, and agent loss, to train teams of agents as well as probe their
robustness and flexibility to such disturbances.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.14349v3,2020-12-07T20:08:44Z,2020-09-30T00:01:54Z,"Computing Systems for Autonomous Driving: State-of-the-Art and
  Challenges","The recent proliferation of computing technologies (e.g., sensors, computer
vision, machine learning, and hardware acceleration), and the broad deployment
of communication mechanisms (e.g., DSRC, C-V2X, 5G) have pushed the horizon of
autonomous driving, which automates the decision and control of vehicles by
leveraging the perception results based on multiple sensors. The key to the
success of these autonomous systems is making a reliable decision in real-time
fashion. However, accidents and fatalities caused by early deployed autonomous
vehicles arise from time to time. The real traffic environment is too
complicated for current autonomous driving computing systems to understand and
handle. In this paper, we present state-of-the-art computing systems for
autonomous driving, including seven performance metrics and nine key
technologies, followed by twelve challenges to realize autonomous driving. We
hope this paper will gain attention from both the computing and automotive
communities and inspire more research in this direction.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.11722v1,2020-09-23T09:23:29Z,2020-09-23T09:23:29Z,"Cloud2Edge Elastic AI Framework for Prototyping and Deployment of AI
  Inference Engines in Autonomous Vehicles","Self-driving cars and autonomous vehicles are revolutionizing the automotive
sector, shaping the future of mobility altogether. Although the integration of
novel technologies such as Artificial Intelligence (AI) and Cloud/Edge
computing provides golden opportunities to improve autonomous driving
applications, there is the need to modernize accordingly the whole prototyping
and deployment cycle of AI components. This paper proposes a novel framework
for developing so-called AI Inference Engines for autonomous driving
applications based on deep learning modules, where training tasks are deployed
elastically over both Cloud and Edge resources, with the purpose of reducing
the required network bandwidth, as well as mitigating privacy issues. Based on
our proposed data driven V-Model, we introduce a simple yet elegant solution
for the AI components development cycle, where prototyping takes place in the
cloud according to the Software-in-the-Loop (SiL) paradigm, while deployment
and evaluation on the target ECUs (Electronic Control Units) is performed as
Hardware-in-the-Loop (HiL) testing. The effectiveness of the proposed framework
is demonstrated using two real-world use-cases of AI inference engines for
autonomous vehicles, that is environment perception and most probable path
prediction.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.03268v2,2020-10-10T14:16:31Z,2020-09-07T17:34:01Z,"Driving Tasks Transfer in Deep Reinforcement Learning for
  Decision-making of Autonomous Vehicles","Knowledge transfer is a promising concept to achieve real-time
decision-making for autonomous vehicles. This paper constructs a transfer deep
reinforcement learning framework to transform the driving tasks in
inter-section environments. The driving missions at the un-signalized
intersection are cast into a left turn, right turn, and running straight for
automated vehicles. The goal of the autonomous ego vehicle (AEV) is to drive
through the intersection situation efficiently and safely. This objective
promotes the studied vehicle to increase its speed and avoid crashing other
vehicles. The decision-making pol-icy learned from one driving task is
transferred and evaluated in another driving mission. Simulation results reveal
that the decision-making strategies related to similar tasks are transferable.
It indicates that the presented control framework could reduce the time
consumption and realize online implementation.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.06189v1,2020-08-14T04:35:10Z,2020-08-14T04:35:10Z,"An Improved Deep Convolutional Neural Network-Based Autonomous Road
  Inspection Scheme Using Unmanned Aerial Vehicles","Advancements in artificial intelligence (AI) gives a great opportunity to
develop an autonomous devices. The contribution of this work is an improved
convolutional neural network (CNN) model and its implementation for the
detection of road cracks, potholes, and yellow lane in the road. The purpose of
yellow lane detection and tracking is to realize autonomous navigation of
unmanned aerial vehicle (UAV) by following yellow lane while detecting and
reporting the road cracks and potholes to the server through WIFI or 5G medium.
The fabrication of own data set is a hectic and time-consuming task. The data
set is created, labeled and trained using default and an improved model. The
performance of both these models is benchmarked with respect to accuracy, mean
average precision (mAP) and detection time. In the testing phase, it was
observed that the performance of the improved model is better in respect of
accuracy and mAP. The improved model is implemented in UAV using the robot
operating system for the autonomous detection of potholes and cracks in roads
via UAV front camera vision in real-time.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.00706v1,2020-08-03T08:19:57Z,2020-08-03T08:19:57Z,LiDAR point-cloud processing based on projection methods: a comparison,"An accurate and rapid-response perception system is fundamental for
autonomous vehicles to operate safely. 3D object detection methods handle point
clouds given by LiDAR sensors to provide accurate depth and position
information for each detection, together with its dimensions and
classification. The information is then used to track vehicles and other
obstacles in the surroundings of the autonomous vehicle, and also to feed
control units that guarantee collision avoidance and motion planning. Nowadays,
object detection systems can be divided into two main categories. The first
ones are the geometric based, which retrieve the obstacles using geometric and
morphological operations on the 3D points. The seconds are the deep
learning-based, which process the 3D points, or an elaboration of the 3D
point-cloud, with deep learning techniques to retrieve a set of obstacles. This
paper presents a comparison between those two approaches, presenting one
implementation of each class on a real autonomous vehicle. Accuracy of the
estimates of the algorithms has been evaluated with experimental tests carried
in the Monza ENI circuit. The position of the ego vehicle and the obstacle is
given by GPS sensors with RTK correction, which guarantees an accurate ground
truth for the comparison. Both algorithms have been implemented on ROS and run
on a consumer laptop.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.08501v1,2020-07-16T17:53:02Z,2020-07-16T17:53:02Z,Accelerating 3D Deep Learning with PyTorch3D,"Deep learning has significantly improved 2D image recognition. Extending into
3D may advance many new applications including autonomous vehicles, virtual and
augmented reality, authoring 3D content, and even improving 2D recognition.
However despite growing interest, 3D deep learning remains relatively
underexplored. We believe that some of this disparity is due to the engineering
challenges involved in 3D deep learning, such as efficiently processing
heterogeneous data and reframing graphics operations to be differentiable. We
address these challenges by introducing PyTorch3D, a library of modular,
efficient, and differentiable operators for 3D deep learning. It includes a
fast, modular differentiable renderer for meshes and point clouds, enabling
analysis-by-synthesis approaches. Compared with other differentiable renderers,
PyTorch3D is more modular and efficient, allowing users to more easily extend
it while also gracefully scaling to large meshes and images. We compare the
PyTorch3D operators and renderer with other implementations and demonstrate
significant speed and memory improvements. We also use PyTorch3D to improve the
state-of-the-art for unsupervised 3D mesh and point cloud prediction from 2D
images on ShapeNet. PyTorch3D is open-source and we hope it will help
accelerate research in 3D deep learning.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.05828v1,2020-07-11T18:41:47Z,2020-07-11T18:41:47Z,Understanding Object Detection Through An Adversarial Lens,"Deep neural networks based object detection models have revolutionized
computer vision and fueled the development of a wide range of visual
recognition applications. However, recent studies have revealed that deep
object detectors can be compromised under adversarial attacks, causing a victim
detector to detect no object, fake objects, or mislabeled objects. With object
detection being used pervasively in many security-critical applications, such
as autonomous vehicles and smart cities, we argue that a holistic approach for
an in-depth understanding of adversarial attacks and vulnerabilities of deep
object detection systems is of utmost importance for the research community to
develop robust defense mechanisms. This paper presents a framework for
analyzing and evaluating vulnerabilities of the state-of-the-art object
detectors under an adversarial lens, aiming to analyze and demystify the attack
strategies, adverse effects, and costs, as well as the cross-model and
cross-resolution transferability of attacks. Using a set of quantitative
metrics, extensive experiments are performed on six representative deep object
detectors from three popular families (YOLOv3, SSD, and Faster R-CNN) with two
benchmark datasets (PASCAL VOC and MS COCO). We demonstrate that the proposed
framework can serve as a methodical benchmark for analyzing adversarial
behaviors and risks in real-time object detection systems. We conjecture that
this framework can also serve as a tool to assess the security risks and the
adversarial robustness of deep object detectors to be deployed in real-world
applications.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.15175v1,2020-06-26T19:06:32Z,2020-06-26T19:06:32Z,Application of Neuroevolution in Autonomous Cars,"With the onset of Electric vehicles, and them becoming more and more popular,
autonomous cars are the future in the travel/driving experience. The barrier to
reaching level 5 autonomy is the difficulty in the collection of data that
incorporates good driving habits and the lack thereof. The problem with current
implementations of self-driving cars is the need for massively large datasets
and the need to evaluate the driving in the dataset. We propose a system that
requires no data for its training. An evolutionary model would have the
capability to optimize itself towards the fitness function. We have implemented
Neuroevolution, a form of genetic algorithm, to train/evolve self-driving cars
in a simulated virtual environment with the help of Unreal Engine 4, which
utilizes Nvidia's PhysX Physics Engine to portray real-world vehicle dynamics
accurately. We were able to observe the serendipitous nature of evolution and
have exploited it to reach our optimal solution. We also demonstrate the ease
in generalizing attributes brought about by genetic algorithms and how they may
be used as a boilerplate upon which other machine learning techniques may be
used to improve the overall driving experience.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.03463v2,2021-05-12T14:17:37Z,2020-06-05T14:10:09Z,Sponge Examples: Energy-Latency Attacks on Neural Networks,"The high energy costs of neural network training and inference led to the use
of acceleration hardware such as GPUs and TPUs. While this enabled us to train
large-scale neural networks in datacenters and deploy them on edge devices, the
focus so far is on average-case performance. In this work, we introduce a novel
threat vector against neural networks whose energy consumption or decision
latency are critical. We show how adversaries can exploit carefully crafted
$\boldsymbol{sponge}~\boldsymbol{examples}$, which are inputs designed to
maximise energy consumption and latency.
  We mount two variants of this attack on established vision and language
models, increasing energy consumption by a factor of 10 to 200. Our attacks can
also be used to delay decisions where a network has critical real-time
performance, such as in perception for autonomous vehicles. We demonstrate the
portability of our malicious inputs across CPUs and a variety of hardware
accelerator chips including GPUs, and an ASIC simulator. We conclude by
proposing a defense strategy which mitigates our attack by shifting the
analysis of energy consumption in hardware from an average-case to a worst-case
perspective.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.00049v1,2020-05-29T19:42:25Z,2020-05-29T19:42:25Z,PointNet on FPGA for Real-Time LiDAR Point Cloud Processing,"LiDAR sensors have been widely used in many autonomous vehicle modalities,
such as perception, mapping, and localization. This paper presents an
FPGA-based deep learning platform for real-time point cloud processing targeted
on autonomous vehicles. The software driver for the Velodyne LiDAR sensor is
modified and moved into the on-chip processor system, while the programmable
logic is designed as a customized hardware accelerator. As the state-of-art
deep learning algorithm for point cloud processing, PointNet is successfully
implemented on the proposed FPGA platform. Targeted on a Xilinx Zynq
UltraScale+ MPSoC ZCU104 development board, the FPGA implementations of
PointNet achieve the computing performance of 182.1 GOPS and 280.0 GOPS for
classification and segmentation respectively. The proposed design can support
an input up to 4096 points per frame. The processing time is 19.8 ms for
classification and 34.6 ms for segmentation, which meets the real-time
requirement for most of the existing LiDAR sensors.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.13976v1,2020-05-22T19:00:38Z,2020-05-22T19:00:38Z,"Towards Automated Safety Coverage and Testing for Autonomous Vehicles
  with Reinforcement Learning","The kind of closed-loop verification likely to be required for autonomous
vehicle (AV) safety testing is beyond the reach of traditional test
methodologies and discrete verification. Validation puts the autonomous vehicle
system to the test in scenarios or situations that the system would likely
encounter in everyday driving after its release. These scenarios can either be
controlled directly in a physical (closed-course proving ground) or virtual
(simulation of predefined scenarios) environment, or they can arise
spontaneously during operation in the real world (open-road testing or
simulation of randomly generated scenarios).
  In AV testing, simulation serves primarily two purposes: to assist the
development of a robust autonomous vehicle and to test and validate the AV
before release. A challenge arises from the sheer number of scenario variations
that can be constructed from each of the above sources due to the high number
of variables involved (most of which are continuous). Even with continuous
variables discretized, the possible number of combinations becomes practically
infeasible to test. To overcome this challenge we propose using reinforcement
learning (RL) to generate failure examples and unexpected traffic situations
for the AV software implementation. Although reinforcement learning algorithms
have achieved notable results in games and some robotic manipulations, this
technique has not been widely scaled up to the more challenging real world
applications like autonomous driving.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.07460v1,2020-05-15T10:34:51Z,2020-05-15T10:34:51Z,"Collective Risk Minimization via a Bayesian Model for Statistical
  Software Testing","In the last four years, the number of distinct autonomous vehicles platforms
deployed in the streets of California increased 6-fold, while the reported
accidents increased 12-fold. This can become a trend with no signs of subsiding
as it is fueled by a constant stream of innovations in hardware sensors and
machine learning software. Meanwhile, if we expect the public and regulators to
trust the autonomous vehicle platforms, we need to find better ways to solve
the problem of adding technological complexity without increasing the risk of
accidents. We studied this problem from the perspective of reliability
engineering in which a given risk of an accident has severity and probability
of occurring. Timely information on accidents is important for engineers to
anticipate and reuse previous failures to approximate the risk of accidents in
a new city. However, this is challenging in the context of autonomous vehicles
because of the sparse nature of data on the operational scenarios (driving
trajectories in a new city). Our approach was to mitigate data sparsity by
reducing the state space through monitoring of multiple-vehicles operations. We
then minimized the risk of accidents by determining proper allocation of tests
for each equivalence class. Our contributions comprise (1) a set of strategies
to monitor the operational data of multiple autonomous vehicles, (2) a Bayesian
model that estimates changes in the risk of accidents, and (3) a feedback
control-loop that minimizes these risks by reallocating test effort. Our
results are promising in the sense that we were able to measure and control
risk for a diversity of changes in the operational scenarios. We evaluated our
models with data from two real cities with distinct traffic patterns and made
the data available for the community.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.07424v1,2020-05-15T09:05:17Z,2020-05-15T09:05:17Z,"Exploring the Capabilities and Limits of 3D Monocular Object Detection
  -- A Study on Simulation and Real World Data","3D object detection based on monocular camera data is a key enabler for
autonomous driving. The task however, is ill-posed due to lack of depth
information in 2D images. Recent deep learning methods show promising results
to recover depth information from single images by learning priors about the
environment. Several competing strategies tackle this problem. In addition to
the network design, the major difference of these competing approaches lies in
using a supervised or self-supervised optimization loss function, which require
different data and ground truth information. In this paper, we evaluate the
performance of a 3D object detection pipeline which is parameterizable with
different depth estimation configurations. We implement a simple distance
calculation approach based on camera intrinsics and 2D bounding box size, a
self-supervised, and a supervised learning approach for depth estimation.
  Ground truth depth information cannot be recorded reliable in real world
scenarios. This shifts our training focus to simulation data. In simulation,
labeling and ground truth generation can be automatized. We evaluate the
detection pipeline on simulator data and a real world sequence from an
autonomous vehicle on a race track. The benefit of simulation training to real
world application is investigated. Advantages and drawbacks of the different
depth estimation strategies are discussed.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.06892v1,2020-05-14T11:54:04Z,2020-05-14T11:54:04Z,ZynqNet: An FPGA-Accelerated Embedded Convolutional Neural Network,"Image Understanding is becoming a vital feature in ever more applications
ranging from medical diagnostics to autonomous vehicles. Many applications
demand for embedded solutions that integrate into existing systems with tight
real-time and power constraints. Convolutional Neural Networks (CNNs) presently
achieve record-breaking accuracies in all image understanding benchmarks, but
have a very high computational complexity. Embedded CNNs thus call for small
and efficient, yet very powerful computing platforms. This master thesis
explores the potential of FPGA-based CNN acceleration and demonstrates a fully
functional proof-of-concept CNN implementation on a Zynq System-on-Chip. The
ZynqNet Embedded CNN is designed for image classification on ImageNet and
consists of ZynqNet CNN, an optimized and customized CNN topology, and the
ZynqNet FPGA Accelerator, an FPGA-based architecture for its evaluation.
ZynqNet CNN is a highly efficient CNN topology. Detailed analysis and
optimization of prior topologies using the custom-designed Netscope CNN
Analyzer have enabled a CNN with 84.5% top-5 accuracy at a computational
complexity of only 530 million multiplyaccumulate operations. The topology is
highly regular and consists exclusively of convolutional layers, ReLU
nonlinearities and one global pooling layer. The CNN fits ideally onto the FPGA
accelerator. The ZynqNet FPGA Accelerator allows an efficient evaluation of
ZynqNet CNN. It accelerates the full network based on a nested-loop algorithm
which minimizes the number of arithmetic operations and memory accesses. The
FPGA accelerator has been synthesized using High-Level Synthesis for the Xilinx
Zynq XC-7Z045, and reaches a clock frequency of 200MHz with a device
utilization of 80% to 90 %.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.01250v6,2021-06-21T18:21:58Z,2020-05-09T09:41:46Z,RUHSNet: 3D Object Detection Using Lidar Data in Real Time,"In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects in
point cloud data. We compare the results with different backbone architectures
including the standard ones like VGG, ResNet, Inception with our backbone. Also
we present the optimization and ablation studies including designing an
efficient anchor. We use the Kitti 3D Birds Eye View dataset for benchmarking
and validating our results. Our work surpasses the state of the art in this
domain both in terms of average precision and speed running at > 30 FPS. This
makes it a feasible option to be deployed in real time applications including
self driving cars.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.02979v3,2021-10-14T16:40:00Z,2020-05-06T17:31:51Z,"A Survey of Algorithms for Black-Box Safety Validation of Cyber-Physical
  Systems","Autonomous cyber-physical systems (CPS) can improve safety and efficiency for
safety-critical applications, but require rigorous testing before deployment.
The complexity of these systems often precludes the use of formal verification
and real-world testing can be too dangerous during development. Therefore,
simulation-based techniques have been developed that treat the system under
test as a black box operating in a simulated environment. Safety validation
tasks include finding disturbances in the environment that cause the system to
fail (falsification), finding the most-likely failure, and estimating the
probability that the system fails. Motivated by the prevalence of
safety-critical artificial intelligence, this work provides a survey of
state-of-the-art safety validation techniques for CPS with a focus on applied
algorithms and their modifications for the safety validation problem. We
present and discuss algorithms in the domains of optimization, path planning,
reinforcement learning, and importance sampling. Problem decomposition
techniques are presented to help scale algorithms to large state spaces, which
are common for CPS. A brief overview of safety-critical applications is given,
including autonomous vehicles and aircraft collision avoidance systems.
Finally, we present a survey of existing academic and commercially available
safety validation tools.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.13866v1,2020-04-28T21:56:10Z,2020-04-28T21:56:10Z,Deflating Dataset Bias Using Synthetic Data Augmentation,"Deep Learning has seen an unprecedented increase in vision applications since
the publication of large-scale object recognition datasets and introduction of
scalable compute hardware. State-of-the-art methods for most vision tasks for
Autonomous Vehicles (AVs) rely on supervised learning and often fail to
generalize to domain shifts and/or outliers. Dataset diversity is thus key to
successful real-world deployment. No matter how big the size of the dataset,
capturing long tails of the distribution pertaining to task-specific
environmental factors is impractical. The goal of this paper is to investigate
the use of targeted synthetic data augmentation - combining the benefits of
gaming engine simulations and sim2real style transfer techniques - for filling
gaps in real datasets for vision tasks. Empirical studies on three different
computer vision tasks of practical use to AVs - parking slot detection, lane
detection and monocular depth estimation - consistently show that having
synthetic data in the training mix provides a significant boost in
cross-dataset generalization performance as compared to training on real data
only, for the same size of the training set.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.06154v1,2020-04-13T18:53:12Z,2020-04-13T18:53:12Z,"An Efficient UAV-based Artificial Intelligence Framework for Real-Time
  Visual Tasks","Modern Unmanned Aerial Vehicles equipped with state of the art artificial
intelligence (AI) technologies are opening to a wide plethora of novel and
interesting applications. While this field received a strong impact from the
recent AI breakthroughs, most of the provided solutions either entirely rely on
commercial software or provide a weak integration interface which denies the
development of additional techniques. This leads us to propose a novel and
efficient framework for the UAV-AI joint technology. Intelligent UAV systems
encounter complex challenges to be tackled without human control. One of these
complex challenges is to be able to carry out computer vision tasks in
real-time use cases. In this paper we focus on this challenge and introduce a
multi-layer AI (MLAI) framework to allow easy integration of ad-hoc
visual-based AI applications. To show its features and its advantages, we
implemented and evaluated different modern visual-based deep learning models
for object detection, target tracking and target handover.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.00336v2,2020-05-06T18:55:28Z,2020-04-03T22:46:34Z,"On-board Deep-learning-based Unmanned Aerial Vehicle Fault Cause
  Detection and Identification","With the increase in use of Unmanned Aerial Vehicles (UAVs)/drones, it is
important to detect and identify causes of failure in real time for proper
recovery from a potential crash-like scenario or post incident forensics
analysis. The cause of crash could be either a fault in the sensor/actuator
system, a physical damage/attack, or a cyber attack on the drone's software. In
this paper, we propose novel architectures based on deep Convolutional and Long
Short-Term Memory Neural Networks (CNNs and LSTMs) to detect (via Autoencoder)
and classify drone mis-operations based on sensor data. The proposed
architectures are able to learn high-level features automatically from the raw
sensor data and learn the spatial and temporal dynamics in the sensor data. We
validate the proposed deep-learning architectures via simulations and
experiments on a real drone. Empirical results show that our solution is able
to detect with over 90% accuracy and classify various types of drone
mis-operations (with about 99% accuracy (simulation data) and upto 88% accuracy
(experimental data)).",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.03576v1,2020-03-07T13:05:03Z,2020-03-07T13:05:03Z,"A machine learning environment for evaluating autonomous driving
  software","Autonomous vehicles need safe development and testing environments. Many
traffic scenarios are such that they cannot be tested in the real world. We see
hybrid photorealistic simulation as a viable tool for developing AI (artificial
intelligence) software for autonomous driving. We present a machine learning
environment for detecting autonomous vehicle corner case behavior. Our
environment is based on connecting the CARLA simulation software to TensorFlow
machine learning framework and custom AI client software. The AI client
software receives data from a simulated world via virtual sensors and
transforms the data into information using machine learning models. The AI
clients control vehicles in the simulated world. Our environment monitors the
state assumed by the vehicle AIs to the ground truth state derived from the
simulation model. Our system can search for corner cases where the vehicle AI
is unable to correctly understand the situation. In our paper, we present the
overall hybrid simulator architecture and compare different configurations. We
present performance measurements from real setups, and outline the main
parameters affecting the hybrid simulator performance.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.01886v1,2020-03-04T04:35:22Z,2020-03-04T04:35:22Z,"Efficient statistical validation with edge cases to evaluate Highly
  Automated Vehicles","The widescale deployment of Autonomous Vehicles (AV) seems to be imminent
despite many safety challenges that are yet to be resolved. It is well known
that there are no universally agreed Verification and Validation (VV)
methodologies to guarantee absolute safety, which is crucial for the acceptance
of this technology. Existing standards focus on deterministic processes where
the validation requires only a set of test cases that cover the requirements.
Modern autonomous vehicles will undoubtedly include machine learning and
probabilistic techniques that require a much more comprehensive testing regime
due to the non-deterministic nature of the operating design domain. A rigourous
statistical validation process is an essential component required to address
this challenge. Most research in this area focuses on evaluating system
performance in large scale real-world data gathering exercises (number of miles
travelled), or randomised test scenarios in simulation.
  This paper presents a new approach to compute the statistical characteristics
of a system's behaviour by biasing automatically generated test cases towards
the worst case scenarios, identifying potential unsafe edge cases.We use
reinforcement learning (RL) to learn the behaviours of simulated actors that
cause unsafe behaviour measured by the well established RSS safety metric. We
demonstrate that by using the method we can more efficiently validate a system
using a smaller number of test cases by focusing the simulation towards the
worst case scenario, generating edge cases that correspond to unsafe
situations.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.04816v1,2020-02-21T07:29:15Z,2020-02-21T07:29:15Z,"Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep
  Reinforcement Learning Approach","In this paper, we design a navigation policy for multiple unmanned aerial
vehicles (UAVs) where mobile base stations (BSs) are deployed to improve the
data freshness and connectivity to the Internet of Things (IoT) devices. First,
we formulate an energy-efficient trajectory optimization problem in which the
objective is to maximize the energy efficiency by optimizing the UAV-BS
trajectory policy. We also incorporate different contextual information such as
energy and age of information (AoI) constraints to ensure the data freshness at
the ground BS. Second, we propose an agile deep reinforcement learning with
experience replay model to solve the formulated problem concerning the
contextual constraints for the UAV-BS navigation. Moreover, the proposed
approach is well-suited for solving the problem, since the state space of the
problem is extremely large and finding the best trajectory policy with useful
contextual features is too complex for the UAV-BSs. By applying the proposed
trained model, an effective real-time trajectory policy for the UAV-BSs
captures the observable network states over time. Finally, the simulation
results illustrate the proposed approach is 3.6% and 3.13% more energy
efficient than those of the greedy and baseline deep Q Network (DQN)
approaches.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.00831v1,2020-02-03T15:39:56Z,2020-02-03T15:39:56Z,An Actor-Critic-Based UAV-BSs Deployment Method for Dynamic Environments,"In this paper, the real-time deployment of unmanned aerial vehicles (UAVs) as
flying base stations (BSs) for optimizing the throughput of mobile users is
investigated for UAV networks. This problem is formulated as a time-varying
mixed-integer non-convex programming (MINP) problem, which is challenging to
find an optimal solution in a short time with conventional optimization
techniques. Hence, we propose an actor-critic-based (AC-based) deep
reinforcement learning (DRL) method to find near-optimal UAV positions at every
moment. In the proposed method, the process searching for the solution
iteratively at a particular moment is modeled as a Markov decision process
(MDP). To handle infinite state and action spaces and improve the robustness of
the decision process, two powerful neural networks (NNs) are configured to
evaluate the UAV position adjustments and make decisions, respectively.
Compared with the heuristic algorithm, sequential least-squares programming and
fixed UAVs methods, simulation results have shown that the proposed method
outperforms these three benchmarks in terms of the throughput at every moment
in UAV networks.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.11610v1,2020-01-30T23:49:15Z,2020-01-30T23:49:15Z,"UAV Autonomous Localization using Macro-Features Matching with a CAD
  Model","Research in the field of autonomous Unmanned Aerial Vehicles (UAVs) has
significantly advanced in recent years, mainly due to their relevance in a
large variety of commercial, industrial, and military applications. However,
UAV navigation in GPS-denied environments continues to be a challenging problem
that has been tackled in recent research through sensor-based approaches. This
paper presents a novel offline, portable, real-time in-door UAV localization
technique that relies on macro-feature detection and matching. The proposed
system leverages the support of machine learning, traditional computer vision
techniques, and pre-existing knowledge of the environment. The main
contribution of this work is the real-time creation of a macro-feature
description vector from the UAV captured images which are simultaneously
matched with an offline pre-existing vector from a Computer-Aided Design (CAD)
model. This results in a quick UAV localization within the CAD model. The
effectiveness and accuracy of the proposed system were evaluated through
simulations and experimental prototype implementation. Final results reveal the
algorithm's low computational burden as well as its ease of deployment in
GPS-denied environments.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.07769v3,2020-02-16T22:19:32Z,2020-01-21T20:41:27Z,"Massif: Interactive Interpretation of Adversarial Attacks on Deep
  Learning","Deep neural networks (DNNs) are increasingly powering high-stakes
applications such as autonomous cars and healthcare; however, DNNs are often
treated as ""black boxes"" in such applications. Recent research has also
revealed that DNNs are highly vulnerable to adversarial attacks, raising
serious concerns over deploying DNNs in the real world. To overcome these
deficiencies, we are developing Massif, an interactive tool for deciphering
adversarial attacks. Massif identifies and interactively visualizes neurons and
their connections inside a DNN that are strongly activated or suppressed by an
adversarial attack. Massif provides both a high-level, interpretable overview
of the effect of an attack on a DNN, and a low-level, detailed description of
the affected neurons. These tightly coupled views in Massif help people better
understand which input features are most vulnerable or important for correct
predictions.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.03864v1,2020-01-12T06:06:03Z,2020-01-12T06:06:03Z,"Learning to drive via Apprenticeship Learning and Deep Reinforcement
  Learning","With the implementation of reinforcement learning (RL) algorithms, current
state-of-art autonomous vehicle technology have the potential to get closer to
full automation. However, most of the applications have been limited to game
domains or discrete action space which are far from the real world driving.
Moreover, it is very tough to tune the parameters of reward mechanism since the
driving styles vary a lot among the different users. For instance, an
aggressive driver may prefer driving with high acceleration whereas some
conservative drivers prefer a safer driving style. Therefore, we propose an
apprenticeship learning in combination with deep reinforcement learning
approach that allows the agent to learn the driving and stopping behaviors with
continuous actions. We use gradient inverse reinforcement learning (GIRL)
algorithm to recover the unknown reward function and employ REINFORCE as well
as Deep Deterministic Policy Gradient algorithm (DDPG) to learn the optimal
policy. The performance of our method is evaluated in simulation-based scenario
and the results demonstrate that the agent performs human like driving and even
better in some aspects after training.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.00048v1,2019-12-31T19:41:59Z,2019-12-31T19:41:59Z,"MIR-Vehicle: Cost-Effective Research Platform for Autonomous Vehicle
  Applications","This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a
feasible option of transforming an electric ride-on-car into a modular Graphics
Processing Unit (GPU) powered autonomous platform equipped with the capability
that supports test and deployment of various intelligent autonomous vehicles
algorithms. To use a platform for research, two components must be provided:
perception and control. The sensors such as incremental encoders, an Inertial
Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR)
must be able to be installed on the platform to add the capability of
environmental perception. A microcontroller-powered control box is designed to
properly respond to the environmental changes by regulating drive and steering
motors. This drive-by-wire capability is controlled by a GPU powered laptop
computer where high-level perception algorithms are processed and complex
actions are generated by various methods including behavior cloning using deep
neural networks. The main goal of this paper is to provide an adequate and
comprehensive approach for fabricating a cost-effective platform that would
contribute to the research quality from the wider community. The proposed
platform is to use a modular and hierarchical software architecture where the
lower and simpler motor controls are taken care of by microcontroller programs,
and the higher and complex algorithms are processed by a GPU powered laptop
computer. The platform uses the Robot Operating System (ROS) as middleware to
maintain the modularity of the perceptions and decision-making modules. It is
expected that the level three and above autonomous vehicle systems and Advanced
Driver Assistance Systems (ADAS) can be tested on and deployed to the platform
with a decent real-time system behavior due to the capabilities and
affordability of the proposed platform.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.03618v2,2020-06-06T03:56:29Z,2019-12-08T05:12:17Z,Efficient Black-box Assessment of Autonomous Vehicle Safety,"While autonomous vehicle (AV) technology has shown substantial progress, we
still lack tools for rigorous and scalable testing. Real-world testing, the
$\textit{de-facto}$ evaluation method, is dangerous to the public. Moreover,
due to the rare nature of failures, billions of miles of driving are needed to
statistically validate performance claims. Thus, the industry has largely
turned to simulation to evaluate AV systems. However, having a simulation stack
alone is not a solution. A simulation testing framework needs to prioritize
which scenarios to run, learn how the chosen scenarios provide coverage of
failure modes, and rank failure scenarios in order of importance. We implement
a simulation testing framework that evaluates an entire modern AV system as a
black box. This framework estimates the probability of accidents under a base
distribution governing standard traffic behavior. In order to accelerate
rare-event probability evaluation, we efficiently learn to identify and rank
failure scenarios via adaptive importance-sampling methods. Using this
framework, we conduct the first independent evaluation of a full-stack
commercial AV system, Comma AI's OpenPilot.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.00752v3,2020-07-15T14:08:12Z,2019-11-28T03:03:24Z,"Deep Learning for Optimal Deployment of UAVs with Visible Light
  Communications","In this paper, the problem of dynamical deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities
for optimizing the energy efficiency of UAV-enabled networks is studied. In the
studied model, the UAVs can simultaneously provide communications and
illumination to service ground users. Since ambient illumination increases the
interference over VLC links while reducing the illumination threshold of the
UAVs, it is necessary to consider the illumination distribution of the target
area for UAV deployment optimization. This problem is formulated as an
optimization problem which jointly optimizes UAV deployment, user association,
and power efficiency while meeting the illumination and communication
requirements of users. To solve this problem, an algorithm that combines the
machine learning framework of gated recurrent units (GRUs) with convolutional
neural networks (CNNs) is proposed. Using GRUs and CNNs, the UAVs can model the
long-term historical illumination distribution and predict the future
illumination distribution. Given the prediction of illumination distribution,
the original nonconvex optimization problem can be divided into two
sub-problems and is then solved using a low-complexity, iterative algorithm.
Then, the proposed algorithm enables UAVs to determine the their deployment and
user association to minimize the total transmit power. Simulation results using
real data from the Earth observations group (EOG) at NOAA/NCEI show that the
proposed approach can achieve up to 68.9% reduction in total transmit power
compared to a conventional optimal UAV deployment that does not consider the
illumination distribution and user association.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.09592v1,2019-11-21T16:37:18Z,2019-11-21T16:37:18Z,"mm-Pose: Real-Time Human Skeletal Posture Estimation using mmWave Radars
  and CNNs","In this paper, mm-Pose, a novel approach to detect and track human skeletons
in real-time using an mmWave radar, is proposed. To the best of the authors'
knowledge, this is the first method to detect >15 distinct skeletal joints
using mmWave radar reflection signals. The proposed method would find several
applications in traffic monitoring systems, autonomous vehicles, patient
monitoring systems and defense forces to detect and track human skeleton for
effective and preventive decision making in real-time. The use of radar makes
the system operationally robust to scene lighting and adverse weather
conditions. The reflected radar point cloud in range, azimuth and elevation are
first resolved and projected in Range-Azimuth and Range-Elevation planes. A
novel low-size high-resolution radar-to-image representation is also presented,
that overcomes the sparsity in traditional point cloud data and offers
significant reduction in the subsequent machine learning architecture. The RGB
channels were assigned with the normalized values of range, elevation/azimuth
and the power level of the reflection signals for each of the points. A forked
CNN architecture was used to predict the real-world position of the skeletal
joints in 3-D space, using the radar-to-image representation. The proposed
method was tested for a single human scenario for four primary motions, (i)
Walking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging
both arms to validate accurate predictions for motion in range, azimuth and
elevation. The detailed methodology, implementation, challenges, and validation
results are presented.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.03565v1,2019-11-08T22:28:53Z,2019-11-08T22:28:53Z,"Vision-Based Lane-Changing Behavior Detection Using Deep Residual Neural
  Network","Accurate lane localization and lane change detection are crucial in advanced
driver assistance systems and autonomous driving systems for safer and more
efficient trajectory planning. Conventional localization devices such as Global
Positioning System only provide road-level resolution for car navigation, which
is incompetent to assist in lane-level decision making. The state of art
technique for lane localization is to use Light Detection and Ranging sensors
to correct the global localization error and achieve centimeter-level accuracy,
but the real-time implementation and popularization for LiDAR is still limited
by its computational burden and current cost. As a cost-effective alternative,
vision-based lane change detection has been highly regarded for affordable
autonomous vehicles to support lane-level localization. A deep learning-based
computer vision system is developed to detect the lane change behavior using
the images captured by a front-view camera mounted on the vehicle and data from
the inertial measurement unit for highway driving. Testing results on
real-world driving data have shown that the proposed method is robust with
real-time working ability and could achieve around 87% lane change detection
accuracy. Compared to the average human reaction to visual stimuli, the
proposed computer vision system works 9 times faster, which makes it capable of
helping make life-saving decisions in time.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.12217v4,2021-01-25T21:19:51Z,2019-09-26T16:15:37Z,"Visual Exploration and Energy-aware Path Planning via Reinforcement
  Learning","Visual exploration and smart data collection via autonomous vehicles is an
attractive topic in various disciplines. Disturbances like wind significantly
influence both the power consumption of the flying robots and the performance
of the camera. We propose a reinforcement learning approach which combines the
effects of the power consumption and the object detection modules to develop a
policy for object detection in large areas with limited battery life. The
learning model enables dynamic learning of the negative rewards of each action
based on the drag forces that is resulted by the motion of the flying robot
with respect to the wind field. The algorithm is implemented in a near-real
world simulation environment both for the planar motion and flight in different
altitudes. The trained agent often performed a trade-off between detecting the
objects with high accuracy and increasing the area coverage within its battery
life. The developed exploration policy outperformed the complete coverage
algorithm by minimizing the traveled path while finding the target objects. The
performance of the algorithms under various wind fields was evaluated in planar
and 3D motion. During an exploration task with sparsely distributed goals and
within a UAV's battery life, the proposed architecture could detect more than
twice the amount of goal objects compared to the coverage path planning
algorithm in moderate wind field. In high wind intensities, the energy-aware
algorithm could detect 4 times the amount of goal objects when compared to its
complete coverage counterpart.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.10914v1,2019-09-23T09:20:44Z,2019-09-23T09:20:44Z,Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs,"Recent advances in unmanned aerial vehicle (UAV) technology have
revolutionized a broad class of civil and military applications. However, the
designs of wireless technologies that enable real-time streaming of
high-definition video between UAVs and ground clients present a conundrum. Most
existing adaptive bitrate (ABR) algorithms are not optimized for the
air-to-ground links, which usually fluctuate dramatically due to the dynamic
flight states of the UAV. In this paper, we present SA-ABR, a new
sensor-augmented system that generates ABR video streaming algorithms with the
assistance of various kinds of inherent sensor data that are used to pilot
UAVs. By incorporating the inherent sensor data with network observations,
SA-ABR trains a deep reinforcement learning (DRL) model to extract salient
features from the flight state information and automatically learn an ABR
algorithm to adapt to the varying UAV channel capacity through the training
process. SA-ABR does not rely on any assumptions or models about UAV's flight
states or the environment, but instead, it makes decisions by exploiting
temporal properties of past throughput through the long short-term memory
(LSTM) to adapt itself to a wide range of highly dynamic environments. We have
implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare
SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the
results show that our system outperforms the best known existing ABR algorithm
by 21.4% in terms of the average quality of experience (QoE) reward.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.07554v1,2019-09-17T02:22:09Z,2019-09-17T02:22:09Z,"Gated Recurrent Units Learning for Optimal Deployment of Visible Light
  Communications Enabled UAVs","In this paper, the problem of optimizing the deployment of unmanned aerial
vehicles (UAVs) equipped with visible light communication (VLC) capabilities is
studied. In the studied model, the UAVs can simultaneously provide
communications and illumination to service ground users. Ambient illumination
increases the interference over VLC links while reducing the illumination
threshold of the UAVs. Therefore, it is necessary to consider the illumination
distribution of the target area for UAV deployment optimization. This problem
is formulated as an optimization problem whose goal is to minimize the total
transmit power while meeting the illumination and communication requirements of
users. To solve this problem, an algorithm based on the machine learning
framework of gated recurrent units (GRUs) is proposed. Using GRUs, the UAVs can
model the long-term historical illumination distribution and predict the future
illumination distribution. In order to reduce the complexity of the prediction
algorithm while accurately predicting the illumination distribution, a Gaussian
mixture model (GMM) is used to fit the illumination distribution of the target
area at each time slot. Based on the predicted illumination distribution, the
optimization problem is proved to be a convex optimization problem that can be
solved by using duality. Simulations using real data from the Earth
observations group (EOG) at NOAA/NCEI show that the proposed approach can
achieve up to 22.1% reduction in transmit power compared to a conventional
optimal UAV deployment that does not consider the illumination distribution.
The results also show that UAVs must hover at areas having strong illumination,
thus providing useful guidelines on the deployment of VLC-enabled UAVs.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.03854v1,2019-09-09T13:40:12Z,2019-09-09T13:40:12Z,A Convolutional Neural Network Approach Towards Self-Driving Cars,"A convolutional neural network (CNN) approach is used to implement a level 2
autonomous vehicle by mapping pixels from the camera input to the steering
commands. The network automatically learns the maximum variable features from
the camera input, hence requires minimal human intervention. Given realistic
frames as input, the driving policy trained on the dataset by NVIDIA and
Udacity can adapt to real-world driving in a controlled environment. The CNN is
tested on the CARLA open-source driving simulator. Details of a beta-testing
platform are also presented, which consists of an ultrasonic sensor for
obstacle detection and an RGBD camera for real-time position monitoring at
10Hz. Arduino Mega and Raspberry Pi are used for motor control and processing
respectively to output the steering angle, which is converted to angular
velocity for steering.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.02562v1,2019-09-05T13:21:22Z,2019-09-05T13:21:22Z,"TFCheck : A TensorFlow Library for Detecting Training Issues in Neural
  Network Programs","The increasing inclusion of Machine Learning (ML) models in safety critical
systems like autonomous cars have led to the development of multiple
model-based ML testing techniques. One common denominator of these testing
techniques is their assumption that training programs are adequate and
bug-free. These techniques only focus on assessing the performance of the
constructed model using manually labeled data or automatically generated data.
However, their assumptions about the training program are not always true as
training programs can contain inconsistencies and bugs. In this paper, we
examine training issues in ML programs and propose a catalog of verification
routines that can be used to detect the identified issues, automatically. We
implemented the routines in a Tensorflow-based library named TFCheck. Using
TFCheck, practitioners can detect the aforementioned issues automatically. To
assess the effectiveness of TFCheck, we conducted a case study with real-world,
mutants, and synthetic training programs. Results show that TFCheck can
successfully detect training issues in ML code implementations.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.08985v2,2020-02-08T22:59:03Z,2019-07-21T15:16:12Z,"Achieving Super-Linear Speedup across Multi-FPGA for Real-Time DNN
  Inference","Real-time Deep Neural Network (DNN) inference with low-latency requirement
has become increasingly important for numerous applications in both cloud
computing (e.g., Apple's Siri) and edge computing (e.g., Google/Waymo's
driverless car). FPGA-based DNN accelerators have demonstrated both superior
flexibility and performance; in addition, for real-time inference with low
batch size, FPGA is expected to achieve further performance improvement.
However, the performance gain from the single-FPGA design is obstructed by the
limited on-chip resource. In this paper, we employ multiple FPGAs to
cooperatively run DNNs with the objective of achieving super-linear speed-up
against single-FPGA design. In implementing such systems, we found two barriers
that hinder us from achieving the design goal: (1) the lack of a clear
partition scheme for each DNN layer to fully exploit parallelism, and (2) the
insufficient bandwidth between the off-chip memory and the accelerator due to
the growing size of DNNs. To tackle these issues, we propose a general
framework, ""Super-LIP"", which can support different kinds of DNNs. In this
paper, we take Convolutional Neural Network (CNN) as a vehicle to illustrate
Super-LIP. We first formulate an accurate system-level model to support the
exploration of best partition schemes. Then, we develop a novel design
methodology to effectively alleviate the heavy loads on memory bandwidth by
moving traffic from memory bus to inter-FPGA links. We implement Super-LIP
based on ZCU102 FPGA boards. Results demonstrate that Super-LIP with 2 FPGAs
can achieve 3.48x speedup, compared to the state-of-the-art single-FPGA design.
What is more, as the number of FPGAs scales up, the system latency can be
further reduced while maintaining high energy efficiency.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.01038v1,2019-07-01T19:42:37Z,2019-07-01T19:42:37Z,AVFI: Fault Injection for Autonomous Vehicles,"Autonomous vehicle (AV) technology is rapidly becoming a reality on U.S.
roads, offering the promise of improvements in traffic management, safety, and
the comfort and efficiency of vehicular travel. With this increasing popularity
and ubiquitous deployment, resilience has become a critical requirement for
public acceptance and adoption. Recent studies into the resilience of AVs have
shown that though the AV systems are improving over time, they have not reached
human levels of automation. Prior work in this area has studied the safety and
resilience of individual components of the AV system (e.g., testing of neural
networks powering the perception function). However, methods for holistic
end-to-end resilience assessment of AV systems are still non-existent.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.01562v2,2019-09-27T13:22:08Z,2019-06-04T16:27:47Z,Privacy-preserving Crowd-guided AI Decision-making in Ethical Dilemmas,"With the rapid development of artificial intelligence (AI), ethical issues
surrounding AI have attracted increasing attention. In particular, autonomous
vehicles may face moral dilemmas in accident scenarios, such as staying the
course resulting in hurting pedestrians or swerving leading to hurting
passengers. To investigate such ethical dilemmas, recent studies have adopted
preference aggregation, in which each voter expresses her/his preferences over
decisions for the possible ethical dilemma scenarios, and a centralized system
aggregates these preferences to obtain the winning decision. Although a useful
methodology for building ethical AI systems, such an approach can potentially
violate the privacy of voters since moral preferences are sensitive information
and their disclosure can be exploited by malicious parties. In this paper, we
report a first-of-its-kind privacy-preserving crowd-guided AI decision-making
approach in ethical dilemmas. We adopt the notion of differential privacy to
quantify privacy and consider four granularities of privacy protection by
taking voter-/record-level privacy protection and centralized/distributed
perturbation into account, resulting in four approaches VLCP, RLCP, VLDP, and
RLDP. Moreover, we propose different algorithms to achieve these privacy
protection granularities, while retaining the accuracy of the learned moral
preference model. Specifically, VLCP and RLCP are implemented with the data
aggregator setting a universal privacy parameter and perturbing the averaged
moral preference to protect the privacy of voters' data. VLDP and RLDP are
implemented in such a way that each voter perturbs her/his local moral
preference with a personalized privacy parameter. Extensive experiments on both
synthetic and real data demonstrate that the proposed approach can achieve high
accuracy of preference aggregation while protecting individual voter's privacy.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.11299v1,2019-05-27T15:32:59Z,2019-05-27T15:32:59Z,"ImgSensingNet: UAV Vision Guided Aerial-Ground Air Quality Sensing
  System","Given the increasingly serious air pollution problem, the monitoring of air
quality index (AQI) in urban areas has drawn considerable attention. This paper
presents ImgSensingNet, a vision guided aerial-ground sensing system, for
fine-grained air quality monitoring and forecasting using the fusion of haze
images taken by the unmanned-aerial-vehicle (UAV) and the AQI data collected by
an on-ground three-dimensional (3D) wireless sensor network (WSN).
Specifically, ImgSensingNet first leverages the computer vision technique to
tell the AQI scale in different regions from the taken haze images, where
haze-relevant features and a deep convolutional neural network (CNN) are
designed for direct learning between haze images and corresponding AQI scale.
Based on the learnt AQI scale, ImgSensingNet determines whether to wake up
on-ground wireless sensors for small-scale AQI monitoring and inference, which
can greatly reduce the energy consumption of the system. An entropy-based model
is employed for accurate real-time AQI inference at unmeasured locations and
future air quality distribution forecasting. We implement and evaluate
ImgSensingNet on two university campuses since Feb. 2018, and has collected
17,630 photos and 2.6 millions of AQI data samples. Experimental results
confirm that ImgSensingNet can achieve higher inference accuracy while greatly
reduce the energy consumption, compared to state-of-the-art AQI monitoring
approaches.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.04166v1,2019-05-10T13:34:18Z,2019-05-10T13:34:18Z,"An Open Source and Open Hardware Deep Learning-powered Visual Navigation
  Engine for Autonomous Nano-UAVs","Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter
and sub-10 Watts of total power budget, have so far been considered incapable
of running sophisticated visual-based autonomous navigation software without
external aid from base-stations, ad-hoc local positioning infrastructure, and
powerful external computation servers. In this work, we present what is, to the
best of our knowledge, the first 27g nano-UAV system able to run aboard an
end-to-end, closed-loop visual pipeline for autonomous navigation based on a
state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie
2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination
of an ultra-low power computing device (the GAP8 system-on-chip) with a novel
methodology for the deployment of deep convolutional neural networks (CNNs). We
enable onboard real-time execution of a state-of-the-art deep CNN at up to
18Hz. Field experiments demonstrate that the system's high responsiveness
prevents collisions with unexpected dynamic obstacles up to a flight speed of
1.5m/s. In addition, we also demonstrate the capability of our visual
navigation engine of fully autonomous indoor navigation on a 113m previously
unseen path. To share our key findings with the embedded and robotics
communities and foster further developments in autonomous nano-UAVs, we
publicly release all our code, datasets, and trained networks.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.06025v2,2020-02-21T18:00:23Z,2019-04-12T04:01:18Z,"Interaction-aware Decision Making with Adaptive Strategies under Merging
  Scenarios","In order to drive safely and efficiently under merging scenarios, autonomous
vehicles should be aware of their surroundings and make decisions by
interacting with other road participants. Moreover, different strategies should
be made when the autonomous vehicle is interacting with drivers having
different level of cooperativeness. Whether the vehicle is on the merge-lane or
main-lane will also influence the driving maneuvers since drivers will behave
differently when they have the right-of-way than otherwise. Many traditional
methods have been proposed to solve decision making problems under merging
scenarios. However, these works either are incapable of modeling complicated
interactions or require implementing hand-designed rules which cannot properly
handle the uncertainties in real-world scenarios. In this paper, we proposed an
interaction-aware decision making with adaptive strategies (IDAS) approach that
can let the autonomous vehicle negotiate the road with other drivers by
leveraging their cooperativeness under merging scenarios. A single policy is
learned under the multi-agent reinforcement learning (MARL) setting via the
curriculum learning strategy, which enables the agent to automatically infer
other drivers' various behaviors and make decisions strategically. A masking
mechanism is also proposed to prevent the agent from exploring states that
violate common sense of human judgment and increase the learning efficiency. An
exemplar merging scenario was used to implement and examine the proposed
method.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.00035v1,2019-03-29T18:15:24Z,2019-03-29T18:15:24Z,Autonomous Highway Driving using Deep Reinforcement Learning,"The operational space of an autonomous vehicle (AV) can be diverse and vary
significantly. This may lead to a scenario that was not postulated in the
design phase. Due to this, formulating a rule based decision maker for
selecting maneuvers may not be ideal. Similarly, it may not be effective to
design an a-priori cost function and then solve the optimal control problem in
real-time. In order to address these issues and to avoid peculiar behaviors
when encountering unforeseen scenario, we propose a reinforcement learning (RL)
based method, where the ego car, i.e., an autonomous vehicle, learns to make
decisions by directly interacting with simulated traffic. The decision maker
for AV is implemented as a deep neural network providing an action choice for a
given system state. In a critical application such as driving, an RL agent
without explicit notion of safety may not converge or it may need extremely
large number of samples before finding a reliable policy. To best address the
issue, this paper incorporates reinforcement learning with an additional short
horizon safety check (SC). In a critical scenario, the safety check will also
provide an alternate safe action to the agent provided if it exists. This leads
to two novel contributions. First, it generalizes the states that could lead to
undesirable ""near-misses"" or ""collisions "". Second, inclusion of safety check
can provide a safe and stable training environment. This significantly enhances
learning efficiency without inhibiting meaningful exploration to ensure safe
and optimal learned behavior. We demonstrate the performance of the developed
algorithm in highway driving scenario where the trained AV encounters varying
traffic density in a highway setting.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1902.01084v2,2021-01-15T20:47:41Z,2019-02-04T08:51:50Z,Paracosm: A Language and Tool for Testing Autonomous Driving Systems,"Systematic testing of autonomous vehicles operating in complex real-world
scenarios is a difficult and expensive problem. We present Paracosm, a reactive
language for writing test scenarios for autonomous driving systems. Paracosm
allows users to programmatically describe complex driving situations with
specific visual features, e.g., road layout in an urban environment, as well as
reactive temporal behaviors of cars and pedestrians. Paracosm programs are
executed on top of a game engine that provides realistic physics simulation and
visual rendering. The infrastructure allows systematic exploration of the state
space, both for visual features (lighting, shadows, fog) and for reactive
interactions with the environment (pedestrians, other traffic). We define a
notion of test coverage for Paracosm configurations based on combinatorial
testing and low dispersion sequences. Paracosm comes with an automatic test
case generator that uses random sampling for discrete parameters and
deterministic quasi-Monte Carlo generation for continuous parameters. Through
an empirical evaluation, we demonstrate the modeling and testing capabilities
of Paracosm on a suite of autonomous driving systems implemented using deep
neural networks developed in research and education. We show how Paracosm can
expose incorrect behaviors or degraded performance.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.08273v1,2018-12-19T22:25:52Z,2018-12-19T22:25:52Z,Analog Signal Processing Using Stochastic Magnets,"We present a low barrier magnet based compact hardware unit for analog
stochastic neurons and demonstrate its use as a building-block for neuromorphic
hardware. By coupling circular magnetic tunnel junctions (MTJs) with a CMOS
based analog buffer, we show that these units can act as leaky-integrate-and
fire (LIF) neurons, a model of biological neural networks particularly suited
for temporal inferencing and pattern recognition. We demonstrate examples of
temporal sequence learning, processing, and prediction tasks in real time, as a
proof of concept demonstration of scalable and adaptive signal-processors.
Efficient non von-Neumann hardware implementation of such processors can open
up a pathway for integration of hardware based cognition in a wide variety of
emerging systems such as IoT, industrial controls, bio- and photo-sensors, and
Unmanned Autonomous Vehicles.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.00145v3,2019-01-12T19:27:45Z,2018-10-31T22:47:22Z,Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation,"While recent developments in autonomous vehicle (AV) technology highlight
substantial progress, we lack tools for rigorous and scalable testing.
Real-world testing, the $\textit{de facto}$ evaluation environment, places the
public in danger, and, due to the rare nature of accidents, will require
billions of miles in order to statistically validate performance claims. We
implement a simulation framework that can test an entire modern autonomous
driving system, including, in particular, systems that employ deep-learning
perception and control algorithms. Using adaptive importance-sampling methods
to accelerate rare-event probability evaluation, we estimate the probability of
an accident under a base distribution governing standard traffic behavior. We
demonstrate our framework on a highway scenario, accelerating system evaluation
by $2$-$20$ times over naive Monte Carlo sampling methods and $10$-$300
\mathsf{P}$ times (where $\mathsf{P}$ is the number of processors) over
real-world testing.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.09729v1,2018-10-23T08:51:54Z,2018-10-23T08:51:54Z,"Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A
  Comprehensive Survey, and Future Directions","Unmanned Aerial Vehicles (UAVs) have recently rapidly grown to facilitate a
wide range of innovative applications that can fundamentally change the way
cyber-physical systems (CPSs) are designed. CPSs are a modern generation of
systems with synergic cooperation between computational and physical potentials
that can interact with humans through several new mechanisms. The main
advantages of using UAVs in CPS application is their exceptional features,
including their mobility, dynamism, effortless deployment, adaptive altitude,
agility, adjustability, and effective appraisal of real-world functions anytime
and anywhere. Furthermore, from the technology perspective, UAVs are predicted
to be a vital element of the development of advanced CPSs. Therefore, in this
survey, we aim to pinpoint the most fundamental and important design challenges
of multi-UAV systems for CPS applications. We highlight key and versatile
aspects that span the coverage and tracking of targets and infrastructure
objects, energy-efficient navigation, and image analysis using machine learning
for fine-grained CPS applications. Key prototypes and testbeds are also
investigated to show how these practical technologies can facilitate CPS
applications. We present and propose state-of-the-art algorithms to address
design challenges with both quantitative and qualitative methods and map these
challenges with important CPS applications to draw insightful conclusions on
the challenges of each application. Finally, we summarize potential new
directions and ideas that could shape future research in these areas.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.10134v1,2018-08-30T06:29:10Z,2018-08-30T06:29:10Z,"Baidu Apollo Auto-Calibration System - An Industry-Level Data-Driven and
  Learning based Vehicle Longitude Dynamic Calibrating Algorithm","For any autonomous driving vehicle, control module determines its road
performance and safety, i.e. its precision and stability should stay within a
carefully-designed range. Nonetheless, control algorithms require vehicle
dynamics (such as longitudinal dynamics) as inputs, which, unfortunately, are
obscure to calibrate in real time. As a result, to achieve reasonable
performance, most, if not all, research-oriented autonomous vehicles do manual
calibrations in a one-by-one fashion. Since manual calibration is not
sustainable once entering into mass production stage for industrial purposes,
we here introduce a machine-learning based auto-calibration system for
autonomous driving vehicles. In this paper, we will show how we build a
data-driven longitudinal calibration procedure using machine learning
techniques. We first generated offline calibration tables from human driving
data. The offline table serves as an initial guess for later uses and it only
needs twenty-minutes data collection and process. We then used an
online-learning algorithm to appropriately update the initial table (the
offline table) based on real-time performance analysis. This longitudinal
auto-calibration system has been deployed to more than one hundred Baidu Apollo
self-driving vehicles (including hybrid family vehicles and electronic
delivery-only vehicles) since April 2018. By August 27, 2018, it had been
tested for more than two thousands hours, ten thousands kilometers (6,213
miles) and yet proven to be effective.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.06352v1,2018-08-20T09:06:21Z,2018-08-20T09:06:21Z,"Navigating the Landscape for Real-time Localisation and Mapping for
  Robotics and Virtual and Augmented Reality","Visual understanding of 3D environments in real-time, at low power, is a huge
computational challenge. Often referred to as SLAM (Simultaneous Localisation
and Mapping), it is central to applications spanning domestic and industrial
robotics, autonomous vehicles, virtual and augmented reality. This paper
describes the results of a major research effort to assemble the algorithms,
architectures, tools, and systems software needed to enable delivery of SLAM,
by supporting applications specialists in selecting and configuring the
appropriate algorithm and the appropriate hardware, and compilation pathway, to
meet their performance, accuracy, and energy consumption goals. The major
contributions we present are (1) tools and methodology for systematic
quantitative evaluation of SLAM algorithms, (2) automated,
machine-learning-guided exploration of the algorithmic and implementation
design space with respect to multiple objectives, (3) end-to-end simulation
tools to enable optimisation of heterogeneous, accelerated architectures for
the specific algorithmic requirements of the various SLAM algorithmic
approaches, and (4) tools for delivering, where appropriate, accelerated,
adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.03506v4,2019-03-05T23:50:01Z,2018-08-10T12:30:03Z,"ChipNet: Real-Time LiDAR Processing for Drivable Region Segmentation on
  an FPGA","This paper presents a field-programmable gate array (FPGA) design of a
segmentation algorithm based on convolutional neural network (CNN) that can
process light detection and ranging (LiDAR) data in real-time. For autonomous
vehicles, drivable region segmentation is an essential step that sets up the
static constraints for planning tasks. Traditional drivable region segmentation
algorithms are mostly developed on camera data, so their performance is
susceptible to the light conditions and the qualities of road markings. LiDAR
sensors can obtain the 3D geometry information of the vehicle surroundings with
high precision. However, it is a computational challenge to process a large
amount of LiDAR data in real-time. In this paper, a convolutional neural
network model is proposed and trained to perform semantic segmentation using
data from the LiDAR sensor. An efficient hardware architecture is proposed and
implemented on an FPGA that can process each LiDAR scan in 17.59 ms, which is
much faster than the previous works. Evaluated using Ford and KITTI road
detection benchmarks, the proposed solution achieves both high accuracy in
performance and real-time processing in speed.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.00259v1,2018-08-01T10:50:47Z,2018-08-01T10:50:47Z,Drone Detection Using Depth Maps,"Obstacle avoidance is a key feature for safe Unmanned Aerial Vehicle (UAV)
navigation. While solutions have been proposed for static obstacle avoidance,
systems enabling avoidance of dynamic objects, such as drones, are hard to
implement due to the detection range and field-of-view (FOV) requirements, as
well as the constraints for integrating such systems on-board small UAVs. In
this work, a dataset of 6k synthetic depth maps of drones has been generated
and used to train a state-of-the-art deep learning-based drone detection model.
While many sensing technologies can only provide relative altitude and azimuth
of an obstacle, our depth map-based approach enables full 3D localization of
the obstacle. This is extremely useful for collision avoidance, as 3D
localization of detected drones is key to perform efficient collision-free path
planning. The proposed detection technique has been validated in several real
depth map sequences, with multiple types of drones flying at up to 2 m/s,
achieving an average precision of 98.7%, an average recall of 74.7% and a
record detection range of 9.5 meters.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.11785v1,2018-07-31T12:17:41Z,2018-07-31T12:17:41Z,Transfer Learning-Based Crack Detection by Autonomous UAVs,"Unmanned Aerial Vehicles (UAVs) have recently shown great performance
collecting visual data through autonomous exploration and mapping in building
inspection. Yet, the number of studies is limited considering the post
processing of the data and its integration with autonomous UAVs. These will
enable huge steps onward into full automation of building inspection. In this
regard, this work presents a decision making tool for revisiting tasks in
visual building inspection by autonomous UAVs. The tool is an implementation of
fine-tuning a pretrained Convolutional Neural Network (CNN) for surface crack
detection. It offers an optional mechanism for task planning of revisiting
pinpoint locations during inspection. It is integrated to a quadrotor UAV
system that can autonomously navigate in GPS-denied environments. The UAV is
equipped with onboard sensors and computers for autonomous localization,
mapping and motion planning. The integrated system is tested through
simulations and real-world experiments. The results show that the system
achieves crack detection and autonomous navigation in GPS-denied environments
for building inspection.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1806.07987v2,2018-09-13T17:20:44Z,2018-06-20T21:12:43Z,"A Hierarchical Deep Architecture and Mini-Batch Selection Method For
  Joint Traffic Sign and Light Detection","Traffic light and sign detectors on autonomous cars are integral for road
scene perception. The literature is abundant with deep learning networks that
detect either lights or signs, not both, which makes them unsuitable for
real-life deployment due to the limited graphics processing unit (GPU) memory
and power available on embedded systems. The root cause of this issue is that
no public dataset contains both traffic light and sign labels, which leads to
difficulties in developing a joint detection framework. We present a deep
hierarchical architecture in conjunction with a mini-batch proposal selection
mechanism that allows a network to detect both traffic lights and signs from
training on separate traffic light and sign datasets. Our method solves the
overlapping issue where instances from one dataset are not labelled in the
other dataset. We are the first to present a network that performs joint
detection on traffic lights and signs. We measure our network on the
Tsinghua-Tencent 100K benchmark for traffic sign detection and the Bosch Small
Traffic Lights benchmark for traffic light detection and show it outperforms
the existing Bosch Small Traffic light state-of-the-art method. We focus on
autonomous car deployment and show our network is more suitable than others
because of its low memory footprint and real-time image processing time.
Qualitative results can be viewed at https://youtu.be/_YmogPzBXOw",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.10829v3,2018-07-01T17:33:53Z,2018-04-28T16:37:01Z,Formal Security Analysis of Neural Networks using Symbolic Intervals,"Due to the increasing deployment of Deep Neural Networks (DNNs) in real-world
security-critical domains including autonomous vehicles and collision avoidance
systems, formally checking security properties of DNNs, especially under
different attacker capabilities, is becoming crucial. Most existing security
testing techniques for DNNs try to find adversarial examples without providing
any formal security guarantees about the non-existence of such adversarial
examples. Recently, several projects have used different types of
Satisfiability Modulo Theory (SMT) solvers to formally check security
properties of DNNs. However, all of these approaches are limited by the high
overhead caused by the solver.
  In this paper, we present a new direction for formally checking security
properties of DNNs without using SMT solvers. Instead, we leverage interval
arithmetic to compute rigorous bounds on the DNN outputs. Our approach, unlike
existing solver-based approaches, is easily parallelizable. We further present
symbolic interval analysis along with several other optimizations to minimize
overestimations of output bounds.
  We design, implement, and evaluate our approach as part of ReluVal, a system
for formally checking security properties of Relu-based DNNs. Our extensive
empirical results show that ReluVal outperforms Reluplex, a state-of-the-art
solver-based system, by 200 times on average. On a single 8-core machine
without GPUs, within 4 hours, ReluVal is able to verify a security property
that Reluplex deemed inconclusive due to timeout after running for more than 5
days. Our experiments demonstrate that symbolic interval analysis is a
promising new direction towards rigorously analyzing different security
properties of DNNs.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.03629v1,2018-04-10T17:05:53Z,2018-04-10T17:05:53Z,Probabilistic Prediction of Vehicle Semantic Intention and Motion,"Accurately predicting the possible behaviors of traffic participants is an
essential capability for future autonomous vehicles. The majority of current
researches fix the number of driving intentions by considering only a specific
scenario. However, distinct driving environments usually contain various
possible driving maneuvers. Therefore, a intention prediction method that can
adapt to different traffic scenarios is needed. To further improve the overall
vehicle prediction performance, motion information is usually incorporated with
classified intentions. As suggested in some literature, the methods that
directly predict possible goal locations can achieve better performance for
long-term motion prediction than other approaches due to their automatic
incorporation of environment constraints. Moreover, by obtaining the temporal
information of the predicted destinations, the optimal trajectories for
predicted vehicles as well as the desirable path for ego autonomous vehicle
could be easily generated. In this paper, we propose a Semantic-based Intention
and Motion Prediction (SIMP) method, which can be adapted to any driving
scenarios by using semantic-defined vehicle behaviors. It utilizes a
probabilistic framework based on deep neural network to estimate the
intentions, final locations, and the corresponding time information for
surrounding vehicles. An exemplar real-world scenario was used to implement and
examine the proposed method.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.06077v2,2018-08-31T09:16:33Z,2018-03-16T05:29:12Z,"Real-time Detection, Tracking, and Classification of Moving and
  Stationary Objects using Multiple Fisheye Images","The ability to detect pedestrians and other moving objects is crucial for an
autonomous vehicle. This must be done in real-time with minimum system
overhead. This paper discusses the implementation of a surround view system to
identify moving as well as static objects that are close to the ego vehicle.
The algorithm works on 4 views captured by fisheye cameras which are merged
into a single frame. The moving object detection and tracking solution uses
minimal system overhead to isolate regions of interest (ROIs) containing moving
objects. These ROIs are then analyzed using a deep neural network (DNN) to
categorize the moving object. With deployment and testing on a real car in
urban environments, we have demonstrated the practical feasibility of the
solution. The video demos of our algorithm have been uploaded to Youtube:
https://youtu.be/vpoCfC724iA, https://youtu.be/2X4aqH2bMBs",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.00680v2,2019-03-17T01:34:35Z,2018-03-02T01:34:06Z,"A Tutorial on UAVs for Wireless Networks: Applications, Challenges, and
  Open Problems","The use of flying platforms such as unmanned aerial vehicles (UAVs),
popularly known as drones, is rapidly growing. In particular, with their
inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs
admit several key potential applications in wireless systems. On the one hand,
UAVs can be used as aerial base stations to enhance coverage, capacity,
reliability, and energy efficiency of wireless networks. On the other hand,
UAVs can operate as flying mobile terminals within a cellular network. Such
cellular-connected UAVs can enable several applications ranging from real-time
video streaming to item delivery. In this paper, a comprehensive tutorial on
the potential benefits and applications of UAVs in wireless communications is
presented. Moreover, the important challenges and the fundamental tradeoffs in
UAV-enabled wireless networks are thoroughly investigated. In particular, the
key UAV challenges such as three-dimensional deployment, performance analysis,
channel modeling, and energy efficiency are explored along with representative
results. Then, open problems and potential research directions pertaining to
UAV communications are introduced. Finally, various analytical frameworks and
mathematical tools such as optimization theory, machine learning, stochastic
geometry, transport theory, and game theory are described. The use of such
tools for addressing unique UAV problems is also presented. In a nutshell, this
tutorial provides key guidelines on how to analyze, optimize, and design
UAV-based wireless communication systems.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.05086v1,2018-01-16T01:14:12Z,2018-01-16T01:14:12Z,Autonomous UAV Navigation Using Reinforcement Learning,"Unmanned aerial vehicles (UAV) are commonly used for missions in unknown
environments, where an exact mathematical model of the environment may not be
available. This paper provides a framework for using reinforcement learning to
allow the UAV to navigate successfully in such environments. We conducted our
simulation and real implementation to show how the UAVs can successfully learn
to navigate through an unknown environment. Technical aspects regarding to
applying reinforcement learning algorithm to a UAV system and UAV flight
control were also addressed. This will enable continuing research using a UAV
with learning capabilities in more important applications, such as wildfire
monitoring, or search and rescue missions.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.02197v1,2018-01-07T15:04:52Z,2018-01-07T15:04:52Z,Realistic Image Degradation with Measured PSF,"Training autonomous vehicles requires lots of driving sequences in all
situations\cite{zhao2016}. Typically a simulation environment
(software-in-the-loop, SiL) accompanies real-world test drives to
systematically vary environmental parameters. A missing piece in the optical
model of those SiL simulations is the sharpness, given in linear system theory
by the point-spread function (PSF) of the optical system. We present a novel
numerical model for the PSF of an optical system that can efficiently model
both experimental measurements and lens design simulations of the PSF. The
numerical basis for this model is a non-linear regression of the PSF with an
artificial neural network (ANN). The novelty lies in the portability and the
parameterization of this model, which allows to apply this model in basically
any conceivable optical simulation scenario, e.g. inserting a measured lens
into a computer game to train autonomous vehicles. We present a lens
measurement series, yielding a numerical function for the PSF that depends only
on the parameters defocus, field and azimuth. By convolving existing images and
videos with this PSF model we apply the measured lens as a transfer function,
therefore generating an image as if it were seen with the measured lens itself.
Applications of this method are in any optical scenario, but we focus on the
context of autonomous driving, where quality of the detection algorithms
depends directly on the optical quality of the used camera system. With the
parameterization of the optical model we present a method to validate the
functional and safety limits of camera-based ADAS based on the real, measured
lens actually used in the product.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.02190v1,2018-01-07T13:46:03Z,2018-01-07T13:46:03Z,Approximate FPGA-based LSTMs under Computation Time Constraints,"Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)
networks have demonstrated state-of-the-art accuracy in several emerging
Artificial Intelligence tasks. However, the models are becoming increasingly
demanding in terms of computational and memory load. Emerging latency-sensitive
applications including mobile robots and autonomous vehicles often operate
under stringent computation time constraints. In this paper, we address the
challenge of deploying computationally demanding LSTMs at a constrained time
budget by introducing an approximate computing scheme that combines iterative
low-rank compression and pruning, along with a novel FPGA-based LSTM
architecture. Combined in an end-to-end framework, the approximation method's
parameters are optimised and the architecture is configured to address the
problem of high-performance LSTM execution in time-constrained applications.
Quantitative evaluation on a real-life image captioning application indicates
that the proposed methods required up to 6.5x less time to achieve the same
application-level accuracy compared to a baseline method, while achieving an
average of 25x higher accuracy under the same computation time constraints.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1712.04248v2,2018-02-16T14:40:42Z,2017-12-12T11:36:26Z,"Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box
  Machine Learning Models","Many machine learning algorithms are vulnerable to almost imperceptible
perturbations of their inputs. So far it was unclear how much risk adversarial
perturbations carry for the safety of real-world machine learning applications
because most methods used to generate such perturbations rely either on
detailed model information (gradient-based attacks) or on confidence scores
such as class probabilities (score-based attacks), neither of which are
available in most real-world scenarios. In many such cases one currently needs
to retreat to transfer-based attacks which rely on cumbersome substitute
models, need access to the training data and can be defended against. Here we
emphasise the importance of attacks which solely rely on the final model
decision. Such decision-based attacks are (1) applicable to real-world
black-box models such as autonomous cars, (2) need less knowledge and are
easier to apply than transfer-based attacks and (3) are more robust to simple
defences than gradient- or score-based attacks. Previous attacks in this
category were limited to simple models or simple datasets. Here we introduce
the Boundary Attack, a decision-based attack that starts from a large
adversarial perturbation and then seeks to reduce the perturbation while
staying adversarial. The attack is conceptually simple, requires close to no
hyperparameter tuning, does not rely on substitute models and is competitive
with the best gradient-based attacks in standard computer vision tasks like
ImageNet. We apply the attack on two black-box algorithms from Clarifai.com.
The Boundary Attack in particular and the class of decision-based attacks in
general open new avenues to study the robustness of machine learning models and
raise new questions regarding the safety of deployed machine learning systems.
An implementation of the attack is available as part of Foolbox at
https://github.com/bethgelab/foolbox .",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1712.02294v4,2018-07-12T14:11:40Z,2017-12-06T17:20:21Z,Joint 3D Proposal Generation and Object Detection from View Aggregation,"We present AVOD, an Aggregate View Object Detection network for autonomous
driving scenarios. The proposed neural network architecture uses LIDAR point
clouds and RGB images to generate features that are shared by two subnetworks:
a region proposal network (RPN) and a second stage detector network. The
proposed RPN uses a novel architecture capable of performing multimodal feature
fusion on high resolution feature maps to generate reliable 3D object proposals
for multiple object classes in road scenes. Using these proposals, the second
stage detection network performs accurate oriented 3D bounding box regression
and category classification to predict the extents, orientation, and
classification of objects in 3D space. Our proposed architecture is shown to
produce state of the art results on the KITTI 3D object detection benchmark
while running in real time with a low memory footprint, making it a suitable
candidate for deployment on autonomous vehicles. Code is at:
https://github.com/kujason/avod",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1711.02757v1,2017-11-07T22:42:09Z,2017-11-07T22:42:09Z,Real-Time Road Segmentation Using LiDAR Data Processing on an FPGA,"This paper presents the FPGA design of a convolutional neural network (CNN)
based road segmentation algorithm for real-time processing of LiDAR data. For
autonomous vehicles, it is important to perform road segmentation and obstacle
detection such that the drivable region can be identified for path planning.
Traditional road segmentation algorithms are mainly based on image data from
cameras, which is subjected to the light condition as well as the quality of
road markings. LiDAR sensor can obtain the 3D geometry information of the
vehicle surroundings with very high accuracy. However, it is a computational
challenge to process a large amount of LiDAR data at real-time. In this work, a
convolutional neural network model is proposed and trained to perform semantic
segmentation using the LiDAR sensor data. Furthermore, an efficient hardware
design is implemented on the FPGA that can process each LiDAR scan in 16.9ms,
which is much faster than the previous works. Evaluated using KITTI road
benchmarks, the proposed solution achieves high accuracy of road segmentation.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.08526v1,2017-10-23T22:09:45Z,2017-10-23T22:09:45Z,Video Labeling for Automatic Video Surveillance in Security Domains,"Beyond traditional security methods, unmanned aerial vehicles (UAVs) have
become an important surveillance tool used in security domains to collect the
required annotated data. However, collecting annotated data from videos taken
by UAVs efficiently, and using these data to build datasets that can be used
for learning payoffs or adversary behaviors in game-theoretic approaches and
security applications, is an under-explored research question. This paper
presents VIOLA, a novel labeling application that includes (i) a workload
distribution framework to efficiently gather human labels from videos in a
secured manner; (ii) a software interface with features designed for labeling
videos taken by UAVs in the domain of wildlife security. We also present the
evolution of VIOLA and analyze how the changes made in the development process
relate to the efficiency of labeling, including when seemingly obvious
improvements did not lead to increased efficiency. VIOLA enables collecting
massive amounts of data with detailed information from challenging security
videos such as those collected aboard UAVs for wildlife security. VIOLA will
lead to the development of new approaches that integrate deep learning for
real-time detection and response.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.06270v2,2017-10-18T06:46:05Z,2017-10-17T13:38:16Z,"Procedural Modeling and Physically Based Rendering for Synthetic Data
  Generation in Automotive Applications","We present an overview and evaluation of a new, systematic approach for
generation of highly realistic, annotated synthetic data for training of deep
neural networks in computer vision tasks. The main contribution is a procedural
world modeling approach enabling high variability coupled with physically
accurate image synthesis, and is a departure from the hand-modeled virtual
worlds and approximate image synthesis methods used in real-time applications.
The benefits of our approach include flexible, physically accurate and scalable
image synthesis, implicit wide coverage of classes and features, and complete
data introspection for annotations, which all contribute to quality and cost
efficiency. To evaluate our approach and the efficacy of the resulting data, we
use semantic segmentation for autonomous vehicles and robotic navigation as the
main application, and we train multiple deep learning architectures using
synthetic data with and without fine tuning on organic (i.e. real-world) data.
The evaluation shows that our approach improves the neural network's
performance and that even modest implementation efforts produce
state-of-the-art results.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1709.03339v3,2018-02-27T10:14:24Z,2017-09-11T11:39:47Z,Autonomous Quadrotor Landing using Deep Reinforcement Learning,"Landing an unmanned aerial vehicle (UAV) on a ground marker is an open
problem despite the effort of the research community. Previous attempts mostly
focused on the analysis of hand-crafted geometric features and the use of
external sensors in order to allow the vehicle to approach the land-pad. In
this article, we propose a method based on deep reinforcement learning that
only requires low-resolution images taken from a down-looking camera in order
to identify the position of the marker and land the UAV on it. The proposed
approach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level
control policy for the navigation toward the marker. We implemented different
technical solutions, such as the combination of vanilla and double DQNs, and a
partitioned buffer replay. Using domain randomization we trained the vehicle on
uniform textures and we tested it on a large variety of simulated and
real-world environments. The overall performance is comparable with a
state-of-the-art algorithm and human pilots.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1708.08559v2,2018-03-20T06:10:24Z,2017-08-28T23:26:14Z,"DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous
  Cars","Recent advances in Deep Neural Networks (DNNs) have led to the development of
DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can
drive without any human intervention. Most major manufacturers including Tesla,
GM, Ford, BMW, and Waymo/Google are working on building and testing different
types of autonomous vehicles. The lawmakers of several US states including
California, Texas, and New York have passed new legislation to fast-track the
process of testing and deployment of autonomous vehicles on their roads.
  However, despite their spectacular progress, DNNs, just like traditional
software, often demonstrate incorrect or unexpected corner case behaviors that
can lead to potentially fatal collisions. Several such real-world accidents
involving autonomous cars have already happened including one which resulted in
a fatality. Most existing testing techniques for DNN-driven vehicles are
heavily dependent on the manual collection of test data under different driving
conditions which become prohibitively expensive as the number of test
conditions increases.
  In this paper, we design, implement and evaluate DeepTest, a systematic
testing tool for automatically detecting erroneous behaviors of DNN-driven
vehicles that can potentially lead to fatal crashes. First, our tool is
designed to automatically generated test cases leveraging real-world changes in
driving conditions like rain, fog, lighting conditions, etc. DeepTest
systematically explores different parts of the DNN logic by generating test
inputs that maximize the numbers of activated neurons. DeepTest found thousands
of erroneous behaviors under different realistic driving conditions (e.g.,
blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in
three top performing DNNs in the Udacity self-driving car challenge.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1708.05884v4,2018-11-22T15:12:02Z,2017-08-19T18:13:23Z,"Teaching UAVs to Race: End-to-End Regression of Agile Controls in
  Simulation","Automating the navigation of unmanned aerial vehicles (UAVs) in diverse
scenarios has gained much attention in recent years. However, teaching UAVs to
fly in challenging environments remains an unsolved problem, mainly due to the
lack of training data. In this paper, we train a deep neural network to predict
UAV controls from raw image data for the task of autonomous UAV racing in a
photo-realistic simulation. Training is done through imitation learning with
data augmentation to allow for the correction of navigation mistakes. Extensive
experiments demonstrate that our trained network (when sufficient data
augmentation is used) outperforms state-of-the-art methods and flies more
consistently than many human pilots. Additionally, we show that our optimized
network architecture can run in real-time on embedded hardware, allowing for
efficient on-board processing critical for real-world deployment. From a
broader perspective, our results underline the importance of extensive data
augmentation techniques to improve robustness in end-to-end learning setups.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1705.05065v2,2017-07-18T05:30:28Z,2017-05-15T04:06:22Z,"AirSim: High-Fidelity Visual and Physical Simulation for Autonomous
  Vehicles","Developing and testing algorithms for autonomous vehicles in real world is an
expensive and time consuming process. Also, in order to utilize recent advances
in machine intelligence and deep learning we need to collect a large amount of
annotated training data in a variety of conditions and environments. We present
a new simulator built on Unreal Engine that offers physically and visually
realistic simulations for both of these goals. Our simulator includes a physics
engine that can operate at a high frequency for real-time hardware-in-the-loop
(HITL) simulations with support for popular protocols (e.g. MavLink). The
simulator is designed from the ground up to be extensible to accommodate new
types of vehicles, hardware platforms and software protocols. In addition, the
modular design enables various components to be easily usable independently in
other projects. We demonstrate the simulator by first implementing a quadrotor
as an autonomous vehicle and then experimentally comparing the software
components with real-world flights.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.10049v5,2022-04-19T12:03:53Z,2017-03-29T14:12:42Z,"Autonomous Recharging and Flight Mission Planning for Battery-operated
  Autonomous Drones","Unmanned aerial vehicles (UAVs), commonly known as drones, are being
increasingly deployed throughout the globe as a means to streamline monitoring,
inspection, mapping, and logistic routines. When dispatched on autonomous
missions, drones require an intelligent decision-making system for trajectory
planning and tour optimization. Given the limited capacity of their onboard
batteries, a key design challenge is to ensure the underlying algorithms can
efficiently optimize the mission objectives along with recharging operations
during long-haul flights. With this in view, the present work undertakes a
comprehensive study on automated tour management systems for an
energy-constrained drone: (1) We construct a machine learning model that
estimates the energy expenditure of typical multi-rotor drones while accounting
for real-world aspects and extrinsic meteorological factors. (2) Leveraging
this model, the joint program of flight mission planning and recharging
optimization is formulated as a multi-criteria Asymmetric Traveling Salesman
Problem (ATSP), wherein a drone seeks for the time-optimal energy-feasible tour
that visits all the target sites and refuels whenever necessary. (3) We devise
an efficient approximation algorithm with provable worst-case performance
guarantees and implement it in a drone management system, which supports
real-time flight path tracking and re-computation in dynamic environments. (4)
The effectiveness and practicality of the proposed approach are validated
through extensive numerical simulations as well as real-world experiments.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1610.01585v1,2016-10-05T19:41:12Z,2016-10-05T19:41:12Z,"Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned
  Aerial Vehicles for Optimized Quality-of-Experience","In this paper, the problem of proactive deployment of cache-enabled unmanned
aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of
wireless devices in a cloud radio access network (CRAN) is studied. In the
considered model, the network can leverage human-centric information such as
users' visited locations, requested contents, gender, job, and device type to
predict the content request distribution and mobility pattern of each user.
Then, given these behavior predictions, the proposed approach seeks to find the
user-UAV associations, the optimal UAVs' locations, and the contents to cache
at UAVs. This problem is formulated as an optimization problem whose goal is to
maximize the users' QoE while minimizing the transmit power used by the UAVs.
To solve this problem, a novel algorithm based on the machine learning
framework of conceptor-based echo state networks (ESNs) is proposed. Using
ESNs, the network can effectively predict each user's content request
distribution and its mobility pattern when limited information on the states of
users and the network is available. Based on the predictions of the users'
content request distribution and their mobility patterns, we derive the optimal
user-UAV association, optimal locations of the UAVs as well as the content to
cache at UAVs. Simulation results using real pedestrian mobility patterns from
BUPT and actual content transmission data from Youku show that the proposed
algorithm can yield 40% and 61% gains, respectively, in terms of the average
transmit power and the percentage of the users with satisfied QoE compared to a
benchmark algorithm without caching and a benchmark solution without UAVs.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1411.6326v1,2014-11-24T02:09:59Z,2014-11-24T02:09:59Z,Vision and Learning for Deliberative Monocular Cluttered Flight,"Cameras provide a rich source of information while being passive, cheap and
lightweight for small and medium Unmanned Aerial Vehicles (UAVs). In this work
we present the first implementation of receding horizon control, which is
widely used in ground vehicles, with monocular vision as the only sensing mode
for autonomous UAV flight in dense clutter. We make it feasible on UAVs via a
number of contributions: novel coupling of perception and control via relevant
and diverse, multiple interpretations of the scene around the robot, leveraging
recent advances in machine learning to showcase anytime budgeted cost-sensitive
feature selection, and fast non-linear regression for monocular depth
prediction. We empirically demonstrate the efficacy of our novel pipeline via
real world experiments of more than 2 kms through dense trees with a quadrotor
built from off-the-shelf parts. Moreover our pipeline is designed to combine
information from other modalities like stereo and lidar as well if available.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1405.1124v1,2014-05-06T02:05:04Z,2014-05-06T02:05:04Z,"An ASP-Based Architecture for Autonomous UAVs in Dynamic Environments:
  Progress Report","Traditional AI reasoning techniques have been used successfully in many
domains, including logistics, scheduling and game playing. This paper is part
of a project aimed at investigating how such techniques can be extended to
coordinate teams of unmanned aerial vehicles (UAVs) in dynamic environments.
Specifically challenging are real-world environments where UAVs and other
network-enabled devices must communicate to coordinate---and communication
actions are neither reliable nor free. Such network-centric environments are
common in military, public safety and commercial applications, yet most
research (even multi-agent planning) usually takes communications among
distributed agents as a given. We address this challenge by developing an agent
architecture and reasoning algorithms based on Answer Set Programming (ASP).
ASP has been chosen for this task because it enables high flexibility of
representation, both of knowledge and of reasoning tasks. Although ASP has been
used successfully in a number of applications, and ASP-based architectures have
been studied for about a decade, to the best of our knowledge this is the first
practical application of a complete ASP-based agent architecture. It is also
the first practical application of ASP involving a combination of centralized
reasoning, decentralized reasoning, execution monitoring, and reasoning about
network communications. This work has been empirically validated using a
distributed network-centric software evaluation testbed and the results provide
guidance to designers in how to understand and control intelligent systems that
operate in these environments.",arxiv,autonomous vehicle,'autonomous vehicle' AND 'machine learning' AND ('real-world' AND 'deploy')
