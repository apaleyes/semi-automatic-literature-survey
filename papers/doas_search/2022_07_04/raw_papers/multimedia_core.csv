id,datePublished,description,journals,publisher,title,doi,downloadUrl,database,query_name,query_value
350944360,2020-10-01T00:00:00,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided.Peer reviewe","[{'title': 'HardwareX', 'identifiers': ['issn:2468-0672', '2468-0672']}]",'Elsevier BV',Partially RepRapable automated open source bag valve mask-based ventilator,10.1016/j.ohx.2020.e00131,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
305078134,2020-03-25T09:38:57,"This is the author accepted manuscript. The final version is available from Springer Verlad via the DOI in this recordRecent advances in “developmental” approach (combining experimental study with computational modeling) of neural networks produce increasingly large data sets, in both complexity and size. This poses a significant challenge in analyzing, visualizing and understanding not only the spatial structure but also the behavior of such networks. This paper describes a virtual reality application for visualization of two biologically accurate computational models that model the anatomical structure of a neural network comprised of 1500 neurons and over 80,000 connections. The visualization enables a user to observe the complex spatiotemporal interplay between seven unique types of neurons culminating in an observable swimming pattern. We present a detailed description of the design approach for the virtual environment, based on a set of initial requirements, followed up by the implementation and optimization steps. Lastly, the results of a pilot usability study are being presented on how confident participants are in their ability to understand how the alternating firing pattern between the two sides of the tadpole’s body generates swimming motion","[{'title': 'Virtual Reality', 'identifiers': ['issn:1359-4338', '1359-4338']}]",'Springer Science and Business Media LLC',Tadpole VR: virtual reality visualization of a simulated tadpole spinal cord,10.1007/s10055-020-00431-z,https://core.ac.uk/download/305078134.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
328720905,2020-08-28T14:06:08,"The “time-varying loudness” (TVL) model of Glasberg and Moore calculates “instantaneous loudness” every 1 ms, and this is used to generate predictions of short-term loudness, the loudness of a short segment of sound, such as a word in a sentence, and of long-term loudness, the loudness of a longer segment of sound, such as a whole sentence. The calculation of instantaneous loudness is computationally intensive and real-time implementation of the TVL model is difficult. To speed up the computation, a deep neural network (DNN) was trained to predict instantaneous loudness using a large database of speech sounds and artificial sounds (tones alone and tones in white or pink noise), with the predictions of the TVL model as a reference (providing the “correct” answer, specifically the loudness level in phons). A multilayer perceptron with three hidden layers was found to be sufficient, with more complex DNN architecture not yielding higher accuracy. After training, the deviations between the predictions of the TVL model and the predictions of the DNN were typically less than 0.5 phons, even for types of sounds that were not used for training (music, rain, animal sounds, and washing machine). The DNN calculates instantaneous loudness over 100 times more quickly than the TVL model. Possible applications of the DNN are discussed",,Trends in Hearing,Development of a Deep Neural Network for Speeding Up a Model of Loudness for Time-Varying Sounds,10.17863/CAM.56818,https://core.ac.uk/download/328720905.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480333455,2021-08-01T00:00:00,"The advancement of the Internet of Things (IoT) brings new opportunities for collecting real-time data and deploying machine learning models. Nonetheless, an individual IoT device may not have adequate computing resources to train and deploy an entire learning model. At the same time, transmitting continuous real-time data to a central server with high computing resource incurs enormous communication costs and raises issues in data security and privacy. Federated learning, a distributed machine learning framework, is a promising solution to train machine learning models with resource-limited devices and edge servers. Yet, the majority of existing works assume an impractically synchronous parameter update manner with homogeneous IoT nodes under stable communication connections. In this paper, we develop an asynchronous federated learning scheme to improve training efficiency for heterogeneous IoT devices under unstable communication network. Particularly, we formulate an asynchronous federated learning model and develop a lightweight node selection algorithm to carry out learning tasks effectively. The proposed algorithm iteratively selects heterogeneous IoT nodes to participate in the global learning aggregation while considering their local computing resource and communication condition. Extensive experimental results demonstrate that our proposed asynchronous federated learning scheme outperforms the state-of-the-art schemes in various settings on independent and identically distributed (i.i.d.) and non-i.i.d. data distribution","[{'title': 'Digital Communications and Networks', 'identifiers': ['2352-8648', 'issn:2352-8648']}]",'Elsevier BV',Towards asynchronous federated learning for heterogeneous edge-powered internet of things,10.1016/j.dcan.2021.04.001,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480154226,2021-08-01T00:00:00,"Abstract This article proposes a new parallel performance model for different workloads of Spark Big Data applications running on Hadoop clusters. The proposed model can predict the runtime for generic workloads as a function of the number of executors, without necessarily knowing how the algorithms were implemented. For a certain problem size, it is shown that a model based on serial boundaries for a 2D arrangement of executors can fit the empirical data for various workloads. The empirical data was obtained from a real Hadoop cluster, using Spark and HiBench. The workloads used in this work were included WordCount, SVM, Kmeans, PageRank and Graph (Nweight). A particular runtime pattern emerged when adding more executors to run a job. For some workloads, the runtime was longer with more executors added. This phenomenon is predicted with the new model of parallelisation. The resulting equation from the model explains certain performance patterns that do not fit Amdahl’s law predictions, nor Gustafson’s equation. The results show that the proposed model achieved the best fit with all workloads and most of the data sizes, using the R-squared metric for the accuracy of the fitting of empirical data. The proposed model has advantages over machine learning models due to its simplicity, requiring a smaller number of experiments to fit the data. This is very useful to practitioners in the area of Big Data because they can predict runtime of specific applications by analysing the logs. In this work, the model is limited to changes in the number of executors for a fixed problem size","[{'title': 'Journal Of Big Data', 'identifiers': ['2196-1115', 'issn:2196-1115']}]",'Springer Science and Business Media LLC',A parallelization model for performance characterization of Spark Big Data jobs on Hadoop clusters,10.1186/s40537-021-00499-7,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
440882566,2021-01-01T00:00:00,"An axial piston pump fault diagnosis algorithm based on empirical wavelet transform (EWT) and one-dimensional convolutional neural network (1D-CNN) is presented. The fault vibration signals and pressure signals of axial piston pump are taken as the analysis objects. Firstly, the original signals are decomposed by EWT, and each signal component is screened and reconstructed according to the energy characteristics. Then, the time-domain features and the frequency-domain features of the denoised signal are extracted, and features of time domain and frequency domain are fused. Finally, the 1D-CNN model was deployed to the WISE-Platform as a Service (WISE-PaaS) cloud platform to realize the real-time fault diagnosis of axial piston pump based on the cloud platform. Compared with ensemble empirical mode decomposition (EEMD) and complementary ensemble empirical mode decomposition (CEEMD), the results show that the axial piston pump fault diagnosis algorithm based on EWT and 1D-CNN has higher fault identification accuracy","[{'title': 'Shock and Vibration', 'identifiers': ['issn:1070-9622', '1875-9203', '1070-9622', 'issn:1875-9203']}]",'Hindawi Limited',Hydraulic Pump Fault Diagnosis Method Based on EWT Decomposition Denoising and Deep Learning on Cloud Platform,10.1155/2021/6674351,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491039194,2021-01-01T00:00:00,"Recent advancements in the domain of Network Function Virtualization (NFV), and rollout of next-generation networks have necessitated the requirement for the upkeep of latency-critical application architectures in future networks and communications. While Cloud service providers recognize the evolving mission-critical requirements in latency sensitive verticals such as autonomous driving, multimedia, gaming, telecommunications, and virtual reality, there is a wide gap to bridge the Quality of Service (QoS) constraints for the end-user experience. Most latency-critical services are over-provisioned on all fronts to offer reliability, which is inefficient towards scalability in the long run. To address this, we propose a strategy to model frequent violations on the application level as a multi-output target to enable more complex decision-making in the management of virtualised communication networks. In this work, we utilize data from a real-world deployment to configure and draft a realistic set of Service Level Objectives (SLOs) for a voice based NFV application, and develop a deep neural network based multi-label classification methodology to identify and predict multiple categories of SLO breaches associated with an application state. With this, we aim to gain granular SLA and SLO violation insights, enabling us to study and mitigate their impact and inform precision in drafting proactive scaling policies. We further compare the performance against a set of multi-label compatible machine learning classifiers, and address class imbalance in a multi-label setup. We perform a comprehensive evaluation to assess the performance on example-based, label-based and ranking-based measures, and demonstrate the suitability of deep learning in such a use-case","[{'title': 'IEEE Open Journal of the Communications Society', 'identifiers': ['2644-125x', 'issn:2644-125X']}]",'Institute of Electrical and Electronics Engineers (IEEE)',A Deep Neural Network-Based Multi-Label Classifier for SLA Violation Prediction in a Latency Sensitive NFV Application,10.1109/OJCOMS.2021.3122844,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
441438944,2020-10-01T00:00:00,"A lack of sensory feedback often hinders minimally invasive operations. Although endoscopy has addressed this limitation to an extent, endovascular procedures such as angioplasty or stenting still face significant challenges. Sensors that rely on a clear line of sight cannot be used because it is unable to gather feedback in blood environments. During the stent deployment procedure, feedback on the deployed stent's state is critical because a partially open stent can affect the blood flow. Despite this, no robust and noninvasive clinical solutions that allow real‐time monitoring of the stent deployment exists. In recent years, radio frequency (RF)‐based sensors can detect the shape and material of an object that is hidden from the direct line of sight. Herein, the use of a 3D RF‐based imaging sensor and a novel Convolutional Neural Network (CNN) called StentNet is proposed for detecting the stent's state without a need for a clear line of sight. The StentNet achieves an overall accuracy of 90% in detecting the state of an occluded stent in the test dataset. Compared with an existing CNN model, the StentNet significantly outperforms the 3D LeNet in the evaluation metrics such as accuracy, precision, recall, and F1‐score","[{'title': 'Advanced Intelligent Systems', 'identifiers': ['2640-4567', 'issn:2640-4567']}]",'Wiley',Stent Deployment Detection Using Radio Frequency‐Based Sensor and Convolutional Neural Networks,10.1002/aisy.202000092,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
390009408,2020-02-20T00:00:00,"Methods of machine intelligence with training contribute their specifics to the creation and commissioning of a gaming system.One of the main problems is the need to anticipate the entire set of input situations and possible answers at the time of design and the impossibility of expanding their list withoutretraining. This leads to a narrowing of the possibility of their use in real gaming systems.  The object of research is the processes of creating and training game agents based on the evolutionary approaches of artificial intelligence. The purpose of the work is the development and justification of a formal model of a game agent based on machine learning methods, software implementation of the game process using neural networks and evolutionary optimization methods for multiple generations of game agent populations. To achieve this goal, the theoretical base, the existing research and development in the industry; a game scenario was designed, the main agents were identified, their main capabilities and expected behavior; training of game agents by various types of neural networks; development testing, quality assessment of behavior and decision-making by artificial intelligence using neural networks were performed; a comparative analysis of various types of neural networks, the proposed recommendations for their use for given conditions. To display the artificial neural network, the template components of the layer, neuron, and bridge were used. The created software module will allow game agents built using various neural networks to compete with each other (and not with a person, as in the normal game mode), and will reveal more prepared ones.  The scientific novelty of the study lies in the fact that a model of a game agent is formalized, based on machine learning methods. The results obtained in this work can be used in the development of video games built on the basis of artificial intelligence of game agents based on machine learning methods, as well as in other scientific studies.Методы машинного интеллекта с обучением вносят свою специфику к созданию и наладке игровой системы.Одна из главных проблем — это необходимость предвидения всего набора входных ситуаций и возможных ответов на моменте проектирования и невозможность расширения их списка без переобучения. Это приводит к сужению возможности их использования в реальных игровых системах.Объектом исследования являются процессы создания и обучения игровых агентов на основе эволюционных подходов искусственного интеллекта. Цель работы - разработка и обоснование формальной модели игрового агента, основанного на методах машинного обучения, программная реализация игрового процесса сприменением нейронных сетей и эволюционных методов оптимизации при множественных поколениях популяций игровых агентов.Для осуществления поставленной цели исследована теоретическая база, существующие исследования и разработки в отрасли; спроектирован игровой сценарий, определены основные агенты, их основные возможности и ожидаемое поведение;реализовано обучение игровых агентов различными типами нейронных сетей; выполнено тестирование разработок, оценка качества поведения и принятия решений искусственныминтеллектом с использованием нейронных сетей; проведен сравнительный анализ различных типов нейронных сетей, предлагаемых рекомендаций по их использованию для заданныхусловий. Для отображения искусственной нейронной сети использованы шаблонные компоненты слоя, нейрона и моста.Созданный программный модуль позволит игровым агентам, построенным с использованием различных нейронных сетей, соперничать друг с другом (а не с человеком,как в обычном режиме игры), позволит выявить более подготовленного из них. Научная новизна исследования заключается в том, что формализована модель игрового агента, в основе которой методы машинного обучения. Полученные в работе результаты могут быть использованы при разработке видеоигр, построенных на базе искусственного интеллекта игровых агентов, в основекоторых методы машинного обучения, а также в рамках других научных исследований.Методи машинного інтелекту з навчанням привносять свою специфіку до створення і налагодження ігрової системи.  Одна з головних проблем - це необхідність передбачення усього набору вхідних ситуацій і можливих відповідей на моменті проектування і неможливість розширення їх списку без перенавчання. Це призводить до звуження можливості їх використання у реальних ігрових системах. Об'єктом дослідження є процеси створення і навчання ігрових агентів на основі еволюційних підходів штучного інтелекту. Мета роботи - розробка і обґрунтування формальної моделі ігрового агенту, заснованої на методах машинного навчання, програмна реалізація ігрового процесу з застосуванням нейронних мереж та еволюційних методів оптимізації при множинних генераціях популяцій ігрових агентів. Для здійснення поставленої мети досліджена теоретична база, існуюча дослідження та розробки в галузі; спроектовано ігровий сценарій, визначені основні агенти, їх основні можливості та очікувана поведінка; реалізоване навчання ігрових агентів різними типами нейронних мереж; виконане тестування розробок, оцінка якості поведінки й прийняття рішень штучним інтелектом з використанням нейронних мереж; проведений порівняльний аналіз різних типів нейронних мереж, запропонування рекомендацій щодо їх використання для заданих умов. Для відображення штучної нейронної мережі використані шаблоні компоненти слою, нейрону і мосту. Створений програмний модуль дозволить ігровим агентам, побудованим з використанням різних нейронних мереж, суперничати один з іншим (а не з людиною, як у звичайному режимі гри), дозволить виявити більш підготовленого з них. Наукова новизна одержаних результатів полягає у тому, що формалізовано модель ігрового агенту, в основі якої методи машинного навчання. Отримані в роботі результати можуть бути використані при розробці відеоігор, побудованих на базі штучного інтелекту ігрових агентів, що гуртуються на методах машинного навчання, а також в рамках інших наукових досліджень",,ДВНЗ «Приазовський державний технічний університет»,ДОСЛІДЖЕННЯ ТА МОДЕЛЮВАННЯ ІГРОВОГО ПРОЦЕСУ НА БАЗІ МЕТОДІВ МАШИННОГО НАВЧАННЯ,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491329314,2021-08-11T19:44:40,"Advances in Deep Neural Network (DNN) techniques have revolutionized video analytics and unlocked the potential for querying
and mining video event patterns. This paper details GNOSIS, an
event processing platform to perform near-real-time video event
detection in a distributed setting. GNOSIS follows a serverless approach where its component acts as independent microservices
and can be deployed at multiple nodes. GNOSIS uses a declarative
query-driven approach where users can write customize queries
for spatiotemporal video event reasoning. The system converts the
incoming video streams into a continuous evolving graph stream
using machine learning (ML) and DNN models pipeline and applies graph matching for video event pattern detection. GNOSIS
can perform both stateful and stateless video event matching. To
improve Quality of Service (QoS), recent work in GNOSIS incorporates optimization techniques like adaptive scheduling, energy
efficiency, and content-driven windows. This paper demonstrates
the Occupational Health and Safety query use cases to show the
GNOSIS efficacyThis work was supported with the financial support of the Science
Foundation Ireland (SFI) grant SFI/12/RC/2289_P2.peer-reviewe","[{'title': 'Proceedings of the VLDB Endowment', 'identifiers': ['issn:2150-8097', '2150-8097']}]",'VLDB Endowment',Query-driven video event processing for the internet of multimedia things,10.14778/3476311.3476360,https://core.ac.uk/download/491329314.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
333567050,2020-01-01T00:00:00,"In recent year, embedded systems architectures and applications have gained a lot of interest, especially the possibility to add on-bard intelligence has fostered research in several directions, including not only smart IoT and cyber physical systems, but also hot topics such as accelerating deep learning. This special issue contains four papers dealing with architectures and design methodologies to support embedded intelligence, but also providing best practices and software support.



The paper “A Technologically Agnostic Framework for Cyber-Physical and IoT Processing-in-Memory-based Systems Simulation”, by Santos et al., aims to focus on Processing-In-Memory (PIM) as a solution for efficiently processing big data. In particular, this work presents a framework to simulate and automatically generate code for IoT PIM-based systems. Moreover, it proposes an high speed and energy efficient architecture for an IoT PIM system, able to compute a real image recognition application.



The paper “Recommender system implementations for embedded collaborative filtering applications”, by Pajuelo-Holguera et al., aims to propose a complete recommender system implemented on reconfigurable hardware with the purpose of testing on-chip, low-energy embedded collaborative filtering applications. The proposed approach solves any prediction problem based on collaborative filtering by using an off-line, highly-portable light computing environment. Moreover, this work exploits a custom, fine-grained parallel circuit for quick matrix multiplication with floating-point numbers.



The paper “SystemC-based Electronic System-Level Design Space Exploration Environment for Dedicated Heterogeneous Multi-Processor Systems”, by Pomante et al., faces the problem of the Electronic System-Level (ESL) HW/SW co-design of dedicated electronic digital systems based on heterogeneous multiprocessor architectures. In particular, the work presents a prototype SystemC -based environment that exploits a Design Space Exploration (DSE) approach able to suggest an HW/SW partitioning of the system specification and a mapping onto an automatically defined architecture.



The paper “A Fast and Scalable Architecture to Run Convolutional Neural Networks in Low Density FPGAs”, by Véstias et al., deals with efficient configurable architectures for Convolutional Neural Networks (CNN) inference targeting any density FPGAs. The architecture exploits fixed-point arithmetic and image batch to reduce computational, memory and memory bandwidth requirements without compromising network accuracy.



In conclusion, this special issue offers some timely contributions to advance the research of intelligent embedded systems by analyzing both architectures and applications. All of four papers are worth reading and will inspire more interesting ideas and research topics.



We sincerely express our gratitude to the Editor-in-Chief of the journal, Prof. Lech Jozwiak for all the valuable advice and constructive comments. We would also like to thank all the reviewers for their hard work on reviewing the papers. Last but not least, we appreciate all the authors who spent time and effort to respond to this call-for-papers. We truly hope that the readers will enjoy and benefit from this special issue",,'Elsevier BV',Guest Editorial: Special Issue on Intelligent Embedded Systems Architectures and Applications (INTESA),10.1016/j.micpro.2020.103187,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
482723796,2021-01-01T00:00:00,"Many emerging applications of nano-sized unmanned aerial vehicles (UAVs), with a few form-factor, revolve around safely interacting with humans in complex scenarios, for example, monitoring their activities or looking after people needing care. Such sophisticated autonomous functionality must be achieved while dealing with severe constraints in payload, battery, and power budget ( 100). In this work, we attack a complex task going from perception to control: to estimate and maintain the nano-UAV’s relative 3D pose with respect to a person while they freely move in the environment – a task that, to the best of our knowledge, has never previously been targeted with fully onboard computation on a nano-sized UAV. Our approach is centered around a novel vision-based deep neural network (DNN), called PULP-Frontnet, designed for deployment on top of a parallel ultra-low-power (PULP) processor aboard a nano-UAV. We present a vertically integrated approach starting from the DNN model design, training, and dataset augmentation down to 8-bit quantization and deployment in-field. PULP-Frontnet can operate in real-time (up to 135frame/), consuming less than 87 for processing at peak throughput and down to 0.43/frame in the most energy-efficient operating point. Field experiments demonstrate a closed-loop top-notch autonomous navigation capability, with a tiny 27-grams Crazyflie 2.1 nano-UAV. Compared against an ideal sensing setup, onboard pose inference yields excellent drone behavior in terms of median absolute errors, such as positional (onboard: 41, ideal: 26) and angular (onboard: 3.7, ideal: 4.1). We publicly release videos and the source code of our work.ISSN:2327-466",,'Institute of Electrical and Electronics Engineers (IEEE)',Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power Autonomous Flying Nano-UAVs,10.1109/jiot.2021.3091643,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
490727938,2021-09-01T00:00:00,"In recent years, there has been an immense amount of research into fall event detection. Generally, a fall event is defined as a situation in which a person unintentionally drops down onto a lower surface. It is crucial to detect the occurrence of fall events as early as possible so that any severe fall consequences can be minimized. Nonetheless, a fall event is a sporadic incidence that occurs seldomly that is falsely detected due to a wide range of fall conditions and situations. Therefore, an automated fall frame detection system, which is referred to as the SmartConvFall is proposed to detect the exact fall frame in a video sequence. It is crucial to know the exact fall frame as it dictates the response time of the system to administer an early treatment to reduce the fall’s negative consequences and related injuries. Henceforth, searching for the optimal training configurations is imperative to ensure the main goal of the SmartConvFall is achieved. The proposed SmartConvFall consists of two parts, which are object tracking and instantaneous fall frame detection modules that rely on deep learning representations. The first stage will track the object of interest using a fully convolutional neural network (CNN) tracker. Various training configurations such as optimizer, learning rate, mini-batch size, number of training samples, and region of interest are individually evaluated to determine the best configuration to produce the best tracker model. Meanwhile, the second module goal is to determine the exact instantaneous fall frame by modeling the continuous object trajectories using the Long Short-Term Memory (LSTM) network. Similarly, the LSTM model will undergo various training configurations that cover different types of features selection and the number of stacked layers. The exact instantaneous fall frame is determined using an assumption that a large movement difference with respect to the ground level along the vertical axis can be observed if a fall incident happened. The proposed SmartConvFall is a novel technique as most of the existing methods still relying on detection rather than the tracking module. The SmartConvFall outperforms the state-of-the-art trackers, namely TCNN and MDNET-N trackers, with the highest expected average overlap, robustness, and reliability metrics of 0.1619, 0.6323, and 0.7958, respectively. The SmartConvFall also managed to produce the lowest number of tracking failures with only 43 occasions. Moreover, a three-stack LSTM delivers the lowest mean error with approximately one second delay time in locating the exact instantaneous fall frame. Therefore, the proposed SmartConvFall has demonstrated its potential and suitability to be implemented for a real-time application that could help to avoid any crucial fall consequences such as death and internal bleeding if the early treatment can be administered","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',Optimal Training Configurations of a CNN-LSTM-Based Tracker for a Fall Frame Detection System,10.3390/s21196485,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
427515100,2021-04-01T00:00:00,"An End-Of-Turn Detection Module (EOTD-M) is an essential component of automatic Spoken Dialogue Systems. The capability of correctly detecting whether a user?s utterance has ended or not improves the accuracy in interpreting the meaning of the message and decreases the latency in the answer. Usually, in dialogue systems, an EOTD-M is coupled with an Automatic Speech Recognition Module (ASR-M) to transmit complete utterances to the Natural Language Understanding unit. Mistakes in the ASR-M transcription can have a strong effect on the performance of the EOTD-M. The actual extent of this effect depends on the particular combination of ASR M transcription errors and the sentence featurization techniques implemented as part of the EOTD-M. In this paper we investigate this important relationship for an EOTD-M based on semantic information and particular characteristics of the speakers (speech profiles). We introduce an Automatic Speech Recognition Simulator (ASR-SIM) that models different types of semantic mistakes in the ASR-M transcription as well as different speech profiles. We use the simulator to evaluate the sensitivity to ASR-M mistakes of a Long Short-Term Memory network classifier trained in EOTD with different featurization techniques. Our experiments reveal the different ways in which the performance of the model is influenced by the ASR-M errors. We corroborate that not only is the ASR-SIM useful to estimate the performance of an EOTD-M in customized noisy scenarios, but it can also be used to generate training datasets with the expected error rates of real working conditions, which leads to better performance.The research presented in this paper has been conducted as part of the project EMPATHIC that has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 769872.

Jose A. Lozano is partially supported by the Basque Government through the BERC 2018-2021 program, IT1244-19 and grant ""Artificial Intelligence in BCAM number EXP. 2019/00432'' and by the Spanish Ministry of Science, Innovation and Universities: BCAM Severo Ochoa accreditation SEV-2017-0718, TIN2016-78365-R and PID2019-104966GB-I00. And R. Santana acknowledge support by the Spanish Ministry of Science, Innovation and Universities (Project TIN201678365-R and PID2019-104966GB-I00), and the Basque Government (IT1244-19 and ELKARTEK Programs","[{'title': 'Engineering Applications of Artificial Intelligence', 'identifiers': ['1873-6769', 'issn:0952-1976', '0952-1976', 'issn:1873-6769']}]",'Elsevier BV',Analysis of the Sensitivity of the End-Of-Turn Detection Task to Errors Generated by the Automatic Speech Recognition Process,10.1016/j.engappai.2021.104189,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
289226841,2020,"The subject matter of the article is the process of developing information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles arises. The goal of the study is to development of the main points for information technology of automated detection and identification of stationary objects by unmanned aerial vehicles. The tasks to be solved are: the structural diagram of the preparatory stage of information technology for automated detection and identification of stationary objects is constructed; the structural diagram of the basic, additional and final stages of information technology automated detection and identification of fixed objects is constructed. General scientific and special methods of scientific knowledge are used. One of the most effective approaches to the recognition and identification of objects is an approach based on the use of deep learning methods. A new model of UAV motion is proposed based on image recognition methods. The methods of pattern recognition with application of neural networks are considered in detail in this work too. The following results are obtained. The developed information technology is implemented in four stages: preparatory, basic, additional and final. Each stage consists of separate procedures aimed at collecting, processing, storing and transmitting information during the flight UAV. Conclusions. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles is based on the knowledge-oriented representation of the stages of image processing of objects on digital aerial photographs on board the UAV. This allows to provide intelligent real-time data processing, changing UAV flight routes depending on the objects detected to improve the effectiveness of the search tasks. Further development of this information technology lies in the development of automated methods of planning UAV routes, automatic change of route parameters in flight processes (performance of a flight task), based on knowledge-oriented technologies. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles can become an element of intelligent decision support systems for the use of UAVs (teams of UAVs) to search for both stationary and dynamic objects.Предметом вивчення в статті є процес розробки інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами. Метою дослідження є розробка основних положень інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами. Задачі: побудова структурної схеми підготовчого етапу інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів; побудова структурної схеми основного, додаткового та заключного етапів інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів. Методологічною основою дослідження стали загальнонаукові та спеціальні методи наукового пізнання. Одним з найбільш ефективних підходів на шляху до виявлення та ідентифікації об'єктів є підхід, що базується на використанні методів глибокого навчання. На основі методів розпізнавання зображень запропонована нова модель руху. Застосовано методи розпізнавання образів із застосуванням нейронних мереж. Отримані такі результати. Розроблена інформаційна технологія реалізується в чотири етапи: підготовчий, основний, додатковий та заключний. Кожний етап складається з окремих процедур, направлених на збір, обробку, зберігання та передачу інформації в процесі польоту БПЛА. Висновки. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами базується на знанняорієнтованому представленні етапів обробки зображень об'єктів на цифрових аерофотознімках на борту безпілотного літального апарату. Це дозволяє забезпечити інтелектуальну обробку даних в режимі часу, наближеного до реального, змінювати маршрути польоту БПЛА в залежності від виявлених об'єктів для підвищення ефективності рішення задач пошуку. Подальший розвиток даної інформаційної технології полягає у розробці автоматизованих методів планування маршрутів руху БПЛА, автоматичної зміни параметрів маршруту в процесів польоту (виконанні польотного завдання), що засновується на знанняорієнтованих технологіях. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами може стати елементом інтелектуальної системи підтримки прийняття рішень на застосування БПЛА (колективів БПЛА) для пошуку як стаціонарних, так і динамічних об'єктів",,"Національний технічний університет ""Харківський політехнічний інститут""",Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами,10.20998/2522-9052.2020.1.01,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480201885,2021-08-01T00:00:00,"The increasing digitalization and advancement in information communication technologies has greatly changed how humans interact with digital information. Nowadays, it is not sufficient to only display relevant data in production activities, as the enormous amount of data generated from smart devices can overwhelm operators without being fully utilized. Operators often require extensive knowledge of the machines in use to make informed decisions during processes such as maintenance and production. To enable novice operators to access such knowledge, it is important to reinvent the way of interacting with digitally enhanced smart devices. In this research, a mobile augmented reality remote monitoring system is proposed to help operators with low knowledge and experience level comprehend digital twin data of a device and interact with the device. It analyses both historic logs as well as real-time data through a cloud server and enriches 2D data with 3D models and animations in the 3D physical space. A cloud-based machine learning algorithm is applied to transform learned knowledge into live presentations on a mobile device for users to interact with. A scaled-down case study is conducted using a tower crane model to demonstrate the potential benefits as well as implications when the system is deployed in industrial environments. This user study verifies that the proposed solution yields consistent measurable improvements for novice users in human-device interaction that is statistically significant","[{'title': 'Computers', 'identifiers': ['issn:2073-431X', '2073-431x']}]",'MDPI AG',An Integrated Mobile Augmented Reality Digital Twin Monitoring System,10.3390/computers10080099,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429686511,2020-03-25T00:00:00,"We present a deep learning-based multitask framework for joint 3D human pose estimation and action recognition from RGB sensors using simple cameras. The approach proceeds along two stages. In the first, a real-time 2D pose detector is run to determine the precise pixel location of important keypoints of the human body. A two-stream deep neural network is then designed and trained to map detected 2D keypoints into 3D poses. In the second stage, the Efficient Neural Architecture Search (ENAS) algorithm is deployed to find an optimal network architecture that is used for modeling the spatio-temporal evolution of the estimated 3D poses via an image-based intermediate representation and performing action recognition. Experiments on Human3.6M, MSR Action3D and SBU Kinect Interaction datasets verify the effectiveness of the proposed method on the targeted tasks. Moreover, we show that the method requires a low computational budget for training and inference. In particular, the experimental results show that by using a monocular RGB sensor, we can develop a 3D pose estimation and human action recognition approach that reaches the performance of RGB-depth sensors. This opens up many opportunities for leveraging RGB cameras (which are much cheaper than depth cameras and extensively deployed in private and public places) to build intelligent recognition systems.Sergio A. Velastin is grateful for funding received from the Universidad Carlos III de Madrid, the European Union’s Seventh Framework Programme for research, technological development and demonstrationunder grant agreement N 600371, el Ministerio de Economía, Industria y Competitividad (COFUND2013-51509) el Ministerio de Educación, Cultura y Deporte (CEI-15-17) and Banco Santander","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',A Unified Deep Framework for Joint 3D Pose Estimation and Action Recognition from a Single RGB Camera,10.3390/s20071825,https://core.ac.uk/download/429686511.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491193342,2022-01-31T01:52:07,"The history of medicine shows that myocardial infarction is one of the significant causes of death in humans. The rapid evolution in autonomous technologies, the rise of computer vision, and edge computing offers intriguing possibilities in healthcare monitoring systems. The major motivation of the work is to improve the survival rate during a cardiac arrest through an automatic emergency recognition system under ambient intelligence. We present a novel approach to chest pain and fall posture-based vital sign detection using an intelligence surveillance camera to address the emergency during myocardial infarction. A real-time embedded solution persuaded from ""edge AI""is implemented using the state-of-the-art convolution neural networks: single shot detector Inception V2, single shot detector MobileNet V2, and Internet of Things embedded GPU platform NVIDIA's Jetson Nano. The deep learning algorithm is implemented for 3000 indoor color image datasets: Nanyang Technological University Red Blue Green and Depth, NTU RGB + D dataset, and private RMS dataset. The research mainly pivots on two key factors in creating and training a CNN model to detect the vital signs and evaluate its performance metrics. We propose a model, which is cost-effective and consumes low power for onboard detection of vital signs of myocardial infarction and evaluated the metrics to achieve a mean average precision of 76.4% and an average recall of 80%","[{'title': 'Advances in Human-Computer Interaction', 'identifiers': ['issn:1687-5907', '1687-5893', '1687-5907', 'issn:1687-5893']}]",'Hindawi Limited',Edge Artificial Intelligence: Real-Time Noninvasive Technique for Vital Signs of Myocardial Infarction Recognition Using Jetson Nano,10.1155/2021/6483003,http://hdl.handle.net/10453/153906,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
337352464,2020-09-30T00:00:00,"Acquiring data for neural network training is an expensive and labour-intensive task, especially when such data isdifficult to access. This article proposes the use of 3D Blender graphics software as a tool to automatically generatesynthetic image data on the example of price labels. Using the fastai library, price label classifiers were trained ona set of synthetic data, which were compared with classifiers trained on a real data set. The comparison of the resultsshowed that it is possible to use Blender to generate synthetic data. This allows for a significant acceleration of thedata acquisition process and consequently, the learning process of neural networks",,'Politechnika Lubelska',Blender as a tool for generating synthetic data,10.35784/jcsi.2086,https://core.ac.uk/download/337352464.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287167378,2020-01-22T00:00:00,"In this article, I review the concept of algorithmic generative and interactive music and discuss the advantages and challenges of its implementation in videogames. Excessive repetition caused by low interactivity in music sequences through gameplay has been tackled primarily by using random or sequential containers, coupled with overlapping rules and adaptive mix parameters, as demonstrated in the Dynamic Music Units in Audiokinetic’s Wwise middleware. This approach provides a higher variety through re-combinatorial properties of music tracks and also a responsive and interactive music stream. However, it mainly uses prerecorded music sequences that reappear and are easy to recognize throughout gameplay. Generative principles such as single-seed design have been occasionally applied in game music scoring to generate material. Some of them are complemented with rules and are assigned to sections with low emotional requirements, but support for real-time interaction in gameplay situations, although desirable, is rarely found.While algorithmic note-by-note generation can offer interactive flexibility and infinite diversity, it poses significant challenges such as achieving human-like performativity and producing a distinctive narrative style through measurable parameters or program arguments. Starting with music generation, I examine conceptual implementations and technical challenges of algorithmic composition studies that use Markov models, a-life/evolutionary music, generative grammars, agents, and artificial neural networks/deep learning. For each model, I evaluate rule-based strategies for interactive music transformation using parameters provided by contextual gameplay situations. Finally, I propose a compositional tool design based in modular instances of algorithmic music generation, featuring stylistic interactive control in connection with an audio engine rendering system",,'Aarhus University Library',Algorithmic interactive music generation in videogames: A modular design for adaptive automatic music scoring,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
524551330,2022-03-04T00:00:00,"The aim of this study was to investigate and assess parents' and teachers' views of the home-visiting program as a method of early childhood education during the COVID-19 outbreak. Exploratory qualitative research employed as methods of inquiry. Twelve resource persons were interviewed (3 teachers and 9 parents). The data revealed, parents and teachers perceive that using home visits has a number of benefits and drawbacks. The benefits are as follows: 1) more effective than online; 2) make learning materials easy for children to understand; 3) pique children's interest and excitement for learning; and 4) eliminate the need for parents to assist their children with their tasks. Meanwhile, the downsides include the following: 1) it was inconvenient for parents because they were needed to entertain teachers and other children; 2) some pupils couldn't study because home visits were far away from their homes.; 3) additional media and learning activities preparation; 4) additional time and energy was wasted; and 5) the risk of exposure to COVID-19 was increased. The researchers recommend that additional study be conducted with a larger and more diverse sample size in order to obtain a more complete picture of this issue. Keywords: COVID-19, early childhood learning, emergency remote learning, preschool, kindergarten References Aliyar, R., Gelli, A., &amp; Hamdani, S. H. (2015). A review of nutritional guidelines and menu compositions for school feeding programs in 12 countries. Frontiers in Public Health, 3, 148.  Anderson-McNamee, J. K., &amp; Bailey, S. J. (2010). The importance of play in early childhood development. Montana State University Extention, 4(10), 1–4. Asanov, I., Flores, F., McKenzie, D., Mensmann, M., &amp; Schulte, M. (2021). Remote-learning, time-use, and mental health of Ecuadorian high-school students during the COVID-19 quarantine. World Development, 138, 105225.  Auger, K. A., Shah, S. S., Richardson, T., Hartley, D., Hall, M., Warniment, A., Timmons, K., Bosse, D., Ferris, S. A., Brady, P. W., Schondelmeyer, A. C., &amp; Thomson, J. E. (2020). Association Between Statewide School Closure and COVID-19 Incidence and Mortality in the US. JAMA, 324(9), 859. https://doi.org/10.1001/jama.2020.14348 Azevedo, J. P., Hasan, A., Goldemberg, D., Geven, K., &amp; Iqbal, S. A. (2021). Simulating the potential impacts of COVID-19 school closures on schooling and learning outcomes: A set of global estimates. The World Bank Research Observer, 36(1), 1–40.  Azevedo, J. P., Hasan, A., Goldemberg, D., Iqbal, S. A., &amp; Geven, K. (2020). Simulating the Potential Impacts of COVID-19 School Closures on Schooling and Learning Outcomes: A Set of Global Estimates. The World Bank. https://doi.org/10.1596/1813-9450-9284 Baker, J. (2020). Experts call for major intervention to help struggling students. Available On-Line at Https://Www. Smh. Com. Au/National/Experts-Call-for-Major-Intervention-to-Help-Strugglingstudents-20200519-P54uii. Html.  Briscese, G., Lacetera, N., Macis, M., &amp; Tonin, M. (2020). Compliance with COVID-19 Social-Distancing Measures in Italy: The Role of Expectations and Duration. https://doi.org/10.3386/w26916 Budianti, A., &amp; Melati, P. A. (2020). Implementasi Kunjungan Rumah Dalam Pembelajaran Pada Masa Pandemi. Academica: Journal of Multidisciplinary Studies, 4(2), 267–278.  Chatterji, P., &amp; Li, Y. (2021). Effects of COVID-19 on school enrollment. Economics of Education Review, 83, 102128.  Chaudron, S., Beutel, M. E., Donoso Navarrete, V., Dreier, M., Fletcher-Watson, B., Heikkilä, A. S., Kontríková, V., Korkeamäki, R. v, Livingstone, S., &amp; Marsh, J. (2015). Young children (0-8) and digital technology: A qualitative exploratory study across seven countries. JRC; ISPRA, Italy.  Commodari, E. (2013). Preschool teacher attachment, school readiness and risk of learning difficulties. Early Childhood Research Quarterly, 28(1), 123–133. https://doi.org/https://doi.org/10.1016/j.ecresq.2012.03.004 Cooper, D. R., Schindler, P. S., &amp; Sun, J. (2006). Business research methods (Vol. 9). Mcgraw-hill New York.  Dayal, H. C., &amp; Tiko, L. (2020). When are we going to have the real school? A case study of early childhood education and care teachers’ experiences surrounding education during the COVID-19 pandemic. Australasian Journal of Early Childhood, 45(4), 336–347.  DeMulder, E. K., Denham, S., Schmidt, M., &amp; Mitchell, J. (2000). Q-sort assessment of attachment security during the preschool years: links from home to school. Developmental Psychology, 36(2), 274.  Dias, M. J. A., Almodóvar, M., Atiles, J. T., Vargas, A. C., &amp; Zúñiga León, I. M. (2020). Rising to the Challenge: Innovative early childhood teachers adapt to the COVID-19 era. Childhood Education, 96(6), 38–45. https://doi.org/10.1080/00094056.2020.1846385 Dikti. (2018). Indonesia Higher Education Statistical Year Book 2018 (Vol. 15, Issue 21). https://doi.org/10.1002/chem.200802548 Dini, J. (2021). Problematika pembelajaran daring dan luring anak usia dini bagi guru dan orang tua di masa pandemi Covid 19. Jurnal Obsesi: Jurnal Pendidikan Anak Usia Dini, 5(2), 1825–1836.  Dong, C., Cao, S., &amp; Li, H. (2020). Young children’s online learning during COVID-19 pandemic: Chinese parents’ beliefs and attitudes. Children and Youth Services Review, 118, 105440.  Dwita, K. D., Anggraeni, A. I., &amp; Haryadi, H. (2018). Pengaruh home visit dan motivasi belajar terhadap hasil belajar siswa di SDIT Harapan Bunda Purwokerto. Jurnal Ekonomi, Bisnis, Dan Akuntansi, 20(1) . Earn, D. J. D. (2012). Effects of School Closure on Incidence of Pandemic Influenza in Alberta, Canada. Annals of Internal Medicine, 156(3), 173. https://doi.org/10.7326/0003-4819-156-3-201202070-00005 FAIZAH, A. B., Sunaryo, I., &amp; AUD, M. P. (2021). Efektivitas Pembelajaran Home Visit Pada Pendidikan Aud Dimasa Pandemi Covid 19 Di TK IT Khoiruummah Sukoharjo Tahun Ajaran 2020-2021. Universitas Muhammadiyah Surakarta.  Filmer, D., Rogers, H., Angrist, N., &amp; Sabarwal, S. (2020). Learning-adjusted years of schooling (LAYS): Defining a new macro measure of education. Economics of Education Review, 77, 101971.  Fumanelli, L., Ajelli, M., Merler, S., Ferguson, N. M., &amp; Cauchemez, S. (2016). Model-Based Comprehensive Analysis of School Closure Policies for Mitigating Influenza Epidemics and Pandemics. PLOS Computational Biology, 12(1), e1004681. https://doi.org/10.1371/journal.pcbi.1004681 Grek, S., &amp; Landri, P. (2021). Education in Europe and the COVID-19 Pandemic. In European Educational Research Journal (Vol. 20, Issue 4, pp. 393–402). SAGE Publications Sage UK: London, England.  Herrenkohl, T. I., Scott, D., Higgins, D. J., Klika, J. B., &amp; Lonne, B. (2021). How COVID-19 is placing vulnerable children at risk and why we need a different approach to child welfare. Child Maltreatment, 26(1), 9–16.  Ibda, H., &amp; Laeli, D. N. (2021). Hasil Belajar Siswa Saat Pandemi Covid-19 Melalui Home Visit Studi di MI Salafiyah Kranggan. At-Thullab: Jurnal Pendidikan Guru Madrasah Ibtidaiyah, 5(1), 12–22.  Kakwani, N. (1980). On a class of poverty measures. Econometrica: Journal of the Econometric Society, 437–446.  Kangas, J., Harju-Luukkainen, H., Brotherus, A., Kuusisto, A., &amp; Gearon, L. (2019). Playing to learn in Finland: Early childhood curricular and operational context. Policification of Early Childhood Education and Care Early Childhood Education in the 21st Century Volume III.  Katz, C., &amp; Fallon, B. (2021). Protecting children from maltreatment during COVID-19: Struggling to see children and their families through the lockdowns. Child Abuse &amp; Neglect.  Kim, J. (2020). Learning and teaching online during Covid-19: Experiences of student teachers in an early childhood education practicum. International Journal of Early Childhood, 52(2), 145–158.  Lau, E. Y. H., &amp; Lee, K. (2021). Parents’ Views on Young Children’s Distance Learning and Screen Time During COVID-19 Class Suspension in Hong Kong. Early Education and Development, 32(6), 863–880. https://doi.org/10.1080/10409289.2020.1843925 Lennox, J., Reuge, N., &amp; Benavides, F. (2021). UNICEF’s lessons learned from the education response to the COVID-19 crisis and reflections on the implications for education policy. International Journal of Educational Development, 85, 102429.  Listyawati, B. W., Hanif, M., &amp; Anggraheni, I. (2021). Problematika Pembelajaran Home Visit di Raudhatul Athfal Darul Falah Karangploso Malang. Jurnal Dewantara, 3(1), 76–81.  Malhotra, A., &amp; Elnakib, S. (2021). 20 years of the evidence base on what works to prevent child marriage: A systematic review. Journal of Adolescent Health, 68(5), 847–862.  Mashburn, A. J., Pianta, R. C., Hamre, B. K., Downer, J. T., Barbarin, O. A., Bryant, D., Burchinal, M., Early, D. M., &amp; Howes, C. (2008). Measures of classroom quality in prekindergarten and children’s development of academic, language, and social skills. Child Development, 79(3), 732–749.  Mastoah, I., &amp; MS, Z. (2020). Kendala Orang Tua Dalam Mendampingi Anak Belajar Pada Masa Covid 19 Di Kota Serang. As-Sibyan: Jurnal Pendidikan Anak Usia Dini, 5(2), 121–128.  Mayurasakorn, K., Pinsawas, B., Mongkolsucharitkul, P., Sranacharoenpong, K., &amp; Damapong, S. (2020). School closure, COVID‐19 and lunch programme: Unprecedented undernutrition crisis in low‐middle income countries. Journal of Paediatrics and Child Health, 56(7), 1013–1017.  Miles, M. B., Huberman, M. a, &amp; Saldana, J. (2014). Drawing and Verying Conclusions. Qualitative Data Analysis: A Methods Sourcebook. https://doi.org/January 11, 2016 Miller, J. C., Danon, L., O’Hagan, J. J., Goldstein, E., Lajous, M., &amp; Lipsitch, M. (2010). Student Behavior during a School Closure Caused by Pandemic Influenza A/H1N1. PLoS ONE, 5(5), e10425. https://doi.org/10.1371/journal.pone.0010425 Ministry of Education and Culture. (2019). The 2019/2020 Early Childhood Education Statis. https://doi.org/10.1017/CBO9781107415324.004 Ministry of Education and Culture. (2020a). 2019/2020 Junior High School Statistic. http://statistik.data.kemdikbud.go.id/index.php/page/smp Ministry of Education and Culture. (2020b). 2019/2020 Primary Education Statistics. http://statistik.data.kemdikbud.go.id/index.php/page/sd Ministry of Education and Culture. (2020c). 2019/2020 Senior High School Statistic. http://statistik.data.kemdikbud.go.id/index.php/page/sma Ministry of Education and Culture. (2020d). 2019/2020 Vocational School Statistic. http://statistik.data.kemdikbud.go.id/index.php/page/smk Misirli, O., &amp; Ergulec, F. (2021). Emergency remote teaching during the COVID-19 pandemic: Parents experiences and perspectives. Education and Information Technologies, 26(6), 6699–6718.  Mohsi, M. (2019). Langghar, Kophung Dan Bhaqaf Konservasi Kebudayaan Khazanah Keislaman Madura. Sabda: Jurnal Kajian Kebudayaan, 14(1), 14–20.  Mokoginta, L., &amp; Nurdiyani, N. (2020). Program Home Visit di Pos-PAUD Bintang Kecil, Semarang: Solusi Menaati Aturan Physical Distancing. E-Prosiding Pascasarjana Universitas Negeri Gorontalo, 43–48.  Mulyaningsih, E., &amp; Iskandar, R. (2021). Efektivitas Belajar Anak Usia Dini pada PAUD Miftahul Ulum di Masa Pandemi COVID-19. Jurnal Pendidikan Indonesia, 2(9), 1512–1521.  Munastiwi, E. (2020). Colorful Online Learning Problem of Early Childhood Education During the Covid-19 Pandemic. Al-Ta Lim Journal, 27(3), 227–235.  Munastiwi, E., &amp; Puryono, S. (2021). Unprepared management decreases education performance in kindergartens during Covid-19 pandemic. Heliyon, 7(5), e07138. https://doi.org/https://doi.org/10.1016/j.heliyon.2021.e07138 Nasution, S. T., &amp; Sutapa, P. (2020). Strategi Guru dalam Menstimulasi Keterampilan Motorik AUD Pada Era Pandemi Covid 19. Jurnal Obsesi: Jurnal Pendidikan Anak Usia Dini, 5(2), 1313–1324.  Nguyen, L. H. (2021). Calculating the impact of COVID-19 pandemic on child abuse and neglect in the US. Child Abuse &amp; Neglect, 118, 105136.  Nilsson, M., Ferholt, B., &amp; Lecusay, R. (2018). ‘The playing-exploring child’: Reconceptualizing the relationship between play and learning in early childhood education. Contemporary Issues in Early Childhood, 19(3), 231–245.  Nirmala, B., &amp; Annuar, H. (2020). Home Visit: Strategi PAUD dari Rumah bagi Guru di Daerah 3T pada Masa Pandemi Covid-19. Jurnal Obsesi: Jurnal Pendidikan Anak Usia Dini, 5(2), 1052–1062.  Nofianti, R. (2020). Peran Orangtua Dalam Pendampingan Pembelajaran Daring Anak Usia Dini di Masa Pandemik Covid 19 Di Tk Islam Ibnu Qoyyim. Jurnal Abdi Ilmu, 13(2), 19–30.  Nurrahmah, N. (2020). Tari Paddupa Khas Masyarakat Suku Bugis Makassar dalam Penyambutan Tamu (Tinjaun Nilai-Nilai Budaya Islam). Universitas Islam Negeri Alauddin Makassar.  Oberholzer, S. (2021). Education as humanitarian response. Graduate Institute of International and Development Studies, Global  Obidike, N. D., &amp; Enemuo, J. O. (2013). The role of teachers of young children in ensuring developmentally appropriate practice in early childhood education curriculum implementation. Journal of Emerging Trends in Educational Research and Policy Studies, 4(5), 821.  Owusu-Fordjour, C., Koomson, C. K., &amp; Hanson, D. (2020). The impact of Covid-19 on learning-the perspective of the Ghanaian student. European Journal of Education Studies.  Palaiologou, I. (2016). Teachers’ dispositions towards the role of digital devices in play-based pedagogy in early childhood education. Early Years, 36(3), 305–321. Punch, K. F. (2013). Introduction to social research: Quantitative and qualitative approaches. sage.  Purbo, O. W. (2017). Digital Indonesia: Connectivity and Divergence. In E. Jurriens &amp; R. Tapsell (Eds.), Narrowing the digital divide (pp. 75–92). ISEAS-Yusof Ishak Institute.  Putra, A. Y. (2020). Strategi pembelajaran motorik kasar pada anak usia dini era pandemi covid-19. Golden Age: Jurnal Ilmiah Tumbuh Kembang Anak Usia Dini, 5(4), 159–166.  Qualls, N., Levitt, A., Kanade, N., Wright-Jegede, N., Dopson, S., Biggerstaff, M., Reed, C., Uzicanin, A., Levitt, A., Dopson, S., Frank, M., Holloway, R., Koonin, L., Rasmussen, S., Redd, S., de la Motte Hurst, C., Kanade, N., Qualls, N., Rainey, J., Reed, C. (2017). Community Mitigation Guidelines to Prevent Pandemic Influenza — United States, 2017. MMWR. Recommendations and Reports, 66(1), 1–34. https://doi.org/10.15585/mmwr.rr6601a1 Rahiem, M. D. H. (2018). Faith and Disaster Resilience: What can Islamic Education Teach Children to Help Prepare Them for A Disaster? TARBIYA: Journal of Education in Muslim Society, 5(2), 178–192. https://doi.org/10.15408/tjems.v5i2.9964 Rahiem, M. D. H. (2020a). The Emergency Remote Learning Experience of University Students in Indonesia amidst the COVID-19 Crisis. International Journal of Learning, Teaching and Educational Research, 19(6), 1–26. https://doi.org/10.26803/ijlter.19.6.1 Rahiem, M. D. H. (2020b). The Emergency Remote Learning Experience of University Students in Indonesia amidst the COVID-19 Crisis. International Journal of Learning, Teaching and Educational Research, 19(6), 1–26. https://doi.org/10.26803/ijlter.19.6.1 Rahiem, M. D. H. (2021a). COVID-19 and Surge of child marriages: A Phenomena in Nusa Tenggara Barat, Indonesia. Child Abuse &amp; Neglect, 105168. https://doi.org/https://doi.org/10.1016/j.chiabu.2021.105168 Rahiem, M. D. H. (2021b). Indonesian University Students’ Likes and Dislikes about Emergency Remote Learning during the COVID-19 Pandemic. Asian Journal of University Education; Vol 17 No 1 (2021): AJUE Vol 17 No 1 January 2021. https://doi.org/10.24191/ajue.v17i1.11525 Rahiem, M. D. H. (2021c). Storytelling in early childhood education: Time to go digital. International Journal of Child Care and Education Policy, 15(1), 4. https://doi.org/10.1186/s40723-021-00081-x Rahiem, M. D. H., &amp; Husna, K. (2020). Buku Cerita Bergambar Untuk Pembelajaran Mitigasi Bencana Gunung Meletus Bagi Anak Usia Dini. PAUD Lectura: Jurnal Pendidikan Anak Usia Dini, 3(2), 54–67. https://doi.org/https://doi.org/10.31849/paud-lectura.v3i02.3974 Rahiem, M. D. H., Krauss, S. E., &amp; Ersing, R. (2021). Perceived Consequences of Extended Social Isolation on Mental Well-Being: Narratives from Indonesian University Students during the COVID-19 Pandemic. In International Journal of Environmental Research and Public Health (Vol. 18, Issue 19). https://doi.org/10.3390/ijerph181910489 Rahiem, M. D. H., &amp; Widiastuti, F. (2020). Pembelajaran Mitigasi Bencana Alam Gempa Bumi untuk Anak Usia Dini melalui Buku Bacaan Bergambar. Jurnal Obsesi : Jurnal Pendidikan Anak Usia Dini, 5(1), 36. https://doi.org/10.31004/obsesi.v5i1.519 Rahman, T., &amp; Sharma, U. (2021). A simulation of COVID-19 school closure impact on student learning in Bangladesh.  Ransford, C. R., Greenberg, M. T., Domitrovich, C. E., Small, M., &amp; Jacobson, L. (2009). The Role of Teachers’ Psychological Experiences and Perceptions of Curriculum Supports on the Implementation of a Social and Emotional Learning Curriculum. School Psychology Review, 38(4).  Reuge, N., Jenkins, R., Brossard, M., Soobrayan, B., Mizunoya, S., Ackers, J., Jones, L., &amp; Taulo, W. G. (2021). Education response to COVID 19 pandemic, a special issue proposed by UNICEF: Editorial review. International Journal of Educational Development, 87, 102485.  Robson, C. (2002). Real world research: A resource for social scientists and practitioner-researchers. Wiley-Blackwell.  Saldaña, J. (2009). An Introduction to Codes and Coding. The Coding Manual for Qualitative Researchers. https://doi.org/10.1519/JSC.0b013e3181ddfd0a Saldaña, J. (2016). The Coding Manual for Qualitative Researchers (No. 14). Sage.  Samuelsson, I. P., &amp; Carlsson, M. A. (2008). The playing learning child: Towards a pedagogy of early childhood. Scandinavian Journal of Educational Research, 52(6), 623–641.  Saputri, I. (2019). Konsep Penafsiran Hadits Memuliakan Tamu Terhadap Perilaku Masyarakat Di Kecamatan Besulutu Kabupaten Konawe. Jurnal Ushuluddin Adab Dan Dakwah, 2(1), 42–64.  Sar, B. K., &amp; Bledsoe, L. K. (2021). Willingness to intervene in child abuse and neglect: An exploratory study. Child Abuse Review, 30(3), 226–238.  Sari, H. N., Maryani, K., &amp; Rusdiyani, I. (2022). Pola Asupan Gizi Anak Usia Dini Pada Masa Pandemi COVID-19. As-Sibyan: Jurnal Pendidikan Anak Usia Dini, 7, 51–64.  Setyowahyudi, R., &amp; Ferdiyanti, T. (2020). Keterampilan guru PAUD Kabupaten Ponorogo dalam memberikan penguatan selama masa pandemi COVID-19. Jurnal Golden Age, 4(01), 99–111.  Shinde, V., Jagtap, N., &amp; Shukla, H. (2021). Deep Learning based Face-Mask and Shield Detection. 2021 International Conference on Computational Intelligence and Computing Applications (ICCICA), 1–4.  Singer, E. (2013). Play and playfulness, basic features of early childhood education. European Early Childhood Education Research Journal, 21(2), 172–184.  Sserwanja, Q., Kawuki, J., &amp; Kim, J. H. (2021). Increased child abuse in Uganda amidst Covid‐19 pandemic. Journal of Paediatrics and Child Health, 57(2), 188–191. Suhendro, E. (2020). Strategi Pembelajaran Pendidikan Anak Usia Dini di Masa Pandemi Covid-19. Golden Age: Jurnal Ilmiah Tumbuh Kembang Anak Usia Dini, 5(3), 133–140.  Sujarwoto, S., &amp; Tampubolon, G. (2016). Spatial inequality and the Internet divide in Indonesia 2010–2012. Telecommunications Policy, 40(7), 602–616. https://doi.org/10.1016/j.telpol.2015.08.008 Tarricone, P., Mestan, K., &amp; Teo, I. (2021). Building resilient education systems: A rapid review of the education in emergencies literature.  Toran, M., Sak, R., Xu, Y., Şahin-Sak, İ. T., &amp; Yu, Y. (2021). Parents and children during the COVID-19 quarantine process: Experiences from Turkey and China. Journal of Early Childhood Research, 19(1), 21–39.  Tsolou, O., Babalis, T., &amp; Tsoli, K. (2021). The Impact of COVID-19 Pandemic on Education: Social Exclusion and Dropping out of School. Creative Education, 12(03), 529.  UNESCO. (2020). COVID-19 Impact on Education. https://en.unesco.org/covid19 Wang, D., &amp; Fawzi, W. W. (2020). Impacts of school feeding on educational and health outcomes of school-age children and adolescents in low-and middle-income countries: protocol for a systematic review and meta-analysis. Systematic Reviews, 9(1), 1–8.  Wendling, J.-M., Fabacher, T., Pébaÿ, P.-P., Cosperec, I., &amp; Rochoy, M. (2021). Experimental efficacy of the face shield and the mask against emitted and potentially received particles. International Journal of Environmental Research and Public Health, 18(4), 1942.  Yukich, J., Worges, M., Gage, A. J., Hotchkiss, D. R., Preaux, A., Murray, C., &amp; Cappa, C. (2021). Projecting the impact of the COVID-19 pandemic on child marriage. Journal of Adolescent Health, 69(6), S23–S30.  Zylke, J. W., &amp; Bauchner, H. (2020). Mortality and Morbidity. JAMA, 324(5), 458. https://doi.org/10.1001/jama.2020.11761&nbsp",,'Lembaga Penelitian dan Pengabdian kepada Masyarakat (LP2M) Universitas Islam Negeri (UIN) Sultan Maulana Hasanuddin Banten',Home Visit  Sebagai Metode Pembelajaran Anak Usia Dini Pada Masa COVID-19,10.32678/as-sibyan.v7i1.5710,https://core.ac.uk/download/524551330.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
441225381,2020-02-01T00:00:00,"This article attempts to represent social technologies as a research area of sociology and a practical field. Social technologies (as technology of government of social processes, agents, organizations, communities) are the complex social phenomenon. Nowadays — the days of radical technological changes (Internet of things, Big Data, virtual and augmented reality, blockchain technology, artificial intelligence, machine learning, robotization, transition to a shared economy), redefining a wide range of social fields and generating principally new social regimes ad configurations — the social technologies acquire almost universal character. The exploration and practices (design, implementation, modification) of social technologies mean the work with the widest possible range of social phenomena, deploying on very different spatial and time scales and in various social spheres. At the same time, there remains a need for conceptual and theoretical clarification of “social technologies” on the other hand, and for their institualization as research and practical fields (with its own standards, human and organizational resources and so on). The department of social technologies was opened in Moscow State University establishment on Faculty of Sociology in 2013 to address that need. The article outlines the whole number of research directions of this department since its establishment, through to the present day","[{'title': 'Moscow State University Bulletin Series 18 Sociology and Political Science', 'identifiers': ['issn:1029-3736', 'issn:2541-8769', '1029-3736', '2541-8769']}]","'Faculty of Sociology, Lomonosov Moscow State University'",Social technologies as research field and instrument of social transformations,10.24290/1029-3736-2019-25-4-77-94,https://core.ac.uk/download/441225381.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479627403,2021-08-01T00:00:00,"Seed purity directly affects the quality of seed breeding and subsequent processing products. Seed sorting based on machine vision provides an effective solution to this problem. The deep learning technology, particularly convolutional neural networks (CNNs), have exhibited impressive performance in image recognition and classification, and have been proven applicable in seed sorting. However the huge computational complexity and massive storage requirements make it a great challenge to deploy them in real-time applications, especially on devices with limited resources. In this study, a rapid and highly efficient lightweight CNN based on visual attention, namely SeedSortNet, is proposed for seed sorting. First, a dual-branch lightweight feature extraction module Shield-block is elaborately designed by performing identity mapping, spatial transformation at higher dimensions and different receptive field modeling, and thus it can alleviate information loss and effectively characterize the multi-scale feature while utilizing fewer parameters and lower computational complexity. In the down-sampling layer, the traditional MaxPool is replaced as MaxBlurPool to improve the shift-invariant of the network. Also, an extremely lightweight sub-feature space attention module (SFSAM) is presented to selectively emphasize fine-grained features and suppress the interference of complex backgrounds. Experimental results show that SeedSortNet achieves the accuracy rates of 97.33% and 99.56% on the maize seed dataset and sunflower seed dataset, respectively, and outperforms the mainstream lightweight networks (MobileNetv2, ShuffleNetv2, etc.) at similar computational costs, with only 0.400M parameters (vs. 4.06M, 5.40M)","[{'title': 'PeerJ Computer Science', 'identifiers': ['2376-5992', 'issn:2376-5992']}]",'PeerJ',SeedSortNet: a rapid and highly effificient lightweight CNN based on visual attention for seed sorting,10.7717/peerj-cs.639,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429033224,2021-01-01T00:00:00,"Artificial intelligence (AI), machine learning (ML) and big data are consistently called upon to analyze and comprehend many facets of modern daily life. AI and ML in particular are widely used in animal husbandry to monitor both the animals and environment around the clock, which leads to a better understanding of animal behavior and distress, disease control and prevention, and effective business decisions for the farmer. One particularly promising area that advances upon AI is digital twin technology, which is currently used to improve efficiencies and reduce costs across multiple industries and sectors. In contrast to a model, a digital twin is a digital replica of a real-world entity that is kept current with a constant influx of data. The application of digital twins within the livestock farming sector is the next frontier and has the potential to be used to improve large-scale precision livestock farming practices, machinery and equipment usage, and the health and well-being of a wide variety of farm animals. The mental and emotional states of animals can be monitored using recognition technology that examines facial features, such as ear postures and eye white regions. Used with modeling, simulation and augmented reality technologies, digital twins can help farmers to build more energy-efficient housing structures, predict heat cycles for breeding, discourage negative behaviors of livestock, and potentially much more. As with all disruptive technological advances, the implementation of digital twin technology will demand a thorough cost and benefit analysis of individual farms. Our goal in this review is to assess the progress toward the use of digital twin technology in livestock farming, with the goal of revolutionizing animal husbandry in the future. View Full-Tex",,'MDPI AG',Digital Twins in Livestock Farming,10.3390/ani11041008,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479182827,2021-06-01T00:00:00,"IEEE 802.11 (Wi-Fi) is one of the technologies that provides high performance with a high density of connected devices to support emerging demanding services, such as virtual and augmented reality. However, in highly dense deployments, Wi-Fi performance is severely affected by interference. This problem is even worse in new standards, such as 802.11n/ac, where new features such as Channel Bonding (CB) are introduced to increase network capacity but at the cost of using wider spectrum channels. Finding the best channel assignment in dense deployments under dynamic environments with CB is challenging, given its combinatorial nature. Therefore, the use of analytical or system models to predict Wi-Fi performance after potential changes (e.g., dynamic channel selection with CB, and the deployment of new devices) are not suitable, due to either low accuracy or high computational cost. This paper presents a novel, data-driven approach to speed up this process, using a Graph Neural Network (GNN) model that exploits the information carried in the deployment’s topology and the intricate wireless interactions to predict Wi-Fi performance with high accuracy. The evaluation results show that preserving the graph structure in the learning process obtains a 64% increase versus a naive approach, and around 55% compared to other Machine Learning (ML) approaches when using all training features","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',ATARI: A Graph Convolutional Neural Network Approach for Performance Prediction in Next-Generation WLANs,10.3390/s21134321,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395079680,2021-01-01T00:00:00,"Since years, the number of seniors increases while, at the same time, we observe a diminution of the potential support ratio. In order to overcome this limitation, solutions emerged, such as smart homes and wearable devices. Smart homes integrate sensors, actuators, and artificial intelligence to assist seniors in their everyday life. One of the objectives is to recognize the activities of everyday life. This recognition aims to provide the right assistance at the right moment and gives some autonomy to seniors. However, it is a complex task (a significant quantity of different sensors, hardware implementation), and the number of solutions (combinations between approaches, for example, video-based HAR and wearable sensors-based HAR) that exist is important. In this paper, we propose to perform the activity recognition from three ultra-wideband (UWB) radars, deep learning models, and a voting system. Also, all the experiments have been conducted in a real apartment and are composed of 15 different activities. The presented solution is simple compared to the literature since we exploit only one type of sensor. Finally, we obtained promising results with our approach. Indeed, the classification rate reaches 90% and more in some cases",,'Elsevier BV',Recognizing activities of daily living from UWB radars and deep learning,10.1016/j.eswa.2020.113994,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
487586037,2021-09-24T00:00:00,"International audienceIn Transport Mode Detection, a great diversity of methodologies exist according to the choice made on sensors, preprocessing, model used, etc. In this domain, the comparisons between each option are not always complete. Experiments on a public, real-life dataset are led here to evaluate carefully each of the choices that were made, with a specific emphasis on data fusion methods. Our most surprising finding is that none of the methods we implemented from the literature is better than a simple late fusion. Two important decisions are the choice of a sensor and the choice of a representation for the data: we found that using 2D convolutions on spectrograms with a logarithmic axis for the frequencies was better than 1-dimensional temporal representations. To foster the research on deep learning with embedded inertial sensors, we release our code along with our publication",,'Springer Science and Business Media LLC',Data Fusion for Deep Learning on Transport Mode Detection: A Case Study,10.1007/978-3-030-80568-5_12,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323366399,2020-06-01T00:00:00,"La colorización es la asignación de posibles colores a los objetos que componen la imagen en escala de grises de forma que correspondan a los reales. La colorización plantea un reto específico en visión computarizada para la reconstrucción de imágenes y video, tales como, la búsqueda de una fiel aproximación, la saturación correcta de colores escogidos y áreas no desfasadas.
La coloración  automatizada de imágenes ha sido abordada desde varios puntos, uno de esos es Image Analogies, en donde se aplican operaciones y filtros para abstraer e integrar características de unas imágenes a otra, lo cual requiere intervención humana para la escogencia de imágenes de referencia con características similares a la imagen que se desea colorear(Gupta, R.K., Chia, A.Y.S., Rajan, D., Ng, E.S., Zhiyong, H, 2012). En intentos de mejorar la respuesta al problema se han presentado soluciones utilizando redes neuronales convolucionales (CNN) y se comienza a reducir la necesidad de semejanza directa entre las imágenes de entrenamiento y las de prueba, se plantea entonces como un problema de predicción del espacio de color (Zhang, Richard, Phillip Isola, and Alexei A., 2016).
Proponemos el diseño e implementación de una herramienta de restauración de imágenes históricas de la ciudad de Barranquilla realizándoles un coloreado por medio de herramientas de computer vision. Cayena, nuestra aplicación web presenta una galería de imágenes de la historia de Barranquilla y de forma interactiva permite realizarles el coloreado. Para aplicar el coloreado la aplicación genera una petición a nuestra API que que aloja el servicio y ejecuta el proceso de coloración; este proceso de coloración consiste en el procesamiento de la imagen para que tenga el tamaño adecuado, la transformación a escala de grises  y la posterior ejecución, por medio del marco de trabajo  de aprendizaje profundo Caffe, de un modelo de CNN pre-entrenado que predice los posibles colores reales de la imagen.Having a grayscale image as an input, colorization is the assignation of the possible colors to the objects composing the image so that the colors are similar to the real ones. Colorization poses a specific challenge on the field of computerized vision for image and video restoration, such as reliable approximation, an adequate saturation of the chosen colors and no mismatched areas.
Different approaches have been made to assess automated colorization of images, such as Image Analogies, where filters and operations are applied to obtain and integrate characterics from some images to other, which requires human intervention to choose reference images with similar characteristics to those of the image to be colorized (Gupta, R.K., Chia, A.Y.S., Rajan, D., Ng, E.S., Zhiyong, H, 2012). In attempts to get better outcomes, convolutional neural networks(CNN) have been presented, increasingly getting rid of the need of the direct image resemblance between training and test images, posing the problem of colorization as one of space color prediction (Zhang, Richard, Phillip Isola, and Alexei A., 2016).
We propose the design and implementation of a image restoration tool for historical images of the city of Barranquilla by applying a colorization using computer vision techniques. Cayena, our web application displays a gallery of historical images of Barranquilla and interactively allows to colorize them. In order to apply the colorization the application makes a request to our API that hosts the service and executes the colorization process; this colorization process consists in the processing of the image so it has the right size and the verification to make sure it is a grayscale image and transform it if it is not, and the subsequent execution of an pre trained CNN model using the Deep Learning framework ‘Caffe’ which predicts the possible real colors of the image",,"Barranquilla, Universidad del Norte, 2020",Automated colorization using Computer Vision tools for restoring historical images of the city of Barranquilla,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
342671590,2020-11-01T00:00:00,"Intelligent fault diagnosis methods have replaced time consuming and unreliable human analysis, increasing anomaly detection efficiency. Deep learning models are clear cut techniques for this purpose. This paper’s fundamental purpose is to automatically detect leakage in tanks during production with more reliability than a manual inspection, a common practice in industries. This research proposes an inspection system to predict tank leakage using hydrophone sensor data and deep learning algorithms after production. In this paper, leak detection was investigated using an experimental setup consisting of a plastic tank immersed underwater. Three different techniques for this purpose were implemented and compared with each other, including fast Fourier transform (FFT), wavelet transforms, and time-domain features, all of which are followed with 1D convolution neural network (1D-CNN). Applying FFT and converting the signal to a 1D image followed by 1D-CNN showed better results than other methods. Experimental results demonstrate the effectiveness and the superiority of the proposed methodology for detecting real-time leakage inaccuracy",,'MDPI AG',Deep Learning Model for Industrial Leakage Detection Using Acoustic Emission Signal,10.3390/informatics7040049,https://core.ac.uk/download/342671590.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478033462,2022-02-01T00:00:00,"Nowadays, the number of road accident in Malaysia is increasing expeditiously. One of the ways to reduce the number of road accident is through the development of the advanced driving assistance system (ADAS) by professional engineers. Several ADAS system has been proposed by taking into consideration the delay tolerance and the accuracy of the system itself. In this work, a traffic sign recognition system has been developed to increase the safety of the road users by installing the system inside the car for driver’s awareness. TensorFlow algorithm has been considered in this work for object recognition through machine learning due to its high accuracy. The algorithm is embedded in the Raspberry Pi 3 for processing and analysis to detect the traffic sign from the real-time video recording from Raspberry Pi camera NoIR. This work aims to study the accuracy, delay and reliability of the developed system using a Raspberry Pi 3 processor considering several scenarios related to the state of the environment and the condition of the traffic signs. A real-time testbed implementation has been conducted considering twenty different traffic signs and the results show that the system has more than 90% accuracy and is reliable with an acceptable delay",,'Institute of Advanced Engineering and Science',Real-time traffic sign detection and recognition using Raspberry Pi,10.11591/ijece.v12i1.pp331-338,https://core.ac.uk/download/478033462.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
372560235,2020-01-01T00:00:00,"In the past few years, Convolutional Neural Networks (CNNs) have seen a massive improvement, outperforming other visual recognition algorithms. Since they are playing an increasingly important role in fields such as face recognition, augmented reality or autonomous driving, there is the growing need for a fast and efficient system to perform the redundant and heavy computations of CNNs. This trend led researchers towards heterogeneous systems provided with hardware accelerators, such as GPUs and FPGAs. The vast majority of CNNs is implemented with floating-point parameters and operations, but from research, it has emerged that high classification accuracy can be obtained also by reducing the floating-point activations and weights to binary values. This context is well suitable for FPGAs, that are known to stand out in terms of performance when dealing with binary operations, as demonstrated in FINN, the state-of-the-art framework for building Binarized Neural Network (BNN) accelerators on FPGAs. In this paper, we propose a framework that extends FINN to a distributed scenario, enabling BNNs implementation on embedded multi-FPGA systems",,'Institute of Electrical and Electronics Engineers (IEEE)',BNNsplit: Binarized Neural Networks for embedded distributed FPGA-based computing systems,10.23919/DATE48585.2020.9116220,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479314553,2021-01-01T00:00:00,"One of the biggest challenges hindering a table tennis robot to play as well as a professional player is the ball&#x2019;s accurate motion control, which depends on various factors such as the incoming ball&#x2019;s position, linear, spin velocity and so forth. Unfortunately, some factors are almost impossible to be directly measured in real practice, such as the ball&#x2019;s spin velocity, which is difficult to be estimated from vision due to the little texture on the ball&#x2019;s surface. To perform accurate motion control in table tennis, this study proposes to learn a ball stroke strategy to guarantee desirable &#x201C;target landing location&#x201D; and the &#x201C;over-net height&#x201D; which are two key indicators to evaluate the quality of a stroke. To overcome the spin velocity challenge, a deep reinforcement learning (DRL) based stroke approach is developed with the spin velocity estimation capability, through which the system can predict the relative spin velocity of the ball and stroke it back accurately by iteratively learning from the robot-environment interactions. To pre-train the DRL-based strategy effectively, this paper develops a virtual table tennis playing environment, through which various simulated data can be collected. For the real table tennis robot implementation, experimental results demonstrate the superior performance of the proposed control strategy compared to that of the traditional aerodynamics-based method with an average landing error around 80mm and the landing-within-table probability higher than 70&#x0025;","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Ball Motion Control in the Table Tennis Robot System Using Time-Series Deep Reinforcement Learning,10.1109/ACCESS.2021.3093340,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479315740,2021-06-01T00:00:00,"Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) methods are a promising approach to solving complex tasks in the real world with physical robots. In this paper, we compare several reinforcement  learning (Q-Learning, SARSA) and deep reinforcement learning (Deep Q-Network, Deep Sarsa) methods for a task aimed at achieving a specific goal using robotics arm UR3. The main optimization problem of this experiment is to find the best solution for each RL/DRL scenario and minimize the Euclidean distance accuracy error and smooth the resulting path by the Bézier spline method. The simulation and real word applications are controlled by the Robot Operating System (ROS). The learning environment is implemented using the OpenAI Gym library which uses the RVIZ simulation tool and the Gazebo 3D modeling tool for dynamics and kinematics","[{'title': 'MENDEL', 'identifiers': ['1803-3814', '2571-3701', 'issn:2571-3701', 'issn:1803-3814']}]",'Brno University of Technology',Comparison of Multiple Reinforcement Learning and Deep Reinforcement Learning Methods for the Task Aimed at Achieving the Goal,10.13164/mendel.2021.1.001,https://core.ac.uk/download/479315740.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
343225290,2020-10-29T00:00:00,"Future mobile networks will enable the massive deployment of mobile multimedia applications anytime and anywhere. In this context, mobility management schemes, such as handover and proactive multimedia service migration, will be essential to improve network performance. In this article, we propose a proactive mobility management approach based on group user trajectory prediction. Specifically, we introduce a mobile user trajectory prediction algorithm by combining the Long-Short Term Memory networks (LSTM) with Reinforcement Learning (RL) to automate the model training procedure. We further develop a group user trajectory predictor to reduce prediction calculation overheads of users with similar movement patterns. To validate the impact of the proposed mobility management approach, we present a virtual reality (VR) service migration scheme built on the top of the proactive handover mechanism that benefits from trajectory predictions. Experiment results validate our predictor’s outstanding accuracy and its impacts on enhancing handover and service migration performance to provide quality of service assurance",,'Institute of Electrical and Electronics Engineers (IEEE)',Mobility Management with Transferable Reinforcement Learning Trajectory Prediction,10.1109/TNSM.2020.3034482,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
430688355,2021-01-01T00:00:00,"Background and objectiveDynamic muscle fascicle length measurements through B-mode ultrasound have become popular for the non-invasive physiological insights they provide regarding musculoskeletal structure-function. However, current practices typically require time consuming post-processing to track muscle length changes from B-mode images. A real-time measurement tool would not only save processing time but would also help pave the way toward closed-loop applications based on feedback signals driven by in vivo muscle length change patterns. In this paper, we benchmark an approach that combines traditional machine learning (ML) models with B-mode ultrasound recordings to obtain muscle fascicle length changes in real-time. To gauge the utility of this framework for 'in-the-loop' applications, we evaluate accuracy of the extracted muscle length change signals against time-series' derived from a standard, post-hoc automated tracking algorithm.MethodsWe collected B-mode ultrasound data from the soleus muscle of six participants performing five defined ankle motion tasks: (a) seated, constrained ankle plantarflexion, (b) seated, free ankle dorsi/plantarflexion, (c) weight-bearing, calf raises (d) walking, and then a (e) mix. We trained machine learning (ML) models by pairing muscle fascicle lengths obtained from standardized automated tracking software (UltraTrack) with the respective B-mode ultrasound image input to the tracker, frame-by-frame. Then we conducted hyperparameter optimizations for five different ML models using a grid search to find the best performing parameters for a combination of high correlation and low RMSE between ML and UltraTrack processed muscle fascicle length trajectories. Finally, using the global best model/hyperparameter settings, we comprehensively evaluated training-testing outcomes within subject (i.e., train and test on same subject), cross subject (i.e., train on one subject, test on another) and within/direct cross task (i.e., train and test on same subject, but different task).ResultsSupport vector machine (SVM) was the best performing model with an average r = 0.70 ±0.34 and average RMSE = 2.86 ±2.55 mm across all direct training conditions and average r = 0.65 ±0.35 and average RMSE = 3.28 ±2.64 mm when optimized for all cross-participant conditions. Comparisons between ML vs. UltraTrack (i.e., ground truth) tracked muscle fascicle length versus time data indicated that ML tracked images reliably capture the salient qualitative features in ground truth length change data, even when correlation values are on the lower end. Furthermore, in the direct training, calf raises condition, which is most comparable to previous studies validating automated tracking performance during isolated contractions on a dynamometer, our ML approach yielded 0.90 average correlation, in line with other accepted tracking methods in the field.ConclusionsBy combining B-mode ultrasound and classical ML models, we demonstrate it is possible to achieve real-time tracking of human soleus muscle fascicles across a number of functionally relevant contractile conditions. This novel sensing modality paves the way for muscle physiology in-the-loop applications that could be used to modify gait via biofeedback or unlock novel wearable device control techniques that could enable restored or augmented locomotion performance","[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",'Public Library of Science (PLoS)',Machine learning to extract muscle fascicle length changes from dynamic ultrasound images in real-time.,10.1371/journal.pone.0246611,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479360462,2021-06-01T00:00:00,"Introduction. An important part of an automotive unmanned vehicle (UV) control system is the environment analysis module. This module is based on various types of sensors, e.g. video cameras, lidars and radars. The development of computer and video technologies makes it possible to implement an environment analysis module using a single video camera as a sensor. This approach is expected to reduce the cost of the entire module. The main task in video image processing is to analyse the environment as a 3D scene. The 3D trajectory of an object, which takes into account its dimensions, angle of view and movement vector, as well as the vehicle pose in a video image, provides sufficient information for assessing the real interaction of objects. A basis for constructing a 3D trajectory is vehicle pose estimation.Aim. To develop an automatic method for estimating vehicle pose based on video data analysis from a single video camera.Materials and methods. An automatic method for vehicle pose estimation from a video image was proposed based on a cascade approach. The method includes vehicle detection, key points determination, segmentation and vehicle pose estimation. Vehicle detection and determination of its key points were resolved via a neural network. The segmentation of a vehicle video image and its mask preparation were implemented by transforming it into a polar coordinate system and searching for the outer contour using graph theory.Results. The estimation of vehicle pose was implemented by matching the Fourier image of vehicle mask signatures and the templates obtained based on 3D models. The correctness of the obtained vehicle pose and angle of view estimation was confirmed by experiments based on the proposed method. The vehicle pose estimation had an accuracy of 89 % on an open Carvana image dataset.Conclusion. A new approach for vehicle pose estimation was proposed, involving the transition from end-to-end learning of neural networks to resolve several problems at once, e.g., localization, classification, segmentation, and angle of view, towards cascade analysis of information. The accuracy level of end-to-end learning requires large sets of representative data, which complicates the scalability of solutions for road environments in Russia. The proposed method makes it possible to estimate the vehicle pose with a high accuracy level, at the same time as involving no large costs for manual data annotation and training","[{'title': 'Journal of the Russian Universities Radioelectronics', 'identifiers': ['issn:1993-8985', '1993-8985', 'issn:2658-4794', '2658-4794']}]",'St. Petersburg Electrotechnical University LETI',Method for Automatic Determination of a 3D Trajectory of Vehicles in a Video Image,10.32603/1993-8985-2021-24-3-49-59,https://core.ac.uk/download/479360462.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
346367817,2020-09-01T00:00:00,"In this paper, mm-Pose, a novel approach to detect and track human skeletons in real-time using an mmWave radar, is proposed. To the best of the authors' knowledge, this is the first method to detect >15 distinct skeletal joints using mmWave radar reflection signals. The proposed method would find several applications in traffic monitoring systems, autonomous vehicles, patient monitoring systems and defense forces to detect and track human skeleton for effective and preventive decision making in real-time. The use of radar makes the system operationally robust to scene lighting and adverse weather conditions. The reflected radar point cloud in range, azimuth and elevation are first resolved and projected in Range-Azimuth and Range-Elevation planes. A novel low-size high-resolution radar-to-image representation is also presented, that overcomes the sparsity in traditional point cloud data and offers significant reduction in the subsequent machine learning architecture. The RGB channels were assigned with the normalized values of range, elevation/azimuth and the power level of the reflection signals for each of the points. A forked CNN architecture was used to predict the real-world position of the skeletal joints in 3-D space, using the radar-to-image representation. The proposed method was tested for a single human scenario for four primary motions, (i) Walking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging both arms to validate accurate predictions for motion in range, azimuth and elevation. The detailed methodology, implementation, challenges, and validation results are presented.University of ArizonaThis item from the UA Faculty Publications collection is made available by the University of Arizona with support from the University of Arizona Libraries. If you have questions, please contact us at repository@u.library.arizona.edu","[{'title': 'IEEE Sensors Journal', 'identifiers': ['issn:2379-9153', '2379-9153', '1530-437x', 'issn:1530-437X']}]",'Institute of Electrical and Electronics Engineers (IEEE)',mm-Pose: Real-Time Human Skeletal Posture Estimation Using mmWave Radars and CNNs,10.1109/jsen.2020.2991741,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479017238,2021-09-01T00:00:00,"Socially assistive robots (SAR) hold significant potential to assist older adults and people with dementia in human engagement and clinical contexts by supporting mental health and independence at home. While SAR research has recently experienced prolific growth, long-term trust, clinical translation and patient benefit remain immature. Affective human-robot interactions are unresolved and the deployment of robots with conversational abilities is fundamental for robustness and humanrobot engagement. In this paper, we review the state of the art within the past two decades, design trends, and current applications of conversational affective SAR for ageing and dementia support. A horizon scanning of AI voice technology for healthcare, including ubiquitous smart speakers, is further introduced to address current gaps inhibiting home use. We discuss the role of user-centred approaches in the design of voice systems, including the capacity to handle communication breakdowns for effective use by target populations. We summarise the state of development in interactions using speech and natural language processing, which forms a baseline for longitudinal health monitoring and cognitive assessment. Drawing from this foundation, we identify open challenges and propose future directions to advance conversational affective social robots for: 1) user engagement, 2) deployment in real-world settings, and 3) clinical translation","[{'title': 'IEEE Transactions on Cognitive and Developmental Systems', 'identifiers': ['2379-8920', 'issn:2379-8920']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Conversational affective social robots for ageing and dementia support,10.1109/tcds.2021.3115228,https://core.ac.uk/download/479017238.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
428920125,2020-03-23T00:00:00,"This paper is the first step of an attempt to equip social robots with emotion recognition capabilities comparable to those of humans. Most of the recent deep learning solutions for facial expression recognition under-perform when deployed in Human-Robot-Interaction scenarios, although they are capable of breaking records on the most varied benchmarks on facial expression recognition. The main reason for that we believe is that they are using techniques that are developed for recognition of static pictures, while in real-life scenarios, we infer emotions from intervals of expression. Utilising on the feature of CNN to form regions of interests that are similar to human gaze patterns, we use recordings from human-gaze patterns to train such a network to infer facial emotions from 3 seconds video footage of humans expressing 6 basic emotions",,'Association for Computing Machinery (ACM)',Improving emotional expression recognition of robots using regions of interest from human data,10.1145/3371382.3378359,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
481998521,2021-01-01T00:00:00,"Density is one of the auxiliary indicators for judging the internal quality of tomatoes. However, in the density measurement process, it is often difficult to measure the volume of the tomatoes accurately. To solve this problem, first, this study proposed a novel tomato volume measurement method based on machine vision. The proposed method uses machine vision to measure the geometric feature parameters of tomatoes, and inputs them into the LabVIEW software to convert the calculation of irregular tomato volume into a BP neural network (BPNN) model that calculates the plane pixel area and pixel volume, thereby realizing the modeling, analysis, design and simulation of tomato volume; then, an experimental platform was constructed to compare the results of the proposed method with the results predicted by the 3D wireframe model. When the number of photos taken was n = 5, the average error of the tomato volume prediction results of the 3D wireframe model was 8.22%, and the highest accuracy was 92.93%; while the average error of the tomato volume prediction results of the BPNN was 4.60%, and the highest accuracy was 95.60%. Increasing the number of orthographic projections can improve the accuracy of the model, but when the number of photos was more than 7, the accuracy improvement was not significant. Also, increasing the number of nodes in the hidden layer can improve the accuracy of the model, however, considering that increasing the number of nodes will increase the host operating cost, it is suggested to choose a node number of 12 for the tomato volume measurement. In the end, the final experimental results showed that the proposed method achieved better measurement results. However, the volume measured by the two models is larger than the real volume of tomatoes. For this reason, we added a correction coefficient to the BPNN model, and its highest accuracy has increased by 1.3%",,'Mechanical Engineering Faculty in Slavonski Brod',A Novel Tomato Volume Measurement Method based on Machine Vision,10.17559/TV-20210616091307,https://core.ac.uk/download/481998521.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
475700206,2021-08-12T09:43:26,"Advances in Deep Neural Network (DNN) techniques have revolutionized video analytics and unlocked the potential for querying
and mining video event patterns. This paper details GNOSIS, an
event processing platform to perform near-real-time video event
detection in a distributed setting. GNOSIS follows a serverless approach where its component acts as independent microservices
and can be deployed at multiple nodes. GNOSIS uses a declarative
query-driven approach where users can write customize queries
for spatiotemporal video event reasoning. The system converts the
incoming video streams into a continuous evolving graph stream
using machine learning (ML) and DNN models pipeline and applies graph matching for video event pattern detection. GNOSIS
can perform both stateful and stateless video event matching. To
improve Quality of Service (QoS), recent work in GNOSIS incorporates optimization techniques like adaptive scheduling, energy
efficiency, and content-driven windows. This paper demonstrates
the Occupational Health and Safety query use cases to show the
GNOSIS efficacyThis work was supported with the financial support of the Science
Foundation Ireland (SFI) grant SFI/12/RC/2289_P2",,'VLDB Endowment',Query-driven video event processing for the internet of multimedia things,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
362229766,2020-11-09T00:00:00,"International audienceThis paper describes an ""all-in-one"" solution for the real-time recognition of users' mental workloads in virtual reality through the cus-tomization of a commercial HMD with physiological sensors. First, we describe the hardware and software solution employed to build the system. Second, we detail the machine learning methods used for the automatic recognition of the users' mental workload, which are based on the well-known Random Forest algorithm. In order to gather data to train the system, we conducted an extensive user study with 75 participants using a VR flight simulator to induce different levels of mental workload. In contrast to previous works which label the data based on a standardized task (e.g. n-back task) or on a pre-defined task-difficulty, participants were asked about their perceived mental workload level along the experiment. With the data collected, we were able to train the system in order to classify four different levels of mental workload with an accuracy up to 65%. In addition, we discuss the role of the signal normalization procedures, the contribution of the different physiological signals on the recognition accuracy and compare the results obtained with the sensors embedded in the HMD with commercial grade systems. Preliminary results show our pipeline is able to recognize mental workload in real-time. Taken together, our results suggest that such all-in-one approach, with physiological sensors directly embedded in the HMD, is a promising path for VR applications in which the real-time or off-line estimation of Mental Workload assessment is beneficial",,HAL CCSD,Towards Real-Time Recognition of Users' Mental Workload Using Integrated Physiological Sensors Into a VR HMD,,https://core.ac.uk/download/362229766.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429396766,2021-01-01T00:00:00,"In this paper, to solve the problem of slow design of arts and crafts and to improve design efficiency and aesthetics, the existing big data and 3D technology are used to conduct an in-depth analysis of the optimization of the rapid design system of arts and crafts machine salt baking. In the system requirement analysis, the functional modules of this system are identified as nine functional modules such as design terminology management system and external information import function according to the actual usage requirements. In the system design, the overall structure design, database design, and functional module design of the system are comprehensively elaborated, and the key issues such as 3D display and home layout generation algorithm based on reinforcement learning are analyzed and designed. In the implementation part of the system, the overall construction of the system and the composition of functional modules are introduced in detail and the main functional modules of the system are presented with interface diagrams. In the system implementation part, the overall system construction and functional module composition are introduced in detail, the main functional modules of the system are shown with interface diagrams, codes, and algorithms, and the specific implementation process of 3D display and soft layout algorithms are also explained in detail. The process of Surface Mount Technology (SMT) big data processing and analysis is designed, and the design of SMT production line data collection scheme and real-time data processing architecture is completed. Based on the characteristics of SMT production line data, the K-means algorithm is used to detect data outliers and verify the accuracy of the method; also, the Spark-based association rule printing parameter recommendation model is designed, and the efficiency of the Apriori algorithm is significantly improved by parallelization","[{'title': 'Complexity', 'identifiers': ['issn:1099-0526', 'issn:1076-2787', '1076-2787', '1099-0526']}]",'Hindawi Limited',Optimization of the Rapid Design System for Arts and Crafts Based on Big Data and 3D Technology,10.1155/2021/7906047,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286449774,2020-01-20T07:13:04,"Текст статьи не публикуется в открытом доступе в соответствии с политикой журнала.Currently, one of the key processes in the higher education is the “transition to a digital platform”, i.e.  the development and adoption of digital technologies, solutions and products in the educational process. In the future, several clusters of digital technology in the higher education will be deployed on the basis of data analytics, digital models, artificial intelligence, augmented and virtual reality, and the blockchain.
The study addresses the following objectives: 1) development of a structured “map” of digital technology for higher education; 2) assessment of the extent of development and use of digital technologies in the higher education sphere at present (in developed countries and in a separate region of the Russian Federation – Krasnoyarsk Krai); 3) assessment of the prospects for the development  and adoption of digital technologies by 2035 (in developed countries and in Krasnoyarsk Krai).
The following research methods were used: 1) a conceptual analysis of scientific publications, forecasts, foresight-studies and analytical reports; 2) expert interviews, 3) a questionnaire based survey (32 experts – researchers, professors, representatives of government and consulting companies).
The following core groups of digital technologies are designated: 1) digital solutions for defining the personal goals of education, educational navigation, building a project for an individual educational trajectory; 2) adaptive educational environment for the implementation of an individual educational trajectory; 3) digital solutions for learning activities support; monitoring the results of education; solutions for educational logistics; 4) digital solutions for assessment and certification (personal identification and competency assessment); 5) digital solutions for career support and lifelong education; 6) digital solutions for building and supporting university communities (including teachers, students, graduates, university partners); 7) digital solutions for monitoring and modeling the dynamics of competences at the population level. Each group includes 3–12 technologies, so it is possible to build a detailed “map” of digital technologies for higher education sphere.
According to the experts, most of the major groups of digital technologies for education are currently (2018) in the stage of “working prototypes and pilot products” and “locally used products” (in the developed countries of the world). The exceptions are “digital solutions for monitoring and modeling the dynamics of competencies at the population level,” which are still at the “research and development” stage. By 2030, all technologies of major groups will reach the stage of “mass market products” and “local market products”.
The structure of assessments of the digital technology application in the present and prospects for adoption by 2030 for Krasnoyarsk Krai is generally similar to the structure of assessments for developed countries of the world, but the magnitudes of the estimates are much smaller. The result reflects the “catching up” nature of the development of digital technology in the education sphere in the region. The basic strategy of digitalization of higher education in the region will be the transfer of ready-made solutions that have already found wide application in the developed countries of the world",,'IATED Academy',Digital technology in higher education: situation analysis and prospects assessment (on the example of Krasnoyarsk krai),10.21125/inted.2019.1392,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286449775,2020-01-20T07:13:05,"Currently, one of the key processes in the higher education is the “transition to a digital platform”, i.e. the development and adoption of digital technologies, solutions and products in the educational process. In the future, several clusters of digital technology in the higher education will be deployed on the basis of data analytics, digital models, artificial intelligence, augmented and virtual reality, and the blockchain.
The study addresses the following objectives: 1) development of a structured “map” of digital technology for higher education; 2) assessment of the extent of development and use of digital technologies in the higher education sphere at present (in developed countries and in a separate region of the Russian Federation – Krasnoyarsk Krai); 3) assessment of the prospects for the development and adoption of digital technologies by 2035 (in developed countries and in Krasnoyarsk Krai).
The following research methods were used: 1) a conceptual analysis of scientific publications, forecasts, foresight-studies and analytical reports; 2) expert interviews, 3) a questionnaire based survey (32 experts – researchers, professors, representatives of government and consulting companies).
The following core groups of digital technologies are designated: 1) digital solutions for defining the personal goals of education, educational navigation, building a project for an individual educational trajectory; 2) adaptive educational environment for the implementation of an individual educational trajectory; 3) digital solutions for learning activities support; monitoring the results of education; solutions for educational logistics; 4) digital solutions for assessment and certification (personal identification and competency assessment); 5) digital solutions for career support and lifelong education; 6) digital solutions for building and supporting university communities (including teachers, students, graduates, university partners); 7) digital solutions for monitoring and modeling the dynamics of competences at the population level. Each group includes 3–12 technologies, so it is possible to build a detailed “map” of digital technologies for higher education sphere.
According to the experts, most of the major groups of digital technologies for education are currently (2018) in the stage of “working prototypes and pilot products” and “locally used products” (in the developed countries of the world). The exceptions are “digital solutions for monitoring and modeling the dynamics of competencies at the population level,” which are still at the “research and development” stage. By 2030, all technologies of major groups will reach the stage of “mass market products” and “local market products”.
The structure of assessments of the digital technology application in the present and prospects for adoption by 2030 for Krasnoyarsk Krai is generally similar to the structure of assessments for developed countries of the world, but the magnitudes of the estimates are much smaller. The result reflects the “catching up” nature of the development of digital technology in the education sphere in the region. The basic strategy of digitalization of higher education in the region will be the transfer of ready-made solutions that have already found wide application in the developed countries of the world",,'IATED Academy',Digital technology in higher education: situation analysis and prospects assessment (on the example of Krasnoyarsk krai),10.21125/inted.2019.1392,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480278110,2021-12-01T00:00:00,"Among the wide variety of malicious behavior commonly observed in modern social platforms, one of the most notorious is the diffusion of fake news, given its potential to influence the opinions of millions of people who can be voters, consumers, or simply citizens going about their daily lives. In this paper, we implement and carry out an empirical evaluation of a version of the recently-proposed NetDER architecture for hybrid AI decision-support systems with the capability of leveraging the availability of machine learning modules, logical reasoning about unknown objects, and forecasts based on diffusion processes. NetDER is a general architecture for reasoning about different kinds of malicious behavior such as dissemination of fake news, hate speech, and malware, detection of botnet operations, prevention of cyber attacks including those targeting software products or blockchain transactions, among others. Here, we focus on the case of fake news dissemination on social platforms by three different kinds of users: non-malicious, malicious, and botnet members. In particular, we focus on three tasks: (i) determining who is responsible for posting a fake news article, (ii) detecting malicious users, and (iii) detecting which users belong to a botnet designed to disseminate fake news. Given the difficulty of obtaining adequate data with ground truth, we also develop a testbed that combines real-world fake news datasets with synthetically generated networks of users and fully-detailed traces of their behavior throughout a series of time points. We designed our testbed to be customizable for different problem sizes and settings, and make its code publicly available to be used in similar evaluation efforts. Finally, we report on the results of a thorough experimental evaluation of three variants of our model and six environmental settings over the three tasks. Our results clearly show the effects that the quality of knowledge engineering tasks, the quality of the underlying machine learning classifier used to detect fake news, and the specific environmental conditions have on smart policing efforts in social platforms.Fil: Paredes, José Nicolás. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Ciencias e Ingeniería de la Computación. Universidad Nacional del Sur. Departamento de Ciencias e Ingeniería de la Computación. Instituto de Ciencias e Ingeniería de la Computación; ArgentinaFil: Simari, Gerardo. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Ciencias e Ingeniería de la Computación. Universidad Nacional del Sur. Departamento de Ciencias e Ingeniería de la Computación. Instituto de Ciencias e Ingeniería de la Computación; ArgentinaFil: Martinez, Maria Vanina. Consejo Nacional de Investigaciones Científicas y Técnicas. Oficina de Coordinación Administrativa Ciudad Universitaria. Instituto de Investigación en Ciencias de la Computación. Universidad de Buenos Aires. Facultad de Ciencias Exactas y Naturales. Instituto de Investigación en Ciencias de la Computación; ArgentinaFil: Falappa, Marcelo Alejandro. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Bahía Blanca. Instituto de Ciencias e Ingeniería de la Computación. Universidad Nacional del Sur. Departamento de Ciencias e Ingeniería de la Computación. Instituto de Ciencias e Ingeniería de la Computación; Argentin","[{'title': 'Future Generation Computer Systems', 'identifiers': ['issn:0167-739X', '0167-739x']}]",'Elsevier BV',Detecting malicious behavior in social platforms via hybrid knowledge and data driven systems,10.1016/j.future.2021.06.033,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
481048939,2020-03-29T00:00:00,"International audienceWe propose a physical alternative of software based approaches for advanced classification task by considering a photonic-based architecture implementing a recurrent neural network with up to 16,384 physical neurons. This architecture is realized with o↵-the-shelf components and can be scaled up to hundred thousand or millions of nodes while ensuring data-ecient training strategy thanks to the reservoir computing framework. We use this architecture to perform a challenging computer vision task: the classification of human actions from a video feed. For this task, we show for the first time that a physical architecture with a simple learning strategy, consisting of training one linear readout for each class, can achieve a &gt;90% success rate in terms of classification accuracy. This rivals the deep-learning approaches in terms of level of performance and hence could pave the way towards novel paradigm for ecient real-time video processing at the physical layer using photonic systems",,HAL CCSD,Automatic classification of video using a scalable photonic neuro-inspired architecture,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
481531506,2020-10-01T07:00:00,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided",,Scholarship@Western,Partially RepRapable automated open source bag valve mask-based ventilator,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
334959107,2021-04-01T00:00:00,"The random subspace method, also known as the pillar of random forests, is good at making precise and robust predictions. However, there is as yet no straightforward way to combine it with deep learning. In this paper, we therefore propose Neural Random Subspace (NRS), a novel deep learning based random subspace method. In contrast to previous forest methods, NRS enjoys the benefits of end-to-end, data-driven representation learning, as well as pervasive support from deep learning software and hardware platforms, hence achieving faster inference speed and higher accuracy. Furthermore, as a non-linear component to be encoded into Convolutional Neural Networks (CNNs), NRS learns non-linear feature representations in CNNs more efficiently than contemporary, higher-order pooling methods, producing excellent results with negligible increase in parameters, floating point operations (FLOPs) and real running time. Compared with random subspaces, random forests and gradient boosting decision trees (GBDTs), NRS demonstrates superior performance on 35 machine learning datasets. Moreover, on both 2D image and 3D point cloud recognition tasks, integration of NRS with CNN architectures achieves consistent improvements with only incremental cost",,,Neural random subspace,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479313872,2021-07-01T00:00:00,"Abstract Rapid advancements of artificial intelligence of things (AIoT) technology pave the way for developing a digital‐twin‐based remote interactive system for advanced robotic‐enabled industrial automation and virtual shopping. The embedded multifunctional perception system is urged for better interaction and user experience. To realize such a system, a smart soft robotic manipulator is presented that consists of a triboelectric nanogenerator tactile (T‐TENG) and length (L‐TENG) sensor, as well as a poly(vinylidene fluoride) (PVDF) pyroelectric temperature sensor. With the aid of machine learning (ML) for data processing, the fusion of the T‐TENG and L‐TENG sensors can realize the automatic recognition of the grasped objects with the accuracy of 97.143% for 28 different shapes of objects, while the temperature distribution can also be obtained through the pyroelectric sensor. By leveraging the IoT and artificial intelligence (AI) analytics, a digital‐twin‐based virtual shop is successfully implemented to provide the users with real‐time feedback about the details of the product. In general, by offering a more immersive experience in human–machine interactions, the proposed remote interactive system shows the great potential of being the advanced human–machine interface for the applications of the unmanned working space","[{'title': 'Advanced Science', 'identifiers': ['2198-3844', 'issn:2198-3844']}]",'Wiley',Artificial Intelligence of Things (AIoT) Enabled Virtual Shop Applications Using Self‐Powered Sensor Enhanced Soft Robotic Manipulator,10.1002/advs.202100230,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479344785,2021-06-21T00:00:00,"Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) methods&nbsp;are a promising approach to solving complex tasks in the real world with physical&nbsp;robots. In this paper, we compare several reinforcement&nbsp; learning (Q-Learning,&nbsp;SARSA) and deep reinforcement learning (Deep Q-Network, Deep Sarsa) methods&nbsp;for a task aimed at achieving a specific goal using robotics arm UR3. The main&nbsp;optimization problem of this experiment is to find the best solution for each RL/DRL scenario and minimize the Euclidean distance accuracy error and smooth&nbsp;the resulting path by the Bézier spline method. The simulation and real word&nbsp;applications are controlled by the Robot Operating System (ROS). The learning&nbsp;environment is implemented using the OpenAI Gym library which uses the RVIZ&nbsp;simulation tool and the Gazebo 3D modeling tool for dynamics and kinematics","[{'title': 'MENDEL', 'identifiers': ['1803-3814', '2571-3701', 'issn:2571-3701', 'issn:1803-3814']}]",'Brno University of Technology',Comparison of Multiple Reinforcement Learning and Deep Reinforcement Learning Methods for the Task Aimed at Achieving the Goal,10.13164/mendel.2021.1.001,https://core.ac.uk/download/479344785.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
477990915,2020-08-01T00:00:00,"[EN] We show a simple model of the dynamics of a viral process based, on the determination of the Kaplan-Meier curvePof the virus. Together with the function of the newly infected individualsI, this model allows us to predict the evolution of the resulting epidemic process in terms of the numberEof the death patients plus individuals who have overcome the disease. Our model has as a starting point the representation ofEas the convolution ofIandP. It allows introducing information about latent patients-patients who have already been cured but are still potentially infectious, and re-infected individuals. We also provide three methods for the estimation ofPusing real data, all of them based on the minimization of the quadratic error: the exact solution using the associated Lagrangian function and Karush-Kuhn-Tucker conditions, a Monte Carlo computational scheme acting on the total set of local minima, and a genetic algorithm for the approximation of the global minima. Although the calculation of the exact solutions of all the linear systems provided by the use of the Lagrangian naturally gives the best optimization result, the huge number of such systems that appear when the time variable increases makes it necessary to use numerical methods. We have chosen the genetic algorithms. Indeed, we show that the results obtained in this way provide good solutions for the model.This research was funded by Ministerio de Ciencia, Innovacion y Universidades: MTM2016-77054-C2-1-P and Generalitat Valenciana: Catedra de Transparencia y Gestion de Datos (U.P.V.). The authors would like to thank the referees for their valuable comments which helped
to improve the manuscript. The author gratefully acknowledge the support of Cátedra de Transparencia y
Gestión de Datos, Universitat Politècnica de València y Generalitat Valenciana, Spain. The last author gratefully
acknowledges the support of the Ministerio de Ciencia, Innovación y Universidades (Spain) and FEDER under
grant MTM2016-77054-C2-1-P.Calabuig, JM.; García-Raffi, LM.; García-Valiente, A.; Sánchez Pérez, EA. (2020). Evolution Model for Epidemic Diseases Based on the Kaplan-Meier Curve Determination. Mathematics. 8(8):1-25. https://doi.org/10.3390/math8081260S12588Ai, T., Yang, Z., Hou, H., Zhan, C., Chen, C., Lv, W., … Xia, L. (2020). Correlation of Chest CT and RT-PCR Testing for Coronavirus Disease                     2019 (COVID-19) in China: A Report of 1014 Cases. Radiology, 296(2), E32-E40. doi:10.1148/radiol.2020200642Chen, D., Xu, W., Lei, Z., Huang, Z., Liu, J., Gao, Z., & Peng, L. (2020). Recurrence of positive SARS-CoV-2 RNA in COVID-19: A case report. International Journal of Infectious Diseases, 93, 297-299. doi:10.1016/j.ijid.2020.03.003Kaplan, E. L., & Meier, P. (1958). Nonparametric Estimation from Incomplete Observations. Journal of the American Statistical Association, 53(282), 457-481. doi:10.1080/01621459.1958.10501452Kenah, E. (2010). Contact intervals, survival analysis of epidemic data, and estimation of R0. Biostatistics, 12(3), 548-566. doi:10.1093/biostatistics/kxq068Kenah, E. (2012). Non-parametric survival analysis of infectious disease data. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 75(2), 277-303. doi:10.1111/j.1467-9868.2012.01042.xOgłuszka, M., Orzechowska, M., Jędroszka, D., Witas, P., & Bednarek, A. K. (2019). Evaluate Cutpoints: Adaptable continuous data distribution system for determining survival in Kaplan-Meier estimator. Computer Methods and Programs in Biomedicine, 177, 133-139. doi:10.1016/j.cmpb.2019.05.023Hethcote, H. W. (2000). The Mathematics of Infectious Diseases. SIAM Review, 42(4), 599-653. doi:10.1137/s0036144500371907Silal, S. P., Little, F., Barnes, K. I., & White, L. J. (2016). Sensitivity to model structure: a comparison of compartmental models in epidemiology. Health Systems, 5(3), 178-191. doi:10.1057/hs.2015.2Kamvar, Z. N., Cai, J., Pulliam, J. R. C., Schumacher, J., & Jombart, T. (2019). Epidemic curves made easy using the R package incidence. F1000Research, 8, 139. doi:10.12688/f1000research.18002.1Lectures on Mathematical Modelling of Biological Systemshttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.8665&rep=rep1&type=pdfKeeling, M. J., & Danon, L. (2009). Mathematical modelling of infectious diseases. British Medical Bulletin, 92(1), 33-42. doi:10.1093/bmb/ldp038Brown, G. D., Oleson, J. J., & Porter, A. T. (2015). An empirically adjusted approach to reproductive number estimation for stochastic compartmental models: A case study of two Ebola outbreaks. Biometrics, 72(2), 335-343. doi:10.1111/biom.12432Huppert, A., & Katriel, G. (2013). Mathematical modelling and prediction in infectious disease epidemiology. Clinical Microbiology and Infection, 19(11), 999-1005. doi:10.1111/1469-0691.12308Paul, M. (2013). Foreseeing the future in infectious diseases: can we? Clinical Microbiology and Infection, 19(11), 991-992. doi:10.1111/1469-0691.12300Roosa, K., Lee, Y., Luo, R., Kirpich, A., Rothenberg, R., Hyman, J. M., … Chowell, G. (2020). Short-term Forecasts of the COVID-19 Epidemic in Guangdong and Zhejiang, China: February 13–23, 2020. Journal of Clinical Medicine, 9(2), 596. doi:10.3390/jcm9020596Package ‘GA’-CRAN-R Projecthttps://luca-scr.github.io/GA/Scrucca, L. (2013). GA: A Package for Genetic Algorithms inR. Journal of Statistical Software, 53(4). doi:10.18637/jss.v053.i0",,'MDPI AG',Evolution Model for Epidemic Diseases Based on the Kaplan-Meier Curve Determination,10.3390/math8081260,https://riunet.upv.es/bitstream/10251/172000/1/CalabuigGarcia-RaffiGarcia-Valiente%20-%20Evolution%20Model%20for%20Epidemic%20Diseases%20Based%20on%20the%20Kaplan-M....pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395143868,2021-02-01T00:00:00,"[EN] Wetlands play a key role in preserving biodiversity and preventing climate change. Their conservation poses an important and pressing challenge. In the Mediterranean region, one of the key threats to wetland survival is the lack of water due to competition for resources. The selection of the most sustainable water resources for wetland conservation is a complex elicitation problem. A novel Water Resources Sustainability Model (WRSM) focused on water quality has been developed to support the decision-making. This collaborative elicitation model is based on the analytical hierarchy process and uses the reference environmental status of the wetland. The model can be used to discriminate which water resources are more sustainable for the conservation of the wetland. The WRSM has been applied successfully to Las Tablas de Daimiel National Park. The framework enables establishing priorities when analyzing in terms of water quality any surface, recycled or underground water resources.Canto-Perello, J.; Benitez-Navio, A.; Martín Utrillas, MG.; Martinez-Leon, J.; Curiel Esparza, J. (2021). Water resources sustainability model for wetland conservation based on anonymous expert elicitation. Environmental Modelling & Software. 136:1-12. https://doi.org/10.1016/j.envsoft.2020.104952S112136Aguilera, H., & Merino, L. M. (2018). Data on chemical composition of soil and water in the semiarid wetland of Las Tablas de Damiel National Park (Spain) during a drought period. Data in Brief, 19, 2481-2486. doi:10.1016/j.dib.2018.04.085Aguilera, H., Moreno, L., Wesseling, J. G., Jiménez-Hernández, M. E., & Castaño, S. (2016). Soil moisture prediction to support management in semiarid wetlands during drying episodes. CATENA, 147, 709-724. doi:10.1016/j.catena.2016.08.007Alafifi, A. H., & Rosenberg, D. E. (2020). Systems modeling to improve river, riparian, and wetland habitat quality and area. Environmental Modelling & Software, 126, 104643. doi:10.1016/j.envsoft.2020.104643Alvarez Etxeberria, I., Garayar, A., & Calvo Sánchez, J. A. (2015). Development of sustainability reports for farming operations in the Basque Country using the Delphi method. Revista de Contabilidad, 18(1), 44-54. doi:10.1016/j.rcsar.2014.03.004Bilotta, G. S., & Brazier, R. E. (2008). Understanding the influence of suspended solids on water quality and aquatic biota. Water Research, 42(12), 2849-2861. doi:10.1016/j.watres.2008.03.018Bilotta, G. S., Burnside, N. G., Cheek, L., Dunbar, M. J., Grove, M. K., Harrison, C., … Davy-Bowker, J. (2012). Developing environment-specific water quality guidelines for suspended particulate matter. Water Research, 46(7), 2324-2332. doi:10.1016/j.watres.2012.01.055Blaas, H., & Kroeze, C. (2016). Excessive nitrogen and phosphorus in European rivers: 2000–2050. Ecological Indicators, 67, 328-337. doi:10.1016/j.ecolind.2016.03.004Caen, A., Latour, D., & Mathias, J. D. (2019). Dynamical effects of retention structures on the mitigation of lake eutrophication. Environmental Modelling & Software, 119, 309-326. doi:10.1016/j.envsoft.2019.06.012Camargo, J. A., & Alonso, Á. (2006). Ecological and toxicological effects of inorganic nitrogen pollution in aquatic ecosystems: A global assessment. Environment International, 32(6), 831-849. doi:10.1016/j.envint.2006.05.002Canto-Perello, J., Martinez-Leon, J., Curiel-Esparza, J., & Martin-Utrillas, M. (2017). Consensus in prioritizing river rehabilitation projects through the integration of social, economic and landscape indicators. Ecological Indicators, 72, 659-666. doi:10.1016/j.ecolind.2016.09.004Canto-Perello, J., Morera-Escrich, J. L., Martin-Utrillas, M., & Curiel-Esparza, J. (2018). Restoration prioritization framework for roadway high cut slopes to reverse land degradation and fragmentation. Land Use Policy, 71, 470-479. doi:10.1016/j.landusepol.2017.11.020Cirujano, S., Casado, C., Bernués, M., & Camargo, J. A. (1996). Ecological study of Las Tablas de Daimiel National Park (Ciudad Real, central Spain): Differences in water physico-chemistry and vegetation between 1974 and 1989. Biological Conservation, 75(3), 211-215. doi:10.1016/0006-3207(95)00079-8Curiel-Esparza, J., Gonzalez-Utrillas, N., Canto-Perello, J., & Martin-Utrillas, M. (2015). Integrating climate change criteria in reforestation projects using a hybrid decision-support system. Environmental Research Letters, 10(9), 094022. doi:10.1088/1748-9326/10/9/094022Curiel-Esparza, J., Mazario-Diez, J. L., Canto-Perello, J., & Martin-Utrillas, M. (2016). Prioritization by consensus of enhancements for sustainable mobility in urban areas. Environmental Science & Policy, 55, 248-257. doi:10.1016/j.envsci.2015.10.015Curiel-Esparza, J., Reyes-Medina, M., Martin-Utrillas, M., Martinez-Garcia, M. P., & Canto-Perello, J. (2019). Collaborative elicitation to select a sustainable biogas desulfurization technique for landfills. Journal of Cleaner Production, 212, 1334-1344. doi:10.1016/j.jclepro.2018.12.095Dong, Y., Zhang, G., Hong, W.-C., & Xu, Y. (2010). Consensus models for AHP group decision making under row geometric mean prioritization method. Decision Support Systems, 49(3), 281-289. doi:10.1016/j.dss.2010.03.003Forman, E., & Peniwati, K. (1998). Aggregating individual judgments and priorities with the analytic hierarchy process. European Journal of Operational Research, 108(1), 165-169. doi:10.1016/s0377-2217(97)00244-0Gu, S., Gruau, G., Dupas, R., Petitjean, P., Li, Q., & Pinay, G. (2019). Respective roles of Fe-oxyhydroxide dissolution, pH changes and sediment inputs in dissolved phosphorus release from wetland soils under anoxic conditions. Geoderma, 338, 365-374. doi:10.1016/j.geoderma.2018.12.034Haas, M. B., Guse, B., & Fohrer, N. (2017). Assessing the impacts of Best Management Practices on nitrate pollution in an agricultural dominated lowland catchment considering environmental protection versus economic development. Journal of Environmental Management, 196, 347-364. doi:10.1016/j.jenvman.2017.02.060Thi Minh Hanh, P., Sthiannopkao, S., The Ba, D., & Kim, K.-W. (2011). Development of Water Quality Indexes to Identify Pollutants in Vietnam’s Surface Water. Journal of Environmental Engineering, 137(4), 273-283. doi:10.1061/(asce)ee.1943-7870.0000314Hes, E. M., & van Dam, A. A. (2019). Modelling nitrogen and phosphorus cycling and retention in Cyperus papyrus dominated natural wetlands. Environmental Modelling & Software, 122, 104531. doi:10.1016/j.envsoft.2019.104531Juston, J. M., & Kadlec, R. H. (2019). Data-driven modeling of phosphorus (P) dynamics in low-P stormwater wetlands. Environmental Modelling & Software, 118, 226-240. doi:10.1016/j.envsoft.2019.05.002Juwana, I., Muttil, N., & Perera, B. J. C. (2012). Indicator-based water sustainability assessment — A review. Science of The Total Environment, 438, 357-371. doi:10.1016/j.scitotenv.2012.08.093Kløve, B., Allan, A., Bertrand, G., Druzynska, E., Ertürk, A., Goldscheider, N., … Schipper, P. (2011). Groundwater dependent ecosystems. Part II. Ecosystem services and management in Europe under risk of climate change and land use intensification. Environmental Science & Policy, 14(7), 782-793. doi:10.1016/j.envsci.2011.04.005Koskiaho, J., & Puustinen, M. (2019). Suspended solids and nutrient retention in two constructed wetlands as determined from continuous data recorded with sensors. Ecological Engineering, 137, 65-75. doi:10.1016/j.ecoleng.2019.04.006Lefebvre, G., Redmond, L., Germain, C., Palazzi, E., Terzago, S., Willm, L., & Poulin, B. (2019). Predicting the vulnerability of seasonally-flooded wetlands to climate change across the Mediterranean Basin. Science of The Total Environment, 692, 546-555. doi:10.1016/j.scitotenv.2019.07.263Zhuang, L.-L., Yang, T., Zhang, J., & Li, X. (2019). The configuration, purification effect and mechanism of intensified constructed wetland for wastewater treatment from the aspect of nitrogen removal: A review. Bioresource Technology, 293, 122086. doi:10.1016/j.biortech.2019.122086Liu, Z., Tai, P., Li, X., Kong, L., Matthews, T. G., Lester, R. E., & Mondon, J. A. (2019). Deriving site-specific water quality criteria for ammonia from national versus international toxicity data. Ecotoxicology and Environmental Safety, 171, 665-676. doi:10.1016/j.ecoenv.2018.12.078Lobanova, A., Liersch, S., Tàbara, J. D., Koch, H., Hattermann, F. F., & Krysanova, V. (2017). Harmonizing human-hydrological system under climate change: A scenario-based approach for the case of the headwaters of the Tagus River. Journal of Hydrology, 548, 436-447. doi:10.1016/j.jhydrol.2017.03.015Martin-Utrillas, M., Reyes-Medina, M., Curiel-Esparza, J., & Canto-Perello, J. (2014). Hybrid method for selection of the optimal process of leachate treatment in waste treatment and valorization plants or landfills. Clean Technologies and Environmental Policy, 17(4), 873-885. doi:10.1007/s10098-014-0834-4Man, Y., Hu, Y., & Ren, J. (2019). Forecasting COD load in municipal sewage based on ARMA and VAR algorithms. Resources, Conservation and Recycling, 144, 56-64. doi:10.1016/j.resconrec.2019.01.030Martinez-Martinez, E., Nejadhashemi, A. P., Woznicki, S. A., Adhikari, U., & Giri, S. (2015). Assessing the significance of wetland restoration scenarios on sediment mitigation plan. Ecological Engineering, 77, 103-113. doi:10.1016/j.ecoleng.2014.11.031Mayo, A. W., Muraza, M., & Norbert, J. (2018). Modelling nitrogen transformation and removal in mara river basin wetlands upstream of lake Victoria. Physics and Chemistry of the Earth, Parts A/B/C, 105, 136-146. doi:10.1016/j.pce.2018.03.005Moreno, L., Jiménez, M.-E., Aguilera, H., Jiménez, P., & de la Losa, A. (2010). The 2009 Smouldering Peat Fire in Las Tablas de Daimiel National Park (Spain). Fire Technology, 47(2), 519-538. doi:10.1007/s10694-010-0172-yNagisetty, R. M., Flynn, K. F., & Uecker, D. (2019). Dissolved oxygen modeling of effluent-dominated macrophyte-rich Silver Bow Creek. Ecological Modelling, 393, 85-97. doi:10.1016/j.ecolmodel.2018.12.009Navarro, V., García, B., Sánchez, D., & Asensio, L. (2011). An evaluation of the application of treated sewage effluents in Las Tablas de Daimiel National Park, Central Spain. Journal of Hydrology, 401(1-2), 53-64. doi:10.1016/j.jhydrol.2011.02.008Norouzian-Maleki, S., Bell, S., Hosseini, S.-B., & Faizi, M. (2015). Developing and testing a framework for the assessment of neighbourhood liveability in two contrasting countries: Iran and Estonia. Ecological Indicators, 48, 263-271. doi:10.1016/j.ecolind.2014.07.033Novakowski, N., & Wellar, B. (2008). Using the Delphi Technique in Normative Planning Research: Methodological Design Considerations. Environment and Planning A: Economy and Space, 40(6), 1485-1500. doi:10.1068/a39267Okoli, C., & Pawlowski, S. D. (2004). The Delphi method as a research tool: an example, design considerations and applications. Information & Management, 42(1), 15-29. doi:10.1016/j.im.2003.11.002O’Neil, G. L., Goodall, J. L., Behl, M., & Saby, L. (2020). Deep learning Using Physically-Informed Input Data for Wetland Identification. Environmental Modelling & Software, 126, 104665. doi:10.1016/j.envsoft.2020.104665Pérez-Martín, M. A., Estrela, T., & del-Amo, P. (2016). Measures required to reach the nitrate objectives in groundwater based on a long-term nitrate model for large river basins (Júcar, Spain). Science of The Total Environment, 566-567, 122-133. doi:10.1016/j.scitotenv.2016.04.206Pottinger, T. G. (2017). Modulation of the stress response in wild fish is associated with variation in dissolved nitrate and nitrite. Environmental Pollution, 225, 550-558. doi:10.1016/j.envpol.2017.03.021Prăvălie, R., Patriche, C., & Bandoc, G. (2017). Quantification of land degradation sensitivity areas in Southern and Central Southeastern Europe. New results based on improving DISMED methodology with new climate data. CATENA, 158, 309-320. doi:10.1016/j.catena.2017.07.006Restuccia, F., Huang, X., & Rein, G. (2017). Self-ignition of natural fuels: Can wildfires of carbon-rich soil start by self-heating? Fire Safety Journal, 91, 828-834. doi:10.1016/j.firesaf.2017.03.052Rivers-Moore, N. A., Dallas, H. F., & Morris, C. (2013). Towards setting environmental water temperature guidelines: A South African example. Journal of Environmental Management, 128, 380-392. doi:10.1016/j.jenvman.2013.04.059Rusydi, A. F. (2018). Correlation between conductivity and total dissolved solid in various type of water: A review. IOP Conference Series: Earth and Environmental Science, 118, 012019. doi:10.1088/1755-1315/118/1/012019Sánchez-Montoya, M. del M., Arce, M. I., Vidal-Abarca, M. R., Suárez, M. L., Prat, N., & Gómez, R. (2012). Establishing physico-chemical reference conditions in Mediterranean streams according to the European Water Framework Directive. Water Research, 46(7), 2257-2269. doi:10.1016/j.watres.2012.01.042Sanchez-Ramos, D., Sánchez-Emeterio, G., & Florín Beltrán, M. (2015). Changes in water quality of treated sewage effluents by their receiving environments in Tablas de Daimiel National Park, Spain. Environmental Science and Pollution Research, 23(7), 6082-6090. doi:10.1007/s11356-015-4660-ySapriza-Azuri, G., Jódar, J., Carrera, J., & Gupta, H. V. (2015). Toward a comprehensive assessment of the combined impacts of climate change and groundwater pumping on catchment dynamics. Journal of Hydrology, 529, 1701-1712. doi:10.1016/j.jhydrol.2015.08.015Singh, S., Ghosh, N. C., Krishan, G., Galkate, R., Thomas, T., & Jaiswal, R. K. (2015). Development of an Overall Water Quality Index (OWQI) for Surface Water in Indian Context. Current World Environment, 10(3), 813-822. doi:10.12944/cwe.10.3.12Singh, S., Ghosh, N. C., Gurjar, S., Krishan, G., Kumar, S., & Berwal, P. (2017). Index-based assessment of suitability of water quality for irrigation purpose under Indian conditions. Environmental Monitoring and Assessment, 190(1). doi:10.1007/s10661-017-6407-3Sperotto, A., Molina, J. L., Torresan, S., Critto, A., Pulido-Velazquez, M., & Marcomini, A. (2019). A Bayesian Networks approach for the assessment of climate change impacts on nutrients loading. Environmental Science & Policy, 100, 21-36. doi:10.1016/j.envsci.2019.06.004Sun, B., Tang, J., Yu, D., Song, Z., & Wang, P. (2019). Ecosystem health assessment: A PSR analysis combining AHP and FCE methods for Jiaozhou Bay, China1. Ocean & Coastal Management, 168, 41-50. doi:10.1016/j.ocecoaman.2018.10.026Sutadian, A. D., Muttil, N., Yilmaz, A. G., & Perera, B. J. C. (2015). Development of river water quality indices—a review. Environmental Monitoring and Assessment, 188(1). doi:10.1007/s10661-015-5050-0Sutadian, A. D., Muttil, N., Yilmaz, A. G., & Perera, B. J. C. (2017). Using the Analytic Hierarchy Process to identify parameter weights for developing a water quality index. Ecological Indicators, 75, 220-233. doi:10.1016/j.ecolind.2016.12.043Tooth, S. (2018). The geomorphology of wetlands in drylands: Resilience, nonresilience, or …? Geomorphology, 305, 33-48. doi:10.1016/j.geomorph.2017.10.017Tyagi, S., Sharma, B., Singh, P., & Dobhal, R. (2020). Water Quality Assessment in Terms of Water Quality Index. American Journal of Water Resources, 1(3), 34-38. doi:10.12691/ajwr-1-3-3Viaroli, S., Mastrorillo, L., Lotti, F., Paolucci, V., & Mazza, R. (2018). The groundwater budget: A tool for preliminary estimation of the hydraulic connection between neighboring aquifers. Journal of Hydrology, 556, 72-86. doi:10.1016/j.jhydrol.2017.10.066Wang, H.-J., Xiao, X.-C., Wang, H.-Z., Li, Y., Yu, Q., Liang, X.-M., … Jeppesen, E. (2017). Effects of high ammonia concentrations on three cyprinid fish: Acute and whole-ecosystem chronic tests. Science of The Total Environment, 598, 900-909. doi:10.1016/j.scitotenv.2017.04.070Xu, Y., Wang, Y., Li, S., Huang, G., & Dai, C. (2018). Stochastic optimization model for water allocation on a watershed scale considering wetland’s ecological water requirement. Ecological Indicators, 92, 330-341. doi:10.1016/j.ecolind.2017.02.019Yuan, L., Ge, Z., Fan, X., & Zhang, L. (2014). Ecosystem-based coastal zone management: A comprehensive assessment of coastal ecosystems in the Yangtze Estuary coastal zone. Ocean & Coastal Management, 95, 63-71. doi:10.1016/j.ocecoaman.2014.04.005Zhang, R., Zhang, X., Yang, J., & Yuan, H. (2013). Wetland ecosystem stability evaluation by using Analytical Hierarchy Process (AHP) approach in Yinchuan Plain, China. Mathematical and Computer Modelling, 57(3-4), 366-374. doi:10.1016/j.mcm.2012.06.014ZHANG, L. (2016). CALCULATION OF WETLANDS ECOLOGICAL WATER REQUIREMENT IN CHINA’S WESTERN JILIN PROVINCE BASED ON REGIONALIZATION AND GRADATION TECHNIQUES. Applied Ecology and Environmental Research, 14(3), 463-478. doi:10.15666/aeer/1403_463478Zhang, B., Zhao, D., Zhou, P., Qu, S., Liao, F., & Wang, G. (2020). Hydrochemical Characteristics of Groundwater and Dominant Water–Rock Interactions in the Delingha Area, Qaidam Basin, Northwest China. Water, 12(3), 836. doi:10.3390/w1203083",,'Elsevier BV',Water resources sustainability model for wetland conservation based on anonymous expert elicitation,10.1016/j.envsoft.2020.104952,http://hdl.handle.net/10251/164063,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395143864,2020-09-23T00:00:00,"[EN] Freshwater quality is deteriorating worldwide. In populated areas, urban pollution is the main pressure on surface continental waters, but intensive wastewater treatment is costly. Setting standards for treatment of wastewater before discharge is a major policy instrument for water authorities, balancing environmental gains and operational costs. Discharge permits usually define concentration limits at the discharge point of the plant effluent. This approach, however, may not guarantee the good status of the receiving waters. Discharge permits should be directly linked to pollutant concentration in the river. Our paper develops an approach to adaptively adjust discharge permits and applies it to Madrid and the Manzanares river, a city of more than 3 million inhabitants discharging its treated wastewater to a stream having less than 2 m(3) s(-1) average flow. Stricter limits to 5-day biological oxygen demand (11 mg O-2 L-1), ammonium (0.5 mg N-NH4 L-1), nitrate (5.9 mg N-NO3 L-1), and phosphate (0.17 mg P-PO4 L-1) at plant effluent are required to meet the river environmental objectives. The results can be generalized to assess wastewater management decisions in other geographical areas.The authors wish to thank the Tagus River Basin Authority (Confederacion Hidrografica del Tajo) for their availability and readiness to share information, and the anonymous reviewers for their valuable and constructive comments. This research was funded by the Botin Foundation, Spain.Bolinches, A.; De Stefano, L.; Paredes Arquiola, J. (2020). Adjusting wastewater treatment effluent standards to protect the receiving waters: the case of low flow rivers in central Spain. Environmental Earth Sciences. 79:1-17. https://doi.org/10.1007/s12665-020-09184-zS11779AEMET (2018) Standard climate Values: Madrid, Retiro. https://www.aemet.es/en/serviciosclimaticos/datosclimatologicos/valoresclimatologicos?l=3195&k=mad. Accessed 25 June 2019Alexakis D, Kagalou I, Tsakiris G (2013) Assessment of pressures and impacts on surface water bodies of the Mediterranean. Case study: Pamvotis Lake, Greece. Environ Earth Sci 70:687–698. https://doi.org/10.1007/s12665-012-2152-7Anderson DM, Glibert PM, Burkholder JM (2002) Harmful algal blooms and eutrophication: nutrient sources, composition, and consequences. Estuaries 25:704–726. https://doi.org/10.1007/BF02804901Andreu J, Capilla J, Sanchís E (1996) AQUATOOL, a generalized decision-support system for water-resources planning and operational management. J Hydrol 177:269–291. https://doi.org/10.1016/0022-1694(95)02963-XArora S, Keshari AK (2018) Estimation of re-aeration coefficient using MLR for modelling water quality of rivers in urban environment. Groundw Sustain Dev. https://doi.org/10.1016/j.gsd.2017.11.006Asad Ismaiel I, Bird G, McDonald MA et al (2018) Establishment of background water quality conditions in the Great Zab River catchment: influence of geogenic and anthropogenic controls on developing a baseline for water quality assessment and resource management. Environ Earth Sci 77:50. https://doi.org/10.1007/s12665-017-7190-8Astaraie-Imani M, Kapelan Z, Fu G, Butler D (2012) Assessing the combined effects of urbanisation and climate change on the river water quality in an integrated urban wastewater system in the UK. J Environ Manag 112:1–9. https://doi.org/10.1016/j.jenvman.2012.06.039Bahamonde PA, Fuzzen ML, Bennett CJ et al (2015) Whole organism responses and intersex severity in rainbow darter (Etheostoma caeruleum) following exposures to municipal wastewater in the Grand River basin, ON, Canada. Part A Aquat Toxicol 159:290–301. https://doi.org/10.1016/J.AQUATOX.2014.11.023Bowie GL, Mills WB, Porcella DB et al (1985) Rates, constants, and kinetics formulations in surface water quality modeling. U.S. Environmental Protection Agency, AthensCarey RO, Migliaccio KW (2009) Contribution of wastewater treatment plant effluents to nutrient dynamics in aquatic systems: a review. Environ Manag 44:205–217. https://doi.org/10.1007/s00267-009-9309-5Chang F-J, Tsai Y-H, Chen P-A et al (2015) Modeling water quality in an urban river using hydrological factors and data driven approaches. J Environ Manag. https://doi.org/10.1016/j.jenvman.2014.12.014Chapra SC (2008) Surface water-quality modeling. Waveland Press, Long GroveConfederación Hidrográfica del Tajo (2018) Resultados/informes: aguas superficiales—control fisicoquímico. https://www.chtajo.es/LaCuenca/CalidadAgua/Resultados_Informes/Paginas/RISupFisicoQuímico.aspx. Accessed 24 May 2018Corominas L, Acuña V, Ginebreda A, Poch M (2013) Integration of freshwater environmental policies and wastewater treatment plant management. Sci Total Environ 445–446:185–191. https://doi.org/10.1016/J.SCITOTENV.2012.12.055Council of the European Communities (1991) Council Directive of 21 May 1991 concerning urban waste water treatment (91/271/EEC). OJCox BA, Whitehead PG (2009) Impacts of climate change scenarios on dissolved oxygen in the River Thames, UK. Hydrol Res 40:138–152. https://doi.org/10.2166/nh.2009.096Cubillo F, Rodriguez B, Barnwell TO (1992) A system for control of river water quality for the community of Madrid using QUAL2E. Water Sci Technol 26:1867–1873Dodds W, Smith V (2016) Nitrogen, phosphorus, and eutrophication in streams. Inl Waters 6:155–164. https://doi.org/10.5268/IW-6.2.909Dojlido J, Best GA (1993) Chemistry of water and water pollution. E. Horwood, ChichesterDonigian AS (2002) Watershed model calibration and validation: the HSPF experience. Proc Water Environ Fed 2002:44–73Duh JD, Shandas V, Chang H, George LA (2008) Rates of urbanisation and the resiliency of air and water quality. Sci Total Environ 400:238–256European Commission (2019) Report from the commission to the European Parliament and Council on the implementation of the Water Framework Directive (2000/60/EC) and the Floods Directive (2007/60/EC). BrusselsEuropean Parliament and Council (2000) Directive 2000/60/EC of the European Parliament and of the Council of 23 October 2000 establishing a framework for Community action in the field of water policy. OJ 2014–7001Even S, Mouchel J-M, Servais P et al (2007) Modelling the impacts of combined sewer overflows on the river Seine water quality. Sci Total Environ. https://doi.org/10.1016/j.scitotenv.2006.12.007Fonseca A, Botelho C, Boaventura RAR, Vilar VJP (2014) Integrated hydrological and water quality model for river management: a case study on Lena River. Sci Total Environ 485–486:474–489. https://doi.org/10.1016/j.scitotenv.2014.03.111Gallego Bernad MS, Sánchez Pérez MÁ (2006) La destrucción ambiental del río Tajo: orígenes, procesos y consecuencias. In: V congreso Ibérico sobre Gestión y Planificación del Agua, FaroGenkai-Kato M, Carpenter SR (2005) Eutrophication due to phosphorus recycling in relation to lake morphometry, temperature, and macrophytes. Ecology 86(1):210–219Google Earth (2018) Google Earth. https://earth.google.com/web/@40.4012607,-3.71553269,604.85487896a,8051.22382757d,35y,0h,0t,0r. Accessed 24 May 2018Griffiths JA, Ka F, Chan S et al (2017) Reach-scale variation surface water quality in a reticular canal system in the lower Yangtze River Delta region, China. J Environ Manag 196:80–90. https://doi.org/10.1016/j.jenvman.2017.02.079Hernández-Sancho F, Molinos-Senante M, Sala-Garrido R (2011) Cost modelling for wastewater treatment processes. Desalination 268:1–5. https://doi.org/10.1016/J.DESAL.2010.09.042Hutchins MG, Bowes MJ (2018) Balancing water demand needs with protection of river water quality by minimising stream residence time: an example from the Thames, UK. Water Resour Manag 32:2561–2568. https://doi.org/10.1007/s11269-018-1946-0IGN Instituto Geográfico Nacional (2018) Centro de Descargas del CNIG (IGN). https://centrodedescargas.cnig.es/CentroDescargas/index.jsp. Accessed 24 May 2018IGN Instituto Geográfico Nacional (2020) Atlas Nacional de España. https://atlasnacional.ign.es/. Accessed 19 May 2020INE (2018) Cifras oficiales de población resultantes de la revisión del Padrón municipal. https://www.ine.es/jaxiT3/Tabla.htm?t=2881&L=0. Accessed 7 Apr 2019INE Instituto Nacional de Estadística (2018) Survey on water supply and sewerage. https://www.ine.es/dynt3/inebase/index.htm?type=pcaxis&path=/t26/p069/p03/serie&file=pcaxis&L=1. Accessed 24 May 2018Jasinska EJ, Goss GG, Gillis PL et al (2015) Assessment of biomarkers for contaminants of emerging concern on aquatic organisms downstream of a municipal wastewater discharge. Sci Total Environ 530–531:140–153. https://doi.org/10.1016/J.SCITOTENV.2015.05.080Jin L, Whitehead PG, Heppell CM et al (2016) Modelling flow and inorganic nitrogen dynamics on the Hampshire Avon: linking upstream processes to downstream water quality. Sci Total Environ 572:1496–1506. https://doi.org/10.1016/j.scitotenv.2016.02.156Kloas W, Urbatzka R, Opitz R et al (2009) Endocrine disruption in aquatic vertebrates. Ann N Y Acad Sci 1163:187–200. https://doi.org/10.1111/j.1749-6632.2009.04453.xKottek M, Grieser J, Beck C et al (2006) World Map of the Köppen-Geiger climate classification updated. Meteorol Zeitschrift 15:259–263. https://doi.org/10.1127/0941-2948/2006/0130Lastra A (2017) Minimizando el impacto de los vertidos en tiempo de lluvia. El caso de Madrid. In: V Jornadas de Ingeniería del Agua, p 2017Loos S, Middelkoop H, van der Perk M, van Beek R (2009) Large scale nutrient modelling using globally available datasets: a test for the Rhine basin. J Hydrol 369:403–415. https://doi.org/10.1016/j.jhydrol.2009.02.019Madrid City Council (2017) Padrón Municipal de Habitantes Ciudad de Madrid, pp 1–45Madrid City Council (2018) Zonas Alcantarillado Municipio Madrid. https://www.madrid.es/UnidadesDescentralizadas/Agua/DeInformacionsobreAgua/SistemasDepuracion/2017ZonasAlcantarilladoMunicipioMadrid.pdf.pdf. Accessed 24 May 2018Mapama M de AA y M ambiente (2011) Resolución de 30 de junio de 2011, de la Secretaría de Estado de Medio Rural y Agua, por la que se declaran las zonas sensibles en las cuencas intercomunitarias. Off Bull SpainMapama M de AA y M ambiente (2016) Real Decreto 1/2016, de 8 de enero, por el que se aprueba la revisión de los Planes Hidrológicos de las demarcaciones (...) y de la parte española de las demarcaciones hidrográficas del Cantábrico Oriental, Miño-Sil, Duero, Tajo, Guadiana y Ebro. Off Bull Spain 16, pp 2972–4301Mapama M de AA y M ambiente (2018) Redes de seguimiento. https://sig.mapama.gob.es/redes-seguimiento/. Accessed 26 June 2019McGrane SJ (2016) Impacts of urbanisation on hydrological and water quality dynamics, and urban water management: a review. Hydrol Sci J 61:2295–2311. https://doi.org/10.1080/02626667.2015.1128084Momblanch A, Paredes-Arquiola J, Munné A et al (2015) Managing water quality under drought conditions in the Llobregat River Basin. Sci Total Environ 503–504:300–318. https://doi.org/10.1016/j.scitotenv.2014.06.069Moriasi DN, Arnold JG, Van Liew MW et al (2007) Model evaluation guidelines for systematic quantification of accuracy in watershed simulations. Trans ASABE 50:885–900. https://doi.org/10.13031/2013.23153Morris L, Colombo V, Hassell K et al (2017) Municipal wastewater effluent licensing: a global perspective and recommendations for best practice. Sci Total Environ 580:1327–1339. https://doi.org/10.1016/J.SCITOTENV.2016.12.096Nash JE, Sutcliffe JV (1970) River flow forecasting through conceptual models part I—a discussion of principles. J Hydrol 10:282–290. https://doi.org/10.1016/0022-1694(70)90255-6Ostace GS, Baeza JA, Guerrero J et al (2013) Development and economic assessment of different WWTP control strategies for optimal simultaneous removal of carbon, nitrogen and phosphorus. Comput Chem Eng 53:164–177. https://doi.org/10.1016/J.COMPCHEMENG.2013.03.007Paredes J, Andreu J, Solera A (2010) A decision support system for water quality issues in the Manzanares River (Madrid, Spain). Sci Total Environ 408:2576–2589. https://doi.org/10.1016/j.scitotenv.2010.02.037Paredes-Arquiola S (2013) Modelo gescal para la simulación de la calidad del agua en sistemas de recursos hídricosParedes-Arquiola J, Andreu-Álvarez J, Martín-Monerris M, Solera A (2010) Water quantity and quality models applied to the Jucar River Basin, Spain. Water Resour Manag 24:2759–2779. https://doi.org/10.1007/s11269-010-9578-zParedes-Arquiola J, Solera A, Martinez-Capel F et al (2014) Integrating water management, habitat modelling and water quality at the basin scale and environmental flow assessment: case study of the Tormes River, Spain. Hydrol Sci J 59:878–889. https://doi.org/10.1080/02626667.2013.821573Paul MJ, Meyer JL (2001) Streams in the urban landscape. Annu Rev Ecol Syst 32:333–365. https://doi.org/10.1146/annurev.ecolsys.32.081501.114040Santhi C, Arnold JG, Williams JR et al (2001) Validation of the SWAT model on a large river basin with point and nonpoint sources. J Am Water Resour Assoc 37:1169–1188. https://doi.org/10.1111/j.1752-1688.2001.tb03630.xSferratore A, Billen G, Garnier J, Théry S (2005) Modeling nutrient (N, P, Si) budget in the Seine watershed: application of the Riverstrahler model using data from local to global scale resolution. Glob Biogeochem Cycles 19:1–14. https://doi.org/10.1029/2005GB002496Singh J, Knapp HV, Arnold JG, Demissie M (2005) Hydrological modeling of the Iroquois river watershed using HSPF and SWAT. J Am Water Resour Assoc 41:343–360. https://doi.org/10.1111/j.1752-1688.2005.tb03740.xSmith VH, Tilman GD, Nekola JC (1999) Eutrophication: impacts of excess nutrient inputs on freshwater, marine, and terrestrial ecosystems. Environ Pollut 100:179–196. https://doi.org/10.1016/S0269-7491(99)00091-3Soares Cruz MA, de Azevedo GA, de Aragão R et al (2019) Spatial and seasonal variability of the water quality characteristics of a river in Northeast Brazil. Environ Earth Sci 78:68. https://doi.org/10.1007/s12665-019-8087-5Soil Conservation Service (1972) SCS national engineering handbook, section 4: hydrologyThomann RV, Mueller JA (1987) Principles of surface water quality modeling and control. HarperCollins, New YorkUnited Nations Environment Program (2015) Good practices for regulating wastewater treatment. Legislations, Policies and Standard",,'Springer Science and Business Media LLC',Adjusting wastewater treatment effluent standards to protect the receiving waters: the case of low flow rivers in central Spain,10.1007/s12665-020-09184-z,http://hdl.handle.net/10251/164059,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
483540883,2021-10-28T00:00:00,"En el panorama europeu, Espanya representa un punt de referència positiu pel que fa a la regulació dels biobancs. De fet, a principis del segle XXI, la legislació espanyola ha respost ràpidament als reptes plantejats pels avanços de la biotecnologia i la genòmica en el camp de la recerca biomèdica mitjançant la promulgació en 2007 de la Llei de Recerca Biomèdica per a mantenir-se al dia amb el canvi de paradigma. Durant els últims 10 anys, aquest marc espanyol juntament amb el Reial decret 1716/2011 ha tingut el mèrit d'abordar les qüestions ètiques més controvertides relacionades amb els biobancs. No obstant això, avui la regulació de la recerca biomèdica i els biobancs ha de bregar amb la intel·ligència artificial i recerques amb gran quantitat de dades que han plantejat una sèrie de desafiaments i controvèrsies. L'objectiu d'aquest article és doble. En primer lloc, analitzaré des d'un punt de vista ètic els mèrits de la regulació espanyola sobre biobancs amb la finalitat d'extreure algunes lliçons de la situació encara no regulada en altres Estats membres.En segon lloc, tractaré el canvi de paradigma en la recerca biomèdica i em preguntaré si el marc ètic i legal que va introduir la llei espanyola a principis de segle encara és capaç de mantenir-se ferm davant els nous desafiaments contextuals i socials. En aquest sentit, identificaré algunes oportunitats d'implementació i suggeriré estratègies per a aconseguir-les en el context específic dels biobancs.In the European landscape, Spain represents a positive reference point when it comes to biobank regulation. Indeed, at the beginning of XXI century, the Spanish legislation has promptly responded to challenges posed by new biotechnologies and advances in genomics in the field of biomedical research by enacting in 2007 the Ley de Investigación Biomédica in order to keep up with the paradigm shift. Over the past 10 years, this Spanish framework along with the Real Decreto 1716/2011 has hold the merit to tackle the most controversial ethical issues related to use of human samples and personal data in biomedical research and biobanking (e.g. broad consent, secondary uses, governance, etc.). However, today the regulation of biomedical research and biobanks has to deal with big data, artificial intelligence and data-intensive research which have brought a number of challenges and controversies. The aim of this paper is two-fold. First, I will analyse from an ethical point of view the merits of Spanish regulation on biobanking in order to draw some lessons for the still unregulated situation in other Member States. Secondly, I will discuss the big data paradigm shift in biomedical research and question if the ethical and legal framework introduced the Spanish law at the beginning of the century is still able to hold the ground with the new contextual and societal challenges. In this respect, I will identify some opportunities for implementation and suggest strategies to achieve them in the specific context of biobanks.En el panorama europeo, España representa un punto de referencia positivo en lo que respecta a la regulación de los biobancos. De hecho, a principios del siglo XXI, la legislación española ha respondido rápidamente a los retos planteados por los avances de la biotecnología y la genómica en el campo de la investigación biomédica mediante la promulgación en 2007 de la Ley de Investigación Biomédica para mantenerse al día con el cambio de paradigma. Durante los últimos 10 años, este marco español junto con el Real Decreto 1716/2011 ha tenido el mérito de abordar las cuestiones éticas más controvertidas relacionadas con los biobancos. Sin embargo, hoy la regulación de la investigación biomédica y los biobancos tiene que lidiar con la inteligencia artificial e investigaciones con gran cantidad de datos que han planteado una serie de desafíos y controversias. El objetivo de este artículo es doble. En primer lugar, analizaré desde un punto de vista ético los méritos de la regulación española sobre biobancos con el fin de extraer algunas lecciones de la situación aún no regulada en otros Estados miembros. En segundo lugar, trataré el cambio de paradigma en la investigación biomédica y me preguntaré si el marco ético y legal que introdujo la ley española a principios de siglo todavía es capaz de mantenerse firmeante los nuevos desafíos contextuales y sociales. En este sentido, identificaré algunas oportunidades de implementación y sugeriré estrategias para lograrlas en el contexto específico de los biobancos",,Universidad de Barcelona,Regulando los biobancos: un análisis ético de la ley española y los nuevos retos de la investigación biomédica con datos masivos,,https://core.ac.uk/download/483540883.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
523270368,2021-08-30T18:11:30,"none3noNowadays, the volume of the multimedia heterogeneous evidence presented for digital forensic analysis has significantly increased, thus requiring the application of big data technologies, cloud-based forensics services, as well as Machine Learning (ML) techniques. In digital forensics domain, ML algorithms have been applied for cybercrime investigation such as child abuse investigations, malware classification, and image forensics. This paper addresses this issues and deals with forensic analysis of digital images and videos. In particular, this work aims at proposing a multimedia classification tool with a parallel software architecture for a fast inspection, which is easy to use (to be used by officers during a search), requires limited hardware resources and it is built on an open-source software to limit its costs. Moreover, this tool must be able to quickly inspect multiple devices at a time. When positives are found in a device, such device will be seized for a deeper analysis later in the lab. It will not be seized otherwise, reducing the inconvenience for the suspect as well as the time required for the next analysis phase. As a case study, we focus on the identification of child pornography images. Experimental results show that the proposed architecture is capable of guaranteeing a high recall, a fast process and high performances in real scenarios.noneSpalazzi L.; Paolanti M.; Frontoni E.Spalazzi, L.; Paolanti, M.; Frontoni, E",,'Springer Science and Business Media LLC',An offline parallel architecture for forensic multimedia classification,10.1007/s11042-021-10819-x,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
430684491,2021-06-01T00:00:00,"Abstract With the rapid growth in the amount of video data, efficient video indexing and retrieval methods have become one of the most critical challenges in multimedia management. For this purpose, Content-Based Video Retrieval (CBVR) is nowadays an active area of research. In this article, a CBVR system providing similar videos from a large multimedia dataset based on query video has been proposed. This approach uses vector motion-based signatures to describe the visual content and uses machine learning techniques to extract key frames for rapid browsing and efficient video indexing. The proposed method has been implemented on both single machine and real-time distributed cluster to evaluate the real-time performance aspect, especially when the number and size of videos are large. Experiments were performed using various benchmark action and activity recognition datasets and the results reveal the effectiveness of the proposed method in both accuracy and processing time compared to previous studies","[{'title': 'Journal Of Big Data', 'identifiers': ['2196-1115', 'issn:2196-1115']}]",'Springer Science and Business Media LLC',A distributed Content-Based Video Retrieval system for large datasets,10.1186/s40537-021-00479-x,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
475699877,2021-07-28T13:29:26,"Efficient video processing is a critical component in many IoMT applications to detect events of interest. Presently, many window optimization techniques have been proposed in event processing with an underlying assumption that the incoming stream has a structured data model. Videos are highly complex due to the lack of any underlying structured data model. Video stream sources, such as CCTV cameras and smartphones are resource-constrained edge nodes. At the same time, video content extraction is expensive and requires computationally intensive deep neural network (DNN) models that are primarily deployed at high-end (or cloud) nodes. This article presents VID-WIN, an adaptive 2-stage allied windowing approach to accelerate video event analytics in an edge-cloud paradigm. VID-WIN runs parallelly across edge and cloud nodes and performs the query and resource-aware optimization for state-based complex event matching. VID-WIN exploits the video content and DNN input knobs to accelerate the video inference process across nodes. This article proposes a novel content-driven microbatch resizing , query-aware caching, and microbatch-based utility filtering strategy of video frames under resource-constrained edge nodes to improve the overall system throughput, latency, and network usage. Extensive evaluations are performed over five real-world data sets. The experimental results show that VID-WIN video event matching achieves &#8764;2.3× higher throughput with minimal latency and ~99% bandwidth reduction compared to other baselines while maintaining query-level accuracy and resource bounds",,'Institute of Electrical and Electronics Engineers (IEEE)',VID-WIN: Fast video event matching with query-aware windowing at the edge for the internet of multimedia things,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
385958357,2021-02-05T13:24:34,"none3noNon-Intrusive Load Monitoring (NILM) implies disaggregating the power consumption of individual appliances from a single power measurement point. Recent approaches use a mix of low and high-frequency features, but real-time NILM on low-cost and resource-constrained smart meters is still challenging due to the computing effort needed for feature extraction and classification. In this paper, we present a thorough survey on low, mid, and high-frequency features for enabling the deployment of NILM algorithms on edge-devices. We compare four different supervised learning techniques on different use-cases. Moreover, we developed a novel Microcontroller (MCU) based Smart Measurement Node for collecting measurements, providing computational capabilities to perform NILM on-the-edge. Experimental results demonstrate that by selecting the proper features, a robust disaggregation model for real-time load monitoring is feasible on our MCU-based meter with an accuracy of 95.99%, relying on merely 9.4kB of memory requirements and 16K MACs operation.mixedTabanelli E.; Brunelli D.; Benini L.Tabanelli E.; Brunelli D.; Benini L",,'Institute of Electrical and Electronics Engineers (IEEE)',A Feature Reduction Strategy for Enabling Lightweight Non-Intrusive Load Monitoring on Edge Devices,10.1109/ISIE45063.2020.9152277,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
483834008,2021-11-01T00:00:00,"Abstract The Commercial Vehicle Safety Alliance (CVSA) aims to achieve uniformity, compatibility and reciprocity of commercial motor vehicle inspections and enforcement by certified inspectors dedicated to driver and vehicle safety. Commercial vehicles that pass a CVSA inspection are eligible for a decal representing a commitment to safety. In this work, we propose a two‐step automatic CVSA decal recognition system using deep convolutional neural network architectures. The first step localizes a vehicle's windshield and the CVSA decal within, and classifies the decal colour. The CVSA decal is cropped and used as input to the second stage, which localizes and classifies a digit and the corner‐cut of a CVSA decal. With the corner cut, colour, and digit, the system can determine the decal's date of issue. We use as our baseline the MobileDet architecture, customizing the backbone to our tasks. Our first custom architecture is larger than the baseline because it needs more representational power to detect small decals within an image. The second architecture is much smaller because digit and corner‐cut recognition is a simpler task. Our custom architectures reduce processing time and exceed accuracies relative to pre‐trained architectures. We implemented our models on different edge hardware accelerators (e.g. the Google Coral, Nvidia Jetsons, and Intel NCS) and compared the performance when processing a real‐time video stream. Our system can predict frames at 173.31 FPS on an NVIDIA Jetson AGX Xavier with 98.5% mean average precision @ 0.5 IoU","[{'title': 'IET Intelligent Transport Systems', 'identifiers': ['issn:1751-956X', 'issn:1751-9578', '1751-9578', '1751-956x']}]",'Institution of Engineering and Technology (IET)',Real‐time CVSA decals recognition system using deep convolutional neural network architectures,10.1049/itr2.12103,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
483555498,2021-06-25T17:27:36,"© 2019, Springer Nature Singapore Pte Ltd. We describe ‘Tidzam’, an application of deep learning that leverages a dense, multimodal sensor network installed at a large wetland restoration performed at Tidmarsh, a 600-acre former industrial-scale cranberry farm in Southern Massachusetts. Wildlife acoustic monitoring is a crucial metric during post-restoration evaluation of the processes, as well as a challenge in such a noisy outdoor environment. This article presents the entire Tidzam system, which has been designed in order to identify in real-time the ambient sounds of weather conditions as well as sonic events such as insects, small animals and local bird species from microphones deployed on the site. This experiment provides insight on the usage of deep learning technology in a real deployment. The originality of this work concerns the system’s ability to construct its own database from local audio sampling under the supervision of human visitors and bird experts",,'Springer Science and Business Media LLC',Deep Learning Locally Trained Wildlife Sensing in Real Acoustic Wetland Environment,10.1007/978-981-13-5758-9_1,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429990396,2021-01-01T00:00:00,"Multiple sclerosis (MS) is a chronic autoimmune, inflammatory neurological disease of the central nervous system. Its diagnosis nowadays commonly includes performing an MRI scan, as it is the most sensitive imaging test for MS. MS plaques are commonly identified from fluid-attenuated inversion recovery (FLAIR) images as hyperintense regions that are highly varying in terms of their shapes, sizes and locations, and are routinely classified in accordance to the McDonald criteria. Recent years have seen an increase in works that aimed at development of various semi-automatic and automatic methods for detection, segmentation and classification of MS plaques. In this paper, we present an automatic combined method, based on two pipelines: a traditional unsupervised machine learning technique and a deep-learning attention-gate 3D U-net network. The deep-learning network is specifically trained to address the weaker points of the traditional approach, namely difficulties in segmenting infratentorial and juxtacortical plaques in real-world clinical MRIs. It was trained and validated on a multi-center multi-scanner dataset that contains 159 cases, each with T1 weighted (T1w) and FLAIR images, as well as manual delineations of the MS plaques, segmented and validated by a panel of raters. The detection rate was quantified using lesion-wise Dice score. A simple label fusion is implemented to combine the output segmentations of the two pipelines. This combined method improves the detection of infratentorial and juxtacortical lesions by 14% and 31% respectively, in comparison to the unsupervised machine learning pipeline that was used as a performance assessment baseline","[{'title': 'NeuroImage Clinical', 'identifiers': ['2213-1582', 'issn:2213-1582']}]",'Elsevier BV',icobrain ms 5.1: Combining unsupervised and supervised approaches for improving the detection of multiple sclerosis lesions,10.1016/j.nicl.2021.102707,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480199312,2021-08-01T00:00:00,"Social distancing and the shortage of healthcare professionals during the COVID-19 pandemic, the impact of population aging on the healthcare system, as well as the rapid pace of digital innovation are catalyzing the development and implementation of new technologies and digital services in psychiatry. Is this transformation a blessing or a curse for psychiatry? To answer this question, we conducted a literature review covering a broad range of new technologies and eHealth services, including telepsychiatry; computer-, internet-, and app-based cognitive behavioral therapy; virtual reality; digital applied games; a digital medicine system; omics; neuroimaging; machine learning; precision psychiatry; clinical decision support; electronic health records; physician charting; digital language translators; and online mental health resources for patients. We found that eHealth services provide effective, scalable, and cost-efficient options for the treatment of people with limited or no access to mental health care. This review highlights innovative technologies spearheading the way to more effective and safer treatments. We identified artificially intelligent tools that relieve physicians from routine tasks, allowing them to focus on collaborative doctor–patient relationships. The transformation of traditional clinics into digital ones is outlined, and the challenges associated with the successful deployment of digitalization in psychiatry are highlighted","[{'title': 'International Journal of Environmental Research and Public Health', 'identifiers': ['issn:1660-4601', '1660-4601', '1661-7827', 'issn:1661-7827']}]",'MDPI AG',Psychiatry in the Digital Age: A Blessing or a Curse?,10.3390/ijerph18168302,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480137986,2021-01-01T00:00:00,"Schizophrenia is a chronic mental illness, characterized by the loss of the notion of reality, failing to distinguish it from the imaginary. It affects the patient in life’s major areas, such as work, interpersonal relationships, or self-care, and the usual treatment is performed with the help of anti-psychotic medication, which targets primarily the hallucinations, delirium, etc. Other symptoms, such as the decreased emotional expression or avolition, require a multidisciplinary approach, including psychopharmacology, cognitive training, and many forms of therapy. In this context, this paper addresses the use of digital technologies to design and develop innovative rehabilitation techniques, particularly focusing on mental health rehabilitation, and contributing for the promotion of well-being and health from a holistic perspective. In this context, serious games and virtual reality allows for creation of immersive environments that contribute to a more effective and lasting recovery, with improvements in terms of quality of life. The use of machine learning techniques will allow the real-time analysis of the data collected during the execution of the rehabilitation procedures, as well as enable their dynamic and automatic adaptation according to the profile and performance of the patients, by increasing or reducing the exercises’ difficulty. It relies on the acquisition of biometric and physiological signals, such as voice, heart rate, and game performance, to estimate the stress level, thus adapting the difficulty of the experience to the skills of the patient. The system described in this paper is currently in development, in collaboration with a health unit, and is an engineering effort that combines hardware and software to develop a rehabilitation tool for schizophrenic patients. A clinical trial is also planned for assessing the effectiveness of the system among negative symptoms in schizophrenia patients.info:eu-repo/semantics/publishedVersio","[{'title': 'Electronics', 'identifiers': ['issn:2079-9292', '2079-9292']}]",Jungong Han,Digital technologies for innovative mental health rehabilitation,,https://core.ac.uk/download/480137986.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
362230590,2021-01-10T00:00:00,"8 pages, 7 figures, submitted to ICPR 2020International audienceRecently, researchers in Machine Learning algorithms, Computer Vision scientists, engineers and others, showed a growing interest in 3D simulators as a mean to artificially create experimental settings that are very close to those in the real world. However, most of the existing platforms to interface algorithms with 3D environments are often designed to setup navigation-related experiments, to study physical interactions, or to handle ad-hoc cases that are not thought to be customized, sometimes lacking a strong photorealistic appearance and an easy-to-use software interface. In this paper, we present a novel platform, SAILenv, that is specifically designed to be simple and customizable, and that allows researchers to experiment visual recognition in virtual 3D scenes. A few lines of code are needed to interface every algorithm with the virtual world, and non-3D-graphics experts can easily customize the 3D environment itself, exploiting a collection of photorealistic objects. Our framework yields pixel-level semantic and instance labeling, depth, and, to the best of our knowledge, it is the only one that provides motion-related information directly inherited from the 3D engine. The client-server communication operates at a low level, avoiding the overhead of HTTP-based data exchanges. We perform experiments using a state-of-the-art object detector trained on real-world images, showing that it is able to recognize the photorealistic 3D objects of our environment. The computational burden of the optical flow compares favourably with the estimation performed using modern GPU-based convolutional networks or more classic implementations. We believe that the scientific community will benefit from the easiness and high-quality of our framework to evaluate newly proposed algorithms in their own customized realistic conditions",,HAL CCSD,SAILenv: Learning in Virtual Visual Environments Made Simple,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480371007,2021-01-01T00:00:00,"RISC-V has been experiencing explosive growth since its first appearance in 2011. Dozens of free and open cores developed based on this instruction set architecture have been released, and RISC-V based devices optimized for specific applications such as the IoT and wearables, embedded systems, AI, and virtual, augmented reality are emerging. As the RISC-V cores are being used in various fields, the demand for multicore platforms composed of RISC-V cores is also rapidly increasing. Although there are various RISC-V cores developed for each specific application, and it seems possible to pick them up to create the most optimized multicore for the target application, unfortunately it is very difficult to realize this in reality. This is mainly because most open cores are released in the form of a single core without cache coherence logic, which requires expensive design effort and development costs to address it. To tackle this issue, this paper proposes a method to solve the cache coherence problem without additional effort from the developer and to maximize the performance of the multicore composed of the RISC-V core selected by the developer. Along with a description of the sophisticated operating mechanisms of the proposed method, this paper details the architecture and hardware implementation of the proposed method. Experiments conducted through the prototype development of a RISC-V multicore platform involving the proposed architecture and development of an application running on the platform demonstrate the effectiveness of the proposed method","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Developing a Multicore Platform Utilizing Open RISC-V Cores,10.1109/ACCESS.2021.3108475,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480191673,2021-08-01T00:00:00,"The provision of high data rate services to mobile users combined with improved quality of experience (i.e., zero latency multimedia content) drives technological evolution towards the design and implementation of fifth generation (5G) broadband wireless networks. To this end, a dynamic network design approach is adopted whereby network topology is configured according to service demands. In parallel, many private companies are interested in developing their own 5G networks, also referred to as non-public networks (NPNs), since this deployment is expected to leverage holistic production monitoring and support critical applications. In this context, this paper introduces a 5G NPN architectural approach, supporting among others various key enabling technologies, such as cell densification, disaggregated RAN with open interfaces, edge computing, and AI/ML-based network optimization. In the same framework, potential applications of our proposed approach in real world scenarios (e.g., support of mission critical services and computer vision analytics for emergencies) are described. Finally, scalability issues are also highlighted since a deployment framework of our architectural design in an additional real-world scenario related to Industry 4.0 (smart manufacturing) is also analyzed","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',"A Cost-Efficient 5G Non-Public Network Architectural Approach: Key Concepts and Enablers, Building Blocks and Potential Use Cases",10.3390/s21165578,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
482086944,2021-09-01T00:00:00,"Artificial Intelligence (AI) is one of the hottest topics in our society, especially when it comes to solving data-analysis problems. Industry are conducting their digital shifts, and AI is becoming a cornerstone technology for making decisions out of the huge amount of (sensors-based) data available in the production floor. However, such technology may be disappointing when deployed in real conditions. Despite good theoretical performances and high accuracy when trained and tested in isolation, a Machine-Learning (M-L) model may provide degraded performances in real conditions. One reason may be fragility in treating properly unexpected or perturbed data. The objective of the paper is therefore to study the robustness of seven M-L and Deep-Learning (D-L) algorithms, when classifying univariate time-series under perturbations. A systematic approach is proposed for artificially injecting perturbations in the data and for evaluating the robustness of the models. This approach focuses on two perturbations that are likely to happen during data collection. Our experimental study, conducted on twenty sensors’ datasets from the public University of California Riverside (UCR) repository, shows a great disparity of the models’ robustness under data quality degradation. Those results are used to analyse whether the impact of such robustness can be predictable—thanks to decision trees—which would prevent us from testing all perturbations scenarios. Our study shows that building such a predictor is not straightforward and suggests that such a systematic approach needs to be used for evaluating AI models’ robustness","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',A Systematic Approach for Evaluating Artificial Intelligence Models in Industrial Settings,10.3390/s21186195,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480188131,2021-08-01T00:00:00,"The automotive sector digitalization accelerates the technology convergence of perception, computing processing, connectivity, propulsion, and data fusion for electric connected autonomous and shared (ECAS) vehicles. This brings cutting-edge computing paradigms with embedded cognitive capabilities into vehicle domains and data infrastructure to provide holistic intrinsic and extrinsic intelligence for new mobility applications. Digital technologies are a significant enabler in achieving the sustainability goals of the green transformation of the mobility and transportation sectors. Innovation occurs predominantly in ECAS vehicles’ architecture, operations, intelligent functions, and automotive digital infrastructure. The traditional ownership model is moving toward multimodal and shared mobility services. The ECAS vehicle’s technology allows for the development of virtual automotive functions that run on shared hardware platforms with data unlocking value, and for introducing new, shared computing-based automotive features. Facilitating vehicle automation, vehicle electrification, vehicle-to-everything (V2X) communication is accomplished by the convergence of artificial intelligence (AI), cellular/wireless connectivity, edge computing, the Internet of things (IoT), the Internet of intelligent things (IoIT), digital twins (DTs), virtual/augmented reality (VR/AR) and distributed ledger technologies (DLTs). Vehicles become more intelligent, connected, functioning as edge micro servers on wheels, powered by sensors/actuators, hardware (HW), software (SW) and smart virtual functions that are integrated into the digital infrastructure. Electrification, automation, connectivity, digitalization, decarbonization, decentralization, and standardization are the main drivers that unlock intelligent vehicles' potential for sustainable green mobility applications. ECAS vehicles act as autonomous agents using swarm intelligence to communicate and exchange information, either directly or indirectly, with each other and the infrastructure, accessing independent services such as energy, high-definition maps, routes, infrastructure information, traffic lights, tolls, parking (micropayments), and finding emergent/intelligent solutions. The article gives an overview of the advances in AI technologies and applications to realize intelligent functions and optimize vehicle performance, control, and decision-making for future ECAS vehicles to support the acceleration of deployment in various mobility scenarios. ECAS vehicles, systems, sub-systems, and components are subjected to stringent regulatory frameworks, which set rigorous requirements for autonomous vehicles. An in-depth assessment of existing standards, regulations, and laws, including a thorough gap analysis, is required. Global guidelines must be provided on how to fulfill the requirements. ECAS vehicle technology trustworthiness, including AI-based HW/SW and algorithms, is necessary for developing ECAS systems across the entire automotive ecosystem. The safety and transparency of AI-based technology and the explainability of the purpose, use, benefits, and limitations of AI systems are critical for fulfilling trustworthiness requirements. The article presents ECAS vehicles’ evolution toward domain controller, zonal vehicle, and federated vehicle/edge/cloud-centric based on distributed intelligence in the vehicle and infrastructure level architectures and the role of AI techniques and methods to implement the different autonomous driving and optimization functions for sustainable green mobility","[{'title': None, 'identifiers': ['issn:2673-5210', '2673-5210']}]",'Frontiers Media SA',Automotive Intelligence Embedded in Electric Connected Autonomous and Shared Vehicles Technology for Sustainable Green Mobility,10.3389/ffutr.2021.688482,https://core.ac.uk/download/480188131.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
474903340,2021-06-01T00:00:00,"Cultural heritage information systems, such as H-BIM, are becoming more and more widespread today, thanks to their potential to bring together, around a 3D representation, the wealth of knowledge related to a given object of study. However, the reconstruction of such tools starting from 3D architectural surveying is still largely deemed as a lengthy and time-consuming process, with inherent complexities related to managing and interpreting unstructured and unorganized data derived, e.g., from laser scanning or photogrammetry. Tackling this issue and starting from reality-based surveying, the purpose of this paper is to semi-automatically reconstruct parametric representations for H-BIM-related uses, by means of the most recent 3D data classification techniques that exploit Artificial Intelligence (AI). The presented methodology consists of a first semantic segmentation phase, aiming at the automatic recognition through AI of architectural elements of historic buildings within points clouds; a Random Forest classifier is used for the classification task, evaluating each time the performance of the predictive model. At a second stage, visual programming techniques are applied to the reconstruction of a conceptual mock-up of each detected element and to the subsequent propagation of the 3D information to other objects with similar characteristics. The resulting parametric model can be used for heritage preservation and dissemination purposes, as common practices implemented in modern H-BIM documentation systems. The methodology is tailored to representative case studies related to the typology of the medieval cloister and scattered over the Tuscan territory","[{'title': None, 'identifiers': ['2194-9034', 'issn:2194-9034', '1682-1750', 'issn:1682-1750']}]",'Copernicus GmbH',CONNECTING GEOMETRY AND SEMANTICS VIA ARTIFICIAL INTELLIGENCE: FROM 3D CLASSIFICATION OF HERITAGE DATA TO H-BIM REPRESENTATIONS,10.5194/isprs-archives-XLIII-B2-2021-145-2021,https://core.ac.uk/download/474903340.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491008795,2021-10-01T00:00:00,"In modern years, network edges have been explored by many applications to lower communication and management costs. They are also integrated with the internet of things (IoT) to achieve network design, in terms of scalability and heterogeneous services for multimedia applications. Many proposed solutions are performing a vital role in the development of robust protocols and reducing the response time for critical networks. However, most of them are not able to support the forwarding processes of high multimedia traffic under dynamic characteristics with constraint bandwidth. Moreover, they increase the rate of data loss in an uncertain environment and compromise network performance by increasing delivery delay. Therefore, this paper presents an optimization model with mobile edges for multimedia sensors using artificial intelligence of things, which aims to maintain the process of real-time data collection with low consumption of resources. Moreover, it improves the unpredictability of network communication with the integration of software-defined networks (SDN) and mobile edges. Firstly, it utilizes the artificial intelligence of things (AIoT), forming the multi-hop network and guaranteed the primary services for constraints network with stable resources management. Secondly, the SDN performs direct association with mobile edges to support the load balancing for multimedia sensors and centralized the management. Finally, multimedia traffic is heading towards applications in an unchanged form and without negotiating using the sharing of subkeys. The experimental results demonstrated its effectiveness for delivery rate by an average of 35%, processing delay by an average of 29%, network overheads by an average of 41%, packet drop ratio by an average of 39%, and packet retransmission by an average of 34% against existing solutions","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',An Optimization Model with Network Edges for Multimedia Sensors Using Artificial Intelligence of Things,10.3390/s21217103,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480201700,2021-08-01T00:00:00,"Deepfake and manipulated digital photos and videos are being increasingly used in a myriad of cybercrimes. Ransomware, the dissemination of fake news, and digital kidnapping-related crimes are the most recurrent, in which tampered multimedia content has been the primordial disseminating vehicle. Digital forensic analysis tools are being widely used by criminal investigations to automate the identification of digital evidence in seized electronic equipment. The number of files to be processed and the complexity of the crimes under analysis have highlighted the need to employ efficient digital forensics techniques grounded on state-of-the-art technologies. Machine Learning (ML) researchers have been challenged to apply techniques and methods to improve the automatic detection of manipulated multimedia content. However, the implementation of such methods have not yet been massively incorporated into digital forensic tools, mostly due to the lack of realistic and well-structured datasets of photos and videos. The diversity and richness of the datasets are crucial to benchmark the ML models and to evaluate their appropriateness to be applied in real-world digital forensics applications. An example is the development of third-party modules for the widely used Autopsy digital forensic application. This paper presents a dataset obtained by extracting a set of simple features from genuine and manipulated photos and videos, which are part of state-of-the-art existing datasets. The resulting dataset is balanced, and each entry comprises a label and a vector of numeric values corresponding to the features extracted through a Discrete Fourier Transform (DFT). The dataset is available in a GitHub repository, and the total amount of photos and video frames is 40,588 and 12,400, respectively. The dataset was validated and benchmarked with deep learning Convolutional Neural Networks (CNN) and Support Vector Machines (SVM) methods; however, a plethora of other existing ones can be applied. Generically, the results show a better F1-score for CNN when comparing with SVM, both for photos and videos processing. CNN achieved an F1-score of 0.9968 and 0.8415 for photos and videos, respectively. Regarding SVM, the results obtained with 5-fold cross-validation are 0.9953 and 0.7955, respectively, for photos and videos processing. A set of methods written in Python is available for the researchers, namely to preprocess and extract the features from the original photos and videos files and to build the training and testing sets. Additional methods are also available to convert the original PKL files into CSV and TXT, which gives more flexibility for the ML researchers to use the dataset on existing ML frameworks and tools","[{'title': 'Data', 'identifiers': ['2306-5729', 'issn:2306-5729']}]",'MDPI AG',A Dataset of Photos and Videos for Digital Forensics Analysis Using Machine Learning Processing,10.3390/data6080087,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
511382804,2021-01-01T00:00:00,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.Scopu",,'Elsevier BV',1D convolutional neural networks and applications: A survey,10.1016/j.ymssp.2020.107398,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478476599,2021-06-16T00:00:00,"Dynamic hand gesture recognition is a challenging task of Human-Computer Interaction (HCI) and Computer Vision. The potential application areas of gesture recognition include sign language translation, video gaming, video surveillance, robotics, and gesture-controlled home appliances. In the proposed research, gesture recognition is applied to recognize sign language words from real-time videos. Classifying the actions from video sequences requires both spatial and temporal features. The proposed system handles the former by the Convolutional Neural Network (CNN), which is the core of several computer vision solutions and the latter by the Recurrent Neural Network (RNN), which is more efficient in handling the sequences of movements. Thus, the real-time Indian sign language (ISL) recognition system is developed using the hybrid CNN-RNN architecture. The system is trained with the proposed CasTalk-ISL dataset. The ultimate purpose of the presented research is to deploy a real-time sign language translator to break the hurdles present in the communication between hearing-impaired people and normal people. The developed system achieves 95.99% top-1 accuracy and 99.46% top-3 accuracy on the test dataset. The obtained results outperform the existing approaches using various deep models on different datasets",,'EMITTER International Journal of Engineering Technology',Indian Sign Language Recognition through Hybrid ConvNet-LSTM Networks,10.24003/emitter.v9i1.613,https://core.ac.uk/download/478476599.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478762593,2021-01-01T00:00:00,"Image segmentation is an important research in image processing and machine vision in which automated driving can be seen the main application scene of image segmentation algorithms. Due to the many constraints of power supply and communication in in-vehicle systems, the vast majority of current image segmentation algorithms are implemented based on the deep learning model. Despite the ultrahigh segmentation accuracy, the problem of mesh artifacts and segmentation being too severe is obvious, and the high cost, computational, and power consumption devices required are difficult to apply in real-world scenarios. It is the focus of this paper to construct a road scene segmentation model with simple structure and no need of large computing power under the premise of certain accuracy. In this paper, the ESPNet (Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation) model is introduced in detail. On this basis, an improved ESPNet model is proposed based on ESPNet. Firstly, the network structure of the ESPNet model is optimized, and then, the model is optimized by using a small amount of weakly labeled and unlabeled scene sample data. Finally, the new model is applied to video image segmentation based on dash cam. It is verified on Cityscape, PASCAL VOC 2012, and other datasets that the algorithm proposed in this paper is faster, and the amount of parameters required is less than 1% of other algorithms, so it is suitable for mobile terminals","[{'title': 'Security and Communication Networks', 'identifiers': ['issn:1939-0122', '1939-0122']}]",'Hindawi Limited',The Segmentation of Road Scenes Based on Improved ESPNet Model,10.1155/2021/1681952,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
524587303,2022-04-02T00:00:00,"Study shows that mask-wearing is a critical factor in stopping the COVID-19 transmission. By the time of this article, most states have mandated face masking in public space. Therefore, real-time face mask detection becomes an essential application to prevent the spread of the pandemic. This study will present a face mask detection system that can detect and monitor mask-wearing from camera feeds and alert when there is a violation. The face mask detection algorithm uses a haar cascade classifier to find facial features from the camera feed and then utilizes it to detect the mask-wearing status. With the increasing number of cases all over the world, a system to replace humans to check masks on the faces of people is greatly needed. This system satisfies that need. This system can be employed in public places like transport stations and malls. It will be of great help in companies and huge establishments where there will be a lot of workers.   Alongside this, we have used basic concepts of transfer learning in neural networks to finally output the presence or absence of a face mask in an image or a video stream. Experimental results show that our model performs well on the test data with 100 percent and 99 percent precision and recall, respectively. We are making a savvy framework that will identify whether the specific user has worn the mask or not and further tell the accuracy level of the detection. Our framework will be python and AI-based which will be safe and quick for implementation.  This system will be of great help there because it is easy to obtain and store the data of the employees working in that Company and will very easily find the people who are not wearing the mask and a will be  sent to that respective person to take Precautions not wearing a mask. Potential delays are analyzed, and efforts are made to reduce them to achieve real-time detection. The experiment result shows that the presented system achieves a real-time 45fps 720p Video output, with a face mask detection response of 0.15s and the accuracy of detection 99%. Keywords: Covid-19, Face Mask Detection, Alert System, CCTV DOI: 10.7176/CEIS/13-2-01 Publication date:March 31st 2022 ",,"The International Institute for Science, Technology and Education (IISTE)",COVID-19 Face Mask Detection Alert System,,https://core.ac.uk/download/524587303.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478580989,2021-09-06T00:00:00,"Implementation of the Industry 4.0 concept is considered in the context of automation of railway transport. The analysis refers to prerequisites for creation of a universal digital platform integrating automation systems at a marshalling yard.The example of JSC Russian Railways has contributed to describe the main goals of Digital Station concept, aimed at fusion of data from low-level local automation equipment. The presented functionality of the system for control and processing information on movements of wagons and locomotives at the station in real time (SCPI MWL RT) implements the set goals by integrating initial data from all automation and centralised traffic control systems operating at the station, checking it for consistency, eliminating information redundancy and generating in real time the current model of a marshalling yard regarding trains and wagons and based on data «from the wheel».Description of the existing functionality of SCPI MWL RT, implemented at a facility, is followed by the analysis of the advantages of this system for the railway cargo transportation network. The objective of the paper is to present some previously unpublished technical solutions for implementation of the specified functionality. The methods of the research are based on fusion of heterogeneous data received from floor devices, specialised video cameras, as well as from real-time wagon positioning models.It is shown that adoption of new technical solutions for SCPI MWL RT will allow to considerably improve the quality of planning of technological process of classifying railway wagons and of forecasting the need for infrastructure maintenance. Deep learning algorithms presented ensure functioning of the developed solutions in real time with high accuracy. Further steps described refer to implementation of a digital platform in the form of a digital twin of a marshalling yard, creating thus a prerequisite for development of an intelligent automatic machine to control the marshalling yard, as well as for further planned ways to implementation there-of.Реализация концепции «Индустрия 4.0» рассмотрена в контексте автоматизации железнодорожного транспорта. Проанализированы предпосылки для создания универсальной цифровой платформы, объединяющей системы автоматизации на сортировочной станции.На примере ОАО «РЖД» описаны основные цели концепции «Цифровая станция», направленные на слияние данных от низовой автоматики. Представлен функционал системы контроля и подготовки информации о перемещениях вагонов и локомотивов на станции в реальном времени (СКПИ ПВЛ РВ), реализующей поставленные цели путём обобщения исходной информации от всех действующих на станции систем автоматизации и централизации, проверки её на непротиворечивость, устранения избыточности информации и формирование в реальном времени текущей поездной и вагонной модели сортировочной станции на основе данных «от колеса».Описан существующий функционал СКПИ ПВЛ РВ, реализованный на реальном объекте внедрения, и представлены преиму щества данной системы для сети грузовых перевозок на железнодорожном транспорте. Целью работы является представление отдельных ранее не опубликованных технических решений реализации указанного функционала. Методы работы основаны на слиянии разнородных данных, получаемых от напольных устройств, специализированных видеокамер, а также моделей позиционирования вагонов реального времени.Показано, что внедрение новых технических решений в СКПИ ПВЛ РВ позволит на порядок повысить качество планирования выполнения технологического процесса сортировки железнодорожных вагонов и прогноза необходимости обслуживания инфраструктуры. Представлены алгоритмы глубокого обучения, обеспечивающие функционирование разрабатываемых решений в реальном времени с высокой точностью. Описаны дальнейшие шаги по реализации цифровой платформы в виде цифрового двойника сортировочной станции, что создаст предпосылку для разработки интеллектуального автомата управления сортировочной станцией и планируемые пути реализации",,'FSBEO HPE Moscow State University of Railway Engineering (MIIT)',Концепция цифровой платформы на сортировочных станциях,10.30932/1992-3252-2021-19-1-60-73,https://core.ac.uk/download/478580989.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491332743,2021-01-01T00:00:00,"Ultrasound imaging can be employed to improve automation levels in minimally invasive surgery and eventually enable full automation by providing real-time situational awareness to medical robots via intra-operative, real-time, volumetric mapping of the surgical site. This talk describes the development of a prototype automated image guidance system, combining high-refresh-rate, volumetric ultrasound (US) imaging (or 4D US) and advanced deep learning strategies for an autonomous robotic platform, currently being investigated for knee surgery. The feasibility of using 4D US for guidance in knee minimally invasive surgery was first proved through cadaver and volunteer studies. The workflow to enable automatic interpretation of 4D US imaging for robotic guidance was then developed and implemented. The essential steps include automatic image quality assessment, tissue segmentation and tracking (in combination with the assessment of uncertainties) and surgical tool tracking. The results obtained show US imaging's potential for quantitative autonomous tasks and for the creation of autonomous, intelligent robotic surgical systems that will hopefully soon make surgery more sustainable and improve people's quality of life.Learning Objectives:1. US imaging combined with deep learning strategies can provide a solution for real-time volumetric guidance for autonomous systems;2. The algorithms developed and implemented can be extended to US images of other body districts;3. The workflow elucidated provides solutions to the issues currently limiting the application of US imaging to quantitative autonomous tasks;<br/",,,Platform for Ultrasound-Guided Autonomous Minimally Invasive Surgery: Application to the Knee,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480336524,2021-12-01T00:00:00,"Speech Emotion Recognition (SER) is an important part of Affective Computing and emotionally aware Human–Computer Interaction. Emotional expression may vary depending on the language, culture, and the speaker’s personality and vocal attributes. Speaker-adaptive systems can address this issue. In real-world applications, it is not feasible to obtain big datasets for deep learning model training from a specific speaker. This paper proposes a transfer learning approach for personalized SER based on convolutional neural networks. A CNN is trained in a multi-user dataset for generalization and then is fine-tuned for a small speaker-specific dataset. A VGGish model, pre-trained a large-scale dataset for audio event recognition is also evaluated for the task. This comparison highlights the significance of network capacity, dataset length, and domain-relativity for transfer learning. To enhance the applicability of this approach in real-world conditions, a web crowdsourcing application is implemented. An online platform is provided where contributors can follow a standard procedure to record and submit annotated utterances of emotional speech. The recordings are validated and added to the publicly available AESDD dataset of emotional speech. The platform can be used for the creation of personalized emotional speech datasets for speaker-adaptive SER, following the transfer learning strategies that have been evaluated","[{'title': None, 'identifiers': ['issn:2666-8270', '2666-8270']}]",'Elsevier BV',A web crowdsourcing framework for transfer learning and personalized Speech Emotion Recognition,10.1016/j.mlwa.2021.100132,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491009773,2021-11-01T00:00:00,"Hydrogel has a complex network structure with inhomogeneous and random distribution of polymer chains. Much effort has been paid to fully understand the relationship between mesoscopic network structure and macroscopic mechanical properties of hydrogels. In this paper, we develop a deep learning approach to predict the mechanical properties of hydrogels from polymer network structures. First, network structural models of hydrogels are constructed from mesoscopic scale using self-avoiding walk method. The constructed model is similar to the real hydrogel network. Then, two deep learning models are proposed to capture the nonlinear mapping from mesoscopic hydrogel network structural model to its macroscale mechanical property. A deep neural network and a 3D convolutional neural network containing the physical information of the network structural model are implemented to predict the nominal stress–stretch curves of hydrogels under uniaxial tension. Our results show that the end-to-end deep learning framework can effectively predict the nominal stress–stretch curves of hydrogel within a wide range of mesoscopic network structures, which demonstrates that the deep learning models are able to capture the internal relationship between complex network structures and mechanical properties. We hope this approach can provide guidance to structural design and material property design of different soft materials","[{'title': 'Mathematics', 'identifiers': ['issn:2227-7390', '2227-7390']}]",'MDPI AG',Deep Learning Approach to Mechanical Property Prediction of Single-Network Hydrogel,10.3390/math9212804,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480151527,2021-06-01T00:00:00,"The article has dealt with the current trends of communication aspects of company’s relations

with the customers. The emphasis is placed on the necessity to review the companies’ marketing

strategies, in particular, due to communication constraints and the corresponding changes in the format

of both direct and feedback with the customers. Restrictive measures have changed the format of

competition, having created the conditions for its concentration in cyberspace. Changes in the nature

of interpersonal communication predetermined by the limited personal activity and the introduction

of remote forms of interaction, have generated demand for innovative ways of communication with

customers. Other factors that require the adjustment of marketing strategies include the emergence

of new behavioral capabilities of consumers associated with the intensive development of digital

communication channels.

It has been noted that in the digital communication environment, digital platforms provide the main

format of communication with the existing customer base and potential customers. In addition, prompt

acquisition and processing of data on purchasing behavior of customers allows companies to increase

significantly the “sensitivity” of marketing research and optimize their own marketing decisions. Among

the areas of increasing targeting and personalization of product offerings, the use of elements of artificial

intelligence and voice search has been accentuated. Moreover, the use of artificial intelligence greatly

facilitates and simplifies the work of marketers on the processing and initial analysis of the growing flow

of digital marketing data, as well as provides greater efficiency. It has been concluded that widespread use

of voice assistants in e-commerce requires companies to rethink radically their approaches to internal data

processing, IT investment and customer engagement strategies.

Active integration of chatbots into various communication platforms is able to make them

universal tools for both business and consumers, which will allow them to become a familiar part of

the user experience. Implementation of virtual reality and augmented reality elements in the interface

of company websites can significantly diversify the process of collecting information by users and push

them to unplanned purchases.

It has been indicated that the growing standards of personalization and new rules of customer

confidentiality will continue to require companies to be flexible and introduce new technologies in

order to adapt permanently their business to new conditions. Focusing on building trust with customers\ud
based on digital communications will enable companies to create a long-term integrated marketing

strategy and concentrate on the multi-channel nature of customer experienc","[{'title': 'Academic Review', 'identifiers': ['2074-5354', 'issn:2074-5354']}]",'Alfred Nobel University',MODERN DIGITAL MARKETING TRENDS AND THEIR INFLUENCE ON THE MARKETING STRATEGY FORMATION,10.32342/2074-5354-2021-1-54-5,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395143647,2021-02-01T00:00:00,"[EN] Although knowledge of the microstructure of food of vegetal origin helps us to understand the behavior of food materials, the variability in the microstructural elements complicates this analysis. In this regard, the construction of learning models that represent the actual microstructures of the tissue is important to extract relevant information and advance in the comprehension of such behavior. Consequently, the objective of this research is to compare two machine learning techniques¿Convolutional Neural Networks (CNN) and Radial Basis Neural Networks (RBNN)¿when used to enhance its microstructural analysis. Two main contributions can be highlighted from this research. First, a method is proposed to automatically analyze the microstructural elements of vegetal tissue; and second, a comparison was conducted to select a classifier to discriminate between tissue structures. For the comparison, a database of microstructural elements images was obtained from pumpkin (Cucurbita pepo L.) micrographs. Two classifiers were implemented using CNN and RBNN, and statistical performance metrics were computed using a 5-fold cross-validation scheme. This process was repeated one hundred times with a random selection of images in each repetition. The comparison showed that the classifiers based on CNN produced a better fit, obtaining F1¿score average of 89.42% in front of 83.83% for RBNN. In this study, the performance of classifiers based on CNN was significantly higher compared to those based on RBNN in the discrimination of microstructural elements of vegetable foods.Oblitas, J.; Mejía, J.; De-La-Torre, M.; Avila-George, H.; Seguí Gil, L.; Mayor López, L.; Ibarz, A.... (2021). Classification of the Microstructural Elements of the Vegetal
Tissue of the Pumpkin (Cucurbita pepo L.) Using Convolutional Neural Networks. Applied Sciences. 11(4):1-13. https://doi.org/10.3390/app11041581S113114Betoret, E., Betoret, N., Rocculi, P., & Dalla Rosa, M. (2015). Strategies to improve food functionality: Structure–property relationships on high pressures homogenization, vacuum impregnation and drying technologies. Trends in Food Science & Technology, 46(1), 1-12. doi:10.1016/j.tifs.2015.07.006Fito, P., LeMaguer, M., Betoret, N., & Fito, P. J. (2007). Advanced food process engineering to model real foods and processes: The «SAFES» methodology. Journal of Food Engineering, 83(2), 173-185. doi:10.1016/j.jfoodeng.2007.02.017Topete-Betancourt, A., De D. Figueroa-Cárdenas, J., Morales-Sánchez, E., Arámbula-Villa, G., & Pérez-Robles, J. F. (2019). EVALUATION OF THE MECHANISM OF OIL UPTAKE AND WATER LOSS DURING DEEP-FAT FRYING OF TORTILLA CHIPS. Revista Mexicana de Ingeniería Química, 19(1), 409-422. doi:10.24275/rmiq/alim605Silva-Jara, J. M., López-Cruz, R., Ragazzo-Sánchez, J. A., & Calderón-Santoyo, M. (2019). Antagonistic microorganisms efficiency to suppress damage caused by Colletotrichum gloeosporioides in papaya crop: Perspectives and challenges. Revista Mexicana de Ingeniería Química, 19(2), 839-849. doi:10.24275/rmiq/bio788Aguilera, J. M. (2005). Why food microstructure? Journal of Food Engineering, 67(1-2), 3-11. doi:10.1016/j.jfoodeng.2004.05.050Pieczywek, P. M., & Zdunek, A. (2012). Automatic classification of cells and intercellular spaces of apple tissue. Computers and Electronics in Agriculture, 81, 72-78. doi:10.1016/j.compag.2011.11.006Mayor, L., Pissarra, J., & Sereno, A. M. (2008). Microstructural changes during osmotic dehydration of parenchymatic pumpkin tissue. Journal of Food Engineering, 85(3), 326-339. doi:10.1016/j.jfoodeng.2007.06.038Mebatsion, H. K., Verboven, P., Verlinden, B. E., Ho, Q. T., Nguyen, T. A., & Nicolaï, B. M. (2006). Microscale modelling of fruit tissue using Voronoi tessellations. Computers and Electronics in Agriculture, 52(1-2), 36-48. doi:10.1016/j.compag.2006.01.002Oblitas-Cruz, J. F., Castro-Silupu, W. M., & Mayor-López, L. (2015). Effect of different combinations of size and shape parameters in the percentage error of classification of structural elements in vegetal tissue of the pumpkin Cucurbita pepo L. using probabilistic neural networks. Revista Facultad de Ingeniería Universidad de Antioquia, (78). doi:10.17533/udea.redin.n78a04Meng, N., Lam, E. Y., Tsia, K. K., & So, H. K.-H. (2019). Large-Scale Multi-Class Image-Based Cell Classification With Deep Learning. IEEE Journal of Biomedical and Health Informatics, 23(5), 2091-2098. doi:10.1109/jbhi.2018.2878878Adeshina, S. A., Adedigba, A. P., Adeniyi, A. A., & Aibinu, A. M. (2018). Breast Cancer Histopathology Image Classification with Deep Convolutional Neural Networks. 2018 14th International Conference on Electronics Computer and Computation (ICECCO). doi:10.1109/icecco.2018.8634690Aliyu, H. A., Sudirman, R., Abdul Razak, M. A., & Abd Wahab, M. A. (2018). Red Blood Cell Classification: Deep Learning Architecture Versus Support Vector Machine. 2018 2nd International Conference on BioSignal Analysis, Processing and Systems (ICBAPS). doi:10.1109/icbaps.2018.8527398Reddy, A. S. B., & Juliet, D. S. (2019). Transfer Learning with ResNet-50 for Malaria Cell-Image Classification. 2019 International Conference on Communication and Signal Processing (ICCSP). doi:10.1109/iccsp.2019.8697909Mayor, L., Moreira, R., & Sereno, A. M. (2011). Shrinkage, density, porosity and shape changes during dehydration of pumpkin (Cucurbita pepo L.) fruits. Journal of Food Engineering, 103(1), 29-37. doi:10.1016/j.jfoodeng.2010.08.031Castro, W., Oblitas, J., De-La-Torre, M., Cotrina, C., Bazan, K., & Avila-George, H. (2019). Classification of Cape Gooseberry Fruit According to its Level of Ripeness Using Machine Learning Techniques and Different Color Spaces. IEEE Access, 7, 27389-27400. doi:10.1109/access.2019.2898223Valdez-Morones, T., Perez-Espinosa, H., Avila-George, H., Oblitas, J., & Castro, W. (2018). An Android App for detecting damage on tobacco (Nicotiana tabacum L.) leaves caused by blue mold (Penospora tabacina Adam). 2018 7th International Conference On Software Process Improvement (CIMPS). doi:10.1109/cimps.2018.8625628Castro, W., Oblitas, J., Chuquizuta, T., & Avila-George, H. (2017). Application of image analysis to optimization of the bread-making process based on the acceptability of the crust color. Journal of Cereal Science, 74, 194-199. doi:10.1016/j.jcs.2017.02.002De-la -Torre, M., Zatarain, O., Avila-George, H., Muñoz, M., Oblitas, J., Lozada, R., … Castro, W. (2019). Multivariate Analysis and Machine Learning for Ripeness Classification of Cape Gooseberry Fruits. Processes, 7(12), 928. doi:10.3390/pr7120928Fernández-Navarro, F., Hervás-Martínez, C., Gutiérrez, P. A., & Carbonero-Ruz, M. (2011). Evolutionary q-Gaussian radial basis function neural networks for multiclassification. Neural Networks, 24(7), 779-784. doi:10.1016/j.neunet.2011.03.014Huang, W., Oh, S.-K., & Pedrycz, W. (2014). Design of hybrid radial basis function neural networks (HRBFNNs) realized with the aid of hybridization of fuzzy clustering method (FCM) and polynomial neural networks (PNNs). Neural Networks, 60, 166-181. doi:10.1016/j.neunet.2014.08.007Zhou, Y., Nejati, H., Do, T.-T., Cheung, N.-M., & Cheah, L. (2016). Image-based vehicle analysis using deep neural network: A systematic study. 2016 IEEE International Conference on Digital Signal Processing (DSP). doi:10.1109/icdsp.2016.7868561Toliupa, S., Tereikovskyi, I., Tereikovskyi, O., Tereikovska, L., Nakonechnyi, V., & Kulakov, Y. (2020). Keyboard Dynamic Analysis by Alexnet Type Neural Network. 2020 IEEE 15th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering (TCSET). doi:10.1109/tcset49122.2020.235466Lu, S., Lu, Z., & Zhang, Y.-D. (2019). Pathological brain detection based on AlexNet and transfer learning. Journal of Computational Science, 30, 41-47. doi:10.1016/j.jocs.2018.11.008Kraus, O. Z., Ba, J. L., & Frey, B. J. (2016). Classifying and segmenting microscopy images with deep multiple instance learning. Bioinformatics, 32(12), i52-i59. doi:10.1093/bioinformatics/btw252Du, C.-J., & Sun, D.-W. (2006). Learning techniques used in computer vision for food quality evaluation: a review. Journal of Food Engineering, 72(1), 39-55. doi:10.1016/j.jfoodeng.2004.11.017Brosnan, T., & Sun, D.-W. (2004). Improving quality inspection of food products by computer vision––a review. Journal of Food Engineering, 61(1), 3-16. doi:10.1016/s0260-8774(03)00183-3Baker, N., Lu, H., Erlikhman, G., & Kellman, P. J. (2018). Deep convolutional networks do not classify based on global object shape. PLOS Computational Biology, 14(12), e1006613. doi:10.1371/journal.pcbi.1006613Rohmatillah, M., Pramono, S. H., Rahmadwati, Suyono, H., & Sena, S. A. (2018). Automatic Cervical Cell Classification Using Features Extracted by Convolutional Neural Network. 2018 Electrical Power, Electronics, Communications, Controls and Informatics Seminar (EECCIS). doi:10.1109/eeccis.2018.8692888Sadanandan, S. K., Ranefall, P., & Wählby, C. (2016). Feature Augmented Deep Neural Networks for Segmentation of Cells. Computer Vision – ECCV 2016 Workshops, 231-243. doi:10.1007/978-3-319-46604-0_17Sharma, M., Bhave, A., & Janghel, R. R. (2019). White Blood Cell Classification Using Convolutional Neural Network. Soft Computing and Signal Processing, 135-143. doi:10.1007/978-981-13-3600-3_13Song, W., Li, S., Liu, J., Qin, H., Zhang, B., Zhang, S., & Hao, A. (2019). Multitask Cascade Convolution Neural Networks for Automatic Thyroid Nodule Detection and Recognition. IEEE Journal of Biomedical and Health Informatics, 23(3), 1215-1224. doi:10.1109/jbhi.2018.2852718Akram, S. U., Kannala, J., Eklund, L., & Heikkila, J. (2016). Cell proposal network for microscopy image analysis. 2016 IEEE International Conference on Image Processing (ICIP). doi:10.1109/icip.2016.753295",,'MDPI AG',"Classification of the Microstructural Elements of the Vegetal
Tissue of the Pumpkin (Cucurbita pepo L.) Using Convolutional Neural Networks",10.3390/app11041581,https://riunet.upv.es/bitstream/10251/163576/1/Oblitas%3bMej%c3%ada%3bDe-La-Torre%20-%20Classification%20of%20the%20Microstructural%20Elements%20of%20the%20VegetalTissue%20o....pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478193234,2022-02-15T00:00:00,"The real-time, and accurate inference of model parameters is of great importance in many scientific and engineering disciplines that use computational models (such as a digital twin) for the analysis and prediction of complex physical processes. However, fast and accurate inference for processes of complex systems cannot easily be achieved in real-time with state-of-the-art methods under noisy real-world conditions with the requirement of a real-time response. The primary reason is that the inference of model parameters with traditional techniques based on optimization or sampling often suffers from computational and statistical challenges, resulting in a trade-off between accuracy and deployment time. In this paper, we propose a novel framework for inference of model parameters based on reinforcement learning. The proposed methodology is demonstrated and evaluated on two different physics-based models of turbofan engines. The experimental results demonstrate that the proposed methodology outperforms all other tested methods in terms of speed and robustness, with high inference accuracy.ISSN:0888-3270ISSN:1096-121",,'Elsevier BV',Real-time model calibration with deep reinforcement learning,10.1016/j.ymssp.2021.108284,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479465616,2021-01-01T00:00:00,"Robotics, Artificial Intelligence (AI), and the Internet of Things (IoT) support various processes in many scenarios of modern life such as e-health and psychological treatments. This article presents the design, development, implementation, and assessment of a Robotic Assistant (RA), named &#x201C;Atent&#x0040;&#x201D;, as a support tool in the homework activities of children with Attention Deficit Hyperactivity Disorder (ADHD). Interacting with the children the RA helps them correct their bad habits and misbehavior caused by the disorder. Its features and functionalities were designed by therapists, implementing AI algorithms to process information and make decisions in real-time to help children to be focused on their homework. This RA interacts with smart objects deployed at home, which are associated with the activity under observation (desk and chair). This solution allows therapists to receive more accurate information about the homework sessions inside the home. At the same time, remote interaction with the child is made possible (through the RA) to provide new instructions and support him/her along with the sessions. This RA is a significant evolution of an earlier version. All the improvements brought to the project by the modifications in technical and qualitative features are explained. Furthermore, the experiment and its results are presented to illustrate the clinical potential. This project shows that the RA can not only make observations with a high degree of precision like an expert (teacher/therapist) but also positively influences the homework performance of children with and without ADHD","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Assessment of a Robotic Assistant for Supporting Homework Activities of Children With ADHD,10.1109/ACCESS.2021.3093233,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478204378,2021-08-26T00:00:00,"Background: Following the induction of oestrus out of season in small ruminants, low fertility and variations in fertility rates are associated with embryonic losses. One of the main causes of embryonic loss is luteal dysfunction. Gonadotropin Releasing Hormone (GnRH) supports the luteal structure, and increasing progesterone levels may be beneficial in terms of promoting embryonic life. The main objective of the present study was to evaluate the efficacy of GnRH administration following an oestrus induction protocol in the anoestrus season for preventing embryonic loss in goats having failure to conceive during the season. Materials, Methods & Results: In the study, 106 Damascus goats aged 3-5 years and weighing 45-60 kg were used. The oestrus of 106 goats in the anoestrous group was stimulated with progesterone and pregnant mare serum gonadotropin (PMSG) treatment. Out of breeding season, goats were divided into the 4 following groups: GnRH0 (n = 27), GnRH7 (n = 26), GnRH0+7 (n = 27) and control (n = 26). In each goat, an intravaginal sponge (IS) containing 20 mg of fluorogestone acetate (FGA) was placed into the vagina and left for 9 days. With the withdrawal of the sponge, 550IU PMSG and 125 μg of d-cloprostenol were injected intramuscularly. Oestrus detection was made via teaser bucks for 3 days starting 24 h after withdrawal of the IS. Eighteen bucks known to be fertile were used for breeding. Goats in the oestrus period were mated via natural breeding. The GnRH analogue lecirelin was injected intramuscularly at breeding in the GnRH0 group, on day 7 post-breeding in the GnRH7 group, and both at breeding and on day 7 post-breeding in the GnRH0+7 group. No injections were given to the control group. Blood samples for progesterone measurement were taken by jugular vena puncturing on days 3, 6, 7, 10, 13, 16, and 19 after breeding from 10 randomly chosen goats in all groups. The goats with a level of > 3.5 ng/mL of progesterone on day 21 post-breeding were evaluated as pregnant. Pregnancy was also viewed on day 50 after breeding by real-time ultrasonography (USG) with a 5-7.5 MHz convex probe. The oestrus rate was 96.23% (102/106) in the goats. The rates of onset of oestrus between 36-48 h, 48-60 h and 60 h and beyond were 38.7% (41/106), 21.7% (23/106) and 35.8% (38/106), respectively. The total pregnancy rate was 35.8% (38/106). There were no statistically significant differences (P > 0.05) found for the pregnancy rate, embryonic death rate or progesterone concentration of the groups. However, serum progesterone levels were statistically different in the GnRH7 group compared with the control group (P < 0.05).Discussion: After synchronisation, various anti-luteolytic strategies can be used to support corpus luteum development and elevate progesterone concentration in the luteal phase to decrease embryonic loss and increase reproductive performance. Therefore, application of GnRH to support the luteal structure and to increase progesterone levels may be beneficial in terms of supporting embryonic life. The results showed that GnRH treatment on the day 7 post-breeding following oestrus induction, including FGA and PMSG, can increase serum progesterone levels in Damascus goats in the anoestrus period. However, following oestrus induction in the anoestrus period, it was seen that GnRH treatment at breeding or on day 7 after breeding did not have any positive effect on embryonic loss or reproductive performance. In conclusion, it was considered that this protocol could be implemented successfully, yielding a 35% pregnancy rate in Damascus goats in the anoestrus period, but embryonic loss must be deeply studied in detail",,'Universidade Federal do Rio Grande do Sul',The Effect of Gonadotropin Releasing Hormone Administration on Fertility and Embryonic Loss in Goats during the Anoestrus Period,10.22456/1679-9216.111167,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491037081,2021-11-01T00:00:00,"Since consuming gutter oil does great harm to people’s health, the Food Safety Administration has always been seeking for a more effective and timely supervision. As laboratory tests consume much time, and existing field tests have excessive limitations, a more comprehensive method is in great need. This is the first time a study proposes machine learning algorithms for real-time gutter oil detection under multiple feature dimensions. Moreover, it is deployed on FPGA to be low-power and portable for actual use. Firstly, a variety of oil samples are generated by simulating the real detection environment. Next, based on previous studies, sensors are used to collect significant features that help distinguish gutter oil. Then, the acquired features are filtered and compared using a variety of classifiers. The best classification result is obtained by k-NN with an accuracy of 97.18%, and the algorithm is deployed to FPGA with no significant loss of accuracy. Power consumption is further reduced with the approximate multiplier we designed. Finally, the experimental results show that compared with all other platforms, the whole FPGA-based classification process consumes 4.77 µs and the power consumption is 65.62 mW. The dataset, source code and the 3D modeling file are all open-sourced","[{'title': 'PeerJ Computer Science', 'identifiers': ['2376-5992', 'issn:2376-5992']}]",'PeerJ',Gutter oil detection for food safety based on multi-feature machine learning and implementation on FPGA with approximate multipliers,10.7717/peerj-cs.774,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
484044156,2021-01-01T00:00:00,"Versatile Video Coding (VVC/H.266) is the next-generation international video coding standard and a successor to the widespread High Efficiency Video Coding (HEVC/H.265). This paper analyzes the rate-distortion-complexity characteristics of the VVC reference software (VTM10.0) by using HEVC reference software (HM16.22) as an anchor. In this independent study, the rate-distortion performance of VTM was benchmarked against HM with the objective PSNR, SSIM, and VMAF quality metrics and the associated encoder and decoder complexities were profiled at function level using Intel VTune Profiler on Intel Xeon E5-2699 v4 22-core processors. For a fair comparison, all our experiments were conducted under the VTM common test conditions (CTC) that define 10-bit configurations of the VTM codec for the addressed All Intra (AI), Random Access (RA), and Low Delay B (LB) conditions. The VTM CTC test set was also extended with complementary 4K UHD sequences to elaborate RD characteristics with higher resolutions. According to our evaluations, VTM improves the average coding efficiency over HM, depending on quality metric, by 23.0&#x2013;23.9% under the AI condition, 33.1&#x2013;36.6% under the RA condition, and 26.7&#x2013;29.5% under the LB condition. However, the coding gain of VTM comes with 34.0&#x00D7;, 8.8&#x00D7;, and 7.5&#x00D7; encoding complexity over that of HM under the AI, RA, and LB conditions, respectively. The corresponding overhead of the VTM decoder stays steady at 1.8&#x00D7; across all conditions. This study also pinpoints the most complex parts of the VTM codec and discusses practical implementation aspects of prospective real-time VVC encoders and decoders.publishedVersionPeer reviewe","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Comparative Rate-Distortion-Complexity Analysis of VVC and HEVC Video Codecs,10.1109/ACCESS.2021.3077116,https://core.ac.uk/download/484044156.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
426057424,2021-01-01T00:00:00,"Clinical trials in cancer treatment are imperative in enhancing patients\u2019 survival and quality of life outcomes. The lack of communication among professionals may produce a non-optimization of patients\u2019 accrual in clinical trials. We developed a specific platform, called \u201cDigital Research Assistant\u201d (DRA), to report real-time every available clinical trial and support clinician. Healthcare professionals involved in breast cancer working group agreed nine minimal fields of interest to preliminarily classify the characteristics of patients\u2019 records (including omic data, such as genomic mutations). A progressive web app (PWA) was developed to implement a cross-platform software that was scalable on several electronic devices to share the patients\u2019 records and clinical trials. A specialist is able to use and populate the platform. An AI algorithm helps in the matchmaking between patient\u2019s data and clinical trial\u2019s inclusion criteria to personalize patient enrollment. At the same time, an easy configuration allows the application of the DRA in different oncology working groups (from breast cancer to lung cancer). The DRA might represent a valid research tool supporting clinicians and scientists, in order to optimize the enrollment of patients in clinical trials. User Experience and Technology The acceptance of participants using the DRA is topic of a future analysis",,'MDPI AG',Development of a digital research assistant for the management of patients\u2019 enrollment in oncology clinical trials within a research hospital,10.3390/jpm11040244,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
344908526,2021-01-01T00:00:00,"Abstract

Real-time intelligent video processing on embedded devices with low power consumption can be useful for applications like drone surveillance, smart cars, and more. However, the limited resources of embedded devices is a challenging issue for effective embedded computing. Most of the existing work on this topic focuses on single device based solutions, without the use of cloud computing mechanisms for parallel processing to boost performance. In this paper, we propose a cloud platform for real-time video processing based on embedded devices. Eight NVIDIA Jetson TX1 and three Jetson TX2 GPUs are used to construct a streaming embedded cloud platform (SECP), on which Apache Storm is deployed as the cloud computing environment for deep learning algorithms (Convolutional Neural Networks — CNNs) to process video streams. Additionally, self-managing services are designed to ensure that this platform can run smoothly and stably, in the form of a metric sensor, a bottleneck detector and a scheduler. This platform is evaluated in terms of processing speed, power consumption, and network throughput by running various deep learning algorithms for object detection. The results show the proposed platform can run deep learning algorithms on embedded devices while meeting the high scalability and fault tolerance required for real-time video processing",,'Institute of Electrical and Electronics Engineers (IEEE)',A streaming cloud platform for real-time video processing on embedded devices,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
493123570,2021-12-31T00:00:00,"[EN] With current data acquisition techniques, exhaustive documentation of patrimonial goods is generated, which allows obtaining a 3D geometric model, on which data from research from research is generated. As in other fields of architecture, the latest graphic techniques and manipulation of the image, allow a working methodology other than the current one in the patrimonial field. The information systems have been evolving towards technologies developed with open source software, the use of standards, ontologies and the structuring of information and of the 3D model itself under a semantic hierarchy. Interoperability between databases is favored and the maintenance of applications is ensured. The purpose is to support decision-making related to the model and simultaneously, serve multiple purposes such as cataloging, protection, restoration, conservation, maintenance or dissemination, among others. The research carried out for the realization of the survey of the City Council and Lonja of Alcañiz (Teruel), has the aim of expanding the historical knowledge of the buildings and delimiting its possible constructive phases, in order to obtain the geometric reality of the buildings. In this way, provide greater instruments to carry out the drafting work of the set restoration project. Quintilla Castán, M.; Agustín Hernández, L. (2021). 3D survey and virtual reconstruction of heritage. The case study of the City Council and Lonja of Alcañiz. VITRUVIO - International Journal of Architectural Technology and Sustainability. 6(2):12-25. https://doi.org/10.4995/vitruvio-ijats.2021.16567OJS122562Afsari, K., Eastman, C., Shelden, D. 2016. Cloud-Based BIM Data Transmission: Current Status and Challenges. 33rd International Symposium on Automation and Robotics in Construction (ISARC 2016). https://doi.org/10.22260/ISARC2016/0129Apollonio, F.I., Benedetti, B., Gaiani, M. 2011. Construction, Management and Visualization of 3D Models of Large Archeological and Architectural Sites for E-Heritage GIS Systems. XXIIIrd International CIPA Symposium, Prague, Czech Republic. https://doi.org/10.6092/unibo/amsacta/3141Armisén Fernández, A., García Fernández-Jardón, B., Mateos Redondo, F. J., Valdeón Menéndez, L., Rojo Álvarez, A. 2016. Plataforma virtual para el diseño, planificación, control, intervención y mantenimiento en el ámbito de la conservación del patrimonio histórico ""PETROBIM"". Congreso Euro-Americano REHABEND 2016, Universidad de Cantabria.Armisén Fernández, A., Agustín, L.,..., Soto, A. 2018. BIM aplicado al patrimonio cultural. España: Building SMART Spanish Chapter: Documento 14. https://www.buildingsmart.es/recursos/gu%C3%ADas-ubim/Banfi, F. 2019. The integration of a scan-To-HBIM process in bim application: The development of an add-in to guide users in autodesk revit. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLII-2/W11, 141-148. https://doi.org/10.5194/isprs-archives-XLII-2-W11-141-2019De Luca, L., Busayarat, C., Stefani, C., Véron, P., Florenzano, M. 2011. A semantic-based platform for the digital analysis of architectural heritage. Computers & Graphics. 35(2), 227-241. https://doi.org/10.1016/j.cag.2010.11.009Dore, C., Murphy, M., Mccarthy, M., Casidy, C., Dirix, E. 2015. Structural Simulations and Conservation Analysis -Historic Building Information Model (HBIM). ISPRS-The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XL-5/W4, 351-357. https://doi.org/10.5194/isprsarchives-XL-5-W4-351-2015Fassi, F., Achille, C., Mandelli, A., Rechichi, F., Parri, S. 2015. A new idea of BIM system for visualization, web sharing and using huge complex 3d models for facility management, ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XL-5/W4, 359-366. https://doi.org/10.5194/isprsarchives-XL-5-W4-359-2015Fassi, F., Fregonese, L., Adami, A., Rechichi, F. 2017. BIM system for the conservation and preservation of the mosaics of San Marco in Venice. ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLII-2/W5, 229-236. doi.org/ 94/isprs-archives-XLII-2-W5-229-2017Hernández Martínez, A. 2016. La restauración monumental en Aragón en la década de los 70 del siglo XX: las intervenciones de Chueca Goitia en las casas consistoriales de Tarazona, Alcañiz y Uncastillo. El Greco en su IV Centenario: patrimonio hispánico y diálogo intercultural. Textos de ponencias y comunicaciones. Cuenca, Ediciones de la Universidad de Castilla-La Mancha, Colección ""Estudios"" 151: 338.Iadanza, E., Maietti, F., Ziri, A.E., Di Giulio, R., Medici, M., Ferrari, F., Bonsma, P., Turillazzi, B. 2019. Semantic web technologies meet BIM for accessing and understanding cultural heritage. ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLII-2/W9, 381-388. https://doi.org/10.5194/isprs-archives-XLII-2-W9-381-2019Malinverni, E.S., Pierdicca, R., Paolanti, M., Martini, M., Morbidoni, C., Matrone, F., Lingua, A. 2019. Deep learning for semantic segmentation of 3D point cloud. ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLII-2/W15, 735-742. https://doi.org/10.5194/isprs-archives-XLII-2-W15-735-2019Marston, S., Li, Z., Bandyopadhyay, S., Zhang, J., Ghalsasi, A. 2011. Cloud computing-The business perspective. Decision Support Systems, 51(1), 176-189. https://doi.org/10.1016/j.dss.2010.12.006Murphy, M., Mcgovern, E., Pavia, S. 2013. Historic Building Information Modelling - Adding intelligence to laser and image based surveys of European claasical architecture. ISPRS Journal of Photogrammetry and Remote Sensing, 76, 89-102. https://doi.org/10.1016/j.isprsjprs.2012.11.006Nieto Julián, J. E., Moyano Campos, J. J. 2014. El Estudio Paramental en el Modelo de Información del Edificio Histórico o ""Proyecto HBIM"". Virtual Archaeology Review, 5(11), 73-85. https://doi.org/10.4995/var.2014.4183Nieto Julián, J.E., Moyano Campos, J.J., Rico Delgado, F., Antón García, D. 2016. Management of built heritage via HBIM Project: A case of study of flooring and tiling, Virtual Archaeology Review, 7(14), 1-12. https://doi.org/ 10.4995/var.2016.4349Oreni, D., Brumana, R., Della Torre, S., Banfi, F., & Previtali, M., 2014. Survey turned into HBIM: the restoration and the work involved concerning the Basilica di Collemaggio after the earthquake (L'Aquila). ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 2(5), 267-273. https://doi.org/10.5194/isprsannals-II-5-267-2014Quattrini, R., Pierdicca, R., Morbidoni, C., Malinverni, E.S. 2017. Conservation-oriented HBIM. The Bimexplorer web tool. ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLII-5/W1, 275-281. https://doi.org/10.5194/isprs-archives-XLII-5-W1-275-2017Rechichi, F., Mandelli, A., Achille, C., Fassi, F. 2016. Sharing high-resolution models and information on web: the web module of bim3dsg system. ISPRS-International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, XLI-B5, 703-710. https://doi.org/10.5194/isprs-archives-XLI-B5-703-2016Schuster, J. M. D. 1997. Information as a tool of preservation action. Preserving the built heritage: tools for implementation. Hanover and London: 32. University Press of New England.Thomson Llisterri, T. 2015. Conjunto Lonja-Ayuntamiento de Alcañiz. Fuentes y estado de la cuestión. Jornadas de Arte sobre la Lonja de Alcañiz. Taller de investigación multidisciplinar. Jornadas de estudio y difusión del patrimonio. Contextualización histórica. Alcañiz, Centro de Estudios de Arte del Renacimiento, 1 al 3 de julio de 2015",,'Universitat Politecnica de Valencia',3D survey and virtual reconstruction of heritage. The case study of the City Council and Lonja of Alcañiz,10.4995/vitruvio-ijats.2021.16567,https://riunet.upv.es/bitstream/10251/179281/1/QuintillaAgustin%20-%203D%20survey%20and%20virtual%20reconstruction%20of%20heritage%20The%20case%20study%20of%20the%20City%20Co....pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
516350676,2021-01-01T00:00:00,"International audienceCollaborative robots are currently deployed in professional environments, in collaboration with professional human operators, helping to strike the right balance between mechanization and manual intervention in manufacturing processes required by Industry 4.0. In this paper, the contribution of gesture recognition and pose estimation to the smooth introduction of cobots into an industrial assembly line is described, with a view to performing actions in parallel with the human operators and enabling interaction between them. The proposed active vision system uses two RGB-D cameras that record different points of view of gestures and poses of the operator, to build an external perception layer for the robot that facilitates spatiotemporal adaptation, in accordance with the human's behavior. The use-case of this work is concerned with LCD TV assembly of an appliance manufacturer, comprising of two parts. The first part of the above-mentioned operation is assigned to a robot, strengthening the assembly line. The second part is assigned to a human operator. Gesture recognition, pose estimation, physical interaction, and sonic notification, create a multimodal human-robot interaction system. Five experiments are performed, to test if gesture recognition and pose estimation can reduce the cycle time and range of motion of the operator, respectively. Physical interaction is achieved using the force sensor of the cobot. Pose estimation through a skeleton-tracking algorithm provides the cobot with human pose information and makes it spatially adjustable. Sonic notification is added for the case of unexpected incidents. A real-time gesture recognition module is implemented through a Deep Learning architecture consisting of Convolutional layers, trained in an egocentric view and reducing the cycle time of the routine by almost 20%. This constitutes an added value in this work, as it affords the potential of recognizing gestures independently of the anthropometric characteristics and the background. Common metrics derived from the literature are used for the evaluation of the proposed system. The percentage of spatial adaptation of the cobot is proposed as a new KPI for a collaborative system and the opinion of the human operator is measured through a questionnaire that concerns the various affective states of the operator during the collaboration",,'Frontiers Media SA',Egocentric Gesture Recognition Using 3D Convolutional Neural Networks for the Spatiotemporal Adaptation of Collaborative Robots,10.3389/fnbot.2021.703545,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429956590,2021-01-01T00:00:00,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap. (C) 2020 The Author(s). Published by Elsevier Ltd",,'Elsevier BV',1D convolutional neural networks and applications : A survey,10.1016/j.ymssp.2020.107398,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
479365133,2021-01-01T00:00:00,"The ability to estimate radio coverage accurately is fundamental for planning and optimizing any wireless network, notably when a new generation, as the 5th Generation (5G), is in an early deployment phase. The knowledge acquired from radio planning of previous generations must be revisited, particularly the used path loss and antennas models, as the 5G propagation is intrinsically distinct. This paper analyses a new beamforming antenna model and distinct path loss models - 3rd Generation Partnership Project (3GPP) and Millimetre-Wave Based Mobile Radio Access Network for Fifth Generation Integrated Communications (mmMAGIC) - applying them to evaluate 5G coverage in 3-Dimensional (3D) synthetic and real scenarios, for outdoor and indoor environments. Further, real 5G Drive Tests (DTs) were used to evaluate the 3GPP path loss model accuracy in Urban Macro (UMa) scenarios. For the new antenna model, it is shown that the use of beamforming with multiple vertical beams is advantageous when the Base Station (BS) is placed below the surrounding buildings; in regular UMa surroundings, one vertical beam provides adequate indoor coverage and a maximized outdoor coverage after antenna tilt optimization. The 3GPP path loss model exhibited a Mean Absolute Error (MAE) of 21.05 dB for Line-of-Sight (LoS) and 14.48 dB for Non-Line-of-Sight (NLoS), compared with real measurements. After calibration, the MAE for LoS and NLoS decreased to 5.45 dB and 7.51 dB, respectively. Moreover, the non-calibrated 3GPP path loss model led to overestimations of the 5G coverage and user throughput up to 25&#x0025; and 163&#x0025;, respectively, when compared to the calibrated model predictions. The use of Machine Learning (ML) algorithms resulted in path loss MAEs within the range of 4.58 dB to 5.38 dB, for LoS, and within the range of 3.70 dB to 5.96 dB, for NLoS, with the Random Forest (RF) algorithm attaining the lowest error","[{'title': 'IEEE Access', 'identifiers': ['issn:2169-3536', '2169-3536']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Analysis and Optimization of 5G Coverage Predictions Using a Beamforming Antenna Model and Real Drive Test Measurements,10.1109/ACCESS.2021.3097633,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
480156297,2021-06-01T00:00:00,"Dynamic hand gesture recognition is a challenging task of Human-Computer Interaction (HCI) and Computer Vision. The potential application areas of gesture recognition include sign language translation, video gaming, video surveillance, robotics, and gesture-controlled home appliances. In the proposed research, gesture recognition is applied to recognize sign language words from real-time videos. Classifying the actions from video sequences requires both spatial and temporal features. The proposed system handles the former by the Convolutional Neural Network (CNN), which is the core of several computer vision solutions and the latter by the Recurrent Neural Network (RNN), which is more efficient in handling the sequences of movements. Thus, the real-time Indian sign language (ISL) recognition system is developed using the hybrid CNN-RNN architecture. The system is trained with the proposed CasTalk-ISL dataset. The ultimate purpose of the presented research is to deploy a real-time sign language translator to break the hurdles present in the communication between hearing-impaired people and normal people. The developed system achieves 95.99% top-1 accuracy and 99.46% top-3 accuracy on the test dataset. The obtained results outperform the existing approaches using various deep models on different datasets","[{'title': 'EMITTER International Journal of Engineering Technology', 'identifiers': ['issn:2355-391X', 'issn:2443-1168', '2443-1168', '2355-391x']}]",'EMITTER International Journal of Engineering Technology',Indian Sign Language Recognition through Hybrid ConvNet-LSTM Networks,10.24003/emitter.v9i1.613,https://core.ac.uk/download/480156297.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
490592519,2021-01-01T00:00:00,"Background: Following the induction of oestrus out of season in small ruminants, low fertility and variations in fertility rates are associated with embryonic losses. One of the main causes of embryonic loss is luteal dysfunction. Gonadotropin Releasing Hormone (GnRH) supports the luteal structure, and increasing progesterone levels may be beneficial in terms of promoting embryonic life. The main objective of the present study was to evaluate the efficacy of GnRH administration following an oestrus induction protocol in the anoestrus season for preventing embryonic loss in goats having failure to conceive during the season. Materials, Methods &amp; Results: In the study, 106 Damascus goats aged 3-5 years and weighing 45-60 kg were used. The oestrus of 106 goats in the anoestrous group was stimulated with progesterone and pregnant mare serum gonadotropin (PMSG) treatment. Out of breeding season, goats were divided into the 4 following groups: GnRH0 (n = 27), GnRH7 (n = 26), GnRH0+7 (n = 27) and control (n = 26). In each goat, an intravaginal sponge (IS) containing 20 mg of fluorogestone acetate (FGA) was placed into the vagina and left for 9 days. With the withdrawal of the sponge, 550IU PMSG and 125 μg of d-cloprostenol were injected intramuscularly. Oestrus detection was made via teaser bucks for 3 days starting 24 h after withdrawal of the IS. Eighteen bucks known to be fertile were used for breeding. Goats in the oestrus period were mated via natural breeding. The GnRH analogue lecirelin was injected intramuscularly at breeding in the GnRH0 group, on day 7 post-breeding in the GnRH7 group, and both at breeding and on day 7 post-breeding in the GnRH0+7 group. No injections were given to the control group. Blood samples for progesterone measurement were taken by jugular vena puncturing on days 3, 6, 7, 10, 13, 16, and 19 after breeding from 10 randomly chosen goats in all groups. The goats with a level of &gt; 3.5 ng/mL of progesterone on day 21 post-breeding were evaluated as pregnant. Pregnancy was also viewed on day 50 after breeding by real-time ultrasonography (USG) with a 5-7.5 MHz convex probe. The oestrus rate was 96.23% (102/106) in the goats. The rates of onset of oestrus between 36-48 h, 48-60 h and 60 h and beyond were 38.7% (41/106), 21.7% (23/106) and 35.8% (38/106), respectively. The total pregnancy rate was 35.8% (38/106). There were no statistically significant differences (P &gt; 0.05) found for the pregnancy rate, embryonic death rate or progesterone concentration of the groups. However, serum progesterone levels were statistically different in the GnRH7 group compared with the control group (P &lt; 0.05).Discussion: After synchronisation, various anti-luteolytic strategies can be used to support corpus luteum development and elevate progesterone concentration in the luteal phase to decrease embryonic loss and increase reproductive performance. Therefore, application of GnRH to support the luteal structure and to increase progesterone levels may be beneficial in terms of supporting embryonic life. The results showed that GnRH treatment on the day 7 post-breeding following oestrus induction, including FGA and PMSG, can increase serum progesterone levels in Damascus goats in the anoestrus period. However, following oestrus induction in the anoestrus period, it was seen that GnRH treatment at breeding or on day 7 after breeding did not have any positive effect on embryonic loss or reproductive performance. In conclusion, it was considered that this protocol could be implemented successfully, yielding a 35% pregnancy rate in Damascus goats in the anoestrus period, but embryonic loss must be deeply studied in detail",,'PGDesign / Universidade Federal do Rio Grande do Sul',The Effect of Gonadotropin Releasing Hormone Administration on Fertility and Embryonic Loss in Goats during the Anoestrus Period,,https://core.ac.uk/download/490592519.pdf,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
475060377,2021-01-01T00:00:00,"Underwater video monitoring systems are being widely used in fisheries to investigate fish behavior in relation to fishing gear and fishing gear performance during fishing. Such systems can be useful to evaluate the catch composition as well. In demersal trawl fisheries, however, their applicability can be challenged by low light conditions, mobilized sediment and scattering in murky waters. In this study, we introduce a novel observation system (called NepCon) which aims at reducing current limitations by combining an optimized image acquisition setup and tailored image analyses software. The NepCon system includes a high-contrast background to enhance the visibility of the target objects, a compact camera and an artificial light source. The image analysis software includes a machine learning algorithm which is evaluated here to test automatic detection and count of Norway lobster (Nephrops norvegicus). NepCon is specifically designed for applications in demersal trawls and this first phase aims at increasing the accuracy of N. norvegicus detection at the data acquisition level. To find the best contrasting background for the purpose we compared the output of four image segmentation methods applied to static images of N. norvegicus fixed in front of four test background colors. The background color with the best performance was then used to evaluate computer vision and deep learning approaches for automatic detection, tracking and counting of N. norvegicus in the videos. In this initial phase we tested the system in an experimental setting to understand the feasibility of the system for future implementation in real demersal fishing conditions. The N. norvegicus directed trawl fishery typically has no assistance from underwater observation technology and therefore are largely conducted blindly. The demonstrated perception system achieves 76% accuracy (F-score) in automatic detection and count of N. norvegicus, which provides a significant elevation of the current benchmark","[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",'Public Library of Science (PLoS)',Towards sustainable demersal fisheries: NepCon image acquisition system for automatic Nephrops norvegicus detection.,10.1371/journal.pone.0252824,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237673362,2019-10-07T00:00:00,"The acquisition of cryo-electron microscopy (cryo-EM) data from biological specimens must be tightly coupled to data preprocessing to ensure the best data quality and microscope usage. Here we describe Warp, a software that automates all preprocessing steps of cryo-EM data acquisition and enables real-time evaluation. Warp corrects micrographs for global and local motion, estimates the local defocus and monitors key parameters for each recorded micrograph or tomographic tilt series in real time. The software further includes deep-learning-based models for accurate particle picking and image denoising. The output from Warp can be fed into established programs for particle classification and 3D-map refinement. Our benchmarks show improvement in the nominal resolution, which went from 3.9 Å to 3.2 Å, of a published cryo-EM data set for influenza virus hemagglutinin. Warp is easy to install from http://github.com/cramerlab/warp and computationally inexpensive, and has an intuitive, streamlined user interface",'Springer Science and Business Media LLC',Real-time cryo-electron microscopy data preprocessing with Warp.,10.1038/s41592-019-0580-y,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
213372873,2019-05-29T00:00:00,"International audienceThis paper describes the principles and implementation results of reinforcement learning algorithms on IoT devices for radio collision mitigation in ISM unlicensed bands. Learning is here used to improve both the IoT network capability to support a larger number of objects as well as the autonomy of IoT devices. We first illustrate the efficiency of the proposed approach in a proof-of-concept based on USRP software radio platforms operating on real radio signals. It shows how collisions with other RF signals present in the ISM band are diminished for a given IoT device. Then we describe the first implementation of learning algorithms on LoRa devices operating in a real LoRaWAN network, that we named IoTligent. The proposed solution adds neither processing overhead so that it can be ran in the IoT devices, nor network overhead so that no change is required to LoRaWAN. Real life experiments have been done in a realistic LoRa network and they show that IoTligent device battery life can be extended by a factor 2 in the scenarios we faced during our experiment.L'article décrit les principes et les résultats de la mise en œuvre d'algorithmes d'apprentissage par renforcement sur des appareils de l'Internet des Objets pour l'atténuation des collisions radio dans les bandes non licenciées ISM. L'apprentissage est ici utilisé pour améliorer à la fois la capacité du réseau IoT à supporter un plus grand nombre d'objets ainsi que l'autonomie des appareils IoT. Nous illustrons d'abord l'efficacité de l'approche proposée dans une preuve de concept basée sur des plates-formes radio logicielles USRP fonctionnant sur des signaux radio réels. Cette démonstration montre comment les collisions avec d'autres signaux RF présents dans la bande ISM sont réduites pour un dispositif IoT donné. Ensuite, nous décrivons la première implémentation d'algorithmes d'apprentissage sur des appareils LoRa fonctionnant dans un réseau LoRaWAN réel, que nous avons nommé IoTligent. La solution proposée n'ajoute aucune surcharge de traitement pour qu'elle puisse être exécutée dans les périphériques IoT, ni de surcharge sur le réseau de sorte qu'aucune modification n'est nécessaire pour LoRaWAN. Des expériences réelles ont été réalisées dans un réseau LoRa, et elles montrent que la durée de vie de la batterie d'un appareil IoTligent peut être augmentée d'un facteur 2 dans les scénarios auxquels nous avons été confrontés pendant notre expérience",HAL CCSD,Apprentissage décentralisé du spectre pour l'atténuation des collisions dans les réseaux IoT sans fil,,https://core.ac.uk/download/213372873.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
352152004,2019-03-20T00:00:00,"Robotic Process Automation (RPA) is a new wave of the future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering, and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available on google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching from the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment, and onboarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor onboarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea","Universidade de São Paulo. Faculdade de Economia, Administração e Contabilidade",The future digital work force: Robotic Process Automation (Rpa),,https://core.ac.uk/download/352152004.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
328720905,2020-08-28T14:06:08,"The “time-varying loudness” (TVL) model of Glasberg and Moore calculates “instantaneous loudness” every 1 ms, and this is used to generate predictions of short-term loudness, the loudness of a short segment of sound, such as a word in a sentence, and of long-term loudness, the loudness of a longer segment of sound, such as a whole sentence. The calculation of instantaneous loudness is computationally intensive and real-time implementation of the TVL model is difficult. To speed up the computation, a deep neural network (DNN) was trained to predict instantaneous loudness using a large database of speech sounds and artificial sounds (tones alone and tones in white or pink noise), with the predictions of the TVL model as a reference (providing the “correct” answer, specifically the loudness level in phons). A multilayer perceptron with three hidden layers was found to be sufficient, with more complex DNN architecture not yielding higher accuracy. After training, the deviations between the predictions of the TVL model and the predictions of the DNN were typically less than 0.5 phons, even for types of sounds that were not used for training (music, rain, animal sounds, and washing machine). The DNN calculates instantaneous loudness over 100 times more quickly than the TVL model. Possible applications of the DNN are discussed",Trends in Hearing,Development of a Deep Neural Network for Speeding Up a Model of Loudness for Time-Varying Sounds,10.17863/CAM.56818,https://core.ac.uk/download/328720905.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
441438944,2020-10-01T00:00:00,"A lack of sensory feedback often hinders minimally invasive operations. Although endoscopy has addressed this limitation to an extent, endovascular procedures such as angioplasty or stenting still face significant challenges. Sensors that rely on a clear line of sight cannot be used because it is unable to gather feedback in blood environments. During the stent deployment procedure, feedback on the deployed stent's state is critical because a partially open stent can affect the blood flow. Despite this, no robust and noninvasive clinical solutions that allow real‐time monitoring of the stent deployment exists. In recent years, radio frequency (RF)‐based sensors can detect the shape and material of an object that is hidden from the direct line of sight. Herein, the use of a 3D RF‐based imaging sensor and a novel Convolutional Neural Network (CNN) called StentNet is proposed for detecting the stent's state without a need for a clear line of sight. The StentNet achieves an overall accuracy of 90% in detecting the state of an occluded stent in the test dataset. Compared with an existing CNN model, the StentNet significantly outperforms the 3D LeNet in the evaluation metrics such as accuracy, precision, recall, and F1‐score",'Wiley',Stent Deployment Detection Using Radio Frequency‐Based Sensor and Convolutional Neural Networks,10.1002/aisy.202000092,,"[{'title': 'Advanced Intelligent Systems', 'identifiers': ['2640-4567', 'issn:2640-4567']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237173517,2019,"In this paper we investigate the impact of a social robot in the context of serious games in which the robot plays the role of a game opponent by challenging and, at the same time, teaching the child to correctly recycle waste materials. To this aim we performed a study in which we investigated the dimensions that are used to evaluate serious games integrated with those that are typical of the interaction with a social robot. To endow the robot with the capability to play as a game opponent in a real-world context, we implemented an image recognition module based on a Convolutional Neural Network so that the robot could detect and classify the waste material as a child would do, by seeing it. After a preliminary evaluation of the approach, we started a formal experiment in which we measured the effectiveness of game design, the robot evaluation and the evaluation of cognitive and affective elements that can form the pro-environmental attitude and then the tendency to recycling. A primary school classroom was involved in the study and, results obtained so far, are encouraging and drew promising possibilities for robotics education in changing recycling attitude for children since Pepper is positively evaluated as trustful and believable and this allowed to be concentrated on the ‘memorization’ task during the game",IEEE Computer Society,Investigating the Social Robots’ Role in Improving Children Attitudes toward Recycling. The case of PeppeRecycle,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
390009408,2020-02-20T00:00:00,"Methods of machine intelligence with training contribute their specifics to the creation and commissioning of a gaming system.One of the main problems is the need to anticipate the entire set of input situations and possible answers at the time of design and the impossibility of expanding their list withoutretraining. This leads to a narrowing of the possibility of their use in real gaming systems.  The object of research is the processes of creating and training game agents based on the evolutionary approaches of artificial intelligence. The purpose of the work is the development and justification of a formal model of a game agent based on machine learning methods, software implementation of the game process using neural networks and evolutionary optimization methods for multiple generations of game agent populations. To achieve this goal, the theoretical base, the existing research and development in the industry; a game scenario was designed, the main agents were identified, their main capabilities and expected behavior; training of game agents by various types of neural networks; development testing, quality assessment of behavior and decision-making by artificial intelligence using neural networks were performed; a comparative analysis of various types of neural networks, the proposed recommendations for their use for given conditions. To display the artificial neural network, the template components of the layer, neuron, and bridge were used. The created software module will allow game agents built using various neural networks to compete with each other (and not with a person, as in the normal game mode), and will reveal more prepared ones.  The scientific novelty of the study lies in the fact that a model of a game agent is formalized, based on machine learning methods. The results obtained in this work can be used in the development of video games built on the basis of artificial intelligence of game agents based on machine learning methods, as well as in other scientific studies.Методы машинного интеллекта с обучением вносят свою специфику к созданию и наладке игровой системы.Одна из главных проблем — это необходимость предвидения всего набора входных ситуаций и возможных ответов на моменте проектирования и невозможность расширения их списка без переобучения. Это приводит к сужению возможности их использования в реальных игровых системах.Объектом исследования являются процессы создания и обучения игровых агентов на основе эволюционных подходов искусственного интеллекта. Цель работы - разработка и обоснование формальной модели игрового агента, основанного на методах машинного обучения, программная реализация игрового процесса сприменением нейронных сетей и эволюционных методов оптимизации при множественных поколениях популяций игровых агентов.Для осуществления поставленной цели исследована теоретическая база, существующие исследования и разработки в отрасли; спроектирован игровой сценарий, определены основные агенты, их основные возможности и ожидаемое поведение;реализовано обучение игровых агентов различными типами нейронных сетей; выполнено тестирование разработок, оценка качества поведения и принятия решений искусственныминтеллектом с использованием нейронных сетей; проведен сравнительный анализ различных типов нейронных сетей, предлагаемых рекомендаций по их использованию для заданныхусловий. Для отображения искусственной нейронной сети использованы шаблонные компоненты слоя, нейрона и моста.Созданный программный модуль позволит игровым агентам, построенным с использованием различных нейронных сетей, соперничать друг с другом (а не с человеком,как в обычном режиме игры), позволит выявить более подготовленного из них. Научная новизна исследования заключается в том, что формализована модель игрового агента, в основе которой методы машинного обучения. Полученные в работе результаты могут быть использованы при разработке видеоигр, построенных на базе искусственного интеллекта игровых агентов, в основекоторых методы машинного обучения, а также в рамках других научных исследований.Методи машинного інтелекту з навчанням привносять свою специфіку до створення і налагодження ігрової системи.  Одна з головних проблем - це необхідність передбачення усього набору вхідних ситуацій і можливих відповідей на моменті проектування і неможливість розширення їх списку без перенавчання. Це призводить до звуження можливості їх використання у реальних ігрових системах. Об'єктом дослідження є процеси створення і навчання ігрових агентів на основі еволюційних підходів штучного інтелекту. Мета роботи - розробка і обґрунтування формальної моделі ігрового агенту, заснованої на методах машинного навчання, програмна реалізація ігрового процесу з застосуванням нейронних мереж та еволюційних методів оптимізації при множинних генераціях популяцій ігрових агентів. Для здійснення поставленої мети досліджена теоретична база, існуюча дослідження та розробки в галузі; спроектовано ігровий сценарій, визначені основні агенти, їх основні можливості та очікувана поведінка; реалізоване навчання ігрових агентів різними типами нейронних мереж; виконане тестування розробок, оцінка якості поведінки й прийняття рішень штучним інтелектом з використанням нейронних мереж; проведений порівняльний аналіз різних типів нейронних мереж, запропонування рекомендацій щодо їх використання для заданих умов. Для відображення штучної нейронної мережі використані шаблоні компоненти слою, нейрону і мосту. Створений програмний модуль дозволить ігровим агентам, побудованим з використанням різних нейронних мереж, суперничати один з іншим (а не з людиною, як у звичайному режимі гри), дозволить виявити більш підготовленого з них. Наукова новизна одержаних результатів полягає у тому, що формалізовано модель ігрового агенту, в основі якої методи машинного навчання. Отримані в роботі результати можуть бути використані при розробці відеоігор, побудованих на базі штучного інтелекту ігрових агентів, що гуртуються на методах машинного навчання, а також в рамках інших наукових досліджень",ДВНЗ «Приазовський державний технічний університет»,ДОСЛІДЖЕННЯ ТА МОДЕЛЮВАННЯ ІГРОВОГО ПРОЦЕСУ НА БАЗІ МЕТОДІВ МАШИННОГО НАВЧАННЯ,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
387876374,2020-01-01T00:00:00,"Volume and ejection fraction (EF) measurements of the left ventricle (LV) in 2-D echocardiography are associated with a high uncertainty not only due to interobserver variability of the manual measurement, but also due to ultrasound acquisition errors such as apical foreshortening. In this work, a real-time and fully automated EF measurement and foreshortening detection method is proposed. The method uses several deep learning components, such as view classification, cardiac cycle timing, segmentation and landmark extraction, to measure the amount of foreshortening, LV volume, and EF. A data set of 500 patients from an outpatient clinic was used to train the deep neural networks, while a separate data set of 100 patients from another clinic was used for evaluation, where LV volume and EF were measured by an expert using clinical protocols and software. A quantitative analysis using 3-D ultrasound showed that EF is considerably affected by apical foreshortening, and that the proposed method can detect and quantify the amount of apical foreshortening. The bias and standard deviation of the automatic EF measurements were -3.6 ± 8.1%, while the mean absolute difference was measured at 7.2% which are all within the interobserver variability and comparable with related studies. The proposed real-time pipeline allows for a continuous acquisition and measurement workflow without user interaction, and has the potential to significantly reduce the time spent on the analysis and measurement error due to foreshortening, while providing quantitative volume measurements in the everyday echo lab",'Institute of Electrical and Electronics Engineers (IEEE)',Real-Time Automatic Ejection Fraction and Foreshortening Detection Using Deep Learning,10.1109/TUFFC.2020.2981037,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
251215068,2019-08-01T00:00:00,"PURPOSE: The use of neural networks to directly predict three-dimensional dose distributions for automatic planning is becoming popular. However, the existing methods use only patient anatomy as input and assume consistent beam configuration for all patients in the training database. The purpose of this work was to develop a more general model that considers variable beam configurations in addition to patient anatomy to achieve more comprehensive automatic planning with a potentially easier clinical implementation, without the need to train specific models for different beam settings. METHODS: The proposed anatomy and beam (AB) model is based on our newly developed deep learning architecture, and hierarchically densely connected U-Net (HD U-Net), which combines U-Net and DenseNet. The AB model contains 10 input channels: one for beam setup and the other 9 for anatomical information (PTV and organs). The beam setup information is represented by a 3D matrix of the non-modulated beam's eye view ray-tracing dose distribution. We used a set of images from 129 patients with lung cancer treated with IMRT with heterogeneous beam configurations (4-9 beams of various orientations) for training/validation (100 patients) and testing (29 patients). Mean squared error was used as the loss function. We evaluated the model's accuracy by comparing the mean dose, maximum dose, and other relevant dose-volume metrics for the predicted dose distribution against those of the clinically delivered dose distribution. Dice similarity coefficients were computed to address the spatial correspondence of the isodose volumes between the predicted and clinically delivered doses. The model was also compared with our previous work, the anatomy only (AO) model, which does not consider beam setup information and uses only 9 channels for anatomical information. RESULTS: The AB model outperformed the AO model, especially in the low and medium dose regions. In terms of dose-volume metrics, AB outperformed AO by about 1-2%. The largest improvement was found to be about 5% in lung volume receiving a dose of 5Gy or more (V5 ). The improvement for spinal cord maximum dose was also important, that is, 3.6% for cross-validation and 2.6% for testing. The AB model achieved Dice scores for isodose volumes as much as 10% higher than the AO model in low and medium dose regions and about 2-5% higher in high dose regions. CONCLUSIONS: The AO model, which does not use beam configuration as input, can still predict dose distributions with reasonable accuracy in high dose regions but introduces large errors in low and medium dose regions for IMRT cases with variable beam numbers and orientations. The proposed AB model outperforms the AO model substantially in low and medium dose regions, and slightly in high dose regions, by considering beam setup information through a cumulative non-modulated beam's eye view ray-tracing dose distribution. This new model represents a major step forward towards predicting 3D dose distributions in real clinical practices, where beam configuration could vary from patient to patient, from planner to planner, and from institution to institution.status: publishe",'Wiley',Three-dimensional dose prediction for lung IMRT patients with deep neural networks: robust learning from heterogeneous beam configurations,10.1002/mp.13597,,"[{'title': 'Medical Physics', 'identifiers': ['issn:0094-2405', 'issn:2473-4209', '0094-2405', '2473-4209']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
220589792,2019-01-01T00:00:00,"Abstract The Robotic Process Automation (RPA) is a new wave of the future technologies. Robotic Process Automation is one of the most advanced technologies in the area of computers science, electronic and communications, mechanical engineering and information technology. It is a combination of both hardware and software, networking and automation for doing things very simple. In this light, the research manuscript investigated the secondary data - which is available in google, academic and research databases. The investigation went for totally 6 months, i.e., 1-1-2018 to 30-6-2018. A very few empirical articles, white papers, blogs and were found RPA and came across to compose this research manuscript. This study is exploratory in nature because of the contemporary phenomenon. The keywords used in searching of the database were Robotic Process Automation, RPA, Robots, Artificial Intelligence, Blue Prism. The study finally discovered that Robots and Robotic Process Automation technologies are becoming compulsory as a part to do business operations in the organizations across the globe. Robotic Process Automation can bring immediate value to the core business processes including employee payroll, employee status changes, new hire recruitment and on boarding, accounts receivable and payable, invoice processing, inventory management, report creation, software installations, data migration, and vendor on boarding etc. to name a few applications. Besides, the Robotic Process Automation has abundant applications including healthcare and pharmaceuticals, financial services, outsourcing, retail, telecom, energy and utilities, real estate and FMCG and many more sectors. To put in the right place of RPA in business operations, their many allied technologies are working at the background level, artificial intelligence, machine learning, deep learning, data analytics, HR analytics, virtual reality (second life), home automation, blockchain technologies, 4D printing etc. Moreover, it covers the content of different start-ups companies and existing companies - their RPA applications used across the world. This manuscript will be a good guideline for the academicians, researchers, students, and practitioners to get an overall idea",,The Future Digital Work Force: Robotic Process Automation (RPA),,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
333567050,2020-01-01T00:00:00,"In recent year, embedded systems architectures and applications have gained a lot of interest, especially the possibility to add on-bard intelligence has fostered research in several directions, including not only smart IoT and cyber physical systems, but also hot topics such as accelerating deep learning. This special issue contains four papers dealing with architectures and design methodologies to support embedded intelligence, but also providing best practices and software support.



The paper “A Technologically Agnostic Framework for Cyber-Physical and IoT Processing-in-Memory-based Systems Simulation”, by Santos et al., aims to focus on Processing-In-Memory (PIM) as a solution for efficiently processing big data. In particular, this work presents a framework to simulate and automatically generate code for IoT PIM-based systems. Moreover, it proposes an high speed and energy efficient architecture for an IoT PIM system, able to compute a real image recognition application.



The paper “Recommender system implementations for embedded collaborative filtering applications”, by Pajuelo-Holguera et al., aims to propose a complete recommender system implemented on reconfigurable hardware with the purpose of testing on-chip, low-energy embedded collaborative filtering applications. The proposed approach solves any prediction problem based on collaborative filtering by using an off-line, highly-portable light computing environment. Moreover, this work exploits a custom, fine-grained parallel circuit for quick matrix multiplication with floating-point numbers.



The paper “SystemC-based Electronic System-Level Design Space Exploration Environment for Dedicated Heterogeneous Multi-Processor Systems”, by Pomante et al., faces the problem of the Electronic System-Level (ESL) HW/SW co-design of dedicated electronic digital systems based on heterogeneous multiprocessor architectures. In particular, the work presents a prototype SystemC -based environment that exploits a Design Space Exploration (DSE) approach able to suggest an HW/SW partitioning of the system specification and a mapping onto an automatically defined architecture.



The paper “A Fast and Scalable Architecture to Run Convolutional Neural Networks in Low Density FPGAs”, by Véstias et al., deals with efficient configurable architectures for Convolutional Neural Networks (CNN) inference targeting any density FPGAs. The architecture exploits fixed-point arithmetic and image batch to reduce computational, memory and memory bandwidth requirements without compromising network accuracy.



In conclusion, this special issue offers some timely contributions to advance the research of intelligent embedded systems by analyzing both architectures and applications. All of four papers are worth reading and will inspire more interesting ideas and research topics.



We sincerely express our gratitude to the Editor-in-Chief of the journal, Prof. Lech Jozwiak for all the valuable advice and constructive comments. We would also like to thank all the reviewers for their hard work on reviewing the papers. Last but not least, we appreciate all the authors who spent time and effort to respond to this call-for-papers. We truly hope that the readers will enjoy and benefit from this special issue",'Elsevier BV',Guest Editorial: Special Issue on Intelligent Embedded Systems Architectures and Applications (INTESA),10.1016/j.micpro.2020.103187,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
352949441,2019-01-01T00:00:00,"Complexity is a fundamental part of product design and manufacturing today, owing to increased demands for customization and advances in digital design techniques. Assembling and repairing such an enormous variety of components means that workers are cognitively challenged, take longer to search for the relevant information and are prone to making mistakes. Although in recent years deep learning approaches to object recognition have seen rapid advances, the combined potential of deep learning and augmented reality in the industrial domain remains relatively under explored. In this paper we introduce AR-ProMO, a combined hardware/software solution that provides a generalizable assistance system for identifying mistakes during product assembly and repair",'Association for Computing Machinery (ACM)',Handling Work Complexity with AR/Deep Learning,10.1145/3369457.3370919,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
219636864,2019-01-01T00:00:00,"Panoramic images are widely used in many scenes, especially in virtual reality and street view capture. However, they are new for street furniture identification which is usually based on mobile laser scanning point cloud data or conventional 2D images. This study proposes to perform semantic segmentation on panoramic images and transformed images to separate light poles and traffic signs from background implemented by pre-trained Fully Convolutional Networks (FCN). FCN is the most important model for deep learning applied on semantic segmentation for its end to end training process and pixel-wise prediction. In this study, we use FCN-8s model that pre-trained on cityscape dataset and finetune it by our own data. The results show that in both pre-trained model and fine-tuning, transformed images have better prediction results than panoramic images.Optical and Laser Remote Sensin",'Copernicus GmbH',Fully convolutional networks for street furniture identification in panorama images,10.5194/isprs-archives-XLII-2-W13-13-2019,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286978978,2019-09-02T00:00:00,"Part 4: AI, Data Analytics and Automated Decision MakingInternational audienceOver the past years, a number of new technologies have emerged with a potential to disrupt many spheres of the society. While public sector traditionally lacks behind business in innovation, significant changes are anticipated with the use of disruptive technologies. The implementation of the new technologies for the government service provision, along with possible benefits, need to be well thought through and challenges need to be carefully discussed, analysed and evaluated. This paper uses scenario-technique to identify research and training needs for the implementation of disruptive technologies in government services. Using the input of 58 experts from three workshops, research and training needs for the internet of things, artificial intelligence, virtual and augmented reality, as well as big data technologies have been identified. The identified needs can serve as a starting point for a broader and more informed discussion about the knowledge and skills that the researchers and practitioners of digital government need to obtain for the broad use of such new (disruptive) technologies",'Springer Science and Business Media LLC',Using Disruptive Technologies in Government: Identification of Research and Training Needs,10.1007/978-3-030-27325-5_21,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
289226841,2020,"The subject matter of the article is the process of developing information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles arises. The goal of the study is to development of the main points for information technology of automated detection and identification of stationary objects by unmanned aerial vehicles. The tasks to be solved are: the structural diagram of the preparatory stage of information technology for automated detection and identification of stationary objects is constructed; the structural diagram of the basic, additional and final stages of information technology automated detection and identification of fixed objects is constructed. General scientific and special methods of scientific knowledge are used. One of the most effective approaches to the recognition and identification of objects is an approach based on the use of deep learning methods. A new model of UAV motion is proposed based on image recognition methods. The methods of pattern recognition with application of neural networks are considered in detail in this work too. The following results are obtained. The developed information technology is implemented in four stages: preparatory, basic, additional and final. Each stage consists of separate procedures aimed at collecting, processing, storing and transmitting information during the flight UAV. Conclusions. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles is based on the knowledge-oriented representation of the stages of image processing of objects on digital aerial photographs on board the UAV. This allows to provide intelligent real-time data processing, changing UAV flight routes depending on the objects detected to improve the effectiveness of the search tasks. Further development of this information technology lies in the development of automated methods of planning UAV routes, automatic change of route parameters in flight processes (performance of a flight task), based on knowledge-oriented technologies. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles can become an element of intelligent decision support systems for the use of UAVs (teams of UAVs) to search for both stationary and dynamic objects.Предметом вивчення в статті є процес розробки інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами. Метою дослідження є розробка основних положень інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами. Задачі: побудова структурної схеми підготовчого етапу інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів; побудова структурної схеми основного, додаткового та заключного етапів інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів. Методологічною основою дослідження стали загальнонаукові та спеціальні методи наукового пізнання. Одним з найбільш ефективних підходів на шляху до виявлення та ідентифікації об'єктів є підхід, що базується на використанні методів глибокого навчання. На основі методів розпізнавання зображень запропонована нова модель руху. Застосовано методи розпізнавання образів із застосуванням нейронних мереж. Отримані такі результати. Розроблена інформаційна технологія реалізується в чотири етапи: підготовчий, основний, додатковий та заключний. Кожний етап складається з окремих процедур, направлених на збір, обробку, зберігання та передачу інформації в процесі польоту БПЛА. Висновки. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами базується на знанняорієнтованому представленні етапів обробки зображень об'єктів на цифрових аерофотознімках на борту безпілотного літального апарату. Це дозволяє забезпечити інтелектуальну обробку даних в режимі часу, наближеного до реального, змінювати маршрути польоту БПЛА в залежності від виявлених об'єктів для підвищення ефективності рішення задач пошуку. Подальший розвиток даної інформаційної технології полягає у розробці автоматизованих методів планування маршрутів руху БПЛА, автоматичної зміни параметрів маршруту в процесів польоту (виконанні польотного завдання), що засновується на знанняорієнтованих технологіях. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами може стати елементом інтелектуальної системи підтримки прийняття рішень на застосування БПЛА (колективів БПЛА) для пошуку як стаціонарних, так і динамічних об'єктів","Національний технічний університет ""Харківський політехнічний інститут""",Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами,10.20998/2522-9052.2020.1.01,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
268992296,2019-07-01,"Multimedia sensors enable monitoring applications to obtain more accurate and detailed information. However, the development of efficient and lightweight solutions for managing data traffic over wireless multimedia sensor networks (WMSNs) has become vital because of the excessive volume of data produced by multimedia sensors. As part of this motivation, this paper proposes a fusion-based WMSN framework that reduces the amount of data to be transmitted over the network by intra-node processing. This framework explores three main issues: 1) the design of a wireless multimedia sensor (WMS) node to detect objects using machine learning techniques; 2) a method for increasing the accuracy while reducing the amount of information transmitted by the WMS nodes to the base station, and; 3) a new cluster-based routing algorithm for the WMSNs that consumes less power than the currently used algorithms. In this context, a WMS node is designed and implemented using commercially available components. In order to reduce the amount of information to be transmitted to the base station and thereby extend the lifetime of a WMSN, a method for detecting and classifying objects on three different layers has been developed. A new energy-efficient cluster-based routing algorithm is developed to transfer the collected information/data to the sink. The proposed framework and the cluster-based routing algorithm are applied to our WMS nodes and tested experimentally. The results of the experiments clearly demonstrate the feasibility of the proposed WMSN architecture in the real-world surveillance applications","Nazarbayev University, School of Engineering and Digital Sciences",A Fusion-Based Framework for Wireless Multimedia Sensor Networks in Surveillance Applications,10.1109/ACCESS.2019.2926206,https://core.ac.uk/download/pdf/268992296.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429686511,2020-03-25T00:00:00,"We present a deep learning-based multitask framework for joint 3D human pose estimation and action recognition from RGB sensors using simple cameras. The approach proceeds along two stages. In the first, a real-time 2D pose detector is run to determine the precise pixel location of important keypoints of the human body. A two-stream deep neural network is then designed and trained to map detected 2D keypoints into 3D poses. In the second stage, the Efficient Neural Architecture Search (ENAS) algorithm is deployed to find an optimal network architecture that is used for modeling the spatio-temporal evolution of the estimated 3D poses via an image-based intermediate representation and performing action recognition. Experiments on Human3.6M, MSR Action3D and SBU Kinect Interaction datasets verify the effectiveness of the proposed method on the targeted tasks. Moreover, we show that the method requires a low computational budget for training and inference. In particular, the experimental results show that by using a monocular RGB sensor, we can develop a 3D pose estimation and human action recognition approach that reaches the performance of RGB-depth sensors. This opens up many opportunities for leveraging RGB cameras (which are much cheaper than depth cameras and extensively deployed in private and public places) to build intelligent recognition systems.Sergio A. Velastin is grateful for funding received from the Universidad Carlos III de Madrid, the European Union’s Seventh Framework Programme for research, technological development and demonstrationunder grant agreement N 600371, el Ministerio de Economía, Industria y Competitividad (COFUND2013-51509) el Ministerio de Educación, Cultura y Deporte (CEI-15-17) and Banco Santander",'MDPI AG',A Unified Deep Framework for Joint 3D Pose Estimation and Action Recognition from a Single RGB Camera,10.3390/s20071825,https://core.ac.uk/download/429686511.pdf,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
337352464,2020-09-30T00:00:00,"Acquiring data for neural network training is an expensive and labour-intensive task, especially when such data isdifficult to access. This article proposes the use of 3D Blender graphics software as a tool to automatically generatesynthetic image data on the example of price labels. Using the fastai library, price label classifiers were trained ona set of synthetic data, which were compared with classifiers trained on a real data set. The comparison of the resultsshowed that it is possible to use Blender to generate synthetic data. This allows for a significant acceleration of thedata acquisition process and consequently, the learning process of neural networks",'Politechnika Lubelska',Blender as a tool for generating synthetic data,10.35784/jcsi.2086,https://core.ac.uk/download/337352464.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287167378,2020-01-22T00:00:00,"In this article, I review the concept of algorithmic generative and interactive music and discuss the advantages and challenges of its implementation in videogames. Excessive repetition caused by low interactivity in music sequences through gameplay has been tackled primarily by using random or sequential containers, coupled with overlapping rules and adaptive mix parameters, as demonstrated in the Dynamic Music Units in Audiokinetic’s Wwise middleware. This approach provides a higher variety through re-combinatorial properties of music tracks and also a responsive and interactive music stream. However, it mainly uses prerecorded music sequences that reappear and are easy to recognize throughout gameplay. Generative principles such as single-seed design have been occasionally applied in game music scoring to generate material. Some of them are complemented with rules and are assigned to sections with low emotional requirements, but support for real-time interaction in gameplay situations, although desirable, is rarely found.While algorithmic note-by-note generation can offer interactive flexibility and infinite diversity, it poses significant challenges such as achieving human-like performativity and producing a distinctive narrative style through measurable parameters or program arguments. Starting with music generation, I examine conceptual implementations and technical challenges of algorithmic composition studies that use Markov models, a-life/evolutionary music, generative grammars, agents, and artificial neural networks/deep learning. For each model, I evaluate rule-based strategies for interactive music transformation using parameters provided by contextual gameplay situations. Finally, I propose a compositional tool design based in modular instances of algorithmic music generation, featuring stylistic interactive control in connection with an audio engine rendering system",'Aarhus University Library',Algorithmic interactive music generation in videogames: A modular design for adaptive automatic music scoring,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
276538470,2019-12-21T00:00:00,"Il paper presenta il modello dell’Area archeologica di Poggio del Molino a Populonia (Piombino, LI) attraverso l’intervento dell’Associazione culturale Past in Progress che ha, nel tempo, acquisito una grande rilevanza, soprattutto a livello internazionale: dal 2008 al 2018, i partecipanti che hanno condiviso “attivamente” l’esperienza archeologica populoniese sono stati oltre duemila. Oggi, a Poggio del Molino è in corso la realizzazione di un Parco di Archeologica Condivisa (PArCo), il primo in Italia. Caratterizzato da un grande set d’offerta didattica, contenutistica ed esperienziale, il PArCo agirà mediante la strutturazione di “esperienze” autentiche e once-in-a-lifetime per rispondere ai bisogni di turisti, volontari e visitatori extra-territoriali. Forse in un mondo in cui i viaggiatori sono “cittadini temporanei”, attrarre un turismo consapevole unito alla capacità di generare valore sono le vere frontiere naturali e contemporanee dell’archeologia pubblica. This paper outlines the management strategy implemented by the cultural association Past in Progress over the archaeological area of Poggio del Molino near Populonia (Piombino, LI). Since 2008, Past in Progress’s model has achieved particular success at the international level, with more than 2,000 participants having taken an “active” share in archaeological experiences in the territory of Populonia. More recently at Poggio del Molino, developments have been initiated to transform the area into a “Shared Archaeology Park” (Parco di Archeologia Condivisa/PArCo), the first in Italy. Characterized by a diverse set of didactic, content-based, and experiential amenities, the PArCo will serve to structure authentic and “once-in-a-lifetime” experiences, responding to the needs of tourists, volunteers, and non-local visitors. In a world in which travelers function as “temporary citizens”, generating a form of tourism which is both conscious and capable of creating real value is the real “next frontier” of public archaeology",eum,Quanto l’archeologia diventa un’opportunità per disegnare il futuro / How much archaeology becomes an opportunity to design the future,10.13138/2039-2362/2196,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
441225381,2020-02-01T00:00:00,"This article attempts to represent social technologies as a research area of sociology and a practical field. Social technologies (as technology of government of social processes, agents, organizations, communities) are the complex social phenomenon. Nowadays — the days of radical technological changes (Internet of things, Big Data, virtual and augmented reality, blockchain technology, artificial intelligence, machine learning, robotization, transition to a shared economy), redefining a wide range of social fields and generating principally new social regimes ad configurations — the social technologies acquire almost universal character. The exploration and practices (design, implementation, modification) of social technologies mean the work with the widest possible range of social phenomena, deploying on very different spatial and time scales and in various social spheres. At the same time, there remains a need for conceptual and theoretical clarification of “social technologies” on the other hand, and for their institualization as research and practical fields (with its own standards, human and organizational resources and so on). The department of social technologies was opened in Moscow State University establishment on Faculty of Sociology in 2013 to address that need. The article outlines the whole number of research directions of this department since its establishment, through to the present day","'Faculty of Sociology, Lomonosov Moscow State University'",Social technologies as research field and instrument of social transformations,10.24290/1029-3736-2019-25-4-77-94,https://core.ac.uk/download/441225381.pdf,"[{'title': 'Moscow State University Bulletin Series 18 Sociology and Political Science', 'identifiers': ['issn:1029-3736', 'issn:2541-8769', '1029-3736', '2541-8769']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
294767316,2019-09-01T00:00:00,"[EN] In this paper, we propose a decision-tree modeling in the framework of membrane computing. We propose an algorithm to obtain a P system that is equivalent to any decision tree taken as input. In our case, and unlike previous proposals, we formulate the concepts of decision trees endogenously, since there is no external agent involved in the modeling. The tree structure can be defined naturally by the topology of the regions in the P system and the decision rules are defined by communication rules of the P system.Sempere Luna, JM. (2019). Modeling of Decision Trees Through P systems. New Generation Computing. 37(3):325-337. https://doi.org/10.1007/s00354-019-00052-4S325337373Breiman, L., Friedman, J., Olshen, R., Stone, C.: Classification and Regression Trees. Chapman & Hall, Boca Raton (1984)Cardona, M., Colomer, M.A., Margalida, A., Palau, A., Pérez-Hurtado, I., Pérez-Jiménez, M.J., Sanuy, D.: A computational modeling for real ecosystems based on P systems. Nat. Comput. 10(1), 39–53 (2011)Cecilia, J.M., García, J.M., Guerrero, G.D., Martínez-del-Amor, M.A., Pérez-Hurtado, I., Pérez-Jiménez, M.J.: Simulation of P systems with active membranes on CUDA. Brief. Bioinform. 11(3), 313–322 (2010)Díaz-Pernil, D., Peña-Cantillana, F., Gutiérrez-Naranjo, M.A.: Self-constructing Recognizer P Systems. In: Proceedings of the Thirteenth Brainstorming Week on Membrane Computing. Fénix Editora, pp. 137–154 (2014)Fayyad, U.M., Irani, K.B.: On the handling of continuous-valued attributes in decision tree generation. Mach. Learn. 8, 87–102 (1992)Kingsford, C., Salzberg, S.L.: What are decision trees ? Nat. Biotechnol. 26(9), 1011–1013 (2008)Martín-Vide, C., Păun, Gh, Pazos, J., Rodríguez-Patón, A.: Tissue P systems. Theor. Comput. Sci. 296, 295–326 (2003)Martínez-del-Amor, M.A., García-Quismondo, M., Macías-Ramos, L.F., Valencia-Cabrera, L., Riscos-Núñez, A., Pérez-Jiménez, M.J.: Simulating P systems on GPU devices: a survey. Fund. Inf. 136(3), 269–284 (2015)Mitchell, T.: Machine Learning. McGraw-Hill, New York City (1997)Păun, Gh: Membrane Computing, An Introduction. Springer, Berlin (2002)Păun, Gh, Rozenberg, G., Salomaa, A. (eds.): The Oxford Handbook of Membrane Computing. Oxford University Press, Oxford (2010)Quinlan, J.R.: C4.5: Programs for Machine Learning. Morgan Kaufmann, Burlington (1993)Sempere, J.M.: A View of P systems from information theory. In: Proceedings of the 17th international conference on membrane computing (CMC 2016) LNCS vol. 10105. Springer, pp. 352–362 (2017)Sammut, C., Webb, G.I. (eds.): Encyclopedia of Machine Learning. Springer, Berlin (2011)Wang, J., Hu, J., Peng, H., Pérez-Jiménez, M.J., Riscos-Núñez, A.: Decision tree models induced by membrane systems. Rom. J. Inf. Sci. Technol. 18(3), 228–239 (2015)Zhang, C., Ma, Y. (eds.): Ensemble Machine Learning, Methods and Applications. Springer, Berlin (2012)Zhang, X., Wang, B., Ding, Z., Tang, J., He, J.: Implementation of membrane algorithms on GPU. J. Appl. Math. 2014, 7 (2014",'Springer Science and Business Media LLC',Modeling of Decision Trees Through P systems,10.1007/s00354-019-00052-4,https://riunet.upv.es/bitstream/10251/140215/7/Sempere%20-%20Modeling%20of%20Decision%20Trees%20Through%20P%20systems.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323366399,2020-06-01T00:00:00,"La colorización es la asignación de posibles colores a los objetos que componen la imagen en escala de grises de forma que correspondan a los reales. La colorización plantea un reto específico en visión computarizada para la reconstrucción de imágenes y video, tales como, la búsqueda de una fiel aproximación, la saturación correcta de colores escogidos y áreas no desfasadas.
La coloración  automatizada de imágenes ha sido abordada desde varios puntos, uno de esos es Image Analogies, en donde se aplican operaciones y filtros para abstraer e integrar características de unas imágenes a otra, lo cual requiere intervención humana para la escogencia de imágenes de referencia con características similares a la imagen que se desea colorear(Gupta, R.K., Chia, A.Y.S., Rajan, D., Ng, E.S., Zhiyong, H, 2012). En intentos de mejorar la respuesta al problema se han presentado soluciones utilizando redes neuronales convolucionales (CNN) y se comienza a reducir la necesidad de semejanza directa entre las imágenes de entrenamiento y las de prueba, se plantea entonces como un problema de predicción del espacio de color (Zhang, Richard, Phillip Isola, and Alexei A., 2016).
Proponemos el diseño e implementación de una herramienta de restauración de imágenes históricas de la ciudad de Barranquilla realizándoles un coloreado por medio de herramientas de computer vision. Cayena, nuestra aplicación web presenta una galería de imágenes de la historia de Barranquilla y de forma interactiva permite realizarles el coloreado. Para aplicar el coloreado la aplicación genera una petición a nuestra API que que aloja el servicio y ejecuta el proceso de coloración; este proceso de coloración consiste en el procesamiento de la imagen para que tenga el tamaño adecuado, la transformación a escala de grises  y la posterior ejecución, por medio del marco de trabajo  de aprendizaje profundo Caffe, de un modelo de CNN pre-entrenado que predice los posibles colores reales de la imagen.Having a grayscale image as an input, colorization is the assignation of the possible colors to the objects composing the image so that the colors are similar to the real ones. Colorization poses a specific challenge on the field of computerized vision for image and video restoration, such as reliable approximation, an adequate saturation of the chosen colors and no mismatched areas.
Different approaches have been made to assess automated colorization of images, such as Image Analogies, where filters and operations are applied to obtain and integrate characterics from some images to other, which requires human intervention to choose reference images with similar characteristics to those of the image to be colorized (Gupta, R.K., Chia, A.Y.S., Rajan, D., Ng, E.S., Zhiyong, H, 2012). In attempts to get better outcomes, convolutional neural networks(CNN) have been presented, increasingly getting rid of the need of the direct image resemblance between training and test images, posing the problem of colorization as one of space color prediction (Zhang, Richard, Phillip Isola, and Alexei A., 2016).
We propose the design and implementation of a image restoration tool for historical images of the city of Barranquilla by applying a colorization using computer vision techniques. Cayena, our web application displays a gallery of historical images of Barranquilla and interactively allows to colorize them. In order to apply the colorization the application makes a request to our API that hosts the service and executes the colorization process; this colorization process consists in the processing of the image so it has the right size and the verification to make sure it is a grayscale image and transform it if it is not, and the subsequent execution of an pre trained CNN model using the Deep Learning framework ‘Caffe’ which predicts the possible real colors of the image","Barranquilla, Universidad del Norte, 2020",Automated colorization using Computer Vision tools for restoring historical images of the city of Barranquilla,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
342671590,2020-11-01T00:00:00,"Intelligent fault diagnosis methods have replaced time consuming and unreliable human analysis, increasing anomaly detection efficiency. Deep learning models are clear cut techniques for this purpose. This paper’s fundamental purpose is to automatically detect leakage in tanks during production with more reliability than a manual inspection, a common practice in industries. This research proposes an inspection system to predict tank leakage using hydrophone sensor data and deep learning algorithms after production. In this paper, leak detection was investigated using an experimental setup consisting of a plastic tank immersed underwater. Three different techniques for this purpose were implemented and compared with each other, including fast Fourier transform (FFT), wavelet transforms, and time-domain features, all of which are followed with 1D convolution neural network (1D-CNN). Applying FFT and converting the signal to a 1D image followed by 1D-CNN showed better results than other methods. Experimental results demonstrate the effectiveness and the superiority of the proposed methodology for detecting real-time leakage inaccuracy",'MDPI AG',Deep Learning Model for Industrial Leakage Detection Using Acoustic Emission Signal,10.3390/informatics7040049,https://core.ac.uk/download/342671590.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
233571269,2019-09-25T12:24:12,"open6siACKNOWLEDGMENTS: D.P.K. and P.R.K. acknowledge support received from NIH-NIAID (R21 AI127381-02 and R33 AI127381-03). D.P.K. acknowledges the Texas 4000 Distinguished Professorship for Cancer Research and the NIH-NCI Cancer Center CORE Support grant no. 16672. P.R.K. acknowledges research support from the CAR-T cell therapy lab, Department of Pediatrics, at The University of Texas M.D. Anderson Cancer Center. R.E.L. has received research support from Merck & Co. and has served on advisory boards for Astellas Pharma and Cidara Therapeutics.Efficient live-imaging methods are pivotal to understand fungal morphogenesis, especially as it relates to interactions with host immune cells and mechanisms of antifungal drugs. Due to the notable similarities in growth patterns of neuronal cells and mycelial networks, we sought to repurpose the NeuroTrack (NT) processing module of the IncuCyte time-lapse microscopy system as a tool to quantify mycelial growth and branching of pathogenic fungi. We showed the robustness of NT analysis to study Candida albicans and five different molds and confirmed established characteristics of mycelial growth kinetics. We also documented high intra-and interassay reproducibility of the NT module for a spectrum of spore inocula and culture periods. Using GFP-expressing Aspergillus fumigatus and Rhizopus arrhizus, the feasibility of fluorescence-based NT analysis was validated. In addition, we performed proof-of-concept experiments of NT analysis for several translational applications such as studying the morphogenesis of a filamentation-defective C. albicans mutant, the effects of different classes of antifungals (polyenes, azoles, and echino-candins), and coculture with host immune cells. High accuracy was found, even at high immune cell-to-fungus ratios or in the presence of fungal debris. For antifungal efficacy studies, addition of a cytotoxicity dye further refined IncuCyte-based analysis, facilitating real-time determination of fungistatic and fungicidal activity in a single assay. Complementing conventional MIC-based assays, NT analysis is an appealing method to study fungal morphogenesis and viability in the context of antifungal compound screening and evaluation of novel immune therapeutics. IMPORTANCE Pathogenic fungi remain a major cause of infectious complications in immunocompromised patients. Microscopic techniques are crucial for our understanding of fungal biology, host-pathogen interaction, and the pleiotropic effects of antifungal drugs on fungal cell growth and morphogenesis. Taking advantage of the morphological similarities of neuronal cell networks and mycelial growth patterns, we employed the IncuCyte time-lapse microscopy system and its NeuroTrack image analysis software package to study growth and branching of a variety of pathogenic yeasts and molds. Using optimized image processing definitions, we validated IncuCyte NeuroTrack analysis as a reliable and efficient tool for translational applications such as antifungal efficacy evaluation and coculture with host immune effector cells. Hence, the IncuCyte system and its NeuroTrack module provide an appealing platform for efficient in vitro studies of antifungal compounds and immunotherapeu-tic strategies in medical mycology.openWurster S.; Kumaresan P.R.; Albert N.D.; Hauser P.J.; Lewis R.E.; Kontoyiannis D.P.Wurster S.; Kumaresan P.R.; Albert N.D.; Hauser P.J.; Lewis R.E.; Kontoyiannis D.P",'American Society for Microbiology',"Live monitoring and analysis of fungal growth, viability, and mycelial morphology using the incucyte neurotrack processing module",10.1128/mBio.00673-19,https://core.ac.uk/download/233571269.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
427382360,2019-09-19T00:00:00,"Driven by the demand to accommodate today’s growing mobile traffic, 5G is designed to

be a key enabler and a leading infrastructure provider in the information and communication technology

industry by supporting a variety of forthcoming services with diverse requirements. Considering the everincreasing

complexity of the network, and the emergence of novel use cases such as autonomous cars,

industrial automation, virtual reality, e-health, and several intelligent applications, machine learning (ML)

is expected to be essential to assist in making the 5G vision conceivable. This paper focuses on the potential

solutions for 5G from an ML-perspective. First, we establish the fundamental concepts of supervised,

unsupervised, and reinforcement learning, taking a look at what has been done so far in the adoption of

ML in the context of mobile and wireless communication, organizing the literature in terms of the types of

learning.We then discuss the promising approaches for how ML can contribute to supporting each target 5G

network requirement, emphasizing its specific use cases and evaluating the impact and limitations they have

on the operation of the network. Lastly, this paper investigates the potential features of Beyond 5G (B5G),

providing future research directions for how ML can contribute to realizing B5G. This article is intended

to stimulate discussion on the role that ML can play to overcome the limitations for a wide deployment of

autonomous 5G/B5G mobile and wireless communications",'Institute of Electrical and Electronics Engineers (IEEE)',"Machine Learning for 5G/B5G Mobile and Wireless Communications: Potential, Limitations, and Future Directions",10.1109/ACCESS.2019.2942390,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237693585,2019,"In this paper we investigate the use of a social robot as an interface to a serious game aiming to train kids in how to recycle materials correctly. Serious games are mostly used to induce motivations and engagement in users and support knowledge transfer during playing. They are especially effective when the goal of the game concerns behavior change. In addition, social robots have been used effectively in educational settings to engage children in the learning process. Following this trend, we designed a serious game in which the social robot Pepper plays with a child to teach him to correctly recycle the materials. To endow the robot with the capability of detecting and classifying the waste material we developed an image recognition module based on a Convolutional Neural Network. Preliminary experimental results show that the implementation of a serious game about recycling into the Pepper robot improves its social behavior. The use of real objects as waste items during the game turns out to be a successful approach not only for perceived learning effectiveness but also for engagement of the children",'Institute of Electrical and Electronics Engineers (IEEE)',Learning waste recycling by playing with a social robot,10.1109/SMC.2019.8914455,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
372560235,2020-01-01T00:00:00,"In the past few years, Convolutional Neural Networks (CNNs) have seen a massive improvement, outperforming other visual recognition algorithms. Since they are playing an increasingly important role in fields such as face recognition, augmented reality or autonomous driving, there is the growing need for a fast and efficient system to perform the redundant and heavy computations of CNNs. This trend led researchers towards heterogeneous systems provided with hardware accelerators, such as GPUs and FPGAs. The vast majority of CNNs is implemented with floating-point parameters and operations, but from research, it has emerged that high classification accuracy can be obtained also by reducing the floating-point activations and weights to binary values. This context is well suitable for FPGAs, that are known to stand out in terms of performance when dealing with binary operations, as demonstrated in FINN, the state-of-the-art framework for building Binarized Neural Network (BNN) accelerators on FPGAs. In this paper, we propose a framework that extends FINN to a distributed scenario, enabling BNNs implementation on embedded multi-FPGA systems",'Institute of Electrical and Electronics Engineers (IEEE)',BNNsplit: Binarized Neural Networks for embedded distributed FPGA-based computing systems,10.23919/DATE48585.2020.9116220,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
233572274,2019-10-10T17:51:12,"open3siThis work has beenpartially funded by projects EC H2020 OPRECOMP (732631) and ALOHA (780788).Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.embargoed_20200220Palossi D.; Conti F.; Benini L.Palossi D.; Conti F.; Benini L",'Institute of Electrical and Electronics Engineers (IEEE)',An Open Source and Open Hardware Deep Learning-Powered Visual Navigation Engine for Autonomous Nano-UAVs,10.1109/DCOSS.2019.00111,https://core.ac.uk/download/233572274.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
343225290,2020-10-29T00:00:00,"Future mobile networks will enable the massive deployment of mobile multimedia applications anytime and anywhere. In this context, mobility management schemes, such as handover and proactive multimedia service migration, will be essential to improve network performance. In this article, we propose a proactive mobility management approach based on group user trajectory prediction. Specifically, we introduce a mobile user trajectory prediction algorithm by combining the Long-Short Term Memory networks (LSTM) with Reinforcement Learning (RL) to automate the model training procedure. We further develop a group user trajectory predictor to reduce prediction calculation overheads of users with similar movement patterns. To validate the impact of the proposed mobility management approach, we present a virtual reality (VR) service migration scheme built on the top of the proactive handover mechanism that benefits from trajectory predictions. Experiment results validate our predictor’s outstanding accuracy and its impacts on enhancing handover and service migration performance to provide quality of service assurance",'Institute of Electrical and Electronics Engineers (IEEE)',Mobility Management with Transferable Reinforcement Learning Trajectory Prediction,10.1109/TNSM.2020.3034482,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
228067323,2019-01-01T00:00:00,"Zaokret u primjeni sankcija Vijeća sigurnosti od općih, usmjerenih protiv država, prema ciljanim (pametnim) sankcijama usmjerenima izravno i isključivo protiv pojedinaca koje se dovodi u vezu s terorizmom, osim pozitivnih izazvao je i određene negativne učinke koji su doveli u pitanje zakonitost i pravednost ciljanih sankcija. Zbog nepostojanja odgovarajućega kontrolnog mehanizma u sustavu
Ujedinjenih naroda koji bi pojedincima pogođenim sankcijama omogućio barem kvazisudsku kontrolu odluka Sankcijskog odbora o uvrštavanju njihova imena na, tzv. sankcijsku listu, u praksi je došlo do kršenja njihovih ljudskih prava, poput prava na pristup sudu, prava na pravično suđenje, prava na učinkovit pravni lijek. Autorica u radu analizira sankcijski režim Vijeća sigurnosti u borbi protiv terorizma koji je uveden Rezolucijom 1267 (1999); zatim se kroz relevantnu sudsku praksu prikazuju konkretne povrede ljudskih prava do kojih u praksi dolazi u provedbi sankcija Vijeća sigurnosti; analizira se uvođenje
instituta Ombudsmana te se ocjenjuje uspješnost reformi u sankcijskom režimu kao iskoraka prema transparentnijoj i učinkovitijoj borbi protiv terorizma.The turn in the implementation of the Security Council’s resolutions from general ones, directed against States, towards targeted (smart) sanctions directed exclusively against individuals linked with terrorism, has produced both positive as well as negative effects which have called in question the legality and justness of targeted sanctions. Due to the lack of an adequate control mechanism in the United Nations system, which would enable the individuals affected by sanctions at least a quasi-judicial review of the decisions adopted by the Sanctions Committee regarding their names being listed on the so called sanctions list, in reality those individuals are faced with violations of their fundamental human rights (e.g. the right to access to court, the right to a fair trial, the right to an effective remedy). The subject of this paper is the analysis of the Security Council’s sanction regime in the fight against terrorism which was introduced in resolution 1267 (1999). The author further analyzes international jurisprudence concerned with the mentioned violations of human rights in the implementation of the sanctions of the Security Council. Special
emphasis is placed on the institution of Ombudsperson and its implications on the sanctions regime. The author concludes with the assessment of the efficacy of the reforms introduced in the sanctions regime as a step forward to the more transparent and effective fight against terrorism.Der Wendepunkt bei der Anwendung von Sanktionen des UN-Sicherheitsrates von an den Staat gerichteten allgemeinen Sanktionen zu den gezielten (klugen) Sanktionen, die direkt und ausschließlich an einzelne mit Terrorismus verbundenen Personen gerichtet sind, hat außer positiven auch negative Auswirkungen verursacht, welche die Gesetzmäßigkeit und Gerechtigkeit von gezielten Sanktionen in Frage
stellten. Wegen des Nichtvorhandenseins des entsprechenden Kontrollmechanismus im System der Vereinten Nationen, der den von Sanktionen betroffenen Personen wenigstens eine quasi-gerichtliche Kontrolle der Entscheidungen des Sanktionsausschusses über die Setzung ihrer Namen auf die sog. Sanktionsliste bieten würde, ist es in der Praxis zur Verletzung ihrer Menschenrechte, wie des Rechtes zum Gerichtszugang, Rechtes auf ein faires Verfahren und Rechtes auf
wirkungsvolle Rechtsmittel, gekommen. In diesem Beitrag wird das Sanktionsregime des Sicherheitsrates im Kampf gegen Terrorismus, das durch Resolution 1267 (1999) eingeführt wurde, analysiert. Anschließend stellt man durch die relevante Rechtsprechung konkrete Verletzungen von Menschenrechten dar, zu denen es in der Praxis bei der Implementierung von Sanktionen des UN-Sicherheitsrates kommt.
Ebenfalls wird die Einführung des Rechtsinstituts des Ombudsmannes analysiert und der Erfolg von Reformen des Sanktionsregimes als Fortschritt auf dem Wege zu transparenter und wirkungsvollerem Kampf gegen Terrorismus bewertet.Il rovesciamento nell’applicazione delle sanzioni del Consiglio di sicurezza da un approccio volto a comminare sanzioni generali, rivolte cioè contro gli stati, verso, invece, sanzioni mirate (intelligenti) indirizzate direttamente ed esclusivamente contro i singoli che vengono collegati al terrorismo, ha comportato oltre ad effetti positivi anche certune conseguenze negative che hanno condotto ad interrogarsi circa la legittimità e la giuridicità di tali sanzioni mirate. A causa dell’assenza di meccanismi di controllo nel sistema delle Nazioni Unite, il quale permetterebbe ai singoli sanzionati perlomeno un controllo quasi-giudiziale delle decisioni del Comitato per le sanzioni circa l’inserimento dei loro nomi nel c.d. elenco delle sanzioni, nella prassi s’è giunti alla violazione dei loro diritti umani quali il diritto all’accesso alla giustizia, il diritto ad un giusto processo ed il diritto all’appello. Nel lavoro l’autrice
analizza il regime sanzionatorio del Consiglio di sicurezza nella lotta contro il terrorismo introdotto con la risoluzione 1267 (del 1999). Successivamente, mediante la prassi giurisprudenziale si illustrano casi concreti di violazione dei diritti umani in conseguenza dell’applicazione delle sanzioni del Consiglio di sicurezza. Si analizza inoltre l’introduzione dell’Ombudsman e si valuta la bontà della riforma del regime sanzionatorio quale espressione di un passo avanti verso una lotta al terrorismo più trasparente ed efficace",'University of Rijeka Faculty of Law',L’IMPATTO DELLE SANZIONI DEL CONSIGLIO DI SICUREZZA DELL’ONU SULLA TUTELA DEI DIRITTI FONDAMENTALI DELL’UOMO,10.30925/zpfsr.40.2.1,https://core.ac.uk/download/228067323.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
346367817,2020-09-01T00:00:00,"In this paper, mm-Pose, a novel approach to detect and track human skeletons in real-time using an mmWave radar, is proposed. To the best of the authors' knowledge, this is the first method to detect >15 distinct skeletal joints using mmWave radar reflection signals. The proposed method would find several applications in traffic monitoring systems, autonomous vehicles, patient monitoring systems and defense forces to detect and track human skeleton for effective and preventive decision making in real-time. The use of radar makes the system operationally robust to scene lighting and adverse weather conditions. The reflected radar point cloud in range, azimuth and elevation are first resolved and projected in Range-Azimuth and Range-Elevation planes. A novel low-size high-resolution radar-to-image representation is also presented, that overcomes the sparsity in traditional point cloud data and offers significant reduction in the subsequent machine learning architecture. The RGB channels were assigned with the normalized values of range, elevation/azimuth and the power level of the reflection signals for each of the points. A forked CNN architecture was used to predict the real-world position of the skeletal joints in 3-D space, using the radar-to-image representation. The proposed method was tested for a single human scenario for four primary motions, (i) Walking, (ii) Swinging left arm, (iii) Swinging right arm, and (iv) Swinging both arms to validate accurate predictions for motion in range, azimuth and elevation. The detailed methodology, implementation, challenges, and validation results are presented.University of ArizonaThis item from the UA Faculty Publications collection is made available by the University of Arizona with support from the University of Arizona Libraries. If you have questions, please contact us at repository@u.library.arizona.edu",'Institute of Electrical and Electronics Engineers (IEEE)',mm-Pose: Real-Time Human Skeletal Posture Estimation Using mmWave Radars and CNNs,10.1109/jsen.2020.2991741,,"[{'title': 'IEEE Sensors Journal', 'identifiers': ['issn:2379-9153', '2379-9153', '1530-437x', 'issn:1530-437X']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
387263536,2020-01-01T00:00:00,"Significance: Multi-exposure laser speckle contrast imaging (MELSCI) estimates microcirculatory blood perfusion more accurately than single-exposure LSCI. However, the technique has been hampered by technical limitations due to massive data throughput requirements and nonlinear inverse search algorithms, limiting it to an offline technique where data must be postprocessed. Aim: To present an MELSCI system capable of continuous acquisition and processing of MELSCI data, enabling real-time video-rate perfusion imaging with high accuracy. Approach: The MELSCI algorithm was implemented in programmable hardware (field programmable gate array) closely interfaced to a high-speed CMOS sensor for real-time calculation. Perfusion images were estimated in real-time from the MELSCI data using an artificial neural network trained on simulated data. The MELSCI perfusion was compared to two existing single-exposure metrics both quantitatively in a controlled phantom experiment and qualitatively in vivo. Results: The MELSCI perfusion shows higher signal dynamics compared to both single-exposure metrics, both spatially and temporally where heartbeat-related variations are resolved in much greater detail. The MELSCI perfusion is less susceptible to measurement noise and is more linear with respect to laser Doppler perfusion in the phantom experiment (R-2 = 0.992). Conclusions: The presented MELSCI system allows for real-time acquisition and calculation of high-quality perfusion at 15.6 frames per second. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.Funding Agencies|Swedish Research CouncilSwedish Research Council [2014-6141]; Swedens Innovation Agency VINNOVAvia the programs Swelife and MedTech4Health [2017-01435, 2019-01522]</p",'SPIE-Intl Soc Optical Eng',Real-time video-rate perfusion imaging using multi-exposure laser speckle contrast imaging and machine learning,10.1117/1.JBO.25.11.116007,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491580041,2020-06-12T00:00:00,"COVID-19'un bazı belirtilerini takip etmek için sistemler önerilmektedir. İnsanlar arasında cep telefonu kullanımı çok yaygın hale geldiğinden, en uygun çözümlerden biri cep telefonlarını bu işlem için kullanmak olabilir. Bununla birlikte, bu tür bir çözümün bazı dezavantajları vardır, çünkü belirtilerin değerlendirilmesi hastalığı tespit etmek için yeterli değildir. Bu tarz teknik çözümler bir hastanın COVID-19'a sahip olduğu konusunda kesin çözüm üretmeyecektir, ancak sistemi daha ayrıntılı verilerle besleyerek doğruluğunu arttırmak mümkün olabilmektedir. Bu çalışmada her bireyin dijital bir kopyasının oluşturulduğu dijital ikiz tabanlı bir sistem öneriyoruz. Bu kopya, bulut üzerinde yer alacaktır ve bireyin tüm tıbbi geçmişine sahip olacaktır. Ayrıca gerçek zamanlı ölçümler ile sürekli olarak beslenecektir. Bu veriler mobil cihazlardan, Sağlık Nesnelerinin Interneti (IoHT) veya doktor raporlarından yapılan herhangi bir ölçümden elde edilebilecektir. Sistem, vücut ısısını, kanı veya tükürüğü örnekleyebilen sensörlerden gelen verileri işleyebilecektir. Öksürük, solunum rutinleri, ten rengi ve sıcaklığı gibi veriler işlenecek, karar verme süreçleriyle analiz edilecektir. Karar alma süreçleri bulutta makine öğrenme teknikleri ve yapay zeka yöntemleri ile uygulanacaktır. Birey, sağlık durumunu dijital ikizinin analiziyle mobil cihazında görebilecektir. Tıbbi veriler anonimleştirildiğinde araştırma amacıyla paylaşılabilecektir. Ayrıca bu veriler mobil cihazda gizli olarak tutulabilir veya bulutta şifrelenebilir. Verilerin gizliliği, blokzinciri teknolojisi kullanılarak sağlanacaktır. Bu merkezi olmayan çözüm, vatandaşın verileri üzerinde kontrol sahibi olmasını sağlayacak bir sistem oluşturmak için kullanılmıştır. Verilerinin ne zaman kullanılacağı konusunda bireylerin rızası sorulacaktır. Hastalar ve hastalık riski altındaki kişiler, sağlık yetkilileri ve diğer kişiler tarafından belirlenmiş bir protokolle takip edilecektir. Protokol, blokzinciri üzerinde çalışan akıllı sözleşmeler tarafından tanımlanacaktır. Önerilen bu sağlık bilgi sistemi ile erken tanı sağlamak ve hastalığın yayılmasının önlenmesi amaçlanmıştır. Özellikle belirtilerin görülmeye başladığı ilk anlarda hastayı karantinaya alabilmek için etkin bir çözüm olarak önerilmiştirSystems are recommended to monitor some of the symptoms of COVID-19. Since the use of mobile phones has become very common among people, one of the most convenient solutions may be to use mobile phones for this process. However, such a solution has some disadvantages, because the evaluation of the symptoms is not enough to detect the disease. Such technical solutions will not produce an exact solution that a patient has COVID-19, but it may be possible to increase its accuracy by feeding the system with more detailed data. In this study, we propose a digital twin-based system in which a digital copy of each individual is created. This copy will be in the cloud and will have the entire medical history of the individual. It will also be fed continuously with real-time measurements. This data can be obtained from mobile devices, the Internet of Health Things (IoHT) or any measurement made from doctor reports. The system will be able to process data from sensors that can sample body temperature, blood, or saliva. Data such as cough, respiratory routines, skin color and temperature will be processed and analyzed through decision making processes. Decision making processes will be implemented in the cloud with machine learning techniques and artificial intelligence methods. The individual will be able to see his/her health status on his/her mobile device with the analysis of his/her digital twin. When medical data are anonymized, they can be shared for research purposes. In addition, this data can be kept confidential on the mobile device or encrypted in the cloud. The confidentiality of the data will be ensured using blockchain technology. This decentralized solution has been used to create a system that allows people to have control over their data. The consent of individuals will be asked about when to use their data. Patients and people at risk will be followed up with a protocol established by health officials. The protocol will be defined by smart contracts working on blockchain. With this proposed health information system, it is aimed to provide early diagnosis and prevent the spread of the disease. It has been proposed as an effective solution to quarantine the patient, especially at the first moments when symptoms begin to appear",Online International Conference of COVID-19 (CONCOVID),A DIGITAL TWIN-BASED HEALTH INFORMATION SYSTEM FOR THE DETECTION OF COVID-19 SYMPTOMS,,https://core.ac.uk/download/491580041.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
428920125,2020-03-23T00:00:00,"This paper is the first step of an attempt to equip social robots with emotion recognition capabilities comparable to those of humans. Most of the recent deep learning solutions for facial expression recognition under-perform when deployed in Human-Robot-Interaction scenarios, although they are capable of breaking records on the most varied benchmarks on facial expression recognition. The main reason for that we believe is that they are using techniques that are developed for recognition of static pictures, while in real-life scenarios, we infer emotions from intervals of expression. Utilising on the feature of CNN to form regions of interests that are similar to human gaze patterns, we use recordings from human-gaze patterns to train such a network to infer facial emotions from 3 seconds video footage of humans expressing 6 basic emotions",'Association for Computing Machinery (ACM)',Improving emotional expression recognition of robots using regions of interest from human data,10.1145/3371382.3378359,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286800324,2019,"Part 4: AI, Data Analytics and Automated Decision MakingInternational audienceOver the past years, a number of new technologies have emerged with a potential to disrupt many spheres of the society. While public sector traditionally lacks behind business in innovation, significant changes are anticipated with the use of disruptive technologies. The implementation of the new technologies for the government service provision, along with possible benefits, need to be well thought through and challenges need to be carefully discussed, analysed and evaluated. This paper uses scenario-technique to identify research and training needs for the implementation of disruptive technologies in government services. Using the input of 58 experts from three workshops, research and training needs for the internet of things, artificial intelligence, virtual and augmented reality, as well as big data technologies have been identified. The identified needs can serve as a starting point for a broader and more informed discussion about the knowledge and skills that the researchers and practitioners of digital government need to obtain for the broad use of such new (disruptive) technologies",Springer International Publishing,Using Disruptive Technologies in Government: Identification of Research and Training Needs,10.1007/978-3-030-27325-5_21,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
303798217,2019-01-01T00:00:00,"While modern CFD tools are able to provide the user with reliable and accurate simulations, there is a strong need for interactive design and analysis tools. State-of-the-art CFD software employs massive resources in terms of CPU time, user interaction, and also GPU time for rendering and analysis. In this work, we develop an innovative tool able to provide a seamless bridge between artistic design and engineering analysis. This platform has three main ingredients: computer vision to avoid long user interaction at the pre-processing stage, machine learning to avoid costly CFD simulations, and augmented reality for an agile and interactive post-processing of the results",'Wiley',An augmented reality platform for interactive aerodynamic design and analysis,10.1002/nme.6127,https://core.ac.uk/download/303798217.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
362229766,2020-11-09T00:00:00,"International audienceThis paper describes an ""all-in-one"" solution for the real-time recognition of users' mental workloads in virtual reality through the cus-tomization of a commercial HMD with physiological sensors. First, we describe the hardware and software solution employed to build the system. Second, we detail the machine learning methods used for the automatic recognition of the users' mental workload, which are based on the well-known Random Forest algorithm. In order to gather data to train the system, we conducted an extensive user study with 75 participants using a VR flight simulator to induce different levels of mental workload. In contrast to previous works which label the data based on a standardized task (e.g. n-back task) or on a pre-defined task-difficulty, participants were asked about their perceived mental workload level along the experiment. With the data collected, we were able to train the system in order to classify four different levels of mental workload with an accuracy up to 65%. In addition, we discuss the role of the signal normalization procedures, the contribution of the different physiological signals on the recognition accuracy and compare the results obtained with the sensors embedded in the HMD with commercial grade systems. Preliminary results show our pipeline is able to recognize mental workload in real-time. Taken together, our results suggest that such all-in-one approach, with physiological sensors directly embedded in the HMD, is a promising path for VR applications in which the real-time or off-line estimation of Mental Workload assessment is beneficial",HAL CCSD,Towards Real-Time Recognition of Users' Mental Workload Using Integrated Physiological Sensors Into a VR HMD,,https://core.ac.uk/download/362229766.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286449774,2020-01-20T07:13:04,"Текст статьи не публикуется в открытом доступе в соответствии с политикой журнала.Currently, one of the key processes in the higher education is the “transition to a digital platform”, i.e.  the development and adoption of digital technologies, solutions and products in the educational process. In the future, several clusters of digital technology in the higher education will be deployed on the basis of data analytics, digital models, artificial intelligence, augmented and virtual reality, and the blockchain.
The study addresses the following objectives: 1) development of a structured “map” of digital technology for higher education; 2) assessment of the extent of development and use of digital technologies in the higher education sphere at present (in developed countries and in a separate region of the Russian Federation – Krasnoyarsk Krai); 3) assessment of the prospects for the development  and adoption of digital technologies by 2035 (in developed countries and in Krasnoyarsk Krai).
The following research methods were used: 1) a conceptual analysis of scientific publications, forecasts, foresight-studies and analytical reports; 2) expert interviews, 3) a questionnaire based survey (32 experts – researchers, professors, representatives of government and consulting companies).
The following core groups of digital technologies are designated: 1) digital solutions for defining the personal goals of education, educational navigation, building a project for an individual educational trajectory; 2) adaptive educational environment for the implementation of an individual educational trajectory; 3) digital solutions for learning activities support; monitoring the results of education; solutions for educational logistics; 4) digital solutions for assessment and certification (personal identification and competency assessment); 5) digital solutions for career support and lifelong education; 6) digital solutions for building and supporting university communities (including teachers, students, graduates, university partners); 7) digital solutions for monitoring and modeling the dynamics of competences at the population level. Each group includes 3–12 technologies, so it is possible to build a detailed “map” of digital technologies for higher education sphere.
According to the experts, most of the major groups of digital technologies for education are currently (2018) in the stage of “working prototypes and pilot products” and “locally used products” (in the developed countries of the world). The exceptions are “digital solutions for monitoring and modeling the dynamics of competencies at the population level,” which are still at the “research and development” stage. By 2030, all technologies of major groups will reach the stage of “mass market products” and “local market products”.
The structure of assessments of the digital technology application in the present and prospects for adoption by 2030 for Krasnoyarsk Krai is generally similar to the structure of assessments for developed countries of the world, but the magnitudes of the estimates are much smaller. The result reflects the “catching up” nature of the development of digital technology in the education sphere in the region. The basic strategy of digitalization of higher education in the region will be the transfer of ready-made solutions that have already found wide application in the developed countries of the world",'IATED Academy',Digital technology in higher education: situation analysis and prospects assessment (on the example of Krasnoyarsk krai),10.21125/inted.2019.1392,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286449775,2020-01-20T07:13:05,"Currently, one of the key processes in the higher education is the “transition to a digital platform”, i.e. the development and adoption of digital technologies, solutions and products in the educational process. In the future, several clusters of digital technology in the higher education will be deployed on the basis of data analytics, digital models, artificial intelligence, augmented and virtual reality, and the blockchain.
The study addresses the following objectives: 1) development of a structured “map” of digital technology for higher education; 2) assessment of the extent of development and use of digital technologies in the higher education sphere at present (in developed countries and in a separate region of the Russian Federation – Krasnoyarsk Krai); 3) assessment of the prospects for the development and adoption of digital technologies by 2035 (in developed countries and in Krasnoyarsk Krai).
The following research methods were used: 1) a conceptual analysis of scientific publications, forecasts, foresight-studies and analytical reports; 2) expert interviews, 3) a questionnaire based survey (32 experts – researchers, professors, representatives of government and consulting companies).
The following core groups of digital technologies are designated: 1) digital solutions for defining the personal goals of education, educational navigation, building a project for an individual educational trajectory; 2) adaptive educational environment for the implementation of an individual educational trajectory; 3) digital solutions for learning activities support; monitoring the results of education; solutions for educational logistics; 4) digital solutions for assessment and certification (personal identification and competency assessment); 5) digital solutions for career support and lifelong education; 6) digital solutions for building and supporting university communities (including teachers, students, graduates, university partners); 7) digital solutions for monitoring and modeling the dynamics of competences at the population level. Each group includes 3–12 technologies, so it is possible to build a detailed “map” of digital technologies for higher education sphere.
According to the experts, most of the major groups of digital technologies for education are currently (2018) in the stage of “working prototypes and pilot products” and “locally used products” (in the developed countries of the world). The exceptions are “digital solutions for monitoring and modeling the dynamics of competencies at the population level,” which are still at the “research and development” stage. By 2030, all technologies of major groups will reach the stage of “mass market products” and “local market products”.
The structure of assessments of the digital technology application in the present and prospects for adoption by 2030 for Krasnoyarsk Krai is generally similar to the structure of assessments for developed countries of the world, but the magnitudes of the estimates are much smaller. The result reflects the “catching up” nature of the development of digital technology in the education sphere in the region. The basic strategy of digitalization of higher education in the region will be the transfer of ready-made solutions that have already found wide application in the developed countries of the world",'IATED Academy',Digital technology in higher education: situation analysis and prospects assessment (on the example of Krasnoyarsk krai),10.21125/inted.2019.1392,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
481048939,2020-03-29T00:00:00,"International audienceWe propose a physical alternative of software based approaches for advanced classification task by considering a photonic-based architecture implementing a recurrent neural network with up to 16,384 physical neurons. This architecture is realized with o↵-the-shelf components and can be scaled up to hundred thousand or millions of nodes while ensuring data-ecient training strategy thanks to the reservoir computing framework. We use this architecture to perform a challenging computer vision task: the classification of human actions from a video feed. For this task, we show for the first time that a physical architecture with a simple learning strategy, consisting of training one linear readout for each class, can achieve a &gt;90% success rate in terms of classification accuracy. This rivals the deep-learning approaches in terms of level of performance and hence could pave the way towards novel paradigm for ecient real-time video processing at the physical layer using photonic systems",HAL CCSD,Automatic classification of video using a scalable photonic neuro-inspired architecture,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
481531506,2020-10-01T07:00:00,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided",Scholarship@Western,Partially RepRapable automated open source bag valve mask-based ventilator,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
231954004,2019-08-29T00:00:00,"The paper aims to organize and structure data collected and associated to technologies that powers the abroad concept of Industry 4.0. It starts with the historic evolution of industry, separated by date landmarks and approaches the last transition between 3.0 to 4.0. Apart from the differences between industry models, production data stats show a huge and important transformation in the amount of data related to manufacturing and how that knowledge is processed. The paper also aims to put on debate the lack of solutions regarding the knowledge extraction of data from machines and systems, needed for data analytics. Approaches with cyber-physical systems, machine learning, virtual environments, Industrial IoT 1 and augmented reality, in an
industrial scale, are some of the strategies to power the reading and interpretation of data, in order to promote industrial efficiency.
Real context industrial applications are taken into account in order to state the importance of collected data in the efficiency of a production process. Exploring technologies and concepts to improve digital twins systems, perception and perceived systems as well as maintenance processes are some of the explored implemented strategies that make Industry 4.0. Some possible strategies are presented, as well as the transition for Industry 5.0.publishe",'Association for Computing Machinery (ACM)',Industry focused in data collection: how industry 4.0 is handled by big data,10.1145/3352411.3352414,https://core.ac.uk/download/231954004.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
477990915,2020-08-01T00:00:00,"[EN] We show a simple model of the dynamics of a viral process based, on the determination of the Kaplan-Meier curvePof the virus. Together with the function of the newly infected individualsI, this model allows us to predict the evolution of the resulting epidemic process in terms of the numberEof the death patients plus individuals who have overcome the disease. Our model has as a starting point the representation ofEas the convolution ofIandP. It allows introducing information about latent patients-patients who have already been cured but are still potentially infectious, and re-infected individuals. We also provide three methods for the estimation ofPusing real data, all of them based on the minimization of the quadratic error: the exact solution using the associated Lagrangian function and Karush-Kuhn-Tucker conditions, a Monte Carlo computational scheme acting on the total set of local minima, and a genetic algorithm for the approximation of the global minima. Although the calculation of the exact solutions of all the linear systems provided by the use of the Lagrangian naturally gives the best optimization result, the huge number of such systems that appear when the time variable increases makes it necessary to use numerical methods. We have chosen the genetic algorithms. Indeed, we show that the results obtained in this way provide good solutions for the model.This research was funded by Ministerio de Ciencia, Innovacion y Universidades: MTM2016-77054-C2-1-P and Generalitat Valenciana: Catedra de Transparencia y Gestion de Datos (U.P.V.). The authors would like to thank the referees for their valuable comments which helped
to improve the manuscript. The author gratefully acknowledge the support of Cátedra de Transparencia y
Gestión de Datos, Universitat Politècnica de València y Generalitat Valenciana, Spain. The last author gratefully
acknowledges the support of the Ministerio de Ciencia, Innovación y Universidades (Spain) and FEDER under
grant MTM2016-77054-C2-1-P.Calabuig, JM.; García-Raffi, LM.; García-Valiente, A.; Sánchez Pérez, EA. (2020). Evolution Model for Epidemic Diseases Based on the Kaplan-Meier Curve Determination. Mathematics. 8(8):1-25. https://doi.org/10.3390/math8081260S12588Ai, T., Yang, Z., Hou, H., Zhan, C., Chen, C., Lv, W., … Xia, L. (2020). Correlation of Chest CT and RT-PCR Testing for Coronavirus Disease                     2019 (COVID-19) in China: A Report of 1014 Cases. Radiology, 296(2), E32-E40. doi:10.1148/radiol.2020200642Chen, D., Xu, W., Lei, Z., Huang, Z., Liu, J., Gao, Z., & Peng, L. (2020). Recurrence of positive SARS-CoV-2 RNA in COVID-19: A case report. International Journal of Infectious Diseases, 93, 297-299. doi:10.1016/j.ijid.2020.03.003Kaplan, E. L., & Meier, P. (1958). Nonparametric Estimation from Incomplete Observations. Journal of the American Statistical Association, 53(282), 457-481. doi:10.1080/01621459.1958.10501452Kenah, E. (2010). Contact intervals, survival analysis of epidemic data, and estimation of R0. Biostatistics, 12(3), 548-566. doi:10.1093/biostatistics/kxq068Kenah, E. (2012). Non-parametric survival analysis of infectious disease data. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 75(2), 277-303. doi:10.1111/j.1467-9868.2012.01042.xOgłuszka, M., Orzechowska, M., Jędroszka, D., Witas, P., & Bednarek, A. K. (2019). Evaluate Cutpoints: Adaptable continuous data distribution system for determining survival in Kaplan-Meier estimator. Computer Methods and Programs in Biomedicine, 177, 133-139. doi:10.1016/j.cmpb.2019.05.023Hethcote, H. W. (2000). The Mathematics of Infectious Diseases. SIAM Review, 42(4), 599-653. doi:10.1137/s0036144500371907Silal, S. P., Little, F., Barnes, K. I., & White, L. J. (2016). Sensitivity to model structure: a comparison of compartmental models in epidemiology. Health Systems, 5(3), 178-191. doi:10.1057/hs.2015.2Kamvar, Z. N., Cai, J., Pulliam, J. R. C., Schumacher, J., & Jombart, T. (2019). Epidemic curves made easy using the R package incidence. F1000Research, 8, 139. doi:10.12688/f1000research.18002.1Lectures on Mathematical Modelling of Biological Systemshttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.465.8665&rep=rep1&type=pdfKeeling, M. J., & Danon, L. (2009). Mathematical modelling of infectious diseases. British Medical Bulletin, 92(1), 33-42. doi:10.1093/bmb/ldp038Brown, G. D., Oleson, J. J., & Porter, A. T. (2015). An empirically adjusted approach to reproductive number estimation for stochastic compartmental models: A case study of two Ebola outbreaks. Biometrics, 72(2), 335-343. doi:10.1111/biom.12432Huppert, A., & Katriel, G. (2013). Mathematical modelling and prediction in infectious disease epidemiology. Clinical Microbiology and Infection, 19(11), 999-1005. doi:10.1111/1469-0691.12308Paul, M. (2013). Foreseeing the future in infectious diseases: can we? Clinical Microbiology and Infection, 19(11), 991-992. doi:10.1111/1469-0691.12300Roosa, K., Lee, Y., Luo, R., Kirpich, A., Rothenberg, R., Hyman, J. M., … Chowell, G. (2020). Short-term Forecasts of the COVID-19 Epidemic in Guangdong and Zhejiang, China: February 13–23, 2020. Journal of Clinical Medicine, 9(2), 596. doi:10.3390/jcm9020596Package ‘GA’-CRAN-R Projecthttps://luca-scr.github.io/GA/Scrucca, L. (2013). GA: A Package for Genetic Algorithms inR. Journal of Statistical Software, 53(4). doi:10.18637/jss.v053.i0",'MDPI AG',Evolution Model for Epidemic Diseases Based on the Kaplan-Meier Curve Determination,10.3390/math8081260,https://riunet.upv.es/bitstream/10251/172000/1/CalabuigGarcia-RaffiGarcia-Valiente%20-%20Evolution%20Model%20for%20Epidemic%20Diseases%20Based%20on%20the%20Kaplan-M....pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395143864,2020-09-23T00:00:00,"[EN] Freshwater quality is deteriorating worldwide. In populated areas, urban pollution is the main pressure on surface continental waters, but intensive wastewater treatment is costly. Setting standards for treatment of wastewater before discharge is a major policy instrument for water authorities, balancing environmental gains and operational costs. Discharge permits usually define concentration limits at the discharge point of the plant effluent. This approach, however, may not guarantee the good status of the receiving waters. Discharge permits should be directly linked to pollutant concentration in the river. Our paper develops an approach to adaptively adjust discharge permits and applies it to Madrid and the Manzanares river, a city of more than 3 million inhabitants discharging its treated wastewater to a stream having less than 2 m(3) s(-1) average flow. Stricter limits to 5-day biological oxygen demand (11 mg O-2 L-1), ammonium (0.5 mg N-NH4 L-1), nitrate (5.9 mg N-NO3 L-1), and phosphate (0.17 mg P-PO4 L-1) at plant effluent are required to meet the river environmental objectives. The results can be generalized to assess wastewater management decisions in other geographical areas.The authors wish to thank the Tagus River Basin Authority (Confederacion Hidrografica del Tajo) for their availability and readiness to share information, and the anonymous reviewers for their valuable and constructive comments. This research was funded by the Botin Foundation, Spain.Bolinches, A.; De Stefano, L.; Paredes Arquiola, J. (2020). Adjusting wastewater treatment effluent standards to protect the receiving waters: the case of low flow rivers in central Spain. Environmental Earth Sciences. 79:1-17. https://doi.org/10.1007/s12665-020-09184-zS11779AEMET (2018) Standard climate Values: Madrid, Retiro. https://www.aemet.es/en/serviciosclimaticos/datosclimatologicos/valoresclimatologicos?l=3195&k=mad. Accessed 25 June 2019Alexakis D, Kagalou I, Tsakiris G (2013) Assessment of pressures and impacts on surface water bodies of the Mediterranean. Case study: Pamvotis Lake, Greece. Environ Earth Sci 70:687–698. https://doi.org/10.1007/s12665-012-2152-7Anderson DM, Glibert PM, Burkholder JM (2002) Harmful algal blooms and eutrophication: nutrient sources, composition, and consequences. Estuaries 25:704–726. https://doi.org/10.1007/BF02804901Andreu J, Capilla J, Sanchís E (1996) AQUATOOL, a generalized decision-support system for water-resources planning and operational management. J Hydrol 177:269–291. https://doi.org/10.1016/0022-1694(95)02963-XArora S, Keshari AK (2018) Estimation of re-aeration coefficient using MLR for modelling water quality of rivers in urban environment. Groundw Sustain Dev. https://doi.org/10.1016/j.gsd.2017.11.006Asad Ismaiel I, Bird G, McDonald MA et al (2018) Establishment of background water quality conditions in the Great Zab River catchment: influence of geogenic and anthropogenic controls on developing a baseline for water quality assessment and resource management. Environ Earth Sci 77:50. https://doi.org/10.1007/s12665-017-7190-8Astaraie-Imani M, Kapelan Z, Fu G, Butler D (2012) Assessing the combined effects of urbanisation and climate change on the river water quality in an integrated urban wastewater system in the UK. J Environ Manag 112:1–9. https://doi.org/10.1016/j.jenvman.2012.06.039Bahamonde PA, Fuzzen ML, Bennett CJ et al (2015) Whole organism responses and intersex severity in rainbow darter (Etheostoma caeruleum) following exposures to municipal wastewater in the Grand River basin, ON, Canada. Part A Aquat Toxicol 159:290–301. https://doi.org/10.1016/J.AQUATOX.2014.11.023Bowie GL, Mills WB, Porcella DB et al (1985) Rates, constants, and kinetics formulations in surface water quality modeling. U.S. Environmental Protection Agency, AthensCarey RO, Migliaccio KW (2009) Contribution of wastewater treatment plant effluents to nutrient dynamics in aquatic systems: a review. Environ Manag 44:205–217. https://doi.org/10.1007/s00267-009-9309-5Chang F-J, Tsai Y-H, Chen P-A et al (2015) Modeling water quality in an urban river using hydrological factors and data driven approaches. J Environ Manag. https://doi.org/10.1016/j.jenvman.2014.12.014Chapra SC (2008) Surface water-quality modeling. Waveland Press, Long GroveConfederación Hidrográfica del Tajo (2018) Resultados/informes: aguas superficiales—control fisicoquímico. https://www.chtajo.es/LaCuenca/CalidadAgua/Resultados_Informes/Paginas/RISupFisicoQuímico.aspx. Accessed 24 May 2018Corominas L, Acuña V, Ginebreda A, Poch M (2013) Integration of freshwater environmental policies and wastewater treatment plant management. Sci Total Environ 445–446:185–191. https://doi.org/10.1016/J.SCITOTENV.2012.12.055Council of the European Communities (1991) Council Directive of 21 May 1991 concerning urban waste water treatment (91/271/EEC). OJCox BA, Whitehead PG (2009) Impacts of climate change scenarios on dissolved oxygen in the River Thames, UK. Hydrol Res 40:138–152. https://doi.org/10.2166/nh.2009.096Cubillo F, Rodriguez B, Barnwell TO (1992) A system for control of river water quality for the community of Madrid using QUAL2E. Water Sci Technol 26:1867–1873Dodds W, Smith V (2016) Nitrogen, phosphorus, and eutrophication in streams. Inl Waters 6:155–164. https://doi.org/10.5268/IW-6.2.909Dojlido J, Best GA (1993) Chemistry of water and water pollution. E. Horwood, ChichesterDonigian AS (2002) Watershed model calibration and validation: the HSPF experience. Proc Water Environ Fed 2002:44–73Duh JD, Shandas V, Chang H, George LA (2008) Rates of urbanisation and the resiliency of air and water quality. Sci Total Environ 400:238–256European Commission (2019) Report from the commission to the European Parliament and Council on the implementation of the Water Framework Directive (2000/60/EC) and the Floods Directive (2007/60/EC). BrusselsEuropean Parliament and Council (2000) Directive 2000/60/EC of the European Parliament and of the Council of 23 October 2000 establishing a framework for Community action in the field of water policy. OJ 2014–7001Even S, Mouchel J-M, Servais P et al (2007) Modelling the impacts of combined sewer overflows on the river Seine water quality. Sci Total Environ. https://doi.org/10.1016/j.scitotenv.2006.12.007Fonseca A, Botelho C, Boaventura RAR, Vilar VJP (2014) Integrated hydrological and water quality model for river management: a case study on Lena River. Sci Total Environ 485–486:474–489. https://doi.org/10.1016/j.scitotenv.2014.03.111Gallego Bernad MS, Sánchez Pérez MÁ (2006) La destrucción ambiental del río Tajo: orígenes, procesos y consecuencias. In: V congreso Ibérico sobre Gestión y Planificación del Agua, FaroGenkai-Kato M, Carpenter SR (2005) Eutrophication due to phosphorus recycling in relation to lake morphometry, temperature, and macrophytes. Ecology 86(1):210–219Google Earth (2018) Google Earth. https://earth.google.com/web/@40.4012607,-3.71553269,604.85487896a,8051.22382757d,35y,0h,0t,0r. Accessed 24 May 2018Griffiths JA, Ka F, Chan S et al (2017) Reach-scale variation surface water quality in a reticular canal system in the lower Yangtze River Delta region, China. J Environ Manag 196:80–90. https://doi.org/10.1016/j.jenvman.2017.02.079Hernández-Sancho F, Molinos-Senante M, Sala-Garrido R (2011) Cost modelling for wastewater treatment processes. Desalination 268:1–5. https://doi.org/10.1016/J.DESAL.2010.09.042Hutchins MG, Bowes MJ (2018) Balancing water demand needs with protection of river water quality by minimising stream residence time: an example from the Thames, UK. Water Resour Manag 32:2561–2568. https://doi.org/10.1007/s11269-018-1946-0IGN Instituto Geográfico Nacional (2018) Centro de Descargas del CNIG (IGN). https://centrodedescargas.cnig.es/CentroDescargas/index.jsp. Accessed 24 May 2018IGN Instituto Geográfico Nacional (2020) Atlas Nacional de España. https://atlasnacional.ign.es/. Accessed 19 May 2020INE (2018) Cifras oficiales de población resultantes de la revisión del Padrón municipal. https://www.ine.es/jaxiT3/Tabla.htm?t=2881&L=0. Accessed 7 Apr 2019INE Instituto Nacional de Estadística (2018) Survey on water supply and sewerage. https://www.ine.es/dynt3/inebase/index.htm?type=pcaxis&path=/t26/p069/p03/serie&file=pcaxis&L=1. Accessed 24 May 2018Jasinska EJ, Goss GG, Gillis PL et al (2015) Assessment of biomarkers for contaminants of emerging concern on aquatic organisms downstream of a municipal wastewater discharge. Sci Total Environ 530–531:140–153. https://doi.org/10.1016/J.SCITOTENV.2015.05.080Jin L, Whitehead PG, Heppell CM et al (2016) Modelling flow and inorganic nitrogen dynamics on the Hampshire Avon: linking upstream processes to downstream water quality. Sci Total Environ 572:1496–1506. https://doi.org/10.1016/j.scitotenv.2016.02.156Kloas W, Urbatzka R, Opitz R et al (2009) Endocrine disruption in aquatic vertebrates. Ann N Y Acad Sci 1163:187–200. https://doi.org/10.1111/j.1749-6632.2009.04453.xKottek M, Grieser J, Beck C et al (2006) World Map of the Köppen-Geiger climate classification updated. Meteorol Zeitschrift 15:259–263. https://doi.org/10.1127/0941-2948/2006/0130Lastra A (2017) Minimizando el impacto de los vertidos en tiempo de lluvia. El caso de Madrid. In: V Jornadas de Ingeniería del Agua, p 2017Loos S, Middelkoop H, van der Perk M, van Beek R (2009) Large scale nutrient modelling using globally available datasets: a test for the Rhine basin. J Hydrol 369:403–415. https://doi.org/10.1016/j.jhydrol.2009.02.019Madrid City Council (2017) Padrón Municipal de Habitantes Ciudad de Madrid, pp 1–45Madrid City Council (2018) Zonas Alcantarillado Municipio Madrid. https://www.madrid.es/UnidadesDescentralizadas/Agua/DeInformacionsobreAgua/SistemasDepuracion/2017ZonasAlcantarilladoMunicipioMadrid.pdf.pdf. Accessed 24 May 2018Mapama M de AA y M ambiente (2011) Resolución de 30 de junio de 2011, de la Secretaría de Estado de Medio Rural y Agua, por la que se declaran las zonas sensibles en las cuencas intercomunitarias. Off Bull SpainMapama M de AA y M ambiente (2016) Real Decreto 1/2016, de 8 de enero, por el que se aprueba la revisión de los Planes Hidrológicos de las demarcaciones (...) y de la parte española de las demarcaciones hidrográficas del Cantábrico Oriental, Miño-Sil, Duero, Tajo, Guadiana y Ebro. Off Bull Spain 16, pp 2972–4301Mapama M de AA y M ambiente (2018) Redes de seguimiento. https://sig.mapama.gob.es/redes-seguimiento/. Accessed 26 June 2019McGrane SJ (2016) Impacts of urbanisation on hydrological and water quality dynamics, and urban water management: a review. Hydrol Sci J 61:2295–2311. https://doi.org/10.1080/02626667.2015.1128084Momblanch A, Paredes-Arquiola J, Munné A et al (2015) Managing water quality under drought conditions in the Llobregat River Basin. Sci Total Environ 503–504:300–318. https://doi.org/10.1016/j.scitotenv.2014.06.069Moriasi DN, Arnold JG, Van Liew MW et al (2007) Model evaluation guidelines for systematic quantification of accuracy in watershed simulations. Trans ASABE 50:885–900. https://doi.org/10.13031/2013.23153Morris L, Colombo V, Hassell K et al (2017) Municipal wastewater effluent licensing: a global perspective and recommendations for best practice. Sci Total Environ 580:1327–1339. https://doi.org/10.1016/J.SCITOTENV.2016.12.096Nash JE, Sutcliffe JV (1970) River flow forecasting through conceptual models part I—a discussion of principles. J Hydrol 10:282–290. https://doi.org/10.1016/0022-1694(70)90255-6Ostace GS, Baeza JA, Guerrero J et al (2013) Development and economic assessment of different WWTP control strategies for optimal simultaneous removal of carbon, nitrogen and phosphorus. Comput Chem Eng 53:164–177. https://doi.org/10.1016/J.COMPCHEMENG.2013.03.007Paredes J, Andreu J, Solera A (2010) A decision support system for water quality issues in the Manzanares River (Madrid, Spain). Sci Total Environ 408:2576–2589. https://doi.org/10.1016/j.scitotenv.2010.02.037Paredes-Arquiola S (2013) Modelo gescal para la simulación de la calidad del agua en sistemas de recursos hídricosParedes-Arquiola J, Andreu-Álvarez J, Martín-Monerris M, Solera A (2010) Water quantity and quality models applied to the Jucar River Basin, Spain. Water Resour Manag 24:2759–2779. https://doi.org/10.1007/s11269-010-9578-zParedes-Arquiola J, Solera A, Martinez-Capel F et al (2014) Integrating water management, habitat modelling and water quality at the basin scale and environmental flow assessment: case study of the Tormes River, Spain. Hydrol Sci J 59:878–889. https://doi.org/10.1080/02626667.2013.821573Paul MJ, Meyer JL (2001) Streams in the urban landscape. Annu Rev Ecol Syst 32:333–365. https://doi.org/10.1146/annurev.ecolsys.32.081501.114040Santhi C, Arnold JG, Williams JR et al (2001) Validation of the SWAT model on a large river basin with point and nonpoint sources. J Am Water Resour Assoc 37:1169–1188. https://doi.org/10.1111/j.1752-1688.2001.tb03630.xSferratore A, Billen G, Garnier J, Théry S (2005) Modeling nutrient (N, P, Si) budget in the Seine watershed: application of the Riverstrahler model using data from local to global scale resolution. Glob Biogeochem Cycles 19:1–14. https://doi.org/10.1029/2005GB002496Singh J, Knapp HV, Arnold JG, Demissie M (2005) Hydrological modeling of the Iroquois river watershed using HSPF and SWAT. J Am Water Resour Assoc 41:343–360. https://doi.org/10.1111/j.1752-1688.2005.tb03740.xSmith VH, Tilman GD, Nekola JC (1999) Eutrophication: impacts of excess nutrient inputs on freshwater, marine, and terrestrial ecosystems. Environ Pollut 100:179–196. https://doi.org/10.1016/S0269-7491(99)00091-3Soares Cruz MA, de Azevedo GA, de Aragão R et al (2019) Spatial and seasonal variability of the water quality characteristics of a river in Northeast Brazil. Environ Earth Sci 78:68. https://doi.org/10.1007/s12665-019-8087-5Soil Conservation Service (1972) SCS national engineering handbook, section 4: hydrologyThomann RV, Mueller JA (1987) Principles of surface water quality modeling and control. HarperCollins, New YorkUnited Nations Environment Program (2015) Good practices for regulating wastewater treatment. Legislations, Policies and Standard",'Springer Science and Business Media LLC',Adjusting wastewater treatment effluent standards to protect the receiving waters: the case of low flow rivers in central Spain,10.1007/s12665-020-09184-z,http://hdl.handle.net/10251/164059,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323090695,2019-09-01T00:00:00,"[EN] An intelligent virtual environment simulates a physical world inhabited by autonomous intelligent entities. Multi-agent systems have been usually employed to design systems of this kind. One of the key aspects in the design of intelligent virtual environments is the use of appropriate ontologies which offer a richer and more expressive representation of knowledge. In this sense, this paper proposes an ontology comprising concepts for modelling intelligent virtual environments enhanced with concepts for describing agent-based organisational features. This new ontology, called MAMbO5, is used as an input of the JaCalIVE framework, which is a toolkit for the design and implementation of agent-based intelligent virtual environments.This work was supported by the project TIN2015-65515-C4-1-R of the Spanish government. This work has been supported in part by the Croatian Science Foundation under the project number 8537.Duric, BO.; Rincon, JA.; Carrascosa Casamayor, C.; Schatten, M.; Julian Inglada, VJ. (2019). MAMbO5: A new Ontology Approach for Modelling and Managing Intelligent Virtual Environments Based on Multi-Agent Systems. Journal of Ambient Intelligence and Humanized Computing. 10(9):3629-3641. https://doi.org/10.1007/s12652-018-1089-4S36293641109Ahmed Abbas H (2015) Organization of multi-agent systems: an overview. Int J Intell Inf Syst 4(3):46 (ISSN: 2328-7675)Amiribesheli M, Bouchachia H (2017) A tailored smart home for dementia care. J Ambient Intell Hum Comput 1:1–28 (ISSN: 1868-5137, 1868-5145)Amiribesheli M, Benmansour A, Bouchachia A (2015) A review of smart homes in healthcare. J Ambient Intell Hum Comput 6(4):495–517 (ISSN: 18685145) arXiv: TSMCC.2012.2189204 [10.1109]Barella A, Ricci A, Boissier O, Carrascosa C (2012) MAM5: multi-agent model for intelligent virtual environments. In: 10th European workshop on multi-agent systems (EUMAS 2012), pp 16–30Bordel B (2017) Self-configuration in humanized cyber-physical systems. J Ambient Intell Hum Comput 8(4):485–496 (ISSN: 1868-5137)Chaib A, Boussebough I, Chaoui A (2018) Adaptive service composition in an ambient environment with a multi-agent system. J Ambient Intell Hum Comput 9(2):367–380 (ISSN: 1868-5137)Chen X (2017) A multiagent-based model for pedestrian simulation in subway stations. Simul Modell Pract Theory 71:134–148 (ISSN: 1569-190X)Chen T, Chiu MC (2018) Smart technologies for assisting the life quality of persons in a mobile environment: a review. J Ambient Intell Hum Comput 9(2):319–327 (ISSN: 1868-5137)Corkill DD, Lander SE (1998) Diversity in agent organizations. Obj Mag 8(4):41–47De Wolf T (2004) Emergence and self-organisation: a statement of similarities and differences. In: Proceedings of of the 2nd international workshop on engineering self, pp 96–110Dignum V (2009) The role of organization in agent systems. English. In: Dignum V (ed) Handbook of research on multi-agent systems. Hershey, IGI Global, pp 1–16 (ISBN: 9781605662565)Fishwick PA, Miller JA (2004) Ontologies for modeling and simulation: issues and approaches. In: Simulation conference, 2004. Proceedings of the 2004 Winter, vol 1. IEEEFurfaro A (2016) Using virtual environments for the assessment of cybersecurity issues in IoT scenarios. Simul Modell Pract Theory 0:1–12Gabriele D, Ferretti S, Ghini V (2016) Multi-level simulation of Internet of Things on smart territories. Simul Modell Pract Theory 0:1–19Hadfi R, Ito T (2016) Holonic multiagent simulation of complex adaptive systems. In: Javier B(Ed) Highlights of practical applications of scalable multi-agent systems. The PAAMS collection: international workshops of PAAMS 2016, Sevilla, Spain, June 1-3, 2016. Proceedings. Springer, Cham, pp 137-147 (ISBN: 978-3-319-39387-2)Hofmann M, Palii J, Mihelcic G (2011) Epistemic and normative aspects of ontologies in modelling and simulation. J Simul 5(3):135–146Hui TKL, Sherratt RS (2017) Towards disappearing user interfaces for ubiquitous computing: human enhancement from sixth sense to super senses. J Ambient Intell Hum Comput 8(3):449–465 (ISSN: 1868-5137, 1868-5145)Kim S, Lee I (2018) IoT device security based on proxy re-encryption. J Ambient Intell Hum Comput 9(4):1267–1273 (ISSN: 1868-5137, 1868-5145)Ko E, Kim T, Kim H (2018) Management platform of threats information in IoT environment. J Ambient Intell Hum Comput 9(4):1167–1176 (ISSN: 1868-5137, 1868-5145)Liu Y, Xu C, Zhan Y, Liu Z, Guan J, Zhang H (2017) Incentive mechanism for computation offloading using edge computing: a stackelberg game approach. Comput Netw 129:399–409Liu Y, Bashar AAE, Wu B, Wu H (2018a) Delay-constrained profit maximization for data deposition in mobile opportunistic device-to-device networks. In: 2018 IEEE 19th international symposium on” a world of wireless, mobile and multimedia networks (WoWMoM), IEEE, pp 1–10Liu Y, et al (2018b) Delay-constrained utility maximization for video ads push in mobile opportunistic D2D networks. IEEE Internet Things JLuck M, Aylett R (2000) Applying artificial intelligence to virtual reality: intelligent virtual environments. Appl Artif Intell 14(1):3–32Marcon E (2017) A multi-agent system based on reactive decision rules for solving the caregiver routing problem in home health care. Simul Modell Pract Theory 74:134–151 (ISSN: 1569-190X)Mulero R (2018) Towards ambient assisted cities using linked data and data analysis. J Ambient Intell Hum Comput 9(5):1573–1591 (ISSN: 1868-5137, 1868-5145)Okreša Đ B, Schatten M (2016) Defining ontology combining concepts of massive multi-player online role playing games and organization of large-scale multi-agent systems. In: Opatija HR (ed) 39th international convention on information and communication technology, electronics and microelectronics (MIPRO). IEEE, pp 1330–1335 (ISBN: 978-953-233-086-1)Ricci A, Viroli M, Omicini A (2007) Give agents their artifacts: the A&A approach for engineering working environments in MAS. In: Proceedings of the 6th international joint conference on autonomous agents and multiagent systems, p 150Rincon JA, Carrascosa C, Garcia E (2014) Developing intelligent virtual environments using MAM5 meta-model. In: Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics) 8473 LNAI, pp 379–382 (ISSN: 16113349)Rincon J (2016) Extending MAM5 meta-model and JaCalIV E framework to integrate smart devices from real environments. PLoS One 11:e0149665. https://doi.org/10.1371/journal.pone.0149665Rincon J, Garcia E, Julian V, Carrascosa C (2018) The jacalive framework for mas in IVE: a case study in evolving modular robotics. Neurocomputing 275:608–617Rodriguez S (2011) Holonic multi-agent systems. In: Di Marzo SG, Gleizes MP, Karageorgos A (eds) Natural computing series, natural computing series, vol 37. Springer, Heidelberg, pp 251–279 (ISBN: 978-3-642-17347-9)Samara A, et al. (2017) Affective state detection via facial expression analysis within a human–computer interaction context. J Ambient Intell Hum Comput (ISSN: 1868-5137, 1868-5145)Schatten M (2014) Organizational architectures for large-scale multi-agent systems’ development: an initial ontology. In: Sigeru O, et al (Ed) Advances in intelligent systems and computing, vol 290, pp 261–268Schatten M (2014) Towards a formal conceptualization of organizational design techniques for large scale multi agent systems. Procedia Technol 15:577–586 (ISSN: 22120173)Sharpanskykh A, Treur J (2012) An ambient agent architecture exploiting automated cognitive analysis. J Ambient Intell Hum Comput 3(3):219–237 (ISSN: 1868-5137, 1868-5145)Weyns D, Haesevoets R, Helleboogh A (2010) The MACODO organization model for context-driven dynamic agent organizations. ACM Trans Auton Adapt Syst 5(4):1–29 (ISSN: 15564665)Yang G, Kifer M, Zhao C (2003) Flora-2: a rule-based knowledge representation and inference infrastructure for the semantic web. In: Robert M, Zahir T, Douglas CS(Ed) On the move to meaningful internet systems 2003: CoopIS, DOA, and ODBASE: OTM confederated international conferences, CoopIS, DOA, and ODBASE 2003, Catania, Sicily, Italy, November 3-7, 2003. Proceedings. Springer, Berlin, pp 671-688 (ISBN: 978-3-540-39964-3)Zehe D, et al (2015) SEMSim cloud service: large-scale urban systems simulation in the cloud. In: 58, pp 157–17",'Springer Science and Business Media LLC',MAMbO5: A new Ontology Approach for Modelling and Managing Intelligent Virtual Environments Based on Multi-Agent Systems,10.1007/s12652-018-1089-4,http://hdl.handle.net/10251/143142,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275586244,2019-06-01T00:00:00,"In this work, we present a semantic situation awareness system for multirotor aerial robots, based on 2D LIDAR measurements, targeting the understanding of the environment and assuming to have a precise robot localization as an input of our algorithm. Our proposed situation awareness system calculates a semantic map of the objects of the environment as a list of circles represented by their radius, and the position and the velocity of their center in world coordinates. Our proposed algorithm includes three main parts. First, the LIDAR measurements are preprocessed and an object segmentation clusters the candidate objects present in the environment. Secondly, a Convolutional Neural Network (CNN) that has been designed and trained using an artificially generated dataset, computes the radius and the position of the center of individual circles in sensor coordinates. Finally, an indirect-EKF provides the estimate of the semantic map in world coordinates, including the velocity of the center of the circles in world coordinates.We have quantitative and qualitative evaluated the performance of our proposed situation awareness system by means of Software-In-The-Loop simulations using VRep with one and multiple static and moving cylindrical objects in the scene, obtaining results that support our proposed algorithm. In addition, we have demonstrated that our proposed algorithm is capable of handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) and moving (i.e. a person) objects",,Deep learning based semantic situation awareness system for multirotor aerial robots using LIDAR,,https://core.ac.uk/download/275586244.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
322372256,2019-01-01T00:00:00,"Timely and accurate bearing fault detection and diagnosis is important for reliable and safe operation of industrial systems. In this study, performance of a generic real-time induction bearing fault diagnosis system employing compact adaptive 1D Convolutional Neural Network (CNN) classifier is extensively studied. In the literature, although many studies have developed highly accurate algorithms for detecting bearing faults, their results have generally been limited to relatively small train/test data sets. As opposed to conventional intelligent fault diagnosis systems that usually encapsulate feature extraction, feature selection and classification as distinct blocks, the proposed system takes directly raw time-series sensor data as input and it can efficiently learn optimal features with the proper training. The main advantages of the 1D CNN based approach are 1) its compact architecture configuration (rather than the complex deep architectures) which performs only 1D convolutions making it suitable for real-time fault detection and monitoring, 2) its cost effective and practical real-time hardware implementation, 3) its ability to work without any pre-determined transformation (such as FFT or DWT), hand-crafted feature extraction and feature selection, and 4) its capability to provide efficient training of the classifier with limited size of training data set and limited number of BP iterations. Effectiveness and feasibility of the 1D CNN based fault diagnosis method is validated by applying it to two commonly used benchmark real vibration data sets and comparing the results with the other competing intelligent fault diagnosis methods.Scopu",'Springer Science and Business Media LLC',A Generic Intelligent Bearing Fault Diagnosis System Using Compact Adaptive 1D CNN Classifier,10.1007/s11265-018-1378-3,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287968699,2019-03-23T00:00:00,International audienceThis work addresses the problem of using real-world data captured from a single viewpoint by a low-cost 360-degree camera to create an immersive and interactive virtual reality scene. We combine different existing state-of-the-art data enhancement methods based on pre-trained deep learning models to quickly and automatically obtain 3D scenes with animated character models from a 360-degree video. We provide details on our implementation and insight on how to adapt existing methods to 360-degree inputs. We also present the results of a user study assessing the extent to which virtual agents generated by this process are perceived as present and engaging,'Institute of Electrical and Electronics Engineers (IEEE)',Automatic Generation of Interactive 3D Characters and Scenes for Virtual Reality from a Single-Viewpoint 360-Degree Video,10.1109/vr.2019.8797969,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287655427,2020-03-09T16:04:06,"Recent advances in “developmental” approach (combining experimental study with computational modelling) of neural networks produces increasingly large data sets, in both complexity and size. This poses a significant challenge in analyzing, visualizing and understanding not only the spatial structure but also the behavior of such networks. This paper describes a Virtual Reality application for visualization of two biologically accurate computational models that model the anatomical structure of a neural network comprised of 1,500 neurons and over 80,000 connections. The visualization enables a user to observe the complex spatio-temporal interplay between seven unique types of neurons culminating in an observable swimming pattern. We present a detailed description of the design approach for the virtual environment, based on a set of initial requirements, followed up by the implementation and optimization steps. Lastly, the results of a pilot usability study are being presented on how confident participants are in their ability to understand how the alternating firing pattern between the two sides of the tadpole’s body generate swimming motion",'Springer Science and Business Media LLC',Tadpole VR: virtual reality visualization of a simulated tadpole spinal cord,10.1007/s10055-020-00431-z,https://core.ac.uk/download/287655427.pdf,"[{'title': 'Virtual Reality', 'identifiers': ['issn:1434-9957', 'issn:1359-4338', '1359-4338', '1434-9957']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
401540916,2020-01-01T00:00:00,"Empirical studies of augmented reality (AR) in education have suggested a vast range of educational benefits, including deep learning (Wu et al., 2013), collaborative learning in locative storytelling (Chinthammit & Thomas, 2014), higher-order thinking skills (Bower et al., 2015), increased student engagement in play-based literacy practices (Yamada-Rice et al., 2017), 21st century skills (Wang et al., 2018), and spatial thinking (George et al., 2020). Yet, in language and literacy teaching, little is known about using AR to enhance inquiry learning, and to encourage students to experiment with affordances of new media to develop critical and creative knowledge. Although teachers are expected to support students in learning, both with and through new digital forms, there is a slow uptake of new media, such as AR, in Australian contexts. This is possibly due to a lack of mainstream understanding about what AR is and what educational affordances it offers. The lack of classroom research and a “conceptual framework regarding the implementation of technologies such as Augmented Reality system” remain an impeding factor to effective explorations of AR in education (Bower et al., 2014, p.7)","Marrickville, N.S.W., Primary English Teaching Association Australia","Teaching language, literacy and literature using augmented reality : an introduction to AR apps and their potential for classroom use",,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
302833051,2019-05-08T00:00:00,"Software implementations of brain-inspired computing underlie many important computational tasks, from image processing to speech recognition, artificial intelligence and deep learning applications. Yet, unlike real neural tissue, traditional computing architectures physically separate the core computing functions of memory and processing, making fast, efficient and low-energy computing difficult to achieve. To overcome such limitations, an attractive alternative is to design hardware that mimics neurons and synapses. Such hardware, when connected in networks or neuromorphic systems, processes information in a way more analogous to brains. Here we present an all-optical version of such a neurosynaptic system, capable of supervised and unsupervised learning. We exploit wavelength division multiplexing techniques to implement a scalable circuit architecture for photonic neural networks, successfully demonstrating pattern recognition directly in the optical domain. Such photonic neurosynaptic networks promise access to the high speed and high bandwidth inherent to optical systems, thus enabling the direct processing of optical telecommunication and visual data",'Springer Science and Business Media LLC',All-optical spiking neurosynaptic networks with self-learning capabilities,10.1038/s41586-019-1157-8,,"[{'title': 'Nature', 'identifiers': ['issn:0028-0836', '0028-0836']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
345057677,2019-01-01T00:00:00,"In this work, we present a semantic situation awareness system for multirotor aerial robots, based on 2D LIDAR measurements, targeting the understanding of the environment and assuming to have a precise robot localization as an input of our algorithm. Our proposed situation awareness system calculates a semantic map of the objects of the environment as a list of circles represented by their radius, and the position and the velocity of their center in world coordinates. Our proposed algorithm includes three main parts. First, the LIDAR measurements are preprocessed and an object segmentation clusters the candidate objects present in the environment. Secondly, a Convolutional Neural Network (CNN) that has been designed and trained using an artificially generated dataset, computes the radius and the position of the center of individual circles in sensor coordinates. Finally, an indirect-EKF provides the estimate of the semantic map in world coordinates, including the velocity of the center of the circles in world coordinates.We have quantitative and qualitative evaluated the performance of our proposed situation awareness system by means of Software-In-The-Loop simulations using VRep with one and multiple static and moving cylindrical objects in the scene, obtaining results that support our proposed algorithm. In addition, we have demonstrated that our proposed algorithm is capable of handling real environments thanks to real laboratory experiments with non-cylindrical static (i.e. a barrel) and moving (i.e. a person) objects",'Institute of Electrical and Electronics Engineers (IEEE)',Deep learning based semantic situation awareness system for multirotor aerial robots using LIDAR,10.1109/ICUAS.2019.8797770,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
355099865,2020-01-01T00:00:00,"Abstract: Poor management practices of road transport assets posed a challenge to the sustainable development of the transport system in developing countries like Nigeria. Studies in the past focused mainly on the performance of road construction process. However, few studies have evaluated the effect of the fourth industrial revolution (4.0IR) on the road transport assets in developing countries such as Nigeria. The current study aimed at assessing the effect of the fourth industrial revolution towards improving the management practice of road transport assets. Survey instruments were administered to project and facility managers in the Nigerian road construction sector of the economy using a proportionate random sampling technique. Partial least square structural equation modelling was used for data analysis utilising the Warp 7.0 PLS-SEM software algorithm. The software calculates p-values with WarpPLS based on non-parametric algorithms, resampling or stable algorithms and thus does not require that the variables to be normally distributed. The study concluded that 4.0IR drivers have a moderate effect change on the management practice of road transport assets in Nigeria at the moment. The findings imply that management of road assets in Nigeria would moderately improve due to 4.0IR technologies resulting in transport, safety and general efficiency and effectiveness of road networks in Nigeria. The study identified 4.0IR drivers to include; robotics, mobility, virtual and augmented reality, internet of things and cloud computing, machine learning, artificial intelligence, blockchain, 3D printing drones that are built with an attached 3D printer, (the drone hangs a 3D printing nozzle that's fed plastic, concrete mix or other material from a tube connected to the top of the drone's printing path that precisely plotted by software, for a promised printing accuracy of 0.1mm),and digital engineering. This study emanated from the government reports and past studies in the area of road transport asset management practice which the study investigated the major causes of poor practices and assessed the effect of the fourth industrial revolution on the practice",,Effect of the Fourth Industrial Revolution on Road Transport Asset Management Practice in Nigeria,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
482965109,2019-11-18T00:00:00,"Rapidly growing technological advances in big data, cloud computing, social media, artificial intelligence, virtual reality and digital media have led many educators to embark upon the pursuit and deployment of various digital tools in the classroom.  They started implementing a technology-centered educational system in order to expand their pedagogical approaches and increase the possibilities of creatively putting ideas together and innovatively conveying their knowledge to their students. In this paper, we explore the convergence of creativity, technology, with art and design education, and we advocate the use of digital tools and repurposing of social media applications to support creative thinking.   We discuss existing multimedia-based classroom practices that might encourage student creativity and suggest new forms and applications of technology aimed at providing the reflective teacher with more effective and efficient strategies to cultivate creativity while teaching art, design, and digital media courses",'International Association of Online Engineering (IAOE)',"The Effectiveness of Social Media and Multimedia-Based Pedagogy in Enhancing Creativity among Art, Design, and Digital Media Students",,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
343666174,2019-10-01T00:00:00,"Con el objetivo de encontrar alimentos amigables para celíacos, el sorgo se presenta como un cereal con un alto contenido de nutrientes, que tiene varias propiedades beneficiosas, especialmente para aquellos países que carecen de otros cereales tradicionales como el trigo, el maíz o el arroz. Además, el cultivo del sorgo es económicamente rentable y no contiene las proteínas que afectan a los pacientes celíacos. En los últimos años, se ha desarrollado una variedad de productos alimenticios de “libre de gluten” para mejorar la dieta de los celíacos, como cervezas de sorgo, que a menudo son producidas de forma artesanal y a muy pequeña escala por cerveceros individuales. Sin embargo, hasta donde se conoce, no existe una bebida no alcohólica a base de sorgo. En este trabajo se propone un modelo matemático para el diseño óptimo de una planta discontinua de producción de malta a partir de sorgo a nivel industrial. El modelo se formula como un problema mixto entero lineal, el cual se implementa y resuelve en GAMS utilizando el resolvedor CPLEX. A través de resultados experimentales, se obtienen los parámetros de diseño y operación del modelo para desarrollar una formulación de ajuste real. Se minimiza el costo de inversión y se presenta un análisis técnico-social-económico con el objetivo de evaluar la opción más rentable y sostenible de producir malta a partir de sorgo. Para una producción de 5.000 L/d, el período de pago es de 4,8 años y el costo unitario por botella de 300 mL es de $ 0,312. La bebida de malta, obtenida con la tecnología presentada en este trabajo, cumple con los requisitos físicos y organolépticos establecidos para su consumo de acuerdo con la comparación reportada por Nieblas, con dos maltas de cebada comercializadas en Cuba malta Bucanero y Tínima.Amb l'objectiu de trobar aliments amigables per a celíacs, la sorgo es presenta com un cereal amb un alt contingut de nutrients, que té diverses propietats beneficioses, especialment per a aquells països que no tenen altres cereals tradicionals com el blat, el blat de moro o l'arròs. A més, el cultiu del sorgo és econòmicament rendible i no conté les proteïnes que afecten els pacients celíacs. En els últims anys, s'ha desenvolupat una varietat de productes alimentaris ""lliure de gluten"" per millorar la dieta dels celíacs, com cerveses de sorgo, que sovint són produïdes de forma artesanal i a molt petita escala per cervesers individuals. No obstant això, fins on es coneix, no existeix una beguda no alcohòlica a base de sorgo. En aquest treball es proposa un model matemàtic per al disseny òptim d'una planta discontínua de producció de malta a partir de sorgo a nivell industrial. El model es formula com un problema mixt sencer lineal, el qual s'implementa i resol en GAMS utilitzant el resolvedor CPLEX. A través de resultats experimentals, s'obtenen els paràmetres de disseny i operació del model per desenvolupar una formulació d'ajust real. Es minimitza el cost d'inversió i es presenta una anàlisi tècnica-social-econòmica amb l'objectiu d'avaluar l'opció més rendible i sostenible de produir malta a partir de sorgo. Per a una producció de 5.000 L/d, el període de pagament és de 4,8 anys i el cost unitari per ampolla de 300 ml és de 0,312 $. La beguda de malta, obtinguda amb la tecnologia presentada en aquest treball, compleix amb els requisits físics i organolèptics establerts per al seu consum d'acord amb la comparació reportada per Nieblas, amb dos maltes d'ordi comercialitzades a Cuba malta Bucanero i Tínima.With the aim of finding friendly celiac food, sorghum is presented as a cereal with a high content of nutrients, which has several beneficial properties, especially for those countries that lack other traditional cereals such as wheat, corn, or rice. In addition, sorghum cultivation is economically profitable and it does not contain the proteins that affect celiac patients. In the last years, a variety of ""free gluten"" food products were developed for improving the celiac diet, as well as sorghum beers, which are frequently produced in a home-made manner on a very small scale by individual brewers. However, to the best of our knowledge, there is not a non-alcoholic beverage from sorghum. In this work, a mathematical model for the optimal design of a batch plant for producing malt drink from sorghum at industrial level is proposed. The model is formulated as a mixed integer linear problem, which is implemented and solved in GAMS using the CPLEX solver. Through experimental results, design and operation model parameters are obtained in order to develop real-fit formulation. The investment cost is minimized, and a technical-social-economical analysis is presented in order to evaluate the more profitable and sustainable option to produce malt drink from sorghum. For a production of 5,000 L/d, the payback period is equal to 4.8 years and the unit cost per bottle of 300 mL is $ 0.312. The obtained malt drink with technology presented in this work, meets the physical and organoleptics requirements established for its consumption according with the comparison reported by Nieblas, with two malt drinks from barley commercialized in Cuba, Bucanero and Tínima malt drink.Fil: Albernas Carvajal, Yailet. Universidad Central Marta Abreu de Las Villas; CubaFil: Corsano, Gabriela. Consejo Nacional de Investigaciones Científicas y Técnicas. Centro Científico Tecnológico Conicet - Santa Fe. Instituto de Desarrollo y Diseño. Universidad Tecnológica Nacional. Facultad Regional Santa Fe. Instituto de Desarrollo y Diseño; Argentina. Universidad Nacional del Litoral. Facultad de Ingeniería Química; ArgentinaFil: Gallardo Aguilar, Irenia. Universidad Central Marta Abreu de Las Villas; CubaFil: Fleites Avila, Yoelvis. Universidad Central Marta Abreu de Las Villas; Cub",Asociación de Químicos e Ingenieros,"Un enfocament integrat pel disseny preliminar òptim d'una planta
de producció de malta a partir de sorgo",,https://core.ac.uk/download/343666174.pdf,"[{'title': None, 'identifiers': ['2339-9686', '0001-9704', 'issn:2339-9686', 'issn:0001-9704']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
344318583,2020-11-09T00:00:00,"International audienceThis paper describes an ""all-in-one"" solution for the real-time recognition of users' mental workloads in virtual reality through the cus-tomization of a commercial HMD with physiological sensors. First, we describe the hardware and software solution employed to build the system. Second, we detail the machine learning methods used for the automatic recognition of the users' mental workload, which are based on the well-known Random Forest algorithm. In order to gather data to train the system, we conducted an extensive user study with 75 participants using a VR flight simulator to induce different levels of mental workload. In contrast to previous works which label the data based on a standardized task (e.g. n-back task) or on a pre-defined task-difficulty, participants were asked about their perceived mental workload level along the experiment. With the data collected, we were able to train the system in order to classify four different levels of mental workload with an accuracy up to 65%. In addition, we discuss the role of the signal normalization procedures, the contribution of the different physiological signals on the recognition accuracy and compare the results obtained with the sensors embedded in the HMD with commercial grade systems. Preliminary results show our pipeline is able to recognize mental workload in real-time. Taken together, our results suggest that such all-in-one approach, with physiological sensors directly embedded in the HMD, is a promising path for VR applications in which the real-time or off-line estimation of Mental Workload assessment is beneficial",HAL CCSD,Towards Real-Time Recognition of Users' Mental Workload Using Integrated Physiological Sensors Into a VR HMD,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237407719,2019-01-01T00:00:00,"Jan, M ORCiD: 0000-0002-5066-4118; Verma, B ORCiD: 0000-0002-4618-0479This paper proposes a new approach for evolving One-Dimensional Convolutional Neural Network (1D-CNN). A Particle Swarm Optimization (PSO) algorithm was incorporated to evolve the network layers and parameters. The proposed approach was evaluated over a real-world rainfall prediction application. It was compared to a trial and error approach and to the first version of the official rainfall prediction system used by the Bureau of Meteorology in Australia. Mean Absolute Error (MAE), Root Mean Squared Error (RMSE) and Pearson correlation (r) statistical measurements were calculated to measure the performance of each approach. The performance of the proposed approach was promising compared to existing state-of-the art methods. This proposed framework can be easily extended and deployed to other applications including machine vision",'Institute of Electrical and Electronics Engineers (IEEE)',Evolving One-Dimensional Deep Convolutional Neural Network: A Swarm based approach,10.1109/CEC.2019.8790036,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226925383,2019-10-01T00:00:00,"International audiencePurpose - Annotation of surgical activities becomes increasingly important for many recent applications such as surgical workflow analysis, surgical situation awareness, and the design of the operating room of the future, especially to train machine learning methods in order to develop intelligent assistance. Currently, annotation is mostly performed by observers with medical background and is incredibly costly and time-consuming, creating a major bottleneck for the above-mentioned technologies. In this paper, we propose a way to eliminate, or at least limit, the human intervention in the annotation process.  Methods - Meaningful information about interaction between objects is inherently available in virtual reality environments. We propose a strategy to convert automatically this information into annotations in order to provide as output individual surgical process models.  Validation - We implemented our approach through a peg-transfer task simulator and compared it to manual annotations. To assess the impact of our contribution, we studied both intra- and inter-observer variability.  Results and conclusion - In average, manual annotations took more than 12 min for 1 min of video to achieve low-level physical activity annotation, whereas automatic annotation is achieved in less than a second for the same video period. We also demonstrated that manual annotation introduced mistakes as well as intra- and inter-observer variability that our method is able to suppress due to the high precision and reproducibility",'Springer Science and Business Media LLC',Automatic annotation of surgical activities using virtual reality environments,10.1007/s11548-019-02008-x,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
295497995,2019-02-19,"In the past, methods for hand sign recognition have been successfully tested in Human Robot Interaction (HRI) using traditional methodologies based on static image features and machine learning. However, the recognition of gestures in video sequences is a problem still open, because current detection methods achieve low scores when the background is undefined or in unstructured scenarios. Deep learning techniques are being applied to approach a solution for this problem in recent years. In this paper, we present a study in which we analyse the performance of a 3DCNN architecture for hand gesture recognition in an unstructured scenario. The system yields a score of 73% in both accuracy and F1. The aim of the work is the implementation of a system for commanding robots with gestures recorded by video in real scenarios.This work was funded by the Ministry of Economy, Industry and Competitiveness from the Spanish Government through the DPI2015-68087-R and the pre-doctoral grant BES-2016-078290, by the European Commission and FEDER funds through the project COMMANDIA (SOE2/P1/F0638), action supported by Interreg-V Sudoe",SciTePress,3DCNN Performance in Hand Gesture Recognition Applied to Robot Arm Interaction,10.5220/0007570208020806,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
328277865,2020-01-01T00:00:00,"As Digital Twins gain more traction and their adoption in industry increases, there is a need to integrate such technology with machine learning features to enhance functionality and enable decision making tasks. This has lead to the emergence of a concept known as Digital Triplet; an enhancement of Digital Twin technology through the addition of an ’intelligent activity layer’. This is a relatively new technology in Industrie 4.0 and research efforts are geared towards exploring its applicability, development and testing of means for implementation and quick adoption. This paper presents the design and implementation of a Digital Triplet for a three-floor elevator system. It demonstrates the integration of a machine learning (ML) object detection model and the system Digital Twin. This was done to introduce an additional security feature that enabled the system to make a decision, based on objects detected and take preliminary security measures. The virtual model was designed in Siemens NX and programmed via Total Integrated Automation (TIA) portal software. The corresponding physical model was fabricated and controlled using a Programmable Logic Controller (PLC) S7 1200. A control program was developed to mimic the general operations of a typical elevator system used in a commercial building setting.  Communication, between the physical and virtual models, was enabled using the OPC-Unified Architecture (OPC-UA) protocol. Object recognition using “You only look once” (YOLOV3) based machine learning algorithm was incorporated. The Digital Triplet’s functionality was tested, ensuring the virtual system duplicated actual operations of the physical counterpart through the use of sensor data. Performance testing was done to determine the impact of the ML module on the real-time functionality aspect of the system. Experiment results showed the object recognition contributed an average of 1.083s to an overall signal travel time of 1.338 s",'MDPI AG',Digital Triplet Approach for Real-Time Monitoring and Control of an Elevator Security System,10.3390/designs4020009,https://core.ac.uk/download/328277865.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
334971119,2020-01-01T00:00:00,"The left ventricular (LV) end-systolic (ES) pressure volume relationship (ESPVR) is the cornerstone of systolic LV function analysis. We describe a 2D real-time (RT) MRI-based method (RTPVR) with separate software tools for 1) semi-automatic level set-based shape prior method (LSSPM) of the LV, 2) generation of synchronized pressure area loops and 3) calculation of the ESPVR. We used the RTPVR method to measure ventricular geometry, ES pressure area relationship (ESPAR) and ESPVR during vena cava occlusion (VCO) in normal sheep. 14 adult sheep were anesthetized and underwent measurement of LV systolic function. Ten of the 14 sheep underwent RTMRI and eight of the 14 underwent measurement with conductance catheter; 4 had both RTMRI and conductance measurements. 2D cross sectional RTMRI were performed at apex, mid-ventricle and base levels during separate VCOs. The Dice similarity coefficient was used to compare LSSPM and manual image segmentation and thus determine LSSPM accuracy. LV cross-sectional area, major and minor axis length, axis ratio, major axis orientation angle and ESPAR were measured at each LV level. ESPVR was calculated with a trapezoidal rule. The Dice similarity coefficient between LSSPM and manual segmentation by two readers was 87.31±2.51% and 88.13±3.43%. All cross sections became more elliptical during VCO. The major axis orientation shifted during VCO but remained in the septo-lateral direction. LV chamber obliteration at the apical level occurred during VCO in 7 of 10 sheep that underwent RTMRI. ESPAR was non-linear at all levels. Finally, ESPVR was non-linear because of apical collapse. ESPVR measured by conductance catheter (EES,Index = 2.23±0.66 mmHg/ml/m2) and RT (EES,Index = 2.31±0.31 mmHg/ml/m2) was not significantly different. LSSPM segmentation of 2D RT MRI images is accurate and allows calculation of LV geometry, ESPAR and ESPVR during VCO. In the future, RTPVR will facilitate determination of regional systolic material parameters underlying ESPVR","eScholarship, University of California",Left ventricular geometry during unloading and the end-systolic pressure volume relationship: Measurement with a modified real-time MRI-based method in normal sheep.,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
270202347,2019-01-01T00:00:00,"Cultural Heritage is a testimony of past human activity, and, as such, its objects exhibit great variety in their nature, size and complexity; from small artefacts and museum items to cultural landscapes, from historical building and ancient monuments to city centers and archaeological sites. Cultural Heritage around the globe suffers from wars, natural disasters and human negligence. The importance of digital documentation is well recognized and there is an increasing pressure to document our heritage both nationally and internationally. For this reason, the three-dimensional scanning and modeling of sites and artifacts of cultural heritage have remarkably increased in recent years. The semantic segmentation of point clouds is an essential step of the entire pipeline; in fact, it allows to decompose complex architectures in single elements, which are then enriched with meaningful information within Building Information Modelling software. Notwithstanding, this step is very time consuming and completely entrusted on the manual work of domain experts, far from being automatized. This work describes a method to label and cluster automatically a point cloud based on a supervised Deep Learning approach, using a state-of-the-art Neural Network called PointNet++. Despite other methods are known, we have choose PointNet++ as it reached significant results for classifying and segmenting 3D point clouds. PointNet++ has been tested and improved, by training the network with annotated point clouds coming from a real survey and to evaluate how performance changes according to the input training data. It can result of great interest for the research community dealing with the point cloud semantic segmentation, since it makes public a labelled dataset of CH elements for further tests",'Copernicus GmbH',Deep learning for semantic segmentation of 3D point cloud.,10.5194/isprs-archives-XLII-2-W15-735-2019,https://core.ac.uk/download/270202347.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
217845873,2019-03-23T00:00:00,International audienceThis work addresses the problem of using real-world data captured from a single viewpoint by a low-cost 360-degree camera to create an immersive and interactive virtual reality scene. We combine different existing state-of-the-art data enhancement methods based on pre-trained deep learning models to quickly and automatically obtain 3D scenes with animated character models from a 360-degree video. We provide details on our implementation and insight on how to adapt existing methods to 360-degree inputs. We also present the results of a user study assessing the extent to which virtual agents generated by this process are perceived as present and engaging,HAL CCSD,Automatic Generation of Interactive 3D Characters and Scenes for Virtual Reality from a Single-Viewpoint 360-Degree Video,,https://core.ac.uk/download/217845873.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
441429715,2020-09-01T00:00:00,"Minimally invasive surgery is increasingly utilized for mitral valve repair and replacement. The intervention is performed with an endoscopic field of view on the arrested heart. Extracting the necessary information from the live endoscopic video stream is challenging due to the moving camera position, the high variability of defects, and occlusion of structures by instruments. During such minimally invasive interventions there is no time to segment regions of interest manually. We propose a real-time-capable deep-learning-based approach to detect and segment the relevant anatomical structures and instruments. For the universal deployment of the proposed solution, we evaluate them on pixel accuracy as well as distance measurements of the detected contours. The U-Net, Google’s DeepLab v3, and the Obelisk-Net models are cross-validated, with DeepLab showing superior results in pixel accuracy and distance measurements",'Walter de Gruyter GmbH',DL-based segmentation of endoscopic scenes for mitral valve repair,10.1515/cdbme-2020-0017,,"[{'title': 'Current Directions in Biomedical Engineering', 'identifiers': ['2364-5504', 'issn:2364-5504']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
322838899,2019-04-01T00:00:00,"Nowadays, we come across games that have unbelievably realistic graphics that it usually becomes hard to distinguish between reality and the virtual world when we are exposed to a virtual reality gaming console. Implementing the concepts of Artificial Intelligence (AI) and Machine-Learning (ML) makes the game self-sustainable and way too intelligent on its own, by making use of self-learning methodologies which can give the user a better gaming experience. The use of AI and ML in games can give a better dimension to the gaming experience in general as the virtual world can behave unpredictably, thus improving the overall stigma of the game. In this paper, we have implemented ‘Connect-4’, a multiplayer game, using ML concepts in Unity3D. The machine learning toolkit ‘ML-Agents’, which depends on Reinforcement Learning (RL) technique, is provided using Unity3D. This toolkit is used for training the game agent which can distinguish its good moves and mistakes while training, so that the agent will not go for same mistakes over and over during actual game with human player. With this paper, authors have increased intelligence of game agent of Connect 4 using Reinforcement Learning, Unity3D and ML-Agents toolkit.</p",Blue Eyes Intelligence Engineering and Sciences Publication,Implementing artificial intelligence agent within connect 4 using unity3d and machine learning concepts,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
491201752,2020-01-01T00:00:00,"An image is worth a thousand words; hence, a face image illustrates extensive details about the specification, gender, age, and emotional states of mind. Facial expressions play an important role in community-based interactions and are often used in the behavioral analysis of emotions. Recognition of automatic facial expressions from a facial image is a challenging task in the computer vision community and admits a large set of applications, such as driver safety, human-computer interactions, health care, behavioral science, video conferencing, cognitive science, and others. In this work, a deep-learning-based scheme is proposed for identifying the facial expression of a person. The proposed method consists of two parts. The former one finds out local features from face images using a local gravitational force descriptor, while, in the latter part, the descriptor is fed into a novel deep convolution neural network (DCNN) model. The proposed DCNN has two branches. The first branch explores geometric features, such as edges, curves, and lines, whereas holistic features are extracted by the second branch. Finally, the score-level fusion technique is adopted to compute the final classification score. The proposed method along with 25 state-of-the-art methods is implemented on five benchmark available databases, namely, Facial Expression Recognition 2013, Japanese Female Facial Expressions, Extended CohnKanade, Karolinska Directed Emotional Faces, and Real-world Affective Faces. The databases consist of seven basic emotions: neutral, happiness, anger, sadness, fear, disgust, and surprise. The proposed method is compared with existing approaches using four evaluation metrics, namely, accuracy, precision, recall, and f1-score. The obtained results demonstrate that the proposed method outperforms all state-of-the-art methods on all the databases",'Institute of Electrical and Electronics Engineers (IEEE)',Facial Expression Recognition Using Local Gravitational Force Descriptor-Based Deep Convolution Neural Networks,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
334962889,2020-09-21T17:14:13,"We present an Augmented Reality (AR) visualization and interaction tool for users to control Internet of Things (IoT) devices with hand gestures. Today, smart IoT devices are becoming increasingly ubiquitous with diverse forms and functions, yet most user controls over them are still limited to mobile devices and web interfaces. Recently, AR has been developed rapidly, and provided immersive solutions to enhance user experience of applications in many fields. Its capability to create immersive interactions allows AR to improve the way smart devices are controlled via more direct visual feedback. In this paper, we create a functional prototype of one such system, enabling seamless interactions with sound and lighting systems through the use of augmented hand-controlled interaction panels. To interpret users' intentions, we implement a standard 2D convolution neural network (CNN) for real-time hand gesture recognition and deploy it within our system. Our prototype is also equipped with a simple but effective object detector which can identify target devices within a proper range by analyzing geometric features. We evaluate the performance of our system qualitatively and quantitatively and demonstrate it on two smart devices",'Institute of Electrical and Electronics Engineers (IEEE)',MagicHand: Interact with IoT Devices in Augmented Reality Environment,10.1109/vr.2019.8798053,,"[{'title': None, 'identifiers': ['2642-5254', 'issn:2642-5254']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
288816295,2020-01-01T00:00:00,"The subject matter of the article is the process of developing information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles arises. The goal of the study is to development of the main points for information technology of automated detection and identification of stationary objects by unmanned aerial vehicles. The tasks to be solved are: the structural diagram of the preparatory stage of information technology for automated detection and identification of stationary objects is constructed; the structural diagram of the basic, additional and final stages of information technology automated detection and identification of fixed objects is constructed. General scientific and special methods of scientific knowledge are used. One of the most effective approaches to the recognition and identification of objects is an approach based on the use of deep learning methods. A new model of UAV motion is proposed based on image recognition methods. The methods of pattern recognition with application of neural networks are considered in detail in this work too. The following results are obtained. The developed information technology is implemented in four stages: preparatory, basic, additional and final. Each stage consists of separate procedures aimed at collecting, processing, storing and transmitting information during the flight UAV. Conclusions. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles is based on the knowledge-oriented representation of the stages of image processing of objects on digital aerial photographs on board the UAV. This allows to provide intelligent real-time data processing, changing UAV flight routes depending on the objects detected to improve the effectiveness of the search tasks. Further development of this information technology lies in the development of automated methods of planning UAV routes, automatic change of route parameters in flight processes (performance of a flight task), based on knowledge-oriented technologies. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles can become an element of intelligent decision support systems for the use of UAVs (teams of UAVs) to search for both stationary and dynamic objects.Предметом вивчення в статті є процес розробки інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами. Метою дослідження є розробка основних положень інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами. Задачі: побудова структурної схеми підготовчого етапу інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів; побудова структурної схеми основного, додаткового та заключного етапів інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів. Методологічною основою дослідження стали загальнонаукові та спеціальні методи наукового пізнання. Одним з найбільш ефективних підходів на шляху до виявлення та ідентифікації об'єктів є підхід, що базується на використанні методів глибокого навчання. На основі методів розпізнавання зображень запропонована нова модель руху. Застосовано методи розпізнавання образів із застосуванням нейронних мереж. Отримані такі результати. Розроблена інформаційна технологія реалізується в чотири етапи: підготовчий, основний, додатковий та заключний. Кожний етап складається з окремих процедур, направлених на збір, обробку, зберігання та передачу інформації в процесі польоту БПЛА. Висновки. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами базується на знанняорієнтованому представленні етапів обробки зображень об'єктів на цифрових аерофотознімках на борту безпілотного літального апарату. Це дозволяє забезпечити інтелектуальну обробку даних в режимі часу, наближеного до реального, змінювати маршрути польоту БПЛА в залежності від виявлених об'єктів для підвищення ефективності рішення задач пошуку. Подальший розвиток даної інформаційної технології полягає у розробці автоматизованих методів планування маршрутів руху БПЛА, автоматичної зміни параметрів маршруту в процесів польоту (виконанні польотного завдання), що засновується на знанняорієнтованих технологіях. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами може стати елементом інтелектуальної системи підтримки прийняття рішень на застосування БПЛА (колективів БПЛА) для пошуку як стаціонарних, так і динамічних об'єктів",'National Technical University Kharkiv Polytechnic Institute',Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об'єктів безпілотними літальними апаратами,10.20998/2522-9052.2020.1.01,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
344908498,2019-01-01T00:00:00,"Abstract

The use of flying platforms such as unmanned aerial vehicles (UAVs), popularly known as drones, is rapidly growing. In particular, with their inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs admit several key potential applications in wireless systems. On the one hand, UAVs can be used as aerial base stations to enhance coverage, capacity, reliability, and energy efficiency of wireless networks. On the other hand, UAVs can operate as flying mobile terminals within a cellular network. Such cellular-connected UAVs can enable several applications ranging from real-time video streaming to item delivery. In this paper, a comprehensive tutorial on the potential benefits and applications of UAVs in wireless communications is presented. Moreover, the important challenges and the fundamental tradeoffs in UAV-enabled wireless networks are thoroughly investigated. In particular, the key UAV challenges such as 3D deployment, performance analysis, channel modeling, and energy efficiency are explored along with representative results. Then, open problems and potential research directions pertaining to UAV communications are introduced. Finally, various analytical frameworks and mathematical tools, such as optimization theory, machine learning, stochastic geometry, transport theory, and game theory are described. The use of such tools for addressing unique UAV problems is also presented. In a nutshell, this tutorial provides key guidelines on how to analyze, optimize, and design UAV-based wireless communication systems",'Institute of Electrical and Electronics Engineers (IEEE)',"A tutorial on UAVs for wireless networks:applications, challenges, and open problems",,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
390007811,2019-06-24T00:00:00,"The subject of the study is the methods and tools for automation of recognition of road signs at the level of software implementation. Detection of road signs is associated with the processing of a significant amount of video data in real time, which requires significant computing power. Therefore, the purpose of the work is to automate the process of recognition of road signs for filling the databases of navigators, which will allow operatively provide drivers with up-to-date information on established road signs. The following tasks are solved: analysis of methods and software for image recognition; development of the search algorithm for characters in the video frame; implementation of the definition of the contour of the sign; realization of a convolutional neural network for recognition of a sign; testing of applied information technology work. Methods are used: convolutional neural networks;  Viola-Jones's method for recognizing objects in an image, the Bousting method as a way to accelerate the recognition process with a large amount of information. Results: Different approaches to the identification of symbols on images, various software tools for object recognition, image transformation for optimal fragment are considered. An algorithm for detecting and recognizing the sign is developed. Using the Viola-Jones method, a fast way to calculate the values of attributes using the integral representation of an image is implemented. The recognition process takes place by constructing a convolutional neural network. Features of the layers of the roller network are considered.  Schematically illustrated script recognition. The process of interaction of the system with different data sources is represented by a diagram of precedents. The main result is the creation of information technology for the automated recognition of road signs. The algorithm of its work is presented in the form of a sequence diagram. Conclusions. Using the applied application information technology, recognition of road signs is made with an average probability of 88%, which allows automating the process of filling the database of navigators to a large extent, to increase the reliability and productivity of the given process.Предметом исследования являются методы и инструментальные средства автоматизации распознавания дорожных знаков на уровне программной реализации. Детектирования дорожных знаков связано с обработкой большого объема видеоданных в реальном времени, что требует значительных вычислительных мощностей. Поэтому целью работы является автоматизация процесса распознавания дорожных знаков для наполнения баз данных навигаторов, что позволит оперативно предоставлять водителям актуальную информацию об установленных дорожных знаках. Решаются следующие задачи: анализ методов и программных средств распознавания изображений; разработка алгоритма поиска знаков в кадре видео; реализация определения контура знака; реализация сгруппированной нейронной сети для распознавания знака; тестирование работы прикладной информационной технологии. Применяются методы: сгруппированные нейронные сети; метод Виолы-Джонса для распознавания объектов на изображении, метод Бустинга как способ ускорения процесса распознавания при большом объеме информации. Результаты: рассмотрены различные подходы к выявлению знаков на изображениях, различные программные средства распознавания объектов, преобразования изображений для получения оптимального фрагмента. Разработан алгоритм обнаружения и распознавания знака. С применением метода Виола-Джонса реализовано быстрый способ вычисления значений признаков, который использует интегральное представление изображения. Процесс распознавания происходит путем построения сгруппированной нейронной сети. Рассмотрены особенности слоев сгруппированной сети. Схематично проиллюстрировано сценарий распознавания. Процесс взаимодействия системы с различными источниками данных представлен с помощью диаграммы прецедентов. Основным результатом является создание информационной технологии автоматизированного распознавания дорожных знаков. Алгоритм ее работы представлен в виде диаграммы последовательности. Выводы. С применением созданной прикладной информационной технологии распознавания дорожных знаков производится со средней вероятностью 88%, что позволяет в значительной степени автоматизировать процесс наполнения базы данных навигаторов, повысить надежность и производительность указанного процесса.Предметом дослідження є методи та інструментальні засоби автоматизації розпізнання дорожніх знаків на рівні програмної реалізації. Детектування дорожніх знаків пов’язане з обробкою значного обсягу відеоданих в реальному часі, що потребує значних обчислювальних потужностей. Тому метою роботи є автоматизація процесу розпізнання дорожніх знаків для наповнення баз даних навігаторів, що дозволить оперативно надавати водіям актуальну інформацію щодо встановлених дорожніх знаків. Вирішуються наступні завдання: аналіз методів та програмних засобів розпізнання зображень; розробка алгоритму пошуку знаків на кадрі відео; реалізація визначення контуру знаку; реалізація згорткової нейронної мережі для розпізнання знаку; тестування роботи прикладної інформаційної технології. Застосовуються методи: згорткові нейронні мережі; метод Віоли-Джонса для розпізнання об’єктів на зображенні, метод Бустінгу як спосіб прискорення процесу розпізнання при великому об’ємі інформації. Результати: розглянуті різні підходи до виявлення знаків на зображеннях, різноманітні програмні засоби розпізнання об’єктів, перетворення зображень для отримання оптимального фрагменту. Розроблено алгоритм виявлення та розпізнання знаку. Із застосуванням методу Віола-Джонса реалізовано швидкий спосіб обчислення значень ознак, який використовує інтегральне представлення зображення. Процес розпізнавання відбувається шляхом побудови згорткової нейронні мережі. Розглянуто особливості шарів згорткової мережі. Схематично проілюстровано сценарій розпізнання. Процес взаємодії системи з різними джерелами даних представлений за допомогою діаграми прецедентів. Основним результатом є створення інформаційної технології автоматизованого розпізнання дорожніх знаків. Алгоритм її роботи представлено у вигляді діаграми послідовності. Висновки. Із застосуванням створеної прикладної інформаційної технології розпізнання дорожніх знаків робиться з середньою вірогідністю 88%, що дозволяє значною мірою автоматизувати процес наповнення бази даних навігаторів, підвищити надійність та продуктивність вказаного процесу","ХНУРЭ и ГП ""ЮЖГИПРОНИИАВИАПРОМ""",ІНФОРМАЦІЙНА ТЕХНОЛОГІЯ РОЗПІЗНАННЯ ДОРОЖНІХ ЗНАКІВ З ВИКОРИСТАННЯМ НЕЙРОННОЇ МЕРЕЖІ,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
441272718,2020-01-01T00:00:00,"The traditional classroom has been impacted by the digital teaching resources. Students are no longer satisfied with the traditional teaching mode of teacher teaching and student learning. Combined with the characteristics of a virtual reality-interactive classroom, the design of a virtual reality-interactive classroom based on the deep learning algorithm is proposed. This paper divides the teaching activities of the VR-interactive classroom into two parts: in-class learning activities and after-class learning activities. The software is used to design the interactive test. The emphasis and difficulty in the virtual reality-interactive classroom are taken as the development object to realize the construction of the virtual reality-interactive classroom. The simulation results show that the statistical output of teaching quality evaluation can be obtained from the quantitative regression analysis of the factors involved in VR classroom participation",'Hindawi Limited',Construction of Virtual Reality-Interactive Classroom Based on Deep Learning Algorithm,10.1155/2020/8870536,,"[{'title': 'Wireless Communications and Mobile Computing', 'identifiers': ['issn:1530-8669', '1530-8677', 'issn:1530-8677', '1530-8669']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
334494250,2020-01-01T00:00:00,"International audienceObjectives. There is now on a service of online psychotherapy, Woebot, practised by an software. It results from twenty years of researches of a psychologists’ team in Stanford University and experts in artificial intelligence and interactive technology. It is based on the deployment of the positive thought advocated by CBT (cognitive-behavioural therapeutic).Methodology. We examine the promise of what is presented as the future of psychotherapy. We lean on the press kit, the elements collected on the site, the scientific, medical and other articles to which il sends back.Discussion. It seems to us that it consists in trying to stop the release and re-operate the repression. It is a soft method to evacuate subjectivity, remobilize desire and adopt the point of view of other one.Patients. This offer of freeing from speech and overtaking guilt addresses particularly to the three hundred million of depressed in the world, according to the World Health Organization.Results. It tends to set a special link with the machine, not without divine echo, and to reset a kind of confession.Conclusion. The real target is psychotherapists who appear as moralizing inquisitors out of reach, both unavailable and unaffordable. The issue is to be done with psychotherapy with the blessing of the medicine.Objectifs. Cet article étudie les principes de la première psychothérapie en ligne pratiquée par une intelligence artificielle. Elle résulte de vingt ans de recherches d’une équipe de psychologues de l’université de Stanford et d’experts en intelligence artificielle et technologie conversationnelle. Elle est basée sur le déploiement de la pensée positive prônée par les traitements cognitivo-comportementalistes.Méthode. Nous examinons la promesse de ce qui est présenté comme l’avenir de la psychothérapie. Nous nous appuyons sur le dossier de presse, les éléments recueillis sur le site, les articles scientifiques, médicaux et autres auxquels elle renvoie.Discussion. Il nous semble que cela consiste à essayer de stopper le défoulement et d’opérer un re-refoulement. Il s’agit d’une méthode douce pour évacuer la subjectivité, remobiliser le désir, adopter le point de vue de l’autre.Patients. Cette offre de libération d’avec la parole et de dépassement de la culpabilité s’adresse particulièrement aux quelque trois cents millions de déprimés dans le monde, selon l’Organisation mondiale de la santé.Résultats. Cela tend à instaurer un lien spécial à la machine, non sans résonance divine, et de restaurer une forme de confession.Conclusion. La véritable cible est les psychothérapeutes qui apparaissent comme des inquisiteurs moralisateurs et inaccessibles, à la fois hors d’atteinte et hors de prix. L’enjeu paraît être d’en finir avec la psychothérapie avec la bénédiction de la médecine",'CAIRN',"Woebot : psychothérapie, suite et fin ?",10.3917/psys.202.0071,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287207358,2020,"This work proposes an innovative method for evaluating users’ engagement, combining the

User Engagement Scale (UES) questionnaire and a facial expression recognition (FER) system, active

research topics of increasing interest in the human–computer interaction domain (HCI). The subject

of the study is a 3D simulator that reproduces a virtual FabLab in which users can approach and

learn 3D modeling software and 3D printing. During the interaction with the virtual environment,

a structured-light camera acquires the face of the participant in real-time, to catch its spontaneous

reactions and compare them with the answers to the UES closed-ended questions. FER methods allow

overcoming some intrinsic limits in the adoption of questioning methods, such as the non-sincerity

of the interviewees and the lack of correspondence with facial expressions and body language.

A convolutional neural network (CNN) has been trained on the Bosphorus database (DB) to perform

expression recognition and the classification of the video frames in three classes of engagement

(deactivation, average activation, and activation) according to the model of emotion developed by

Russell. The results show that the two methodologies can be integrated to evaluate user engagement,

to combine weighted answers and spontaneous reactions and to increase knowledge for the design of

the new product or service",'MDPI AG',Questionnaires or Inner Feelings: Who Measures the Engagement Better?,10.3390/app10020609,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
345949772,2020-01-01T08:00:00,"Machine Learning is a branch of AI (Artificial Intelligence) which expands on the idea of a computational system extending its knowledge about set methodical behaviors from the data that is fed to it to essentially develop analytical skills that can help in identifying patterns and making decisions with little to no participation of a real human being. Computer algorithms help in gaining experience to improve the facility over time for use by both consumers and corporations. In today’s technologically advanced world, Machine Learning has given us self-driving cars, speech recognition software, and AI agents like Siri and Google assistant. This project evaluates how the Beta function came to be and how Stirling’s formula is implemented in calculating the magnitude of this function for large input values. The Beta function can then be used to produce a Beta distribution of probabilities to find whether people will actually watch a video they come across on their recommendations feed or search feed and then using Bayesian inference update the prior set predictions",Scholar Commons,Probabilistic Machine Learning Using Bayesian Inference,,https://core.ac.uk/download/345949772.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
233572457,2020-01-01T00:00:00,"In this article, we propose an augmented reality semiautomatic labeling (ARS), a semiautomatic method which leverages on moving a 2-D camera by means of a robot, proving precise camera tracking, and an augmented reality pen (ARP) to define initial object bounding box, to create large labeled data sets with minimal human intervention. By removing the burden of generating annotated data from humans, we make the deep learning technique applied to computer vision, which typically requires very large data sets, truly automated and reliable. With the ARS pipeline, we created two novel data sets effortlessly, one on electromechanical components (industrial scenario) and other on fruits (daily-living scenario) and trained two state-of-the-art object detectors robustly, based on convolutional neural networks, such as you only look once (YOLO) and single shot detector (SSD). With respect to conventional manual annotation of 1000 frames that takes us slightly more than 10 h, the proposed approach based on ARS allows to annotate 9 sequences of about 35,000 frames in less than 1 h, with a gain factor of about 450. Moreover, both the precision and recall of object detection is increased by about 15% with respect to manual labeling. All our software is available as a robot operating system (ROS) package in a public repository alongside with the novel annotated data sets",'Institute of Electrical and Electronics Engineers (IEEE)',Semiautomatic Labeling for Deep Learning in Robotics,10.1109/TASE.2019.2938316,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237398591,2020-05-01T00:00:00,"A Digital Twin (DT) refers to a digital replica of physical assets, processes and systems. DTs integrate artificial intelligence, machine learning and data analytics to create living digital simulation models that are able to learn and update from multiple sources, and to represent and predict the current and future conditions of physical counterparts. However, the current activities related to DTs are still at an early stage with respect to buildings and other infrastructure assets from an architectural and engineering/construction point of view. Less attention has been paid to the operation & maintenance (O&M) phase, which is the longest time span in the asset life cycle. A systematic and clear architecture verified with practical use cases for constructing a DT would be the foremost step for effective operation and maintenance of buildings and cities. According to current research about multi-tier architectures, this paper presents a system architecture for DTs which is specifically designed at both the building and city levels. Based on this architecture, a DT demonstrator of the West Cambridge site of the University of Cambridge was developed, which integrates heterogeneous data sources, supports effective data querying and analysing, supports decision-making processes in O&M management, and further bridges the gap between human relationships with buildings/cities. This paper aims at going through the whole process of developing DTs in building and city levels from the technical perspective and sharing lessons learnt and challenges involved in developing DTs in real practices. Through developing this DT demonstrator, the results provide a clear roadmap and present particular DT research efforts for asset management practitioners, policymakers and researchers to promote the implementation and development of DT at the building and city levels.Centre for Digital Built Britain (Innovate UK); Centre for Smart Infrastructure and Construction (Innovate UK/EPSRC",Journal of Management in Engineering,Developing a dynamic digital twin at building and city levels: A case study of the West Cambridge campus,10.17863/CAM.45198,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
344885219,2020-03-25T00:00:00,"International audienceWe present a deep learning-based multitask framework for joint 3D human pose estimation and action recognition from RGB sensors using simple cameras. The approach proceeds along two stages. In the first, a real-time 2D pose detector is run to determine the precise pixel location of important keypoints of the human body. A two-stream deep neural network is then designed and trained to map detected 2D keypoints into 3D poses. In the second stage, the Efficient Neural Architecture Search (ENAS) algorithm is deployed to find an optimal network architecture that is used for modeling the spatio-temporal evolution of the estimated 3D poses via an image-based intermediate representation and performing action recognition. Experiments on Human3.6M, MSR Action3D and SBU Kinect Interaction datasets verify the effectiveness of the proposed method on the targeted tasks. Moreover, we show that the method requires a low computational budget for training and inference. In particular, the experimental results show that by using a monocular RGB sensor, we can develop a 3D pose estimation and human action recognition approach that reaches the performance of RGB-depth sensors. This opens up many opportunities for leveraging RGB cameras (which are much cheaper than depth cameras and extensively deployed in private and public places) to build intelligent recognition systems",'MDPI AG',A Unified Deep Framework for Joint 3D Pose Estimation and Action Recognition from a Single RGB Camera,10.3390/s20071825,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395143458,2020-05-01T00:00:00,"[EN] This paper uses a two-fold multi-criteria decision-making (MCDM) approach applied for the first time to the field of microbial management of drinking water distribution systems (DWDS). Specifically, the decision-making trial and evaluation laboratory (DEMATEL) was applied removing the need for reliance on expert judgement, and analysed interdependencies among water quality parameters and microbiological characteristics of DWDS composed of different pipe materials. In addition, the fuzzy technique for order preference by similarity to ideal solution (FTOPSIS) ranked the most common bacteria identified during trials in a DWDS according to their relative abundance while managing vagueness affecting the measurements. The novel integrated approach presented and proven here for an initial real world data set provides new insights in the interdependence of environmental conditions and microbial populations. Specifically, the application shows as the bacteria having associated the most significant microbial impact may not be the most abundant. This offers the potential for integrated management strategies to promote favourable microbial conditions to help safeguard drinking water quality.The research reported here was supported by the UK Engineering and Physical Sciences Research Council (EPSRC), EPSRC-LWEC Challenge Fellowship EP/N02950X/1. We also would like to thank United Utilities for sampling sites, field work and physicochemical sample analysis.Carpitella, S.; Del Olmo, G.; Izquierdo Sebastián, J.; Husband, S.; Boxall, J.; Douterelo, I. (2020). Decision-Making Tools to Manage the Microbiology of Drinking Water Distribution Systems. Water. 12(5):1-18. https://doi.org/10.3390/w12051247S118125Guidelines for Drinking Water Quality, 4th Edition, Incorporating the 1st Addendum 2017 https://www.who.int/water_sanitation_health/publications/drinking-water-quality-guidelines-4-including-1st-addendum/en/Water Quality-Sampling-Part 5: Guidance on Sampling of Drinking Water from Treatment Works and Piped Distribution Systems https://www.iso.org/obp/ui/#iso:std:iso:5667:-5:ed-2:v1:enDeng, W., & Wang, G. (2017). A novel water quality data analysis framework based on time-series data mining. Journal of Environmental Management, 196, 365-375. doi:10.1016/j.jenvman.2017.03.024McClymont, K., Keedwell, E., & Savic, D. (2015). An analysis of the interface between evolutionary algorithm operators and problem features for water resources problems. A case study in water distribution network design. Environmental Modelling & Software, 69, 414-424. doi:10.1016/j.envsoft.2014.12.023Izquierdo, J., Montalvo, I., Pérez-García, R., & Matías, A. (2012). On the Complexities of the Design of Water Distribution Networks. Mathematical Problems in Engineering, 2012, 1-25. doi:10.1155/2012/947961Fox, S., Shepherd, W., Collins, R., & Boxall, J. (2016). Experimental Quantification of Contaminant Ingress into a Buried Leaking Pipe during Transient Events. Journal of Hydraulic Engineering, 142(1), 04015036. doi:10.1061/(asce)hy.1943-7900.0001040Mounce, S. R., Mounce, R. B., & Boxall, J. B. (2010). Novelty detection for time series data analysis in water distribution systems using support vector machines. Journal of Hydroinformatics, 13(4), 672-686. doi:10.2166/hydro.2010.144Vališ, D., Hasilová, K., Forbelská, M., & Vintr, Z. (2020). Reliability modelling and analysis of water distribution network based on backpropagation recursive processes with real field data. Measurement, 149, 107026. doi:10.1016/j.measurement.2019.107026Liu, G., Bakker, G. L., Li, S., Vreeburg, J. H. G., Verberk, J. Q. J. C., Medema, G. J., … Van Dijk, J. C. (2014). Pyrosequencing Reveals Bacterial Communities in Unchlorinated Drinking Water Distribution System: An Integral Study of Bulk Water, Suspended Solids, Loose Deposits, and Pipe Wall Biofilm. Environmental Science & Technology, 48(10), 5467-5476. doi:10.1021/es5009467Donlan, R. M., & Costerton, J. W. (2002). Biofilms: Survival Mechanisms of Clinically Relevant Microorganisms. Clinical Microbiology Reviews, 15(2), 167-193. doi:10.1128/cmr.15.2.167-193.2002Douterelo, I., Husband, S., Loza, V., & Boxall, J. (2016). Dynamics of Biofilm Regrowth in Drinking Water Distribution Systems. Applied and Environmental Microbiology, 82(14), 4155-4168. doi:10.1128/aem.00109-16Wang, H., Hu, C., Hu, X., Yang, M., & Qu, J. (2012). Effects of disinfectant and biofilm on the corrosion of cast iron pipes in a reclaimed water distribution system. Water Research, 46(4), 1070-1078. doi:10.1016/j.watres.2011.12.001Husband, S., Fish, K. E., Douterelo, I., & Boxall, J. (2016). Linking discolouration modelling and biofilm behaviour within drinking water distribution systems. Water Supply, 16(4), 942-950. doi:10.2166/ws.2016.045Wingender, J., & Flemming, H.-C. (2011). Biofilms in drinking water and their role as reservoir for pathogens. International Journal of Hygiene and Environmental Health, 214(6), 417-423. doi:10.1016/j.ijheh.2011.05.009Douterelo, I., Boxall, J. B., Deines, P., Sekar, R., Fish, K. E., & Biggs, C. A. (2014). Methodological approaches for studying the microbial ecology of drinking water distribution systems. Water Research, 65, 134-156. doi:10.1016/j.watres.2014.07.008Douterelo, I., Sharpe, R. L., & Boxall, J. B. (2013). Influence of hydraulic regimes on bacterial community structure and composition in an experimental drinking water distribution system. Water Research, 47(2), 503-516. doi:10.1016/j.watres.2012.09.053Harwani, D. (2012). The Great Plate Count Anomaly and the Unculturable Bacteria. International Journal of Scientific Research, 2(9), 350-351. doi:10.15373/22778179/sep2013/122Ikonen, J., Pitkänen, T., Kosse, P., Ciszek, R., Kolehmainen, M., & Miettinen, I. T. (2017). On-line detection of Escherichia coli intrusion in a pilot-scale drinking water distribution system. Journal of Environmental Management, 198, 384-392. doi:10.1016/j.jenvman.2017.04.090Wang, Z., Chen, Q., Zhang, J., Dong, J., Yan, H., Chen, C., & Feng, R. (2019). Characterization and source identification of tetracycline antibiotics in the drinking water sources of the lower Yangtze River. Journal of Environmental Management, 244, 13-22. doi:10.1016/j.jenvman.2019.04.070Yu, J., Kim, D., & Lee, T. (2010). Microbial diversity in biofilms on water distribution pipes of different materials. Water Science and Technology, 61(1), 163-171. doi:10.2166/wst.2010.813Rogers, J. W., & Louis, G. E. (2008). Risk and opportunity in upgrading the US drinking water infrastructure system. Journal of Environmental Management, 87(1), 26-36. doi:10.1016/j.jenvman.2007.01.002Henriques, J. J., & Louis, G. E. (2011). A decision model for selecting sustainable drinking water supply and greywater reuse systems for developing communities with a case study in Cimahi, Indonesia. Journal of Environmental Management, 92(1), 214-222. doi:10.1016/j.jenvman.2010.09.016Ramos-Martínez, E., Herrera, M., Gutiérrez-Pérez, J., Izquierdo, J., & Pérez-García, R. (2014). Rehabilitation Actions in Water Supply Systems: Effects on Biofilm Susceptibility. Procedia Engineering, 89, 225-231. doi:10.1016/j.proeng.2014.11.181Dalvi-Esfahani, M., Niknafs, A., Kuss, D. J., Nilashi, M., & Afrough, S. (2019). Social media addiction: Applying the DEMATEL approach. Telematics and Informatics, 43, 101250. doi:10.1016/j.tele.2019.101250Si, S.-L., You, X.-Y., Liu, H.-C., & Zhang, P. (2018). DEMATEL Technique: A Systematic Review of the State-of-the-Art Literature on Methodologies and Applications. Mathematical Problems in Engineering, 2018, 1-33. doi:10.1155/2018/3696457Chen, C.-T. (2000). Extensions of the TOPSIS for group decision-making under fuzzy environment. Fuzzy Sets and Systems, 114(1), 1-9. doi:10.1016/s0165-0114(97)00377-1Gul, M., & Ak, M. F. (2018). A comparative outline for quantifying risk ratings in occupational health and safety risk assessment. Journal of Cleaner Production, 196, 653-664. doi:10.1016/j.jclepro.2018.06.106Carpitella, S., Certa, A., Izquierdo, J., & La Fata, C. M. (2018). A combined multi-criteria approach to support FMECA analyses: A real-world case. Reliability Engineering & System Safety, 169, 394-402. doi:10.1016/j.ress.2017.09.017Palczewski, K., & Sałabun, W. (2019). The fuzzy TOPSIS applications in the last decade. Procedia Computer Science, 159, 2294-2303. doi:10.1016/j.procs.2019.09.404Sarkar, S., Pratihar, D. K., & Sarkar, B. (2018). An integrated fuzzy multiple criteria supplier selection approach and its application in a welding company. Journal of Manufacturing Systems, 46, 163-178. doi:10.1016/j.jmsy.2017.12.004Dinçer, H., Yüksel, S., & Martínez, L. (2019). Interval type 2-based hybrid fuzzy evaluation of financial services in E7 economies with DEMATEL-ANP and MOORA methods. Applied Soft Computing, 79, 186-202. doi:10.1016/j.asoc.2019.03.018Chen, J.-K., & Chen, I.-S. (2010). Using a novel conjunctive MCDM approach based on DEMATEL, fuzzy ANP, and TOPSIS as an innovation support system for Taiwanese higher education. Expert Systems with Applications, 37(3), 1981-1990. doi:10.1016/j.eswa.2009.06.079Nilashi, M., Samad, S., Manaf, A. A., Ahmadi, H., Rashid, T. A., Munshi, A., … Hassan Ahmed, O. (2019). Factors influencing medical tourism adoption in Malaysia: A DEMATEL-Fuzzy TOPSIS approach. Computers & Industrial Engineering, 137, 106005. doi:10.1016/j.cie.2019.106005Li, G., Ma, X., Chen, R., Yu, Y., Tao, H., & Shi, B. (2019). Field studies of manganese deposition and release in drinking water distribution systems: Insight into deposit control. Water Research, 163, 114897. doi:10.1016/j.watres.2019.114897Zhu, Y., Wang, H., Li, X., Hu, C., Yang, M., & Qu, J. (2014). Characterization of biofilm and corrosion of cast iron pipes in drinking water distribution system with UV/Cl2 disinfection. Water Research, 60, 174-181. doi:10.1016/j.watres.2014.04.035Du, Y.-W., & Zhou, W. (2019). New improved DEMATEL method based on both subjective experience and objective data. Engineering Applications of Artificial Intelligence, 83, 57-71. doi:10.1016/j.engappai.2019.05.001Carpitella, S., Carpitella, F., Certa, A., Benítez, J., & Izquierdo, J. (2018). Managing Human Factors to Reduce Organisational Risk in Industry. Mathematical and Computational Applications, 23(4), 67. doi:10.3390/mca23040067Gerami Seresht, N., & Fayek, A. R. (2019). Computational method for fuzzy arithmetic operations on triangular fuzzy numbers by extension principle. International Journal of Approximate Reasoning, 106, 172-193. doi:10.1016/j.ijar.2019.01.005Zadeh, L. A. (1965). Fuzzy sets. Information and Control, 8(3), 338-353. doi:10.1016/s0019-9958(65)90241-xProkopowicz, P. (2019). The use of Ordered Fuzzy Numbers for modelling changes in dynamic processes. Information Sciences, 470, 1-14. doi:10.1016/j.ins.2018.08.045Okunuki, S., Kawaharasaki, M., Tanaka, H., & Kanagawa, T. (2004). Changes in phosphorus removing performance and bacterial community structure in an enhanced biological phosphorus removal reactor. Water Research, 38(9), 2433-2439. doi:10.1016/j.watres.2004.02.008Rofner, C., Sommaruga, R., & Teresa Pérez, M. (2016). Phosphate and ATP uptake by lake bacteria: does taxonomical identity matter? Environmental Microbiology, 18(12), 4782-4793. doi:10.1111/1462-2920.13368Ferro, P., Vaz-Moreira, I., & Manaia, C. M. (2019). Betaproteobacteria are predominant in drinking water: are there reasons for concern? Critical Reviews in Microbiology, 45(5-6), 649-667. doi:10.1080/1040841x.2019.1680602Ertekin, E., Hatt, J. K., Konstantinidis, K. T., & Tezel, U. (2016). Similar Microbial Consortia and Genes Are Involved in the Biodegradation of Benzalkonium Chlorides in Different Environments. Environmental Science & Technology, 50(8), 4304-4313. doi:10.1021/acs.est.5b0595",'MDPI AG',Decision-Making Tools to Manage the Microbiology of Drinking Water Distribution Systems,10.3390/w12051247,https://riunet.upv.es/bitstream/10251/162955/1/Carpitella%3bDel%3bIzquierdo%20-%20Decision-Making%20Tools%20to%20Manage%20the%20Microbiology%20of%20Drinking%20Water%20Dis....pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
429121482,2020-09-01T00:00:00,"[EN] Background and objective: As Computed Tomography scans are an essential medical test, many techniques have been proposed to reconstruct high-quality images using a smaller amount of radiation. One approach is to employ algebraic factorization methods to reconstruct the images, using fewer views than the traditional analytical methods. However, their main drawback is the high computational cost and hence the time needed to obtain the images, which is critical in the daily clinical practice. For this reason, faster methods for solving this problem are required.

Methods: In this paper, we propose a new reconstruction method based on the QR factorization that is very efficient on affordable equipment (standard multicore processors and standard Solid-State Drives) by using Out-Of-Core techniques.

Results: Combining both affordable hardware and the new software proposed in our work, the images can be reconstructed very quickly and with high quality. We analyze the reconstructions using real Computed Tomography images selected from a dataset, comparing the QR method to the LSQR and FBP. We measure the quality of the images using the metrics Peak Signal-To-Noise Ratio and Structural Similarity Index, obtaining very high values. We also compare the efficiency of using spinning disks versus Solid-State Drives, showing how the latter performs the Input/Output operations in a significantly lower amount of time. Conclusions: The results indicate that our proposed me thod and software are valid to efficiently solve large-scale systems and can be applied to the Computed Tomography reconstruction problem to obtain high-quality images.This research has been supported by ""Universitat Politecnica de Valencia"", ""Generalitat Valenciana"" under PROMETEO/2018/035 and ACIF/2017/075, co-financed by FEDER and FSE funds, and the ""Spanish Ministry of Science, Innovation and Universities"" under Grant RTI2018-098156-B-C54 co-financed by FEDER funds.Chillarón-Pérez, M.; Quintana Ortí, G.; Vidal-Gimeno, V.; Verdú Martín, GJ. (2020). Computed tomography medical image reconstruction on affordable equipment by using Out-Of-Core techniques. Computer Methods and Programs in Biomedicine. 193:1-11. https://doi.org/10.1016/j.cmpb.2020.105488S111193Berrington de González, A. (2009). Projected Cancer Risks From Computed Tomographic Scans Performed in the United States in 2007. Archives of Internal Medicine, 169(22), 2071. doi:10.1001/archinternmed.2009.440HALL, E. J., & BRENNER, D. J. (2008). Cancer risks from diagnostic radiology. The British Journal of Radiology, 81(965), 362-378. doi:10.1259/bjr/01948454Tang, X., Hsieh, J., Nilsen, R. A., Dutta, S., Samsonov, D., & Hagiwara, A. (2006). A three-dimensional-weighted cone beam filtered backprojection (CB-FBP) algorithm for image reconstruction in volumetric CT—helical scanning. Physics in Medicine and Biology, 51(4), 855-874. doi:10.1088/0031-9155/51/4/007Zhuang, T., Leng, S., Nett, B. E., & Chen, G.-H. (2004). Fan-beam and cone-beam image reconstruction via filtering the backprojection image of differentiated projection data. Physics in Medicine and Biology, 49(24), 5489-5503. doi:10.1088/0031-9155/49/24/007Mori, S., Endo, M., Komatsu, S., Kandatsu, S., Yashiro, T., & Baba, M. (2006). A combination-weighted Feldkamp-based reconstruction algorithm for cone-beam CT. Physics in Medicine and Biology, 51(16), 3953-3965. doi:10.1088/0031-9155/51/16/005Willemink, M. J., de Jong, P. A., Leiner, T., de Heer, L. M., Nievelstein, R. A. J., Budde, R. P. J., & Schilham, A. M. R. (2013). Iterative reconstruction techniques for computed tomography Part 1: Technical principles. European Radiology, 23(6), 1623-1631. doi:10.1007/s00330-012-2765-yWillemink, M. J., Leiner, T., de Jong, P. A., de Heer, L. M., Nievelstein, R. A. J., Schilham, A. M. R., & Budde, R. P. J. (2013). Iterative reconstruction techniques for computed tomography part 2: initial results in dose reduction and image quality. European Radiology, 23(6), 1632-1642. doi:10.1007/s00330-012-2764-zWu, W., Liu, F., Zhang, Y., Wang, Q., & Yu, H. (2019). Non-Local Low-Rank Cube-Based Tensor Factorization for Spectral CT Reconstruction. IEEE Transactions on Medical Imaging, 38(4), 1079-1093. doi:10.1109/tmi.2018.2878226Wu, W., Zhang, Y., Wang, Q., Liu, F., Chen, P., & Yu, H. (2018). Low-dose spectral CT reconstruction using image gradient ℓ0–norm and tensor dictionary. Applied Mathematical Modelling, 63, 538-557. doi:10.1016/j.apm.2018.07.006Andersen, A. H. (1989). Algebraic reconstruction in CT from limited views. IEEE Transactions on Medical Imaging, 8(1), 50-55. doi:10.1109/42.20361Andersen, A. H., & Kak, A. C. (1984). Simultaneous Algebraic Reconstruction Technique (SART): A Superior Implementation of the Art Algorithm. Ultrasonic Imaging, 6(1), 81-94. doi:10.1177/016173468400600107Yu, W., & Zeng, L. (2014). A Novel Weighted Total Difference Based Image Reconstruction Algorithm for Few-View Computed Tomography. PLoS ONE, 9(10), e109345. doi:10.1371/journal.pone.0109345Flores, L., Vidal, V., & Verdú, G. (2015). Iterative Reconstruction from Few-view Projections. Procedia Computer Science, 51, 703-712. doi:10.1016/j.procs.2015.05.188Flores, L. A., Vidal, V., Mayo, P., Rodenas, F., & Verdú, G. (2014). Parallel CT image reconstruction based on GPUs. Radiation Physics and Chemistry, 95, 247-250. doi:10.1016/j.radphyschem.2013.03.011Chillarón, M., Vidal, V., Segrelles, D., Blanquer, I., & Verdú, G. (2017). Combining Grid Computing and Docker Containers for the Study and Parametrization of CT Image Reconstruction Methods. Procedia Computer Science, 108, 1195-1204. doi:10.1016/j.procs.2017.05.065Sollmann, N., Mei, K., Schwaiger, B. J., Gersing, A. S., Kopp, F. K., Bippus, R., … Baum, T. (2018). Effects of virtual tube current reduction and sparse sampling on MDCT-based femoral BMD measurements. Osteoporosis International, 29(12), 2685-2692. doi:10.1007/s00198-018-4675-6Yan Liu, Zhengrong Liang, Jianhua Ma, Hongbing Lu, Ke Wang, Hao Zhang, & Moore, W. (2014). Total Variation-Stokes Strategy for Sparse-View X-ray CT Image Reconstruction. IEEE Transactions on Medical Imaging, 33(3), 749-763. doi:10.1109/tmi.2013.2295738Tang, J., Nett, B. E., & Chen, G.-H. (2009). Performance comparison between total variation (TV)-based compressed sensing and statistical iterative reconstruction algorithms. Physics in Medicine and Biology, 54(19), 5781-5804. doi:10.1088/0031-9155/54/19/008Vandeghinste, B., Vandenberghe, S., Vanhove, C., Staelens, S., & Van Holen, R. (2013). Low-Dose Micro-CT Imaging for Vascular Segmentation and Analysis Using Sparse-View Acquisitions. PLoS ONE, 8(7), e68449. doi:10.1371/journal.pone.0068449Qi, H., Chen, Z., & Zhou, L. (2015). CT Image Reconstruction from Sparse Projections Using Adaptive TpV Regularization. Computational and Mathematical Methods in Medicine, 2015, 1-8. doi:10.1155/2015/354869Wu, W., Chen, P., Vardhanabhuti, V. V., Wu, W., & Yu, H. (2019). Improved Material Decomposition With a Two-Step Regularization for Spectral CT. IEEE Access, 7, 158770-158781. doi:10.1109/access.2019.2950427Rodriguez-Alvarez, M. J., Sanchez, F., Soriano, A., Moliner, L., Sanchez, S., & Benlloch, J. (2018). QR-Factorization Algorithm for Computed Tomography (CT): Comparison With FDK and Conjugate Gradient (CG) Algorithms. IEEE Transactions on Radiation and Plasma Medical Sciences, 2(5), 459-469. doi:10.1109/trpms.2018.2843803Chillarón, M., Vidal, V., & Verdú, G. (2020). CT image reconstruction with SuiteSparseQR factorization package. Radiation Physics and Chemistry, 167, 108289. doi:10.1016/j.radphyschem.2019.04.039Joseph, P. M. (1982). An Improved Algorithm for Reprojecting Rays through Pixel Images. IEEE Transactions on Medical Imaging, 1(3), 192-196. doi:10.1109/tmi.1982.4307572S. Toledo, F. Gustavson, The design and implementation of solar, a portable library for scalable out-of-core linear algebra computations, in: Proceedings of the Annual Workshop on I/O in Parallel and Distributed Systems, IOPADS,D’Azevedo, E., & Dongarra, J. (2000). The design and implementation of the parallel out-of-core ScaLAPACK LU, QR, and Cholesky factorization routines. Concurrency: Practice and Experience, 12(15), 1481-1493. doi:10.1002/1096-9128(20001225)12:153.0.co;2-vGunter, B. C., & Van De Geijn, R. A. (2005). Parallel out-of-core computation and updating of the QR factorization. ACM Transactions on Mathematical Software, 31(1), 60-78. doi:10.1145/1055531.1055534Quintana-Ortí, G., Igual, F. D., Marqués, M., Quintana-Ortí, E. S., & van de Geijn, R. A. (2012). A Runtime System for Programming Out-of-Core Matrix Algorithms-by-Tiles on Multithreaded Architectures. ACM Transactions on Mathematical Software, 38(4), 1-25. doi:10.1145/2331130.2331133Marqués, M., Quintana-Ortí, G., Quintana-Ortí, E. S., & van de Geijn, R. (2010). Using desktop computers to solve large-scale dense linear algebra problems. The Journal of Supercomputing, 58(2), 145-150. doi:10.1007/s11227-010-0394-2G. Lauritsch, H. Bruder, FORBILD head phantom, http://www.imp.uni-erlangen.de/phantoms/head/head.html.Yan, K., Wang, X., Lu, L., & Summers, R. M. (2018). DeepLesion: automated mining of large-scale lesion annotations and universal lesion detection with deep learning. Journal of Medical Imaging, 5(03), 1. doi:10.1117/1.jmi.5.3.036501Miqueles, E., Koshev, N., & Helou, E. S. (2018). A Backprojection Slice Theorem for Tomographic Reconstruction. IEEE Transactions on Image Processing, 27(2), 894-906. doi:10.1109/tip.2017.2766785N. Koshev, E.S. Helou, E.X. Miqueles, Fast backprojection techniques for high resolution tomographyarXiv preprint: 1608.03589",'Elsevier BV',Computed tomography medical image reconstruction on affordable equipment by using Out-Of-Core techniques,10.1016/j.cmpb.2020.105488,https://riunet.upv.es/bitstream/handle/10251/165764/CHILLAR%c3%93N-P%c3%89REZ%3bQuntana%3bVdal-Gmeno%20-%20Computed%20tomography%20medcalmage%20reconstructon%20on%20affordable%20e....pdf?sequence=7&isAllowed=y,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
426867658,2020-10-01T00:00:00,"Acoustic pollution has been associated with adverse effects on the health and life expectancy of people, especially when noise exposure happens during the nighttime. With over half of the world population living in urban areas, acoustic pollution is an important concern for city administrators, especially those focused on transportation and leisure noise. Advances in sensor and network technologies made the deployment of Wireless Acoustic Sensor Networks (WASN) possible in cities, which, combined with artificial intelligence (AI), can enable smart services for their citizens. However, the creation of such services often requires structured environmental audio databases to train AI algorithms. This paper reports on an environmental audio dataset of 363 min and 53 s created in a lively area of the Barcelona city center, which targeted traffic and leisure events. This dataset, which is free and publicly available, can provide researchers with real-world acoustic data to help the development and testing of sound monitoring solutions for urban environments",'MDPI AG',BCNDataset: Description and Analysis of an Annotated Night Urban Leisure Sound Dataset,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287866167,2020-12-01T00:00:00,"A video game is an interactive software able to arouse intense emotions in players. Consequentially, different theories have been proposed to understand which game aspects are able to affect the players\u2019 emotional state. However, only few works have tried to use empirical evidence to investigate the effects of different game aspects of the players\u2019 emotions. In this paper, we present the results of a set of experiments aimed at predicting the players\u2019 emotions during video games sessions using their physiological data. We have created a physiological dataset from the data acquired by 33 participants during video game fruition using a standard monitor and a Virtual Reality headset. The dataset contains information about electrocardiogram, 5 facials electromyographies, electrodermal activity, and respiration. Furthermore, we have asked the players to self-assess their emotional state on the Arousal and Valence space. We have then analyzed the contribution of each physiological signal to the overall definition of the players\u2019 mental state. Finally, we have applied Machine Learning techniques to predict the emotional state of players during game sessions at a precision of one second. The obtained results can contribute to define game devices and engines able to detect physiological data, as well to improve the game design process",'Springer Science and Business Media LLC',An empirical study of players&#8217; emotions in VR racing games based on a dataset of physiological data,10.1007/s11042-019-08585-y,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
483665146,2020-01-01T00:00:00,"An image is worth a thousand words; hence, a face image illustrates extensive details about the speciﬁcation, gender, age, and emotional states of mind. Facial expressions play an important role in community-based interactions and are often used in the behavioral analysis of emotions. Recognition of automatic facial expressions from a facial image is a challenging task in the computer vision community and admits a large set of applications, such as driver safety, human–computer interactions, health care, behavioral science, video conferencing, cognitive science, and others. In this work, a deep-learning-based scheme is proposed for identifying the facial expression of a person. The proposed method consists of two parts. The former one ﬁnds out local features from face images using a local gravitational force descriptor, while, in the latter part, the descriptor is fed into a novel deep convolution neural network (DCNN) model. The proposed DCNN has two branches. The ﬁrst branch explores geo-metric features, such as edges, curves, and lines, whereas holistic features are extracted by the second branch. Finally, the score-level fusion technique is adopted to compute the ﬁnal classiﬁca-tion score. The proposed method along with 25 state-of-the-art methods is implemented on ﬁve benchmark available databases, namely, Facial Expression Recognition 2013, Japanese Female Facial Expressions, Extended CohnKanade, Karolinska Directed Emotional Faces, and Real-world Affective Faces. The data-bases consist of seven basic emotions: neutral, happiness, anger, sadness, fear, disgust, and surprise. The proposed method is compared with existing approaches using four evaluation metrics, namely, accuracy, precision, recall, and f1-score. The obtained results demonstrate that the proposed method outperforms all state-of-the-art methods on all the databases",'Institute of Electrical and Electronics Engineers (IEEE)',Facial Expression Recognition Using Local Gravitational Force Descriptor-Based Deep Convolution Neural Networks,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
440979163,2020-01-01T00:00:00,"Wrong-site surgeries can occur due to the absence of an appropriate surgical time-out. However, during a time-out, surgical participants are unable to review the patient's charts due to their aseptic hands. To improve the conditions in surgical time-outs, we introduce a deep learning-based smart speaker to confirm the surgical information prior to cataract surgeries. This pilot study utilized the publicly available audio vocabulary dataset and recorded audio data published by the authors. The audio clips of the target words, such as left, right, cataract, phacoemulsification, and intraocular lens, were selected to determine and confirm surgical information in the time-out speech. A deep convolutional neural network model was trained and implemented in the smart speaker that was developed using a mini development board and commercial speakerphone. To validate our model in the consecutive speeches during time-outs, we generated 200 time-out speeches for cataract surgeries by randomly selecting the surgical statuses of the surgical participants. After the training process, the deep learning model achieved an accuracy of 96.3% for the validation dataset of short-word audio clips. Our deep learning-based smart speaker achieved an accuracy of 93.5% for the 200 time-out speeches. The surgical and procedural accuracy was 100%. Additionally, on validating the deep learning model by using web-generated time-out speeches and video clips for general surgery, the model exhibited a robust and good performance. In this pilot study, the proposed deep learning-based smart speaker was able to successfully confirm the surgical information during the time-out speech. Future studies should focus on collecting real-world time-out data and automatically connecting the device to electronic health records. Adopting smart speaker-assisted time-out phases will improve the patients' safety during cataract surgeries, particularly in relation to wrong-site surgeries",'Public Library of Science (PLoS)',Deep learning-based smart speaker to confirm surgical sites for cataract surgeries: A pilot study.,10.1371/journal.pone.0231322,,"[{'title': 'PLoS ONE', 'identifiers': ['issn:1932-6203', '1932-6203']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
333924544,2020-01-01T00:00:00,"International audienceThis paper proposes a learning method for denoising gyroscopes of Inertial Measurement Units (IMUs) using ground truth data, and estimating in real time the orientation (attitude) of a robot in dead reckoning. The obtained algorithm outperforms the state-of-the-art on the (unseen) test sequences. The obtained performances are achieved thanks to a well-chosen model, a proper loss function for orientation increments, and through the identification of key points when training with high-frequency inertial data. Our approach builds upon a neural network based on dilated convolutions, without requiring any recurrent neural network. We demonstrate how efficient our strategy is for 3D attitude estimation on the EuRoC and TUM-VI datasets. Interestingly, we observe our dead reckoning algorithm manages to beat top-ranked visual-inertial odometry systems in terms of attitude estimation although it does not use vision sensors. We believe this paper offers new perspectives for visual-inertial localization and constitutes a step toward more efficient learning methods involving IMUs. Our open-source implementation is available at https://github.com/mbrossar/denoise-imu-gyro",'Institute of Electrical and Electronics Engineers (IEEE)',Denoising IMU Gyroscopes with Deep Learning for Open-Loop Attitude Estimation,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
328165066,2020-05-29,"The detection of a vehicle in video is a activity that is important to help the security forces keep an eye on the traffic flow. However, it is hard to security forces to keep watching the video (CCTV) of traffic flow in all day long. Artificial intelligence can be use to help the security to monitoring and analyze the traffic of vehicles, such as to know the level of vehicle traffic density at a certain time period or find out detailed information about the vehicle that want to observe. In this study, Principle Component Analysis (PCA) method used to doing background substraction process to detect vehicles in a real time. To improve the results of PCA method, morphological operation is implemented. The experiment result shown that PCA method is well used to detect the vehicle in a real time with accuracy at 95%",STMIK JAKARTA STI&K,Vehicle Detection Using Principal Component Analysis,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
328925501,2020-09-01T00:00:00,"Combining high-resolution magnetic resonance imaging (MRI) with a linear accelerator (Linac) as a single MRI-Linac system provides the capability to monitor intra-fractional motion and anatomical changes during radiotherapy, which facilitates more accurate delivery of radiation dose to the tumour and less exposure to healthy tissue. The gradient non-linearity (GNL) induced distortions in MRI; however, hinder the implementation of MRI-Linac system in image-guided radiotherapy where highly accurate geometry and anatomy of the target tumour is indispensable.To correct the geometric distortions in MR images, in particular, for the 1 Tesla (T) MRI-Linac system, a deep fully-connected neural network was proposed to automatically learn the intricate relationship between the undistorted (theoretical) and distorted (real) space. A data set, consisting of spatial samples acquired by phantom measurement that covers both inside and outside the working diameter of spherical volume (DSV), was utilised for training the neural network; which offers the ability to describe subtle deviations of the GNL field within the entire region of interest (ROI).The performance of the proposed method was evaluated on MR images of a three-dimensional (3D) phantom and the pelvic region of an adult volunteer scanned in the 1T MRI-Linac system. The experimental results showed that the severe geometric distortions within the entire ROI had been successfully corrected with an error less than the pixel size. Also, the presented network is highly efficient, which achieved significant improvement in terms of computational efficiency compared to existing methods.The feasibility of the presented deep neural network for characterising the GNL field deviations in the 1T MRI-Linac system was demonstrated in this study, which shows promise in facilitating the MRI-Linac system to be routinely implemented in real-time MRI-guided radiotherapy",'Wiley',Fast geometric distortion correction using a deep neural network: implementation for the 1 Tesla MRI-Linac system,10.1002/mp.14382,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
477795978,2020-01-01T08:00:00,"Machine Learning is a branch of AI (Artificial Intelligence) which expands on the idea of a computational system extending its knowledge about set methodical behaviors from the data that is fed to it to essentially develop analytical skills that can help in identifying patterns and making decisions with little to no participation of a real human being. Computer algorithms help in gaining experience to improve the facility over time for use by both consumers and corporations. In today’s technologically advanced world, Machine Learning has given us self-driving cars, speech recognition software, and AI agents like Siri and Google assistant. This project evaluates how the Beta function came to be and how Stirling’s formula is implemented in calculating the magnitude of this function for large input values. The Beta function can then be used to produce a Beta distribution of probabilities to find whether people will actually watch a video they come across on their recommendations feed or search feed and then using Bayesian inference update the prior set predictions",Digital Commons @ University of South Florida,Probabilistic Machine Learning Using Bayesian Inference,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
483556158,2020-08-04T19:07:00,"© 2020 SPIE. We propose a generalized, modular, closed-loop system for objective assessment of human visual parameters. Our system presents periodical visual stimuli to the patient's field of view and analyses the consequent evoked brain potentials elicited in the occipital lobe and recorded through EEG. The analysis of the monitored EEG data is performed in an end-to-end fashion by a convolutional neural network (CNN). We propose a novel CNN architecture for EEG signal analysis that can be trained utilizing the benefits of multi-task learning. The closedloop attribute of our system allows for a real-time adaptation of the subsequent stimuli to further examine a potentially damaged area or increase the granularity of the exploration. Interchangeability is provided in terms of software modules, stimulus type, visual hardware, EEG acquisition device and EEG electrodes. Initially, the system is designed to monitor visual field loss originating from glaucoma or damage to the optic nerve using a virtual reality (VR) headset for the stimuli presentation. The modular architecture of our system paves the way for the assessment and monitoring of other neuro-visual functions",'SPIE-Intl Soc Optical Eng',A system approach for closed-loop assessment of neuro-visual function based on convolutional neural network analysis of EEG signals,10.1117/12.2554417,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
390006717,2020-03-14T00:00:00,"The subject matter of the article is the process of developing information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles arises. The goal of the study is to development of the main points for information technology of automated detection and identification of stationary objects by unmanned aerial vehicles. The tasks to be solved are: the structural diagram of the preparatory stage of information technology for automated detection and identification of stationary objects is constructed; the structural diagram of the basic, additional and final stages of information technology automated detection and identification of fixed objects is constructed. General scientific and special methods of scientific knowledge are used. One of the most effective approaches to the recognition and identification of objects is an approach based on the use of deep learning methods. A new model of UAV motion is proposed based on image recognition methods. The methods of pattern recognition with application of neural networks are considered in detail in this work too. The following results are obtained. The developed information technology is implemented in four stages: preparatory, basic, additional and final. Each stage consists of separate procedures aimed at collecting, processing, storing and transmitting information during the flight UAV. Conclusions. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles is based on the knowledge-oriented representation of the stages of image processing of objects on digital aerial photographs on board the UAV. This allows to provide intelligent real-time data processing, changing UAV flight routes depending on the objects detected to improve the effectiveness of the search tasks. Further development of this information technology lies in the development of automated methods of planning UAV routes, automatic change of route parameters in flight processes (performance of a flight task), based on knowledge-oriented technologies. Information technology for the automated detection and identification of stationary objects by unmanned aerial vehicles can become an element of intelligent decision support systems for the use of UAVs (teams of UAVs) to search for both stationary and dynamic objects.Предметом изучения в статье является процесс разработки информационной технологии автоматизированного обнаружения и идентификации стационарных объектов беспилотными летательными аппаратами. Целью исследования является разработка основных положений информационной технологии автоматизированного обнаружения и идентификации стационарных объектов беспилотными летательными аппаратами. Задачи: построение структурной схемы подготовительного этапа информационной технологии автоматизированного обнаружения и идентификации стационарных объектов; построение структурной схемы основного, дополнительного и заключительного этапов информационной технологии автоматизированного обнаружения и идентификации стационарных объектов. Методологической основой исследования стали общенаучные и специальные методы научного познания. Одним из наиболее эффективных подходов для обнаружения и идентификации объектов является подход, который базируется на использовании методов глубокого обучения. На основе методов распознавания изображений предложена новая модель движения. Использованы методы распознавания образов с использованием нейронных сетей. Получены такие результаты. Разработанная информационная технология реализуется в четыри этапа: подготовительный, основной, дополнительный и заключительный. Каждый этап состоит из отдельных процедур, направленных на сбор, обработку, хранение и передачу информации в процессе полета БПЛА. Выводы. Информационная технология автоматизированного обнаружения и идентификации стационарных объектов беспилотными летательными аппаратами базируется на знаниеориентированном представлении этапов обработки изображений объектов на цифровых аэрофотоснимках на борту беспилотного летательного аппарата. Это позволяет обеспечить интеллектуальную обработку данных в режиме времени, приближенного к реальному, изменять маршруты полета БПЛА в зависимости от выявленных объектов для повышения эффективности решения задач поиска. Дальнейшее развитие этой информационной технологии состоит в разработке автоматизированных методов планирования маршрутов движения БПЛА, автоматической смены параметров маршрута в процессе полета (выполнении полетного задания), которое основывается на знаниеориентированных технологиях. Информационная технология автоматизированного обнаружения и идентификации стационарных объектов беспилотными летательными аппаратами может стать элементом интеллектуальной системы поддержки принятия решений для использования БПЛА (коллективов БПЛА) для поиска как стационарных, так и динамических объектов.Предметом вивчення в статті є процес розробки інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами. Метою дослідження є розробка основних положень інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами. Задачі: побудова структурної схеми підготовчого етапу інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів; побудова структурної схеми основного, додаткового та заключного етапів інформаційної технології автоматизованого виявлення та ідентифікації стаціонарних об'єктів. Методологічною основою дослідження стали загальнонаукові та спеціальні методи наукового пізнання. Одним з найбільш ефективних підходів на шляху до виявлення та ідентифікації об'єктів є підхід, що базується на використанні методів глибокого навчання. На основі методів розпізнавання зображень запропонована нова модель руху. Застосовано методи розпізнавання образів із застосуванням нейронних мереж. Отримані такі результати. Розроблена інформаційна технологія реалізується в чотири етапи: підготовчий, основний, додатковий та заключний. Кожний етап складається з окремих процедур, направлених на збір, обробку, зберігання та передачу інформації в процесі польоту БПЛА. Висновки. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами базується на знанняорієнтованому представленні етапів обробки зображень об’єктів на цифрових аерофотознімках на борту безпілотного літального апарату. Це дозволяє забезпечити інтелектуальну обробку даних в режимі часу, наближеного до реального, змінювати маршрути польоту БПЛА в залежності від виявлених об’єктів для підвищення ефективності рішення задач пошуку. Подальший розвиток даної інформаційної технології полягає у розробці автоматизованих методів планування маршрутів руху БПЛА, автоматичної зміни параметрів маршруту в процесів польоту (виконанні польотного завдання), що засновується на знанняорієнтованих технологіях. Інформаційна технологія автоматизованого виявлення та ідентифікації стаціонарних об’єктів безпілотними літальними апаратами може стати елементом інтелектуальної системи підтримки прийняття рішень на застосування БПЛА (колективів БПЛА) для пошуку як стаціонарних, так і динамічних об’єктів","NTU ""KhPI""",Інформаційна технологія автоматизованого виявлення та ідентифікації  стаціонарних об’єктів безпілотними літальними апаратами,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
326520478,2020-01-01T00:00:00,"The “time-varying loudness (TVL)” model of Glasberg and Moore (2002) calculates “instantaneous loudness” every 1 ms, and this is used to generate predictions of short-term loudness, the loudness of a short segment of sound, such as a word in a sentence, and of long-term loudness, the loudness of a longer segment of sound, such as a whole sentence. The calculation of instantaneous loudness is computationally intensive and real-time implementation of the TVL model is difficult. To speed up the computation, a deep neural network (DNN) was trained to predict instantaneous loudness using a large database of speech sounds and artificial sounds (tones alone and tones in white or pink noise), with the predictions of the TVL model as a reference (providing the ""correct"" answer, specifically the loudness level in phons). A multilayer perceptron with three hidden layers was found to be sufficient, with more complex DNN architecture not yielding higher accuracy. After training, the deviations between the predictions of the TVL model and the predictions of the DNN were typically less than 0.5 phons, even for types of sounds that were not used for training (music, rain, animal sounds, washing machine). The DNN calculates instantaneous loudness over 100 times more quickly than the TVL model. Possible applications of the DNN are discussed.EPSR",Trends in hearing,Development of a Deep Neural Network for Speeding Up a Model of Loudness for Time-Varying Sounds.,10.17863/CAM.54634,https://core.ac.uk/download/326520478.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
386952744,2020-12-17T00:00:00,"Digitalisierung hat sich in Wirtschaft, Wissenschaft und Gesellschaft als der Change Maker schlechthin etabliert. Infrastrukturen, Arbeitsweisen und Kompetenzen stehen im Vordergrund vieler Debatten und bestimmen mehr und mehr die Zukunftsfähigkeit ganzer Branchen. Wir haben uns offenbar auf den permanenten Wandel bei zunehmender Beschleunigung eingelassen. Aber: Wo geht die Reise tatsächlich hin? Konstituieren sich Gemeinschaften ausschließlich im Wechselspiel hybrider Realitäten? Sind große Datenmengen Bedrohung oder Chance? Können wir diese überhaupt verarbeiten oder bedarf es dafür grundlegend veränderter Werkzeuge und Methoden – wie Visual Analytics, Virtuelle Rekonstruktion, Virtual Engineering, virtueller Assistenten und kooperativer VR? Waren IT-Innovationen bis vor kurzem etwas für Digital-Experten*innen so sind hybride Gemeinschaften in virtuellen Realitäten mittlerweile Alltag. Doch worauf müssen sich Führungskräfte einstellen? Digitalisierung bedeutet neue Möglichkeiten für Öffnung, Transparenz und Partizipation. Kommt es in diesem Zuge auch zu einem Revival humanzentrierter Managementaktivitäten? [... aus der Einleitung]:Gemeinschaften in Neuen Medien. Von hybriden Realitäten zu hybriden Gemeinschaften XXIX
Communities in New Media. From hybrid realities to hybrid communities XXXIV

A Eingeladene Vorträge 1
A.1 Interaktive Online Formate zur Wissensteilung: Systematisierung und Handlungsempfehlung für geeignete IT-Tools 1
A.2 Von der Hand in den Kopf in die Stadt 9

B Erfahrungen mit digitaler Praxis 10
B.1 Den Gottesdienst von zu Hause mitfeiern 10
B.2 Konzeption und Evaluation des Kompetenzzentrums Medien 19
B.3 Supporting Learning in Art History – Artificial Intelligence in Digital Humanities Education 28
B.4 Detecting Treasures in Museums with Artificial Intelligence 36

C Digitale Entwicklung in Wirtschaft und Industrie 49
C.1 Triebkräfte der digitalen Partizipation: Was Online-Community-Mitglieder zur proaktiven Beteiligung motiviert 49
C.2 Online-Panel: Communities und Netzwerke als Treiber des digitalen Wandels: Erfahrungen, Perspektiven und Ausblick 60
C.3 Digitale Innovationen im Handwerk 65
C.4 Online-Panel: Conversational Platforms als strategisches Digitalisierungsinstrument 75

D Partizipation 80
D.1 Ein systematisch gestalteter Softwareprototyp zur Erhöhung der Partizipationsbereitschaft 80
D.2 Gamification as a Means to Improve Stakeholder Management in Urban Planning Participation 90
D.3 The Right Reaction: Entwicklung und Evaluation eines emotionsbasierten Software-Prototypen 99

E Cases of digitizing higher education – a global perspective 110
E.1 EdTec Implementation in a global higher education network. Empirical data from a field study in South Asia 110
E.2 Use-Case Studie eines auf der Nutzung von Handlungsfehlern basierenden AR-Lernsystems zur kritischen Reflexion der technischen Umsetzbarkeit 126
E.3 Organizational models in virtual teaching cooperation – documentation and evaluation of organisational didactics in a collaborative higher education project 133
E.4 Ein Fall für zwei Hochschulen: Entwicklung eines modularen Manuals zur Gestaltung von Fallstudienseminaren im virtuellen Raum 144

F Future learning in der beruflichen Bildung 150
F.1 Potenziale für das technologiebasierte Lehren und Lernen in der Weiterbildung 150
F.2 Mediennutzungskonzepte an Berufsschulen – Webseitenanalyse zur Selbstdarstellung der digitalen Kompetenz 164
F.3 Spielend leicht Veränderungen lernen – Serious Games in der Schulungsumgebung von Unternehmen 173
F.4 Game-Based Learning in der beruflichen Bildung 179

G Methoden und Technologien des Assessments 186
G.1 Itempool-Management mit Microsoft Excel: Eine UX-Studie 186
G.2 KiWI-Kompetenzmodellentwicklung in der Wirtschaftsinformatik 195
G.3 „Nichts als die Wahrheit?“ – eine empirische Untersuchung des Zusammenhangs zwischen persönlichkeits- und nutzerbezogenen Faktoren und der Suggestibilität für Fake News im Internet 204
G.4 Decision-making style and trusting stance at the workplace: a socio-cultural approach 217

H Exploring Digital Realities empirically 226
H.1 Who gets the fame, who is to blame? Empirical exploration of responsibility attribution in HCI 226
H.2 VibTacX: A taxonomy for vibro-tactile patterns 236
H.3 Das Robot Impression Inventory – Ein modulares Instrument zur Erfassung des subjektiven Eindrucks von Robotern 244
H.4 Augmented Reality Passenger Information on Mobile Public Displays 250

I Teaching in Open Education 258
I.1 Parcours on Gamification – Ein Train-the-Trainer-Konzept zur Steigerung der Gamification-Readiness 258
I.2 Lehren mit OER: Förderung von Kompetenzen für Lehrende an Hochschulen für offene Bildung auf spielerischem Weg 264
I.3 Digitale Lehr und Lernunterstützung an deutschen Universitäten – Anforderungen und Rahmenbedingungen für die Implementierung einer Mentoring Workbench 279
I.4 Nach dem sog. MOOC-Hype: Welche kritischen Fragen an die Hochschullehre bleiben 289
I.5 Conducting Oral Examinations Virtually using MS Teams – An Insightful Experience Report 294

J Digitale Lern- und Spielkulturen 299
J.1 Spielerischer Zugang zu MINT-Studiengängen – das Serious Game des Learn&Play Projekts als Anwendungsbeispiel 299
J.2 Entwicklung und Evaluation digitaler Lernspiele – Wissenschaftliche Befunde jenseits des Entertainment 306
J.3 Ausgespielt? Zu Risiken und Nebenwirkungen von Gamification 318

K Betriebliche Weiterbildung 332
K.1 Leading Digital Change – Management of Hybridity and Change in Education and Social Service Institutions 332
K.2 Use Cases of Enterprise Social Software in Consulting: A Practice Perspective 342
K.3 Betriebliche Weiterbildung in sächsischen Klein- und Kleinstunter nehmen – arbeitsplatzintegriert und digital gestützt? 353
K.4 Wie „Change Maker“ Visionen für den digitalen Wandel an Bildungs einrichtungen des Handels entwickeln und umsetzen – ein Praxisbeispiel 364

L Digitalisierung im Lehramtsstudium 370
L.1 Anknüpfungspunkte zur Integration informatischer Inhalte und Kompetenzen in der Grundschule am Beispiel sächsischer Lehrpläne 370
L.2 Digitalisierungsbezogene Kompetenzen von Lehrenden in den Lehramtsstudiengängen – Entwicklung eines Kompetenzrahmens 377
L.3 DigiBlock – E-Learning im Blockpraktikum A im Lehramt an berufsbildenden Schulen 385

M Lehren und Lernen 391
M.1 Jump starting e-learning: the impact of COVID-19 on perceived learning success – A real-time case study 391
M.2 Online-Lehre im Lockdown: Analyse des Nutzungsverhaltens von kollaborativen Werkzeugen durch Studierende und Lehrende im Fachhochschul- und Berufsschulkontext 403
M.3 Teaching in a crisis? Guidance for digital education in Pandemic Times 413
M.4 Mit dem MINTcoach auf Mission 422
M.5 Onboarding in Virtuellen Kollaborativen Umgebungen – Implikationen für Lehre und Betrieb 432
M.6 Modulare Selbstlernangebote auf Basis von Videotutorien zur Vermittlung digitaler Forschungsmethoden in den Geisteswissenschaften – Forschungsstand und curriculare Perspektiven 441

N Wissenskollaboration im betrieblichen Kontext 452
N.1 Digitalisierung als Treiber in der beruflichen Bildung – Entwicklung eines Instruments zur Erfassung von Indikatoren für die Akzeptanz von virtuellen Lernortkooperationen 452
N.2 Digitaler Wissenstransfer in der beruflichen Bildung – Potentiale eines Online-Berichtsheftes 470
Autorenverzeichnis 476Digitisation has established itself as the change maker par excellence in business, science and society. Infrastructures, working methods and skills are at the forefront of many debates and increasingly determine the future viability of entire industries. We have obviously embraced the permanent change with increasing acceleration. But: Where is the journey really going? Do communities constitute themselves exclusively in the interplay of hybrid realities? Are large amounts of data a threat or an opportunity? Can we process them at all or do we need fundamentally different tools and methods – such as visual analytics, virtual reconstruction, virtual engineering, virtual assistants and cooperative VR? Until recently, IT innovations were something for digital experts*, but hybrid communities in virtual realities are now part of everyday life. But what do managers have to prepare for? Digitalisation means new opportunities for openness, transparency and participation. Will this also lead to a revival of human-centred management activities? [... from the introduction]:Gemeinschaften in Neuen Medien. Von hybriden Realitäten zu hybriden Gemeinschaften XXIX
Communities in New Media. From hybrid realities to hybrid communities XXXIV

A Eingeladene Vorträge 1
A.1 Interaktive Online Formate zur Wissensteilung: Systematisierung und Handlungsempfehlung für geeignete IT-Tools 1
A.2 Von der Hand in den Kopf in die Stadt 9

B Erfahrungen mit digitaler Praxis 10
B.1 Den Gottesdienst von zu Hause mitfeiern 10
B.2 Konzeption und Evaluation des Kompetenzzentrums Medien 19
B.3 Supporting Learning in Art History – Artificial Intelligence in Digital Humanities Education 28
B.4 Detecting Treasures in Museums with Artificial Intelligence 36

C Digitale Entwicklung in Wirtschaft und Industrie 49
C.1 Triebkräfte der digitalen Partizipation: Was Online-Community-Mitglieder zur proaktiven Beteiligung motiviert 49
C.2 Online-Panel: Communities und Netzwerke als Treiber des digitalen Wandels: Erfahrungen, Perspektiven und Ausblick 60
C.3 Digitale Innovationen im Handwerk 65
C.4 Online-Panel: Conversational Platforms als strategisches Digitalisierungsinstrument 75

D Partizipation 80
D.1 Ein systematisch gestalteter Softwareprototyp zur Erhöhung der Partizipationsbereitschaft 80
D.2 Gamification as a Means to Improve Stakeholder Management in Urban Planning Participation 90
D.3 The Right Reaction: Entwicklung und Evaluation eines emotionsbasierten Software-Prototypen 99

E Cases of digitizing higher education – a global perspective 110
E.1 EdTec Implementation in a global higher education network. Empirical data from a field study in South Asia 110
E.2 Use-Case Studie eines auf der Nutzung von Handlungsfehlern basierenden AR-Lernsystems zur kritischen Reflexion der technischen Umsetzbarkeit 126
E.3 Organizational models in virtual teaching cooperation – documentation and evaluation of organisational didactics in a collaborative higher education project 133
E.4 Ein Fall für zwei Hochschulen: Entwicklung eines modularen Manuals zur Gestaltung von Fallstudienseminaren im virtuellen Raum 144

F Future learning in der beruflichen Bildung 150
F.1 Potenziale für das technologiebasierte Lehren und Lernen in der Weiterbildung 150
F.2 Mediennutzungskonzepte an Berufsschulen – Webseitenanalyse zur Selbstdarstellung der digitalen Kompetenz 164
F.3 Spielend leicht Veränderungen lernen – Serious Games in der Schulungsumgebung von Unternehmen 173
F.4 Game-Based Learning in der beruflichen Bildung 179

G Methoden und Technologien des Assessments 186
G.1 Itempool-Management mit Microsoft Excel: Eine UX-Studie 186
G.2 KiWI-Kompetenzmodellentwicklung in der Wirtschaftsinformatik 195
G.3 „Nichts als die Wahrheit?“ – eine empirische Untersuchung des Zusammenhangs zwischen persönlichkeits- und nutzerbezogenen Faktoren und der Suggestibilität für Fake News im Internet 204
G.4 Decision-making style and trusting stance at the workplace: a socio-cultural approach 217

H Exploring Digital Realities empirically 226
H.1 Who gets the fame, who is to blame? Empirical exploration of responsibility attribution in HCI 226
H.2 VibTacX: A taxonomy for vibro-tactile patterns 236
H.3 Das Robot Impression Inventory – Ein modulares Instrument zur Erfassung des subjektiven Eindrucks von Robotern 244
H.4 Augmented Reality Passenger Information on Mobile Public Displays 250

I Teaching in Open Education 258
I.1 Parcours on Gamification – Ein Train-the-Trainer-Konzept zur Steigerung der Gamification-Readiness 258
I.2 Lehren mit OER: Förderung von Kompetenzen für Lehrende an Hochschulen für offene Bildung auf spielerischem Weg 264
I.3 Digitale Lehr und Lernunterstützung an deutschen Universitäten – Anforderungen und Rahmenbedingungen für die Implementierung einer Mentoring Workbench 279
I.4 Nach dem sog. MOOC-Hype: Welche kritischen Fragen an die Hochschullehre bleiben 289
I.5 Conducting Oral Examinations Virtually using MS Teams – An Insightful Experience Report 294

J Digitale Lern- und Spielkulturen 299
J.1 Spielerischer Zugang zu MINT-Studiengängen – das Serious Game des Learn&Play Projekts als Anwendungsbeispiel 299
J.2 Entwicklung und Evaluation digitaler Lernspiele – Wissenschaftliche Befunde jenseits des Entertainment 306
J.3 Ausgespielt? Zu Risiken und Nebenwirkungen von Gamification 318

K Betriebliche Weiterbildung 332
K.1 Leading Digital Change – Management of Hybridity and Change in Education and Social Service Institutions 332
K.2 Use Cases of Enterprise Social Software in Consulting: A Practice Perspective 342
K.3 Betriebliche Weiterbildung in sächsischen Klein- und Kleinstunter nehmen – arbeitsplatzintegriert und digital gestützt? 353
K.4 Wie „Change Maker“ Visionen für den digitalen Wandel an Bildungs einrichtungen des Handels entwickeln und umsetzen – ein Praxisbeispiel 364

L Digitalisierung im Lehramtsstudium 370
L.1 Anknüpfungspunkte zur Integration informatischer Inhalte und Kompetenzen in der Grundschule am Beispiel sächsischer Lehrpläne 370
L.2 Digitalisierungsbezogene Kompetenzen von Lehrenden in den Lehramtsstudiengängen – Entwicklung eines Kompetenzrahmens 377
L.3 DigiBlock – E-Learning im Blockpraktikum A im Lehramt an berufsbildenden Schulen 385

M Lehren und Lernen 391
M.1 Jump starting e-learning: the impact of COVID-19 on perceived learning success – A real-time case study 391
M.2 Online-Lehre im Lockdown: Analyse des Nutzungsverhaltens von kollaborativen Werkzeugen durch Studierende und Lehrende im Fachhochschul- und Berufsschulkontext 403
M.3 Teaching in a crisis? Guidance for digital education in Pandemic Times 413
M.4 Mit dem MINTcoach auf Mission 422
M.5 Onboarding in Virtuellen Kollaborativen Umgebungen – Implikationen für Lehre und Betrieb 432
M.6 Modulare Selbstlernangebote auf Basis von Videotutorien zur Vermittlung digitaler Forschungsmethoden in den Geisteswissenschaften – Forschungsstand und curriculare Perspektiven 441

N Wissenskollaboration im betrieblichen Kontext 452
N.1 Digitalisierung als Treiber in der beruflichen Bildung – Entwicklung eines Instruments zur Erfassung von Indikatoren für die Akzeptanz von virtuellen Lernortkooperationen 452
N.2 Digitaler Wissenstransfer in der beruflichen Bildung – Potentiale eines Online-Berichtsheftes 470
Autorenverzeichnis 47",TUDpress,Gemeinschaften in Neuen Medien. Von hybriden Realitäten zu hybriden Gemeinschaften: 23. Workshop GeNeMe'20 Gemeinschaften in Neuen Medien,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
289652309,2020-03-03T20:58:37,"Статья посвящена реализации во входном блоке нейропроцессора некоторых известных принципов информационной работы биологических систем, в том числе спайкового кодирования информации, применяемого в моделях нейронных сетей последнего поколения. Развитие современных нейросетевых ИТ порождает ряд актуальных задач, находящихся на стыке нескольких научных дисциплин. Одна из них заключается в создании аппаратной платформы –  нейропроцессора для энергоэффективной работы нейросетей. Разработка нанотехнологии основных блоков нейропроцессора в последнее время ведется на основе комбинированных мемристорных сверхбольших логических и запоминающих матриц. Топология матриц построена по принципу максимальной интеграции программируемых связей между узлами. В настоящей статье описан способ реализации биоморфной нейронной функциональности на базе программируемых связей высокоинтегрированной 3D-логической матрицы. Во введении статьи основное внимание сконцентрировано на проблеме достижения энергоэффективности работы аппаратных средств, применяемых для моделирования нейронных сетей. В основной части исследования проанализированы известные факты принципов передачи и обработки информации в биологических системах с точки зрения реализации их во входном блоке нейропроцессора. В тексте рассмотрена схема электронного нейрона, реализуемая на базе элементов 3D-логической матрицы. Представлен импульсный способ кодирования входной информации, который наиболее реалистично отражает принцип работы сенсорной биологической нейронной системы. Проанализирована модель электронного нейрона для выбора диапазонов технологических параметров в реальной схеме 3D-логической матрицы. Показана реализация дизъюнктивных нормальных форм на примере работы логической функции во входном блоке нейропроцессора. Представлены результаты моделирования фрагментов электрических цепей с мемристорами 3D-логической матрицы в режиме программирования. Биоморфное импульсное кодирование стандартных цифровых сигналов позволяет достичь высокой степени энергоэффективности работы логических элементов нейропроцессора за счет уменьшения количества срабатываний вентилей. Энергоэффективность дает возможность преодолеть тепловое ограничение масштабируемой технологии трехмерной компоновки элементов в мемристорных кроссбарах.This article studies the implementation of some well-known principles of information work of biological systems in the input unit of the neuroprocessor, including spike coding of information used in models of neural networks of the latest generation. The development of modern neural network IT gives rise to a number of urgent tasks at the junction of several scientific disciplines. One of them is to create a hardware platform – a neuroprocessor for energy-efficient operation of neural networks. Recently, the development of nanotechnology of the main units of the neuroprocessor relies on combined memristor super-large logical and storage matrices. The matrix topology is built on the principle of maximum integration of programmable links between nodes. This article describes a method for implementing biomorphic neural functionality based on programmable links of a highly integrated 3D logic matrix. This paper focuses on the problem of achieving energy efficiency of the hardware used to model neural networks. The main part analyzes the known facts of the principles of information transfer and processing in biological systems from the point of view of their implementation in the input unit of the neuroprocessor. The author deals with the scheme of an electronic neuron implemented based on elements of a 3D logical matrix. A pulsed method of encoding input information is presented, which most realistically reflects the principle of operation of a sensory biological neural system. The model of an electronic neuron for selecting ranges of technological parameters in a real 3D logic matrix scheme is analyzed. The implementation of disjunctively normal forms is shown, using the logic function in the input unit of a neuroprocessor as an example. The results of modeling fragments of electric circuits with memristors of a 3D logical matrix in programming mode are presented. The author concludes that biomorphic pulse coding of standard digital signals allows achieving a high degree of energy efficiency of the logic elements of the neuroprocessor by reducing the number of valve operations. Energy efficiency makes it possible to overcome the thermal limitation of the scalable technology of three-dimensional layout of elements in memristor crossbars",'Tyumen State University',Energy efficient biomorphic pulse information coding in electronic neurons for the entrance unit of the neuroprocessor,10.21684/2411-7978-2019-5-3-186-212,,"[{'title': 'Tyumen State University Herald Physical and Mathematical Modeling Oil Gas Energy', 'identifiers': ['issn:2500-3526', '2500-3526', '2411-7978', 'issn:2411-7978']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
522188581,2018-09-01T00:00:00,"© 2018 IEEE.The capability of following a person is crucial in service-oriented robots for human assistance and cooperation. Though a vast variety of following systems exist, they lack robustness against dynamic changes of the environment and relocating to continue following a lost target. Here we present a robust human following system that has the extendability to commercial service robot platforms having a RGB-D camera. The proposed framework integrates deep learning methods for perception and variational Bayesian techniques for trajectory prediction. Deep learning modules enable robots to accompany a person by detecting the target, learning the target and following while avoiding collision within the dynamic home environment. The variational Bayesian techniques robustly predict the trajectory of the target by empowering the following ability of the robot when target is lost. We experimentally demonstrate the capability of the deep Bayesian trajectory prediction method on real-time usage, following abilities, collision avoidance and trajectory prediction of the system. The proposed system was deployed at the RoboCup@Home 2017 Social Standard Platform League and successfully demonstrated its robust functions and smooth person following capability resulting in winning the 1st place.N","[{'title': None, 'identifiers': ['issn:1050-4729', '1050-4729']}]",Institute of Electrical and Electronics Engineers Inc.,Robust Human Following by Deep Bayesian Trajectory Prediction for Home Service Robots,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478629245,2018-01-01T00:00:00,"Purpose: This retrospective study analyzes deviations between preoperative planning and postoperative outcome in orthognathic surgery using 2D Onyx Ceph (R) - cephalometric analyzing and planning system. Materials and methods: A total of 100 patients with a mean age 25.1 of years were included in this study. In 33 patients a bilateral sagittal split osteotomy and in seven patients a Le Fort I osteotomy was performed. A total of 60 patients were treated by a bimaxillary approach. Onyx Ceph (R) was used as cephalometric planning software (Onyx Ceph (R)), followed by mock operations. Postoperative cephalograms were obtained after 3.3 days and compared to preoperative planning cephalograms for sagittal (SNA, SNB, ANB) and vertical (ArGoMe, ML-NSL, NL-NSL) angle measurements. Real and absolute mean deviation were documented. Results: Absolute mean deviation (degrees) between postoperative and planned jaw movement was lower for the sagittal parameters SNA (0.58), SNB (1.15) and ANB (1.05) compared to the vertical parameters NL-NSL (1.47), ML-NSL (1.96) and ArGoMe (3.20). SNA, SNB and ANB showed constant deviations independent from the extent of jaw movement. With regard to the vertical parameters ML-NSL, ArGoMe and NL-NSL the extent of the postoperative rotational jaw movement was not as much as planned, particularly for vertical shifts of more than 4 degrees. Conclusion: By using the 2D Onyx Ceph (R) cephalometric software for orthognathic surgery, the deviations between planned and actual movements are within an acceptable and predictable range. Planning of extensive vertical alterations may result in greater deviations after surgery. (C) 2018 European Association for Cranio-Maxillo-Facial Surgery. Published by Elsevier Ltd. All rights reserved",,'Elsevier BV',Accuracy in orthognathic surgery─comparison of preoperative plan and postoperative outcome using computer-assisted two-dimensional cephalometry by the Onyx Ceph® system,,10.1016/j.jcms.2018.07.006,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226070622,2016-12-06T14:02:43,"reserved3siThis paper presents a revision of Real Logic and its implementation with Logic Tensor Networks to address the problem of Semantic Image Interpretation. Real Logic is a framework where learning from numerical data and logical reasoning are integrated using first order logic syntax. The symbols of the signature of Real Logic are interpreted in the data-space, i.e, on the domain of real numbers. The integration of learning and reasoning obtained in Real Logic allows us to formalize learning as approximate satisfiability in the presence of logical constraints, and to perform inference on symbolic and numerical data. After introducing a refined version of the formalism, we describe its implementation into Logic Tensor Networks which uses deep learning within Google's Tensorflow. We evaluate LTN on the task of classifying objects and their parts in images, where we combine state-of-the-art-object detectors with a part-of ontology. LTN outperforms the state-of-the-art on object classification, and improves the performances on part-of relation detection with respect to a rule-based baseline.Luciano Serafini; Ivan Donadello; Artur d'Avila GarcezSerafini, Luciano; Donadello, Ivan; Artur d'Avila, Garce",,'Association for Computing Machinery (ACM)',Learning and Reasoning in Logic Tensor Networks: Theory and Application to Semantic Image Interpretation,,10.1145/3019612.3019642,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
195551950,2016-12-05T00:00:00,"International audienceOur demonstration presents an open-source hardware and software platform which allows non-roboticistsresearchers to conduct machine learning experiments to benchmark algorithms for autonomous explorationand active learning. In particular, in addition to showing the general properties of the platform such asits modularity and usability, we will demonstrate the online functioning of a particular algorithm whichallows efficient learning of multiple forward and inverse models and can leverage information from humanguidance. A first aspect of our demonstration is to illustrate the ease of use of the 3D printed low-costPoppy humanoid robotic platform, that allows non-roboticists to quickly set up and program roboticexperiments. A second aspect is to show how the Explauto library allows systematic comparison andevaluation of active learning and exploration algorithms in sensorimotor spaces, through a Python API toselect already implemented exploration algorithms. The third idea is to showcase Active Model Babbling,an efficient exploration algorithm dynamically choosing which task/goal space to explore and particulargoals to reach, and integrating social guidance from humans in real time to drive exploration towardsparticular objects or actions.[Forestier and Oudeyer, 2016] Forestier, S. and Oudeyer, P.-Y. (2016). Modular active curiosity-driven discovery oftool use. In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, Korea.[Lapeyre et al., 2014] Lapeyre, M., Rouanet, P., Grizou, J., Nguyen, S., Depraetre, F., Le Falher, A., and Oudeyer,P.-Y. (2014). Poppy Project: Open-Source Fabrication of 3D Printed Humanoid Robot for Science, Educationand Art. In Digital Intelligence 2014, page 6, Nantes, France.[Moulin-Frier et al., 2014] Moulin-Frier, C., Rouanet, P., Oudeyer, P.-Y., and others (2014). Explauto: an open-source Python library to study autonomous exploration in developmental robotics. In ICDL-Epirob-InternationalConference on Development and Learning, Epirob",,HAL CCSD,"Autonomous exploration, active learning and human guidance with open-source Poppy humanoid robot platform and Explauto library",,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
162472091,2018,"In this paper, a novel sensor platform based on screen printed carbon electrode coated by graphene modified polyacrylamide gel (GR/PAAGC) was developed and implemented for sampling, detection and enumeration of coliform bacteria (coliforms) on food contact surfaces. The optimized formula of polyacrylamide (PAA) and agar-agar increased the adhesive properties of the gel, being crucial for the coliforms recovery, attached to food contact surfaces. The 6-Chloro-3-indoxyl-β-D-galactopyranoside (6-CIGP) was used as a new electrochemical reporter for β-D-galactosidase activity. The released 6,6′-Dichloro-Indigo (6-DI) was directly detected by GR/PAAGC sensor. The presence of Isopropyl-β-D-thiogalactopyranoside (IPTG) and n-Octyl-β-D-thiogalactopyranoside (OBDG) in the gel contributed to reduction of the detection time. The addition of graphene enhanced the voltammetric signal and increased the conductivity of PAA gel. The anodic and cathodic peaks of the released product were directly proportional to the concentration of coliforms. Bacterial cell concentrations ranging from 1.6log10CFU/mL to 6.6log10CFU/mL were detected. Well-shaped, sharp voltammetric curves were generated within 3 h. Redox peaks exhibited good sensitivity with detection limits (LOD) < 0.6log10CFU/mL. After series of optimization experiments, coliforms ranging from 0.6log10CFU/cm2 to 6.610CFU/cm2 on stainless steel surfaces have been detected within 30 min with a LOD of 0.1log10CFU/cm2. The developed rapid, sensitive, reproducible and specific sensor successfully applied for single detection as well as for real-time monitoring of growth of coliform bacteria on stainless steel surfaces during food processing",,,Novel sensor platform for rapid detection and quantification of coliforms on food contact surfaces,,10.1016/j.mimet.2018.09.009,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
211369644,2017-11-01T00:00:00,"Accurately detecting and counting sparse bacterial samples has many applications in the food, beverage, and pharmaceutical processing industries, in medical diagnostics, and for life detection by robotic missions to other planets and moons of the solar system. Currently, sparse bacterial samples are counted by culture plating or epifluorescence microscopy. Culture plates require long incubation times (days to weeks), and epifluorescence microscopy requires extensive staining and concentration of the sample. Here, we demonstrate how to use off-axis digital holographic microscopy (DHM) to enumerate bacteria in very dilute cultures (100-104 cells/mL). First, the construction of the custom DHM is discussed, along with detailed instructions on building a low-cost instrument. The principles of holography are discussed, and a statistical model is used to estimate how long videos should be to detect cells, based on the optical performance characteristics of the instrument and the concentration of the bacterial solution (Table 2). Video detection of cells at 105, 104, 103, and 100 cells/mL is demonstrated in real time using un-reconstructed holograms. Reconstruction of amplitude and phase images is demonstrated using an open-source software package",,'MyJove Corporation',Quantifying Microorganisms at Low Concentrations Using Digital Holographic Microscopy (DHM),,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
217873301,2018-09-01T00:00:00,"International audienceModern surface acquisition devices, such as interferometers and confocal microscopes, make it possible to have accurate three-dimensional (3D) numerical representations of real surfaces. The numerical dental surfaces hold details that are related to the microwear that is caused by food processing. As there are numerous surface parameters that describe surface properties and knowing that a lot more can be built, is it possible to identify the ones that can separate taxa based on their diets? Until now, the candidates were chosen from among those provided by metrology software, which often implements International Organization for Standardization (ISO) parameters. Moreover, the way that a parameter is declared as diet-discriminative differs from one researcher to another. The aim of the present work is to propose a framework to broaden the investigation of relevant parameters and subsequently a procedure that is based on statistical tests to highlight the best of them. Many parameters were tested in a previous study. Here, some were dropped and others added to the classical ones. The resulting set is doubled while considering two derived surfaces: the initial one minus a second order and an eighth order polynomial. The resulting surfaces are then sampled—256 samples per surface—making it possible to build new derived parameters that are based on statistics. The studied dental surfaces belong to seven sets of three or more groups with known differences in diet. In almost all cases, the statistical procedure succeeds in identifying the most relevant parameters to reflect the group differences. Surprisingly, the widely used Area-scale fractal complexity (Asfc) parameter—despite some improvements—cannot differentiate the groups as accurately. The present work can be used as a standalone procedure, but it can also be seen as a first step towards machine learning where a lot of training data is necessary, thus making the human intervention prohibitive",,'MDPI AG',Gathering and Analyzing Surface Parameters for Diet Identification Purposes,https://core.ac.uk/download/217873301.pdf,10.3390/technologies6030075,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
301243147,2016-01-01T00:00:00,"© 20xx IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.Hand-crafted feature functions are usually designed based on the domain knowledge of a presumably controlled environment and often fail to generalize, as the statistics of real-world data cannot always be modeled correctly. Data-driven feature learning methods, on the other hand, have emerged as an alternative that often generalize better in uncontrolled environments. We present a simple, yet robust, 2D convolutional neural network extended to a concatenated 3D network that learns to extract features from the spatio-temporal domain of raw video data. The resulting network model is used for content-based recognition of videos. Relying on a 2D convolutional neural network allows us to exploit a pretrained network as a descriptor that yielded the best results on the largest and challenging ILSVRC-2014 dataset. Experimental results on commonly used benchmarking video datasets demonstrate that our results are state-of-the-art in terms of accuracy and computational time without requiring any preprocessing (e.g., optic flow) or a priori knowledge on data capture (e.g., camera motion estimation), which makes it more general and flexible than other approaches. Our implementation is made available.Peer Reviewe","[{'title': 'IEEE Robotics and Automation Letters', 'identifiers': ['issn:2377-3766', '2377-3766']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Action recognition based on efficient deep feature learning in the spatio-temporal domain,,10.1109/LRA.2016.2529686,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
144848064,2016-04-21,"In this paper, we present an architecture for recognizing events related to activities of daily living in the context of a health monitoring environment. The proposed approach explores the integration of a Raspberry PI single-board PC both as an audio acquisition and analysis unit. A set of real-time feature extraction and classification procedures has been implemented and integrated on the Raspberry PI device, in order to provide continuous and online audio event recognition. In addition, a tuning and calibration workflow is presented, according to which the technicians installing the device in a fast ans user-friendly manner, without any requirements for machine learning expertise. The proposed approach has been evaluated against a particular scenario that is rather important in the context of any healthcare monitoring system for the elder, namely the ""bathroom scenario"" according to which a single microphone installed on a Raspberry PI device is used to monitor bathroom activity in a 24/7 basis. Experimental results indicate a satisfactory performance rate on the classification process (around 70% for five bathroom-related audio classes) even when less than two minutes of annotated data are used for training in the installation procedure. This makes the whole procedure non demanding in terms of time and effort needed to be calibrated by the technician",,,A Low-cost Approach for Detecting Activities of Daily Living using Audio Information: A Use Case on Bathroom Activity Monitoring,https://core.ac.uk/download/pdf/144848064.pdf,10.5220/0005803700260032,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
158414686,2018-04-09T17:56:06,"Robots that use learned  perceptual  models in the real world must be able to safely handle cases where they are forced to make decisions in scenarios that are unlike any of their training  examples. However,  state-of-the-art  deep  learning methods are known to produce erratic or unsafe predictions when faced with novel inputs. Furthermore, recent ensemble, bootstrap and dropout methods for quantifying neural network uncertainty may not efficiently provide accurate uncertainty estimates when queried  with  inputs  that  are  very  different  from  their  training data. Rather than unconditionally trusting the predictions of a neural network for unpredictable real-world data, we use an autoencoder  to recognize when a query is novel, and revert to a safe prior behavior. With this capability,  we can deploy an autonomous deep learning system in arbitrary environments, without concern for whether it has received the appropriate training. We demonstrate our method with a vision-guided robot that can leverage its deep neural network to navigate 50% faster than  a  safe  baseline  policy in familiar types of  environments, while  reverting  to  the prior behavior in novel environments so that it can safely collect additional training data and continually improve. A video illustrating our approach is available at: http://groups.csail.mit.edu/rrg/videos/safe visual navigation",,'Robotics: Science and Systems Foundation',Safe Visual Navigation via Deep Learning and Novelty Detection,,10.15607/RSS.2017.XIII.064,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
235261716,2017-01-01T00:00:00,"This paper presents the development and implementation of a theoretical mathematical-statistical framework for sequential updating of the grade control model, based on a support vector machine learning algorithm. Utilising the Zambujal orebody within the Neves-Corvo Cu deposit in Portugal, parameters that can be measured in real time, used in visualisation, modelled for resource estimation, and used for process control visualisation and optimisation are considered.
The methodology broadly comprises of three steps. Firstly, the provided dataset is used to develop a virtual asset model (VAM) representing the true 3D grade distribution in order to simulate the mining method. Then ore quality parameters are established simulating real time monitoring sensor installation at: (a) stope development and rock face monitoring (face imaging and drillholes); and (b) transport monitoring (muck pile, LHD/scooptram). Next, the acquired data was assimilated into the models as part of the sequential model update.
Two different mining methods and the monitoring information that can be acquired during the ore extraction are analysed: (a) drift and fill mining and (b) bench and fill mining, which are widely implemented at the Neves-Corvo mine. Selected study zones were chosen such as to contrast mining through the high/low grade zones with different degrees of heterogeneity, which demonstrate the performance of resource estimation and classification models developed in heterogeneous mining stopes.
The grade accuracy and error in the resource model, and high/low grade ore classification accuracy and error are evaluated as performance metrics for the proposed methods.
In drift and fill mining, drillhole and face sampling data collection was simulated in a real-time manner and fed into the support vector machine (SVM) regressor to update the resource estimation model in both a high grade and low grade drift scenarios. In each scenario, six drift and fill mining steps were simulated sequentially and the posterior resource models, after integrating real time mining data, have shown significant improvement of bias correction in both updating planned resources and reconciling extracted ore.
In bench and fill mining, grade classification based on random sampling data from muck pile was demonstrated, considering scoop by scoop derived monitoring data. Three different classifiers (mean, median, and Bayesian) were tested and shown very good performance. In the case study presented here, a sequence of 15 blasting steps was simulated with each step requiring 112 scooping operations to transport the blasted ore. Using the real time monitored information, it was shown that at each blasting step over 85% of the scoops can be labelled correctly using the proposed methods and with an accuracy of over 95%",,TU Bergakademie Freiberg,Development of support vector machine learning algorithm for real time update of resource estimation and grade classification,https://core.ac.uk/download/235261716.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
347692253,2016-11-14T00:00:00,"Nowadays, monitoring of people and events is a common matter in the street, in the industry or at home, and acoustic event detection is commonly used. This increases the knowledge of what is happening in the soundscape, and this information encourages any monitoring system to take decisions depending on the measured events. Our research in this field includes, on one hand, smart city applications, which aim is to develop a low cost sensor network for real time noise mapping in the cities, and on the other hand, ambient assisted living applications through audio event recognition at home. This requires acoustic signal processing for event recognition, which is a challenging problem applying feature extraction techniques and machine learning methods. Furthermore, when the techniques come closer to implementation, a complete study of the most suitable platform is needed, taking into account computational complexity of the algorithms and commercial platforms price. In this work, the comparative study of several platforms serving to implement this sensing application is detailed. An FPGA platform is chosen as the optimum proposal considering the application requirements and taking into account time restrictions of the signal processing algorithms. Furthermore, we describe the first approach to the real-time implementation of the feature extraction algorithm on the chosen platform",,'MDPI AG',An FPGA Platform Proposal for Real-Time Acoustic Event Detection: Optimum Platform Implementation for Audio Recognition with Time Restrictions,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
144867413,2017-10-16,"Fast and accurate object detection is a desire of many vision-guided robotics based systems. Agriculture is an area where detection accuracy is often sacrificed for speed, especially in the pursuit of real time results. Pastoral landscapes are especially challenging with varying levels of complexity, as competing objects are rarely textually smooth or visibly different from surroundings. This study presents a machine learning algorithm designed for object detection called the Multiple Expert Colour Extreme Learning Machine (MEC-ELM). The MEC-ELM is a multiple expert implementation of a Colour Feature Extreme Learning Machine (CF-ELM). The CF-ELM is itself a modification of the Extreme Learning Machine (ELM) with a partially connected hidden layer and a fully connected output layer, taking 3 inputs. The inputs can be utilised by multiple colour systems, including, RGB, Y'UV and HSV. Colour inputs were chosen, as colour is not sensitive to adjustments in scale, size and location and provides information not available in the standard grey-scale ELM. In the MEC-ELM algorithm, feature extraction and classification techniques were implemented simultaneously making a fully functional object detection algorithm. The algorithm was tested on weed detection and cattle detection from a video feed, delivering 0.89 (cattle) to 0.98 (weeds) accuracy in tuning and a precision of 0.61 to 0.95 in testing, with classification times between 0.5s to 1s per frame. The algorithm has been designed with complex and unpredictable terrain in mind, making it an ideal application for agricultural or pastoral landscapes",,,Fast object detection in pastoral landscapes using a multiple expert colour feature extreme learning machine,https://core.ac.uk/download/pdf/144867413.pdf,10.5281/zenodo.897216,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
78397771,2016-01-01T00:00:00,"BACKGROUND: Aggressive periodontitis is associated with the presence of Aggregatibacter actinomycetemcomitans, a leukotoxin (Ltx)-producing periodontal pathogen. Ltx has the ability to lyse white blood cells including neutrophils. OBJECTIVES: This study was aimed at investigating the interactions between neutrophils and Ltx with regard to the chemotactic properties of Ltx and the release of neutrophil extracellular traps (NETs). METHODS: Neutrophils from healthy blood donors were isolated and incubated for 30 min and 3 h with increasing concentrations of Ltx (1, 10, and 100 ng/mL) as well as with A. actinomycetemcomitans strains (NCTC 9710 and HK 1651) producing different levels of Ltx. Formation of NETs and cell lysis were assessed by microscopy, fluorescence-based assays, and measurement of released lactate dehydrogenase. Neutrophil migration in response to different Ltx gradients was monitored by real-time video microscopy, and image analysis was performed using ImageJ software. RESULTS: Although Ltx (10 and 100 ng/mL) and the leukotoxic A. actinomycetemcomitans strain HK 1651 lysed some neutrophils, other cells were still capable of performing NETosis in a concentration-dependent manner. Low doses of Ltx and the weakly leukotoxic strain NCTC 9710 did not lead to neutrophil lysis, but did induce some NETosis. Furthermore, all three concentrations of Ltx enhanced random neutrophil movement; however, low directional accuracy was observed compared with the positive control (fMLP). CONCLUSIONS: The results indicate that Ltx acts both as a neutrophil activator and also causes cell death. In addition, Ltx directly induces NETosis in neutrophils prior to cell lysis. In future studies, the underlying pathways involved in Ltx-meditated neutrophil activation and NETosis need to be investigated further.Virulence mechanisms of Aggregatibacter actinomycetemcomitans leukotoxi",,'Co-Action Publishing',Effects of Aggregatibacter actinomycetemcomitans leukotoxin on neutrophil migration and extracellular trap formation.,,10.3402/jom.v8.33070,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237404380,2017-12-01T00:00:00,"Radiotherapy guidance based on magnetic resonance imaging (MRI) is currently becoming a clinical reality. Fast 2d cine MRI sequences are expected to increase the precision of radiation delivery by facilitating tumour delineation during treatment. This study compares four auto-contouring algorithms for the task of delineating the primary tumour in six locally advanced (LA) lung cancer patients.Twenty-two cine MRI sequences were acquired using either a balanced steady-state free precession or a spoiled gradient echo imaging technique. Contours derived by the auto-contouring algorithms were compared against manual reference contours. A selection of eight image data sets was also used to assess the inter-observer delineation uncertainty.Algorithmically derived contours agreed well with the manual reference contours (median Dice similarity index: ⩾0.91). Multi-template matching and deformable image registration performed significantly better than feature-driven registration and the pulse-coupled neural network (PCNN). Neither MRI sequence nor image orientation was a conclusive predictor for algorithmic performance. Motion significantly degraded the performance of the PCNN. The inter-observer variability was of the same order of magnitude as the algorithmic performance.Auto-contouring of tumours on cine MRI is feasible in LA lung cancer patients. Despite large variations in implementation complexity, the different algorithms all have relatively similar performance","[{'title': 'Radiotherapy and Oncology', 'identifiers': ['issn:1879-0887', 'issn:0167-8140', '0167-8140', '1879-0887']}]",'Elsevier BV',Tumour auto-contouring on 2d cine MRI for locally advanced lung cancer: A comparative study.,https://core.ac.uk/download/237404380.pdf,10.1016/j.radonc.2017.09.013,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395008361,2018-01-01T00:00:00,"Human-robot collaboration could be advanced by facilitating the intuitive, gaze-based control of robots, and enabling robots to recognize human actions, infer human intent, and plan actions that support human goals. Traditionally, gaze tracking approaches to action recognition have relied upon computer vision-based analyses of two-dimensional egocentric camera videos. The objective of this study was to identify useful features that can be extracted from three-dimensional (3D) gaze behavior and used as inputs to machine learning algorithms for human action recognition. We investigated human gaze behavior and gaze-object interactions in 3D during the performance of a bimanual, instrumental activity of daily living: the preparation of a powdered drink. A marker-based motion capture system and binocular eye tracker were used to reconstruct 3D gaze vectors and their intersection with 3D point clouds of objects being manipulated. Statistical analyses of gaze fixation duration and saccade size suggested that some actions (pouring and stirring) may require more visual attention than other actions (reach, pick up, set down, and move). 3D gaze saliency maps, generated with high spatial resolution for six subtasks, appeared to encode action-relevant information. The ""gaze object sequence"" was used to capture information about the identity of objects in concert with the temporal sequence in which the objects were visually regarded. Dynamic time warping barycentric averaging was used to create a population-based set of characteristic gaze object sequences that accounted for intra- and inter-subject variability. The gaze object sequence was used to demonstrate the feasibility of a simple action recognition algorithm that utilized a dynamic time warping Euclidean distance metric. Averaged over the six subtasks, the action recognition algorithm yielded an accuracy of 96.4%, precision of 89.5%, and recall of 89.2%. This level of performance suggests that the gaze object sequence is a promising feature for action recognition whose impact could be enhanced through the use of sophisticated machine learning classifiers and algorithmic improvements for real-time implementation. Robots capable of robust, real-time recognition of human actions during manipulation tasks could be used to improve quality of life in the home and quality of work in industrial environments",,"eScholarship, University of California",Exploiting Three-Dimensional Gaze Tracking for Action Recognition During Bimanual Manipulation to Enhance Human-Robot Collaboration.,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
224493157,2018-01-01T00:00:00,"Automatic gaze estimation not based on commercial and expensive eye tracking hardware solutions can enable several applications in the fields of human-computer interaction (HCI) and human behavior analysis. It is therefore not surprising that sev- eral related techniques and methods have been investi- gated in recent years. However, very few camera-based systems proposed in the literature are both real-time and robust. In this work, we propose a real-time user- calibration-free gaze estimation system that does not need person-dependent calibration, can deal with illumi- nation changes and head pose variations, and can work with a wide range of distances from the camera. Our solution is based on a 3-D appearance-based method that processes the images from a built-in laptop camera. Real-time performance is obtained by combining head pose information with geometrical eye features to train a machine learning algorithm. Our method has been validated on a data set of images of users in a natural environment, showing promising results. The possibility of a real time implementation, combined with the good quality of gaze tracking, make this system suitable for various HCI applications",,"eScholarship, University of California",Real-time gaze estimation via pupil center tracking.,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
333954951,2016-01-01T00:00:00,"In this proceeding, the architecture of a third generation Real-Time Cellular Neural Network (CNN) Processor (RTCNNP-v3) is disclosed, which is a digital CNN emulator to be implemented on an FPGA device. The previous generation emulator, RTCNNP-v2, is the only CNN implementation reported to be capable of processing full-HD 1080p@60 (1080×1920 resolution at 60 Hz frame rate) video images in real-time. However, there are some weaknesses in both the design and implementation of RTCNNP-v2, like the inability to process different parts of the video images in parallel, lack of support for recording and recalling intermediate frames using external memory and it has some jitter issues at computation rates above 200 MHz. All of those issues are addressed in the next architecture of our CNN emulator, RTCNNP-v3, which is being implemented of an FPGA device.Publisher's Versio","[{'title': None, 'identifiers': ['2165-0160', 'issn:2165-0160']}]",IEEE Computer Society,On the way to a third generation real-time cellular neural network processor,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
199457819,2017-01-01T00:00:00,"В даній роботі розглядається один із етапів розпізнавання зображення, кодування та аналіз інформації, що успішно використовується в методах штучного інтелекту. Запропонований символьний опис зображення «центр-образ» представляється в ущільненому вигляді та передбачає більш прості перетворення для виділення метричних ознак. Створені еталони, що враховують властивості математичної моделі, розширюють інформаційний простір ознак, який прийнятний для аналізу плоских та просторових образів в технічних засобах. Для апаратурної реалізації в кожному конкретному випадку слід вибирати компромісні варіанти та забезпечувати обробку зображення в системах реального часу. Реалізація блока обробки в таких системах розпізнавання з використанням нанотехнологій дозволяє досягати високої продуктивності, забезпечувати високу швидкість, інформаційну щільність, широку полосу частот пропускання та малі витрати на передачу.В данной работе рассматривается один из этапов распознавания изображений, кодирование и анализ информации, который успешно используется в методах искусственного интеллекта. Предложенное символьное описание изображения «центр-образ» представляется в сжатом виде и предусматривает более простые преобразования для выделения метрических признаков. Созданные эталоны, учитывающие свойства математической модели, расширяют информационное пространство признаков, которые приемлемы для анализа плоских и пространственных образов в технических средствах. Для аппаратурной реализации в каждом конкретном случае следует выбирать компромиссные варианты и обеспечивать обработку изображения в системах реального времени. Реализация блока обработки в таких системах распознавания с использованием нанотехнологий позволяет достигать высокой производительности, обеспечивать высокую скорость, информационную плотность, широкую полосу частот пропускания и малые затраты на передачу.In this paper, one of the stages of image recognition, coding and analysis of information that is successfully used in artificial intelligence methods is considered. The proposed symbolic description of the image the ""center-pattern"" is presented in a compressed form and provides simpler transformations for the allocation of metric features. The created standards, that consider the properties of the mathematical model, expand the information space of features that are acceptable for analyzing flat and spatial images in technical devices. For hardware implementation in each specific case choose compromise options and provide image processing in real-time systems. The implementation of the processing unit in such recognition systems using nanotechnology allows achieving high performance, providing high speed, information density, wide bandwidth and low transmission costs","[{'title': 'Optoelectronic Information-Power Technologies', 'identifiers': ['issn:2311-2662', 'issn:1681-7893', '2311-2662', '1681-7893']}]",ВНТУ,Метричні ознаки в двовимірному та тривимірному просторі,https://core.ac.uk/download/199457819.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275610953,2016-02-01T00:00:00,"[EN] This paper presents the extension of a meta-model (MAM5) and a framework based on the model (JaCalIVE) for developing intelligent virtual environments. The goal of this extension is to develop augmented mirror worlds that represent a real and virtual world coupled, so that the virtual world not only reflects the real one, but also complements it. A new component called a smart resource artifact, that enables modelling and developing devices to access the real physical world, and a human in the loop agent to place a human in the system have been included in the meta-model and framework. The proposed extension of MAM5 has been tested by simulating a light control system where agents can access both virtual and real sensor/actuators through the smart resources developed. The results show that the use of real environment interactive elements (smart resource artifacts) in agent-based simulations allows to minimize the error between simulated and real system.This work is partially supported by the TIN2009-13839-C03-01, TIN2011-27652-C03-01, 547CSD2007-00022, COST Action IC0801, FP7-294931 and the FPI grant AP2013-01276 548 awarded to Jaime-Andres Rincon.Rincón Arango, JA.; Poza Luján, JL.; Julian Inglada, VJ.; Posadas Yagüe, JL.; Carrascosa Casamayor, C. (2016). Extending MAM5 Meta-Model and JaCalIVE Framework to Integrate Smart Devices from Real Environments. PLoS ONE. 11(2):1-27. https://doi.org/10.1371/journal.pone.0149665S127112Luck, M., & Aylett, R. (2000). Applying artificial intelligence to virtual reality: Intelligent virtual environments. Applied Artificial Intelligence, 14(1), 3-32. doi:10.1080/088395100117142Barella A, Ricci A, Boissier O, Carrascosa C. MAM5: Multi-Agent Model For Intelligent Virtual Environments. In: 10th European Workshop on Multi-Agent Systems (EUMAS 2012); 2012. p. 16–30.Omicini, A., Ricci, A., & Viroli, M. (2008). Artifacts in the A&A meta-model for multi-agent systems. Autonomous Agents and Multi-Agent Systems, 17(3), 432-456. doi:10.1007/s10458-008-9053-xYu Ch, Nagpal R. Distributed Consensus and Self-Adapting Modular Robots. In: IROS-2008 workshop on Self-Reconfigurable Robots and Applications; 2008. Available from: http://www.isi.edu/robots/iros08wksp/Papers/iros08-wksp-paper.pdfLidoris G, Buss M. A Multi-Agent System Architecture for Modular Robotic Mobility Aids. In: European Robotics Symposium 2006; 2006. p. 15–26. Available from: http://link.springer.com/chapter/10.1007/11681120_2Yu, C.-H., & Nagpal, R. (2010). A Self-adaptive Framework for Modular Robots in a Dynamic Environment: Theory and Applications. The International Journal of Robotics Research, 30(8), 1015-1036. doi:10.1177/0278364910384753Barbero A, González-Rodríguez MS, de Lara J, Alfonseca M. Multi-Agent Simulation of an Educational Collaborative Web System. In: European Simulation and Modelling Conference; 2007. Available from: http://sistemas-humano-computacionais.wikidot.com/local--files/capitulo:colaboracao-auxiliada-por-computador/%5BBarbero%202007%5D%20Multi-Agent%20Simulation%20of%20an%20Educational%20Collaborative%20Web%20System.pdfRanathunga S, Cranefield S, Purvis MK. Interfacing a cognitive agent platform with a virtual world: a case study using Second Life. In: AAMAS; 2011. p. 1181–1182. Available from: http://www.aamas-conference.org/Proceedings/aamas2011/papers/B20.pdfAndreoli R, De Chiara R, Erra U, Scarano V. Interactive 3d environments by using videogame engines. In: Information Visualisation, 2005. Proceedings. Ninth International Conference on. IEEE; 2005. p. 515–520. Available from: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1509124Dignum, F. (2011). Agents for games and simulations. Autonomous Agents and Multi-Agent Systems, 24(2), 217-220. doi:10.1007/s10458-011-9169-2dos Santos C, Osorio F. AdapTIVE: an intelligent virtual environment and its application in e-commerce. In: Computer Software and Applications Conference, 2004. COMPSAC 2004. Proceedings of the 28th Annual International; 2004. p. 468–473 vol.1.Kazemi, A., Fazel Zarandi, M. H., & Moattar Husseini, S. M. (2008). A multi-agent system to solve the production–distribution planning problem for a supply chain: a genetic algorithm approach. The International Journal of Advanced Manufacturing Technology, 44(1-2), 180-193. doi:10.1007/s00170-008-1826-5Dimuro GP, Costa ACdR, Gonçalves LV, Hubner A. Interval-valued Hidden Markov Models for recognizing personality traits in social exchanges in open multiagent systems. Repositório Institucional da Universidade Federal do Rio Grande. 2008;.Woźniak, M., Graña, M., & Corchado, E. (2014). A survey of multiple classifier systems as hybrid systems. Information Fusion, 16, 3-17. doi:10.1016/j.inffus.2013.04.006Jia L, Zhenjiang M. Entertainment Oriented Intelligent Virtual Environment with Agent and Neural Networks. In: IEEE International Workshop on Haptic, Audio and Visual Environments and Games, 2007. HAVE 2007; 2007. p. 90–95.Corchado, E., Woźniak, M., Abraham, A., de Carvalho, A. C. P. L. F., & Snášel, V. (2014). Recent trends in intelligent data analysis. Neurocomputing, 126, 1-2. doi:10.1016/j.neucom.2013.07.001Ricci A, Viroli M, Omicini A. Give agents their artifacts: the A&amp;A approach for engineering working environments in MAS. In: Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems; 2007. p. 150. Available from: http://dl.acm.org/citation.cfm?id=1329308Barella, A., Valero, S., & Carrascosa, C. (2009). JGOMAS: New Approach to AI Teaching. IEEE Transactions on Education, 52(2), 228-235. doi:10.1109/te.2008.925764Behrens, T. M., Hindriks, K. V., & Dix, J. (2010). Towards an environment interface standard for agent platforms. Annals of Mathematics and Artificial Intelligence, 61(4), 261-295. doi:10.1007/s10472-010-9215-9Ricci A, Viroli M, Omicini A. A general purpose programming model &amp; technology for developing working environments in MAS. In: 5th International Workshop Programming Multi-Agent Systems(PROMAS 2007); 2007. p. 54–69. Available from: http://lia.deis.unibo.it/~ao/pubs/pdf/2007/promas.pdfChee-Yee Chong, & Kumar, S. P. (2003). Sensor networks: Evolution, opportunities, and challenges. Proceedings of the IEEE, 91(8), 1247-1256. doi:10.1109/jproc.2003.814918Kushner D. The making of arduino. IEEE Spectrum. 2011;26.Schmidt, A., & van Laerhoven, K. (2001). How to build smart appliances? IEEE Personal Communications, 8(4), 66-71. doi:10.1109/98.944006Salzmann C, Gillet D. Smart device paradigm standardization for online labs. In: 4th IEEE Global Engineering Education Conference (EDUCON); 2013.Gonzalez-Jorge, H., Riveiro, B., Vazquez-Fernandez, E., Martínez-Sánchez, J., & Arias, P. (2013). Metrological evaluation of Microsoft Kinect and Asus Xtion sensors. Measurement, 46(6), 1800-1806. doi:10.1016/j.measurement.2013.01.011Cook, D. J., & Das, S. K. (2007). How smart are our environments? An updated look at the state of the art. Pervasive and Mobile Computing, 3(2), 53-73. doi:10.1016/j.pmcj.2006.12.001Compton, M., Barnaghi, P., Bermudez, L., García-Castro, R., Corcho, O., Cox, S., … Taylor, K. (2012). The SSN ontology of the W3C semantic sensor network incubator group. Journal of Web Semantics, 17, 25-32. doi:10.1016/j.websem.2012.05.003Munera, E., Poza-Lujan, J.-L., Posadas-Yagüe, J.-L., Simó-Ten, J.-E., & Noguera, J. (2015). Dynamic Reconfiguration of a RGBD Sensor Based on QoS and QoC Requirements in Distributed Systems. Sensors, 15(8), 18080-18101. doi:10.3390/s150818080Castrillón-Santan, M., Lorenzo-Navarro, J., & Hernández-Sosa, D. (2014). Conteo de personas con un sensor RGBD comercial. Revista Iberoamericana de Automática e Informática Industrial RIAI, 11(3), 348-357. doi:10.1016/j.riai.2014.05.006Rincon JA, Julian V, Carrascosa C. An Emotional-based Hybrid Application for Human-Agent Societies. In: 10th International Conference on Soft Computing Models in Industrial and Environmental Applications. vol. 368; 2015. p. 203–214.Rincon JA, Julian V, Carrascosa C. Applying a Social Emotional Model in Human-Agent Societies. In: Workshop WIHAS’15. Intelligent Human-Agent Societies‥ vol. 524 of CCIS; 2015. p. 377–388.Leccese, F., Cagnetti, M., & Trinca, D. (2014). A Smart City Application: A Fully Controlled Street Lighting Isle Based on Raspberry-Pi Card, a ZigBee Sensor Network  and WiMAX. Sensors, 14(12), 24408-24424. doi:10.3390/s141224408Mateevitsi V, Haggadone B, Leigh J, Kunzer B, Kenyon RV. Sensing the environment through SpiderSense. In: Proceedings of the 4th Augmented Human International Conference. ACM; 2013. p. 51–57.Kavitha R, Thiyagarajan N. Distributed Intelligent Street Lamp Monitoring and Control System Based on Zigbee. International Journal of Science and Research (IJSR) PP; p. 2319–7064.Pan, M.-S., Yeh, L.-W., Chen, Y.-A., Lin, Y.-H., & Tseng, Y.-C. (2008). A WSN-Based Intelligent Light Control System Considering User Activities and Profiles. IEEE Sensors Journal, 8(10), 1710-1721. doi:10.1109/jsen.2008.2004294Villarrubia, G., De Paz, J., Bajo, J., & Corchado, J. (2014). Ambient Agents: Embedded Agents for Remote Control and Monitoring Using the PANGEA Platform. Sensors, 14(8), 13955-13979. doi:10.3390/s14081395",,'Public Library of Science (PLoS)',Extending MAM5 Meta-Model and JaCalIVE Framework to Integrate Smart Devices from Real Environments,https://riunet.upv.es/bitstream/handle/10251/61521/J.A.%20Rincon%3bPoza-Lujan%3bJulian%20-%20Extending%20MAM5%20Meta-Model%20and%20JaCalIVE%20Framework%20to%20Integrate%20Sma....PDF?sequence=1&isAllowed=y,10.1371/journal.pone.0149665,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
335619155,2017-01-01T00:00:00,"[EN] The Audio-to-Score framework consists of two separate stages: pre- processing and alignment. The alignment is commonly solved through offline Dynamic Time Warping (DTW), which is a method to find the path over the distortion matrix with the minimum cost to determine the relation between the performance and the musical score times. In this work we propose a par- allel online DTW solution based on a client-server architecture. The current version of the application has been implemented for multi-core architectures (x86, x64 and ARM), thus covering either powerful systems or mobile devices. An extensive experimentation has been conducted in order to validate the software. The experiments also show that our framework allows to achieve a good score alignment within the real-time window by using parallel computing techniques.This work has been partially supported by Spanish Ministry of Science and Innovation and FEDER under Projects TEC2012-38142-C04-01, TEC2012-38142-C04-03, TEC2012-38142-C04-04, TEC2015-67387-C4-1-R, TEC2015-67387-C4-3-R, TEC2015-67387-C4-4-R, the European Union FEDER (CAPAP-H5 network TIN2014-53522-REDT), and the Generalitat Valenciana under Grant PROMETEOII/2014/003.Alonso-Jordá, P.; Cortina, R.; Rodríguez-Serrano, F.; Vera-Candeas, P.; Alonso-González, M.; Ranilla, J. (2017). Parallel Online Time Warping for Real-Time Audio-to-Score Alignment in Multi-core Systems. The Journal of Supercomputing. 73(1):126-138. https://doi.org/10.1007/s11227-016-1647-5S126138731Joder C, Essid S, Richard G (2011) A conditional random field framework for robust and scalable audio-to-score matching. IEEE Trans Speech Audio Lang Process 19(8):2385–2397McNab RJ, Smith LA, Witten IH, Henderson CL, Cunningham SJ (1996) Towards the digital music library: tune retrieval from acoustic input. In: DL 96: Proceedings of the first ACM international conference on digital libraries. ACM, New York, pp 11–18Dannenberg RB (2007) An intelligent multi-track audio editor. In: Proceedings of international computer music conference (ICMC), vol 2, pp 89–94Duan Z, Pardo B (2011) Soundprism: an online system for score-informed source separation of music audio. IEEE J Sel Topics Signal Process 5(6):1205–1215Dixon S (2005) Live tracking of musical performances using on-line time warping. In: Proceedings of the international conference on digital audio effects (DAFx), Madrid, Spain, pp 92–97Orio N, Schwarz D (2001) Alignment of monophonic and polyphonic music to a score. In: Proceedings of the international computer music conference (ICMC), pp 129–132Simon I, Morris D, Basu S (2008) MySong: automatic accompaniment generation for vocal melodies. In: Proceedings of the SIGCHI conference on human factors in computing systems. ACM, New York, pp 725–734Rodriguez-Serrano FJ, Duan Z, Vera-Candeas P, Pardo B, Carabias-Orti JJ (2015) Online score-informed source separation with adaptive instrument models. J New Music Res Lond 44(2):83–96Arzt A, Widmer G, Dixon S (2008) Automatic page turning for musicians via real-time machine listening. In: Proceedings of the 18th European conference on artificial intelligence. IOS Press, Amsterdam, pp 241–245Carabias-Orti JJ, Rodriguez-Serrano FJ, Vera-Candeas P, Canadas-Quesada FJ, Ruiz-Reyes N (2015) An audio to score alignment framework using spectral factorization and dynamic time warping. In: 16th International Society for music information retrieval conference, pp 742–748Rodríguez-Serrano FJ, Menéndez-Canal J, Vidal A, Cañadas-Quesada FJ, Cortina R (2015) A DTW based score following method for score-informed sound source separation. In: Proceedings of the 12th sound and music computing conference 2015 (SMC-15), Ireland, pp 491–496Carabias-Ortí JJ, Rodríguez-Serrano FJ, Vera-Candeas P, Cañadas-Quesada FJ, Ruíz-Reyes N (2013) Constrained non-negative sparse coding using learnt instrument templates for realtime music transcription. Eng Appl Artif Intell 26(7):1671–1680Raphael C (2006) Aligning music audio with symbolic scores using a hybrid graphical model. Mach Learn 65:389–409Schreck-Ensemble (2001–2004) ComParser 1.42. http://home.hku.nl/~pieter.suurmond/SOFT/CMP/doc/cmp.html . Accessed Sept 2015Itakura F (1975) Minimum prediction residual principle applied to speech recognition. IEEE Trans Acoust Speech Signal Process 23:52–72Dannenberg R, Hu N (2003) Polyphonic audio matching for score following and intelligent audio editors. In: Proceedings of the international computer music conference. International Computer Music Association, San Francisco, pp 27–34Mueller M, Kurth F, Roeder T (2004) Towards an efficient algorithm for automatic score-to-audio synchronization. In: Proceedings of the 5th international conference on music information retrieval, Barcelona, SpainMueller M, Mattes H, Kurth F (2006) An efficient multiscale approach to audio synchronization. In: Proceedings of the 7th international conference on music information retrieval, Victoria, CanadaKaprykowsky H, Rodet X (2006) Globally optimal short-time dynamic time warping applications to score to audio alignment. In: IEEE ICASSP, Toulouse, France, pp 249–252Fremerey C, Müller M, Clausen M (2010) Handling repeats and jumps in score-performance synchronization. In: Proceedings of ISMIR, pp 243–248Arzt A, Widmer G (2010) Towards effective any-time music tracking. In: Proceedings of starting AI researchers symposium (STAIRS), Lisbon, Portugal, pp 24–3",,'Springer Science and Business Media LLC',Parallel Online Time Warping for Real-Time Audio-to-Score Alignment in Multi-core Systems,https://riunet.upv.es/bitstream/handle/10251/152274/Alonso-Jord%c3%a1%3bCortina%3bRodr%c3%adguez-Serrano%20-%20Parallel%20Online%20Time%20Warping%20for%20Real-Time%20Audio-to-Scor....pdf?sequence=3&isAllowed=y,10.1007/s11227-016-1647-5,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275635798,2017-01-01T00:00:00,"[EN] Wellness state is affected by the habitability state of the domestic environment. Monitoring it can help to discover the causes of a low wellness levels aiding people in the improvement of their quality of life. In this paper, we propose a system to monitor the wellness state of people utilizing Likert¿s scale to determine the state of the user through an emoticon-based human¿computer interaction. The system is intended for domestic environments and measures the habitability conditions of the dwelling (such as temperature, humidity, luminosity and noise) employing sensors. An algorithm is designed in order to establish how to measure those conditions and to calculate the statistics that allows tracking their progress. The obtained information is presented to the user to compare his/her wellness state with the habitability conditions. Measures in a real domestic environment were performed in order to determine the configuration of our system. The energy efficiency of the algorithm provides an improvement between 99.36 and 99.62% in the energy consumption depending on the selected parameters.This work has been partially supported by the “Ministerio de Ciencia e Innovación”, through the “Plan Nacional de I+D+i 2008–2011” and by the “Ministerio de Educación, Cultura y Deporte”, through the grand “Ayudas para contratos predoctorales de Formación del Profesorado Universitario FPU14/02953”.García-García, L.; Parra-Boronat, L.; Romero Martínez, JO.; Lloret, J. (2017). System for monitoring the wellness state of people in domestic environments employing emoticon-based HCI. The Journal of Supercomputing. 1-25. https://doi.org/10.1007/s11227-017-2214-4S125Sendra S, Parra L, Lloret J, Tomás J (2017) Smart system for children’s chronic illness monitoring. Inf Fusion 40:76–86Lloret J, Parra L, Taha M, Tomás J (2017) An architecture and protocol for smart continuous eHealth monitoring using 5G. Comput Netw. https://doi.org/10.1016/j.comnet.2017.05.018 (in press)Hettler B (1976) The six dimensions of wellness. National Wellness Institute. http://c.ymcdn.com/sites/www.nationalwellness.org/resource/resmgr/docs/sixdimensionsfactsheet.pdf . Accessed 12 Dec 2017Dunn HL (1959) What high-level wellness means. Can J Public Health 50(11):447–457Herbes DJ, Mulder CH (2016) Housing and subjective well-being of older adults in Europe. J Hous Built Environ. https://doi.org/10.1007/s10901-016-9526-1OECD (2015) How’s life? measuring well-being. http://www.oecd-ilibrary.org/economics/how-s-life_23089679;jsessionid=55pjippucpjrq.x-oecd-live-02 . Accessed 12 Dec 2017Donaldson GC, Seemungal T, Jeffries DJ, Wedzicha JA (1999) Effect of temperature on lung function and symptoms in chronic obstructive pulmonary disease. Eur Respir J ERS 13(4):844–849Schwartz J, Samet J, Patz J (2004) Hospital admissions for heart disease: the effects of temperature and humidity. Epidemiology 15(6):755–761National Institute of Statistics of Spain (2005) Defunciones según causa de muerte en 2003. http://www.ine.es/prensa/np393.pdf . Accessed 12 Dec 2017Grimes A, Denne T, Howden-Dhapman P, Arnold R, Telfar-Barnard L, Preval N, Young C (2012) Cost benefit analysis of the warm up New Zealand: heat smart programme. University of Wellington, Wellington. http://sustainablecities.org.nz/wp-content/uploads/NZIF_CBA_report2.pdf . Accessed 12 Dec 2017Martínez-Pérez B, de la Torre-Díez I, Candelas-Plasencia S, López-Coronado M (2013) Developement and evaluation of tools for measuring the quality of experience (QoE) in mHealth applications. J Med Syst 37(5):9976Walther JB, D’addario KP (2001) The impacts of emotions on message interpretation in computer-mediated communication. Soc Sci Comput Rev 19(3):324–347Ghayvat H, Liu J, Mukhopadhay SC, Gui X (2015) Wellness sensor networks: a proposal and implementation for smart home for assisted living. IEEE Sens J 15(12):7341–7348Forkan ARM, Hu W (2016) A context-aware, predictive and protective approach for wellness monitoring of cardiac patients. In: Computing in Cardiology Conference, Vancouver, Canada, pp 369–372Booc CER, San Diego CMD, Tee ML, Caro JDL (2016) A mobile application for campus-based psychosocial wellness program. In: 7th International Conference on Information, Systems and Applications, Chalkidiki, Greece, pp 1–4Khan WA, Idris M, Ali T, Ali R, Hussain S, Hussain M, Amin MB, Khattak AM, Weiwei Y, Afzal M, Lee S, Kang BH, (2015) Correlating health and wellness analytics for personalized decision making. Boston, USA, pp 256–261Lim C, Kim ZM, Choi H (2017) Context-based healthy lifestyle recommendation for enhancing user’s wellness. In: IEEE International Conference on Big Data and Smart Computing, Jeju, South Korea, pp 418–421Tulu B, Strong D, Wang L, He Q, Agu E, Pedersen P, Djamasbi S (2016) Design implications of user experience studies: the case of a diabetes wellness app. In: 49th Hawaii International Conference on System Sciences, Koloa, USA, pp 3473–3482Kaur D, Siddaraju GS (2016) Experimental study of cardiac functionality for the wellness of individual by developing an android application. In: International Conference on Computation System and Information Technology for Sustainable Solutions, Bangalore, India, pp 174–183Arshad A, Khan S, Alam AHMZ, Tasnim R, Boby RI (2016) Health and wellness monitoring of elderly people using intelligent sensing technique. In: International Conference on Computer and Communications Engineering, Kuala Lumpur, Malaysia, pp 231–235Martin CJ, Platt SD, Hunt SM (1987) Housing conditions and ill health. Br Med J (Clin Res Ed) 294(6580):1125–1127Evans GW, Wells NM, Moch A (2003) Housing and mental health: a review of the evidence and a methodological and conceptual critique. J Soc Issues 59(3):475–500Shaw M (2004) Housing and public health. Annu Rev Public Health 25:397–418Thomson H, Thomas S (2015) Developing empirically supported theories of change for housing investment and health. Soc Sci Med 124:205–214Gustafson CJ, Feldman SR, Quandt SA, Isom S, Chem H, Spears CR, Arcury TA (2014) The association of skin conditions with housing conditions among North Carolina Latino migrant farm workers. Int J Dermatol 53(9):1091–1097Laquesta R, Garcia L, Garcia-Magarino I, Lloret J (2017) System to recommend the best place to life based on wellness state of the user employing the heart rate variability. IEEE Access 5:10594–10604Isiaka F, Mwitondi K, Ibrahim A (2015) Automatic prediction and detection of affect state based on invariant human computer interaction and human physiological response. In: Seventh International Conference on Computational Intelligence, Modelling and Simulation, Kuantan, Malaysia, pp 19–25Han S, Liu R, Zhu C, Soo YG, Yu H, Liu T, Duan F (2016) Development of a human computer interaction system based on multi-modal gaze tracking methods. In: IEEE International Conference on Robotics and Biomimetics, Qingdao, China, pp 1894–1899Chen B, Huang S, Tsai W (2017) Eliminating driving distractions: human–computer interaction with built-in applications. IEEE Veh Technol Mag 12(1):20–29Kamal S, Sayeed F, Rafeeq M (2016) Facial emotion recognition for human–computer interactions using hybrid feature extraction technique. In: International Conference on Data Mining and Advanced Computing, Ernakulam, India, pp 180–184Agrawal R, Gupta N (2016) Real time hand gesture recognition for human computer interaction. In: IEEE 6th International Conference on Advanced Computing, Bhimavaram, India, pp 470–475Sánchez CS, Mavrogianni A, González FJN (2017) On the minimal thermal habitability conditions in low income dwellings in Spain for a new definition of fuel poverty. Build Environ 114:344–356Ministry of Health, Social Services and Equality of Spain (2015) Plan Nacional de Actuaciones Preventivas de los Efectos del Exceso de Temperaturas Sobre la Salud. http://www.msssi.gob.es/ciudadanos/saludAmbLaboral/planAltasTemp/2015/docs/Plan_Nacional_de_Exceso_de_Temperaturas_2015.pdf . Accessed 12 Dec 2017Bornehag CG, Blomquist G, Gyntelberg F, Järvholm B, Malmberg P, Nordvall L, Nielsen A, Pershagen G, Sundell J (2001) Dampness in buildings and health. Indoor Air 11(2):72–86Garret MH, Rayment PR, Hooper MA, Abramson MJ, Hooper BM (1997) Indoor airborne fungal spores, house dampness and associations with environmental factors and respiratory health in children. Clin Exp Allergy 28:459–467Ariës MBC, Zonneveldt L (2004) Architectural aspects of healthy lighting. In: 21th Conference on Passive and Low Energy Architecture, The Netherlands, pp 1–5Boubekri M, Cheung IN, Reid KJ, Wang C, Zee PC (2014) Impact of windows and daylight exposure on overall health and sleep quality of office workers: a case-control pilot study. J Clin Sleep Med 10(6):603–611Beute F, de Kort YAW (2014) Salutogenic effects of the environments: review of health protective effects of nature and daylight. Appl Psychol Health Well Being 6(1):67–95Boyce P, Hunter C, Howlett O (2003) The benefits of daylight through windows. Rensselaer Polytechnic Institute, TroyHoogendijk WJG, Lips P, Dik MG, Deeg DJH, Beekman ATF, Penninx BWJH (2008) Depression is associated with decreased 25-hydroxyvitamin D and increased parathyroid hormone levels in older adults. Arch Gen Psychiatry 65(5):508–512Ising H, Kruppa B (2004) Health effects caused by noise: evidence in the literature from the past 25 years. Noise Health 6(22):5–13Sandra S, Lloret J, Garcia M, Toledo JF (2011) Power saving and energy optimization techniques for wireless sensor networks. J Commun 6(6):439–459Heinzelman WR, Chandrakasan A, Balakrishnan H (2000) Energy-efficient communication protocol for wireless microsensor networks. In: Proceedings of the IEEE 33rd Annual Hawaii International Conference on System Sciences, Maui, HawaiiKaps JP, Sunar B (2006) Energy comparison of AES and SHA-1 for ubiquitous computing. In: Proceedings of the EUC 2006 Workshops: NCUS, SecUbiq, USN, TRUST, ESO, and MSA, Seoul, KoreaParra L, Sendra S, Jiménez JM, Lloret J (2016) Multimedia sensors embedded in smartphones for ambient assisted living and e-health. Multimed Tools Appl 75(21):13271–1329",,'Springer Science and Business Media LLC',System for monitoring the wellness state of people in domestic environments employing emoticon-based HCI,https://riunet.upv.es/bitstream/10251/102349/2/System%20for%20monitoring%20the%20wellness%20state%20of%20people_v11.pdf,10.1007/s11227-017-2214-4,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275634127,2017-01-01T00:00:00,"[EN] In this paper, we describe a new low-cost and portable electronic nose instrument, the Multisensory Odor Olfactory System MOOSY4. This prototype is based on only four metal oxide semiconductor (MOS) gas sensors suitable for IoT technology. The system architecture consists of four stages: data acquisition, data storage, data processing, and user interfacing. The designed eNose was tested with experiment for detection of volatile components in water pollution, as a dimethyl disulphide or dimethyl diselenide or sulphur. Therefore, the results provide evidence that odor information can be recognized with around 86% efficiency, detecting smells unwanted in the water and improving the quality control in bottled water factories.This work was supported by the I+D+i Program of the Generalitat Valenciana, Spain [AICO/2016/046], and the II Program UPV-La Fe [2013/0504].Climent-Martí, E.; Pelegrí Sebastiá, J.; Sogorb Devesa, T.; Talens-Felis, J.; Chilo, J. (2017). Development of the MOOSY4 eNose IoT for Sulphur-Based VOC Water Pollution Detection. Sensors. 17(8):1-10. https://doi.org/10.3390/s17081917S110178Babovic, Z. B., Protic, J., & Milutinovic, V. (2016). Web Performance Evaluation for Internet of Things Applications. IEEE Access, 4, 6974-6992. doi:10.1109/access.2016.2615181Getting Startedhttps://docs.smartcitizen.me/#/start/detailed-specificationsXu, L. D., He, W., & Li, S. (2014). Internet of Things in Industries: A Survey. IEEE Transactions on Industrial Informatics, 10(4), 2233-2243. doi:10.1109/tii.2014.2300753Huang, J., Meng, Y., Gong, X., Liu, Y., & Duan, Q. (2014). A Novel Deployment Scheme for Green Internet of Things. IEEE Internet of Things Journal, 1(2), 196-205. doi:10.1109/jiot.2014.2301819Gardner, J. W., & Bartlett, P. N. (1994). A brief history of electronic noses. Sensors and Actuators B: Chemical, 18(1-3), 210-211. doi:10.1016/0925-4005(94)87085-3Gardner, J. W., & Bartlett, P. N. (1996). Performance definition and standardization of electronic noses. Sensors and Actuators B: Chemical, 33(1-3), 60-67. doi:10.1016/0925-4005(96)01819-9Wilson, A., & Baietto, M. (2009). Applications and Advances in Electronic-Nose Technologies. Sensors, 9(7), 5099-5148. doi:10.3390/s90705099Jia, X.-M., Meng, Q.-H., Jing, Y.-Q., Qi, P.-F., Zeng, M., & Ma, S.-G. (2016). A New Method Combining KECA-LDA With ELM for Classification of Chinese Liquors Using Electronic Nose. IEEE Sensors Journal, 16(22), 8010-8017. doi:10.1109/jsen.2016.2606163Jing, Y.-Q., Meng, Q.-H., Qi, P.-F., Cao, M.-L., Zeng, M., & Ma, S.-G. (2016). A Bioinspired Neural Network for Data Processing in an Electronic Nose. IEEE Transactions on Instrumentation and Measurement, 65(10), 2369-2380. doi:10.1109/tim.2016.2578618Fine, G. F., Cavanagh, L. M., Afonja, A., & Binions, R. (2010). Metal Oxide Semi-Conductor Gas Sensors in Environmental Monitoring. Sensors, 10(6), 5469-5502. doi:10.3390/s100605469Santra, S., Guha, P. K., Ali, S. Z., Hiralal, P., Unalan, H. E., Covington, J. A., … Udrea, F. (2010). ZnO nanowires grown on SOI CMOS substrate for ethanol sensing. Sensors and Actuators B: Chemical, 146(2), 559-565. doi:10.1016/j.snb.2010.01.009Wilson, A. (2013). Diverse Applications of Electronic-Nose Technologies in Agriculture and Forestry. Sensors, 13(2), 2295-2348. doi:10.3390/s130202295Lorwongtragool, P., Sowade, E., Watthanawisuth, N., Baumann, R., & Kerdcharoen, T. (2014). A Novel Wearable Electronic Nose for Healthcare Based on Flexible Printed Chemical Sensor Array. Sensors, 14(10), 19700-19712. doi:10.3390/s141019700Son, M., Cho, D., Lim, J. H., Park, J., Hong, S., Ko, H. J., & Park, T. H. (2015). Real-time monitoring of geosmin and 2-methylisoborneol, representative odor compounds in water pollution using bioelectronic nose with human-like performance. Biosensors and Bioelectronics, 74, 199-206. doi:10.1016/j.bios.2015.06.053Gardner, J. W., Shin, H. W., Hines, E. L., & Dow, C. S. (2000). An electronic nose system for monitoring the quality of potable water. Sensors and Actuators B: Chemical, 69(3), 336-341. doi:10.1016/s0925-4005(00)00482-2Goschnick, J., Koronczi, I., Frietsch, M., & Kiselev, I. (2005). Water pollution recognition with the electronic nose KAMINA. Sensors and Actuators B: Chemical, 106(1), 182-186. doi:10.1016/j.snb.2004.05.055Guadayol, M., Cortina, M., Guadayol, J. M., & Caixach, J. (2016). Determination of dimethyl selenide and dimethyl sulphide compounds causing off-flavours in bottled mineral waters. Water Research, 92, 149-155. doi:10.1016/j.watres.2016.01.016Wilson, A. D. (2012). Review of Electronic-nose Technologies and Algorithms to Detect Hazardous Chemicals in the Environment. Procedia Technology, 1, 453-463. doi:10.1016/j.protcy.2012.02.101Becher, C., Kaul, P., Mitrovics, J., & Warmer, J. (2010). The detection of evaporating hazardous material released from moving sources using a gas sensor network. Sensors and Actuators B: Chemical, 146(2), 513-520. doi:10.1016/j.snb.2009.12.030Berrueta, L. A., Alonso-Salces, R. M., & Héberger, K. (2007). Supervised pattern recognition in food analysis. Journal of Chromatography A, 1158(1-2), 196-214. doi:10.1016/j.chroma.2007.05.024Lajara, R. J., Perez-Solano, J. J., & Pelegri-Sebastia, J. (2015). A Method for Modeling the Battery State of Charge in Wireless Sensor Networks. IEEE Sensors Journal, 15(2), 1186-1197. doi:10.1109/jsen.2014.2361151Batista, B. L., da Silva, L. R. S., Rocha, B. A., Rodrigues, J. L., Berretta-Silva, A. A., Bonates, T. O., … Barbosa, F. (2012). Multi-element determination in Brazilian honey samples by inductively coupled plasma mass spectrometry and estimation of geographic origin with data mining techniques. Food Research International, 49(1), 209-215. doi:10.1016/j.foodres.2012.07.015Benedetti, S., Mannino, S., Sabatini, A. G., & Marcazzan, G. L. (2004). Electronic nose and neural network use for the classification of honey. Apidologie, 35(4), 397-402. doi:10.1051/apido:200402",,'MDPI AG',Development of the MOOSY4 eNose IoT for Sulphur-Based VOC Water Pollution Detection,https://riunet.upv.es/bitstream/10251/98785/1/sensors-17-01917.pdf,10.3390/s17081917,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
160467102,2018-01-01T00:00:00,"Background/Aims: Apparent treatment resistant hypertension (aTRH) is highly prevalent in patients with type 2 diabetes (T2D) and chronic kidney disease (CKD). The impact of aTRH and achievement of recommended blood pressure (BP) values on the rate of glomerular filtration rate (eGFR) loss in CKD patients is poorly known. To assess the role of aTRH and time-updated BP control (BPC) on the progression of CKD in patients with T2D and hypertension (HT) in real life clinical practice. Methods: Clinical records from a total of 2,778 diabetic patients with HT and stage 3 CKD (i.e. baseline eGFR values between 30 and 60 ml/min) and regular visits during a four-year follow-up were analyzed. The association between BPC (i.e. 75% of visits with BP &lt;140/90 mmHg) and eGFR loss (i.e. a &gt;30% reduction from baseline) or worsening of albuminuria status over time was assessed. Results: At baseline 33% of patients had aTRH. Over the 4-year follow-up, 20% had a &gt;30% eGFR reduction. Patients with aTRH had an increased risk of eGFR loss &gt;30% (OR 1.31; P&lt;0.007). In patients with aTRH, BPC was associated with a 79% (P=0.029) greater risk of eGFR reduction despite a 58% (P=0.001) lower risk of albuminuria status worsening. In non-aTRH, no association was found between BPC and renal outcome. Conclusion: In patients with stage 3 CKD the presence of aTRH entails a faster loss of eGFR. More effective prevention of aTRH should be implemented as this condition is associated with a burden of risk not modifiable by tight BP reduction",,'S. Karger AG',"Apparent Treatment Resistant Hypertension, Blood Pressure Control and the Progression of Chronic Kidney Disease in Patients with Type 2 Diabetes",https://core.ac.uk/download/160467102.pdf,10.1159/000488255,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
132714466,2017-09-01T00:00:00,"Bulk body motion may randomly occur during PET acquisitions introducing blurring, attenuation emission mismatches and, in dynamic PET, discontinuities in the measured time activity curves between consecutive frames. Meanwhile, dynamic PET scans are longer, thus increasing the probability of bulk motion. In this study, we propose a streamlined 3D PET motion-compensated image reconstruction (3D-MCIR) framework, capable of robustly deconvolving intra-frame motion from a static or dynamic 3D sinogram. The presented 3D-MCIR methods need not partition the data into multiple gates, such as 4D MCIR algorithms, or access list-mode (LM) data, such as LM MCIR methods, both associated with increased computation or memory resources. The proposed algorithms can support compensation for any periodic and non-periodic motion, such as cardio-respiratory or bulk motion, the latter including rolling, twisting or drifting. Inspired from the widely adopted point-spread function (PSF) deconvolution 3D PET reconstruction techniques, here we introduce an image-based 3D generalized motion deconvolution method within the standard 3D maximum-likelihood expectation-maximization (ML-EM) reconstruction framework. In particular, we initially integrate a motion blurring kernel, accounting for every tracked motion within a frame, as an additional MLEM modeling component in the image space (integrated 3D-MCIR). Subsequently, we replaced the integrated model component with a nested iterative Richardson-Lucy (RL) image-based deconvolution method to accelerate the MLEM algorithm convergence rate (RL-3D-MCIR). The final method was evaluated with realistic simulations of whole-body dynamic PET data employing the XCAT phantom and real human bulk motion profiles, the latter estimated from volunteer dynamic MRI scans. In addition, metabolic uptake rate K-i parametric images were generated with the standard Patlak method. Our results demonstrate significant improvement in contrast-to-noise ratio (CNR) and noise bias performance in both dynamic and parametric images. The proposed nested RL-3D-MCIR method is implemented on the Software for Tomographic Image Reconstruction (STIR) open-source platform and is scheduled for public release. (C) 2016 Elsevier Ltd. All rights reserved",,'Elsevier BV',Quantitative PET image reconstruction employing nested expectation-maximization deconvolution for motion compensation,,10.1016/j.compmedimag.2016.11.006,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
78814394,2017-03-05T00:00:00,"International audienceRecent research on machine learning focuses on audio source identification in complex environments. They rely on extracting features from audio signals and use machine learning techniques to model the sound classes. However, such techniques are often not optimized for a real-time implementation and in multi-source conditions. We propose a new real-time audio single-source classification method based on a dictionary of sound models (that can be extended to a multi-source setting). The sound spectrums are modeled with mixture models and form a dictionary. The classification is based on a comparison with all the elements of the dictionary by computing likelihoods and the best match is used as a result. We found that this technique outperforms classic methods within a temporal horizon of 0.5s per decision (achieved 6% of errors on a database composed of 50 classes). Future works will focus on the multi-sources classification and reduce the computational load",,HAL CCSD,A mixture model-based real-time audio sources classification method,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
80462064,2017-03-05T00:00:00,"International audienceRecent research on machine learning focuses on audio source identification in complex environments. They rely on extracting features from audio signals and use machine learning techniques to model the sound classes. However, such techniques are often not optimized for a real-time implementation and in multi-source conditions. We propose a new real-time audio single-source classification method based on a dictionary of sound models (that can be extended to a multi-source setting). The sound spectrums are modeled with mixture models and form a dictionary. The classification is based on a comparison with all the elements of the dictionary by computing likelihoods and the best match is used as a result. We found that this technique outperforms classic methods within a temporal horizon of 0.5s per decision (achieved 6% of errors on a database composed of 50 classes). Future works will focus on the multi-sources classification and reduce the computational load",,HAL CCSD,A mixture model-based real-time audio sources classification method,https://core.ac.uk/download/80462064.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
160631705,2017-01-01T00:00:00,"This paper presents the development and implementation of a theoretical mathematical-statistical framework for sequential updating of the grade control model, based on a support vector machine learning algorithm. Utilising the Zambujal orebody within the Neves-Corvo Cu deposit in Portugal, parameters that can be measured in real time, used in visualisation, modelled for resource estimation, and used for process control visualisation and optimisation are considered.
The methodology broadly comprises of three steps. Firstly, the provided dataset is used to develop a virtual asset model (VAM) representing the true 3D grade distribution in order to simulate the mining method. Then ore quality parameters are established simulating real time monitoring sensor installation at: (a) stope development and rock face monitoring (face imaging and drillholes); and (b) transport monitoring (muck pile, LHD/scooptram). Next, the acquired data was assimilated into the models as part of the sequential model update.
Two different mining methods and the monitoring information that can be acquired during the ore extraction are analysed: (a) drift and fill mining and (b) bench and fill mining, which are widely implemented at the Neves-Corvo mine. Selected study zones were chosen such as to contrast mining through the high/low grade zones with different degrees of heterogeneity, which demonstrate the performance of resource estimation and classification models developed in heterogeneous mining stopes.
The grade accuracy and error in the resource model, and high/low grade ore classification accuracy and error are evaluated as performance metrics for the proposed methods.
In drift and fill mining, drillhole and face sampling data collection was simulated in a real-time manner and fed into the support vector machine (SVM) regressor to update the resource estimation model in both a high grade and low grade drift scenarios. In each scenario, six drift and fill mining steps were simulated sequentially and the posterior resource models, after integrating real time mining data, have shown significant improvement of bias correction in both updating planned resources and reconciling extracted ore.
In bench and fill mining, grade classification based on random sampling data from muck pile was demonstrated, considering scoop by scoop derived monitoring data. Three different classifiers (mean, median, and Bayesian) were tested and shown very good performance. In the case study presented here, a sequence of 15 blasting steps was simulated with each step requiring 112 scooping operations to transport the blasted ore. Using the real time monitored information, it was shown that at each blasting step over 85% of the scoops can be labelled correctly using the proposed methods and with an accuracy of over 95%",,TU Bergakademie Freiberg,Development of support vector machine learning algorithm for real time update of resource estimation and grade classification,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
335618283,2017-11-01T00:00:00,"""© ACM, 2017. This is the author's version of the work. It is posted here by permission of ACM for your personal use. Not for redistribution. The definitive version was published in ACM Computing Surveys, {50, 4, 2017} https://dl.acm.org/doi/10.1145/3106740""[EN] Algorithmic debugging is a technique proposed in 1982 by E. Y. Shapiro in the context of logic programming. This survey shows how the initial ideas have been developed to become a widespread debugging schema ftting many diferent programming paradigms and with applications out of the program debugging feld. We describe the general framework and the main issues related to the implementations in diferent programming paradigms and discuss several proposed improvements and optimizations. We also review the main algorithmic debugger tools that have been implemented so far and compare their features. From this comparison, we elaborate a summary of desirable characteristics that should be considered when implementing future algorithmic debuggers.This work has been partially supported by the EU (FEDER) and the Spanish Ministerio de Economia y Competitividad under grant TIN2013-44742-C4-1-R, TIN2016-76843-C4-1-R, StrongSoft (TIN2012-39391-C04-04), and TRACES (TIN2015-67522-C3-3-R) by the Generalitat Valenciana under grant PROMETEO-II/2015/013 (SmartLogic) and by the Comunidad de Madrid project N-Greens Software-CM (S2013/ICE-2731).Caballero, R.; Riesco, A.; Silva, J. (2017). A Survey of Algorithmic Debugging. ACM Computing Surveys. 50(4):1-35. https://doi.org/10.1145/3106740S135504Abramson, D., Foster, I., Michalakes, J., & Sosič, R. (1996). Relative debugging. Communications of the ACM, 39(11), 69-77. doi:10.1145/240455.240475K. R. Apt H. A. Blair and A. Walker. 1988. Towards a theory of declarative knowledge. In Foundations of Deductive Databases and Logic Programming J. Minker (Ed.). Morgan Kaufmann Publishers Inc. San Francisco CA 89--148. 10.1016/B978-0-934613-40-8.50006-3 K. R. Apt H. A. Blair and A. Walker. 1988. Towards a theory of declarative knowledge. In Foundations of Deductive Databases and Logic Programming J. Minker (Ed.). Morgan Kaufmann Publishers Inc. San Francisco CA 89--148. 10.1016/B978-0-934613-40-8.50006-3Arora, T., Ramakrishnan, R., Roth, W. G., Seshadri, P., & Srivastava, D. (1993). Explaining program execution in deductive systems. Lecture Notes in Computer Science, 101-119. doi:10.1007/3-540-57530-8_7E. Av-Ron. 1984. Top-Down Diagnosis of Prolog Programs. Ph.D. Dissertation. Weizmann Institute. E. Av-Ron. 1984. Top-Down Diagnosis of Prolog Programs. Ph.D. Dissertation. Weizmann Institute.A. Beaulieu. 2005. Learning SQL. O’Reilly Farnham UK. A. Beaulieu. 2005. Learning SQL. O’Reilly Farnham UK.D. Binks. 1995. Declarative Debugging in Gödel. Ph.D. Dissertation. University of Bristol. D. Binks. 1995. Declarative Debugging in Gödel. Ph.D. Dissertation. University of Bristol.B. Braßel and H. Siegel. 2008. Debugging Lazy Functional Programs by Asking the Oracle. Springer-Verlag Berlin 183--200. DOI:http://dx.doi.org/10.1007/978-3-540-85373-2_11 10.1007/978-3-540-85373-2_11 B. Braßel and H. Siegel. 2008. Debugging Lazy Functional Programs by Asking the Oracle. Springer-Verlag Berlin 183--200. DOI:http://dx.doi.org/10.1007/978-3-540-85373-2_11 10.1007/978-3-540-85373-2_11Caballero, R. (2005). A declarative debugger of incorrect answers for constraint functional-logic programs. Proceedings of the 2005 ACM SIGPLAN workshop on Curry and functional logic programming  - WCFLP  ’05. doi:10.1145/1085099.1085102Caballero, R., García-Ruiz, Y., & Sáenz-Pérez, F. (2012). Declarative Debugging of Wrong and Missing Answers for SQL Views. Lecture Notes in Computer Science, 73-87. doi:10.1007/978-3-642-29822-6_9Caballero, R., García-Ruiz, Y., & Sáenz-Pérez, F. (2015). Debugging of wrong and missing answers for datalog programs with constraint handling rules. Proceedings of the 17th International Symposium on Principles and Practice of Declarative Programming - PPDP  ’15. doi:10.1145/2790449.2790522Caballero, R., Martin-Martin, E., Riesco, A., & Tamarit, S. (2015). A zoom-declarative debugger for sequential Erlang programs. Science of Computer Programming, 110, 104-118. doi:10.1016/j.scico.2015.06.011Caballero, R., & Rodríguez-Artalejo, M. (2002). A Declarative Debugging System for Lazy Functional Logic Programs. Electronic Notes in Theoretical Computer Science, 64, 113-175. doi:10.1016/s1571-0661(04)80349-9Ceri, S., Gottlob, G., & Tanca, L. (1989). What you always wanted to know about Datalog (and never dared to ask). IEEE Transactions on Knowledge and Data Engineering, 1(1), 146-166. doi:10.1109/69.43410Chen, M., Mao, S., & Liu, Y. (2014). Big Data: A Survey. Mobile Networks and Applications, 19(2), 171-209. doi:10.1007/s11036-013-0489-0Chitil, O., & Davie, T. (2008). Comprehending finite maps for algorithmic debugging of higher-order functional programs. Proceedings of the 10th international ACM SIGPLAN symposium on Principles and practice of declarative programming - PPDP  ’08. doi:10.1145/1389449.1389475Chitil, O., Faddegon, M., & Runciman, C. (2016). A Lightweight Hat. Proceedings of the 28th Symposium on the Implementation and Application of Functional Programming Languages - IFL 2016. doi:10.1145/3064899.3064904O. Chitil C. Runciman and M. Wallace. 2001. Freja Hat and Hood—A Comparative Evaluation of Three Systems for Tracing and Debugging Lazy Functional Programs. Springer Berlin 176--193. O. Chitil C. Runciman and M. Wallace. 2001. Freja Hat and Hood—A Comparative Evaluation of Three Systems for Tracing and Debugging Lazy Functional Programs. Springer Berlin 176--193.O. Chitil C. Runciman and Malcolm Wallace. 2003. Transforming Haskell for Tracing. Springer-Verlag Berlin 165--181. DOI:http://dx.doi.org/10.1007/3-540-44854-3_11 10.1007/3-540-44854-3_11 O. Chitil C. Runciman and Malcolm Wallace. 2003. Transforming Haskell for Tracing. Springer-Verlag Berlin 165--181. DOI:http://dx.doi.org/10.1007/3-540-44854-3_11 10.1007/3-540-44854-3_11Minh Ngoc Dinh, Abramson, D., & Chao Jin. (2014). Scalable Relative Debugging. IEEE Transactions on Parallel and Distributed Systems, 25(3), 740-749. doi:10.1109/tpds.2013.86Faddegon, M., & Chitil, O. (2015). Algorithmic debugging of real-world haskell programs: deriving dependencies from the cost centre stack. ACM SIGPLAN Notices, 50(6), 33-42. doi:10.1145/2813885.2737985Faddegon, M., & Chitil, O. (2016). Lightweight computation tree tracing for lazy functional languages. Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation - PLDI 2016. doi:10.1145/2908080.2908104Ferrand, G. (1987). Error diagnosis in logic programming an adaptation of E.Y. Shapiro’s method. The Journal of Logic Programming, 4(3), 177-198. doi:10.1016/0743-1066(87)90001-xFritzson, P., Shahmehri, N., Kamkar, M., & Gyimothy, T. (1992). Generalized algorithmic debugging and testing. ACM Letters on Programming Languages and Systems, 1(4), 303-322. doi:10.1145/161494.161498Fromherz, M. P. J. (s. f.). Towards declarative debugging of concurrent constraint programs. Lecture Notes in Computer Science, 88-100. doi:10.1007/bfb0019403Harman, M., & Hierons, R. (2001). An overview of program slicing. Software Focus, 2(3), 85-92. doi:10.1002/swf.41F. Henderson T. Conway Z. Somogyi D. Jeffery P. Schachte S. Taylor C. Speirs T. Dowd R. Becket M. Brown and P. Wang. 2014. The Mercury Language Reference Manual (Version 14.01.1). The University of Melbourne. F. Henderson T. Conway Z. Somogyi D. Jeffery P. Schachte S. Taylor C. Speirs T. Dowd R. Becket M. Brown and P. Wang. 2014. The Mercury Language Reference Manual (Version 14.01.1). The University of Melbourne.C. Hermanns and H. Kuchen. 2013. Hybrid Debugging of Java Programs. Springer-Verlag Berlin 91--107. DOI:http://dx.doi.org/10.1007/978-3-642-36177-7_6 10.1007/978-3-642-36177-7_6 C. Hermanns and H. Kuchen. 2013. Hybrid Debugging of Java Programs. Springer-Verlag Berlin 91--107. DOI:http://dx.doi.org/10.1007/978-3-642-36177-7_6 10.1007/978-3-642-36177-7_6Hirunkitti, V., & Hogger, C. J. (s. f.). A generalised query minimisation for program debugging. Lecture Notes in Computer Science, 153-170. doi:10.1007/bfb0019407Hughes, J. (2010). Software Testing with QuickCheck. Lecture Notes in Computer Science, 183-223. doi:10.1007/978-3-642-17685-2_6G. Hutton. 2016. Programming in Haskell. Cambridge University Press Cambridge UK. G. Hutton. 2016. Programming in Haskell. Cambridge University Press Cambridge UK.Insa, D., & Silva, J. (2010). An algorithmic debugger for Java. 2010 IEEE International Conference on Software Maintenance. doi:10.1109/icsm.2010.5609661Insa, D., & Silva, J. (2011). Optimal Divide and Query. Lecture Notes in Computer Science, 224-238. doi:10.1007/978-3-642-24769-9_17Insa, D., & Silva, J. (2011). An optimal strategy for algorithmic debugging. 2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011). doi:10.1109/ase.2011.6100055D. Insa and J. Silva. 2011c. Scaling Up Algorithmic Debugging with Virtual Execution Trees. Springer-Verlag Berlin 149--163. DOI:http://dx.doi.org/10.1007/978-3-642-20551-4_10 10.1007/978-3-642-20551-4_10 D. Insa and J. Silva. 2011c. Scaling Up Algorithmic Debugging with Virtual Execution Trees. Springer-Verlag Berlin 149--163. DOI:http://dx.doi.org/10.1007/978-3-642-20551-4_10 10.1007/978-3-642-20551-4_10D. Insa and J. Silva. 2015a. Automatic transformation of iterative loops into recursive methods. Information 8 Software Technology 58 (2015) 95--109. DOI:http://dx.doi.org/10.1016/j.infsof.2014.10.001 10.1016/j.infsof.2014.10.001 D. Insa and J. Silva. 2015a. Automatic transformation of iterative loops into recursive methods. Information 8 Software Technology 58 (2015) 95--109. DOI:http://dx.doi.org/10.1016/j.infsof.2014.10.001 10.1016/j.infsof.2014.10.001Insa, D., & Silva, J. (2015). A Generalized Model for Algorithmic Debugging. Lecture Notes in Computer Science, 261-276. doi:10.1007/978-3-319-27436-2_16Insa, D., Silva, J., & Riesco, A. (2013). Speeding Up Algorithmic Debugging Using Balanced Execution Trees. Lecture Notes in Computer Science, 133-151. doi:10.1007/978-3-642-38916-0_8Insa, D., Silva, J., & Tomás, C. (2013). Enhancing Declarative Debugging with Loop Expansion and Tree Compression. Lecture Notes in Computer Science, 71-88. doi:10.1007/978-3-642-38197-3_6K. Jensen and N. Wirth. 1974. PASCAL User Manual and Report. Springer-Verlag Berlin. 10.1007/978-3-662-21554-8 K. Jensen and N. Wirth. 1974. PASCAL User Manual and Report. Springer-Verlag Berlin. 10.1007/978-3-662-21554-8Jia, Y., & Harman, M. (2011). An Analysis and Survey of the Development of Mutation Testing. IEEE Transactions on Software Engineering, 37(5), 649-678. doi:10.1109/tse.2010.62Kamkar, M., Shahmehri, N., & Fritzson, P. (s. f.). Bug localization by algorithmic debugging and program slicing. Lecture Notes in Computer Science, 60-74. doi:10.1007/bfb0024176S. Köhler B. Ludäscher and Y. Smaragdakis. 2012. Declarative Datalog Debugging for Mere Mortals. Springer-Verlag Berlin 111--122. S. Köhler B. Ludäscher and Y. Smaragdakis. 2012. Declarative Datalog Debugging for Mere Mortals. Springer-Verlag Berlin 111--122.Kouh, H.-J., & Yoo, W.-H. (2003). The Efficient Debugging System for Locating Logical Errors in Java Programs. Lecture Notes in Computer Science, 684-693. doi:10.1007/3-540-44839-x_72Benzmüller, C., & Miller, D. (2014). Automation of Higher-Order Logic. Handbook of the History of Logic, 215-254. doi:10.1016/b978-0-444-51624-4.50005-8Kowalski, R., & Kuehner, D. (1971). Linear resolution with selection function. Artificial Intelligence, 2(3-4), 227-260. doi:10.1016/0004-3702(71)90012-9K. Kuchcinski W. Drabent and J. Maluszynski. 1993. Automatic Diagnosis of VLSI Digital Circuits Using Algorithmic Debugging. Springer-Verlag Berlin 350--367. DOI:http://dx.doi.org/10.1007/BFb0019419 10.1007/BFb0019419 K. Kuchcinski W. Drabent and J. Maluszynski. 1993. Automatic Diagnosis of VLSI Digital Circuits Using Algorithmic Debugging. Springer-Verlag Berlin 350--367. DOI:http://dx.doi.org/10.1007/BFb0019419 10.1007/BFb0019419S. Liang. 1999. Java Native Interface: Programmer’s Guide and Reference (1st ed.). Addison-Wesley Longman Publishing Co. Inc. Boston MA. S. Liang. 1999. Java Native Interface: Programmer’s Guide and Reference (1st ed.). Addison-Wesley Longman Publishing Co. Inc. Boston MA.Lloyd, J. W. (1987). Declarative error diagnosis. New Generation Computing, 5(2), 133-154. doi:10.1007/bf03037396J. W. Lloyd. 1987b. Foundations of Logic Programming (2nd ed.). Springer-Verlag Berlin. 10.1007/978-3-642-83189-8 J. W. Lloyd. 1987b. Foundations of Logic Programming (2nd ed.). Springer-Verlag Berlin. 10.1007/978-3-642-83189-8W. Lux. 2006. Münster Curry User’s guide (Release 0.9.10 of May 10 2006). Retrieved from http://danae.uni-muenster.de/&sim;lux/curry/user.pdf. W. Lux. 2006. Münster Curry User’s guide (Release 0.9.10 of May 10 2006). Retrieved from http://danae.uni-muenster.de/&sim;lux/curry/user.pdf.Lux, W. (2008). Declarative Debugging Meets the World. Electronic Notes in Theoretical Computer Science, 216, 65-77. doi:10.1016/j.entcs.2008.06.034I. MacLarty. 2005. Practical Declarative Debugging of Mercury Programs. Ph.D. Dissertation. Department of Computer Science and Software Engineering The University of Melbourne. I. MacLarty. 2005. Practical Declarative Debugging of Mercury Programs. Ph.D. Dissertation. Department of Computer Science and Software Engineering The University of Melbourne.Naganuma, J., Ogura, T., & Hoshino, T. (s. f.). High-level design validation using algorithmic debugging. Proceedings of European Design and Test Conference EDAC-ETC-EUROASIC. doi:10.1109/edtc.1994.326833Naish, L. (1992). Declarative diagnosis of missing answers. New Generation Computing, 10(3), 255-285. doi:10.1007/bf03037939H. Nilsson. 1998. Declarative Debugging for Lazy Functional Languages. Ph.D. Dissertation. Linköping Sweden. H. Nilsson. 1998. Declarative Debugging for Lazy Functional Languages. Ph.D. Dissertation. Linköping Sweden.NILSSON, H. (2001). How to look busy while being as lazy as ever: the Implementation of a lazy functional debugger. Journal of Functional Programming, 11(6), 629-671. doi:10.1017/s095679680100418xNilsson, H., & Fritzson, P. (s. f.). Algorithmic debugging for lazy functional languages. Lecture Notes in Computer Science, 385-399. doi:10.1007/3-540-55844-6_149Nilsson, H., & Fritzson, P. (1994). Algorithmic debugging for lazy functional languages. Journal of Functional Programming, 4(3), 337-369. doi:10.1017/s095679680000109xNilsson, H., & Sparud, J. (1997). Automated Software Engineering, 4(2), 121-150. doi:10.1023/a:1008681016679Ostrand, T. J., & Balcer, M. J. (1988). The category-partition method for specifying and generating fuctional tests. Communications of the ACM, 31(6), 676-686. doi:10.1145/62959.62964Pereira, L. M. (1986). Rational debugging in logic programming. Third International Conference on Logic Programming, 203-210. doi:10.1007/3-540-16492-8_76B. Pope. 2006. A Declarative Debugger for Haskell. Ph.D. Dissertation. The University of Melbourne Australia. B. Pope. 2006. A Declarative Debugger for Haskell. Ph.D. Dissertation. The University of Melbourne Australia.Ramakrishnan, R., & Ullman, J. D. (1995). A survey of deductive database systems. The Journal of Logic Programming, 23(2), 125-149. doi:10.1016/0743-1066(94)00039-9Riesco, A., Verdejo, A., Martí-Oliet, N., & Caballero, R. (2012). Declarative debugging of rewriting logic specifications. The Journal of Logic and Algebraic Programming, 81(7-8), 851-897. doi:10.1016/j.jlap.2011.06.004DeRose, L., Gontarek, A., Vose, A., Moench, R., Abramson, D., Dinh, M. N., & Jin, C. (2015). Relative debugging for a highly parallel hybrid computer system. Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis on - SC  ’15. doi:10.1145/2807591.2807605Runeson, P. (2006). A survey of unit testing practices. IEEE Software, 23(4), 22-29. doi:10.1109/ms.2006.91Russo, F., & Sancassani, M. (1992). A declarative debugging environment for DATALOG. Lecture Notes in Computer Science, 433-441. doi:10.1007/3-540-55460-2_32E. Y. Shapiro. 1982a. Algorithmic Program Debugging. MIT Press Cambridge MA. E. Y. Shapiro. 1982a. Algorithmic Program Debugging. MIT Press Cambridge MA.Shapiro, E. Y. (1982). Algorithmic program diagnosis. Proceedings of the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages  - POPL  ’82. doi:10.1145/582153.582185Shmueli, O., & Tsur, S. (1991). Logical diagnosis ofLDL programs. New Generation Computing, 9(3-4), 277-303. doi:10.1007/bf03037166Silva, J. (s. f.). A Comparative Study of Algorithmic Debugging Strategies. Lecture Notes in Computer Science, 143-159. doi:10.1007/978-3-540-71410-1_11Silva, J. (2011). A survey on algorithmic debugging strategies. Advances in Engineering Software, 42(11), 976-991. doi:10.1016/j.advengsoft.2011.05.024Silva, J., & Chitil, O. (2006). Combining algorithmic debugging and program slicing. Proceedings of the 8th ACM SIGPLAN symposium on Principles and practice of declarative programming  - PPDP  ’06. doi:10.1145/1140335.1140355J. A. Silva E. R. Faria R. C. Barros E. R. Hruschka A. C. P. L. F. de Carvalho and J. Gama. 2013. Data stream clustering: A survey. Comput. Surv. 46 1 Article 13 (July 2013) 31 pages.DOI:http://dx.doi.org/10.1145/2522968.2522981 10.1145/2522968.2522981 J. A. Silva E. R. Faria R. C. Barros E. R. Hruschka A. C. P. L. F. de Carvalho and J. Gama. 2013. Data stream clustering: A survey. Comput. Surv. 46 1 Article 13 (July 2013) 31 pages.DOI:http://dx.doi.org/10.1145/2522968.2522981 10.1145/2522968.2522981SOSIČ, R., & ABRAMSON, D. (1997). Guard: A Relative Debugger. Software: Practice and Experience, 27(2), 185-206. doi:10.1002/(sici)1097-024x(199702)27:23.0.co;2-dL. Sterling and E. Shapiro. 1986. The Art of Prolog: Advanced Programming Techniques. The MIT Press Cambridge MA. L. Sterling and E. Shapiro. 1986. The Art of Prolog: Advanced Programming Techniques. The MIT Press Cambridge MA.P. Kambam Sugavanam. 2013. Debugging Framework for Attribute Grammars. Ph.D. Dissertation. University of Minnesota. P. Kambam Sugavanam. 2013. Debugging Framework for Attribute Grammars. Ph.D. Dissertation. University of Minnesota.Tamarit, S., Riesco, A., Martin-Martin, E., & Caballero, R. (2016). Debugging Meets Testing in Erlang. Lecture Notes in Computer Science, 171-180. doi:10.1007/978-3-319-41135-4_10A. Tessier and G. Ferrand. 2000. Declarative diagnosis in the CLP scheme. In Analysis and Visualization Tools for Constraint Programming: Constraint Debugging Pierre Deransart Manuel V. Hermenegildo and Jan Maluszynski (Eds.). Springer-Verlag Berlin 151--174. 10.1007/10722311_6 A. Tessier and G. Ferrand. 2000. Declarative diagnosis in the CLP scheme. In Analysis and Visualization Tools for Constraint Programming: Constraint Debugging Pierre Deransart Manuel V. Hermenegildo and Jan Maluszynski (Eds.). Springer-Verlag Berlin 151--174. 10.1007/10722311_6Zinn, C. (2013). Algorithmic Debugging for Intelligent Tutoring: How to Use Multiple Models and Improve Diagnosis. Lecture Notes in Computer Science, 272-283. doi:10.1007/978-3-642-40942-4_24Zinn, C. (2014). Algorithmic Debugging and Literate Programming to Generate Feedback in Intelligent Tutoring Systems. KI 2014: Advances in Artificial Intelligence, 37-48. doi:10.1007/978-3-319-11206-0_",,'Association for Computing Machinery (ACM)',A Survey of Algorithmic Debugging,https://riunet.upv.es/bitstream/10251/151050/3/Caballero%3bRiesco%3bSilva%20-%20A%20Survey%20of%20Algorithmic%20Debugging.pdf,10.1145/3106740,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
147682587,2017,"Scene reconstruction from multiple viewpoints are not always possible and rather it represents a small minority of the potential applications, from robotic manipulators to drones, autonomous vehicles etc... To overcome those limitations, we propose a fully convolutional 3D neural network capable of reconstructing a full scene from a single depth image by creating a 3D representation of it and automatically filling holes and inserting hidden elements. Our algorithm was evaluated on a real word dataset of tabletop scenes acquired using a Kinect and processed using KinectFusion software in order to obtain ground truth for network training and evaluation. Extensive measurements show that our deep neural network architecture outperforms the previous state of the art in terms of both precision and recall for the scene reconstruction task",,'Association for Computing Machinery (ACM)',Scene Reconstruction from a Single Depth Image Using 3D CNN,,10.1145/3155077.3155098,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
288358137,2018-01-01T00:00:00,"Two-dimensional (2D) crystals, for which the shape is described by two linear sizes, are common in fine chemical and pharmaceutical industries. Since the crystal size and shape are directly related to the performance of active pharmaceutical ingredients, the simultaneous size and shape distribution control is of paramount importance in pharmaceutical crystallization engineering. To efficiently achieve simultaneous size and shape control often requires model-based control strategies; however, the increased computational cost of the process simulation and the substantial differences between the simulated and measurable quantities make the implementation of model-based control approaches challenging. This paper addresses the important problem of the real-time simulation of the most likely measurable chord length distribution (CLD) and aspect ratio distribution (ARD) as well as the concentration variations during the crystallization of 2D needle-shaped crystals. This enables the application of focused beam reflectance measurement (FBRM) and particle vision and microscopy (PVM), two routinely applied probes, as quantitative direct feedback control tools. Artificial neural network (ANN)-based FBRM and PVM soft-sensors are developed, which enable the direct and fast transformation of 2D crystal size distribution (CSD) to CLD and ARD on arbitrary 2D grids. The training data for the ANN are generated by a first principle, geometrical model-based simulation of FBRM and PVM for high aspect ratio crystals, although the ANN approach is applicable for any simulated or experimental training data sets. It is also demonstrated that the in situ imaging-based shape measurement underestimates the real aspect ratio (AR) of crystals, for which a simple correction is proposed. From the model-equation solution perspective, the soft-sensors require full population balance solution. The 2D high-resolution finite volume method is applied to simulate the full 2D CSD, which is an accurate, stable, but computationally expensive technique. The real-time applicability is achieved through various implementation improvements including grid optimization and data-type optimized hybrid central processing unit-graphical processing unit calculations",,,Aspect ratio distribution and chord length distribution driven modeling of crystallization of two-dimensional crystals for real-time model-based applications,https://core.ac.uk/download/288358137.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
111082602,2017-12-01T00:00:00,"BACKGROUND AND PURPOSE: Radiotherapy guidance based on magnetic resonance imaging (MRI) is currently becoming a clinical reality. Fast 2d cine MRI sequences are expected to increase the precision of radiation delivery by facilitating tumour delineation during treatment. This study compares four auto-contouring algorithms for the task of delineating the primary tumour in six locally advanced (LA) lung cancer patients. MATERIAL AND METHODS: Twenty-two cine MRI sequences were acquired using either a balanced steady-state free precession or a spoiled gradient echo imaging technique. Contours derived by the auto-contouring algorithms were compared against manual reference contours. A selection of eight image data sets was also used to assess the inter-observer delineation uncertainty. RESULTS: Algorithmically derived contours agreed well with the manual reference contours (median Dice similarity index: ⩾0.91). Multi-template matching and deformable image registration performed significantly better than feature-driven registration and the pulse-coupled neural network (PCNN). Neither MRI sequence nor image orientation was a conclusive predictor for algorithmic performance. Motion significantly degraded the performance of the PCNN. The inter-observer variability was of the same order of magnitude as the algorithmic performance. CONCLUSION: Auto-contouring of tumours on cine MRI is feasible in LA lung cancer patients. Despite large variations in implementation complexity, the different algorithms all have relatively similar performance",,,Tumour auto-contouring on 2d cine MRI for locally advanced lung cancer: A comparative study,https://core.ac.uk/download/111082602.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
379236211,2017-11-01T00:00:00,"Accurately detecting and counting sparse bacterial samples has many applications in the food, beverage, and pharmaceutical processing industries, in medical diagnostics, and for life detection by robotic missions to other planets and moons of the solar system. Currently, sparse bacterial samples are counted by culture plating or epifluorescence microscopy. Culture plates require long incubation times (days to weeks), and epifluorescence microscopy requires extensive staining and concentration of the sample. Here, we demonstrate how to use off-axis digital holographic microscopy (DHM) to enumerate bacteria in very dilute cultures (100-104 cells/mL). First, the construction of the custom DHM is discussed, along with detailed instructions on building a low-cost instrument. The principles of holography are discussed, and a statistical model is used to estimate how long videos should be to detect cells, based on the optical performance characteristics of the instrument and the concentration of the bacterial solution (Table 2). Video detection of cells at 105, 104, 103, and 100 cells/mL is demonstrated in real time using un-reconstructed holograms. Reconstruction of amplitude and phase images is demonstrated using an open-source software package",,'MyJove Corporation',Quantifying Microorganisms at Low Concentrations Using Digital Holographic Microscopy (DHM),,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
217586045,2018-01-01T00:00:00,"Embedded vision is a disruptive new technology in the vision industry. It is a revolutionary concept with far reaching implications, and it is opening up new applications and shaping the future of entire industries. It is applied in self-driving cars, autonomous vehicles in agriculture, digital dermascopes that help specialists make more accurate diagnoses, among many other unique and cutting-edge applications. The design of such systems gives rise to new challenges for embedded Software developers. Embedded vision applications are characterized by stringent performance constraints to guarantee real-time behaviours and, at the same time, energy constraints to save battery on the mobile platforms. In this paper, we address such challenges by proposing an overall view of the problem and by analysing current solutions. We present our last results on embedded vision design automation over two main aspects: the adoption of the model-based paradigm for the embedded vision rapid prototyping, and the application of heterogeneous programming languages to improve the system performance. The paper presents our recent results on the design of a localization and mapping application combined with image recognition based on deep learning optimized for an NVIDIA Jetson TX2",,'Institute of Electrical and Electronics Engineers (IEEE)',Rapid Prototyping of Embedded Vision Systems: Embedding Computer Vision Applications into Low-Power Heterogeneous Architectures,https://core.ac.uk/download/217586045.pdf,10.1109/RSP.2018.8631995,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
199450757,2018-01-01T00:00:00,"Este artigo inclúese no número especial ""Selected Papers from the 1st International Electronic Conference on the Hydrological Cycle (ChyCle-2017)""[Abstract:] This paper presents Iber+, a new parallel code based on the numerical model Iber for two-dimensional (2D) flood inundation modelling. The new implementation, which is coded in C++ and takes advantage of the parallelization functionalities both on CPUs (central processing units) and GPUs (graphics processing units), was validated using different benchmark cases and compared, in terms of numerical output and computational efficiency, with other well-known hydraulic software packages. Depending on the complexity of the specific test case, the new parallel implementation can achieve speedups up to two orders of magnitude when compared with the standard version. The speedup is especially remarkable for the GPU parallelization that uses Nvidia CUDA (compute unified device architecture). The efficiency is as good as the one provided by some of the most popular hydraulic models. We also present the application of Iber+ to model an extreme flash flood that took place in the Spanish Pyrenees in October 2012. The new implementation was used to simulate 24 h of real time in roughly eight minutes of computing time, while the standard version needed more than 15 h. This huge improvement in computational efficiency opens up the possibility of using the code for real-time forecasting of flood events in early-warning systems, in order to help decision making under hazardous events that need a fast intervention to deploy countermeasures.Water JPI—WaterWorks Programme, project Improving
Drought and Flood Early Warning, Forecasting and Mitigation, IMDROFLOOD; PCIN-2015-243European Commission; project RISC_ML 034_RISC_ML_6_EXunta de Galicia; ED431C 2017/64-GRCXunta de Galicia; ED481A-2017/314Xunta de Galicia; ED481B-2018/020European Commission; IMDROFLOOD PCIN-2015-24","[{'title': 'Water', 'identifiers': ['issn:2073-4441', '2073-4441']}]",'MDPI AG',An accelerated tool for flood modelling based on Iber,https://core.ac.uk/download/199450757.pdf,10.3390/w10101459,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286034170,2018-06-30T00:00:00,"The measuring of education quality in school can be conducted by delivering the examination to the students. Composing questions in the examination process to measure students’ achievement in the school teaching and learning process can be difficult and time consuming. To solve this problem, this research proposes Automatic Question Generation (AQG) method to generate Open Domain Indonesian Question by using syntactical approach. Open Domain questions are questions covering many domains of knowledge. The challenge of generating the questions is how to identify the types of declarative sentences that are

potential to be transformed into questions and how to develop the method for generating question

automatically. In realizing the method, this research incorporates four stages, namely: the identification of

declarative sentence for 8 coarse-class and 19 fine-class sentences, the classification of features for coarseclass

sentence and the classification rules for fine-class sentence, the identification of question patterns, and the extraction of sentence’s components as well as the rule generation of questions. The coarse-class classification was carried out based on a machine learning with syntactical features of the sentence, namely:

Part of Speech (POS) Tag, the presence of punctuation, the availability of specific verbs, sequence of words, etc. The fine-class classification was carried out based on a set of rules. According to the implementation and experiment, the findings show that the accuracy of coarse-class classification reaches

83.26% by using the SMO classifier and the accuracy of proposed fine-class classification reaches 92%. The generated questions are categorized into three types, namely: TRUE, UNDERSTANDABLE, and FALSE. The accuracy of generated TRUE and UNDERSTANDABLE questions reaches 88.66%. Thus, the

obtained results show that the proposed method is prospective to implement in the real situation",,Journal of Theoretical and Applied Information Technology,AUTOMATIC QUESTION GENERATION FOR 5W-1H OPEN DOMAIN OF INDONESIAN QUESTIONS BY USING SYNTACTICAL TEMPLATE-BASED FEATURES FROM ACADEMIC TEXTBOOKS,https://core.ac.uk/download/286034170.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
148792611,2018-04-11T00:00:00,"Evolutionary Computation (EC) has been an active research area for over 60 years, yet its commercial/home uptake has not been as prolific as we might have expected. By way of comparison, technologies such as 3D printing, which was introduced about 35 years ago, has seen much wider uptake, to the extent that it is now available to home users and is routinely used in manufacturing. Other technologies, such as immersive reality and artificial intelligence have also seen commercial uptake and acceptance by the general public. In this paper we provide a brief history of EC, recognizing the significant contributions that have been made by its pioneers. We focus on two methodologies (Genetic Programming and Hyper-heuristics), which have been proposed as being suitable for automated software development, and question why they are not used more widely by those outside of the academic community. We suggest that different research strands need to be brought together into one framework before wider uptake is possible. We hope that this position paper will serve as a catalyst for automated software development that is used on a daily basis by both companies and home users",,'Institute of Electrical and Electronics Engineers (IEEE)',Is Evolutionary Computation evolving fast enough?,,10.1109/MCI.2018.2807019,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
235050674,2018-09-24T00:00:00,"A simulated human hand model has been built using a virtual reality program which converts printed letters into a human hand figure that represents American Sign Language (ASL), this program was built using forward and inverse kinematics equations of a human hand. The inputs to the simulation program are normal language letters and the outputs are the human hand figures that represent ASL letters. In this research, a hardware system was designed to recognize the human hand manual alphabet of the ASL utilizing a hardware glove sensor design and using artificial neural network for enhancing the recognition process of ASL and for converting the ASL manual alphabet into printed letters. The hardware system uses flex sensors which are positioned on gloves to obtain the finger joint angle data when shown each letter of ASL. In addition, the system uses DAQ 6212 to interface the sensors and the PC. We trained and tested our hardware system for (ASL) manual alphabet words and names recognition and the recognition results have the accuracy of 90.19% and the software system for converting printed English names and words into (ASL) have 100% accuracy",,"American Academic Scientific Research Journal for Engineering, Technology, and Sciences",ASL Recognition Quality Analysis Based on Sensory Gloves and MLP Neural Network,https://core.ac.uk/download/235050674.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
160077678,2018-06-27T00:00:00,"International audienceWe propose a non-invasive method to detect sleep deprivation by evaluating a short video sequence of a subject. Computer Vision techniques are used to crop the face from every frame and classify it (within a Deep Learning framework) into two classes: "" rested "" or "" sleep deprived "". The system has been trained on a database of subjects recorded under severe sleep deprivation conditions. A prototype has been implemented in a low-cost Android device proving its viability for real-time driver monitoring applications. Tests on real world data have been carried out and show encouraging performances but also reveal the need of larger datasets for training",,HAL CCSD,Sleep Deprivation Detection for Real-Time Driver Monitoring using Deep Learning,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
251212951,2018-01-01T00:00:00,"© 2018 IEEE. The ubiquitous importance of speech recognition for diverse applications in mobile devices, necessitates its low power embedded execution. Often, a Keyword Spotting System (KWS) is used to detect specific wake-up words spoken by a user, as a simple user interface, or front-end layer to a larger speech recognition system. Yet, such KWS must be always active, hence imposing strict power and latency constraints. While deep learning algorithms like Long Short-Term Memory (LSTM) demonstrated excellent KWS accuracies, current implementations fail to fit in the tight embedded memory and power budgets. This paper presents Laika: the implementation of a KWS system using an LSTM accelerator designed in 65nm CMOS. For this application, an LSTM model is trained through a speech database and deployed on our custom, yet highly programmable LSTM accelerator. Approximate computing techniques further reduce power consumption, while maintaining high accuracy and reliability. Experimental results demonstrate a power consumption of less than 5μW for real-time KWS applications.status: publishe","[{'title': None, 'identifiers': ['issn:1930-8833', '1930-8833']}]",'Institute of Electrical and Electronics Engineers (IEEE)',Laika: A 5uW programmable LSTM accelerator for always-on keyword spotting in 65nm CMOS,,10.1109/ESSCIRC.2018.8494342,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226891506,2018-10-19T00:00:00,"Part 7: Social ComputingInternational audienceCurrent virtual reality systems are more immersive than other traditional forms of digital entertainment, but the handheld controllers they use detract from what would otherwise be a truly immersive experience. This paper outlines a project implemented to overcome this issue by creating a spell-casting game in which everything is controlled by the user’s hand gestures. The implemented game made use of optical capture of the user’s hands using a Leap Motion controller attached to the front of a virtual reality headset. The captured gesture data was passed through a neural network for precise gesture classification in real-time, and the correct sequence of classified gestures created a spell effect in the game. The user was able to cast 10 different spells utilizing various combinations of a set of 14 different gestures",,'Springer Science and Business Media LLC',Immersive Virtual Reality Utilizing Hand Gesture Capture as a Replacement for Traditional Controls,,10.1007/978-3-030-00828-4_28,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
301259192,2017-01-01T00:00:00,"La publicació definitiva d'aquest treball està disponible a IOS Press a través de http://dx.doi.org/10.3233/978-1-61499-806-8-196Within the machine learning framework, incremental learning of multivariate spaces is of special interest for on-line applications. In this work, the regression problem for multivariate systems is solved by implementing an efficient probabilistic incremental algorithm. It allows learning high-dimensional redundant non-linear maps by the cumulative acquisition of data from input-output systems. The proposed model is aimed at solving prediction and inference problems. The implementation introduced in this work allows learning from data batches without the need of keeping them in memory afterwards. The learning architecture is built using Incremental Gaussian Mixture Models. The Expectation-Maximization algorithm and general geometric properties of Gaussian distributions are used to train the models. Our current implementation can produce accurate results fitting models in real multivariate systems. Results are shown from testing the algorithm for both situations, one where the incremental learning is demonstrated and the second where the performance to solve the regression problem is evaluated on a toy example.Peer Reviewe",,'IOS Press',Multivariate Regression with Incremental Learning of Gaussian Mixture Models,,10.3233/978-1-61499-806-8-196,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
301274186,2017-01-01T00:00:00,"Road safety applications envisaged for vehicular ad hoc networks (VANETs) depend largely on the exchange of messages to deliver information to concerned vehicles. Safety applications as well as inherent VANET characteristics make data dissemination an essential service and a challenging task. We are developing a decentralized efficient solution for broadcast data dissemination through two game-theoretical mechanisms. Besides, VANETs can also include autonomous vehicles (AVs). AVs might represent a revolutionary new paradigm that can be a reality in our cities in the next few years. AVs do not need a driver to work; instead, they should copy a proper human behavior to adapt the driving according to the current circumstances, such as speed limit, pedestrian crossing street or wheather conditions. We will develop an AV software module including artificial intelligence (AI) techniques so that AVs can interact with the dynamic scenario throughout time. Finally, we also will include electrical vehicles (EV) in the VANET, so that special services such as finding and reserving an EV charging station place will be welcome. In addition, we are developing a multimetric geographic routing protocol for VANETs to transmit H.265 video (traffic accident, traffic state, commercial….) over VANETsPeer Reviewe",,'Universitat Politecnica de Valencia',Multimedia communications in vehicular adhoc networks for several applications in the smart cities,,10.4995/JITEL2017.2017.6584,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
160311734,2018-07-23T00:00:00Z,"Two-dimensional
(2D) crystals, for which the shape is described
by two linear sizes, are common in fine chemical and pharmaceutical
industries. Since the crystal size and shape are directly related
to the performance of active pharmaceutical ingredients, the simultaneous
size and shape distribution control is of paramount importance in
pharmaceutical crystallization engineering. To efficiently achieve
simultaneous size and shape control often requires model-based control
strategies; however, the increased computational cost of the process
simulation and the substantial differences between the simulated and
measurable quantities make the implementation of model-based control
approaches challenging. This paper addresses the important problem
of the real-time simulation of the most likely measurable chord length
distribution (CLD) and aspect ratio distribution (ARD) as well as
the concentration variations during the crystallization of 2D needle-shaped
crystals. This enables the application of focused beam reflectance
measurement (FBRM) and particle vision and microscopy (PVM), two routinely
applied probes, as quantitative direct feedback control tools. Artificial
neural network (ANN)-based FBRM and PVM soft-sensors are developed,
which enable the direct and fast transformation of 2D crystal size
distribution (CSD) to CLD and ARD on arbitrary 2D grids. The training
data for the ANN are generated by a first principle, geometrical model-based
simulation of FBRM and PVM for high aspect ratio crystals, although
the ANN approach is applicable for any simulated or experimental training
data sets. It is also demonstrated that the in situ imaging-based
shape measurement underestimates the real aspect ratio (AR) of crystals,
for which a simple correction is proposed. From the model-equation
solution perspective, the soft-sensors require full population balance
solution. The 2D high-resolution finite volume method is applied to
simulate the full 2D CSD, which is an accurate, stable, but computationally
expensive technique. The real-time applicability is achieved through
various implementation improvements including grid optimization and
data-type optimized hybrid central processing unit–graphical
processing unit calculations",,,"Aspect Ratio Distribution and Chord Length Distribution
Driven Modeling of Crystallization of Two-Dimensional Crystals for
Real-Time Model-Based Applications",,10.1021/acs.cgd.8b00758.s001,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
145159196,2017-01-01T00:00:00,"18 pages, 16 figures, 3 tables, 6 pseudocodes/algorithms, video at https://youtu.be/IqtyHFrb3BUInternational audienceThe high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In this situation, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require the robot and the environment to be reset to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called "" Reset-free Trial-and-Error "" (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention",,'Elsevier BV',Reset-free Trial-and-Error Learning for Robot Damage Recovery,,10.1016/j.robot.2017.11.010,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
322838899,2019-04-01T00:00:00,"Nowadays, we come across games that have unbelievably realistic graphics that it usually becomes hard to distinguish between reality and the virtual world when we are exposed to a virtual reality gaming console. Implementing the concepts of Artificial Intelligence (AI) and Machine-Learning (ML) makes the game self-sustainable and way too intelligent on its own, by making use of self-learning methodologies which can give the user a better gaming experience. The use of AI and ML in games can give a better dimension to the gaming experience in general as the virtual world can behave unpredictably, thus improving the overall stigma of the game. In this paper, we have implemented ‘Connect-4’, a multiplayer game, using ML concepts in Unity3D. The machine learning toolkit ‘ML-Agents’, which depends on Reinforcement Learning (RL) technique, is provided using Unity3D. This toolkit is used for training the game agent which can distinguish its good moves and mistakes while training, so that the agent will not go for same mistakes over and over during actual game with human player. With this paper, authors have increased intelligence of game agent of Connect 4 using Reinforcement Learning, Unity3D and ML-Agents toolkit.</p",,Blue Eyes Intelligence Engineering and Sciences Publication,Implementing artificial intelligence agent within connect 4 using unity3d and machine learning concepts,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
373108474,2018-01-01T00:00:00,"У статті досліджено особливості розвитку цифрового маркетингу в сучасних умовах. Розглянуто специфіку запровадження інноваційних цифрових технологій у маркетингові діяльності. Визначено специфіку розвитку віртуальної реальності та особливості її використання у системі цифрового маркетингу. У науковому дослідженні представлено приклади передового використання технологій віртуальної реальності компаніями світу при реалізації їх маркетингових стратегій. Висвітлено специфіку застосування технології віртуальної реальності за умови витрат значних фінансових ресурсів. Також наведено приклад використання дешевих аналогів цифрових технологій за умови використання смартфонів. Висвітлено специфіку залучення клієнтів до дешевих цифрової технологій та особливості збільшення інтересу цільової аудиторії. Отримані результати дають можливість визначити основні тенденції розвитку цифрового маркетингу з застосуванням технологій віртуальної реальності. У дослідженні значну увагу приділено питанням реалізації технологій використання LED панелей. Обґрунтовано доцільність використання зазначеної технології для indoor маркетингу – виду діяльності всередині приміщень (торговельних закладів, кафе, офісів компаній тощо) та outdoor маркетингу – виду діяльності у зовнішньому просторі (на улицях, парках та ін.). Наведено приклади застосування LED панелей передовими компаніями світу. Висвітлено специфіку застосування даної технології у сфері харчування. Встановлено, що LED панелі відіграють важливу роль у цифровій маркетинговій стратегії кафе та ресторанів. Визначено, що цифрові панелі сприяють зростанню кількості клієнтів. Доведено, що запровадження систем штучного інтелекту у подальшому сприятиме збільшенню інтерактивності та персоніфікації контенту у відповідності з умовами, які будуть проявлятись у певний момент часу в конкретному місці. Встановлено, що зазначений підхід дозволить національним компаніям підвищити рівень їх конкурентоспроможності на національному та міжнародному ринках. Доведено необхідність запровадження державної програми сприяння розвитку цифрового маркетингу в Україні.In the article the features of development of digital marketing in modern conditions are investigated. The specifics of introduction of innovative technologies in marketing strategies of companies are considered. The specificity of the development of virtual reality and the peculiarities of its using in the digital marketing system are determined. In the scientific research, examples of the advanced use of technologies of virtual reality by companies of the world in the implementation of their marketing strategies are presented. The specificity of the application of the virtual reality technology is highlighted with the cost of significant financial resources. The example is the using of cheap analogues of digital technology such as using smartphones. The specifics of attraction the clients to cheap digital technologies and interest increase features of the target audience are highlighted. The obtained results give an opportunity to define the basic tendencies of digital marketing development with application of virtual reality technologies. The study focuses on the implementation of technology for the use of LED panels. The expediency of using this technology for indoor marketing is grounded - the type of activity in the middle of the premises (shopping centers, cafes, offices of companies, etc.) and outdoor marketing - the type of activity in the outer space (in streets, parks, etc.). One example of the using of LED panels is presented by leading companies of the world. The application specifics of this technology in the field of food are highlighted. It has been established that LED panels play the important role in the digital marketing strategy of cafes and restaurants. It is determined that digital panels help to increase the number of clients. It is proved that the introduction of artificial intelligence systems will further enhance the interactivity and personalization of content in accordance with conditions that will manifest at a certain point in time in a special place. It has been established that this approach will allow national companies to increase their competitiveness in the national and international markets. The necessity of implementation of the state program of digital marketing promotion in Ukraine has been proved","[{'title': 'Економічний вісник Національного технічного університету України «Київський політехнічний інститут»', 'identifiers': ['2307-5651', 'issn:2412-5296', '2412-5296', 'issn:2307-5651']}]",,Practical aspects of innovative digital technologies application in marketing,https://core.ac.uk/download/373108474.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
344908498,2019-01-01T00:00:00,"Abstract

The use of flying platforms such as unmanned aerial vehicles (UAVs), popularly known as drones, is rapidly growing. In particular, with their inherent attributes such as mobility, flexibility, and adaptive altitude, UAVs admit several key potential applications in wireless systems. On the one hand, UAVs can be used as aerial base stations to enhance coverage, capacity, reliability, and energy efficiency of wireless networks. On the other hand, UAVs can operate as flying mobile terminals within a cellular network. Such cellular-connected UAVs can enable several applications ranging from real-time video streaming to item delivery. In this paper, a comprehensive tutorial on the potential benefits and applications of UAVs in wireless communications is presented. Moreover, the important challenges and the fundamental tradeoffs in UAV-enabled wireless networks are thoroughly investigated. In particular, the key UAV challenges such as 3D deployment, performance analysis, channel modeling, and energy efficiency are explored along with representative results. Then, open problems and potential research directions pertaining to UAV communications are introduced. Finally, various analytical frameworks and mathematical tools, such as optimization theory, machine learning, stochastic geometry, transport theory, and game theory are described. The use of such tools for addressing unique UAV problems is also presented. In a nutshell, this tutorial provides key guidelines on how to analyze, optimize, and design UAV-based wireless communication systems",,'Institute of Electrical and Electronics Engineers (IEEE)',"A tutorial on UAVs for wireless networks:applications, challenges, and open problems",,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
482259928,2018-01-01T00:00:00,"This paper presents the R package EMMIXcskew for the fitting of the canonical fundamental skew t-distribution (CFUST) and finite mixtures of CFUST distributions (FMCFUST) via maximum likelihood (ML). The CFUST distribution provides a flexible family to model non-normal data, with parameters for capturing skewness and heavy-tails in the data. It formally encompasses the normal, t, and skew normal distributions as special and/or limiting cases. A few other versions of the skew t-distributions are also nested within the CFUST distribution. In this paper, an expectation-maximization (EM) algorithm is described for computing the ML estimates of the parameters of the FM-CFUST model, and different strategies for initializing the algorithm are discussed and illustrated. The methodology is implemented in the EMMIXcskew package, and examples are presented using two real datasets. The EMMIXcskew package contains functions to fit the FM-CFUST model, including procedures for generating different initial values. Additional features include random sample generation and contour visualization in 2D and 3D.Sharon X. Lee, Geoffrey J. McLachla","[{'title': 'Journal of Statistical Software', 'identifiers': ['1548-7660', 'issn:1548-7660']}]",'Foundation for Open Access Statistic',EMMIXcskew: an R package for the fitting of a mixture of canonical fundamental skew t-distributions,https://core.ac.uk/download/482259928.pdf,10.18637/jss.v083.i03,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
390007811,2019-06-24T00:00:00,"The subject of the study is the methods and tools for automation of recognition of road signs at the level of software implementation. Detection of road signs is associated with the processing of a significant amount of video data in real time, which requires significant computing power. Therefore, the purpose of the work is to automate the process of recognition of road signs for filling the databases of navigators, which will allow operatively provide drivers with up-to-date information on established road signs. The following tasks are solved: analysis of methods and software for image recognition; development of the search algorithm for characters in the video frame; implementation of the definition of the contour of the sign; realization of a convolutional neural network for recognition of a sign; testing of applied information technology work. Methods are used: convolutional neural networks;  Viola-Jones's method for recognizing objects in an image, the Bousting method as a way to accelerate the recognition process with a large amount of information. Results: Different approaches to the identification of symbols on images, various software tools for object recognition, image transformation for optimal fragment are considered. An algorithm for detecting and recognizing the sign is developed. Using the Viola-Jones method, a fast way to calculate the values of attributes using the integral representation of an image is implemented. The recognition process takes place by constructing a convolutional neural network. Features of the layers of the roller network are considered.  Schematically illustrated script recognition. The process of interaction of the system with different data sources is represented by a diagram of precedents. The main result is the creation of information technology for the automated recognition of road signs. The algorithm of its work is presented in the form of a sequence diagram. Conclusions. Using the applied application information technology, recognition of road signs is made with an average probability of 88%, which allows automating the process of filling the database of navigators to a large extent, to increase the reliability and productivity of the given process.Предметом исследования являются методы и инструментальные средства автоматизации распознавания дорожных знаков на уровне программной реализации. Детектирования дорожных знаков связано с обработкой большого объема видеоданных в реальном времени, что требует значительных вычислительных мощностей. Поэтому целью работы является автоматизация процесса распознавания дорожных знаков для наполнения баз данных навигаторов, что позволит оперативно предоставлять водителям актуальную информацию об установленных дорожных знаках. Решаются следующие задачи: анализ методов и программных средств распознавания изображений; разработка алгоритма поиска знаков в кадре видео; реализация определения контура знака; реализация сгруппированной нейронной сети для распознавания знака; тестирование работы прикладной информационной технологии. Применяются методы: сгруппированные нейронные сети; метод Виолы-Джонса для распознавания объектов на изображении, метод Бустинга как способ ускорения процесса распознавания при большом объеме информации. Результаты: рассмотрены различные подходы к выявлению знаков на изображениях, различные программные средства распознавания объектов, преобразования изображений для получения оптимального фрагмента. Разработан алгоритм обнаружения и распознавания знака. С применением метода Виола-Джонса реализовано быстрый способ вычисления значений признаков, который использует интегральное представление изображения. Процесс распознавания происходит путем построения сгруппированной нейронной сети. Рассмотрены особенности слоев сгруппированной сети. Схематично проиллюстрировано сценарий распознавания. Процесс взаимодействия системы с различными источниками данных представлен с помощью диаграммы прецедентов. Основным результатом является создание информационной технологии автоматизированного распознавания дорожных знаков. Алгоритм ее работы представлен в виде диаграммы последовательности. Выводы. С применением созданной прикладной информационной технологии распознавания дорожных знаков производится со средней вероятностью 88%, что позволяет в значительной степени автоматизировать процесс наполнения базы данных навигаторов, повысить надежность и производительность указанного процесса.Предметом дослідження є методи та інструментальні засоби автоматизації розпізнання дорожніх знаків на рівні програмної реалізації. Детектування дорожніх знаків пов’язане з обробкою значного обсягу відеоданих в реальному часі, що потребує значних обчислювальних потужностей. Тому метою роботи є автоматизація процесу розпізнання дорожніх знаків для наповнення баз даних навігаторів, що дозволить оперативно надавати водіям актуальну інформацію щодо встановлених дорожніх знаків. Вирішуються наступні завдання: аналіз методів та програмних засобів розпізнання зображень; розробка алгоритму пошуку знаків на кадрі відео; реалізація визначення контуру знаку; реалізація згорткової нейронної мережі для розпізнання знаку; тестування роботи прикладної інформаційної технології. Застосовуються методи: згорткові нейронні мережі; метод Віоли-Джонса для розпізнання об’єктів на зображенні, метод Бустінгу як спосіб прискорення процесу розпізнання при великому об’ємі інформації. Результати: розглянуті різні підходи до виявлення знаків на зображеннях, різноманітні програмні засоби розпізнання об’єктів, перетворення зображень для отримання оптимального фрагменту. Розроблено алгоритм виявлення та розпізнання знаку. Із застосуванням методу Віола-Джонса реалізовано швидкий спосіб обчислення значень ознак, який використовує інтегральне представлення зображення. Процес розпізнавання відбувається шляхом побудови згорткової нейронні мережі. Розглянуто особливості шарів згорткової мережі. Схематично проілюстровано сценарій розпізнання. Процес взаємодії системи з різними джерелами даних представлений за допомогою діаграми прецедентів. Основним результатом є створення інформаційної технології автоматизованого розпізнання дорожніх знаків. Алгоритм її роботи представлено у вигляді діаграми послідовності. Висновки. Із застосуванням створеної прикладної інформаційної технології розпізнання дорожніх знаків робиться з середньою вірогідністю 88%, що дозволяє значною мірою автоматизувати процес наповнення бази даних навігаторів, підвищити надійність та продуктивність вказаного процесу",,"ХНУРЭ и ГП ""ЮЖГИПРОНИИАВИАПРОМ""",ІНФОРМАЦІЙНА ТЕХНОЛОГІЯ РОЗПІЗНАННЯ ДОРОЖНІХ ЗНАКІВ З ВИКОРИСТАННЯМ НЕЙРОННОЇ МЕРЕЖІ,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287484449,2019-01-01T00:00:00,"International audienceWhile modern CFD tools are able to provide the user with reliable and accurate simulations, there is a strong need for interactive design and analysis tools. State-of-the-art CFD software employs massive resources in terms of CPU time, user interaction, and also GPU time for rendering and analysis. In this work, we develop an innovative tool able to provide a seamless bridge between artistic design and engineering analysis. This platform has three main ingredients: computer vision to avoid long user interaction at the pre-processing stage, machine learning to avoid costly CFD simulations, and augmented reality for an agile and interactive post-processing of the results",,'Wiley',An augmented reality platform for interactive aerodynamic design and analysis,https://core.ac.uk/download/287484449.pdf,10.1002/nme.6127,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
212253632,2018-01-01T00:00:00,"Running has a positive impact on human health and is an accessible sport for most people. There is high demand for tracking running performance and progress for amateurs and professionals alike. The parameters velocity and distance are thereby of main interest. In this work, we evaluate the accuracy of four algorithms, which calculate the stride velocity and stride length during running using data of an inertial measurement unit (IMU) placed in the midsole of a running shoe. The four algorithms are based on stride time, foot acceleration, foot trajectory estimation, and deep learning, respectively. They are compared using two studies: a laboratory-based study comprising 2377 strides from 27 subjects with 3D motion tracking as a reference and a field study comprising 12 subjects performing a 3.2-km run in a real-world setup. The results show that the foot trajectory estimation algorithm performs best, achieving a mean error of 0.032 ± 0.274 m/s for the velocity estimation and 0.022 ± 0.157 m for the stride length. An interesting alternative for systems with a low energy budget is the acceleration-based approach. Our results support the implementation decision for running velocity and distance tracking using IMUs embedded in the sole of a running shoe",,'MDPI AG',Comparison of Different Algorithms for Calculating Velocity and Stride Length in Running Using Inertial Measurement Units,,10.3390/s18124194,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
216279954,2017-11-01T00:00:00,"Accurately detecting and counting sparse bacterial samples has many applications in the food, beverage, and pharmaceutical processing industries, in medical diagnostics, and for life detection by robotic missions to other planets and moons of the solar system. Currently, sparse bacterial samples are counted by culture plating or epifluorescence microscopy. Culture plates require long incubation times (days to weeks), and epifluorescence microscopy requires extensive staining and concentration of the sample. Here, we demonstrate how to use off-axis digital holographic microscopy (DHM) to enumerate bacteria in very dilute cultures (100-104 cells/mL). First, the construction of the custom DHM is discussed, along with detailed instructions on building a low-cost instrument. The principles of holography are discussed, and a statistical model is used to estimate how long videos should be to detect cells, based on the optical performance characteristics of the instrument and the concentration of the bacterial solution (Table 2). Video detection of cells at 105, 104, 103, and 100 cells/mL is demonstrated in real time using un-reconstructed holograms. Reconstruction of amplitude and phase images is demonstrated using an open-source software package",,'MyJove Corporation',Quantifying Microorganisms at Low Concentrations Using Digital Holographic Microscopy (DHM),,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
147682594,2017,"In this work, we propose a 3D scene reconstruction algorithm based on a fully convolutional 3D denoising autoencoder neural network. The network is capable of reconstructing a full scene from a single depth image by creating a 3D representation of it and automatically filling holes and inserting hidden elements. We exploit the fact that our neural network is capable of generalizing object shapes by inferring similarities in geometry. Our fully convolutional architecture enables the network to be unconstrained by a fixed 3D shape, and so it is capable of successfully reconstructing arbitrary scene sizes. Our algorithm was evaluated on a real word dataset of tabletop scenes acquired using a Kinect and processed using KinectFusion software in order to obtain ground truth for network training and evaluation. Extensive measurements show that our deep neural network architecture outperforms the previous state of the art both in terms of precision and recall for the scene reconstruction task. The network has been broadly profiled in terms of memory footprint, number of floating point operations, inference time and power consumption in CPU, GPU and embedded devices. Its small memory footprint and its low computation requirements enable low power, memory constrained, real time always-on embedded applications such as autonomous vehicles, warehouse robots, interactive gaming controllers and drones",,'Institute of Electrical and Electronics Engineers (IEEE)',Fully convolutional denoising autoencoder for 3D scene reconstruction from a single depth image,,10.1109/ICSAI.2017.8248355,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
187742851,2018-01-01T00:00:00,"A key requirement of autonomous vehicles is the capability to safely navigate in their environment. However, outside of controlled environments, safe navigation is a very difficult problem. In particular, the real-world often contains both complex 3D structure, and dynamic obstacles such as people or other vehicles. Dynamic obstacles are particularly challenging, as a principled solution requires planning trajectories with regard to both vehicle dynamics, and the motion of the obstacles. Additionally, the real-time requirements imposed by obstacle motion, coupled with real-world computational limitations, make classical optimality and completeness guarantees difficult to satisfy. We present a unified optimization-based motion planning and control solution, that can navigate in the presence of both static and dynamic obstacles. By combining optimal and receding-horizon control, with temporal multi-resolution lattices, we can precompute optimal motion primitives, and allow real-time planning of physically-feasible trajectories in complex environments with dynamic obstacles. We demonstrate the framework by solving difficult indoor 3D quadcopter navigation scenarios, where it is necessary to plan in time. Including waiting on, and taking detours around, the motions of other people and quadcopters.This work was partially supported by FFI/VINNOVA, the Wallenberg Artificial Intelligence, Autonomous Systems and Software Program (WASP) funded by Knut and Alice Wallenberg Foundation, the Swedish Foundation for Strategic Research (SSF) project Symbicloud, the ELLIIT Excellence Center at Linköping-Lund for Information Technology, Swedish Research Council (VR) Linnaeus Center CADICS, and the National Graduate School in Computer Science, Sweden (CUGS).</p",,'Institute of Electrical and Electronics Engineers (IEEE)',Receding-Horizon Lattice-based Motion Planning with Dynamic Obstacle Avoidance,,10.1109/CDC.2018.8618964,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323317411,2019-12-12T00:00:00,"[EN] Over the last few years, several researchers have been developing protocols and applications in order to autonomously land unmanned aerial vehicles (UAVs). However, most of the proposed protocols rely on expensive equipment or do not satisfy the high precision needs of some UAV applications such as package retrieval and delivery or the compact landing of UAV swarms. Therefore, in this work, a solution for high precision landing based on the use of ArUco markers is presented. In the proposed solution, a UAV equipped with a low-cost camera is able to detect ArUco markers sized 56×56 cm from an altitude of up to 30 m. Once the marker is detected, the UAV changes its flight behavior in order to land on the exact position where the marker is located. The proposal was evaluated and validated using both the ArduSim simulation platform and real UAV flights. The results show an average offset of only 11 cm from the target position, which vastly improves the landing accuracy compared to the traditional GPS-based landing, which typically deviates from the intended target by 1 to 3 m.This work was funded by the  Ministerio de Ciencia, Innovación y Universidades, Programa Estatal de Investigación, Desarrollo e Innovación Orientada a los Retos de la Sociedad, Proyectos I+D+I 2018 , Spain, under Grant RTI2018-096384-B-I00.Wubben, J.; Fabra Collado, FJ.; Tavares De Araujo Cesariny Calafate, CM.; Krzeszowski, T.; Márquez Barja, JM.; Cano, J.; Manzoni, P. (2019). Accurate Landing of Unmanned Aerial Vehicles Using Ground Pattern Recognition. Electronics. 8(12):1-16. https://doi.org/10.3390/electronics8121532S116812Pan, X., Ma, D., Jin, L., & Jiang, Z. (2008). Vision-Based Approach Angle and Height Estimation for UAV Landing. 2008 Congress on Image and Signal Processing. doi:10.1109/cisp.2008.78Tang, D., Li, F., Shen, N., & Guo, S. (2011). UAV attitude and position estimation for vision-based landing. Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology. doi:10.1109/emeit.2011.6023131Gautam, A., Sujit, P. B., & Saripalli, S. (2014). A survey of autonomous landing techniques for UAVs. 2014 International Conference on Unmanned Aircraft Systems (ICUAS). doi:10.1109/icuas.2014.6842377Holybro Pixhawk 4 · PX4 v1.9.0 User Guidehttps://docs.px4.io/v1.9.0/en/flight_controller/pixhawk4.htmlGarrido-Jurado, S., Muñoz-Salinas, R., Madrid-Cuevas, F. J., & Medina-Carnicer, R. (2016). Generation of fiducial marker dictionaries using Mixed Integer Linear Programming. Pattern Recognition, 51, 481-491. doi:10.1016/j.patcog.2015.09.023Romero-Ramirez, F. J., Muñoz-Salinas, R., & Medina-Carnicer, R. (2018). Speeded up detection of squared fiducial markers. Image and Vision Computing, 76, 38-47. doi:10.1016/j.imavis.2018.05.004ArUco: Augmented reality library based on OpenCVhttps://sourceforge.net/projects/aruco/Jin, S., Zhang, J., Shen, L., & Li, T. (2016). On-board vision autonomous landing techniques for quadrotor: A survey. 2016 35th Chinese Control Conference (CCC). doi:10.1109/chicc.2016.7554984Chen, X., Phang, S. K., Shan, M., & Chen, B. M. (2016). System integration of a vision-guided UAV for autonomous landing on moving platform. 2016 12th IEEE International Conference on Control and Automation (ICCA). doi:10.1109/icca.2016.7505370Nowak, E., Gupta, K., & Najjaran, H. (2017). Development of a Plug-and-Play Infrared Landing System for Multirotor Unmanned Aerial Vehicles. 2017 14th Conference on Computer and Robot Vision (CRV). doi:10.1109/crv.2017.23Shaker, M., Smith, M. N. R., Yue, S., & Duckett, T. (2010). Vision-Based Landing of a Simulated Unmanned Aerial Vehicle with Fast Reinforcement Learning. 2010 International Conference on Emerging Security Technologies. doi:10.1109/est.2010.14Araar, O., Aouf, N., & Vitanov, I. (2016). Vision Based Autonomous Landing of Multirotor UAV on Moving Platform. Journal of Intelligent & Robotic Systems, 85(2), 369-384. doi:10.1007/s10846-016-0399-zPatruno, C., Nitti, M., Petitti, A., Stella, E., & D’Orazio, T. (2018). A Vision-Based Approach for Unmanned Aerial Vehicle Landing. Journal of Intelligent & Robotic Systems, 95(2), 645-664. doi:10.1007/s10846-018-0933-2Baca, T., Stepan, P., Spurny, V., Hert, D., Penicka, R., Saska, M., … Kumar, V. (2019). Autonomous landing on a moving vehicle with an unmanned aerial vehicle. Journal of Field Robotics, 36(5), 874-891. doi:10.1002/rob.21858De Souza, J. P. C., Marcato, A. L. M., de Aguiar, E. P., Jucá, M. A., & Teixeira, A. M. (2019). Autonomous Landing of UAV Based on Artificial Neural Network Supervised by Fuzzy Logic. Journal of Control, Automation and Electrical Systems, 30(4), 522-531. doi:10.1007/s40313-019-00465-ySITL Simulator (Software in the Loop)http://ardupilot.org/dev/docs/sitl-simulator-software-in-the-loop.htmlFabra, F., Calafate, C. T., Cano, J.-C., & Manzoni, P. (2017). On the impact of inter-UAV communications interference in the 2.4 GHz band. 2017 13th International Wireless Communications and Mobile Computing Conference (IWCMC). doi:10.1109/iwcmc.2017.7986413MAVLink Micro Air Vehicle Communication Protocolhttp://qgroundcontrol.org/mavlink/startFabra, F., Calafate, C. T., Cano, J. C., & Manzoni, P. (2018). ArduSim: Accurate and real-time multicopter simulation. Simulation Modelling Practice and Theory, 87, 170-190. doi:10.1016/j.simpat.2018.06.009Careem, M. A. A., Gomez, J., Saha, D., & Dutta, A. (2019). HiPER-V: A High Precision Radio Frequency Vehicle for Aerial Measurements. 2019 16th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON). doi:10.1109/sahcn.2019.882490",,'MDPI AG',Accurate Landing of Unmanned Aerial Vehicles Using Ground Pattern Recognition,https://riunet.upv.es/bitstream/10251/144317/1/Wubben%3bFABRA%3bTavares%20-%20Accurate%20Landing%20of%20Unmanned%20Aerial%20Vehicles%20Using%20Ground%20Pattern%20Recognit....pdf,10.3390/electronics8121532,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
395142912,2019-11-01T00:00:00,"[EN] Falls represent a major public health risk worldwide for the elderly people. A fall not assisted in time can cause functional impairment in an elderly and a significant decrease in his mobility, independence, and life quality. In this sense, we propose IoTE-Fall system, an intelligent system for detecting falls of elderly people in indoor environments that takes advantages of the Internet of Thing and the ensemble machine learning algorithm. IoTE-Fall system employs a 3D-axis accelerometer embedded into a 6LowPAN wearable device capable of capturing in real time the data of the movements of elderly volunteers. To provide high efficiency in fall detection, in this paper, four machine learning algorithms (classifiers): decision trees, ensemble, logistic regression, and Deepnets are evaluated in terms of AUC ROC, training time and testing time. The acceleration readings are processed and analyzed at the edge of the network using an ensemble-based predictor model that is identified as the most suitable predictor for fall detection. The experiment results from collection data, interoperability services, data processing, data analysis, alert emergency service, and cloud services show that our system achieves accuracy, precision, sensitivity, and specificity above 94%.Research presented in this article has been partially funded by Horizon 2020 European Project grant INTER-IoT no. 687283, ACTIVAGE project under grant agreement no. 732679, the Escuela Politecnica Nacional, Ecuador, and Secretaria de Educacion Superior Ciencia, Tecnologia e Innovacion (SENESCYT), Ecuador.Yacchirema, D.; Suárez De Puga, J.; Palau Salvador, CE.; Esteve Domingo, M. (2019). Fall detection system for elderly people using IoT and ensemble machine learning algorithm. Personal and Ubiquitous Computing. 23(5-6):801-817. https://doi.org/10.1007/s00779-018-01196-8S801817235-6He W, Goodkind D, Kowal P (2016) U.S. Census Bureau, International Population Reports, P95/16-1, An Aging World: 2015. U.S. Government Publishing Office, Washington, DCBousquet J, Kuh D, Bewick M, Standberg T, Farrell J, Pengelly R, Joel ME, Rodriguez Mañas L, Mercier J, Bringer J, Camuzat T, Bourret R, Bedbrook A, Kowalski ML, Samolinski B, Bonini S, Brayne C, Michel JP, Venne J, Viriot-Durandal P, Alonso J, Avignon A, Ben-Shlomo Y, Bousquet PJ, Combe B, Cooper R, Hardy R, Iaccarino G, Keil T, Kesse-Guyot E, Momas I, Ritchie K, Robine JM, Thijs C, Tischer C, Vellas B, Zaidi A, Alonso F, Andersen Ranberg K, Andreeva V, Ankri J, Arnavielhe S, Arshad H, Augé P, Berr C, Bertone P, Blain H, Blasimme A, Buijs GJ, Caimmi D, Carriazo A, Cesario A, Coletta J, Cosco T, Criton M, Cuisinier F, Demoly P, Fernandez-Nocelo S, Fougère B, Garcia-Aymerich J, Goldberg M, Guldemond N, Gutter Z, Harman D, Hendry A, Heve D, Illario M, Jeande C, Krauss-Etschmann S, Krys O, Kula D, Laune D, Lehmann S, Maier D, Malva J, Matignon P, Melen E, Mercier G, Moda G, Nizinkska A, Nogues M, O’Neill M, Pelissier JY, Poethig D, Porta D, Postma D, Puisieux F, Richards M, Robalo-Cordeiro C, Romano V, Roubille F, Schulz H, Scott A, Senesse P, Slagter S, Smit HA, Somekh D, Stafford M, Suanzes J, Todo-Bom A, Touchon J, Traver-Salcedo V, van Beurden M, Varraso R, Vergara I, Villalba-Mora E, Wilson N, Wouters E, Zins M (2015) Operational definition of active and healthy ageing (AHA): a conceptual framework. J Nutr Health Aging 19(9):955–960Yacchirema DC, Sarabia-Jácome D, Palau CE, Esteve M (2018) A Smart System for sleep monitoring by integrating IoT with big data analytics. IEEE Access, p 1Robie K (2010) Falls in older people: risk factors and strategies for prevention. JAMA 304(17):1958–1959Jrad RBN, Ahmed MD, Sundaram D (2014) Insider Action Design Research a multi-methodological Information Systems research approach. 2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS). Marrakech, pp 1–12. https://doi.org/10.1109/RCIS.2014.6861053Chaccour K, Darazi R, El Hassani AH, Andrès E (2017) From fall detection to fall prevention: a generic classification of fall-related systems. IEEE Sensors J 17(3):812–822Min W, Cui H, Rao H, Li Z, Yao L (2018) Detection of human falls on furniture using scene analysis based on deep learning and activity characteristics. IEEE Access 6:9324–9335Ma X, Wang H, Xue B, Zhou M, Ji B, Li Y (2014) Depth-based human fall detection via shape features and improved extreme learning machine. IEEE J Biomed Heal Inform 18(6):1915–1922Yang L, Ren Y, Zhang W (2016) 3D depth image analysis for indoor fall detection of elderly people. Digit Commun Netw 2(1):24–34Mastorakis G, Makris D (2014) Fall detection system using Kinect’s infrared sensor. J Real-Time Image Process 9(4):635–646Kwolek B, Kepski M (2014) Human fall detection on embedded platform using depth maps and wireless accelerometer. Comput Methods Prog Biomed 117(3):489–501Wang Y, Wu K, Ni LM (2017) WiFall: device-free fall detection by wireless networks. IEEE Trans Mob Comput 16(2):581–594Sehairi K, Chouireb F, Meunier J (2018) Elderly fall detection system based on multiple shape features and motion analysis. 2018 International Conference on Intelligent Systems and Computer Vision (ISCV). Fez, pp 1–8. https://doi.org/10.1109/ISACV.2018.8354084Álvarez de la Concepción MÁ, Soria Morillo LM, Álvarez García JA, González-Abril L (2017) Mobile activity recognition and fall detection system for elderly people using Ameva algorithm. Pervasive Mob Comput 34:3–13Fortino G, Gravina R (2015) Fall-MobileGuard: a smart real-time fall detection system. In: Proceedings of the 10th EAI International Conference on Body Area Networks (BodyNets '15). ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering). ICST, Brussels, Belgium, pp 44–50. https://doi.org/10.4108/eai.28-9-2015.2261462Aguiar B, Rocha T, Silva J, Sousa I (2014) Accelerometer-based fall detection for smartphones. 2014 IEEE International Symposium on Medical Measurements and Applications (MeMeA). Lisboa, pp 1–6. https://doi.org/10.1109/MeMeA.2014.6860110Kau L, Chen C (2015) A smart phone-based pocket fall accident detection, positioning, and rescue system. IEEE J Biomed Heal Inform 19(1):44–56He J, Bai S, Wang X (2017) An Unobtrusive Fall Detection and Alerting System Based on Kalman Filter and Bayes Network Classifier. Sensors 17:1393. https://doi.org/10.3390/s17061393Santoyo-Ramón JA, Casilari E, Cano-García JM (2018) Analysis of a Smartphone-Based Architecture with Multiple Mobility Sensors for Fall Detection with Supervised Learning. Sensors 18:1155. https://doi.org/10.3390/s18041155Mao A, Ma X, He Y, Luo J (2017) Highly Portable, Sensor-Based System for Human Fall Monitoring. Sensors 17:2096. https://doi.org/10.3390/s17092096Casilari E, Oviedo-Jiménez MA (2015) Automatic fall detection system based on the combined use of a smartphone and a smartwatch. PLoS One 10(11):e0140929Dias PVGF, Costa EDM, Tcheou MP, Lovisolo L (2016) Fall detection monitoring system with position detection for elderly at indoor environments under supervision. 2016 8th IEEE Latin-American Conference on Communications (LATINCOM). Medellin, pp. 1–6. https://doi.org/10.1109/LATINCOM.2016.7811576Phu PT, Hai NT, Tam NT (2015) A Threshold Algorithm in a Fall Alert System for Elderly People. In: Toi V, Lien Phuong T (eds) 5th International Conference on Biomedical Engineering in Vietnam. IFMBE Proceedings, vol 46. Springer, Cham. https://doi.org/10.1007/978-3-319-11776-8_85 . ISBN:978-3-319-11775-1Santiago J, Cotto E, Jaimes LG, Vergara-Laurens, I (2017) Fall detection system for the elderly. 2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC). Las Vegas, NV, pp 1–4. https://doi.org/10.1109/CCWC.2017.7868363Malheiros L, Nze GDA, Cardoso LX (2017) Fall detection system and body positioning with heart rate monitoring. IEEE Lat Am Trans 15(6):1021–1026Ethem Alpaydin (2010) Introduction to Machine Learning, 2nd edn. The MIT PressMezghani N, Ouakrim Y, Islam MR, Yared R, Abdulrazak B (2017) Context aware adaptable approach for fall detection bases on smart textile. 2017 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI). Orlando, FL, pp 473–476. https://doi.org/10.1109/BHI.2017.7897308Pierleoni P, Belli A, Palma L, Pellegrini M, Pernini L, Valenti S (2015) A high reliability wearable device for elderly fall detection. IEEE Sensors J 15(8):4544–4553Aziz O, Musngi M, Park EJ, Mori G, Robinovitch SN (2017) A comparison of accuracy of fall detection algorithms (threshold-based vs. machine learning) using waist-mounted tri-axial accelerometer signals from a comprehensive set of falls and non-fall trials. Med Biol Eng Comput 55(1):45–55Nguyen LP, Saleh M, Le Bouquin Jeannès R (2018) An Efficient Design of a Machine Learning-Based Elderly Fall Detector. In: Ahmed M, Begum S, Fasquel JB (eds) Internet of Things (IoT) Technologies for HealthCare. HealthyIoT 2017. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering, vol 225. Springer, ChamÖzdemir TA, Barshan B (2014) Detecting falls with wearable sensors using machine learning techniques. Sensors 14(6):10691–10708Tong L, Song Q, Ge Y, Liu M (2013) HMM-based human fall detection and prediction method using tri-axial accelerometer. IEEE Sensors J 13(5):1849–1856SISTEMIC: Research group on Embedded Systems and Computational Intelligence of the Electronics and Telecommunications Department at the Faculty of Engineering, University of Antioquia, “SisFall Dataset.” Online. Available: http://sistemic.udea.edu.co/investigacion/proyectos/english-falls/?lang=en . Accessed 2 Feb 2018Rubenstein L (2006) Falls in older people: epidemiology. Risk Factors and Strategies for Prev 35(Suppl 2):ii37–ii41Youn J, Okuma Y, Hwang M, Kim D, Cho JW (2017) Falling direction can predict the mechanism of recurrent falls in advanced Parkinson’s disease. Sci Rep 7(1):3921Nevitt S, Cummings MC (2018) Type of fall and risk of hip and wrist fractures: The study of osteoporotic fractures. J Am Geriatr Soc 41(11):1226–1234Karantonis DM, Narayanan MR, Mathie M, Lovell NH, Celler BG (2006) Implementation of a real-time human movement classifier using a triaxial accelerometer for ambulatory monitoring. IEEE Trans Inf Technol Biomed 10(1):156–167Khan AM, Lee YK, Kim TS (2008) Accelerometer signal-based human activity recognition using augmented autoregressive model coefficients and artificial neural nets in 2008 30th Annual International. Conf Proc IEEE Eng Med Biol Soc 2008:5172–5175Yoshida T, Mizuno F, Hayasaka T, Tsubota K, Wada S, Yamaguchi T (2005) A wearable computer system for a detection and prevention of elderly users from falling. In: Proceedings of the 12th international conference on biomedical engineering. Singapore, pp 179–182Kangas M, Konttila A, Winblad I, Jamsa T (2007) Determination of simple thresholds for accelerometry based parameters for fall detection. In: 2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. Lyon (France), pp 1367–1370. https://doi.org/10.1109/IEMBS.2007.4352552 . E- ISSN: 1558-4615Shan S, Yuan T (2010) A wearable pre-impact fall detector using feature selection and Support Vector Machine. In: IEEE 10th International Conference on Signal Processing Proceedings. Beijin (China), pp 1686–1689. https://doi.org/10.1109/ICOSP.2010.5656840 . E- ISSN: 2164-523XLombardi A, Ferri M, Rescio G, Grassi M, Malcovati P (2009) Wearable wireless accelerometer with embedded fall-detection logic for multi-sensor ambient assisted living applications. In: 2009 IEEE Sensors. Christchurch (New Zealand), pp. 1967–1970. https://doi.org/10.1109/ICSENS.2009.5398327 . E- ISSN: 1930-0395Aziz O, Klenk J, Schwickert L, Chiari L, Becker C, Park EJ, Mori G, Robinovitch SN (2017) Validation of accuracy of SVM-based fall detection system using real-world fall and non-fall datasets. PLoS One 12(7):e0180318Wang K, Delbaere K, Brodie MAD, Lovell NH, Kark L, Lord SR, Redmond SJ (2017) Differences between gait on stairs and flat surfaces in relation to fall risk and future falls. IEEE J Biomed Heal Inform 21(6):1479–1486Lindholm B, Hagell P, Hansson O, Nilsson MH (2015) Prediction of falls and/or near falls in people with mild Parkinson’s disease. PLoS One 10(1):e0117018Fan Y, Levine MD, Wen G, Qiu S (2017) A deep neural network for real-time detection of falling humans in naturally occurring scenes. Neurocomputing 260:43–58Jokanovic B, Amin M, Ahmad F (2016) Radar fall motion detection using deep learning. In: 2016 IEEE Radar Conference (RadarConf). Philadelphia (USA), pp 1–6. https://doi.org/10.1109/RADAR.2016.7485147 . E- ISSN: 2375-5318Jankowski S, Szymański Z, Dziomin U, Mazurek P, Wagner J (2015) Deep learning classifier for fall detection based on IR distance sensor data. In: 2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS), vol 2. Warsar (Polonia), pp. 723–727. https://doi.org/10.1109/IDAACS.2015.7341398Jokanović B, Amin M (2018) Fall detection using deep learning in range-Doppler radars. IEEE Trans Aerosp Electron Syst 54(1):180–189Shojaei-Hashemi A, Nasiopoulos P, Little JJ, Pourazad MT (2018) Video-based Human Fall Detection in Smart Homes Using Deep Learning. In: 2018 IEEE International Symposium on Circuits and Systems (ISCAS). Florence (Italy), pp 1–5. https://doi.org/10.1109/ISCAS.2018.8351648 . E- ISSN: 2379-447XLeu F-Y, Ko C-Y, Lin Y-C, Susanto H, Yu H-C (2017) Chapter 10 - Fall Detection and Motion Classification by Using Decision Tree on Mobile Phone. In: Xhafa F, Leu F-Y, Hung L-LBT-SSN (eds) Intelligent Data-Centric Systems Book. Academic Press, pp 205–237. https://doi.org/10.1016/B978-0-12-809859-2.00013-9Yacchirema D, Suárez de Puga J, Palau C, Esteve M (2018) Fall detection system for elderly people using IoT and Big Data. In: 9th International Conference on Ambient Systems, Networks and Technologies (ANT 2018), Porto (Portugal), available at Procedia Computer Science, vol 130, pp 603–610. https://doi.org/10.1016/j.procs.2018.04.110 E-ISSN:1877-0509Rougier C, Meunier J, St-Arnaud A, Rousseau J (2011) Robust video surveillance for fall detection based on human shape deformation. IEEE Trans Circuits Syst Video Technol 21(5):611–622Stone EE, Skubic M (2015) Fall detection in homes of older adults using the Microsoft Kinect. IEEE J Biomed Heal Inform 19(1):290–301Yuwono M, Moulton BD, Su SW, Celler BG, Nguyen HT (2012) Unsupervised machine-learning method for improving the performance of ambulatory fall-detection systems. Biomed Eng Online 11(1):9Friedman J, Hastie T, Tibshirani R (2001) The elements of statistical learning, vol. 1, no. 10. Springer series in statistics New York, NY, USA. https://doi.org/10.1007/b94608 . E-ISBN: 9780387848587Zhang C, Ma Y (2012) Ensemble machine learning: Methods and applications. Springer-Verlag New York, NY. https://doi.org/10.1007/978-1-4419-9326-7 . E-ISBN 978-1-4419-9326-7Big ML (2017) Inc. US “Comprehensive Machine Learning Platform”. Online. Available: https://bigml.com/features . Accessed 12 Aug 2018Ling CX, Huang J, Zhang H et al (2003) AUC: a statistically consistent and more discriminating measure than accuracy. In: 18th Int'l Joint Conf. Artificial Intelligence (IJCAI), Acapulco (mexico), vol 3, pp 519–524. ISBN:0-7695-2728-0Dai J, Bai X, Yang Z, Shen Z, Xuan D (2010) PerFallD: A pervasive fall detection system using mobile phones. In: 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops). Mannheim (Germany), pp 292–297. https://doi.org/10.1109/PERCOMW.2010.5470652 . E- ISBN: 978-1-4244-6606-1Li Y, Ho KC, Popescu M (2012) A microphone array system for automatic fall detection. IEEE Trans Biomed Eng 59(5):1291–1301Fawcett T (2006) An introduction to ROC analysis. Pattern Recogn Lett 27(8):861–874Pease SG, Trueman R, Davies C, Grosberg J, Yau KH, Kaur N, Conway P, West A (2018) An intelligent real-time cyber-physical toolset for energy and process prediction and optimisation in the future industrial Internet of Things. Futur Gener Comput Syst 79(Part 3):815–829Breiman L (1996) Bagging predictors. Mach Learn 24(2):123–140Hanke S, Mayer C, Hoeftberger O, Boos H, Wichert R, Tazari M-R, Wolf P, Furfari F (2011) universAAL -- An Open and Consolidated AAL Platform. In: Wichert R, Eberhardt B (eds) Ambient Assisted Living: 4. AAL-Kongress 2011, Berlin, Germany, January 25–26, 2011. Springer Berlin Heidelberg, Berlin, Heidelberg, pp. 127–140. https://doi.org/10.1007/978-3-642-18167-2_10 . E-ISBN: 978-3-642-18167-2Gjoreski H, Lustrek M, Gams M (2011) Accelerometer Placement for Posture Recognition and Fall Detection. In: 2011 Seventh International Conference on Intelligent Environments. Nottingham (UK), pp 47–54. doi: https://doi.org/10.1109/IE.2011.11 . E- ISBN: 978-0-7695-4452-6Parker C (2011) An Analysis of Performance Measures for Binary Classifiers. In: 2011 IEEE 11th International Conference on Data Mining, Vancouver (Canada), pp 517–526. doi: https://doi.org/10.1109/ICDM.2011.21 . E- ISSN: 2374-8486Han J, Kamber M, Pei J (2012) Data Mining Concepts and Techniques, Third Edit. Morgan Kaufmann Publishers in The Morgan Kaufmann Series in Data Management Systems. Waltham (USA). E-ISBN: 978012381480",,'Springer Science and Business Media LLC',Fall detection system for elderly people using IoT and ensemble machine learning algorithm,http://hdl.handle.net/10251/161870,10.1007/s00779-018-01196-8,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
200765967,2019-05-20T12:26:52,"This is the author accepted manuscript. The final version is available from Nature Research via the DOI in this record.Software implementations of brain-inspired computing underlie many important computational tasks, from image processing to speech recognition, artificial intelligence and deep learning applications. Yet, unlike real neural tissue, traditional computing architectures physically separate the core computing functions of memory and processing, making fast, efficient and low-energy computing difficult to achieve. To overcome such limitations, an attractive alternative is to design hardware that mimics neurons and synapses. Such hardware, when connected in networks or neuromorphic systems, processes information in a way more analogous to brains. Here we present an all-optical version of such a neurosynaptic system, capable of supervised and unsupervised learning. We exploit wavelength division multiplexing techniques to implement a scalable circuit architecture for photonic neural networks, successfully demonstrating pattern recognition directly in the optical domain. Such photonic neurosynaptic networks promise access to the high speed and high bandwidth inherent to optical systems, thus enabling the direct processing of optical telecommunication and visual data.Engineering and Physical Sciences Research Council (EPSRC)European CommissionDeutsche Forschungsgemeinschaft (DFG","[{'title': 'Nature', 'identifiers': ['issn:0028-0836', '0028-0836']}]",'Springer Science and Business Media LLC',All-optical spiking neurosynaptic networks with self-learning capabilities,https://core.ac.uk/download/200765967.pdf,10.1038/s41586-019-1157-8,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
299968308,2019-01-01T00:00:00,"Intracranial hemorrhage is a medical emergency that requires urgent diagnosis and immediate treatment to improve patient outcome. Machine learning algorithms can be used to perform medical image classification and assist clinicians in diagnosing radiological scans. In this paper, we apply 3-dimensional convolutional neural networks (3D CNN) to classify computed tomography (CT) brain scans into normal scans (N) and abnormal scans containing subarachnoid hemorrhage (SAH), intraparenchymal hemorrhage (IPH), acute subdural hemorrhage (ASDH) and brain polytrauma hemorrhage (BPH). The dataset used consists of 399 volumetric CT brain images representing approximately 12,000 images from the National Neuroscience Institute, Singapore. We used a 3D CNN to perform both 2-class (normal versus a specific abnormal class) and 4-class classification (between normal, SAH, IPH, ASDH). We apply image thresholding at the image pre-processing step, that improves 3D CNN classification accuracy and performance by accentuating the pixel intensities that contribute most to feature discrimination. For 2-class classification, the F1 scores for various pairs of medical diagnoses ranged from 0.706 to 0.902 without thresholding. With thresholding implemented, the F1 scores improved and ranged from 0.919 to 0.952. Our results are comparable to, and in some cases, exceed the results published in other work applying 3D CNN to CT or magnetic resonance imaging (MRI) brain scan classification. This work represents a direct application of a 3D CNN to a real hospital scenario involving a medically emergent CT brain diagnosisPublished versio","[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",'MDPI AG',Image thresholding improves 3-dimensional convolutional neural network diagnosis of different acute brain hemorrhages on computed tomography scans,,10.3390/s19092167,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
301274637,2019-04-20T00:00:00,"© 2019. ElsevierOne of the major challenges that faces today regulatory risk assessment is to speed up the way of assessing threshold sublethal detrimental effects of existing and new chemical products. Recently advances in imaging allows to monitor in real time the behaviour of individuals under a given stress. Light is a common stress for many different organisms. Fish larvae and many invertebrate species respond to light altering their behaviour. The water flea Daphnia magna as many other zooplanktonic species has a marked diel vertical phototactic swimming behaviour against light due to fish predation. The aim of this study was to develop a high throughput image analysis to study changes in the vertical swimming behaviour to light of D. magna first reproductive adult females exposed to 0.1 and 1 µg/L of four psychiatric drugs: diazepam, fluoxetine, propranolol and carbamazepine during their entire life. Experiments were conducted using a new custom designed vertical oriented four 50 mL chamber device controlled by the Noldus software (Netherlands). Changes in speed, preferred area (bottom vs upper areas) and animal aggregation were analysed using groups of animals under consecutive periods of dark and apical light stimulus of different intensities. Obtained results indicated that light intensity increased the speed but low light intensities allowed to better discriminate individual responses to the studied drugs. The four tested drugs decreased the response of exposed organisms to light: individuals move less, were closer to the bottom and at low light intensities were closer each other. At high light intensities, however, exposed individuals were less aggregated. Propranolol, carbamazepine and fluoxetine were the compounds effecting most the behaviour. Our results indicated that psychiatric drugs at environmental relevant concentrations alter the vertical phototactic behaviour of D. magna individuals and that it is possible to develop appropriate high-throughput image analysis devices to measure those responses.Peer Reviewe","[{'title': 'The Science of The Total Environment', 'identifiers': ['issn:0048-9697', '0048-9697']}]",'Elsevier BV',Using a new high-throughput video-tracking platform to assess behavioural changes in Daphnia magna exposed to neuro-active drugs,,10.1016/j.scitotenv.2019.01.187,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
185663536,2018-01-01T00:00:00,"A key requirement of autonomous vehicles is the capability to safely navigate in their environment. However, outside of controlled environments, safe navigation is a very difficult problem. In particular, the real-world often contains both complex 3D structure, and dynamic obstacles such as people or other vehicles. Dynamic obstacles are particularly challenging, as a principled solution requires planning trajectories with regard to both vehicle dynamics, and the motion of the obstacles. Additionally, the real-time requirements imposed by obstacle motion, coupled with real-world computational limitations, make classical optimality and completeness guarantees difficult to satisfy. We present a unified optimization-based motion planning and control solution, that can navigate in the presence of both static and dynamic obstacles. By combining optimal and receding-horizon control, with temporal multi-resolution lattices, we can precompute optimal motion primitives, and allow real-time planning of physically-feasible trajectories in complex environments with dynamic obstacles. We demonstrate the framework by solving difficult indoor 3D quadcopter navigation scenarios, where it is necessary to plan in time. Including waiting on, and taking detours around, the motions of other people and quadcopters.This work was partially supported by FFI/VINNOVA, the Wallenberg Artificial Intelligence, Autonomous Systems and Software Program (WASP) funded by Knut and Alice Wallenberg Foundation, the Swedish Foundation for Strategic Research (SSF) project Symbicloud, the ELLIIT Excellence Center at Linköping-Lund for Information Technology, Swedish Research Council (VR) Linnaeus Center CADICS, and the National Graduate School in Computer Science, Sweden (CUGS).</p",,'Institute of Electrical and Electronics Engineers (IEEE)',Receding-Horizon Lattice-based Motion Planning with Dynamic Obstacle Avoidance,,10.1109/CDC.2018.8618964,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
345057372,2019-11-01T00:00:00,"Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep- and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights)",,'MDPI AG',Vision-Based Multirotor Following Using Synthetic Learning Techniques,,10.3390/s19214794,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
145170263,2017-01-01T00:00:00,"18 pages, 16 figures, 3 tables, 6 pseudocodes/algorithms, video at https://youtu.be/IqtyHFrb3BUInternational audienceThe high probability of hardware failures prevents many advanced robots (e.g., legged robots) from being confidently deployed in real-world situations (e.g., post-disaster rescue). Instead of attempting to diagnose the failures, robots could adapt by trial-and-error in order to be able to complete their tasks. In this situation, damage recovery can be seen as a Reinforcement Learning (RL) problem. However, the best RL algorithms for robotics require the robot and the environment to be reset to an initial state after each episode, that is, the robot is not learning autonomously. In addition, most of the RL methods for robotics do not scale well with complex robots (e.g., walking robots) and either cannot be used at all or take too long to converge to a solution (e.g., hours of learning). In this paper, we introduce a novel learning algorithm called "" Reset-free Trial-and-Error "" (RTE) that (1) breaks the complexity by pre-generating hundreds of possible behaviors with a dynamics simulator of the intact robot, and (2) allows complex robots to quickly recover from damage while completing their tasks and taking the environment into account. We evaluate our algorithm on a simulated wheeled robot, a simulated six-legged robot, and a real six-legged walking robot that are damaged in several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and whose objective is to reach a sequence of targets in an arena. Our experiments show that the robots can recover most of their locomotion abilities in an environment with obstacles, and without any human intervention",,'Elsevier BV',Reset-free Trial-and-Error Learning for Robot Damage Recovery,https://core.ac.uk/download/145170263.pdf,10.1016/j.robot.2017.11.010,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
219700633,2019-06-04T00:00:00,"Panoramic images are widely used in many scenes, especially in virtual reality and street view capture. However, they are new for street furniture identification which is usually based on mobile laser scanning point cloud data or conventional 2D images. This study proposes to perform semantic segmentation on panoramic images and transformed images to separate light poles and traffic signs from background implemented by pre-trained Fully Convolutional Networks (FCN). FCN is the most important model for deep learning applied on semantic segmentation for its end to end training process and pixel-wise prediction. In this study, we use FCN-8s model that pre-trained on cityscape dataset and finetune it by our own data. The results show that in both pre-trained model and fine-tuning, transformed images have better prediction results than panoramic images",,'Copernicus GmbH',Fully convolutional networks for street furniture identification in panorama images,,10.5194/isprs-archives-xlii-2-w13-13-2019,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
390037696,2019-09-11T00:00:00,"The article deals with the prerequisites and generalizes approaches to defining the concept of “creative economy”; on the theoretical basis and practices of creative economy in leading countries of the world an internals and the main principles of its development are identified; genesis of the concept of creative economy is considered; goals, policies, implementation practices in countries around the world are systematized. The position of Ukraine and other countries of the world in the ranking of the global index of creativity are characterized; features of the creative industry in Ukraine are revealed; index of activity of the creative industry of Ukraine is calculated, which indicates a stable tendency of its development.  Potentials of digital technologies, in particular, artificial intelligence, augmented and virtual reality, blockchain technology, to the transformation of creative economy are grounded.The article deals with the prerequisites and generalizes approaches to defining the concept of “creative economy”; on the theoretical basis and practices of creative economy in leading countries of the world an internals and the main principles of its development are identified; genesis of the concept of creative economy is considered; goals, policies, implementation practices in countries around the world are systematized. The position of Ukraine and other countries of the world in the ranking of the global index of creativity are characterized; features of the creative industry in Ukraine are revealed; index of activity of the creative industry of Ukraine is calculated, which indicates a stable tendency of its development.  Potentials of digital technologies, in particular, artificial intelligence, augmented and virtual reality, blockchain technology, to the transformation of creative economy are grounded",,Черкаський навчально-науковий інститут Університету банківської справи,The theory and practice of creative economy in the conditions of digitalization,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
187750255,2019-01-01T00:00:00,"The Internet-of-Things (IoT) revolution has shaped a new application domain where low-power RISC architectures constitute the standard computational backbone. The current de-facto design practice for such architectures is to extend the ISA and the corresponding microarchitecture with custom instructions to efficiently manage the complex tasks imposed by IoT applications, i.e., augmented reality, artificial intelligence and autonomous driving, within narrow energy and area budgets. However, the new IoT application domain also offers a unique opportunity to revisit and optimize the RISC microarchitectural design flow from a more communication- and memory-centric viewpoint. This manuscript critically explores and optimizes the design of a RISC CPU front-end for IoT delivering a two-fold objective: (i) provide an optimized CPU microarchitecture; and (ii) present a set of three design guidelines to steer the implementation of IoT CPUs. The exploration sits on a newly proposed Systems-on-Chip (SoC) and RISC CPU implementing the RISC-V/IMF ISA and accounting for area, timing, and performance design metrics. Such SoC offers a reference design to evaluate pros and cons of different microarchitectural solutions. A wide combination of microarchitectures considering different branch prediction schemes, cache design architectures and on-chip bus solutions have been evaluated. The entire exploration is focused on the FPGA-based implementation due to the renewed interest for this technology demonstrated by both the research community and companies. We note that ARM launched the DesignStart FPGA program to make available the Cortex-M microcontrollers on Xilinx FPGAs in the form of IP blocks",,'MDPI AG',A Fresh View on the Microarchitectural Design of FPGA-Based RISC CPUs in the IoT Era,,10.3390/jlpea9010009,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226721064,2017-01-01T00:00:00,"This paper reports about teaching Artificial Intelligence (AI) by applying the experiential approach called \u201clearning by doing\u201d, where traditional, formal teaching is integrated with a practical activity (a game competition, in our case), that is relevant for AI discipline and allows for an active and playful participation of students.

Students of the course of Fundamentals of AI at the University of Bologna have been challenged (on a voluntary base) to develop an AI software able to play the game of Nine Men\u2019s Morris: at the end of the course, the software players have been compared within a tournament, so as to establish the competition winner. The game has been chosen to let the students deepen the knowledge about AI techniques in solving games, and to apply it in a real, not trivial setting.

The significance and the impact of this approach, from the educational point of view, have been assessed through two questionnaires, a first one focused on the technical aspects, and a second one on the students\u2019 opinions about the initiative. The results are encouraging: students declare they felt highly motivated in studying AI algorithms and techniques, and they have been stimulated in autonomously search for extensions and new solutions not deeply investigated during traditional lessons",,'Springer Science and Business Media LLC',A Game-Based Competition as Instrument for Teaching Artificial Intelligence,,10.1007/978-3-319-70169-1_6,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275767070,2018-01-01T00:00:00,"Automatic assessment of music performance is an open research area widely studied in the past. A vast amount of systems aiming to enhance the learning process of a musical instrument are being developed in the recent years. However, most of the systems focus on the assessment of pitch and onset accuracy, and very few pay attention to tone quality. This is particularly true in violin music education, where although a consensus exist on what is a good or a bad tone quality, there is not a formal definition due to its subjectivity. We present a machine learning approach for the automatic assessment of violin tone quality. We depart from our previous work on the preliminary modelling of several dimensions involving tone quality. Based on recorded examples of tones with different qualities defined and recorded by a professional violinist, we applied machine learning techniques to learn computational models able to evaluate tone quality from extracted audio features. The tone quality models were implemented into a real-time-visual-feedback system.This work has been partly sponsored by the Spanish TIN project TIMUL (TIN2013-48152-C2-2-R), the
European Union Horizon 2020 research and innovation programme under grant agreement No. 688269
(TELMI project), and the Spanish Ministry of Economy and Competitiveness under the Maria de Maeztu
Units of Excellence Programme (MDM-2015-0502)",,'McGill University Library and Archives',Computational modelling of timbre dimensions for automatic violin tone quality assessment,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286356367,2018-10-23T00:00:00,"This is an accepted manuscript of an article published by Elsevier in Cognitive Computation on 23/10/2018, available online: https://doi.org/10.1007/s12559-018-9607-4
The accepted version of the publication may differ from the final published version.© 2019, Springer Science+Business Media, LLC, part of Springer Nature. Hearing loss, a partial or total inability to hear, is one of the most commonly reported disabilities. A hearing test can be carried out by an audiologist to assess a patient’s auditory system. However, the procedure requires an appointment, which can result in delays and practitioner fees. In addition, there are often challenges associated with the unavailability of equipment and qualified practitioners, particularly in remote areas. This paper presents a novel idea that automatically identifies any hearing impairment based on a cognitively inspired feature extraction and speech recognition approach. The proposed system uses an adaptive filter bank with weighted Mel-frequency cepstral coefficients for feature extraction. The adaptive filter bank implementation is inspired by the principle of spectrum sensing in cognitive radio that is aware of its environment and adapts to statistical variations in the input stimuli by learning from the environment. Comparative performance evaluation demonstrates the potential of our automated hearing test method to achieve comparable results to the clinical ground truth, established by the expert audiologist’s tests. The overall absolute error of the proposed model when compared with the expert audiologist test is less than 4.9 dB and 4.4 dB for the pure tone and speech audiometry tests, respectively. The overall accuracy achieved is 96.67% with a hidden Markov model (HMM). The proposed method potentially offers a second opinion to audiologists, and serves as a cost-effective pre-screening test to predict hearing loss at an early stage. In future work, authors intend to explore the application of advanced deep learning and optimization approaches to further enhance the performance of the automated testing prototype considering imperfect datasets with real-world background noise.Published versio","[{'title': 'Cognitive Computation', 'identifiers': ['issn:1866-9964', '1866-9956', '1866-9964', 'issn:1866-9956']}]",'Springer Science and Business Media LLC',Cognitively inspired feature extraction and speech recognition for automated hearing loss testing,https://core.ac.uk/download/286356367.pdf,10.1007/s12559-018-9607-4,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
148807974,2019-01-01T00:00:00,"A real-time visual servo tracking system for an industrial robot has been implemented using PSD (Position Sensitive Detector) cameras, neural networks, and an extended trapezoidal motion planning method. PSD and directly transduces the light&apos;s projected position on its sensor plane into an analog current and lends itself to fast real-time tracking. A neural network, after proper training, transforms the PSD sensor reading into a 3D position of the target, which is then input to an extended trapezoidal motion planning algorithm. This algorithm implements a continuous motion update strategy in response to an ever-changing sensor information from the moving target, while greatly reducing the tracking delay. This planning method is found to be very useful for sensor-based control such as moving target tracking or weld-seam tracking in which the robot needs to change its motion in real time in response to incoming sensor information. Further, for real-time usage of the neural net, a new architecture called LANN (Locally Activated Neural Network) has been developed based on the concept of CMAC input partitioning and local learning. Experimental evidence shows that an industrial robot can smoothly track a moving target of unknown motion with speeds of up to 1 m/s and with oscillation frequency up to 5 Hz.X1113sciescopu","[{'title': 'Applied Intelligence', 'identifiers': ['issn:0924-669X', '0924-669x']}]",'Springer Science and Business Media LLC',Real-time dynamic visual tracking using PSD sensors and extended trapezoidal motion planning,,10.1023/A:1008385515068,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
299953422,2018-01-01T00:00:00,"The fast advancements in sensor data acquisition and vehicle telematics facilitate data collection from taxis and thus, enable building a system to monitor and analyze the citywide taxi service. In this paper, we present a novel and practical system for taxi service analytics and visualization. By utilizing both real time and historical taxi data, the system conducts the estimation on region based passenger wait time for taxi, where recurrent neural network (RNN) and deep learning algorithms are used to build a predictive model. The built RNN-based predictive model achieves 73.3% overall accuracy, which is significantly higher than other classic models. Meanwhile, the system conducts the analytics on the taxi pickup hotspots and trip distributions. The experimental results show that around 97% trips are accurately identified and more than 200 hotspots in the city are successfully detected. Moreover, a novel three dimensional (3D) visualization together with the informative user interface is designed and implemented to ease the information access, and to help system users to understand the characteristics and gain insights of the taxi service","[{'title': 'AI Communications', 'identifiers': ['0921-7126', 'issn:0921-7126']}]",'IOS Press',"An intelligent system for taxi service : analysis, prediction and visualization",,10.3233/AIC-170747,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
296224748,2017-06,"Over the last decade, toxic events along the Mediterranean coast associated with exceptional harmful blooms of the dinoflagellate Ostreopsis cf. ovata have increased in frequency and distribution, causing not only the death of marine organisms and human health problems, but also economic loss on the tourism and aquaculture industries. In order to reduce the burden of routine algal counting, an innovative automated, low-cost, opto-electronic system called OvMeter was developed. It is able to speed up the monitoring process and therefore it enables early warning of incipient harmful algal blooms. An ad-hoc software tool provides automated cell recognition, counting and real-time calculation of the final algal concentration. The core of dinoflagellate recognition relies on a localization step which takes advantage of the synergistic exploitation of 2D bright-field and quantitative phase microscopy images, and a classification phase performed by a machine learning algorithm based on Boosted Trees approach. The architectural design of the OvMeter device is presented here, together with a performance evaluation on sea samples",,Springer,OvMeter: an automated 3D-integrated opto-electronic system for Ostreopsis cf. ovata bloom monitoring,,10.1007/s10811-017-1069-7,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237690220,2019-01-01T00:00:00,"In the Architecture, Engineering, Construction and Operations (AECO) there is a growing interest in the use of the Building Information Modelling (BIM). Through integration of information and processes in a digital model, BIM can optimise resources along the lifecycle of a physical asset. Despite the potential savings are much higher in the operational phase, BIM is nowadays mostly used in design and construction stages and there are still many barriers hindering its implementation in Facility Management (FM). Its scarce integration with live data, i.e. data that changes at high frequency, can be considered one of its major limitations in FM. The aim of this research is to overcome this limit and prove that buildings or infrastructures operations can benefit from a digital model updated with live data. The scope of the research concerns the optimisation of FM operations. The optimisation of operations can be further enhanced by the use of maintenance smart contracts allowing a better integration between users’ behaviour and maintenance implementation. In this case study research, the Image Recognition (ImR), a type of Artificial Intelligence (AI), has been used to detect users’ movements in an office building, providing real time occupancy data. This data has been stored in a BIM model, employed as single reliable source of information for FM. This integration can enhance maintenance management contracts if the BIM model is coupled with a smart contract. Far from being a comprehensive case study, this research demonstrates how the transition from BIM to the Asset Information Model (AIM) and, finally, to the Digital Twin (i.e. a near-real-time digital clone of a physical asset, of its conditions and processes) is desirable because of the outstanding benefits that have already been measured in other industrial sectors by applying the principles of Industry 4.0",,'WITPRESS LTD.',Office building occupancy monitoring through image recognition sensors,,10.2495/SAFE-V9-N4-371-380,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237010479,2019-01-01T00:00:00,"Accurately predicting where the user of a Virtual Reality (VR) application will be looking at in the near future improves the perceive quality of services, such as adaptive tile-based streaming or personalized online training. However, because of the unpredictability and dissimilarity of user behavior it is still a big challenge. In this work, we propose to use reinforcement learning, in particular contextual bandits, to solve this problem. The proposed solution tackles the prediction in two stages: (1) detection of movement; (2) prediction of direction. In order to prove its potential for VR services, the method was deployed on an adaptive tile-based VR streaming testbed, for benchmarking against a 3D trajectory extrapolation approach. Our results showed a significant improvement in terms of prediction error compared to the benchmark. This reduced prediction error also resulted in an enhancement on the perceived video quality",,'Institute of Electrical and Electronics Engineers (IEEE)',Contextual bandit learning-based viewport prediction for 360 video,https://core.ac.uk/download/237010479.pdf,10.1109/VR.2019.8797830,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
215919971,2018-04-01T00:00:00,"This paper introduces a software for dyslexic patients. Dyslexia is a brain condition in which people face problems in detecting words, reading sentences. They cannot read words aloud and they get confused in similar alphabets and numbers. This problem can be cured but it requires proper attention and training to dyslexic people. Training is given like word detecting practices, character visualization, practicing similar alphabets, teaching phonics. This software is based on artificial intelligence and virtual reality. It will try to help dyslexic people and will improve their condition. This software will also contain some animations to reduce the frustration level of dyslexics",,'Nextgen Research Publications',Tulexia: Tutor for Dyslexics,https://media.neliti.com/media/publications/263083-tulexia-tutor-for-dyslexics-13af3072.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
228470486,2018-01-11T00:00:00,"The paper is text-based artwork, which is representing the initial conceptualization or contemplative phase of the media art and contemporary art performance and installation.The objective of the long term art project is to further examine the potential of engagement of the advanced technology within the context of artistic research and contemporary art practice, with the specific postulate that the potential product of the artwork is expected to be imperceptible.
The artistic research is referring to the philosophical and metaphysics idea that the alleged real reality cannot be perceived or defined via some concept. The question is, if it is so, than, is the art or the artist capable to successfully illustrate the undetectable real reality, even with the most advanced technological instruments employed.
The text-based contemporary artwork is partly referring to another segment, which can be also observed within the context of the contemporary art – text based computer adventure games. More specifically, the method implemented for establishing the artwork’s concept uses some aspects similar to those used in early text-based computer games.There are several stages in which the long-term artwork will progress.
The initial form is designed in such a manner which would confirm that this segment of artwork not only does serve as a fundament for the other parts to unfold, but is also autonomous and is already completed in terms of contemporary art. This stand is applicable to all the consecutive stages – each segment is both independent and contextual.The following stages would include the interactivity between the author, art audience, but also with the devices applied for the producing the artwork, like advanced technology instruments e.g. augmented reality (AR), virtual reality (VR), mixed reality (MR) devices, then interactive 3D technology, artificial intelligence (AI), plus the interactivity with the no-reality (reality in spiritual and philosophical contexts)",,International Ambient Media Assocation (iAMEA),"AI, You're Fired! Artwork",https://core.ac.uk/download/228470486.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
335413867,2019-11-01T00:00:00,"Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep- and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights)",,'MDPI AG',Vision-Based Multirotor Following Using Synthetic Learning Techniques,https://oa.upm.es/64118/,10.3390/s19214794,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
224840689,2019-01-01T00:00:00,"PURPOSE: The use of neural networks to directly predict three-dimensional dose distributions for automatic planning is becoming popular. However, the existing methods use only patient anatomy as input and assume consistent beam configuration for all patients in the training database. The purpose of this work was to develop a more general model that considers variable beam configurations in addition to patient anatomy to achieve more comprehensive automatic planning with a potentially easier clinical implementation, without the need to train specific models for different beam settings. METHODS: The proposed anatomy and beam (AB) model is based on our newly developed deep learning architecture, and hierarchically densely connected U-Net (HD U-Net), which combines U-Net and DenseNet. The AB model contains 10 input channels: one for beam setup and the other 9 for anatomical information (PTV and organs). The beam setup information is represented by a 3D matrix of the non-modulated beam's eye view ray-tracing dose distribution. We used a set of images from 129 patients with lung cancer treated with IMRT with heterogeneous beam configurations (4-9 beams of various orientations) for training/validation (100 patients) and testing (29 patients). Mean squared error was used as the loss function. We evaluated the model's accuracy by comparing the mean dose, maximum dose, and other relevant dose-volume metrics for the predicted dose distribution against those of the clinically delivered dose distribution. Dice similarity coefficients were computed to address the spatial correspondence of the isodose volumes between the predicted and clinically delivered doses. The model was also compared with our previous work, the anatomy only (AO) model, which does not consider beam setup information and uses only 9 channels for anatomical information. RESULTS: The AB model outperformed the AO model, especially in the low and medium dose regions. In terms of dose-volume metrics, AB outperformed AO by about 1-2%. The largest improvement was found to be about 5% in lung volume receiving a dose of 5Gy or more (V5 ). The improvement for spinal cord maximum dose was also important, that is, 3.6% for cross-validation and 2.6% for testing. The AB model achieved Dice scores for isodose volumes as much as 10% higher than the AO model in low and medium dose regions and about 2-5% higher in high dose regions. CONCLUSIONS: The AO model, which does not use beam configuration as input, can still predict dose distributions with reasonable accuracy in high dose regions but introduces large errors in low and medium dose regions for IMRT cases with variable beam numbers and orientations. The proposed AB model outperforms the AO model substantially in low and medium dose regions, and slightly in high dose regions, by considering beam setup information through a cumulative non-modulated beam's eye view ray-tracing dose distribution. This new model represents a major step forward towards predicting 3D dose distributions in real clinical practices, where beam configuration could vary from patient to patient, from planner to planner, and from institution to institution",,'Wiley',Three-dimensional dose prediction for lung IMRT patients with deep neural networks: robust learning from heterogeneous beam configurations,,10.1002/mp.13597,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
161678999,2017,"This paper presents the development and implementation of a theoretical mathematical-statistical framework for sequential updating of the grade control model, based on a support vector machine learning algorithm. Utilising the Zambujal orebody within the Neves-Corvo Cu deposit in Portugal, parameters that can be measured in real time, used in visualisation, modelled for resource estimation, and used for process control visualisation and optimisation are considered.
The methodology broadly comprises of three steps. Firstly, the provided dataset is used to develop a virtual asset model (VAM) representing the true 3D grade distribution in order to simulate the mining method. Then ore quality parameters are established simulating real time monitoring sensor installation at: (a) stope development and rock face monitoring (face imaging and drillholes); and (b) transport monitoring (muck pile, LHD/scooptram). Next, the acquired data was assimilated into the models as part of the sequential model update.
Two different mining methods and the monitoring information that can be acquired during the ore extraction are analysed: (a) drift and fill mining and (b) bench and fill mining, which are widely implemented at the Neves-Corvo mine. Selected study zones were chosen such as to contrast mining through the high/low grade zones with different degrees of heterogeneity, which demonstrate the performance of resource estimation and classification models developed in heterogeneous mining stopes.
The grade accuracy and error in the resource model, and high/low grade ore classification accuracy and error are evaluated as performance metrics for the proposed methods.
In drift and fill mining, drillhole and face sampling data collection was simulated in a real-time manner and fed into the support vector machine (SVM) regressor to update the resource estimation model in both a high grade and low grade drift scenarios. In each scenario, six drift and fill mining steps were simulated sequentially and the posterior resource models, after integrating real time mining data, have shown significant improvement of bias correction in both updating planned resources and reconciling extracted ore.
In bench and fill mining, grade classification based on random sampling data from muck pile was demonstrated, considering scoop by scoop derived monitoring data. Three different classifiers (mean, median, and Bayesian) were tested and shown very good performance. In the case study presented here, a sequence of 15 blasting steps was simulated with each step requiring 112 scooping operations to transport the blasted ore. Using the real time monitored information, it was shown that at each blasting step over 85% of the scoops can be labelled correctly using the proposed methods and with an accuracy of over 95%",,TU Bergakademie Freiberg,Development of support vector machine learning algorithm for real time update of resource estimation and grade classification,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
160167470,2018-06-27T00:00:00,"International audienceWe propose a non-invasive method to detect sleep deprivation by evaluating a short video sequence of a subject. Computer Vision techniques are used to crop the face from every frame and classify it (within a Deep Learning framework) into two classes: "" rested "" or "" sleep deprived "". The system has been trained on a database of subjects recorded under severe sleep deprivation conditions. A prototype has been implemented in a low-cost Android device proving its viability for real-time driver monitoring applications. Tests on real world data have been carried out and show encouraging performances but also reveal the need of larger datasets for training",,HAL CCSD,Sleep Deprivation Detection for Real-Time Driver Monitoring using Deep Learning,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275648598,2019-07-25T00:00:00,"[EN] Umm ar-Rasas is a Jordan archaeological site, located 30 km southeast of the city of Madaba, in the northern part of Wadi Mujib. It preserves findings dating back the period from the end of 3rd to the 9th century AD and, since 2004, it belongs to the world heritage list of UNESCO. In 2015 a multidisciplinary work was undertaken over the archaeological site, mainly focusing on the Church of Saint Stephen, with the main purpose of enhancing the knowledge and documenting the conservation state of the polychrome mosaic floor, which covers the entire surface of the hall and presbytery. A huge amount of data has been collected, coming from archaeological and historical investigations, geophysics and geodetic inspections and geomatics surveying, which produced also a true orthophoto of the mosaic floor. Data has been organized in a geo-database, facilitating the exchange of information between different actors. Moreover, the management of data within a dedicated Geographic Information System (GIS), has allowed in-depth analysis for understanding the evolution of the iconographic repertoire that, over the centuries, has undergone several disfigurements due to the iconoclastic age. The knowledge of the mosaic has also been vital for the implementation of multimedia applications and for the creation of virtual experiences, in which the information can be conveyed and visualized directly on the virtual reconstruction of the whole archaeological site. The innovation of the proposed work, is therefore in the management of a data flow that can be exploited by different actors through different platforms: experts, thanks to the use of GIS, and visitors with the use of multimedia applications (such as Augmented Reality (AR) or highresolution web visualization) for dissemination purposes, in order to preserve this priceless mankind heritage.Highlights:Definition of a complete pipeline ranging from data acquisition to visualization in multi-channel multimedia applications.Management of heterogeneous data in Geographic Information Systems (GIS) and their exploitation in Augmented and Virtual Reality (AR/VR).GIS applied to the archaeological domain for expert and non-expert users.[ES] Umm er-Rasas es un sitio arqueológico de Jordania, ubicado a 30 km al sureste de la ciudad de Madaba, en la parte norte de Wadi Mujib. Conserva hallazgos que datan del período comprendido entre finales del siglo III y IX d.C. y, desde 2004, pertenece a la lista del patrimonio mundial de la UNESCO. En 2015, se realizó un trabajo multidisciplinar en el sitio arqueológico, que se centró principalmente en la Iglesia de San Esteban, con el propósito principal de mejorar el conocimiento y la documentación del estado de conservación del suelo con el mosaico policromado que cubre toda la superficie de la sala y el presbiterio. Se ha recopilado una gran cantidad de datos provenientes de investigaciones arqueológicas e históricas, inspecciones geofísicas y geodésicas y levantamientos geomáticos, que produjeron también una ortofoto verdadera del suelo con el mosaico. Los datos se han organizado en una geodatabase, facilitando el intercambio de información entre diferentes actores. Además, la gestión de los datos en un Sistema de Información Geográfica (SIG) dedicado, ha permitido un análisis profundo que facilita la comprensión de la evolución del repertorio iconográfico que, a lo largo de los siglos, ha sufrido varias desfiguraciones debido a la era iconoclasta. El conocimiento del mosaico también ha sido vital en la implementación de aplicaciones multimedia y en la creación de experiencias virtuales, en las que la información se puede transmitir y visualizar directamente en la reconstrucción virtual de todo el sitio arqueológico. La innovación del trabajo propuesto está, por lo tanto, en la gestión del flujo de datos que puede ser  explotado por diferentes actores a través de diferentes plataformas: expertos, gracias al uso del SIG, y visitantes con el uso de las aplicaciones multimedia (como son la Realidad Aumentada (AR) o la visualización web de alta resolución) para fines de divulgación, con el fin de preservar este patrimonio incalculable de la humanidad.Malinverni, ES.; Pierdiccaa, R.; Di Stefano, F.; Gabrielli, R.; Albiero, A. (2019). Museo virtual enriquecido con datos GIS para compartir ciencia y cultura. La Iglesia de San Esteban en Umm er-Rasas (Jordania). Virtual Archaeology Review. 10(21):31-39. https://doi.org/10.4995/var.2019.11919SWORD31391021Anichini, F., Bini, D., Bini, M., Dubbini, N., Fabiani, F., Gattiglia, G., ... Steffè, S. (2012). MAPPAproject: Methodologies applied to archaeological potential predictivity. MapPapers, 1en-I, 23-43.Anichini, F., Fabiani, F., Gattiglia, G., & Gualandi, M. L. (2012). A database for archaeological data recording and analysis. MapPapers, 1en-II, 21-38.Baik, A., Yaagoubi, R., & Boehm, J. (2015). Integration of Jeddah historical BIM and 3D GIS for documentation and restoration of historical monument. International Society for Photogrammetry and Remote Sensing, XL-5/W7, 29-34. https://doi.org/10.5194/isprsarchives-XL-5-W7-29-2015Barrile, V., Fotia, A., Bilotta, G., & De Carlo, D. (2019). Integration of geomatics methodologies and creation of a cultural heritage app using augmented reality. Virtual Archaeology Review, 10(20), 40-51. https://doi.org/10.4995/var.2019.10361Blanco-Pons, S., Carrión-Ruiz, B., Lerma, J. L., & Villaverde, V. (2019). Design and implementation of an augmented reality application for rock art visualization in Cova dels Cavalls (Spain). Journal of Cultural Heritage. https://doi.org/10.1016/j.culher.2019.03.014Bruno, F., Bruno, S., De Sensi, G., Luchi, M. L., Mancuso, S., & Muzzupappa, M. (2010). From 3D reconstruction to virtual reality: A complete methodology for digital archaeological exhibition. Journal of Cultural Heritage, 11(1), 42-49. https://doi.org/10.1016/j.culher.2009.02.006Colosi, F., Fangi, G., Gabrielli, R., Orazi, R., Angelini, A., & Bozzi, C. A. (2009). Planning the Archaeological Park of Chan Chan (Peru) by means of satellite images, GIS and photogrammetry. Journal of Cultural Heritage, 10 (SUPPL. 1), 27-34. https://doi.org/10.1016/j.culher.2009.08.002d'Annibale, E., Tassetti, A. N., & Malinverni, E. S. (2014). Finalizing a low-cost photogrammetric workflow: from panoramic photos to Heritage 3D documentation and visualization. International Journal of Heritage in the Digital Era, 3(1), 33-49. https://doi.org/10.1260/2047-4970.3.1.33Dilek, A. P. S. E., Doğan, M., & Kozbe, G. (2019). The Influences of the Interactive Systems on Museum Visitors' Experience: A Comparative Study from Turkey. Journal of Tourism Intelligence and Smartness, 2(1), 27-38. Retrieved from http://dergipark.org.tr/jtis/issue/44975/559246Felicetti, A., Albiero, A., Gabrielli, R., Pierdicca, R., Paolanti, M., Zingaretti, P.,& Malinverni, E. S. (2018). Automatic Mosaic Digitalization: a Deep Learning approach to tessera segmentation. In METROARCHEO, IEEE International Conference on Metrology for Archaeology and Cultural Heritage. Cassino.Gabrielli, R., Portarena, D., & Franceschinis, M. (2017). Tecniche di documentazione dei tappeti musivi del sito archeologico di Umm Al-Rasas-Kastron Mefaa (Giordania). Archeologia e Calcolatori, 28(1), 201-218.Gabrielli, R., & Greco, G. (2018). Umm Ar-Rasas: The Application of Integrated Methodologies for the Valorization of a Unesco Site. Global Journal of Archaeology & Anthropology, 6(3), 555688. https://doi.org/10.19080/GJAA.2018.06.555688Han, D.-I. D., Weber, J., Bastiaansen, M., Mitas, O., & Lub, X. (2019). Virtual and augmented reality technologies to enhance the visitor experience in cultural tourism. In M. C. tom Dieck & T. Jung (Eds.), Augmented Reality and Virtual Reality (pp. 113-128). Cham: Springer. https://doi.org/10.1007/978-3-030-06246-0Hunter, J., Jateff, E., & van den Hengel, A. (2019). Using digital visualization of archival sources to enhance archaeological interpretation of the 'Life History'of Ships: The case study of HMCS/HMAS Protector. In J. McCarthy, J. Benjamin, T. Winton, & W. van Duivenvoorde (Eds.), 3D Recording and Interpretation for Maritime Archaeology (vol. 31, pp. 89-101). Cham: Springer. https://doi.org/10.1007/978-3-030-03635-5_6Kyriakou, P., & Hermon, S. (2019). Can I touch this? Using natural interaction in a Museum Augmented Reality System. Digital Applications in Archaeology and Cultural Heritage, 12. https://doi.org/10.1016/j.daach.2018.e00088Malinverni, E. S., Pierdicca, R., Giuliano, A., & Mariano, F. (2018). A geographical information system to support restoration activities: a methodological approach experienced upon the case study of Ascoli Satriano Fortress. Applied Geomatics, 10(4), 427-439. https://doi.org/10.1007/s12518-018-0216-4Ognibene, S. (2002). Umm al-Rasas. L'Erma di Bretschneider.Piccirillo, M. (1991). Il complesso di Santo Stefano a Umm al-Rasas Kastron Mefaa in Giordania (1986-1991). Liber Annuus Studii Biblici Franciscani, 41, 327-357.Piccirillo, M. (2008). La Palestina cristiana: I-VII secolo. EDB.Piccirillo, M., & Alliata, E. (1994). Umm al-Rasas Mayfa'ah I: gli scavi del complesso di Santo Stefano.Pierdicca, R., Frontoni, E., Malinverni, E. S., Colosi, F., & Orazi, R. (2016). Virtual reconstruction of archaeological heritage using a combination of photogrammetric techniques: Huaca Arco Iris, Chan Chan, Peru. Digital Applications in Archaeology and Cultural Heritage, 3(3), 80-90. https://doi.org/10.1016/j.daach.2016.06.002Pierdicca, R., Malinverni, E. S., Frontoni, E., Colosi, F., & Orazi, R. (2016). 3D visualization tools to explore ancient architectures in South America. Virtual Archaeology Review, 7(15), 44-53. https://doi.org/10.4995/var.2016.5904Rahaman, H., Champion, E., & Bekele, M. (2019). From photo to 3D to mixed reality: A complete workflow for cultural heritage visualisation and experience. Digital Applications in Archaeology and Cultural Heritage, 13. https://doi.org/10.1016/j.daach.2019.e00102Salonia, P., & Negri, A. (2003). Cultural Heritage emergency: GIS-based tools for assessing and deciding preservation. In Proceedings of the Twenty-Third Annual ESRI International User Conference, San Diego, CA, USA (pp. 7-11).Saygi, G., & Remondino, F. (2013). Management of architectural heritage information in BIM and GIS: State-of-the-art and future perspectives. Internationa",,'Universitat Politecnica de Valencia',Virtual museum enriched by GIS data to share science and culture. Church of Saint Stephen in Umm Ar-Rasas (Jordan),https://riunet.upv.es/bitstream/10251/124244/4/11919-48092-2-PB.pdf,10.4995/var.2019.11919,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
442409320,2019-01-01T00:00:00,"Within the strongly regulated avionic engineering field, conventional graphical desktop hardware and software application programming interface (API) cannot be used because they do not conform to the avionic certification standards. We observe the need for better avionic graphical hardware, but system engineers lack system design tools related to graphical hardware. The endorsement of an optimal hardware architecture by estimating the performance of a graphical software, when a stable rendering engine does not yet exist, represents a major challenge. As proven by previous hardware emulation tools, there is also a potential for development cost reduction, by enabling developers to have a first estimation of the performance of its graphical engine early in the development cycle. In this paper, we propose to replace expensive development platforms by predictive software running on a desktop computer. More precisely, we present a system design tool that helps predict the rendering performance of graphical hardware based on the OpenGL Safety Critical API. First, we create nonparametric models of the underlying hardware, with machine learning, by analyzing the instantaneous frames per second (FPS) of the rendering of a synthetic 3D scene and by drawing multiple times with various characteristics that are typically found in synthetic vision applications. The number of characteristic combinations used during this supervised training phase is a subset of all possible combinations, but performance predictions can be arbitrarily extrapolated. To validate our models, we render an industrial scene with characteristic combinations not used during the training phase and we compare the predictions to those real values. We find a median prediction error of less than 4 FPS","[{'title': 'Scientific Programming', 'identifiers': ['1058-9244', 'issn:1058-9244', '1875-919x', 'issn:1875-919X']}]",'Hindawi Limited',Avionics Graphics Hardware Performance Prediction with Machine Learning,,10.1155/2019/9195845,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
225446790,2017-01-01T00:00:00,"INTRODUCTION: The recent scientific and technologic advances have profoundly affected the training of surgeons worldwide. We describe a novel intraoperative real-time training module, the Advanced Robotic Multi-display Educational System (ARMES).

METHODS: We created a real-time training module, which can provide a standardized step by step guidance to robotic distal subtotal gastrectomy with D2 lymphadenectomy procedures, ARMES. The short video clips of 20 key steps in the standardized procedure for robotic gastrectomy were created and integrated with TilePro™ software to delivery on da Vinci Surgical Systems (Intuitive Surgical, Sunnyvale, CA).

RESULTS: We successfully performed the robotic distal subtotal gastrectomy with D2 lymphadenectomy for patient with gastric cancer employing this new teaching method without any transfer errors or system failures. Using this technique, the total operative time was 197 min and blood loss was 50 mL and there were no intra- or post-operative complications.

CONCLUSIONS: Our innovative real-time mentoring module, ARMES, enables standardized, systematic guidance during surgical procedures.restrictio","[{'title': 'Journal of Surgical Oncology', 'identifiers': ['issn:0022-4790', '1096-9098', 'issn:1096-9098', '0022-4790']}]",'Wiley',Advanced real-time multi-display educational system (ARMES): An innovative real-time audiovisual mentoring tool for complex robotic surgery,,10.1002/jso.24722,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
228047801,2019-05-29T00:00:00,"International audienceThis paper describes the principles and implementation results of reinforcement learning algorithms on IoT devices for radio collision mitigation in ISM unlicensed bands. Learning is here used to improve both the IoT network capability to support a larger number of objects as well as the autonomy of IoT devices. We first illustrate the efficiency of the proposed approach in a proof-of-concept based on USRP software radio platforms operating on real radio signals. It shows how collisions with other RF signals present in the ISM band are diminished for a given IoT device. Then we describe the first implementation of learning algorithms on LoRa devices operating in a real LoRaWAN network, that we named IoTligent. The proposed solution adds neither processing overhead so that it can be ran in the IoT devices, nor network overhead so that no change is required to LoRaWAN. Real life experiments have been done in a realistic LoRa network and they show that IoTligent device battery life can be extended by a factor 2 in the scenarios we faced during our experiment.L'article décrit les principes et les résultats de la mise en œuvre d'algorithmes d'apprentissage par renforcement sur des appareils de l'Internet des Objets pour l'atténuation des collisions radio dans les bandes non licenciées ISM. L'apprentissage est ici utilisé pour améliorer à la fois la capacité du réseau IoT à supporter un plus grand nombre d'objets ainsi que l'autonomie des appareils IoT. Nous illustrons d'abord l'efficacité de l'approche proposée dans une preuve de concept basée sur des plates-formes radio logicielles USRP fonctionnant sur des signaux radio réels. Cette démonstration montre comment les collisions avec d'autres signaux RF présents dans la bande ISM sont réduites pour un dispositif IoT donné. Ensuite, nous décrivons la première implémentation d'algorithmes d'apprentissage sur des appareils LoRa fonctionnant dans un réseau LoRaWAN réel, que nous avons nommé IoTligent. La solution proposée n'ajoute aucune surcharge de traitement pour qu'elle puisse être exécutée dans les périphériques IoT, ni de surcharge sur le réseau de sorte qu'aucune modification n'est nécessaire pour LoRaWAN. Des expériences réelles ont été réalisées dans un réseau LoRa, et elles montrent que la durée de vie de la batterie d'un appareil IoTligent peut être augmentée d'un facteur 2 dans les scénarios auxquels nous avons été confrontés pendant notre expérience",,HAL CCSD,Apprentissage décentralisé du spectre pour l'atténuation des collisions dans les réseaux IoT sans fil,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275635397,2018-01-10T00:00:00,"[EN] Road safety applications envisaged for vehicular ad hoc networks (VANETs) depend largely on the exchange of messages to deliver information to concerned vehicles. Safety applications as well as inherent VANET characteristics make data dissemination an essential service and a challenging task. We are developing a decentralized efficient solution for broadcast data dissemination through two game-theoretical mechanisms. Besides, VANETs can also include autonomous vehicles (AVs). AVs might represent a revolutionary new paradigm that can be a reality in our cities in the next few years. AVs do not need a driver to work; instead, they should copy a proper human behavior to adapt the driving according to the current circumstances, such as speed limit, pedestrian crossing street or wheather conditions. We will develop an AV software module including artificial intelligence (AI) techniques so that AVs can interact with the dynamic scenario throughout time. Finally, we also will include electrical vehicles (EV) in the VANET, so that special services such as finding and reserving an EV charging station place will be welcome. In addition, we are developing a multimetric geographic routing protocol for VANETs to transmit H.265 video (traffic accident, traffic state, commercial….) over VANETs.This work was partly supported by the Spanish Government through the project TEC2014-54335-C4-
1-R INcident monitoRing In Smart COmmunities, QoS and Privacy (INRISCO). Cristian Iza is recipient of a grant from Secretaria Nacional de Educación Superior, Ciencia y Tecnología SENESCYT. Ahmad Mohamad Mezher is a postdoctoral researcher with the Information Security Group (ISG) at the Universitat Politècnica de Catalunya (UPC).Iza Paredes, C.; Uribe Ramírez, JA.; López Márquez, N.; Lemus, L.; Mezher, A.; Aguilar Igartua, M. (2018). Multimedia communications in vehicular adhoc networks for several applications in the smart cities. Editorial Universitat Politècnica de València. 212-215. https://doi.org/10.4995/JITEL2017.2017.6584OCS21221",,'Universitat Politecnica de Valencia',Multimedia communications in vehicular adhoc networks for several applications in the smart cities,https://riunet.upv.es/bitstream/10251/102992/1/6584-18904-1-PB.pdf,10.4995/JITEL2017.2017.6584,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
188692532,2018,"This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) licenseGrowing access to tap water and consequent expansion of water distribution systems has created numerous challenges to maintaining water quality between the treatment node and final consumer. Despite all efforts to develop sustainable monitoring systems, there is still a lack of low cost, continuous and real time devices that demonstrate potential for large-scale implementation in wide water distribution networks. The following work presents a study of a low-cost, optofluidic sensor, based on Trypthopan Intrinsic Fluorescence. The fluorospectrometry analysis performed (before sensor development) supports the existence of a measurable fluorescence output signal originating from the tryptophan contained within pathogenic bacteria. The sensor was mounted using a rapid prototyping technique (3D printing), and the integrated optical system was achieved with low-cost optical components. The sensor performance was evaluated with spiked laboratory samples containing E. coli and Legionella, in both continuous and non-continuous flow situations. Results have shown a linear relationship between the signal measured and pathogen concentration, with limits of detection at 1.4 × 103 CFU/mL. The time delay between contamination and detection of the bacteria was practically null. Therefore, this study supports the potential application of tryptophan for monitoring drinking water against water pathogens. View Full-Text
Keywords: pathogen detection; drinking water quality; intrinsic fluorescence; tryptophan; real-time detection; continuous monitoring; on-line optofluidic sensor; low-cost instrumentation; optofluidicpublishedVersio",,,Continuous and real-time detection of drinking-water pathogens with a low-cost fluorescent optofluidic sensor,,10.3390/s18072210,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
237010931,2019-01-01T00:00:00,"Over the past years, deep neural networks (DNNs) have quickly grown into the state-of-the-art technologyfor various machine learning tasks such as image and speech recognition or natural language processing.However, as DNN-based applications typically require significant amounts of computation, running DNNson resource-constrained devices still constitutes a challenge,  especially for real-time applications such aslow-latency audio processing.  In this paper, we aimed to perform real-time noise suppression on a low-costembedded platform with limited resources, using a pre-trained DNN-based speech enhancement model.  Aportable setup was employed, consisting of a Raspberry Pi 3 Model B+ fitted with a soundcard and head-phones.  A (basic) low-latency Python framework was developed to accommodate an audio processing al-gorithm operating in a real-time environment.  Various layouts and trainable parameters of the DNN-basedmodel as well as different processing time intervals (from 64 up to 8 ms) were tested and compared usingobjective metrics (e.g.   PESQ, segSNR) to achieve the best possible trade-off between noise suppressionperformance and audio latency.  We show that 10-layer DNNs with up to 350,000 trainable parameters cansuccessfully be implemented on the Raspberry Pi 3 Model B+ and yield latencies below 16-ms for real-timeaudio applications",,Deutsche Gesellschaft für Akustik,Real-time audio processing on a raspberry Pi using deep neural networks,https://core.ac.uk/download/237010931.pdf,10.18154/RWTH-CONV-239335,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
156747554,2018-04-25T05:00:00Z,"Figure S1. Smad7, YAP, and TAZ mRNA expression in human skin dermis in vivo and primary dermal fibroblasts in vitro. (A) Human skin dermis was prepared by cutting off epidermis at a depth of 1 mm by cryostat. Dermal total RNA was prepared using a commerical kit (RNeasy midikit, Qiagen, Chatsworth, CA). N = 8. (B) Total RNA from primary dermal dibroblasts was extracted using TRIzol reagent (Invitrogen, Carlsbad, CA). N = 3 mRNA levels for Smad7, YAP, and TAZ were determined by real-time RT-PCR. mRNA levels were normalized to mRNA for 36B4, a ribosomal protein used as an internal control for quantitation. Data are expressed as mean + SEM, *p < 0.05 vs Smad7. Figure S2. Full-length Western blots for Fig. 1a. Figure S3. Full-length Western blots for Fig. 2b. Figure S4. Full-length Western blots for Fig. 3b. Figure S5 A. Full-length Western blots for Fig. 5d. B. Full-length Western blots for Fig. 5f. C. Full-length Western blots for Fig. 5g. Figure S6 YAP/TAZ knockdown did not alter AP-1 family transcription factors mRNA expression. Primary dermal fibroblasts were transfected with non-specific control siRNA or YAP/TAZ siRNAs (400 nM) for 48 h. AP-1 family transcription factors mRNA levels were quantified by real-time RT-PCR. mRNA levels were normalized to mRNA for 36B4, a ribsomal protein used as an internal control for quantitation. N = 4, data are expressed as mean + SEM. Figure S7. Smad3 antibody specificity testing by Smad3. Primary dermal fibroblasts were transfected with with non-specific control siRNA or Smad3 siRNA (400 nM). 48 h after transfection, cells were treated with TGF-β1 (ng/ml) for one hour and whole cell extract was prepared. Protein levels of phospho-Smad3 were determined by Capillary electrophoresis immunoassay and normalized to β-actin (loading control). Band intensities were quantified by Compass software. Bands show representative digital images. (PDF 175 kb",,,Additional file 1: of YAP/TAZ regulates TGF-β/Smad3 signaling by induction of Smad7 via AP-1 in human skin dermal fibroblasts,,10.6084/m9.figshare.6187841.v1,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
289704177,2018-01-01T00:00:00,"This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing",,'Elsevier BV',Arrhythmia detection using deep convolutional neural network with long duration ECG signals,,10.1016/j.compbiomed.2018.09.009,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
186351804,2019-01-01T00:00:00,"Urban planning is central to flood risk prevention. Flood-sensitive urban planning pursues two goals: reducing flood exposure and vulnerability [1]; but also addressing the influence of urban characteristics on flood flow severity (flow depths and velocities) [2]. Focusing on the latter, we present here a unique software which automatically optimizes the geometry of urban layouts to enhance flood resilience [3]. The optimized parameters describe the arrangement of the road network, the blocks, the parcels, and the buildings. The proposed approach is particularly innovative since, so far, such automatic urban design tools were developed only for totally different objectives (e.g. optimizing sun exposure or distance to parks); but not in the context of flood risk management.
Our automatic urban design system consists of three components: (i) a procedural urban model, (ii) a surrogate for a hydraulic model and (iii) an optimization engine.
•	Starting from a set of input parameters pi (typical road length, width, curvature …) the procedural urban model generates urban layouts which mimic fairly realistically real-world urban patterns [3].
•	To achieve interactive feedback (i.e. getting the results within a few seconds), the system uses a neural network (NN) to approximate the relationship between urban layout and flood flow characteristics. The NN was trained using a relatively fast 2D porosity-based hydraulic model [4], which in turn was calibrated against a detailed shallow-water model [2].
•	A Markov Chain Monte Carlo optimization is used to adjust iteratively the procedural model parameters pi so as to yield the desired urban layout.
The system was tested for optimizing the layout of an urban district of 1 km by 1 km subject to river flooding. The system runs about one minute to find the optimal urban layout. The system tends to improve the flow conveyance through the urban area by increasing the voids in-between the buildings (e.g., increase road width) and by promoting a more “fragmented” urban pattern (e.g., decrease road length). The optimization reduces the flood water depths in the district by up to 20 to 25%.
Several real-world examples showcase the operationality of the system for improving flood resilience through flood-sensitive urban design [3]. In practice, such an interactive digital tool can valuably assist urban planners and architects to assess the implications of various design decisions on flooding and end up with improved flood-sensitive urban layouts. The approach should be further developed to accommodate more diverse flooding scenarios (e.g. pluvial floods, coastal floods, etc.).
References
[1]	Mustafa, A. et al. (2018). Effects of spatial planning on future flood risks in urban environments. J. Environ. Manage. 225, 193–204. 
[2]	Bruwier, M. et al. (2018). Influence of urban pattern on inundation flow in floodplains of lowland rivers. Sci. Total Environ. 622-623, 446–458. 
[3]	Mustafa, A. et al. (2019). Procedural Generation of Flood-Sensitive Urban Layouts. Environ Plan B Urban Anal City Sci. In press. 
[4]	Bruwier, M. et al. (2017). Shallow-water models with anisotropic porosity and merging for flood modelling on Cartesian grids. J. Hydrol. 554, C, 693–709.FloodLan",,,Automatic design of ﬂood-resilient urban layouts,https://orbi.uliege.be/handle/2268/232295,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
200793946,2019-01-01T00:00:00,"Augmented reality (AR) is a new technology. Very few people know about its development, which began in 1970s from massive and primitive devices. Now AR is at the very peak of its improvement in the form of various software. Augmented reality has its application in the following devices: glasses, phones, tablets. Augmented reality works on the basis of two stages: object recognition and marker tracking. Recognition occurs on the basis of machine learning and tracking of markers by finding certain elements or special markers. The analogue of this principle of operation is SLAM technology (Simultaneous Localization and Map Building). But the best results are achieved with the simultaneous use of two technologies. AR is involved in different areas: education, medicine, entertainment, military training. For education, three-dimensional 3D models are used, which are more visual for students and simplify their studies. In entertainment, AR has found a place for itself in various social networks in the form of masks (Snapchat), games (Pokemon GO) and others. In medicine, in addition to training, AR is used to visualize the internal organs of patients. Augmented reality has great potential for development in practical application in everyday life environments because it does not require high hardware characteristics.Дополненная реальность, или AR (augmented reality) – новая технология, развитие которой сейчас мало кому известно. Она начала развитие в 70-х годах прошлого века от массивных и примитивных устройств. Сейчас же находится на самом пике своего совершенствования в виде различных ПО. Дополненная реальность имеет свое применение в следующий устройствах: очки, телефоны, планшеты. AR работает на основе двух этапов: распознавание объектов и отслеживание маркеров. Распознавание происходит на базе машинного обучения, а отслеживание маркеров путем нахождения определенных элементов или специальных маркеров. Аналогом данного принципа работы является технология SLAM. Но наилучшие результаты достигаются при одновременном использовании двух технологий. AR заполняет все больше сфер. Для образования используют объемные 3D модели, которые являются более наглядными для студентов и упрощают их обучение. В развлечениях AR нашло себе место в различных социальных сетях в виде масок (Snapchat), игр (Pokemon GO) и других. В медицине, помимо обучения, AR используют для визуализации внутренних органов пациентов. Дополненная реальность имеет большие возможности для развития в практическом применение в повседневных средах жизни, потому что не требует высоких характеристик аппаратных средств",,ООО «Издательский Дом «Ажур»,Дополненная реальность,http://elar.urfu.ru/bitstream/10995/72058/1/978-5-91256-441-3_2019_082.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275646428,2018-01-01T00:00:00,"[EN] Traditional interaction mechanisms in distributed digital spaces often fail to consider the intrinsic properties of action, perception, and communication among workgroups, which may affect access to the common resources used to mutually organize information. By developing suitable spatial geometries and natural interaction mechanisms, distributed spaces can become blended where the physical and virtual boundaries of local and remote spaces merge together to provide the illusion of a single unified space. In this paper, we discuss the importance of blended interaction in distributed spaces and the particular challenges faced when designing accessible technology. We illustrate this discussion through a new tangible interaction mechanism for collaborative spaces based on tabletop system technology implemented with optical frames. Our tangible elements facilitate the exchange of digital information in distributed collaborative settings by providing a physical manifestation of common digital operations. The tangibles are designed as passive elements that do not require the use of any additional hardware or external power while maintaining a high degree of accuracy.This work was supported by the Spanish Ministry of Economy and Competitiveness and the European Regional Development Fund, through the ANNOTA Project (Ref. TIN2013-46036-C3-1-R).Salvador-Herranz, G.; Camba, J.; Contero, M.; Naya Sanchis, F. (2018). Accessibility and tangible interaction in distributed workspaces based on multi-touch surfaces. Universal Access in the Information Society. 17(2):247-256. https://doi.org/10.1007/s10209-017-0563-7S247256172Arkin, E.M., Chew, L.P., Huttenlocher, D.P., Kedem, K., Mitchell, J.S.B.: An efficiently computable metric for comparing polygonal shapes. IEEE Trans. Acoust. Speech Signal Process. 13(3), 209–216 (1991)Benyon, D.: Presence in blended spaces. Interact. Comput. 24(4), 219–226 (2012)Bhalla, M.R., Bhalla, A.V.: Comparative study of various touchscreen technologies. Int. J. Comput. Appl. 6(8), 12–18 (2010)Bradski, G., Kaehler, A.: Learning OpenCV: Computer Vision with the OpenCV Library. O’Reilly Media Inc., Newton (2008)Candela, E.S., Pérez, M.O., Romero, C.M., López, D.C.P., Herranz, G.S., Contero, M., Raya, M.A.: Humantop: a multi-object tracking tabletop. Multimed. Tools Appl. 70(3), 1837–1868 (2014)Cohen, J., Withgott, M., Piernot, P.: Logjam: a tangible multi-person interface for video logging. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 128–135. ACM (1999)Couture, N., Rivière, G., Reuter, P.: Geotui: a tangible user interface for geoscience. In: Proceedings of the 2nd International Conference on Tangible and Embedded Interaction, pp. 89–96. ACM (2008)de la Guía, E., Lozano, M.D., Penichet, V.R.: Cognitive rehabilitation based on collaborative and tangible computer games. In: 2013 7th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth), pp. 389–392. IEEE (2013)Dietz, P., Leigh, D.: Diamondtouch: a multi-user touch technology. In: Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, pp. 219–226. ACM (2001)Falcão, T.P., Price, S.: What have you done! the role of ‘interference’ in tangible environments for supporting collaborative learning. In: Proceedings of the 9th International Conference on Computer Supported Collaborative Learning-Volume 1, pp. 325–334. International Society of the Learning Sciences (2009)Fallman, D.: Wear, point and tilt. In: Proceedings of the Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, pp. 293–302. ACM Press (2002)Fishkin, K.P., Gujar, A., Harrison, B.L., Moran, T.P., Want, R.: Embodied user interfaces for really direct manipulation. Commun. ACM 43(9), 74–80 (2000)Fitzmaurice, G.W., Buxton, W.: An empirical evaluation of graspable user interfaces: towards specialized, space-multiplexed input. In: Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pp. 43–50. ACM (1997)Fitzmaurice, G.W., Ishii, H., Buxton, W.A.: Bricks: laying the foundations for graspable user interfaces. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 442–449. ACM Press (1995)Graham, R.L., Yao, F.F.: Finding the convex hull of a simple polygon. J. Algorithms 4(4), 324–331 (1983)Hartigan, J.A., Wong, M.A.: Algorithm as 136: a k-means clustering algorithm. J. R. Stat. Soc.: Ser. C (Appl. Stat.) 28(1), 100–108 (1979)Higgins, S.E., Mercier, E., Burd, E., Hatch, A.: Multi-touch tables and the relationship with collaborative classroom pedagogies: a synthetic review. Int. J. Comput. Support. Collab. Learn. 6(4), 515–538 (2011)Hinckley, K., Pausch, R., Goble, J.C., Kassell, N.F.: Passive real-world interface props for neurosurgical visualization. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 452–458. ACM (1994)Hinske, S.: Determining the position and orientation of multi-tagged objects using RFID technology. In: 5th Annual IEEE International Conference on Pervasive Computing and Communications Workshops, 2007. PerCom Workshops’07, pp. 377–381. IEEE (2007)Hornecker, E.: A design theme for tangible interaction: embodied facilitation. In: ECSCW 2005, pp. 23–43. Springer (2005)Hoshi, K., Öhberg, F., Nyberg, A.: Designing blended reality space: conceptual foundations and applications. In: Proceedings of the 25th BCS Conference on Human–Computer Interaction, pp. 217–226. British Computer Society (2011)Ishii, H.: Tangible User Interfaces. CRC Press, Boca Raton (2007)Ishii, H., Ullmer, B.: Tangible bits: towards seamless interfaces between people, bits and atoms. In: Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, pp. 234–241. ACM (1997)Jacob, R.J., Girouard, A., Hirshfield, L.M., Horn, M.S., Shaer, O., Solovey, E.T., Zigelbaum, J.: Reality-based interaction: a framework for post-wimp interfaces. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 201–210. ACM (2008)Jetter, H.C., Dachselt, R., Reiterer, H., Quigley, A., Benyon, D., Haller, M.: Blended Interaction: Envisioning Future Collaborative Interactive Spaces. ACM, New York (2013)Jin, X., Han, J.: Quality threshold clustering. In: Sammut, C., Webb, G.I. (eds.) Encyclopedia of Machine Learning, pp. 820–820. Springer, Boston, MA (2011)Jordà, S., Geiger, G., Alonso, M., Kaltenbrunner, M.: The reactable: exploring the synergy between live music performance and tabletop tangible interfaces. In: Proceedings of the 1st International Conference on Tangible and Embedded Interaction, pp. 139–146. ACM (2007)Kaltenbrunner, M., Bovermann, T., Bencina, R., Costanza, E.: Tuio: a protocol for table-top tangible user interfaces. In: Proceedings of the 6th International Workshop on Gesture in Human–Computer Interaction and Simulation, pp. 1–5 (2005)Kirk, D., Sellen, A., Taylor, S., Villar, N., Izadi, S.: Putting the physical into the digital: issues in designing hybrid interactive surfaces. In: Proceedings of the 23rd British HCI Group Annual Conference on People and Computers: Celebrating People and Technology, pp. 35–44. British Computer Society (2009)Marques, T., Nunes, F., Silva, P., Rodrigues, R.: Tangible interaction on tabletops for elderly people. In: International Conference on Entertainment Computing, pp. 440–443. Springer (2011)Müller, D.: Mixed reality systems. iJOE 5(S2), 10–11 (2009)Newton-Dunn, H., Nakano, H., Gibson, J.: Block jam: a tangible interface for interactive music. In: Proceedings of the 2003 Conference on New Interfaces for Musical Expression, pp. 170–177. National University of Singapore (2003)Patten, J., Recht, B., Ishii, H.: Audiopad: a tag-based interface for musical performance. In: Proceedings of the 2002 Conference on New Interfaces for Musical Expression, pp. 1–6. National University of Singapore (2002)Patten, J., Recht, B., Ishii, H.: Interaction techniques for musical performance with tabletop tangible interfaces. In: Proceedings of the 2006 ACM SIGCHI International Conference on Advances in Computer Entertainment Technology, p. 27. ACM (2006)PQLabs: Inc. http://multitouch.com/ . Retrieved on 16 October 2016Ryokai, K., Marti, S., Ishii, H.: I/o brush: drawing with everyday objects as ink. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI’04, pp. 303–310. ACM, New York (2004). doi: 10.1145/985692.985731Salvador, G., Bañó, M., Contero, M., Camba, J.: Evaluation of a distributed collaborative workspace as a creativity tool in the context of design education. In: 2014 IEEE Frontiers in Education Conference (FIE) Proceedings, pp. 1–7. IEEE (2014)Salvador-Herranz, G., Contero, M., Camba, J.: Use of tangible marks with optical frame interactive surfaces in collaborative design scenarios based on blended spaces. In: International Conference on Cooperative Design, Visualization and Engineering, pp. 253–260. Springer (2014)Salvador-Herranz, G., Camba, J.D., Naya, F., Contero, M.: On the integration of tangible elements with multi-touch surfaces for the collaborative creation of concept maps. In: International Conference on Learning and Collaboration Technologies, pp. 177–186. Springer (2016)Schöning, J., Hook, J., Bartindale, T., Schmidt, D., Oliver, P., Echtler, F., Motamedi, N., Brandl, P., von Zadow, U.: Building interactive multi-touch surfaces. In: Müller-Tomfelde, C. (ed.) Tabletops-Horizontal Interactive Displays, pp. 27–49. Springer, London, UK (2010)Shaer, O., Hornecker, E.: Tangible user interfaces: past, present, and future directions. Found. Trends Hum. Comput. Interact. 3(1–2), 1–137 (2010)Shen, C., Everitt, K., Ryall, K.: Ubitable: Impromptu face-to-face collaboration on horizontal interactive surfaces. In: International Conference on Ubiquitous Computing, pp. 281–288. Springer (2003)Suzuki, H., Kato, H.: Algoblock: a tangible programming language, a tool for collaborative learning. In: Proceedings of 4th European Logo Conference, pp. 297–303 (1993)Suzuki, H., Kato, H.: Interaction-level support for collaborative learning: Algoblockan open programming language. In: The 1st International Conference on Computer Support for Collaborative Learning, pp. 349–355. L. Erlbaum Associates Inc. (1995)Terrenghi, L., Kirk, D., Richter, H., Krämer, S., Hilliges, O., Butz, A.: Physical handles at the interactive surface: exploring tangibility and its benefits. In: Proceedings of the Working Conference on Advanced Visual Interfaces, pp. 138–145. ACM (2008)Veltkamp, R.C.: Shape matching: similarity measures and algorithms. In: SMI 2001 International Conference on Shape Modeling and Applications, pp. 188–197. IEEE (2001)Weinberg, G., Gan, S.L.: The squeezables: Toward an expressive and interdependent multi-player musical instrument. Comput. Music J. 25(2), 37–45 (2001)Weiser, M.: Some computer science issues in ubiquitous computing. Commun. ACM 36(7), 75–84 (1993)Wilson, F.: The hand: how its use shapes the brain, language, and human culture. Vintage Series. Vintage Books (1998). https://books.google.es/books?id=l_Boy_-NkwUCZuckerman, O., Arida, S., Resnick, M.: Extending tangible interfaces for education: digital montessori-inspired manipulatives. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 859–868. ACM (2005",,'Springer Science and Business Media LLC',Accessibility and tangible interaction in distributed workspaces based on multi-touch surfaces,https://riunet.upv.es/bitstream/10251/120351/9/Postprint%20UAIS%202018.pdf,10.1007/s10209-017-0563-7,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
294829072,2019-04-20T00:00:00,"© 2019. ElsevierOne of the major challenges that faces today regulatory risk assessment is to speed up the way of assessing threshold sublethal detrimental effects of existing and new chemical products. Recently advances in imaging allows to monitor in real time the behaviour of individuals under a given stress. Light is a common stress for many different organisms. Fish larvae and many invertebrate species respond to light altering their behaviour. The water flea Daphnia magna as many other zooplanktonic species has a marked diel vertical phototactic swimming behaviour against light due to fish predation. The aim of this study was to develop a high throughput image analysis to study changes in the vertical swimming behaviour to light of D. magna first reproductive adult females exposed to 0.1 and 1 µg/L of four psychiatric drugs: diazepam, fluoxetine, propranolol and carbamazepine during their entire life. Experiments were conducted using a new custom designed vertical oriented four 50 mL chamber device controlled by the Noldus software (Netherlands). Changes in speed, preferred area (bottom vs upper areas) and animal aggregation were analysed using groups of animals under consecutive periods of dark and apical light stimulus of different intensities. Obtained results indicated that light intensity increased the speed but low light intensities allowed to better discriminate individual responses to the studied drugs. The four tested drugs decreased the response of exposed organisms to light: individuals move less, were closer to the bottom and at low light intensities were closer each other. At high light intensities, however, exposed individuals were less aggregated. Propranolol, carbamazepine and fluoxetine were the compounds effecting most the behaviour. Our results indicated that psychiatric drugs at environmental relevant concentrations alter the vertical phototactic behaviour of D. magna individuals and that it is possible to develop appropriate high-throughput image analysis devices to measure those responses.Peer ReviewedPostprint (author's final draft","[{'title': 'The Science of The Total Environment', 'identifiers': ['issn:0048-9697', '0048-9697']}]",'Elsevier BV',Using a new high-throughput video-tracking platform to assess behavioural changes in Daphnia magna exposed to neuro-active drugs,https://core.ac.uk/download/294829072.pdf,10.1016/j.scitotenv.2019.01.187,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
286528899,2019-01-01T00:00:00,"Video-based hand grasp analysis can support both robotics and prosthetics. Indeed, computational aspects represent a major issue, as hand grasp analysis is expected to support grasping systems that are hosted on low-power embedded systems. This paper proposes a framework for video-based grasping classification that is designed for implementation on resourceconstrained devices. The framework adopts a fully data-driven strategy and relies on deep learning to deal with advanced analysis of video signals. Nonetheless, the overall design takes advantage of CNN architectures that can cope with the constraints imposed by embedded systems. The experimental session involved a real-world dataset containing daily life activities collected using egocentric perspective. In addition, the complete inference system is implemented on a NVIDIA Jetson-TX2 obtaining real time performances. The results confirm that the proposed system can suitably balance the trade off between accuracy and computational costs",,'Institute of Electrical and Electronics Engineers (IEEE)',Data-Driven Video Grasping Classification for Low-Power Embedded System,,10.1109/ICECS46596.2019.8964645,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
483665539,2019-01-01T00:00:00,"We report work in progress from interdisciplinary
research on Assisted Living Technology in smart homes for older
adults with mild cognitive impairments or dementia. We present
our field trial, the set-up for collecting and storing data from real
homes, and preliminary results on action recognition using low
resolution depth video cameras. The data have been collected
from seven apartments with one resident each over a period
of two weeks. We propose a pre-processing of the depth videos
by applying an Infinite Response Filter (IIR) for extracting the
movements in the frames prior to classification. In this work
we classify four actions: TV interaction (turn it on/ off and
switch over), standing up, sitting down, and no movement. Our
first results indicate that using the IIR filter for movement
information extraction improves accuracy and can be an efficient
method for recognizing actions. Our current implementation uses
a convolutional long short-term memory (ConvLSTM) neural
network, and achieved an average peak accuracy of 86%",,'Institute of Electrical and Electronics Engineers (IEEE)',Action Recognition in Real Homes using Low Resolution Depth Video Data,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
146941634,2012-02-10,"Monitoring the natural environment is increasingly important as habit degradation and climate change reduce theworld’s biodiversity.We have developed software tools and applications to assist ecologists with the collection and analysis of acoustic data at large spatial and temporal scales.One of our key objectives is automated animal call recognition, and our approach has three novel attributes. \ud
\ud
First, we work with raw environmental audio, contaminated by noise and artefacts and containing calls that vary greatly in volume depending on the animal’s proximity to the microphone. \ud
\ud
Second, initial experimentation suggested that no single recognizer could dealwith the enormous variety of calls. Therefore, we developed a toolbox of generic recognizers to extract invariant features for each call type. Third, many species are cryptic and offer little data with which to train a recognizer.\ud
\ud
Many popular machine learning methods require large volumes of training and validation data and considerable time and expertise to prepare. Consequently we adopt bootstrap techniques that can be initiated with little data and refined subsequently. In this paper, we describe our recognition tools and present results for real ecological problems",Taylor & Francis,A toolbox for animal call recognition,10.1080/09524622.2011.648753,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
55130489,2014,"SIRE(opens in a new window)|View at Publisher|

    Export

    | Download | Add to List	| More... 



European Physical Journal C

Volume 74, Issue 9, 1 September 2014, 8p

Deep sea tests of a prototype of the KM3NeT digital optical module: KM3NeT Collaboration  (Article)



Adrián-Martínez, S.a, 

Ageron, M.b, 

Aharonian, F.c, 

Aiello, S.d, 

Albert, A.e, 

Ameli, F.f, 

Anassontzis, E.G.g, 

Anghinolfi, M.h, 

Anton, G.i, 

Anvar, S.j, 

Ardid, M.a, 

de Asmundis, R.k, 

Balasi, K.l, 

Band, H.m, 

Barbarino, G.kn, 

Barbarito, E.o, 

Barbato, F.kn, 

Baret, B.p, 

Baron, S.p, 

Belias, A.lq, 

Berbee, E.m, 

van den Berg, A.M.r, 

Berkien, A.m, 

Bertin, V.b, 

Beurthey, S.b, 

van Beveren, V.m, 

Beverini, N.st, 

Biagi, S.uv, 

Bianucci, S.t, 

Billault, M.b, 

Birbas, A.w, 

Boer Rookhuizen, H.m, 

Bormuth, R.mx, 

Bouché, V.fy, 

Bouhadef, B.t, 

Bourlis, G.w, 

Bouwhuis, M.m, 

Bozza, C.nz, 

Bruijn, R.maa, 

Brunner, J.b, 

Cacopardo, G.ab, 

Caillat, L.b, 

Calamai, M.t, 

Calvo, D.ad, 

Capone, A.y, 

Caramete, L.ae, 

Caruso, F.ab, 

Cecchini, S.uv, 

Ceres, A.o, 

Cereseto, R.h, 

Champion, C.p, 

Château, F.j, 

Chiarusi, T.u, 

Christopoulou, B.w, 

Circella, M.o, 

Classen, L.i, 

Cocimano, R.ab, 

Colonges, S.p, 

Coniglione, R.ab, 

Cosquer, A.b, 

Costa, M.ab, 

Coyle, P.b, 

Creusot, A.p, 

Curtil, C.b, 

Cuttone, G.ab, 

D’Amato, C.ab, 

D’Amico, A.ab, 

De Bonis, G.f, 

De Rosa, G.kn, 

Deniskina, N.k, 

Destelle, J.-J.b, 

Distefano, C.ab, 

Donzaud, C.pac, 

Dornic, D.b, 

Dorosti-Hasankiadeh, Q.r, 

Drakopoulou, E.l, 

Drouhin, D.e, 

Drury, L.c, 

Durand, D.j, 

Eberl, T.i, 

Eleftheriadis, C.af, 

Elsaesser, D.ag, 

Enzenhöfer, A.i, 

Fermani, P.fy, 

Fusco, L.A.uv, 

Gajana, D.m, 

Gal, T.i, 

Galatà, S.p, 

Gallo, F.b, 

Garufi, F.kn, 

Gebyehu, M.m, 

Giordano, V.d, 

Gizani, N.w, 

Gracia Ruiz, R.p, 

Graf, K.i, 

Grasso, R.ab, 

Grella, G.nz, 

Grmek, A.ab, 

Habel, R.ah, 

van Haren, H.ai, 

Heid, T.i, 

Heijboer, A.m, 

Heine, E.m, 

Henry, S.b, 

Hernández-Rey, J.J.ad, 

Herold, B.i, 

Hevinga, M.A.r, 

van der Hoek, M.m, 

Hofestädt, J.i, 

Hogenbirk, J.m, 

Hugon, C.h, 

Hößl, J.i, 

Imbesi, M.ab, 

James, C.i, 

Jansweijer, P.m, 

Jochum, J.aj, 

de Jong, M.mx, 

Kadler, M.ag, 

Kalekin, O.i, 

Kappes, A.i, 

Kappos, E.gl, 

Katz, U.i, 

Kavatsyuk, O.r, 

Keller, P.b, 

Kieft, G.m, 

Koffeman, E.maa, 

Kok, H.m, 

Kooijman, P.maaak , 

Koopstra, J.m, 

Korporaal, A.m, 

Kouchner, A.p, 

Koutsoukos, S.q, 

Kreykenbohm, I.al, 

Kulikovskiy, V.h, 

Lahmann, R.i, 

Lamare, P.b, 

Larosa, G.ab, 

Lattuada, D.ab, 

Le Provost, H.j, 

Leisos, A.w, 

Lenis, D.w, 

Leonora, E.d, 

Lindsey Clark, M.p, 

Liolios, A.af, 

Llorens Alvarez, C.D.a, 

Löhner, H.r, 

Lo Presti, D.dam, 

Louis, F.j, 

Maccioni, E.s, 

Mannheim, K.ag, 

Manolopoulos, K.gl, 

Margiotta, A.uv, 

Mariş, O.ae, 

Markou, C.l, 

Martínez-Mora, J.A.ad, 

Martini, A.ah, 

Masullo, R.fy, 

Michael, T.m, 

Migliozzi, P.k, 

Migneco, E.ab, 

Miraglia, A.ab, 

Mollo, C.k, 

Mongelli, M.o, 

Morganti, M.t, 

Mos, S.m, 

Moudden, Y.j, 

Musico, P.h, 

Musumeci, M.ab, 

Nicolaou, C.an, 

Nicolau, C.A.f, 

Orlando, A.ab, 

Orzelli, A.h, 

Papageorgiou, K.ao, 

Papaikonomou, A.lw, 

Papaleo, R.ab, 

Păvălaş, G.E.ae, 

Peek, H.m, 

Pellegrino, C.ab, 

Pellegriti, M.G.ab, 

Perrina, C.fy, 

Petridou, C.af, 

Piattelli, P.ab, 

Pikounis, K.l, 

Popa, V.ae, 

Pradier, T.ap, 

Priede, M.aq, 

Pühlhofer, G.aj, 

Pulvirenti, S.ab, 

Racca, C.e, 

Raffaelli, F.t, 

Randazzo, N.d, 

Rapidis, P.A.lq, 

Razis, P.an, 

Real, D.ad, 

Resvanis, L.gq, 

Reubelt, J.i, 

Riccobene, G.ab, 

Rovelli, A.ab, 

Royon, J.b, 

Saldaña, M.a, 

Samtleben, D.F.E.mx, 

Sanguineti, M.ar, 

Santangelo, A.aj, 

Sapienza, P.ab, 

Savvidis, I.af, 

Schmelling, J.m, 

Schnabel, J.i, 

Sedita, M.ab, 

Seitz, T.i, 

Sgura, I.o, 

Simeone, F.f, 

Siotis, I.l, 

Sipala, V.d, 

Solazzo, M.b, 

Spitaleri, A.ab, 

Spurio, M.uv, 

Stavropoulos, G.l, 

Steijger, J.m, 

Stolarczyk, T.as, 

Stransky, D.i, 

Taiuti, M.har, 

Terreni, G.t, 

Tézier, D.b, 

Théraube, S.b, 

Thompson, L.F.at, 

Timmer, P.m, 

Trapierakis, H.I.lq, 

Trasatti, L.ap, 

Trovato, A.ab, 

Tselengidou, M.i, 

Tsirigotis, A.w, 

Tzamarias, S.w, 

Tzamariudaki, E.l, 

Vallage, B.pas, 

Van Elewyck, V.p, 

Vermeulen, J.m, 

Vernin, P.as, 

Viola, S.ab, 

Vivolo, D.kn, 

Werneke, P.m, 

Wiggers, L.m, 

Wilms, J.al, 

de Wolf, E.maa, 

van Wooning, R.H.L.r, 

Yatkin, K.b, 

Zachariadou, K.au, 

Zonca, E.j, 

Zornoza, J.D.ad, 

Zúñiga, J.ad, 

Zwart, A.m

 

View additional authors



a  Instituto de Investigación para la Gestión Integrada de las Zonas Costeras, Universitat Politècnica de València, Gandia, Spain

b  CPPM, Aix-Marseille Université, CNRS/IN2P3, Marseille, France

c  DIAS, Dublin, Ireland

View additional affiliations

View references (22)

Abstract



The first prototype of a photo-detection unit of the future KM3NeT neutrino telescope has been deployed in the deep waters of the Mediterranean Sea. This digital optical module has a novel design with a very large photocathode area segmented by the use of 31 three inch photomultiplier tubes. It has been integrated in the ANTARES detector for in-situ testing and validation. This paper reports on the first months of data taking and rate measurements. The analysis results highlight the capabilities of the new module design in terms of background suppression and signal recognition. The directionality of the optical module enables the recognition of multiple Cherenkov photons from the same40 K decay and the localisation of bioluminescent activity in the neighbourhood. The single unit can cleanly identify atmospheric muons and provide sensitivity to the muon arrival direction",'Springer Science and Business Media LLC',Deep sea tests of a prototype of the KM3NeT digital optical module,10.1140/epjc/s10052-014-3056-3,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
209643445,2005-03-01,"ObjectivesWe sought to investigate the geometric changes of the mitral leaflets and annulus, clarify the maximum tenting site of the leaflets, and quantify the valve tenting in ischemic mitral regurgitation (MR) using three-dimensional (3D) echocardiography.BackgroundAlthough the understanding of the mechanisms of ischemic MR has advanced recently, the geometric changes of the mitral leaflets and annulus have been assessed by two-dimensional echocardiography in the clinical setting, despite the unique configuration of the leaflets and annulus.MethodsUtilizing real-time 3D echocardiography, we obtained transthoracic volumetric images in 12 patients with ischemic MR presenting with global left ventricular dysfunction and in 10 controls. Original software was used to crop the 3D data into 18 radial planes, and we marked the mitral annulus and leaflets in each plane in mid-systole. The 3D images of the leaflets and annulus were reconstructed for the quantitative measurements.ResultsIn ischemic MR, the annulus flattened with apparent tenting of the leaflets. Maximum and mean tenting length were longer and tenting volume was larger in ischemic MR than control subjects (maximum tenting length: 9.8 ± 2.0 mm vs. 3.1 ± 1.2 mm, p < 0.0001, mean tenting length: 3.7 ± 0.9 mm vs. 0.7 ± 0.5 mm, p < 0.0001, tenting volume: 4.09 ± 1.22 ml vs. 0.45 ± 0.29 ml, p < 0.0001). The maximum tenting site was located in anterior leaflet in all patients.ConclusionsWe clearly demonstrated 3D geometric deformity of the mitral leaflets and annulus in ischemic MR using novel software for creating images by 3D echocardiography. This technique will be helpful in making a proper decision for the surgical strategy in each patient",American College of Cardiology Foundation. Published by Elsevier Inc.,Quantitation of mitral valve tenting in ischemic mitral regurgitation by transthoracic real-time three-dimensional echocardiography ,10.1016/j.jacc.2004.11.048,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
200047717,2011-01-01T00:00:00,"International audienceIn this paper, we propose to create a rich database of syn- thetic time series of 3D echocardiography (US) images using simulations of a cardiac electromechanical model, in order to study the relationship between electrical disorders and kinematic patterns visible in medical images. From a real 4D sequence, a software pipeline is applied to create several synthetic sequences by combining various steps including motion tracking and segmentation. We use here this synthetic database to train a machine learning algorithm which estimates the depolarization times of each cardiac segment from invariant kinematic descriptors such as local displacements or strains. First experiments on the inverse electro- kinematic learning are demonstrated on the synthetic 3D US database and are evaluated on clinical 3D US sequences from two patients with Left Bundle Branch Block",'Springer Science and Business Media LLC',Synthetic Echocardiographic Image Sequences for Cardiac Inverse Electro-Kinematic Learning,10.1007/978-3-642-23623-5_63,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
478720738,2004-01-01T00:00:00,"Virtual Reality for Handicap Project nasce con l\u2019obiettivo di approfondire e valutare le potenzialit\ue0 educativo-riabilitative della Realt\ue0 Virtuale, con particolare riferimento all\u2019handicap. Questa tecnologia offre, infatti, la possibilit\ue0 di esperire situazioni cognitivo-motorie complesse attraverso l\u2019interazione con mondi simulati, consentendo di sviluppare aree corticali inutilizzate o sottoutilizzate. Lo studio e la ricerca della Virtual Reality Technology, inquadrata in una prospettiva pedagogica, risulta importante sia nella contestualizzazione del suo utilizzo, evidenziandone pregi e limiti entro progetti educativi finalizzati, che per perseguirne l\u2019introduzione in ambito riabilitativo e rieducativo, attraverso l\u2019uso di hardware e software appositamente creati per il mercato \u201chome\u201de adattati alle esigenze dei disabili. Si \ue8 convinti che attraverso una politica di questo genere, mirata cio\ue8 ad un contenimento dei costi di acquisto del sistema attorno ai 2500-3500\u20ac, sia possibile promuovere l\u2019utilizzo di questa tecnologia in ambito scolastico, sanitario, famigliare, ecc.: riteniamo, infatti, che un uso di tale tecnologia, interpretata in ottica pedagogica, potr\ue0 indurre i produttori a migliorare gli strumenti ora disponibili sul mercato, riducendone ulteriormente i costi e aumentandone la diffusione. L\u2019attuale fase del progetto prevede la realizzazione di diverse attivit\ue0 sperimentali. La prima legata ad esperienze di Realt\ue0 Virtuale (nello specifico di Realt\ue0 Aumentata o Potenziata), le altre mirate a verificare il grado di fruibilit\ue0 di alcune interfacce (NoHands Mouse, CyMouse, ecc. - HOME INTERFACES ANALYSIS). Nel primo caso un campione sperimentale di persone affette da deficit sensoriali viene sottoposto ad alcune esperienze di esplorazione ambientale all\u2019interno di scenari virtuali, contesto di gioco di alcuni videogames di ultima generazione con prospettiva tridimensionale. I canali sensoriali sollecitati sono quello visivo, attraverso l\u2019impiego di visori stereoscopici, nonch\ue9 uditivo, attraverso l\u2019utilizzo di un sistema dolby-surround. Altre interfacce impiegate sono una trackball per le operazioni di puntamento e una comune tastiera per le operazioni di spostamento. Al campione sperimentale si affianca un campione di controllo composto da studenti universitari della Facolt\ue0 di Scienze Motorie. Parallelamente al filone sperimentale sopraccitato sono in corso di svolgimento alcune ricerche collegate e mirate a verificare/valutare l\u2019efficacia e la facilit\ue0 d\u2019uso di alcune periferiche di puntamento e spostamento, coinvolgendo un campione di studenti universitari (MOTOR CONTROL ANALYSIS). Da queste prime indagini verranno tratte indicazioni per inserire nuovi strumenti e nuove variabili nell\u2019ambito della sperimentazione di Realt\ue0 Aumentata con i soggetti diversamente abili. La relazione che verr\ue0 presentata presso il Convegno fornir\ue0 una panoramica delle prime elaborazioni quantitative dei dati fin qui raccolti e una interpretazione qualitativa degli aspetti pedagogici",place:Bergamo,Virtual Reality for Handicap Project:  educational and motor control aspects in virtual reality.,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
291303738,,"Comunicació presentada a la 138th Audio Engineering Society Convention, celebrada a Varsòvia (Polònia) els dies 7 a 10 de maig de 2015 i organitzada per la Audio Engineering Society.This paper presents a system that complements the functionality of a typical tuner by evaluating the sound quality of a music performer in real-time. It consists of a software tool that computes a score of how well single notes are played with respect to a collection of reference sounds. To develop such a tool we first record a collection of single notes played by professional performers. Then, the collection is annotated by music teachers in terms of the performance quality of each individual sample. From the recorded samples, several audio features are extracted and a machine learning method is used to find the features that best described performance quality according to musician’s annotations. An evaluation is carried out to assess thecorrelation between systems predictions and musicians criteria. Results show that the system can reasonably predict musicians annotations of performance quality",'Audio Engineering Society',A real-time system for measuring sound goodness in instrumental sounds,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
82692863,2005-03-01,"ObjectivesWe sought to investigate the geometric changes of the mitral leaflets and annulus, clarify the maximum tenting site of the leaflets, and quantify the valve tenting in ischemic mitral regurgitation (MR) using three-dimensional (3D) echocardiography.BackgroundAlthough the understanding of the mechanisms of ischemic MR has advanced recently, the geometric changes of the mitral leaflets and annulus have been assessed by two-dimensional echocardiography in the clinical setting, despite the unique configuration of the leaflets and annulus.MethodsUtilizing real-time 3D echocardiography, we obtained transthoracic volumetric images in 12 patients with ischemic MR presenting with global left ventricular dysfunction and in 10 controls. Original software was used to crop the 3D data into 18 radial planes, and we marked the mitral annulus and leaflets in each plane in mid-systole. The 3D images of the leaflets and annulus were reconstructed for the quantitative measurements.ResultsIn ischemic MR, the annulus flattened with apparent tenting of the leaflets. Maximum and mean tenting length were longer and tenting volume was larger in ischemic MR than control subjects (maximum tenting length: 9.8 ± 2.0 mm vs. 3.1 ± 1.2 mm, p < 0.0001, mean tenting length: 3.7 ± 0.9 mm vs. 0.7 ± 0.5 mm, p < 0.0001, tenting volume: 4.09 ± 1.22 ml vs. 0.45 ± 0.29 ml, p < 0.0001). The maximum tenting site was located in anterior leaflet in all patients.ConclusionsWe clearly demonstrated 3D geometric deformity of the mitral leaflets and annulus in ischemic MR using novel software for creating images by 3D echocardiography. This technique will be helpful in making a proper decision for the surgical strategy in each patient",American College of Cardiology Foundation. Published by Elsevier Inc.,Quantitation of mitral valve tenting in ischemic mitral regurgitation by transthoracic real-time three-dimensional echocardiography ,10.1016/j.jacc.2004.11.048,https://core.ac.uk/download/pdf/82692863.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
291388760,,"© 20xx IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.Hand-crafted feature functions are usually designed based on the domain knowledge of a presumably controlled environment and often fail to generalize, as the statistics of real-world data cannot always be modeled correctly. Data-driven feature learning methods, on the other hand, have emerged as an alternative that often generalize better in uncontrolled environments. We present a simple, yet robust, 2D convolutional neural network extended to a concatenated 3D network that learns to extract features from the spatio-temporal domain of raw video data. The resulting network model is used for content-based recognition of videos. Relying on a 2D convolutional neural network allows us to exploit a pretrained network as a descriptor that yielded the best results on the largest and challenging ILSVRC-2014 dataset. Experimental results on commonly used benchmarking video datasets demonstrate that our results are state-of-the-art in terms of accuracy and computational time without requiring any preprocessing (e.g., optic flow) or a priori knowledge on data capture (e.g., camera motion estimation), which makes it more general and flexible than other approaches. Our implementation is made available.Peer Reviewe",Institute of Electrical and Electronics Engineers (IEEE),Action recognition based on efficient deep feature learning in the spatio-temporal domain,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
427084953,2013-09-13T00:00:00,"This  paper  demonstrates  a  new  alternative  way  in  estimating seismically thin-bed (below-tuning) thickness. Initial thickness is built by bandpass filtering the amplitude display of a zero-phase seismic. The filter removes the  non  minimum  and  or  non  maximum  and  left  the  maximum  and  or  the minimum of seismic amplitude. The unresolved below-tuning thickness is then corrected  by  zero-INTENS-difference  (z-i-d)  attribute.  INTENS  is  integrated energy  spectra,  an  attribute  which  can  be  derived  from  spectral  analysis.  z-i-d attribute is zero difference of INTENS between the seismic and its synthetic. The method  generates  INTENS  difference  profile  by  subtracting  seismic  INTENS and its synthetic INTENS iteratively. The iteration is controlled by dipole space shifting from  distance to closer or  vice  versa.  The true thickness is derived  by locating z-i-d which laid in INTENS different profile. It has found that, for free noise  true  seismic  and  perfect-wavelet  (a  wavelet  which  only  approximately similar  with  wavelet  which  constructing  the  true  seismic)  synthetic  seismic,  in INTENS  different  profile,  the  z-i-d  location  always  corresponds  to  true  dipole space or thickness. The method could resolve all thickness of a wedge-modeled seismic with three different dominant frequencies. When the synthetic seismic is constructed with imperfect wavelet, slightly different analysis is needed to locate z-i-d  attribute  and  the  result  is  not  as  perfect  as  when  perfect  wavelet constructing synthetic seismic. A quiet similar result is got when the method is implemented  for  noisy  wedge-modeled  seismic.  Bad  thickness  estimation  is resulted  for  20%  noise  seismic.  The  method  algorithm  is  extended  for  similar dipole polarity model and multilayer model to bring the method to real seismic data  nearer.  The  extension  is  done  by  estimating  thickness  of  every  layer  of  a stacked-wedge-modeled  seismic. The algorithm then generalized for estimating layers  thickness  with  several  thickness  combinations.  The  method  was  able  to delineate shallow channel of Stratton Field by providing good pseudo-acousticimpedance (pseudo AI) map",'The Institute for Research and Community Services (LPPM) ITB',Combination of Minimum-Maximum (m-m) Attribute and Zero-INTENS-Difference (z-i-d) Attribute for Estimating Seismically Thin-Bed Thickness,10.5614/itbj.eng.sci.2011.43.2.1,https://core.ac.uk/download/427084953.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226221892,2009-01-01,"This paper presents a discrete-time direct current (DC) motor torque tracking controller, based on a recurrent high order neural network (RHONN) to identify the plant model. Using this model, a control law is derived, which combines block control and sliding modes techniques. The applicability of the scheme is illustrated via real time implementation for a DC motor with separate winding excitation. "" 2009 IEEE."",,,,,,""10.1109/CCA.2009.5280996"",,,""http://hdl.handle.net/20.500.12104/44099"",""http://www.scopus.com/inward/record.url?eid=2-s2.0-74049154211&partnerID=40&md5=0f9e698ef0e77076f1f91ef7889cc5d6"",,,,,,,,""Proceedings of the IEEE International Conference on Control Applications"",,""180",'Maney Publishing',Recombinant murine IL-12 promotes a protective Th1/cellular response in mongolian gerbils infected with sporothrix schenckii,10.1179/1973947814Y.0000000174,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226221850,2014-01-01,"This paper presents the real-time application of a discrete-time inverse optimal control to a three-phase linear induction motor (LIM) in order to achieve trajectory tracking of a position reference. A recurrent high-order neural network (RHONN) is employed on-line to determine the model of the motor. The equipment and software employed are described as well as real-time trajectory tracking results. "" 2014 Springer International Publishing Switzerland."",,,,,,""10.1007/978-3-319-03674-8-16"",,,""http://hdl.handle.net/20.500.12104/44091"",""http://www.scopus.com/inward/record.url?eid=2-s2.0-84891800661&partnerID=40&md5=2c36ef045d7a57bf6707dab0f5de0673"",,,,,,,,""Studies in Fuzziness and Soft Computing"",,""16",'Elsevier BV',"Reactions, characterization and uptake of ammoxidized kraft lignin labeled with 15N",10.1016/j.biortech.2005.08.004,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
224612515,1999-12-01T00:00:00,"A significant body of research on advanced techniques for automated freeway incident detection has been conducted at the University of California, Irvine (UCI). Such advanced pattern recognition techniques as artificial neural networks (ANNs) have been thoroughly investigated and their potential superiority to other techniques has been demonstrated. Of the investigated ANN architectures, two have shown the best potential for real-time implementation: namely, the Probabilistic Neural Network (PNN), (Abdulhai and Ritchie 1997), and the Multi-Layer-Feed-Forward Neural Network (MLF), (Cheu and Ritchie 1995). This project extended existing freeway incident detection research conducted under both PATH and under the ATMS Testbed Research Program, to operationalizes its principal findings. The most prosmising neural network, the PNN, was integrated into the UCI testbed for on line operation on the testbed network in Southern California. The PNN incident detection system was re-coded in Java, to facilitate network communications and platform-independent operation. A Java-based graphical user interface has been developed. The GUI components include a display of the probabilistic neural network (PNN), the current input to the PNN, a sliding window display of the output (the computed incident probability every time step) and a sliding button to allow the user to specify the desired misclassification cost ratio. The GUI code is in the form of a Java Applet object and has a modular structure that makes it easier to incorporate possible future modifications and extensions. The PNN algorithm itself was then translated from C to Java as a stand alone application object and was interfaced to the GUI applet running on the same host. The GUI display is updated each time a new output is computed by the PNN. The PNN algorithm and the GUI display update run as separate threads of control in Java; this concurrency leads to better utilization of CPU resources. A new module for computing the principal component transformation of the volume and occupancy inputs was developed to replace using statistical packages for this transformation. This was needed for maximum portability and independence of the overall system. Another module for computing volume and occupancy historical Averages for different Times and Locations (ATLs.) was alsodeveloped to prepare the ATLs from real freeway data. The PNN and GUI were tested and correct operation was confirmed with sample inputs from data files. The whole package was interfaced to a remote C++ CORBA client program that acquires online CalTrans traffic data from a CORBA server in the Testbed. Communication modules were added to the CORBA client program as well as the PNN to enable online volume and occupancy data from different freeway sections to be sent from the CORBA client to the PNN at a specific rate (once every 30s). The data are sent to the PNN using a reliable TCP/IP streams sockets connection. An on-line retraining module was developed as well. This module enables the TMC operator to initiate retraining on recently captured incident data, on-line without disturbing the operation of the system. The PNN was then started on-line on a 5 mile section of the 405 freeway, for on line monitoring and testing. The overall on-line operation of the PNN was demonstrated to Caltrans engineers from D12. Currently, efforts are in progress to expand the network coverage to enhance the odds of capturing incidents. On line evaluation will be performed next","eScholarship, University of California",Implementation of Advanced Techniques for Automated Freeway Incident Detection,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
46651322,2012-07-01T00:00:00,"El vertiginoso crecimiento de los centros urbanos, las tecnologías emergentes y la demanda de nuevos servicios por parte de la población plantea encaminar esfuerzos hacia el desarrollo de las ciudades inteligentes. Éste concepto ha tomado fuerza entre los sectores político, económico, social, académico, ambiental y civil; de forma paralela, se han generado iniciativas que conducen hacia la integración de la infraestructura, la tecnología y los servicios para los ciudadanos. En éste contexto, una de las problemáticas con mayor impacto en la sociedad es la seguridad vial. Es necesario contar con mecanismos que disminuyan la accidentalidad, mejoren la atención a incidentes, optimicen la movilidad urbana y planeación municipal, ayuden a reducir el consumo de combustible y la emisión de gases de efecto de invernadero, así como ofrecer información dinámica y efectiva a los viajeros. En este artículo se describen dos (2) enfoques que contribuyen de manera eficiente dicho problema: los videojuegos como juegos serios y los sistemas de transporte inteligente. Ambos enfoques están encaminados a evitar colisiones y su diseño e implementación requieren componentes altamente tecnológicos (e.g. sistemas telemáticos e informáticos, inteligencia artificial, procesamiento de imágenes y modelado 3D).The rapid growth of urban centers, the emerging technologies
and the demand for new services by the increasing population
introduce a new challenge: going towards smart cities. This
concept has taken hold among the political, economic, social,
academic, environmental and civil sectors, and several initiatives
leads to the integration of infrastructure, technology and
services for citizens. In this context, road safety and traffic
efficiency became in key issues to be solved. New mechanisms
are needed in order to reduce accidents and its mortality rate,
also requirements such as the optimization of the urban mobility
and municipal planning, fuel consumption and greenhouse gases
emissions reduction and real-time systems that provide dynamic
and effective information to travelers. This article describes
two (2) approaches that contribute efficiently to the traffic
safety problem: video games used as serious games and vehicular
applications for intelligent transportation systems. Both approaches
aims to reduce collisions and required a highly technological
baseline to be implemented (e.g. telematic and computer systems,
artificial intelligence, image processing and 3D modeling)",'Universidad Santiago de Cali',From the Videogame to the Reality: Interactive System for Road Safety,10.18046/syt.v10i22.1259,,"[{'title': 'Sistemas y Telemática', 'identifiers': ['1692-5238', 'issn:1692-5238']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
291327806,,"Automatic assessment of music performance is an open research area widely studied in the past. A vast amount of systems aiming to enhance the learning process of a musical instrument are being developed in the recent years. However, most of the systems focus on the assessment of pitch and onset accuracy, and very few pay attention to tone quality. This is particularly true in violin music education, where although a consensus exist on what is a good or a bad tone quality, there is not a formal definition due to its subjectivity. We present a machine learning approach for the automatic assessment of violin tone quality. We depart from our previous work on the preliminary modelling of several dimensions involving tone quality. Based on recorded examples of tones with different qualities defined and recorded by a professional violinist, we applied machine learning techniques to learn computational models able to evaluate tone quality from extracted audio features. The tone quality models were implemented into a real-time-visual-feedback system.This work has been partly sponsored by the Spanish TIN project TIMUL (TIN2013-48152-C2-2-R), the
European Union Horizon 2020 research and innovation programme under grant agreement No. 688269
(TELMI project), and the Spanish Ministry of Economy and Competitiveness under the Maria de Maeztu
Units of Excellence Programme (MDM-2015-0502)",McGill University,Computational modelling of timbre dimensions for automatic violin tone quality assessment,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
302880831,2010-01-01T00:00:00,"In resource-constrained environments, supply chains for consumables, repairs and calibration of diagnostic equipment are generally poor. To obviate this issue, we propose the use of widely available hardware with a strong supply chain: a cellphone with a hands-free kit. In particular, we focus on the use of the audio channel to determine heart rate (HR) and heart rate variability (HRV) in order to provide a first level screening system for infection. This article presents preliminary work performed on a gold standard database and a cellphone platform. Results indicate that HR and HRV can be accurately assessed from acoustic recordings of heart sounds using only a cellphone and hands-free kit. Heart sound analysis software, which can run on a standard cellphone in real time, has been developed that detects S1 heart sounds with a sensitivity of 92.1% and a positive predictivity of 88.4%. Evaluation of data recorded from cellphones demonstrates that the low-frequency response (<100 Hz) is key to the success of heart sound analysis on cellphones. Noise rejection is also shown to be important. © 2010, Association for the Advancement of Artificial Intelligence",,Intelligent heartsound diagnostics on a cellphone using a hands-free kit,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
35218608,2012-07-01T00:00:00,"El vertiginoso crecimiento de los centros urbanos, las tecnologías emergentes y la demanda de nuevos servicios por parte de la población plantea encaminar esfuerzos hacia el desarrollo de las ciudades inteligentes. Éste concepto ha tomado fuerza entre los sectores político, económico, social, académico, ambiental y civil; de forma paralela, se han generado iniciativas que conducen hacia la integración de la infraestructura, la tecnología y los servicios para los ciudadanos. En éste contexto, una de las problemáticas con mayor impacto en la sociedad es la seguridad vial. Es necesario contar con mecanismos que disminuyan la accidentalidad, mejoren la atención a incidentes, optimicen la movilidad urbana y planeación municipal, ayuden a reducir el consumo de combustible y la emisión de gases de efecto de invernadero, así como ofrecer información dinámica y efectiva a los viajeros. En este artículo se describen dos (2) enfoques que contribuyen de manera eficiente dicho problema: los videojuegos como juegos serios y los sistemas de transporte inteligente. Ambos enfoques están encaminados a evitar colisiones y su diseño e implementación requieren componentes altamente tecnológicos (e.g. sistemas telemáticos e informáticos, inteligencia artificial, procesamiento de imágenes y modelado 3D).The rapid growth of urban centers, the emerging technologies
and the demand for new services by the increasing population
introduce a new challenge: going towards smart cities. This
concept has taken hold among the political, economic, social,
academic, environmental and civil sectors, and several initiatives
leads to the integration of infrastructure, technology and
services for citizens. In this context, road safety and traffic
efficiency became in key issues to be solved. New mechanisms
are needed in order to reduce accidents and its mortality rate,
also requirements such as the optimization of the urban mobility
and municipal planning, fuel consumption and greenhouse gases
emissions reduction and real-time systems that provide dynamic
and effective information to travelers. This article describes
two (2) approaches that contribute efficiently to the traffic
safety problem: video games used as serious games and vehicular
applications for intelligent transportation systems. Both approaches
aims to reduce collisions and required a highly technological
baseline to be implemented (e.g. telematic and computer systems,
artificial intelligence, image processing and 3D modeling)",'Facultad De Ingenieria Universidad Del Zulia',Del videojuego a la realidad : sistema interactivo para la seguridad vial,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
82051586,2014-12-31,"AbstractThe use of proposed technology of Modeling of Intelligent Systems Thinking in Complex Adaptive systems is oriented on use in autonomous, intelligent Fuzzy Control and Information Complex Adaptive systems, that operate in real-time, fuzzy conditions, heterogeneous subject areas and multilingual communications, there the situations are unknown in advance, fuzzy structured and not clearly regulated. The technology consists in extracting of relevant data, information and knowledge from texts (speech) in various natural languages, within dissimilar subject areas for implementation of fuzzy control of data, information and knowledge in light of representing them in knowledge bases and organizing on basis of them the processes of Reasoning and Systems Thinking under uncertainty and in Fuzzy Environment. The technology is formalized using Fuzzy Logic, Situational Control theories, Linguistics, Artificial Intelligence, Knowledge base technologies and is defined by methods of a) Situational Control of fuzzy data, information and knowledge, b) Knowledge Representation, Generalization and Explanation, c) Modeling of Fuzzy Logic Inference, Decision making and Fuzzy Control, d) Intelligent Fuzzy Reasoning and Systems Thinking",The Authors. Published by Elsevier B.V.,Modeling of Intelligent System Thinking in Complex Adaptive Systems ,10.1016/j.procs.2014.09.043,https://core.ac.uk/download/pdf/82051586.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
73574078,2014-04-14T00:00:00,"This paper reviews a cluster of recent and current researches in the field of visual attention conducted at the LEPSIS Lab (IFSTTAR). Taking advantage of the multidisciplinary structure of the research team, contributions have been proposed in the fields of image processing, artificial intelligence, virtual reality, cognitive psychology and ethology. In image processing, we have contributed to predictive models of the gaze fixations in a driving task, namely, looking for road signs, proposing a computational model of top-down visual attention. In artificial intelligence, a simple computational model of visual attention was proposed and implemented in an agent-based microscopic traffic simulation model. In virtual reality, the blink frequency was proposed in order to assess the relevance of driving simulators in terms of the driver's mental workload. In cognitive psychology, the visual conspicuity of powered two wheels was assessed on a driving simulator, leading to recommendations about their lighting system design; another contribution gave evidence that oculomotor patterns can reveal crossing decisions at crossroads. In cognitive ethology, a joint work is in progress with the CEREMA in order to study oculomotor patterns at crossroads in a field test, thanks to a dedicated vehicle.Cet article présente un ensemble de recherches récentes et en cours dans le domaine de l’attention visuelle, menées au laboratoire LEPSIS de l’IFSTTAR. Grâce à la structure pluridisciplinaire du laboratoire, des contributions ont été proposées dans les domaines du traitement d’images, de l’intelligence artificielle, de la réalité virtuelle, de la psychologie cognitive et de l’éthologie. En traitement d’images, nous avons proposé un modèle de calcul de la saillance visuelle des panneaux routiers, en référence à une tâche de conduite. En intelligence artificielle, nous avons implémenté un modèle d’attention visuelle pour améliorer la simulation de trafic microscopique. En réalité virtuelle, nous avons proposé d’utiliser les clignements pour mesurer la charge mentale sur simulateur de conduite. En psychologie cognitive, la saillance visuelle des deux roues motorisés a été étudiée, ce qui a permis d’aboutir à des recommandations sur le design des phares; nous avons également montré que les patterns oculomoteurs peuvent nous informer sur la décision de traverser en carrefour. En ethologie, des travaux conjoints avec le CEREMA sont en cours pour étudier le comportement oculomoteur en carrefour, grâce à un véhicule instrumenté",HAL CCSD,Where we look when we drive: A multidisciplinary approach,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
148440389,2007-01-01T00:00:00,"One primary goal in rescue robotics is to deploy a team of robots for coordinated victim search after a disaster. This requires robots to perform subtasks, such as victim detection, in real-time. Human detection by computationally cheap techniques, such as color thresholding, turn out to produce a large number of false-positives. Markov Random Fields (MRFs) can be utilized to combine the local evidence of multiple weak classifiers in order to improve the detection rate. However, inference in MRFs is computational expensive. In this paper we present a novel approach for the genetic optimizing of the building process of MRF models. The genetic algorithm determines offline relevant neighborhood relations with respect to the data, which are then utilized for generating efficient MRF models from video streams during runtime. Experimental results clearly show that compared to a Support Vector Machine (SVM) based classifier, the optimized MRF models significantly reduce the false-positive rate. Furthermore, the optimized models turned out to be up to five times faster then the non-optimized ones at nearly the same detection rate.Artificial Intelligence & Integrated Computer System",'Institute of Electrical and Electronics Engineers (IEEE)',Genetic MRF Model Optimization for Real-Time Victim Detection in Search and Rescue,10.1109/IROS.2007.4399006,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323317331,2011-01-04T00:00:00,"[EN] This paper proposes a Computational Decision Support System, the Fire Emergency Manager (GCF), designed for assisting a person to make decisions in real time during emergency situations, specifically during a fire in a building. The dynamics of the GCF is based on the estimation of the final state related to each alternative via a net of concepts and some evolution functions that define how the initial state will evolve given a certain alternative. The GCF scores the alternatives computing their expected utility and so, it requires a probability value associated to each possible final state. The estimated values of the criteria that characterize a state are bounded using fuzzy sets, which provide an easy method for assigning probability values. The GCF considers that it could be necessary to carry out simultaneously more than one alternative to mitigate a fire emergency.[ES] Este trabajo propone un Sistema Computacional de Ayuda a la Decisión, el Gestor de Crisis de Fuego (GCF), diseñado para ayudar a una persona a tomar decisiones en tiempo real en situaciones de emergencia, concretamente, en caso de incendio en un edificio. El funcionamiento del GCF se basa principalmente en la estimación del estado final asociado a cada alternativa a través de una red de conceptos y unas funciones de evolución que serán aplicadas al estado inicial. El GCF tiene en cuenta que para mitigar la crisis producida por un incendio pueden ser necesarias varias alternativas ejecutándose simultáneamente.Este  trabajo  se  ha  desarrollado  dentro  del  marco  del  proyecto HESPERIA (CDTI-Programa CENIT-2005).Iglesias, Á.; Del Castillo, MD.; Serrano, JI.; Oliva, J. (2011). Sistema de Ayuda a la Decisión Aplicado a Situaciones de Emergencia en Tiempo Real. Revista Iberoamericana de Automática e Informática industrial. 8(1):80-88. https://doi.org/10.1016/S1697-7912(11)70010-3OJS808881Aamodt, A., & Plaza, E. (1994). Case-Based Reasoning: Foundational Issues, Methodological Variations, and System Approaches. AI Communications, 7(1), 39-59. doi:10.3233/aic-1994-7104Aleskerov, F., Say, A. I., Toker, A., Akin, H. L., & Altay, G. (2005). A cluster-based decision support system for estimating earthquake damage and casualties. Disasters, 29(3), 255-276. doi:10.1111/j.0361-3666.2005.00290.xBonazountas, M., Kallidromitou, D., Kassomenos, P., & Passas, N. (2007). A decision support system for managing forest fire casualties. Journal of Environmental Management, 84(4), 412-418. doi:10.1016/j.jenvman.2006.06.016Church, R. L. (2002). Geographical information systems and location science. Computers & Operations Research, 29(6), 541-562. doi:10.1016/s0305-0548(99)00104-5Hamalainen, R. P., Lindstedt, M. R. K., & Sinkko, K. (2000). Multiattribute Risk Analysis in Nuclear Emergency Management. Risk Analysis, 20(4), 455-468. doi:10.1111/0272-4332.204044Iliadis, L. S. (2005). A decision support system applying an integrated fuzzy model for long-term forest fire risk estimation. Environmental Modelling & Software, 20(5), 613-621. doi:10.1016/j.envsoft.2004.03.006Mowrer, F. W. (2009). Driving Forces for Smoke Movement and Management. Fire Technology, 45(2), 147-162. doi:10.1007/s10694-008-0077-1Overton, I. C. (2005). Modelling floodplain inundation on a regulated river: integrating GIS, remote sensing and hydrological models. River Research and Applications, 21(9), 991-1001. doi:10.1002/rra.867Ray, S. K., & Singh, R. P. (2007). Recent Developments and Practices to Control Fire in Undergound Coal Mines. Fire Technology, 43(4), 285-300. doi:10.1007/s10694-007-0024-6Stylios, C. D., Georgopoulos, V. C., Malandraki, G. A., & Chouliara, S. (2008). Fuzzy cognitive map architectures for medical decision support systems. Applied Soft Computing, 8(3), 1243-1251. doi:10.1016/j.asoc.2007.02.022Zadeh, L. A. (1975). The concept of a linguistic variable and its application to approximate reasoning—I. Information Sciences, 8(3), 199-249. doi:10.1016/0020-0255(75)90036-5Zadeh, L. . (1978). Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets and Systems, 1(1), 3-28. doi:10.1016/0165-0114(78)90029-5Zhang, J., Delichatsios, M., & Colobert, M. (2008). Assessment of Fire Dynamics Simulator for Heat Flux and Flame Heights Predictions from Fires in SBI Tests. Fire Technology, 46(2), 291-306. doi:10.1007/s10694-008-0072-",'Elsevier BV',A Decision Support System Applied to Emergency Situations in Real Time,10.1016/S1697-7912(11)70010-3,http://hdl.handle.net/10251/144669,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
333955122,2013-01-01T00:00:00,"In this paper, hardware optimization of the preprocessing part of a computer aided semen analysis (CASA) system is proposed, which is also implemented on an FPGA device as a working prototype. A real-time cellular neural network (CNN) emulator (RTCNNP-v2) is used for the realization of the image processing algorithms, whose regular, flexible and reconfigurable infrastructure simplifies the prototyping process. For future work, the post-processing part of the CASA system is proposed to be implemented on the same FPGA device as software, using either a soft or hard processor core. By the integration of the pre- and post-processing parts, the designed CASA system will be capable of processing full-HD 1080p@60 (1080×1920) video images in real-time.Publisher's Versio",'Institute of Electrical and Electronics Engineers (IEEE)',Realization of preprocessing blocks of CNN based CASA system on FPGA,10.1109/ECCTD.2013.6662238,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
34996307,2013-01-01T00:00:00,"Efficient and reliable simulation tools are essential for progress in brain research. Since the early days of neuronal computing (Farley & Clark, 1954), a wide range of simulators have been developed, each specialized on one or few spatial and temporal scales (Brette et al., 2007). But the reliable and reproducible simulation of such complex systems as the brain is a very demanding challenge. Thus, the Computational Neuroscience community concentrated on a few reliable and widely used simulation tools in recent years. Neuronal network simulation is thus coming of age: Just as our colleagues in electrophysiology, we begin to base our work increasingly on the use of standard tools, with modifications and adaptations for our particular research, instead of building home-brew solutions from scratch. This concentration was not least the result of a series of large-scale EU funded projects, such as FACETS, BrainScaleS and the recently announced Human Brain Project.From its humble beginnings as a PhD-student project 20 years ago, the Neural Simulation Tool NEST (Gewaltig & Diesmann, 2007) saw its first incarnation as the SYNOD simulator in 1995 (Diesmann et al., 1995), leading to exciting results on synfire chains early on (Diesmann et al., 1999). By tightly coupling software development with computational neuroscience research (Kunkel et al., 2010), simulator technology evolved steadily, facilitating new scientific insight at (nearly) every step. Some key examples were parallelization (Morrison et al., 2005; Plesser et al., 2007), exact integration of model equations (Rotter & Diesmann, 1999), precise spike times in a time-driven simulator (Morrison et al., 2007; Hanuschkin et al., 2010), spike- time-dependent (Morrison et al., 2007) and neuro-modulated plasticity (Potjans et al., 2010), and a Topology module for spatially structured networks (Plesser & Enger, 2013). Streamlined data-structures (Kunkel et al., 2011) allow NEST to efficiently exploit the capabilities of some of the largest computers on Earth for simula- tions on the brain scale (Helias et al., 2012). Systematic quality assurance through testsuites (Eppler et al., 2009) and continuous integration technology (Zaytsev & Morrison, 2013) ensure simulator reliability (within limits). With a user-friendly Python-based interface (Eppler et al., 2008; Gewaltig et al., 2012), integration with PyNN (Davison et al., 2008) for simulator-independent scripting and MUSIC support (Djurfeldt et al., 2010) for integrated multi-scale simulation, NEST is a powerful simulation tool for brain-scale simulations today.NEST has been publicly available since 2004 and has been taught at summer schools and graduate courses since, training a generation of computational scientists. This has lead to a steady increase in computational neuroscience publications based on NEST simulations in recent years (see http://www.nest-initiative.org for a list), indicating that NEST is indeed establishing itself as a widely used tool for the simulation of large networks of (comparatively) simple model neurons.As of the NEST 2.0 release in 2012, NEST is available under the GNU Public License to ensure wide dissemination. The further development of NEST is chaperoned by the NEST Initiative, a non-for-profit organization incorporated in Ecublens, Switzerland, which is open for interested scientists. We are currently preparing to move NEST source code to a distributed version control system, allowing all NEST users ”real time” access to bug fixes and improvements, and to facilitate contributions by the NEST Community.In our demonstration, we will illustrate the capabilities and versatility of NEST. We will in particular focus on three complementary approaches to simulating large-scale cortical networks: A data-driven approach based on detailed connectivity information (based on data from the Blue Brain Project), constructive network generation, based on connectivity patterns (Potjans & Diesmann, 2012), and simulation of advanced 3D topological networks.AcknowledgementsWe present this work on behalf of the NEST Initiative. Many institutions have supported NEST development including: Weizmann Institute, U Bochum, U & BCCN Freiburg, Honda Research Institute Europe, MPI for Fluid Dynamics, Norwegian U of Life Sciences, RIKEN Brain Science Institute, Helmholtz Gesellschaft and Forschungszentrum Jülich, EPFL and BlueBrainProject, EU grants FACETS (FP6-15879) and BrainScales (FP7-269921) and Research Council of Norway grant eNeuro (178892/V30).ReferencesBrette, R., Rudolph, M., Carnevale, T., Hines, M., Beeman, D., Bower, J. M., Diesmann, M., Morrison, A., Goodman, P. H., Jr., F. C. H., Zirpe, M., Natschläger, T., Pecevski, D., Ermentrout, B., Djurfeldt, M., Lansner, A., Rochel, O., Vieville, T., Muller, E., Davison, A. P., Boustani, S. E., & Destexhe, A. (2007). Simulation of networks of spiking neurons: A review of tools and strategies. J Comput Neurosci 23, 349–398.Davison, A., Brüderle, D., Eppler, J., Kremkow, J., Muller, E., Pecevski, D., Perrinet, L., & Yger, P. (2008). PyNN: a common interface for neuronal network simulators. Front Neuroinform 2, 11.Diesmann, M., Gewaltig, M.-O., & Aertsen, A. (1995). SYNOD: an environment for neural sytems simula- tions. language interface and tutorial. Technical Report GC-AA-/95-3, The Weizmann Instiute of Science, The Grodetsky Center for Research of Higher Brain Functions, Weizmann Institute of Science, Israel.Diesmann, M., Gewaltig, M.-O., & Aertsen, A. (1999). Conditions for stable propagation of synchronous spiking in cortical neural networks. Nature 402, 529–533.Djurfeldt, M., Hjorth, J., Eppler, J. M., Dudani, N., Helias, M., Potjans, T. C., Bhalla, U. S., Diesmann, M., Kotaleski, J. H., & Ekeberg, O. (2010). Run-time interoperability between neuronal network simulators based on the music framework. Neuroinformatics 8(1), 43–60.Eppler, J. M., Helias, M., Muller, E., Diesmann, M., & Gewaltig, M.-O. (2008). PyNEST: A convenient interface to the NEST simulator. Front Neuroinformatics 2, 12.Eppler, J. M., Kupper, R., Plesser, H. E., & Diesmann, M. (2009). A testsuite for a neural simulation engine. In Frontiers in Neuroinformatics. Conference Abstract: 2nd INCF Congress of Neuroinformatics, Plzen. International Neuroinformatics Coordinating Facility.Farley, B. G., & Clark, W. A. (1954). Simulation of self-organized systems by digital computer. IEEE Trans Info Theory IT-4, 76–84.Gewaltig, M.-O., & Diesmann, M. (2007). Nest (neural simulation tool). Scholarpedia 2(4), 1430.Gewaltig, M.-O., Morrison, A., & Plesser, H. E. (2012). NEST by example: An introduction to the neural simulation tool NEST. In N. Le Novère (Ed.), Computational Systems Neurobiology, Chapter 18, pp. 533–558. Dordrecht: Springer Science+Business Media.Hanuschkin, A., Kunkel, S., Helias, M., Morrison, A., & Diesmann, M. (2010). A general and efficient method for incorporating exact spike times in globally time-driven simulations. Front Neuroinformatics 4, 113.Helias, M., Kunkel, S., Masumoto, G., Igarashi, J., Eppler, J. M., Ishii, S., Fukai, T., Morrison, A., & Diesmann, M. (2012). Supercomputers ready for use as discovery machines for neuroscience. Front Neuroinform 6, 26.Kunkel, S., Eppler, J. M., Plesser, H. E., Gewaltig, M.-O., Diesmann, M., & Morrison, A. (2010). NEST: Science-driven development of neuronal network simulation software. In Frontiers in Neuroscience. Conference Abstract: Neuroinformatics 2010.Kunkel, S., Potjans, T. C., Eppler, J. M., Plesser, H. E., Morrison, A., & Diesmann, M. (2011). Meeting the memory challenges of brain-scale network simulation. Front. Neuroinform. 5, 35.Morrison, A., Aertsen, A., & Diesmann, M. (2007). Spike-time dependent plasticity in balanced recurrent networks. Neural Comput 19, 1437–1467.Morrison, A., Mehring, C., Geisel, T., Aertsen, A., & Diesmann, M. (2005). Advancing the boundaries of high connectivity network simulation with distributed computing. Neural Comput 17, 1776–1801.Morrison, A., Straube, S., Plesser, H. E., & Diesmann, M. (2007). Exact subthreshold integration with continuous spike times in discrete time neural network simulations. Neural Comput 19, 47–79.Plesser, H. E., & Enger, H. (2013). Nest topology user manual.Plesser, H. E., Eppler, J. M., Morrison, A., Diesmann, M., & Gewaltig, M.-O. (2007). Efficient parallel simulation of large-scale neuronal networks on clusters of multiprocessor computers. In A.-M. Kermarrec, L. Bougé, & T. Priol (Eds.), Euro-Par 2007: Parallel Processing, Volume 4641 of Lecture Notes in Computer Science, Berlin, pp. 672–681. Springer-Verlag.Potjans, T. C., & Diesmann, M. (2012). The cell-type specific cortical microcircuit: Relating structure and activity in a full-scale spiking network model. Cereb Cortex.Potjans, W., Morrison, A., & Diesmann, M. (2010). Enabling functional neural circuit simulations with distributed computing of neuromodulated plasticity. Front Comput Neurosci 4, 141.Rotter, S., & Diesmann, M. (1999). Exact digital simulation of time-invariant linear systems with applications to neuronal modeling. Biol Cybern 81, 381–402.Zaytsev, Y. V., & Morrison, A. (2013). Increasing quality and managing complexity in neuroinformatics software development with continuous integration. Front Neuroinform 6, 31",Frontiers Research Foundation,20 Years of NEST: A Mature Brain Simulator,10.3389/conf.fninf.2013.09.00106,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
53980494,2009-01-01T00:00:00,"The notion of equivalent number of degrees of freedom (e.d.f.) has been recently proposed in the context of neural network modeling for small data sets. This quantity is much smaller than the number of the parameters in the network and it does not depend on the number of input variables. In this paper, we present numerical studies on both real and simulated data sets assuring the validity of e.d.f. in a general framework. Results confirm that e.d.f. performs more reliably than the total number W of adaptive parameters - which are usually assumed equal to the degrees of freedom of the model in common statistical softwares - for analyzing and comparing neural models. Numerical studies also point out that e.d.f. works well in estimating the error variance and constructing approximate confidence intervals. We then propose a comparison among some model selection criteria and results show that for neural networks GCV performs slightly better. We finally present a simple forward procedure which can be easily implemented for automatically selecting a neural model with good trade-off between learning error and generalization properties",country:IND,Computational studies with equivalent degrees of freedoms in neural networks,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
55606136,2004-01-01T00:00:00,"A novel meso reactor based on oscillatory flow technology (Harvey et al., 2001) has been
recently presented in Harvey et al. (2003) as a new technology for reaction engineering and
particle suspension applications. Due to the demonstrated enhanced performances for fluid micro
mixing and suspension of catalyst beads and to the small volume of the reactor, this novel
miniature reactor is suitable for applications at specialist chemical manufacture and high
throughput screening. Furthermore, a high control of environment conditions (e.g. mixing
intensity, temperature) coupled with an online monitoring turns this reactor suitable for smallscale
applications to the bioengineering field, such as for fast parallel bioprocessing tasks.
This work concerns with the fluid dynamics characterisation of a novel miniature reactor.
Experimental results using state-of-art fibre-optic technology is used in order to demonstrate that
an accurate control of the residence time distribution (RTD) of liquid and solid phases can be
achieved within this reactor as well as enhanced (oxygen) mass transfer rates. Furthermore,
numerical simulations using Fluent ® software will be presented where simulated RTDs agrees
with the experimental results.
The meso reactor unit consists of 4.4 mm internal diameter and 35 cm long jacketed glass tubes,
with a unit volume of 4.5 ml and provided with smooth periodic constrictions (SPCs), with an
average baffle spacing of 13 mm. The internal diameter at the constricted zone (baffle internal
diameter) is 1.6 mm, leading to a reduction of the baffle free are of 87 %. This unit is able to
support batch or continuous operations mode, simply by configuring the tubes in parallel or in
series, according to the intended application. Mixing is achieved by oscillating the fluid at the
bottom or the top of the reactor by means of a piston pump, using oscillation amplitudes and
frequencies ranging from 0 to 4 mm centre-to-peak and 0 to 25 Hz, respectively.
Experimental studies using the Particle Image Velocimetry (PIV) technique (Harvey et al., 2003)
showed that different fluid mechanics are originated at different oscillation conditions
(oscillation amplitudes and frequencies). A plug flow or a stirred tank behaviour can be obtained
just by controlling the oscillation conditions. At low oscillatory Reynolds numbers (Reo), e.g. 10
to 100, the formation of axisymmetric eddies detached from the constrictions is coupled with low
axial velocities and makes it possible to continuously operate the reactor in a plug flow mode.
Increasing the Reo to values higher than 100, the eddy symmetry is broken and a complete
mixing state is achieved inside the meso reactor. Low oscillation amplitudes must be used if
axial dispersion is intended to be minimized, namely at plug flow setup.
Through an overall oscillation cycle, changes of the location of the main flow stream from near
the wall to the centre of each cavity and vice-versa was observed and is expected to lead to high
mass and heat transfer rates (Perry, 2002). Due to the observed high radial velocities, narrow
residence times distributions are expected to be obtained (Perry, 2002). Also high axial
circulation rates were also observed at high Reos (above 100) and it was proved to lead to an
enhanced performance on catalyst beads suspension. The relation of this fluid mechanics with
the real performance of this novel meso reactor will be demonstrated.
Tracer injection technique is applied to perform RTD studies inside a single SPC tube of the
meso reactor. Spectroscopy UV/VIS technique is used to measure the concentration of a
coloured tracer at the inlet and outlet (at continuous mode) or at the bottom and the top of the
tube (at batch mode). A fibre optic apparatus is employed in order to obtain highly accurate
online measurements of the UV/VIS absorbance. Mixing times are calculated for experiments at
batch mode. Different flow rates are used to determine the effect of the flow rate over the RTD at
continuous operation and axial dispersion is presented by the Bodenstein number, Bo.
Determination of KL.a values is achieved by online measurement of the oxygen concentration
using a special fibre optic probe. The working tip of the probe was dip-coated with a ruthenium
complex immobilised in a sol-gel matrix. This complex is excited to fluorescence by a blue led
(470 nm outpuk peak) and the level of the fluorescence is inversely related to the concentration
of the oxygen through the Stern-Volmer equation (Wang et al., 1999), which is measured by the
fibre-optic apparatus. Retention of solid phases (e.g. catalyst beads and yeast cells) inside the
meso reactor will also be tested.
Further studies using the Computation Fluid Dynamics (CFD) technique will be presented where
accurate prediction of the distribution of residence times is achieved. The use of the distributionfunctions
permits to classify the flow behaviour inside this novel meso reactor patterns and to
calculate mixing efficiencies and axial dispersion coefficients (expressed by the Bo number) at
different oscillation conditions.
A simple 2-D axisymmetric laminar model showed good agreement with flow patterns
visualisations using PIV for Reo below 100 but a 3-D model with a very fine mesh was required
to simulate breakage of axisymmetry. Consequently, 3-D models based on laminar and Large
Eddy Simulations (LES) will be used to maximize the matching of RTD at higher oscillation
conditions. Main intended application of CFDs to this novel meso reactor is the design of a meso
reactor unit, which could operate at the best oscillation conditions and flow rate for cell cultures
and biocatalyst applications",,Residence times and mixing of a novel continuous oscillatory flow meso reactor,,https://core.ac.uk/download/55606136.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
295401191,2013-10-01T00:00:00,"The 3D modeling techniques applied on laser scanner data are becoming increasingly relevant in the cultural heritage dissemination field. Howe- ver the need for a satisfactory similarity between model and real object collides with the need to preserve the original accuracy of the measure- ment of the former than the latter. The analysis of the Compañía de Jesús facade has tried to cope this duality using the power of reverse modeling and texturing, the latter is really important due to the function of the photographic images into accurate description of materials and colours, as well as in the creation of 3D models using UV mapping tools, which are a very advanced field of the computer graphic software.Nell’ ambito delle ricerche scientifiche sui beni culturali le tecniche di modellazione 3D applicate ai dati provenienti da campagne di rilevamento scanner laser stanno assumendo sempre più importanza. Tuttavia l’esigenza di una soddisfacente verosimiglianza del modello rispetto all’oggetto si scontra con la necessità di preservare l’originaria accuratezza della misurazione del primo rispetto al secondo. Nello studio della facciata della chiesa della Compañía de Jesús si è cercato di far fronte a tale dicotomia sfruttando le potenzialità del reverse modelling e del texturing; quest’ultimo di grande rilievo data la funzione che rivestono le immagini fotografiche nella descrizione accurata delle qualità materiche e cromatiche dei manufatti, così come nel processo stesso di realizzazione del modello 3D mediante strumenti di mappatura UV, che rappresentano un comparto molto evoluto dei programmi di computer graphic","Alma Mater Studiorum, Università di Bologna",Texturing e ottimizzazione dei modelli digitali reality based: la chiesa della Compañía de Jesús,10.6092/issn.1828-5961/3868,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
11276235,2011-01-01T00:00:00,"Various micro-devices have been used to assess single cell mechanical properties. Here, we designed and implemented a novel, mechanically actuated, two dimensional cell culture system that enables a measure of cell stiffness based on quantitative functional imaging of cell-substrate interaction. Based on parametric finite element design analysis, we fabricated a soft (5 kPa) polydimethylsiloxane (PDMS) cell substrate coated with collagen-I and fluorescent micro-beads, thus providing a favorable terrain for cell adhesion and for substrate deformation quantification, respectively. We employed a real-time tracking system that analyzes high magnification images of living cells under stretch, and compensates for gross substrate motions by dynamic adjustment of the microscope stage. Digital image correlation (DIC) was used to quantify substrate deformation beneath and surrounding the cell, leading to an estimate of cell stiffness based upon the ability of the cell to resist the applied substrate deformation. Sensitivity of the system was tested using chemical treatments to both ""soften"" and ""stiffen"" the cell cytoskeleton with either 0.5 μg/ml Cytochalasin-D or 3% Glutaraldehyde, respectively. Results indicate that untreated osteosarcoma cells (SAOS-2) exhibit a 1.5 ± 0.7% difference in strain from an applied target substrate strain of 8%. Compared to untreated cells, those treated with Cyochalasin-D passively followed the substrate (0.5 ± 0.5%, p < 0.001), whereas Glutaraldehyde enhanced cellular stiffness and the ability to resist the substrate deformation (2.9 ± 1.6%, p < 0.001). Nano-indentation testing showed differences in cell stiffness based on culture treatment, consistent with DIC findings. Our results indicate that mechanics and image analysis approaches do hold promise as a method to quantitatively assess tensile cell constitutive properties",'Springer Science and Business Media LLC',A novel method for assessing adherent single-cell stiffness in tension: design and testing of a substrate-based live cell functional imaging device,10.1007/s10544-010-9493-3,https://www.zora.uzh.ch/id/eprint/43527/1/ZORA_NL_43527.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275618948,2013-01-01T00:00:00,"The final publication is available at Springer via  http://dx.doi.org/10.1007/978-3-319-00551-5_24This paper presents the work in progress of a mobile-based distributed system which aims to minimize the social impact of abandoned or lost animals. System is based on the use of smart mobile devices to provide message warnings of animals localized. Messages are stored in a database to be processed. In order to enter data such as photography, audio and artificial images, system uses different mobile device interfaces. Data processing consists mainly in matching localized animals with lost animals, assigning abandoned animals at shelters and generating notifications for animal shelters or authorities. Currently, the system is in the development phase. The technical challenges in which we are working are to optimize data and metadata matching, and the management of message warning.The study described in this paper is a part of the coordinated project COBAMI: Mission-based Hierarchical Control. Education and Science Department, Spanish Government. CICYT: MICINN: DP1201 1-28507-C02-01/02.Garrote-Hildebrand, D.; Poza-Lujan, J.; Posadas-Yagüe, J.; Simó Ten, JE. (2013). Mobile-Based Distributed System for Managing Abandoned or Lost Pets. En Distributed Computing and Artificial Intelligence. Springer. 197-200. https://doi.org/10.1007/978-3-319-00551-5_24S197200Lord, L.K., Wittum, T.E., Ferketich, A.K., Funk, J.A., Rajala-Schultz, P.J.: Search methods that people use to find owners of lost pets. Journal of the Veterinary Association 230(12), 1835–1840 (2007)Weiss, E., Slater, M., Lord, L.: Frequency of Lost Dogs and Cats in the United States and the Methods Used to Locate Them. Animals 2, 301–315 (2012)Laplante, P.A.: Exciting Real-Time Location Applications. IT Professional 13(2), 4–5 (2011), doi:10.1109/MITP.2011.22IFPUG (International Function Point Users Group). The IFPUG Guide to IT and Software Measurement. Auerbach Publications (2012)Yun, L., Peiji, S.: Applying RFID to the pet’s information management to realize collaboration. In: 7th Int. Conf. on Proc. Serv. Syst. Serv. Manage., Tokyo, Japan, pp. 1–6 (2010)Android SDK, http://developer.android.com/sdkClarck, J.E., Johnson, P.B.: Sencha Touch Mobile Javascript Framework. Packt Publishing (2012",'Springer Science and Business Media LLC',Mobile-Based Distributed System for Managing Abandoned or Lost Pets,10.1007/978-3-319-00551-5_24,https://riunet.upv.es/bitstream/handle/10251/72767/versi%c3%b3n%20de%20autor.pdf?sequence=3&isAllowed=y,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275598738,2013-01-01T00:00:00,"The bale collecting problem (BCP) appears after harvest operations in grain and other crops. Its solution defines the sequence of collecting bales which lie scattered over the field. Current technology on navigation-aid systems or auto-steering for agricultural vehicles and machines, is able to provide accurate data to make a reliable bale collecting planning. This paper presents a hybrid genetic algorithm (HGA) approach to address the BCP pursuing resource optimization such as minimizing non-productive time, fuel consumption, or distance travelled. The algorithmic route generation provides the basis for a navigation tool dedicated to loaders and bale wagons. The approach is experimentally tested on a set of instances similar to those found in real situations. In particular, comparative results show an average improving of a 16% from those obtained by previous heuristics.This work was supported in part by the Spanish Government (research project AGL2010-15334).Gracia Calandin, CP.; Diezma Iglesias, B.; Barreiro Elorza, P. (2013). A hybrid genetic algorithm for route optimization in the bale collecting problem. Spanish Journal of Agricultural Research. 11(3):603-614. https://doi.org/10.5424/sjar/2013113-3635S603614113Amiama, C., Bueno, J., Álvarez, C. J., & Pereira, J. M. (2008). Design and field test of an automatic data acquisition system in a self-propelled forage harvester. Computers and Electronics in Agriculture, 61(2), 192-200. doi:10.1016/j.compag.2007.11.006Baker, B. M., & Ayechew, M. A. (2003). A genetic algorithm for the vehicle routing problem. Computers & Operations Research, 30(5), 787-800. doi:10.1016/s0305-0548(02)00051-5Baykasolu, A., Oumlzbakr, L., & Tapk, P. (2007). Artificial Bee Colony Algorithm and Its Application to Generalized Assignment Problem. Swarm Intelligence, Focus on Ant and Particle Swarm Optimization. doi:10.5772/5101Bentley, J. J. (1992). Fast Algorithms for Geometric Traveling Salesman Problems. ORSA Journal on Computing, 4(4), 387-411. doi:10.1287/ijoc.4.4.387Bochtis, D. D., & Sørensen, C. G. (2009). The vehicle routing problem in field logistics part I. Biosystems Engineering, 104(4), 447-457. doi:10.1016/j.biosystemseng.2009.09.003Bochtis, D. D., & Sørensen, C. G. (2010). The vehicle routing problem in field logistics: Part II. Biosystems Engineering, 105(2), 180-188. doi:10.1016/j.biosystemseng.2009.10.006Bochtis, D. D., Dogoulis, P., Busato, P., Sørensen, C. G., Berruto, R., & Gemtos, T. (2013). A flow-shop problem formulation of biomass handling operations scheduling. Computers and Electronics in Agriculture, 91, 49-56. doi:10.1016/j.compag.2012.11.015Brady, R. M. (1985). Optimization strategies gleaned from biological evolution. Nature, 317(6040), 804-806. doi:10.1038/317804a0Chen, J.-S., Pan, J. C.-H., & Lin, C.-M. (2008). A hybrid genetic algorithm for the re-entrant flow-shop scheduling problem. Expert Systems with Applications, 34(1), 570-577. doi:10.1016/j.eswa.2006.09.021Cook, S. E., & Bramley, R. G. V. (1998). Precision agriculture — opportunities, benefits and pitfalls of site-specific crop management in Australia. Australian Journal of Experimental Agriculture, 38(7), 753. doi:10.1071/ea97156Cordeau, J.-F., Gendreau, M., Laporte, G., Potvin, J.-Y., & Semet, F. (2002). A guide to vehicle routing heuristics. Journal of the Operational Research Society, 53(5), 512-522. doi:10.1057/palgrave.jors.2601319Dantzig, G., Fulkerson, R., & Johnson, S. (1954). Solution of a Large-Scale Traveling-Salesman Problem. Journal of the Operations Research Society of America, 2(4), 393-410. doi:10.1287/opre.2.4.393Dasgupta, D. (Ed.). (1999). Artificial Immune Systems and Their Applications. doi:10.1007/978-3-642-59901-9Davis L, 1985. Job shop scheduling with genetic algorithms. Proc of the First Int Conf on Genetic Algorithms and their Applications, Pittsburg, PA (USA). July 24-26. pp: 136-140.De Castro LN, Timmis J, 2002. Artificial immune systems: a new computational approach. Springer-Verlag Inc, London, UK.Dorigo, M., Birattari, M., Blum, C., Gambardella, L. M., Mondada, F., & Stützle, T. (Eds.). (2004). Ant Colony Optimization and Swarm Intelligence. Lecture Notes in Computer Science. doi:10.1007/b99492Eksioglu, B., Vural, A. V., & Reisman, A. (2009). The vehicle routing problem: A taxonomic review. Computers & Industrial Engineering, 57(4), 1472-1483. doi:10.1016/j.cie.2009.05.009Garey MR, Johnson DS, 1979. Computers and intractability: a guide to the theory of NP-completeness. WH Freeman & Company, NY.Gillett, B. E., & Miller, L. R. (1974). A Heuristic Algorithm for the Vehicle-Dispatch Problem. Operations Research, 22(2), 340-349. doi:10.1287/opre.22.2.340Goldberg DE, 1989. Genetic algorithms in search, optimization and machine learning. Kluwer Acad Publ, Boston, MA, USA.Gracia, C., Andrés, C., & Gracia, L. (2011). A hybrid approach based on genetic algorithms to solve the problem of cutting structural beams in a metalwork company. Journal of Heuristics, 19(2), 253-273. doi:10.1007/s10732-011-9187-xGrisso RD, Cundiff JS, Vaughan DH, 2007. Investigating machinery management parameters with computers tools, ASABE Conf, Paper 071030.Hameed, I. A., Bochtis, D. D., Sørensen, C. G., & Vougioukas, S. (2012). An object-oriented model for simulating agricultural in-field machinery activities. Computers and Electronics in Agriculture, 81, 24-32. doi:10.1016/j.compag.2011.11.003Holland JH, 1975. Adaptation in natural and artificial systems (Holland JH, ed.). Ann Arbor MI Univ of Michigan Press, MI, USA.Jünger M, Reinelt G, Rinaldi G, 1995. The traveling salesman problem. In: Network models. Handbooks on Operations Research and Management Science 7 (Ball MO, Magnanti TL, Monma CL, Nemhauser GL, eds.). Elsevier, Amsterdam, pp: 225-330.Kennedy JF, Kennedy J, Eberhart R, Shi Y, 2001. Swarm intelligence. Academic Press Inc, London.Laporte, G., Gendreau, M., Potvin, J.-Y., & Semet, F. (2000). Classical and modern heuristics for the vehicle routing problem. International Transactions in Operational Research, 7(4-5), 285-300. doi:10.1111/j.1475-3995.2000.tb00200.xMartin O, Otto SW, Felten EW, 1991. Large-step markov chains for the travelling salesman problem. Complex Syst 5(3): 299-326.Nikkilä, R., Seilonen, I., & Koskinen, K. (2010). Software architecture for farm management information systems in precision agriculture. Computers and Electronics in Agriculture, 70(2), 328-336. doi:10.1016/j.compag.2009.08.013Sørensen, C. G., Pesonen, L., Bochtis, D. D., Vougioukas, S. G., & Suomi, P. (2011). Functional requirements for a future farm management information system. Computers and Electronics in Agriculture, 76(2), 266-276. doi:10.1016/j.compag.2011.02.005Toth, P., & Vigo, D. (2002). 2. Branch-And-Bound Algorithms for the Capacitated VRP. The Vehicle Routing Problem, 29-51. doi:10.1137/1.9780898718515.ch2Wang, C.-H., & Lu, J.-Z. (2008). An effective evolutionary algorithm for the practical capacitated vehicle routing problems. Journal of Intelligent Manufacturing, 21(4), 363-375. doi:10.1007/s10845-008-0185-2Zhang, N., Wang, M., & Wang, N. (2002). Precision agriculture—a worldwide overview. Computers and Electronics in Agriculture, 36(2-3), 113-132. doi:10.1016/s0168-1699(02)00096-",'Instituto Nacional de Investigacion y Tecnologia Agraria y Alimentaria (INIA)',A hybrid genetic algorithm for route optimization in the bale collecting problem,10.5424/sjar/2013113-3635,https://riunet.upv.es/bitstream/handle/10251/45759/Gracia%3bPILAR%20BARREIRO%20ELORZA%3bBel%c3%a9n%20-%20A%20hybrid%20genetic%20algorithm%20for%20route%20optimization%20in%20the%20bal....pdf?sequence=1&isAllowed=y,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
29405426,2011-11-01T00:00:00,"Autonomy is a prime issue on robotics field and it is closely related to decision making. Last researches on decision making for social robots are focused on biologically inspired mechanisms for taking decisions. Following this approach, we propose a motivational system for decision making, using internal (drives) and external stimuli for learning to choose the right action. Actions are selected from a finite set of skills in order to keep robot's needs within an acceptable range. The robot uses reinforcement learning in order to calculate the suitability of every action in each state. The state of the robot is determined by the dominant motivation and its relation to the objects presents in its environment. The used reinforcement learning method exploits a new algorithm called Object Q-Learning. The proposed reduction of the state space and the new algorithm considering the collateral effects (relationship between different objects) results in a suitable algorithm to be applied to robots living in real environments. In this paper, a first implementation of the decision making system and the learning process is implemented on a social robot showing an improvement in robot's performance. The quality of its performance will be determined by observing the evolution of the robot's wellbeing.The funds provided by the Spanish Government through the project called “Peer
to Peer Robot-Human Interaction” (R2H), of MEC (Ministry of Science and Education), the project “A new approach to social robotics” (AROS), of MICINN (Ministry of Science and Innovation), and the RoboCity2030-II-CM project (S2009/DPI-1559), funded by Programas de Actividades I+D en la Comunidad de Madrid and cofunded by Structural Funds of the EU",'Springer Science and Business Media LLC',Learning the selection of actions for an autonomous social robot by reinforcement learning based on motivations,10.1007/s12369-011-0113-z,https://core.ac.uk/download/29405426.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
287318677,2014-03-24T00:00:00,"Safety concerns in the operation of autonomous aerial systems require safe-landing protocols be followed during situations where the mission should be aborted due to mechanical or other failure. This article presents a pulse-coupled neural network (PCNN) to assist in the vegetation classification in a vision-based landing site detection system for an unmanned aircraft. We propose a heterogeneous computing architecture and an OpenCL implementation of a PCNN feature generator. Its performance is compared across OpenCL kernels designed for CPU, GPU, and FPGA platforms. This comparison examines the compute times required for network convergence under a variety of images to determine the plausibility for real-time feature detection. 

  References       Altera. Implementing FPGA design with the OpenCL standard. White Paper, Altera Inc., November 2012. http://www.altera.com/literature/wp/wp-01173-opencl.pdf    Bittware. S5-PCIe-HQ user guide. Technical report, Bittware, Inc., September 2013.    M. T. DeGarmo. Issues concerning integration of unmanned aerial vehicles in civil airspace. Technical Report mP 04W0000323, MITRE Corporation, 2004. https://www.mitre.org/sites/default/files/pdf/04_1232.pdf    R. Eckhorn, H. J. Reiboeck, M. Arndt, and P. W. Dicke. A neural network for feature linking via synchronous activity: Results from a cat visual cortex and from simulations. In  Models of Brain Function, pages 255&ndash;272, Cambridge, UK, 1989. Cambridge University Press.    Khronos OpenCL Working Group. The OpenCL specification. Technical report, Khronos Group, October 2009. http://www.khronos.org/registry/cl/specs/opencl-1.0.pdf    X. Gu, Y. Fang, and Y. Wang. Attention selection using global topological properties based on pulse coupled neural network.  Computer Vision and Image Understanding, 117:1400&ndash;1411, 2013. doi:10.1016/j.cviu.2013.05.004    X. Gu, L. Zhang, and D. Yu. General design approach to unit-linking pcnn for image processing. In  Proceedings of International Joint Conference on Neural Networks, pages 1837&ndash;1841, 2005. doi:10.1109/IJCNN.2005.1556159    Z. Li, R. F. Hayward, R. A. Walker, and Y. Liu. A biologically inspired object spectral-texture descriptor and its application to vegetation classification in power-line corridors.  IEEE Geoscience and Remote Sensing Letters, 8(4):631&ndash;635, 2011. doi:10.1109/LGRS.2010.2098391    A. Lu, W. Ding, J. Wang, and H. Li. Automonmous vision-based safe area selection algorithm for UAV emergency forced landing. In  Proceedings of the International Conference on Information and Computer Applications 2012, pages 254&ndash;261, 2012. doi:10.1007/978-3-642-34041-3_37    L. Mejias and P. Eng. Controlled emergency landing of an unpowered unmanned aerial system.  Journal of Intelligent and Robotic Systems, 70:421&ndash;435, 2013. doi:10.1007/s10846-012-9767-5    L. Mejias and D. L. Fitzgerald. A multi-layered approach for site detection in uas emergency landing scenarios using geometry-based image segmentation. In  Proceedings of the 2013 International Conference on Unmanned Aerial Systems, pages 366&ndash;372, Atlanta, Georgia, 2013. IEEE Control Society. doi:10.1109/ICUAS.2013.6564710    L. Mejias, D. L. Fitzgerald, P. C. Eng, and L. Xi. Forced landing technologies for unmanned aerial vehicles : towards safer operations. In  Aerial Vehicles, pages 415&ndash;442, Kirchengasse, Austria, 2009. In-Tech. doi:10.5772/6481    US-OSoD. Unmanned systems integrated roadmap fy2011-2036. Technical report, Office of the Secretary of Defense, US, 2011. http://info.publicintelligence.net/DoD-UAS-2011-2036.pdf    Z. Wang, Y. Ma, F. Cheng, and L. Yang. Review of pulse-coupled neural networks.  Image and Vision Computing, 28:5&ndash;13, 2010. doi:10.1016/j.imavis.2009.06.00",Australian Mathematical Society,Pulse-coupled neural network performance for real-time identification of vegetation during forced landing,,https://core.ac.uk/download/287318677.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226221819,2010-01-01,"This paper deals with real-time adaptive tracking for discrete-time induction motors in the presence of bounded disturbances. A high-order neural-network structure is used to identify the plant model, and based on this model, a discrete-time control law is derived, which combines discrete-time block-control and sliding-mode techniques. This paper also includes the respective stability analysis for the whole system with a strategy to avoid adaptive weight zero-crossing. The scheme is implemented in real time using a three-phase induction motor. "" 2009 IEEE."",,,,,,""10.1109/TCST.2008.2009466"",,,""http://hdl.handle.net/20.500.12104/44086"",""http://www.scopus.com/inward/record.url?eid=2-s2.0-73249124869&partnerID=40&md5=40ad04de385b99524d40fb61bb4157b5"",,,,,,""1"",,""IEEE Transactions on Control Systems Technology"",,""1",'Institute of Electrical and Electronics Engineers (IEEE)',Real-time recurrent neural state estimation,10.1109/TNN.2010.2103322,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
203190541,2011-08-31,"AbstractObjective(s)Patient-specific simulated rehearsal (PsR) is a technological advance within the domain of endovascular virtual reality (VR) simulation. It allows incorporation of patient-specific computed tomography Digital Imaging and Communications in Medicine (CT DICOM) data into the simulation and subsequent rehearsal of real patient cases. This study aimed to evaluate whether a part-task rehearsal (PTr) of a carotid artery stenting procedure (CAS) on a VR simulator is as effective as a full-task (FTr) preoperative run through.MethodsMedical trainees were trained in the CAS procedure and randomised to a PTr or FTr of a challenging CAS case (Type-II arch). PTr consisted of 30min of repeated catheterisations of the common carotid artery (CCA). Thereafter, both groups performed the CAS procedure in a fully functional simulated operating suite (SOS) with an interventional team. Technical performances were assessed using simulator-based metrics and expert ratings. Other aspects of performance were assessed using the Non-Technical Skills for Surgeons (NOTSS) scoring.ResultsTwenty trainees were evenly randomised to either PTr or FTr. No differences in performance were seen except for the total time the embolic protection device (EPD) was deployed (9.4min for the PT vs. 8.1min for the FT, p=0.02). Total time (26.3 vs. 25.5min, p=0.94), fluoroscopy time (15.8 vs. 14.4min, p=0.68), number of roadmaps (10.5 vs. 11.0, p=0.54), amount of contrast (53.5 vs. 58.0ml, p=0.33), time to deploy the EPD (0.9 vs. 0.8min, p=0.31) and time to catheterise the CCA (9.2 vs. 8.9min, p=0.94) were similar. Qualitative performances as measured by expert ratings (score 24 vs. 24, p=0.49) and NOTSS (p>0.05 for all categories) were also comparable.ConclusionsPart- and full-task rehearsals are equally effective with respect to the operative performance of a simulated CAS intervention. This finding makes a patient-specific rehearsal more efficient and may increase the feasibility of implementation of this technology into medical practice",European Society for Vascular Surgery. Published by Elsevier Ltd.,Efficient Implementation of Patient-specific Simulated Rehearsal for the Carotid Artery Stenting Procedure: Part-task Rehearsal ,10.1016/j.ejvs.2011.03.032,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226269996,2005-01-01T00:00:00,"Real-time three-dimensional echocardiographic (RT3DE) datasets contain dynamic volumetric information on cardiac function. However, quantification of left ventricular (LV) function from 3D echocardiographic data is performed on cut-planes extracted from the 3D datasets and thus does not fully exploit the volumetric information. Accordingly, we developed a volumetric analysis technique aimed at quantification of global and regional LV function. Methods and Results. RT3DE images obtained in 30 patients (Philips 7500) were analyzed using custom software based on level-set approach for semi-automated detection of LV endocardial surface throughout the cardiac cycle, from which global and regional LV volume (LVV) and wall motion (WM) time-curves were obtained. Study design included three protocols. In protocol 1, time-curves obtained in 16 patients were compared point-by-point with magnetic resonance (MR) data (linear regression and Bland-Altman analyses). Global LVV correlated highly with MR (r=0.98; y=0.99x+2.3) with minimal bias (1.4ml) and narrow limits of agreement (\ub120ml). WM correlated highly only in basal and mid-ventricular segments (r=0.88; y=0.85x+0.7). In protocol 2, we tested the ability of this technique to differentiate populations with known differences in LV function by studying 9 patients with dilated cardiomyopathy and 9 normal subjects. All calculated indices of global and regional systolic and diastolic LV function were significantly different between the groups. In protocol 3, we tested the feasibility of automated detection of regional WM abnormalities in 11 patients. In each segment, abnormality was detected when regional shortening fraction was below a threshold obtained in normal subjects. The automated detection agreed with expert interpretation of 2D WM in 86% segments. Conclusion. Volumetric analysis of RT3DE data is clinically feasible and allows fast, semi-automated, dynamic measurement of LVV and automated detection of regional wall motion abnormalities",'Ovid Technologies (Wolters Kluwer Health)',Volumetric quantification of global and regional left ventricular function from real-time three-dimensional echocardiographic images,10.1161/CIRCULATIONAHA.104.513689,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
36204612,2007-01-01T00:00:00,"One primary goal in rescue robotics is to deploy a team of robots for coordinated victim search after a disaster. This requires robots to perform subtasks, such as victim detection, in real-time. Human detection by computationally cheap techniques, such as color thresholding, turn out to produce a large number of false-positives. Markov Random Fields (MRFs) can be utilized to combine the local evidence of multiple weak classifiers in order to improve the detection rate. However, inference in MRFs is computational expensive. In this paper we present a novel approach for the genetic optimizing of the building process of MRF models. The genetic algorithm determines offline relevant neighborhood relations with respect to the data, which are then utilized for generating efficient MRF models from video streams during runtime. Experimental results clearly show that compared to a Support Vector Machine (SVM) based classifier, the optimized MRF models significantly reduce the false-positive rate. Furthermore, the optimized models turned out to be up to five times faster then the non-optimized ones at nearly the same detection rate.Artificial Intelligence & Integrated Computer System",'Institute of Electrical and Electronics Engineers (IEEE)',Genetic MRF Model Optimization for Real-Time Victim Detection in Search and Rescue,10.1109/IROS.2007.4399006,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226191101,2008-01-01,"In this article we propose an effective method for a user-dependant voice command (small vocabulary) recognition system based on the combination of genetic algorithms and the Fisher's Linear Discriminant Ratio (FLDR). A genetic algorithm here is used to search in the frequency domain of the voice for those sub-bands whose energy is discriminant enough so as to distinguish between at least two different classes, and at the same time, being able to appropriately agglomerate the different utterances of one word of the vocabulary in a compact class. Once the sub-bands have been evolutionary selected, its energy is represented in feature vectors; in this way, very few samples of each voice command are required to build each words' model; moreover, this is a convenient method for feature selection. Real time implementation was done in a DSP TMS320LF2407 using elliptic bandpass filters -one per sub-band- with floating point representation. Encouraging results were obtained. "" 2008 IEEE."",,,,,,""10.1109/MICAI.2008.61"",,,""http://hdl.handle.net/20.500.12104/40174"",""http://www.scopus.com/inward/record.url?eid=2-s2.0-57849164034&partnerID=40&md5=366b0289aa59ea9fa0b062b34d2e114d"",,,,,,,,""7th Mexican International Conference on Artificial Intelligence - Proceedings of the Special Session, MICAI 2008"",,""16",'International Association for Food Protection',Comparison of different washing treatments for reducing pathogens on orange surfaces and for preventing the transfer of bacterial pathogens to fresh-squeezed orange juice,10.4315/0362-028X.JFP-10-357,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
210554287,2008-01-01T08:00:00,"Multi-agent teaming is a key research field of multi-agent systems. BDI (Belief, Desire, and Intension) architecture has been widely used to solve complex problems. The theory of joint behavior has been widely used to solve the team level optimisation problems. Due to the inherent complexity of real-time and dynamic environments, it is often extremely complex and difficult to formally specify the joint behavior of the team a priori. This paper presents a role-based BDI framework to facilitate cooperation and coordination problems. This BDI framework is extended and based on the commercial agent software development environment known as JACK Teams. A real-time 2D simulation environment known as soccerbots has been used to investigate the difficulties of multi-agent teaming. The layered architecture has been used to group the agents’ competitive and cooperative behaviors, which can be learned through experience by using the reinforcement learning techniques","Edith Cowan University, Research Online, Perth, Western Australia",A Role-based Framework for Multi-agent Teaming,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275594362,2013-06-01T00:00:00,"Thanks to the built in intelligence (deployment of new intelligent devices and sensors in places where historically they were not present), the Smart Grid and Microgrid paradigms are able to take advantage from aggregated load forecasting, which opens the door for the implementation of new algorithms to seize this information for optimization and advanced planning. Therefore, accuracy in load forecasts will potentially have a big impact on key operation factors for the future Smart Grid/Microgrid-based energy network like user satisfaction and resource saving, and new methods to achieve an efficient prediction in future energy landscapes (very different from the centralized, big area networks studied so far). This paper proposes different improved models to forecast next day's aggregated load using artificial neural networks, taking into account the variables that are most relevant. In particular, seven models based on the multilayer perceptron will be proposed, progressively adding input variables after analyzing the influence of climate factors on aggregated load. The results section presents the forecast from the proposed models, obtained from real data.Hernández, L.; Baladrón Zorita, C.; Aguiar Pérez, JM.; Calavia Domínguez, L.; Carro Martínez, B.; Sanchez-Esguevillas, A.; Garcia Fernandez, P.... (2013). Experimental Analysis of the Input Variables' Relevance to Forecast Next Day's Aggregated Electric Demand Using Neural Networks. Energies. 6(6):2927-2948. doi:10.3390/en6062927S2927294866Zhang, Q., Lai, K. K., Niu, D., Wang, Q., & Zhang, X. (2012). A Fuzzy Group Forecasting Model Based on Least Squares Support Vector Machine (LS-SVM) for Short-Term Wind Power. Energies, 5(9), 3329-3346. doi:10.3390/en5093329Hsu, C.-C., & Chen, C.-Y. (2003). Regional load forecasting in Taiwan––applications of artificial neural networks. Energy Conversion and Management, 44(12), 1941-1949. doi:10.1016/s0196-8904(02)00225-xCarpaneto, E., & Chicco, G. (2008). Probabilistic characterisation of the aggregated residential load patterns. IET Generation, Transmission & Distribution, 2(3), 373. doi:10.1049/iet-gtd:20070280Shu Fan, Methaprayoon, K., & Wei-Jen Lee. (2009). Multiregion Load Forecasting for System With Large Geographical Area. IEEE Transactions on Industry Applications, 45(4), 1452-1459. doi:10.1109/tia.2009.2023569Pudjianto, D., Ramsay, C., & Strbac, G. (2007). Virtual power plant and system integration of distributed energy resources. IET Renewable Power Generation, 1(1), 10. doi:10.1049/iet-rpg:20060023Ruiz, N., Cobelo, I., & Oyarzabal, J. (2009). A Direct Load Control Model for Virtual Power Plant Management. IEEE Transactions on Power Systems, 24(2), 959-966. doi:10.1109/tpwrs.2009.2016607Hernandez, L., Baladron, C., Aguiar, J. M., Carro, B., Sanchez-Esguevillas, A., Lloret, J., … Cook, D. (2013). A multi-agent system architecture for smart grid management and forecasting of energy demand in virtual power plants. IEEE Communications Magazine, 51(1), 106-113. doi:10.1109/mcom.2013.6400446Mousavi, S. M., & Abyaneh, H. A. (2011). Effect of Load Models on Probabilistic Characterization of Aggregated Load Patterns. IEEE Transactions on Power Systems, 26(2), 811-819. doi:10.1109/tpwrs.2010.2062542Ipakchi, A., & Albuyeh, F. (2009). Grid of the future. IEEE Power and Energy Magazine, 7(2), 52-62. doi:10.1109/mpe.2008.931384Naphade, M., Banavar, G., Harrison, C., Paraszczak, J., & Morris, R. (2011). Smarter Cities and Their Innovation Challenges. Computer, 44(6), 32-39. doi:10.1109/mc.2011.187Hernández, L., Baladrón, C., Aguiar, J. M., Calavia, L., Carro, B., Sánchez-Esguevillas, A., … Gómez, J. (2012). A Study of the Relationship between Weather Variables and Electric Power Demand inside a Smart Grid/Smart World Framework. Sensors, 12(9), 11571-11591. doi:10.3390/s120911571Hernandez, L., Baladrón, C., Aguiar, J., Carro, B., Sanchez-Esguevillas, A., & Lloret, J. (2013). Short-Term Load Forecasting for Microgrids Based on Artificial Neural Networks. Energies, 6(3), 1385-1408. doi:10.3390/en6031385Perez, E., Beltran, H., Aparicio, N., & Rodriguez, P. (2013). Predictive Power Control for PV Plants With Energy Storage. IEEE Transactions on Sustainable Energy, 4(2), 482-490. doi:10.1109/tste.2012.2210255Ogliari, E., Grimaccia, F., Leva, S., & Mussetta, M. (2013). Hybrid Predictive Models for Accurate Forecasting in PV Systems. Energies, 6(4), 1918-1929. doi:10.3390/en6041918Douglas, A. P., Breipohl, A. M., Lee, F. N., & Adapa, R. (1998). The impacts of temperature forecast uncertainty on Bayesian load forecasting. IEEE Transactions on Power Systems, 13(4), 1507-1513. doi:10.1109/59.736298Sadownik, R., & Barbosa, E. P. (1999). Short-term forecasting of industrial electricity consumption in Brazil. Journal of Forecasting, 18(3), 215-224. doi:10.1002/(sici)1099-131x(199905)18:33.0.co;2-bHuang, S. R. (1997). Short-term load forecasting using threshold autoregressive models. IEE Proceedings - Generation, Transmission and Distribution, 144(5), 477. doi:10.1049/ip-gtd:19971144Infield, D. G., & Hill, D. C. (1998). Optimal smoothing for trend removal in short term electricity demand forecasting. IEEE Transactions on Power Systems, 13(3), 1115-1120. doi:10.1109/59.709108Sargunaraj, S., Sen Gupta, D. P., & Devi, S. (1997). Short-term load forecasting for demand side management. IEE Proceedings - Generation, Transmission and Distribution, 144(1), 68. doi:10.1049/ip-gtd:19970599Hong-Tzer Yang, & Chao-Ming Huang. (1998). A new short-term load forecasting approach using self-organizing fuzzy ARMAX models. IEEE Transactions on Power Systems, 13(1), 217-225. doi:10.1109/59.651639Hong-Tzer Yang, Chao-Ming Huang, & Ching-Lien Huang. (1996). Identification of ARMAX model for short term load forecasting: an evolutionary programming approach. IEEE Transactions on Power Systems, 11(1), 403-408. doi:10.1109/59.486125Yu, Z. (1996). A temperature match based optimization method for daily load prediction considering DLC effect. IEEE Transactions on Power Systems, 11(2), 728-733. doi:10.1109/59.496146Charytoniuk, W., Chen, M. S., & Van Olinda, P. (1998). Nonparametric regression based short-term load forecasting. IEEE Transactions on Power Systems, 13(3), 725-730. doi:10.1109/59.708572Taylor, J. W., & Majithia, S. (2000). Using combined forecasts with changing weights for electricity demand profiling. Journal of the Operational Research Society, 51(1), 72-82. doi:10.1057/palgrave.jors.2600856Ramanathan, R., Engle, R., Granger, C. W. J., Vahid-Araghi, F., & Brace, C. (1997). Short-run forecasts of electricity loads and peaks. International Journal of Forecasting, 13(2), 161-174. doi:10.1016/s0169-2070(97)00015-0Elman, J. L. (1990). Finding Structure in Time. Cognitive Science, 14(2), 179-211. doi:10.1207/s15516709cog1402_1Elman, J. L. (1991). Distributed representations, simple recurrent networks, and grammatical structure. Machine Learning, 7(2-3), 195-225. doi:10.1007/bf00114844Kohonen, T. (1990). The self-organizing map. Proceedings of the IEEE, 78(9), 1464-1480. doi:10.1109/5.58325Razavi, S., & Tolson, B. A. (2011). A New Formulation for Feedforward Neural Networks. IEEE Transactions on Neural Networks, 22(10), 1588-1598. doi:10.1109/tnn.2011.216316",'MDPI AG',Experimental Analysis of the Input Variables' Relevance to Forecast Next Day's Aggregated Electric Demand Using Neural Networks,10.3390/en6062927,https://riunet.upv.es/bitstream/handle/10251/43121/Luis%3bCarlos%3bJavier%20M.%20-%20Experimental%20Analysis%20of%20the%20Input%20Variables%20%20Relevance%20to%20Forecast%20Next%20....pdf?sequence=1&isAllowed=y,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275591397,2011-01-01T00:00:00,"In this paper we present a new algorithm for solving polynomial
equations based on the Taylor series of the inverse function of a polynomial,
fP(y). The foundations of the computing of such series have been previously
developed by the authors in some recent papers, proceeding as follows: given
a polynomial function y = P(x) = a0 + a1x +···+ amxm, with ai ∈ R, 0 ≤ i ≤
m, and a real number u so that P 
(u)  = 0, we have got an analytic function
fP(y) that satisfies x = fP(P(x)) around x = u. Besides, we also introduce a
new proof (completely different) of the theorems involves in the construction
of fP(y), which provide a better radius of convergence of its Taylor series,
and a more general perspective that could allow its application to other kinds
of equations, not only polynomials. Finally, we illustrate with some examples
how fP(y) could be used for solving polynomial systems. This question has
been already treated by the authors in preceding works in a very complex
and hard way, that we want to overcome by using the introduced algorithm in
this paper.Moreno Flores, J.; Saiz Martinez, A. (2011). Inverse functions of polynomials and its applications to initialize the search of solutions of polynomials and polynomial systems. Numerical Algorithms. 58(2):203-233. doi:10.1007/s11075-011-9453-xS203233582Pérez, R., Rocha, V.L.: Recent applications and numerical implementation of quasi-Newton methods for solving nonlinear systems of equations. Numer. Algorithms 35, 261–285 (2004)Pan, V.Y.: Solving a polynomial equation: some history and recent progress. SIAM Rev. 39(2), 187–220 (1997)Pan, V.Y.: On approximating polynomial zeros: modified quad tree (Weyl’s) construction and improved Newton’s iteration. Research Report 2894, INRIA, Sophia-Antipolis, France (1996)Pan, V.Y.: Optimal and nearly optimal algorithms for approximating polynomial zeros. Comput. Math. Appl. 31, 97–138 (1996)Mcnamee, J.M.: A bibliography on roots of polynomials. J. Comput. Appl. Math. 47, 391–394 (1993)Pan, V.Y.: Fast and efficient parallel evaluation of the zeros of a polynomial having only real zeros. Comput. and Math. 17, 1475–1480 (1989)Davidon, W.C.: Variable metric methods for min imitation. Research and Development Report ANL-5990 Rev (1959)Broyden, C.G., Luss, D.: A class of methods for solving nonlinear simultaneous equations. Math. Comput. 19, 577–593 (1965)Ortega, J.M., Reinboldt, W.C.: Iterative Solutions of Nonlinear Equations in Several Variables. Academic Press, New York (1970)Dennid, J.E., More, J.J.: Quasi-Newton methods, motivations and theory. SIAM Rev. 19, 46–89 (1977)Martínez, J.M.: Practical quasi-Newton methods for solving nonlinear systems. J. Comput. Appl. Math. 124, 97–121 (2000)Zhang, J.Z., Chen, L.H., Deng, N.Y.: A family scaled factorized Broyden-like methods for nonlinear least squares problems. SIAM J. Optm. 10(4), 1163–1179 (2000)Brezinski, C.: Classification of quasi-Newton methods. Numer. Algorithms 33, 123–135 (2003)Eriksson, J., Gulliksson, M.E.: Local results for the Gauss-Nreyon method on constrained rank-deficient nonlinear least squares. Math. Comput.73(248), 1865–1883 (2003)Birgin, E.G., Krejic, N., Martínez, J.M.: Globally convergent inexact quasi-Newton methods for solving nonlinear systems. Numer. Algorithms 32, 249–260 (2003)Yabe, H., Martínez, H.J., Tapia, R.A.: On sizing and shifting the BFGS update within the sized-Broyden family of secant updates. SIAM J. Optim. 15(1), 139–160 (2004)Heng-Bin, A.: On convergence of the additive archway preconditioned inexact newton method. SIAM J. Numer. Anal. 43(5), 1850–1871 (2005)Brett, W.B.: Tensor-Krylov methods for solving large-scale systems of nonlinear equations. SIAM J. Numer. Anal. 43(3), 1321–1347 (2005)Cordero, A., Torregrosa, J.R.: Variants of Newton’s method using fifth-order quadrature formulas. Appl. Math. Comput. 190, 686–698 (2007)Marek, J.S.: Convergence of a generalized Newton and inexact generalized Newton algorithms for solving nonlinear equations with non differentiable terms. Numer. Algorithms 50(4), 401–415 (2008)Haijun, W.: On new third-order convergent iterative formulas. Numer. Algorithms 48, 317–325 (2008)Hueso, J.L., Martínez, E., Torregrosa, J.R.: Modified Newton’s method for systems of nonlinear equations with singular jacobian. J. Comput. Appl. Math. 224, 77–83 (2009)Moreno, J.: Explicit construction of inverse function of polynomials. Int. J. Appl. Sci. Comput. 11(1), 53–64 (2004)Moreno, J.: Inverse functions of polynomials around all its roots. Int. J. Appl. Sci. Comput. 11(2), 72–84 (2004)Demidovich, B.P., Maron, I.A.: Cálculo Numérico Fundamental. Paraninfo, Madrid (1985)Moreno, J., Casabán, M.C., Rodríguez-Álvarez, M.J.: An algorithm to initialize the search of solutions of polynomial systems. Comput. Math. Appl. 50, 919–933 (2005",'Springer Science and Business Media LLC',Inverse functions of polynomials and its applications to initialize the search of solutions of polynomials and polynomial systems,10.1007/s11075-011-9453-x,http://hdl.handle.net/10251/49340,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323091055,2013-07-09T00:00:00,"[ES] En el presente artículo se muestra un esquema de identificación y control que sintoniza en línea las ganancias proporcional, integral y derivativa de un controlador PID discreto aplicado a un sistema dinámico SISO. Esto se logra empleando una red neuronal de base radial con funciones de activación wavelet hijas Morlet (wavenet) adicionalmente en cascada un filtro de respuesta infinita al impulso (IIR). Dicho esquema es aplicado en tiempo real para controlar la velocidad de un motor de inducción de CA trifásico del tipo jaula de ardilla (MIJA) alimentado con un variador de frecuencia trifásico, de esta forma se muestra cómo este esquema de identificación y control en línea, puede ser implementado en este tipo de plantas que son ampliamente utilizadas en la industria, sin la necesidad de obtener los parámetros del modelo matemático del conjunto variador de frecuencia-motor de inducción trifásico. Se presentan los resultados obtenidos en simulación numérica y experimentales, empleando para esto la plataforma de LabVIEW.[EN] This paper presents a control scheme to tune online the proportional, integral and derivative gains of a discrete PID controller, through the identification and control of a SISO stable and minimum phase dynamic system. This is accomplished using a radial basis network neural with daughter Morlet wavelets activation functions in cascaded with an infinite impulse response (IIR) filter. This scheme is applied in real time to control the speed of an AC three-phase induction motor supplied with a three-phase inverter. So in this way we show how the identification and control scheme can be implemented in this type of plants that are widely used in industry, without the need of mathematical model parameters of the induction motor. We present numerical simulation and experimental results.El autor O. Islas Gomez agradece profundamente al CONACyT por la beca otorgada para realizar estudios de posgrado, con numero de registro 266520.Ramos Velasco, L.; Ramos Fernández, J.; Islas Gómez, O.; García Lamont, J.; Espejel Rivera, M.; Márquez Vera, M. (2013). Identificación y Control Wavenet de un Motor de CA. Revista Iberoamericana de Automática e Informática industrial. 10(3):269-278. https://doi.org/10.1016/j.riai.2013.05.002OJS269278103Bocker, J., & Mathapati, S. (2007). State of the Art of Induction Motor Control. 2007 IEEE International Electric Machines & Drives Conference. doi:10.1109/iemdc.2007.383643Domínguez Mayorga, C. R., Espejel Rivera, M. A., Ramos Velasco, L. E., Ramos Fernández, J. C., & Escamilla Hernández, E. (2012). Algoritmos Wavenet con Aplicaciones en la Aproximación de Señales: un Estudio Comparativo. Revista Iberoamericana de Automática e Informática Industrial RIAI, 9(4), 347-358. doi:10.1016/j.riai.2012.09.001Farahani, M. (2013). Intelligent control of SVC using wavelet neural network to enhance transient stability. Engineering Applications of Artificial Intelligence, 26(1), 273-280. doi:10.1016/j.engappai.2012.05.006Haykin, S., 2001. Kalman Filtering and Neural Networks. Wiley, New York. Holtz, J.,;1; 2002. Sensorlees control of induction motor drives. Proceeding of IEEE International Conference in Electric Machines and Drives, IEDMC’07, Wuppertal, Germany, 1359-1394.Jahedi, G., & Ardehali, M. M. (2012). Wavelet based artificial neural network applied for energy efficiency enhancement of decoupled HVAC system. Energy Conversion and Management, 54(1), 47-56. doi:10.1016/j.enconman.2011.10.005Levin, A. U., & Narendra, K. S. (1993). Control of nonlinear dynamical systems using neural networks: controllability and stabilization. IEEE Transactions on Neural Networks, 4(2), 192-206. doi:10.1109/72.207608Levin, A. U., & Narendra, K. S. (1996). Control of nonlinear dynamical systems using neural networks. II. Observability, identification, and control. IEEE Transactions on Neural Networks, 7(1), 30-42. doi:10.1109/72.478390Lin, C.-J. (2009). Nonlinear systems control using self-constructing wavelet networks. Applied Soft Computing, 9(1), 71-79. doi:10.1016/j.asoc.2008.03.014Payakkawan, P., Klomkarn, K., Sooraksa, P., 2009. Dual-line pid controller based on pso for speed control of dc motors. The 9th International Symposium on Communication and Information Technologies (ISCIT), Incheon, Korea.Polo, M. P., Albertos, P., & Galiano, J. Á. B. (2008). Tuning of a PID controlled gyro by using the bifurcation theory. Systems & Control Letters, 57(1), 10-17. doi:10.1016/j.sysconle.2007.06.007Wu, W., & Jhao, D.-W. (2012). Control of a direct internal reforming molten carbonate fuel cell system using wavelet network-based Hammerstein models. Journal of Process Control, 22(3), 653-658. doi:10.1016/j.jprocont.2012.01.01",'Elsevier BV',Identification and Wavenet Control of AC Motor,10.1016/j.riai.2013.05.002,http://hdl.handle.net/10251/143955,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
53020779,2006-02-01T00:00:00,"International audienceThis paper describes an objective measurement method designed to assess the perceived quality for digital videos. The proposed approach can be used either in the context of a reduced reference quality assessment or in the more challenging situation where no reference is available. In that way, it can be deployed in a QoS monitoring strategy in order to control the end-user perceived quality. The originality of the approach relies on the very limited computation resources which are involved, such a system could be integrated quite easily in a real time application. It uses a convolutional neural network (CNN) that allows a continuous time scoring of the video. Experiments conducted on different MPEG-2 videos, with bit rates ranging from 2 to 6 Mbits/s, show the effectiveness of the proposed approach. More specifically, a linear correlation criterion, between objective and subjective scoring, ranging from 0.90 up to 0.95 has been obtained on a set of typical TV videos in the case of a reduced reference assessment. Without any reference to the original video, the correlation criteria remains quite satisfying since it still lies between 0.85 and 0.90, which is quite high with respect to the difficulty of the task, and equivalent and more in some cases than the traditional PSNR, which is a full reference measurement",'Oxford University Press (OUP)',No reference and reduced reference video quality metrics for end to end QoS monitoring,10.1093/ietcom/e89-b.2.289,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
92079287,1997-05-20T00:00:00,"In this paper we document our experiences in developing and teaching design classes. The courses we teach, and that we still try to improve and try to keep up with state of the art design approaches, originaly developed in close cooperation with colleagues like Michael Tauber and Steve Guest. Only in a way of cooperation we will be able to improve and to produce state of the art education. Teaching interactive systems design in our situation means teaching various groups of university students, as well as groups of experienced practitioners, in most cases stemming from a variety of disciplines like software engineering, electrical engineering, cognitive psychology, and AI. Our current design classes are organised in such a way that students are forming a design team with subteams for different specialist design methods like task analysis, formal modeling, prototyping, usability evaluation, and requirements analysis. The team collaborates in an iterative manner, starting from an initial statement from a real client and ending with the presentation of a complete design (including design rationales, working prototype that is evaluated, but also including organisational re-design and possible video scenarios",,Teaching design of complex interactive systems: Learning by Interacting,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
155518096,2009-01-01T00:00:00,"目的:评价实时三维超声心动图(RT3D)测量左心室射血分数(LVEF)≥45% 成年人左心室容量的准确性和重复性.方法:选取因各种不同原因进行心脏磁共振(MRI)检查显示 LVEF ≥45%的患者37例,同时进行RT3D检查.RT3D检查采用Philips iE-33型超声心动图仪,左心室容量及左心室功能的分析通过TomTec工作站用人工描记法完成,并与MRI所得结果相比较.结果:MRI测量的左心室舒张末期容量(EDV)为:60～208.76(110.48&amp;#177;33.50)ml,左心室收缩末期容量(ESV)为:19～102.4(45.80&amp;#177;17.84 )ml,LVEF为:45.40～71.10(59.13&amp;#177;7.24)%.RT3D测量的EDV为:42.8～ 211.9(100.64&amp;#177;34.48)ml,ESV为:14.30 ～94.54(44.08 &amp;#177;17.62)ml,LVEF为:35.1～73.4(56.70&amp;#177;7.02)%.与MRI相比,RT3D低估EDV(P＜0.01,r=0.842,y=0.867x+4.88,SEE=18.86ml),二者平均相差(-9.84&amp;#177;38.26) ml.RT3D同时低估ESV,二者相比差异无统计学意义(P＞0.05,r=0.846,y=0.835x+5.82,SEE=9.53 ml),二者平均相差(-1.71&amp;#177;19.68)ml.RT3D所测的LVEF稍小于MRI所测得的LVEF,二者相比差异有统计学意义(P＜0.05,r=0.616,y=0.597x+21.38,SEE=5.61%),平均相差(-2.42&amp;#177;12.5 )%.在不同观察者间及观察者自身不同时间内测量的RT3D,结果显示良好的重复性.结论:与MRI相比,RT3D测量成人患者的左心室容量及LVEF有较好的准确性和重复性.Objective:The purpose of this study was to assess the left ventricle (LV) volumes and function acquired by real-time(RT) three-dimensional echocardiography (3D) in adult patients whose LV ejection fraction (LVEF) more than 45%, compared with magnetic resonance imaging (MRI) data. Methods:Unselected patients (n=37; 22 men; age, 57.78&amp;#177;17.23 years) with various cardiovascular disease were evaluated on the same day by MRI and RT3D. RT3D was performed with a Philips iE-33 echocardiographic system and LV volumes and function analyses with the assistance of TomTec software. The results for LV volumes and function obtained by manual tracing were compared with Signa 1.5-T MRI data.Results:The average MRI EDV was 110.48&amp;#177;33.50ml (60-208.76ml),ESV was 45.80&amp;#177;17.84 ml(19-102.4ml),EF was 59.13&amp;#177;7.24% (45.40-71.10%). The average RT3D EDV was 100.64&amp;#177;34.48ml (42.8- 211.9ml),ESV was 44.08 &amp;#177;17.62ml (14.30 - 94.54ml),EF was 56.70&amp;#177;7.02% (35.1-73.4%). Compared with MRI values, EDV was underestimated by 3D (P＜0.01,r=0.842,y=0.867x+4.88,SEE=18.86 ml), with a mean difference of (-9.84&amp;#177;38.26) ml; ESV was also underestimated by 3D (P＞0.05,r=0.846,y=0.835x+5.82,SEE=9.53 ml) with a mean difference of( -1.71&amp;#177;19.68)ml. Ejection fraction by MRI was larger than that by 3D (P＜0.05,r=0.616,y=0.597x+21.38,SEE=5.61%), with a mean difference of (-2.42&amp;#177;12.5) %. There was good inter-and intra-observer correlation between RT-3D by two sonographers for volumes and ejection fraction.Conclutsions:The assessment of LV volume and ejection fraction from RT-3D data is feasible in patients . The volume and ejection fraction can be determined with high accuracy and low interobserver variability in patients with adequate echocardiographic image quality.中文核心期刊要目总览(PKU)中国科技核心期刊(ISTIC)中国科学引文数据库(CSCD)012911-9152",临床心血管病杂志,Comparison of real-time three-dimensional echocardiography to magnetic resonance imaging for assessment of the left ventricle volumes in patients whose left ventricle ejection fraction more than 45%,10.3969/j.issn.1001-1439.2009.12.011,,"[{'title': None, 'identifiers': ['issn:1001-1439', '1001-1439']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
31676248,2007-07-01T00:00:00,"International audienceTightening European standards on fuel consumption and pollutant emissions reduction lead to a sophistication of engine concepts and associated control. Since few years, downsizing (reduction of the engine displacement) appears as a major way to achieve those requirements for spark ignition engines. Efficientperformance and drivability can be then achieved with a direct injection downsized engine with turbocharging and Variable Camshaft Timing (VCT). One of the major issues of the torque-oriented control is in-cylinder mass observation and control. To have an efficient torque response, the in-cylinder trapped mass, adjusted by the throttle and the waste gate, must be controlled with accuracy according to performance and drivability requirements. Depending on admission and exhaust pressures, the twin VCT will allow to control in-cylinder burned gases rate to reduce fuel consumption and pollutant emissions, and air scavenging to improve transient speed response. Another major issue is in-cylinder trapped mass and air scavenging prediction for AFR control. In this paper, we propose a model-based approach to achieve those engine control issues. The first challenge is to design accurate observers for non-measurable variables (in-cylinder burned gases and trapped air mass). The method is based on a complex high frequency 0D engine model, which has been validated on a large range of engine operating points and transient operations based on test bed results. Then, this model permits to design and learn open-loop nonlinear static observers of in-cylinder masses (based on neural network). The static and dynamic behavior of high frequency 0D engine model allows to achieve design of dynamic and closed-loop in-cylinder mass observation and prediction, multivariable and non-linear control of air path according to in-cylinder mass trajectory (trapped air mass & recirculated gases rate). Then, the complete engine control can be developed and validated on simulation and on a real time Software-In-the-Loop platform based on high frequency 0D engine model, before a complete validation and calibration on test bed. Finally, the complete torque-oriented engine control has been integrated on vehicle. From 0D engine model, a complete vehicle model has been set on real-time platform in order to validate engine control integration and design vehicle layout. The major issue is then supervision of engine control set points (torque, AFR, efficiency) according to engine states (start, idle, driver request, cut-off) and warm-up strategies",'EDP Sciences',Engine Control of a Downsized Spark Ignited Engine : from Simulation to Vehicle,10.2516/ogst:2007057,https://core.ac.uk/download/31676248.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
74319877,2007-01-01T00:00:00,"Purpose: To assess the efficacy of low mechanical index (MI) real time grey scale contrast-enhanced US (CEUS) in the differentiation of breast lesions in comparison to Magnetic Resonance Imaging (MRI). Materials and Methods: 50 lesions previously detected at mammography or conventional US were evaluated by means of CEUS and MRI. Contrast-enhanced examinations were performed with a dedicated equipment (Esatune, Esaote, Genoa, Italy), before and after injection of 4.8 ml of Sonovue (Bracco, Milan, Italy). MRI was conducted with a 1.5 T equipment (Siemens Vision Plus, Erlangen, Germany) with bilateral dedicated superficial coil, on T2w STIR and 3D Flash T1w before and 1, 2, 3, 4, 5 minutes after the administration of contrast agent (Gd-DTPA, 1.5 ml/ Kg). Wash-in and wash out curves were assessed for both procedures. A specific sonographic quan-, tification software (Qontrast, Bracco, Milan, Italy), based off pixel by pixel signal intensity over time, was used to obtain contrast-enhanced sonographic perfusion maps for each lesion. Mc Nemar test was then calculated. Results: 24 invasive ductal carcinomas, 18 fibroadenomas, 4 fibro-cystic dysplasias, 1 mucin ous carcinoma, 1 invasive ducto-lobularcarcinoma, 1 intraductal florid papillomatosis and 1 phylloides tumour were diagnosed. Contrastenhanced sonographic patterns correlated well with those provided by MRI. Sensitivity, specificity, and accuracy of US were: 69.2%, 66.7%, and 68%, respectively. According to the different contrast enhancement patterns and the resulting perfusion maps, all the malignant lesions and 9 out of 12 benign lesions were correctly diagnosed, thus resulting in 87.5% of specificity and 100% of sensitivity. Regarding the specificity, there is no difference between US and CEUS with McNemar (p=0.18). Regarding sensitivity, the difference between contrast-enhanced US and US is significant as calculated with McNemar test (p=0.013). The three lesions which were incorrectly classified as malignant were two hypervascularised fibroadenomas in young women and a phylloides tumour. Conclusion: CEUS seems to be a reliable method to differentiate breast lesions, since it provides typical enhancement patterns. Contrast sonographic perfusion curves correlate well with MRI wash in-wash out curves",'Georg Thieme Verlag KG',Benign and malignant breast lesions: Efficacy of real time contrast-enhanced ultrasound vs. magnetic resonance imaging,10.1055/s-2006-927226,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
203067856,2014-12-31,"AbstractThe use of proposed technology of Modeling of Intelligent Systems Thinking in Complex Adaptive systems is oriented on use in autonomous, intelligent Fuzzy Control and Information Complex Adaptive systems, that operate in real-time, fuzzy conditions, heterogeneous subject areas and multilingual communications, there the situations are unknown in advance, fuzzy structured and not clearly regulated. The technology consists in extracting of relevant data, information and knowledge from texts (speech) in various natural languages, within dissimilar subject areas for implementation of fuzzy control of data, information and knowledge in light of representing them in knowledge bases and organizing on basis of them the processes of Reasoning and Systems Thinking under uncertainty and in Fuzzy Environment. The technology is formalized using Fuzzy Logic, Situational Control theories, Linguistics, Artificial Intelligence, Knowledge base technologies and is defined by methods of a) Situational Control of fuzzy data, information and knowledge, b) Knowledge Representation, Generalization and Explanation, c) Modeling of Fuzzy Logic Inference, Decision making and Fuzzy Control, d) Intelligent Fuzzy Reasoning and Systems Thinking",The Authors. Published by Elsevier B.V.,Modeling of Intelligent System Thinking in Complex Adaptive Systems ,10.1016/j.procs.2014.09.043,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
161775962,1998-12-01T00:00:00,"This paper describes how to implement a partially connected neural network by Giga-Ops Spectrum G800 FPGAs (Field Programmable Gate Arrays) based custom computer which consists of up to 32 Xilinx XC4010 logic chips. From the training data, a decision tree is generated by classifier program C4.5. The tree is then used to initialize the neural network to a nearly optimum configuration. This initialized partially connected network is then trained by training data. The trained neural network is then implemented by our Custom Computer system. This implementation requires fewer connections and can provide a very high speed classifier for many real-time image recognition applications",,High speed neural network based classifier for real-time application,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
15035381,2007-01-01T00:00:00,"Background: The accuracy, reproducibility, and test-retest reliability of 3-dimensional (3D) echocardiography (3DE) with 3D reconstruction (3DR) and real-time (RT) imaging (RT 3DE) exceed that of 2-dimensional echocardiography (2DE). However, image quality with RT 3DE is inferior to 2DE and we sought to determine whether this justified ongoing use of 3DR. Methods: Unselected patients (n = 30, 22 men, age 66 ± 7 years) presenting to the echocardiography laboratory for left ventricular (LV) evaluation were studied with 2DE and RT 3DE; 3DR images were obtained using external localization. The 3D measurements and reconstructions were obtained offline. Magnetic resonance images (MRI) were obtained using true free induction, steady state precession during breath hold and 3D volumes and ejection fraction (EF) were measured using 3D software. A separate cohort of 20 patients (13 men, age 60 ± 12 years) was measured for test-retest variation. Results: All echocardiographic measures underestimated LV volumes and EF compared with MRI, but this was least with RT 3DE. End-diastolic volume by MRI (168 ± 54 mL) was underestimated by RT 3DE (-15 ± 31, P = .02), 3DR (-26 ± 33, P < .01), and 2DE (-57 ± 40, P < .01). Similarly, end-systolic volume by MRI (86 ± 50 mL) was underestimated by RT 3DE (-15 ± 31, P = .02), 3DR (-26 ± 33, P < .01), and 2DE (-57 ± 40, P < .01). However, EF measurements were similar with each method. Test-retest variation was less and interobserver and intraobserver correlations were better with RT 3DE for volumes and EF, compared with 3DR and 2DE. Conclusions: Despite limitations of image quality, RT 3DE is the most feasible and accurate approach for LV volume and EF measurements and follow-up LV assessment in daily practice",'Elsevier BV',Reconstructed versus real-time 3-dimensional echocardiography: Comparison with magnetic resonance imaging,10.1016/j.echo.2006.12.010,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
158662514,2000-01-01T00:00:00,"This paper describes Virtual Reality as an environment to collect information about user satisfaction. Because Virtual Reality (VR) allows visualization with added interactivity, this form of representation bas particular advantages when presenting new designs. The paper reports on the development of a VR system that supports architects to collect opinions about their design alternatives in terms of user preferences. An alternative to conjoint analysis, that uses statistical choice variations to estimate user preference functions, is developed. Artificial intelligence (AI) Agent technology will be implemented to build a model for data collection, prediction, and learning processes",Technische Universiteit Eindhoven / EIRASS,Measuring user satisfaction for design variations through virtual reality,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
196680311,2007-10-01T00:00:00,"One of the main obstacles in applying AI planning techniques to real problems is the difficulty to model the domains. Usually, this requires that people that have developed the planning system carry out the modeling phase since the representation depends very much on a deep knowledge of the internal working of the planning tools. On some domains such as business process reengineering (BPR), there has already been work on the definition of languages that allow non-experts entering knowledge on processes into the tools. We propose here the use of one of such BPR languages to enter knowledge on the organisation processes to be used by planning tools. Then, planning tools can be used to semi-automatically generate business process models.
As instances of this domain, we will use the workflow modeling tool SHAMASH, where we have exploded its object oriented structure to
introduce the knowledge through its user-friendly interface and, using a translator transform it into predicate logic terms. After this conversion,
real models can be automatically generated using a planner that integrates planning and scheduling, IPSS. We present results in a real workflow domain, the telephone installation (TI) domain.The SHAMASH project has being carried out in the course of the R&D project funded by the Esprit Program of the Commission of the European Communities as project number 25491. A complementary grant was given by the Spanish research commission, CICYT, under project number
TIC98-1847-CE. We thank the partners of this project, who have originated and contributed to the ideas reported: UF (Unio´n Fenosa), SAGE (Software AG Espan˜ a), SEMA GROUP sae, UC3M (Universidad Carlos III de Madrid), WIP (Wirstchaft und infrastruktur & Co Planungs
KG), and EDP (Electricidade de Portugal). We would
specially like to thank all the UC3M team, the PLANET people and Paul Kearney (BT). Through talks with him we have outlined many ideas. This work has also been partially funded by grant MCyT TIC2002-04146-C05-05 and the UAH project PI2005/084.Publicad",'Elsevier BV',Integrating planning and scheduling in workflow domains,10.1016/j.eswa.2006.05.027,,"[{'title': 'Expert Systems with Applications', 'identifiers': ['0957-4174', 'issn:0957-4174']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
54423606,2011-01-01T00:00:00,"Vieni via con me. Culture partecipative, fruizione televisiva, social media e civic engagement



Obiettivi del contributo e teorie di riferimento



Obiettivo di questo paper è ragionare sul ruolo che i social media esercitano - in accordo con i contenuti mediali tradizionali - nella definizione del senso di appartenenza sociale e partecipazione culturale dei soggetti alla vita quotidiana.



In particolare, oggetto del nostro lavoro sono le pratiche partecipative messe in campo dagli utenti dei social media a ridosso di Vieni via con me, un programma televisivo andato in onda sulla Rai nel mese di novembre 2010, per 4 puntate. 

Il prodotto si è configurato come vero e proprio media event (Dayan e Katz, 1992), per diverse ragioni:

In primo luogo, ha dato vita ad una vastissima copertura mediale, sia attraverso mezzi tradizionali che social media, che si è sviluppata precedentemente e successivamente alla messa in onda, in relazione  alla valenza politica dei contenuti proposti (letti in chiave ideologico-oppositiva al Governo) e rispetto alla scelta dei conduttori e degli ospiti del programma (uno dei quali è il noto scrittore Roberto Saviano, autore di Gomorra, un libro denuncia sulla camorra, apertamente schierato in senso anti-Berlusconiano).

Un altro aspetto degno di nota è senza dubbio il risultato in termini di dati di ascolto registrati durante le 4 puntate: il sistema di rilevazione metrico Auditel (people meter) ha segnalato medie di share nel prime time pari al 25,48%, 30%, 21,21% 31,60% 29,17% , e un ascolto medio intorno ai 9 milioni; pur in una fase di costante contrazione degli ascolti della tv generalista (free e/o servizio pubblico), il programma  si è posizionato al 7 posto tra i più visti in Italia nel 2010 e ha riportato davanti agli schermi tv pubblici giovani, ormai orientati verso altre forme di consumo culturale. 

Infine, per la prima volta in maniera significativa in Italia, è emerso, a ridosso di un programma certamente non di intrattenimento o di fiction, un fenomeno consistente di fruizione on line e just in time del prodotto (Baym), attraverso social media che ne hanno rilanciato contenuti e commenti, coltivando un senso di appartenenza e di comunità e una ritualità performativa innovativa tra le audience.



Nell’ambito di una più ampia riflessione sul rapporto tra utilizzo delle nuove tecnologie, proiezioni identitarie e articolazione delle relazioni sociali (si vedano, tra gli altri, Boase e Wellman 2006, Buckingham 2008, Castells 2001, Castells et al., 2006, Wellman 2004), il presente lavoro fa riferimento, in modo specifico, all’ampio dibattito sviluppato intorno ai concetti di cultura convergente, culture partecipative, user generated content (si vedano in primo luogo Jenkins 2006 e Jenkins et al. 2009; Burgess e Green, 2009), recuperando parte della letteratura sul fandom e, in particolare, sulle produzioni dei fan (si vedano tra gli altri Jenkins 2006, Hills 2002). Faremo inoltre riferimento alla più recente letteratura sulle nuove pratiche di fruizione televisiva, che vedono una crescente integrazione tra la programmazione broadcast e forme di appropriazione dei contenuti da parte delle audience che prevedono un crescente uso dei social media – e di Twitter1 in particolare (Gripsrud, 2010; Kackman et al, 2011; Rappaport, 2011). Attraverso il commento e la rielaborazione in tempo reale dei contenuti broadcast, le audience connesse costituiscono specifiche comunità immaginate (Anderson, 1983) legate a specifici contenuti mediali. Il programma è stato recepito come un'occasione di riflessione politica, con forti connotazioni anti governative, al punto che la sua stessa fruizione è stata interpretata, da molti degli spettatori attivi sui social media, come un momento di civic engagement (sul tema della nuova sfera pubblica si vedano Castells 2008 e 2009; sul rapporto tra social media e civic engagement si veda Johnson et al, 2011).



Obiettivi di ricerca



1.Valutare l’impatto del prodotto a livello sociale e culturale, cercando di individuare le ragioni di un successo non solo televisivo (e fuori dai canoni televisivi) e rintracciando le connessioni tra l’engagement nei confronti del programma tv e l’eventuale civic engagement (Silverstone, 1999) dei soggetti verso la sfera politica e pubblica.

2.Individuare le ritualità del consumo del contenuto mediale e la costruzione grassroot dell’evento, indagando e descrivendo le connessioni esistenti tra il momento squisitamente televisivo e le pratiche discorsive e produttive delle audience, così come si sono concretizzate attraverso differenti piattaforme di comunicazione on line.

3.Cogliere i tratti e le pratiche di una participatory culture (Jenkins et al., 2009) e individuare i segni della costruzione di una comunità immaginata (Anderson, 1983) tra i pubblici dell’evento.

4.Leggere il ruolo dei social network sites in Italia come preparatori ad una nuova forma di partecipazione politica (in linea con quanto emerso recentemente in Nord Africa o a ridosso delle elezioni amministrative di maggio 2011) 



Metodologia utilizzata



Dal punto di vista della metodologia di ricerca, è stato scelto un approccio blended, etnografico e netnografico (Hine, 2000; Markham & Baym, 2009; Kozinets, 2010):



1.Interviste in profondità (30) ai pubblici del programma, selezionati sulla base dei dati di ascolto registrati dal people meter (Auditel) sulle motivazioni del successo del prodotto, sul vissuto sociale e culturale dell’intervistato, il contesto e le pratiche della sua fruizione televisiva, l’approccio al programma, la percezione e il giudizio del prodotto o di alcune sue parti, l’eventuale utilizzo di Internet e dei social media prima, durante o dopo la visione, la valenza politica del consumo culturale.

2.Analisi quanti-qualitativa dei Tweet registrati in rete in relazione al programma #Vieni via con me# (26.000), per cronologia (just in time o pre-post visione), tipologia di contenuti e aree semantiche di riferimento. 

3.Analisi quanti-qualitativa dei video caricati su Youtube in relazione al programma, in termini di cronologia (just in time o post visione), tipologia dei video (cut and paste, o new editing), visualizzazioni e commenti.



Principali risultati della ricerca



La ricerca ha prodotto interessanti esiti in termini di individuazione di:

nuove modalità ibride di fruizione dei contenuti video attraverso diverse piattaforme 

Costruzioni di comunità e rituali on line in relazione a contenuti mediali off line

Emergenza di pratiche proprie della cultura partecipativa

Connessione tra consumo mediale e civic engagementCome away with me. Participatory cultures, television viewing, social media and civic engagementObiettivi contribution and theories of riferimentoObiettivo of this paper is to reason about the role that social media exercise - in agreement with the contents of traditional media - in the definition of a sense of social and cultural participation of the subjects life quotidiana.In particular object of our work are participatory practices put in place by the users of social media in the shelter of Come away with me, a television program aired on Rai in November 2010 for 4 episodes. The product is configured as a real media event (Dayan and Katz, 1992), for several reasons: First, it has created a huge media coverage, both through traditional means and social media, which has been previously developed and after the broadcast, in relation to the political significance of the proposed contents (beds in key ideological and oppositional to the government) and with respect to the choice of conductors and guest of the program (one of which is the well-known writer Roberto Saviano, author of Gomorrah, a book report on the Camorra, openly deployed in an anti-Berlusconi). Another noteworthy aspect is undoubtedly the result in terms of audience figures recorded during the 4 episodes: the detection system metric Auditel (people meter) reported average audience share in prime time equal to 25.48%, 30%, 21,21% 31,60% 29,17%, and an average audience of around 9 million, while in a state of constant contraction of the plays of generalist TV (free and / or public service), the program was ranked seventh place among the most viewed in Italy in 2010 and brought in front of the tv screens young audiences, now oriented towards other forms of cultural consumption. Finally, for the first time significantly in Italy, it was found, next to a program certainly not entertainment or fiction, a phenomenon consisting of fruition online and just in time of the product (Baym), through social media that relaunched content and comments, cultivating a sense of belonging and community rituals and performative innovative audience.Nell between the 'context of a wider reflection on the relationship between use of new technologies, projections of identity and articulation of social relations (see, among others, Boase and Wellman 2006 Buckingham in 2008, Castells 2001, Castells et al., 2006 Wellman 2004), this paper refers, specifically, the broad debate developed around the concepts of convergence culture, participatory cultures , user generated content (see first Jenkins 2006 Jenkins et al., 200",,"Vieni via con me. Consumo televisivo, social media e civic engagement",,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
47520140,2014-04-14T00:00:00,"This paper reviews a cluster of recent and current researches in the field of visual attention conducted at the LEPSIS Lab (IFSTTAR). Taking advantage of the multidisciplinary structure of the research team, contributions have been proposed in the fields of image processing, artificial intelligence, virtual reality, cognitive psychology and ethology. In image processing, we have contributed to predictive models of the gaze fixations in a driving task, namely, looking for road signs, proposing a computational model of top-down visual attention. In artificial intelligence, a simple computational model of visual attention was proposed and implemented in an agent-based microscopic traffic simulation model. In virtual reality, the blink frequency was proposed in order to assess the relevance of driving simulators in terms of the driver's mental workload. In cognitive psychology, the visual conspicuity of powered two wheels was assessed on a driving simulator, leading to recommendations about their lighting system design; another contribution gave evidence that oculomotor patterns can reveal crossing decisions at crossroads. In cognitive ethology, a joint work is in progress with the CEREMA in order to study oculomotor patterns at crossroads in a field test, thanks to a dedicated vehicle.Cet article présente un ensemble de recherches récentes et en cours dans le domaine de l’attention visuelle, menées au laboratoire LEPSIS de l’IFSTTAR. Grâce à la structure pluridisciplinaire du laboratoire, des contributions ont été proposées dans les domaines du traitement d’images, de l’intelligence artificielle, de la réalité virtuelle, de la psychologie cognitive et de l’éthologie. En traitement d’images, nous avons proposé un modèle de calcul de la saillance visuelle des panneaux routiers, en référence à une tâche de conduite. En intelligence artificielle, nous avons implémenté un modèle d’attention visuelle pour améliorer la simulation de trafic microscopique. En réalité virtuelle, nous avons proposé d’utiliser les clignements pour mesurer la charge mentale sur simulateur de conduite. En psychologie cognitive, la saillance visuelle des deux roues motorisés a été étudiée, ce qui a permis d’aboutir à des recommandations sur le design des phares; nous avons également montré que les patterns oculomoteurs peuvent nous informer sur la décision de traverser en carrefour. En ethologie, des travaux conjoints avec le CEREMA sont en cours pour étudier le comportement oculomoteur en carrefour, grâce à un véhicule instrumenté",HAL CCSD,Where we look when we drive: A multidisciplinary approach,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
291395428,,"La publicació definitiva d'aquest treball està disponible a IOS Press a través de http://dx.doi.org/10.3233/978-1-61499-806-8-196Within the machine learning framework, incremental learning of multivariate spaces is of special interest for on-line applications. In this work, the regression problem for multivariate systems is solved by implementing an efficient probabilistic incremental algorithm. It allows learning high-dimensional redundant non-linear maps by the cumulative acquisition of data from input-output systems. The proposed model is aimed at solving prediction and inference problems. The implementation introduced in this work allows learning from data batches without the need of keeping them in memory afterwards. The learning architecture is built using Incremental Gaussian Mixture Models. The Expectation-Maximization algorithm and general geometric properties of Gaussian distributions are used to train the models. Our current implementation can produce accurate results fitting models in real multivariate systems. Results are shown from testing the algorithm for both situations, one where the incremental learning is demonstrated and the second where the performance to solve the regression problem is evaluated on a toy example.Peer Reviewe",'IOS Press',Multivariate Regression with Incremental Learning of Gaussian Mixture Models,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
83021791,2010-01-01T00:00:00,"This work was funded by the Companions project (2006-2009) sponsored by the European Commission as part of the Information Society Technologies (IST) programme under EC grant number IST-FP6-034434.This paper describes an initial prototype demonstrator of a Companion, designed as a platform for novel approaches to the following: 1) The use of Information Extraction (IE) techniques to extract the content of incoming dialogue utterances after an Automatic Speech Recognition (ASR) phase, 2) The conversion of the input to Resource Descriptor Format (RDF) to allow the generation of new facts from existing ones, under the control of a Dialogue Manger (DM), that also has access to stored knowledge and to open knowledge accessed in real time from the web, all in RDF form, 3) A DM implemented as a stack and network virtual machine that models mixed initiative in dialogue control, and 4) A tuned dialogue act detector based on corpus evidence. The prototype platform was evaluated, and we describe this briefly; it is also designed to support more extensive forms of emotion detection carried by both speech and lexical content, as well as extended forms of machine learning.peer-reviewe",The Association for Computational Linguistics,Demonstration of a prototype for a conversational companion for reminiscing about images,,https://core.ac.uk/download/83021791.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
76530664,2014,"State-of-the-art aeronautic Low Pressure gas Turbines (LPTs) are already characterized by high quality standards, thus they offer very narrow margins of improvement. Typical design process starts with a Concept Design (CD) phase, defined using mean-line 1D and other low-order tools, and evolves through a Preliminary Design (PD) phase, which allows the geometric definition in details. In this framework, multidisciplinary optimization is the only way to properly handle the complicated peculiarities of the design. The authors present different strategies and algorithms that have been implemented exploiting the PD phase as a real-like design benchmark to illustrate results. The purpose of this work is to describe the optimization techniques, their settings and how to implement them effectively in a multidisciplinary environment. Starting from a basic gradient method and a semi-random second order method, the authors have introduced an Artificial Bee Colony-like optimizer, a multi-objective Genetic Diversity Evolutionary Algorithm [1] and a multi-objective response surface approach based on Artificial Neural Network, parallelizing and customizing them for the gas turbine study. Moreover, speedup and improvement arrangements are embedded in different hybrid strategies with the aim at finding the best solutions for different kind of problems that arise in this fiel",,Multidiscipinary Optimization For Gas Turbines Design,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
197597588,2011,"BACKGROUND:

The aim of the study was to detect if right ventricular (RV) ejection fraction assessed by real-time 3-dimensional echocardiography (RT3DE) could predict patients with dilated cardiomyopathy (DCM) with greater functional impairment in response to cardiopulmonary exercise.

METHODS AND RESULTS:

Seventy chronic heart failure patients with DCM (55.5 ± 9.1 years; 48 males; 30 ischemic; New York Heart Association Class III: 48) underwent both left ventricular (LV) and RV analysis by RT3DE. Postprocessing software provided data of RT3DE systolic dyssynchrony index of 16 LV segments (systolic dyssynchrony index [SDI]) and of both LV and RV ejection fraction. Cardiac magnetic resonance was performed in a subgroup of 40 DCM patients to confirm RT3DE measurements. All the patients underwent also bicycle cardiopulmonary exercise test with evaluation of oxygen consumption (VO2) peak% (percentage of the predicted value), VE/VCO2 slope, and circulatory power (CP). Mean LV ejection fraction was 29.8 ± 4.6%. RT3DE LV SDI index was 8.4.4 ± 4.2, and RV ejection fraction was 51.3 ± 4.6%. By cardiopulmonary test, mean VO2 peak was 15.2 ± 4.4 mL·kg·min, and mean CP was 2.1 ± 0.8. By univariable analyses, significant correlations were detectable between SDI index and VO2 peak% (r = -0.56; P < .0001) and peak CP (r = -0.48; P < .0005). Also RV ejection fraction directly correlated with VO2 peak% (r = 0.58; P < .0001) and inversely with VE/VCO2 slope (r = -0.44; P < .001). By multivariable analysis, SDI index (β coefficient = -0.46; P < .001) and 3D RV ejection fraction (β coefficient = 0.42; P < .001) emerged as the only independent determinants of VO2 peak% during cardiopulmonary test.

CONCLUSIONS:

Increased LV electromechanical dyssynchrony and impaired RV function in DCM patients are independently associated with worse ability to perform aerobic exercise",,Right ventricular ejection fraction and left ventricular dyssynchrony by 3D echo correlate with functional impairment in patients with dilated cardiomyopathy.,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
288560397,2002,"The implementation of an artificial vision algorithm in real time is really attractive in such an application as the field of environment sensing. The SVCNN (stereo vision cellular neural network) chip is an analogue circuit able to compute in real time the Disparity Map from a couple of images by using a stereo visual system algorithm. A ""test-bed"" board for the 16×64 SVCNN chip is presented in this paper. This board is composed of an analogue processing core implemented by two 16×64 SVCNN chips together with a digital high performance pre-processing unit and a video grabbing section",IEEE,Test-bed board for 16X64 stereo vision CNN chip,10.1109/CNNA.2002.1035109,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275615551,2014-11-01T00:00:00,"© ACM (2014). This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in {Source Publication}, http://dx.doi.org/10.1145/2693787.2693794Looking for effective ways to understand how animals interact with computer-mediated systems, Animal-Computer Interaction (ACI) research should rely on the most natural and intrinsic behavior among the majority of living species: play. Animals are naturally motivated towards playing. Playful environments are, therefore, a promising scenario in which to start developing animal-centered ecosystems, and there are plenty of circumstances where playful environments could help to improve animals  well-being. However, developing a custom system for each possible context remains unfeasible, and more appealing solutions are required. If playful environments were equipped with intelligent capabilities, they could learn from the animals  behavior and automatically adapt themselves to the animals  needs and preferences by creating engaging playful activities for different purposes. Hence, this work will define intelligent playful environments for animals and explain how Ambient Intelligence (AmI) can contribute to create adaptable playful experiences for animals in order to improve their quality of life.This work was partially funded by the Spanish Ministry of Science and Innovation under the National R&D&I Program within the project CreateWorlds (TIN2010-20488). It also received support from a postdoctoral fellowship within the VALi+d Program of the Conselleria d'Educació, Cultura i Esport (Generalitat Valenciana) awarded to Alejandro Catalá (APOSTD/2013/013). The work of Patricia Pons has been supported by the Universitat Politecnica de Valencia under the 'Beca de Excelencia"" program, and currently by an FPU fellowship from the Spanish Ministry of Education, Culture and Sports (FPU13/03831).Pons Tomás, P.; Jaén Martínez, FJ.; Catalá Bolós, A. (2014). Animal Ludens: Building Intelligent Playful Environments for Animals. ACM. https://doi.org/10.1145/2693787.2693794SAlfrink, K., Peer, I. van, Lagerweij, H., Driessen, C., Bracke, M., and Copier, M. Pig Chase. Playing with Pigs project. 2012. www.playingwithpigs.nl.Amat, M., Camps, T., Brech, S. Le, and Manteca, X. Separation anxiety in dogs: the implications of predictability and contextual fear for behavioural treatment. Animal Welfare 23, 3 (2014), 263--266.Barker, S. B. and Dawson, K. S. The effects of animal-assisted therapy on anxiety ratings of hospitalized psychiatric patients. Psychiatric services 49, 6 (1998), 797--801.Bateson, P. and Martin, P. Play, Playfulness, Creativity and Innovation. Cambridge University Press, 2013.Bekoff, M. and Allen, C. Intentional communication and social play: how and why animals negotiate and agree to play. In Animal play: Evolutionary, comparative, and ecological perspectives. Cambridge University Press, 1997.Burghardt, G. M. The genesis of animal play. Testing the limits. MIT Press, 2006.Catal&#225;, A., Ja&#233;n, J., Pons, P., and Garc&#237;a-Sanjuan, F. Playful Creativity: Playing to Create Games on Surfaces. In A. Nijholt, ed., Playful User Interfaces. Springer Singapore, Singapore, 2014, 293--315.Catal&#225;, A., Pons, P., Ja&#233;n, J., Mochol&#237;, J. A., and Navarro, E. A meta-model for dataflow-based rules in smart environments: Evaluating user comprehension and performance. Science of Computer Programming 78, 10 (2013), 1930--1950.Cheok, A. D., Tan, R. T. K. C., Peiris, R. L., et al. Metazoa Ludens: Mixed-Reality Interaction and Play for Small Pets and Humans. IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans 41, 5 (2011), 876--891.Costello, B. and Edmonds, E. A Study in Play, Pleasure and Interaction Design. Proceedings of the 2007 conference on Designing pleasurable products and interfaces, (2007), 76--91.Csikszentmihalyi, M. Beyond Boredom and Anxiety. The Experience of Play in Work and Games. Jossey-Bass Publishers, 1975.Filan, S. L. and Llewellyn-Jones, R. H. Animal-assisted therapy for dementia: a review of the literature. International psychogeriatrics / IPA 18, 4 (2006), 597--611.Huizinga, J. Homo ludens. 1985.Kamioka, H., Okada, S., Tsutani, K., et al. Effectiveness of animal-assisted therapy: A systematic review of randomized controlled trials. Complementary therapies in medicine 22, 2 (2014), 371--390.Lee, S. P., Cheok, A. D., James, T. K. S., et al. A mobile pet wearable computer and mixed reality system for human--poultry interaction through the internet. Personal and Ubiquitous Computing 10, 5 (2006), 301--317.Mancini, C., van der Linden, J., Bryan, J., and Stuart, A. Exploring interspecies sensemaking: Dog Tracking Semiotics and Multispecies Ethnography. Proceedings of the 2012 ACM Conference on Ubiquitous Computing - UbiComp '12, ACM Press (2012), 143--152.Mancini, C. Animal-computer interaction: a manifesto. Magazine interactions 18, 4 (2011), 69--73.Mancini, C. Animal-computer interaction (ACI): changing perspective on HCI, participation and sustainability. CHI '13 Extended Abstracts on Human Factors in Computing Systems, ACM Press (2013), 2227--2236.Mankoff, D., Dey, A. K., Mankoff, J., and Mankoff, K. Supporting Interspecies Social Awareness: Using peripheral displays for distributed pack awareness. Proceedings of the 18th annual ACM symposium on User interface software and technology, (2005), 253--258.Matsuzawa, T. The Ai project: historical and ecological contexts. Animal cognition 6, 4 (2003), 199--211.McGrath, R. E. Species-appropriate computer mediated interaction. Proceedings of the 27th international conference extended abstracts on Human factors in computing systems - CHI EA '09, ACM Press (2009), 2529--2534.Norman, D. A. The invisible computer. MIT Press, Cambridge, MA, USA, 1998.Noz, F. and An, J. Cat Cat Revolution: An Interspecies Gaming Experience. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, (2011), 2661--2664.Paldanius, M., K&#228;rkk&#228;inen, T., V&#228;&#228;n&#228;nen-Vainio-Mattila, K., Juhlin, O., and H&#228;kkil&#228;, J. Communication technology for human-dog interaction. Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11, ACM Press (2011), 2641--2650.Pons, P., Catala, A., and Jaen, J. Customizing smart environments: a tabletop approach. Journal of Ambient Intelligence and Smart Environments, in press.Rumbaugh, D. M. Language learning by a chimpanzee: the Lana Project. Academic Press, 1977.Schwartz, S. Separation anxiety syndrome in cats: 136 cases (1991--2000). Journal of the American Veterinary Medical Association 220, 7 (2002), 1028--1033.Schwartz, S. Separation anxiety syndrome in dogs and cats. Journal of the American Veterinary Medical Association 222, 11 (2003), 1526--1532.Solomon, O. What a Dog Can Do: Children with Autism and Therapy Dogs in Social Interaction. Ethos: Journal of the Society for Psychological Anthropology 38, 1 (2010), 143--166.Teh, K. S., Lee, S. P., and Cheok, A. D. Poultry. Internet: a remote human-pet interaction system. CHI '06 Extended Abstracts on Human Factors in Computing Systems, (2006), 251--254.Weilenmann, A. and Juhlin, O. Understanding people and animals. Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11, ACM Press (2011), 2631--2640.Weiser, M. The computer for the 21st century. Scientific American 265, 3 (1991), 94--104.Wingrave, C. A., Rose, J., Langston, T., and LaViola, J. J. J. Early explorations of CAT: canine amusement and training. CHI '10 Extended Abstracts on Human Factors in Computing Systems, (2010), 2661--2669.Young, J., Young, N., Greenberg, S., and Sharlin, E. Feline Fun Park: A Distributed Tangible Interface for Pets and Owners. 2013. https://www.youtube.com/watch?v=HB5LsSYkhCc",'Association for Computing Machinery (ACM)',Animal Ludens: Building Intelligent Playful Environments for Animals,10.1145/2693787.2693794,https://riunet.upv.es/bitstream/handle/10251/68376/Animal%20Ludens.%20Building%20Intelligent%20Pla...ments%20for%20Animals%20-%20author%20version.pdf?sequence=3&isAllowed=y,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275603241,2010-01-01T00:00:00,"In this paper, we propose a secure spontaneous ad-hoc network, based on direct peer-to-peer interaction, to grant a quick, easy, and secure access to the users to surf the Web. The paper shows the description of our proposal, the procedure of the nodes involved in the system, the security algorithms implemented, and the designed messages. We have taken into account the security and its performance. Although some people have defined and described the main features of spontaneous ad-hoc networks, nobody has published any design and simulation until today. Spontaneous networking will enable a more natural form of wireless computing when people physically meet in the real world. We also validate the success of our proposal through several simulations and comparisons with a regular architecture, taking into account the optimization of the resources of the devices. Finally, we compare our proposal with other caching techniques published in the related literature. The proposal has been developed with the main objective of improving the communication and integration between different study centers of low-resource communities. That is, it lets communicate spontaneous networks, which are working collaboratively and which have been created on different physical places.Authors want to give thanks to the anonymous reviewers for their valuable suggestions, useful comments, and proofreading of this paper. This work was partially supported by the Ministerio de Educacion y Ciencia, Spain, under Grant no. TIN2008-06441-C02-01, and by the ""Ayudas complementarias para proyectos de I+D para grupos de calidad de la Generalitat Valenciana"" (ACOMP/2010/005).Lacuesta Gilaberte, R.; Lloret, J.; García Pineda, M.; Peñalver Herrero, ML. (2010). A spontaneous ad hoc network to share www access. EURASIP Journal on Wireless Communications and Networking. 2010:1-16. https://doi.org/10.1155/2010/232083S1162010Preuß S, Cap CH: Overview of spontaneous networking-evolving concepts and technologies. In Rostocker Informatik-Berichte. Volume 24. Fachbereich Informatik der Universit at Rostock; 2000:113-123.Gallo S, Galluccio L, Morabito G, Palazzo S: Rapid and energy efficient neighbor discovery for spontaneous networks. Proceedings of the 7th ACM International Symposium on Modeling, Analysis and Simulation of Wireless and Mobile Systems, October 2004, Venice, ItalyLatvakoski J, Pakkala D, Pääkkönen P: A communication architecture for spontaneous systems. IEEE Wireless Communications 2004, 11(3):36-42. 10.1109/MWC.2004.1308947Zarate Silva VH, De Cruz Salgado EI, Quintana FR: AWISPA: an awareness framework for collaborative spontaneous networks. Proceedings of the 36th ASEE/IEEE Frontiers in Education Conference (FIE '06), October 2006 1-6.Feeney LM, Ahlgren B, Westerlund A: Spontaneous networking: an application-oriented approach to ad hoc networking. IEEE Communications Magazine 2001, 39(6):176-181. 10.1109/35.925687Perkins CE, Bhagwat P: Highly dynamic destination-sequenced distance-vector routing (DSDV) for mobile computers. Proceedings of the Conference on Communications Architectures, Protocols and Applications (SIGCOMM '94), August 1994 234-244.Johnson DB, Maltz DA, Broch J: DSR: The Dynamic Source Routing Protocol for Multihop Wireless Ad Hoc Networks, Ad Hoc Networking. Addison-Wesley Longman Publishing, Boston, Mass, USA; 2001.Perkins C, Belding-Royer E, Das S: Ad hoc on-demand distance vector (AODV) routing. RFC 3561, July 2003Park V, Corson MS: IETF MANET Internet Draft ""draft-ietf-MANET-tora-spe03.txt"". Novemmer 2000.Viana AC, De Amorim MD, Fdida S, de Rezende JF: Self-organization in spontaneous networks: the approach of DHT-based routing protocols. Ad Hoc Networks 2005, 3(5):589-606.Gilaberte RL, Herrero LP: IP addresses configuration in spontaneous networks. Proceedings of the 9th WSEAS International Conference on Computers, July 2005, Athens, GreeceViana AC, Dias de Amorim M, Fdida S, de Rezende JF: Self-organization in spontaneous networks: the approach of DHT-based routing protocols. Ad Hoc Networks 2005, 3(5):589-606.Alvarez-Hamelin JI, Carneiro Viana A, Dias De Amorim M: Architectural considerations for a self-configuring routing scheme for spontaneous networks.,Tech. Rep. 1 October 2005.Lacuesta R, Peñalver L: Automatic configuration of ad-hoc networks: establishing unique IP link-local addresses. Proceedings of the International Conference on Emerging Security Information, Systems and Technologies (SECURWARE '07), October 2007, Valencia, SpainFoulks EF: Social network therapies and society: an overview. Contemporary Family Therapy 1985, 3(4):316-320.Wang Y, Wu H: DFT-MSN: the delay/fault-tolerant mobile sensor network for pervasive information gathering. Proceedings of the 25th IEEE International Conference on Computer Communications (INFOCOM '06), April 2006Kindberg T, Zhang K: Validating and securing spontaneous associations between wireless devices. In Proceedings of the 6th Information Security Conference (ISC '03), 2003. Springer; 44-53.Al-Jaroodi J: Routing security in open/dynamic mobile ad hoc networks. The International Arab Journal of Information Technology 2007, 4(1):17-25.Stajano F, Anderson RJ: The resurrecting duckling: security issues for ad-hoc wireless networks. Proceedings of the 7th International Workshop on Security Protocols, April 1999 172-194.Zhou L, Haas ZJ: Securing ad hoc networks. IEEE Network 1999, 13(6):24-30. 10.1109/65.806983Hauspie M, Simplot-Ryl I: Cooperation in ad hoc networks: enhancing the virtual currency based models. Proceedings of the 1st International Conference on Integrated Internet Ad Hoc and Sensor Networks (InterSense '06), May 2006, Nice, FranceWang X, Dai F, Qian L, Dong H: A way to solve the threat of selfish and malicious nodes for ad hoc networks. Proceedings of the International Symposium on Information Science and Engieering (ISISE '08), December 2008, Shanghai, China 1: 368-370.Kargl F, Klenk A, Weber M, Schlott S: Sensors for detection of misbehaving nodes in MANETs. Detection of Intrusion and Malware and Vulnerability Assessment (DIMVA '04), July 2004, Dortmund, Germany 83-97.Kargl F, Geiss A, Scholott S, Weber M: Secure dynamic source routing. Proceedings of the 38th Annual Hawaii International Conference on System Sciences (HICSS '05), January 2005, Big Island, Hawaii, USAGokhale S, Dasgupta P: Distributed authentication for peer-to-peer networks. Proceedings of the Symposium on Applications and the Internet Workshops, January 2003 347-353.Capkun S, Buttyán L, Hubaux J-P: Self-organized public-key management for mobile ad hoc networks. IEEE Transactions on Mobile Computing 2003, 2(1):52-64. 10.1109/TMC.2003.1195151Stajano F, Anderson R: The resurrecting duckling security issues for ad-hoc wireless networks. In Proceedings of the 7th International Workshop on Security Protocols, 1999, Berlin, Germany, Lecture Notes in Computer Science. Volume 1796. Springer; 172-194.Balfanz D, Smetters DK, Stewart P, Wong HC: Talking to strangers: authentication in ad-hoc wireless networks. Proceedings of the International Symposium on Network and Distributed Systems Security (NDSS '02), February 2002, San Diego, Calif, USABarbara D, Imielinski T: Sleepers and workaholics: caching strategies in mobile environments. Proceedings of the ACM SIGMOD International Conference on Management of Data, May 1994 1-12.Cao G: A scalable low-latency cache invalidation strategy for mobile environments. IEEE Transactions on Knowledge and Data Engineering 2003, 15(5):1251-1265. 10.1109/TKDE.2003.1232276Hu Q, Lee D: Cache algorithms based on adaptive invalidation reports for mobile environments. Cluster Computing 1998, 1(1):39-50. 10.1023/A:1019012927328Jing J, Elmagarmid A, Helal A, Alonso R: Bit-sequences: an adaptive cache invalidation method in mobile client/server environments. Mobile Networks and Applications 1997, 2(2):115-127. 10.1023/A:1013616213333Kahol A, Khurana S, Gupta S, Srimani P: An efficient cache management scheme for mobile environment. Proceedings of the 20th International Conference on Distributied Computing System (ICDCS '00), April 2000, Taipei, Taiwan 530-537.Kazar M: Synchronization and caching issues in the Andrew file system. Proceedings of USENIX Conference, February 1988, Dallas, Tex, USA 27-36.Roussopoulos M, Baker M: CUP: controlled update propagation in peer-to-peer networks. Proceedings of USENIX Annual Technical Conference, June 2003, San Antonio, Tex, USASandberg S, Kleiman S, Goldberg D, Walsh D, Lyon B: Design and implementation of the sun network file system. Proceedings of USENIX Summer Conference, June 1985, Portland, Ore, USA 119-130.Wu K, Yu PS, Chen M: Energy-efficient caching for wireless mobile computing. Proceedings of the 12th IEEE International Conference on Data Engineering, February-March 1996, New Orleans, La, USA 336-343.Yeung MKH, Kwok Y-K: Wireless cache invalidation schemes with link adaptation and downlink traffic. IEEE Transactions on Mobile Computing 2005, 4(1):68-83.Wessels D, Claffy K: Internet cache protocol (IC) v.2. http://www.ietf.org/rfc/rfc2186.txtFan L, Cao P, Almeida J, Broder AZ: Summary cache: a scalable wide-area web cache sharing protocol. IEEE/ACM Transactions on Networking 2000, 8(3):281-293. 10.1109/90.851975Dykes SG, Robbins KA: A viability analysis of cooperative proxy caching. Proceedings of the 20th Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM '01), April 2001, Anchorage, Alaska, USA 3: 1205-1214.Wessels D, Claffy K: RFC 2186: Internet cache protocol (ICP), version 2. The Internet Engineering Taskforce, September 1997Wessels D, Claffy K: RFC 2187: application of internet cache protocol (ICP), version 2. The Internet Engineering Taskforce, September 1997Ren Q, Dunhan MH: Using semantic caching to manage location dependent data in mobile computing. Proceedings of the 6th Annual International Conference on Mobile Computing and Networking, August 2000, Boston, Mass, USA 210-221.Lim S, Lee W-C, Cao G, Das CR: Cache invalidation strategies for internet-based mobile ad hoc networks. Computer Communications 2007, 30(8):1854-1869. 10.1016/j.comcom.2007.02.020Park B-N, Lee W, Lee C: QoS-aware internet access schemes for wireless mobile ad hoc networks. Computer Communications 2007, 30(2):369-384. 10.1016/j.comcom.2006.09.004Hara T: Effective replica allocation in ad hoc networks for improving data accessibility. Proceedings of the 20th Annual Joint Conference of the IEEE Computer and Communications Societies (INFOCOM '01), April 2001, Anchorage, Alaska, USA 1568-1576.Papadopouli M, Schulzrinne H: Effects of power conservation, wireless converage and cooperation on data dissemination among mobile devices. Proceedings of the ACM International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc '01), October 2001, Long Beach, Calif, USA 117-127.Can P, Irani S: Cost-aware WWW proxy caching algorithms. Proceedings of the USENIX Symposium on lnternet Technology and Systems, December 1997Rizzo L, Vicisano L: Replacement policies for a proxy cache. IEEE/ACM Transactions on Networking 2000, 8(2):158-170. 10.1109/90.842139Williams S, Abrams M, Strandridge CR, Abdulla G, Fox EA: Removal policies in network caches for world-wide web documents. Proceedings of the ACM SIGCOMM Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications, August 1996, Palo Alto, Calif, USA 293-305.Hara T: Replica allocation in ad hoc networks with period data update. Proceedings of the 3rd International Conference on Mobile Data Management (MDM '02), July 2002, Edmonton, Canada 79-86.Papadopouli M, Schulzrinne H: Effects of power conservation, wireless coverage and cooperation on data dissemination among mobile devices. Proceedings of the ACM International Symposium on Mobile Ad Hoc Networking and Computing (MobiHoc '01), October 2001, Long Beach, Calif, USA 117-127.Sailhan F, Issarny V: Cooperative caching in ad hoc networks. Proceedings of the 4th International Conference on Mobile Data Management (MDM '03), January 2003, Melbourne, Australia, Lecture Notes in Computer Science 2574: 13-28.Yin L, Cao G: Supporting cooperative caching in ad hoc networks. IEEE Transactions on Mobile Computing 2006, 5(1):77-89.Karumanchi G, Muralidharan S, Prakash R: Information dissemination in partitionable mobile ad hoc networks. Proceedings of the 18th IEEE Symposium on Reliable Distributed Systems (SRDS '99), October 1999, Lausanne, Switzerland 4-13.Corson MS, Macker JP, Cirincione GH: Internet-based mobile ad hoc networking. IEEE Internet Computing 1999, 3(4):63-70. 10.1109/4236.780962Lim S, Lee W-C, Cao G, Das CR: A novel caching scheme for improving internet-based mobile ad hoc networks performance. Ad Hoc Networks 2006, 4(2):225-239. 10.1016/j.adhoc.2004.04.013Opnet Modeler http://www.opnet.com/solutions/network_rd/modeler_wireless.htmlLacuesta R, Lloret J, Garcia M, Peñalver L: Two secure and energy-saving spontaneous ad-hoc protocol for wireless mesh client networks. Journal of Network and Computer Applications. In pres",'Hindawi Limited',A spontaneous ad hoc network to share www access,10.1155/2010/232083,https://riunet.upv.es/bitstream/handle/10251/51077/RAQUEL%20LAQUESTA%20GILABERTE%3bLloret%3bGarc%c3%ada%20-%20A%20Spontaneous%20Ad%20Hoc%20Network%20to%20Share%20WWW%20Access.pdf?sequence=1&isAllowed=y,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275622154,2006-01-01T00:00:00,"[EN] In this paper, a new CBR system for Technology Management Centers is presented. The system helps the staff of the centers to solve customer problems by finding solutions successfully applied to similar problems experienced in the past. This improves the satisfaction of customers and ensures a good reputation for the company who manages the center and thus, it may increase its profits. The CBR system is portable, flexible and multi-domain. It is implemented as a module of a help-desk application to make the CBR system as independent as
possible of any change in the help-desk. Each phase of the reasoning cycle is implemented as a series of configurable plugins, making the CBR module easy to update and maintain. This system has been introduced and tested in a real Technology Management center ran by the Spanish company TISSAT S.A.Financial support from Spanish government under grant PROFIT FIT-340001-2004-11 is gratefully acknowledgeHeras Barberá, SM.; Garcia Pardo Gimenez De Los Galanes, JA.; Ramos-Garijo Font De Mora, R.; Palomares Chust, A.; Julian Inglada, VJ.; Rebollo Pedruelo, M.; Botti, V. (2006). CBR model for the intelligent management of customer support centers. En Lecture Notes in Computer Science. Springer Verlag (Germany). 663-670. https://doi.org/10.1007/11875581_80S663670Acorn, T., Walden, S.: SMART: SupportManagement Automated Reasoning Technology for Compaq Customer Service. In: Scott, A., Klahr, P. (eds.) Proceedings of the 2 International Conference on Intelligent Tutoring Systems, ITS-92 Berlin, vol. 4, pp. 3–18. AAAI Press, Menlo Park (1992)Simoudis, E.: Using Case-Based Retrieval for Customer Technical Support. IEEE Intelligent Systems 7, 10–12 (1992)Kriegsman, M., Barletta, R.: Building a Case-Based Help Desk Application. IEEE Expert: Intelligent Systems and Their Applications 8, 18–26 (1993)Shimazu, H., Shibata, A., Nihei, K.: Case-Based Retrieval Interface Adapted to Customer-Initiated Dialogues in Help Desk Operations. In: Mylopoulos, J., Reiter, R. (eds.) Proceedings of the 12th National Conference on Artificial Intelligence, vol. 1, pp. 513–518. AAAI Press, Menlo Park (1994)Raman, R., Chang, K.H., Carlisle, W.H., Cross, J.H.: A self-improving helpdesk service system using case-based reasoning techniques. Computers in Industry 2, 113–125 (1996)Kang, B.H., Yoshida, K., Motoda, H., Compton, P.: Help Desk System with Intelligent Interface. Applied Artificial Intelligence 11, 611–631 (1997)Roth-Berghofer, T., Iglezakis, I.: Developing an Integrated Multilevel Help-Desk Support System. In: Proceedings of the 8th German Workshop on Case-Based Reasoning, pp. 145–155 (2000)Goker, M., Roth-Berghofer, T.: The development and utilization of the case-based help-desk support system HOMER. Engineering Applications of Artificial Intelligence 12, 665–680 (1999)Roth-Berghofer, T.R.: Learning from HOMER, a case-based help-desk support system. In: Melnik, G., Holz, H. (eds.) Advances in Learning Software Organizations, pp. 88–97. Springer, Heidelberg (2004)Bergmann, R., Althoff, K.D., Breen, S., Göker, M., Manago, M., Traphöner, R., Wess, S.: Developing Industrial Case-Based Reasoning Applications. In: The INRECA Methodology, 2nd edn. LNCS (LNAI), vol. 1612. Springer, Heidelberg (2003)eGain (2006), http://www.egain.comKaidara Software Corporation (2006), http://www.kaidara.com/Empolis Knowledge Management GmbH - Arvato AG (2006), http://www.empolis.com/Althoff, K.D., Auriol, E., Barletta, R., Manago, M.: A Review of Industrial Case-Based Reasoning Tools. AI Perspectives Report. Goodall, A., Oxford (1995)Watson, I.: Applying Case-Based Reasoning. Techniques for Enterprise Systems. Morgan Kaufmann Publishers, Inc. California (1997)empolis: empolis Orenge Technology Whitepaper. Technical report, empolis GmbH (2002)Tissat, S.A. (2006), http://www.tissat.esGiraud-Carrier, C., Martinez, T.R.: An integrated framework for learning and reasoning. Journal of Artificial Intelligence Research 3, 147–185 (1995)Corchado, J.M., Borrajo, M.L., Pellicer, M.A., Yanez, J.C.: Neuro-symbolic system for Business Internal Control. In: Perner, P. (ed.) ICDM 2004. LNCS (LNAI), vol. 3275, pp. 1–10. Springer, Heidelberg (2004)Aamodt, A., Plaza, E.: Case-based reasoning: foundational issues, methodological variations and system approaches. AI Communications 7(1), 39–59 (1994)Tversky, A.: Features of similarity. Psychological Review 84(4), 327–352 (1997",'Springer Science and Business Media LLC',CBR model for the intelligent management of customer support centers,10.1007/11875581_80,https://riunet.upv.es/bitstream/10251/78887/3/ideal06.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226069866,2010,"Introduzione. Il gene dell’Interleuchina 6 (IL-6) nell’uomo è localizzato sul braccio corto del cromosoma 7 (7p21) e ha un polimorfismo G→C in posizione –174 del promotore. La presenza di una sequenza di AT altamente ripetute in corrispondenza della 3’“flanking region” del gene dell’IL-6 dà luogo al polimorfismo delle “variable number of tandem repeats” (VNTR). La presenza dell’allele C (640 bp) nella regione VNTR è stata associata con una ridotta attività dell’IL-6. È stato anche riportato che il polimorfismo G→C in posizione –174 del promotore è associato con una ridotta espressione genica e con ridotti livelli plasmatici di IL-6. Precedenti studi condotti su popolazioni anziane hanno messo in evidenza che i soggetti geneticamente predisposti a produrre elevati livelli di IL-6, ad esempio maschi omozigoti per l’allele G del promotore, hanno una ridotta capacità di raggiungere l’estrema longevità.

Scopo dello studio. Scopo dello studio è stato valutare la presenza di un’associazione fra i polimorfismi della regione VNTR dell’IL-6 e l’estrema longevità, in una popolazione di centenari pugliesi, e valutare la possibile interazione fra gli alleli della regione VNTR e gli alleli dell’Apolipoproteina E (APOE).

Materiali e metodi. Sono stati studiati 155 soggetti pugliesi, di cui 61 centenari (13 maschi e 48 femmine, età media 100 ± 2 anni). Il gruppo di controllo di 94 soggetti (32 maschi e 62 femmine, età media 52 ± 18 anni) era costituito da volontari sani osservati fra il giugno 2007 e aprile 2008. A tutti i soggetti sono stati prelevati 2 cc circa di sangue da cui è stato estratto il DNA per l’analisi del genotipo dell’APOE e dei genotipi della regione VNTR dell’IL-6. L’analisi del polimorfismo della regione VNTR è stata eseguita mediante PCR e successiva elettroforesi su gel di agarosio 3%. L’analisi del polimorfismo dell’APOE è stata eseguita mediante Real-Time PCR – Fluorescence Resonance Energy Transfer (FRET) system – e successiva analisi delle curve di melting. È stata eseguita un’analisi mediante test del χ2 per valutare la presenza di eventuali differenze fra le frequenze alleliche della regione VNTR nei centenari rispetto ai controlli. Per l’analisi dei dati è stato usato il software statistico STATA SE versione 8.0. Risultati. È stata rilevata una sovra-rappresentazione statisticamente significativa dell’allele B (680bp) della regione VNTR nei soggetti di controllo rispetto ai centenari (allele B vs allele C, allele D e allele A Pearson χ2 = 6.31, Bonferroni p < 0.05; Odds Ratio: 0.56, IC 95%: 0.35–0.88, Bonferroni p-value < 0.05); Non sono state rilevate differenze statisticamente significative per la distribuzione degli alleli A (760bp), C (640bp) e D (760bp) fra centenari e controlli (allele D vs allele C, allele B e allele A Pearson χ2 = 0.59, Bonferroni p = 1.76; allele C vs allele D, allele B e allele A Pearson χ2 = 4.8, Bonferroni p = 0.11; allele A vs allele C, allele B e allele D Pearson χ2 = 0.1, Bonferroni p = 3.03). A causa dell’esiguità del campione, non è stato possibile calcolare l’odds ratio per valutare un’eventuale associazione, nei centenari, fra gli alleli del VNTR, e gli alleli dell’APOE. Conclusioni. Il nostro studio ha messo per la prima volta in evidenza come i polimorfismi della regione VNTR dell’IL-6 possano giocare un ruolo nella longevità. Infatti, precedenti studi condotti per verificare il ruolo del gene

dell’IL6 gene nella longevità nell’uomo, hanno interessato esclusivamente il polimorfismo IL6 -174 G/C del promotore. I risultati del nostro studio suggeriscono che la presenza dell’allele B della regione VNTR dell’IL6 allele B potrebbe determinare un incremento dell’espressione del gene dell’IL6, magari aumentandone la produzione di mRNA, e quindi i livelli sierici dell’IL-6. Mentre precedenti studi hanno dimostrato come la presenza dell’allele C

della regione VNTR dell’IL-6 può essere associate con livelli sierici di IL6 più bassi, il che può essere vantaggioso nel raggiungimento dell’età avanzata, non ci sono attualmente studi di associazione genotipo-fenotipo che possono dimostrare un effetto della presenza dell’allele B del VNTR sui livelli sierici

di IL6. I risultati del nostro studio vanno comunque interpretati con cautela. Si tratta infatti di un analisi di tipo trasversale su di un numero esiguo di

centenari, il che ha costituito un limite per la potenza statistica dello studio, non consentendo di raggiungere conclusioni definitive. Inoltre, non è stato

possibile valutare la possibile interazione fra gli alleli della regione VNTR e gli alleli dell’Apolipoproteina E (APOE) a causa dell’esiguità del campione,

e del numero assai basso di soggetti portatori dell’allele ε4- ad ε2- nei centenari e nei controlli. Infine, non è stata valutata una possibile associazione

fra gli alleli della regione VNTR dell’IL6 e i livelli sierici di IL6, per definire una spiegazione biologica del ruolo svantaggioso della presenza dell’allele B

della regione VNTR nel raggiungimento dell’estrema longevità. Solo studi di tipo longitudinale specificamente disegnati per verificare il ruolo degli alleli

della regione VNTR dell’IL6 sulla longevità potranno fornire evidenze più significative per un ulteriore comprensione del ruolo di questi polimorfismi

nel raggiungimento dell’estrema longevità",Pacini Editore S.p.A.,Polimorfismi della regione VNTR del gene dell’Interleuchina 6 e interazione con l’ApoE in una popolazione di centenari del sud italia.,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
202124266,1998-12-31,"AbstractImpressive work has been done in the last years concerning the meaning of negation and disjunction in logic programs, but most of this research concentrated on propositional programs only. While it suffices to consider the propositional case for investigating general properties and the overall behavior of a semantics, we feel that for real applications and for computational purposes an implementation should be able to handle first-order programs without grounding them. In this paper we present a theoretical framework by defining a calculus of program transformations that apply directly to rules with variables and function symbols. Our main results are that (a) this calculus is weakly confluent for arbitrary programs (i.e., it has the normal form property), (b) it is weakly terminating for Datalog ∨,¬ programs, (c) for finite ground programs it is equivalent to a weakly terminating calculus introduced by Brass and Dix (S.Brass, J.Dix, in: J.Dix, L.Pereira, T.Przymusinski (Eds.), Non-monotonic Extensions of Logic Programming, Springer Lecture Notes in Artificial Intelligence, Vol.927, Springer, Berlin, 1995, pp. 127–155), and (d) it approximates a generalization of Disjunctive Well-founded semantics (D-WFS) for arbitrary programs. We achieve this by transforming program rules into rules with equational constraints thereby using heavily methods and techniques from constraint logic programming (CLP). In particular, disconnection-methods play a crucial role. In principle, any constraint theory known from CLP can be exploited in the context of non-monotonic reasoning, not only equational constraints over the Herbrand domain. However, the respective constraint solver must be able to treat negative constraints of the considered constraint domain. In summary, this work yields the basis for a general combination of two paradigms: constraint logic programming and non-monotonic reasoning",Elsevier Science B.V.,A framework to incorporate non-monotonic reasoning into constraint logic programming ,10.1016/S0743-1066(98)10003-1,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
53832591,2010,"It is known that one of the most critical issues for the implementation of a fully automatic processing dedicated to the detection of oil spills from SAR imagery is the extraction of the oil spill candidate. In fact, the segmentation of the image is the first of three necessary steps, the other two being the characterization of the extracted black spot by using a set of features and the classification between oil spill and look-alike. In this paper we investigate an unsupervised neural network approach for automatically extracting oil spill candidates from ERS and ENVISAT SAR images. The technique is based on the use of Pulse-Coupled Neural Networks (PCNN) which is a relatively novel technique based on models of the visual cortex of small mammals. When applied to image processing, it yields a series of binary pulsed signals, each associated to one pixel or to a cluster. In literature, interesting results have been already reported by several authors in applications of this model to image segmentation, including, in few cases, the use of satellite data. The architecture of PCNN is rather simpler than most other neural network implementations. PCNN do not have multiple layers and receive input directly from the original image, forming a resulting “pulse” image. The network consists of multiple nodes coupled together with their neighbors within a definite distance, forming a grid (2D-vector). The PCNN neuron has two input compartments: linking and feeding. The feeding compartment receives both an external and a local stimulus, whereas the linking compartment only receives a local stimulus. When the internal activity becomes larger than an internal threshold, the neuron fires and the threshold sharply increases. Afterward, it begins to decay until once again the internal activity becomes larger. This process gives rise to the pulsing nature of PCNN, forming a wave signature which is invariant to rotation, scale, shift or skew of an object within the image. This study discusses the use of PCNN technique in a fully automatic chain for oil spill detection from SAR images. The objects segmented by the PCNN are successively processed by a more standard Multi-Layer Perceptron Neural Network, which provides the classification response between real oil spill and look-alike. The performance yielded by the PCNN-MLP chain is evaluated and critically discussed for a set of ERS-SAR and ENVISAT ASAR images. The application of the methodology to the very-high resolution SAR images taken by COSMO-Skymed and TerraSAR-X satellites will be also considered",,Pulse coupled neural networks for automatic oil spill detection from satellite SAR images,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
82019810,2011-08-31,"AbstractObjective(s)Patient-specific simulated rehearsal (PsR) is a technological advance within the domain of endovascular virtual reality (VR) simulation. It allows incorporation of patient-specific computed tomography Digital Imaging and Communications in Medicine (CT DICOM) data into the simulation and subsequent rehearsal of real patient cases. This study aimed to evaluate whether a part-task rehearsal (PTr) of a carotid artery stenting procedure (CAS) on a VR simulator is as effective as a full-task (FTr) preoperative run through.MethodsMedical trainees were trained in the CAS procedure and randomised to a PTr or FTr of a challenging CAS case (Type-II arch). PTr consisted of 30min of repeated catheterisations of the common carotid artery (CCA). Thereafter, both groups performed the CAS procedure in a fully functional simulated operating suite (SOS) with an interventional team. Technical performances were assessed using simulator-based metrics and expert ratings. Other aspects of performance were assessed using the Non-Technical Skills for Surgeons (NOTSS) scoring.ResultsTwenty trainees were evenly randomised to either PTr or FTr. No differences in performance were seen except for the total time the embolic protection device (EPD) was deployed (9.4min for the PT vs. 8.1min for the FT, p=0.02). Total time (26.3 vs. 25.5min, p=0.94), fluoroscopy time (15.8 vs. 14.4min, p=0.68), number of roadmaps (10.5 vs. 11.0, p=0.54), amount of contrast (53.5 vs. 58.0ml, p=0.33), time to deploy the EPD (0.9 vs. 0.8min, p=0.31) and time to catheterise the CCA (9.2 vs. 8.9min, p=0.94) were similar. Qualitative performances as measured by expert ratings (score 24 vs. 24, p=0.49) and NOTSS (p>0.05 for all categories) were also comparable.ConclusionsPart- and full-task rehearsals are equally effective with respect to the operative performance of a simulated CAS intervention. This finding makes a patient-specific rehearsal more efficient and may increase the feasibility of implementation of this technology into medical practice",European Society for Vascular Surgery. Published by Elsevier Ltd.,Efficient Implementation of Patient-specific Simulated Rehearsal for the Carotid Artery Stenting Procedure: Part-task Rehearsal ,10.1016/j.ejvs.2011.03.032,https://core.ac.uk/download/pdf/82019810.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
234909889,2014,"State-of-the-art aeronautic Low Pressure gas Turbines (LPTs) are already

characterized by high quality standards, thus they offer very narrow margins of

improvement. Typical design process starts with a Concept Design (CD) phase,

defined using mean-line 1D and other low-order tools, and evolves through a

Preliminary Design (PD) phase, which allows the geometric definition in

details. In this framework, multidisciplinary optimization is the only way to

properly handle the complicated peculiarities of the design. The authors

present different strategies and algorithms that have been implemented

exploiting the PD phase as a real-like design benchmark to illustrate results.

The purpose of this work is to describe the optimization techniques, their

settings and how to implement them effectively in a multidisciplinary

environment. Starting from a basic gradient method and a semi-random second

order method, the authors have introduced an Artificial Bee Colony-like

optimizer, a multi-objective Genetic Diversity Evolutionary Algorithm [1] and a

multi-objective response surface approach based on Artificial Neural Network,

parallelizing and customizing them for the gas turbine study. Moreover, speedup

and improvement arrangements are embedded in different hybrid strategies with

the aim at finding the best solutions for different kind of problems that arise

in this field",,Multidiscipinary Optimization For Gas Turbines Design,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
201948697,2007-10-23,"ObjectivesWe tested a newly developed 4-dimensional (4D) right ventricular (RV) analysis method for computing RV volumes for both 3-dimensional (3D) ultrasound (US) and magnetic resonance (MR) images.BackgroundAsymmetry and the anatomical complexity of the RV make accurate determination of RV shape and volume difficult.MethodsThirty patients, 14 with grossly normal cardiac anatomy and 16 with major congenital heart disease, were studied at the same visit with both 3D echocardiography (echo) and magnetic resonance imaging (MRI) for RV size and function. Ultrasound images were acquired on a Philips 7500 system (Philips Medical Systems, Andover, Massachusetts) with a matrix-array transducer (real-time 3D echo) with full volume sweeps from apical and subcostal views. Sagittal, 4-chamber, and coronal views were derived for contour detection (all 12 to 24 slices). The MR images were acquired with a 3-T MRI magnet with segmented cine-loop gradient echo sequences in short- and rotated long-axis views to cover the RV inflow, body, and outflow tract. The RV volumes were analyzed with the new software applicable to 3D echo MR images.ResultsNew software aided delineation of the RV free wall, tricuspid valve, RV outflow tract, and apex on 3D echo volumes. Although there was a slightly higher variability measuring right ventricular ejection fraction (RVEF) and volumes obtained by US compared with MRI, both imaging methods showed closely correlated results. The RVEF was measured with 4% variability for US and 5% variability for MRI with a correlation coefficient of r = 0.91. The RV end-diastolic volume was measured at 70.97 ± 15.0 ml with 3D US and at 70.06 ± 14.8 ml with MRI (r = 0.99), end-systolic volume measured 39.8 ± 10.4 ml with 3D US and 39.1 ± 10.2 ml with MRI (r = 0.98).ConclusionsThe new RV analysis software allowed validation of the accuracy of 4D echo RV volume data compared with MRI",American College of Cardiology Foundation. Published by Elsevier Inc.,Anatomically Oriented Right Ventricular Volume Measurements With Dynamic Three-Dimensional Echocardiography Validated by 3-Tesla Magnetic Resonance Imaging ,10.1016/j.jacc.2007.07.031,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
58800040,2012-09-01T00:00:00,"Traffic accidents are still one of the main health problems in the World. A number of measures have been applied in order to reduce the number of injuries and fatalities in roads, i.e., implementation of Advanced Driver Assistance Systems (ADAS) based on image processing. In this paper, a real time speed supervisor based on road sign recognition that can work both in urban and non-urban environments is presented. The system is able to recognize 135 road signs, belonging to the danger, yield, prohibition obligation and indication types, and sends warning messages to the driver upon the combination of two pieces of information: the current speed of the car and the road sign symbol. The core of this paper is the comparison between the two main methods which have been traditionally used for detection and recognition of road signs: template matching (TM) and neural networks (NN). The advantages and disadvantages of the two approaches will be shown and commented. Additionally we will show how the use of well-known algorithms to avoid illumination issues reduces the amount of images needed to train a neural network.The work reported in this article has been partly funded by the Spanish Government by the grants
FEDORA (TRA2010-20225-C03-01) and D3System (TRA2011-29454-C03-02)",'MDPI AG',Recognition Stage for a Speed Supervisor Based on Road Sign Detection,10.3390/s120912153,,"[{'title': 'Sensors', 'identifiers': ['issn:1424-8220', '1424-8220']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
58785997,2007-10-01T00:00:00,"One of the main obstacles in applying AI planning techniques to real problems is the difficulty to model the domains. Usually, this requires that people that have developed the planning system carry out the modeling phase since the representation depends very much on a deep knowledge of the internal working of the planning tools. On some domains such as business process reengineering (BPR), there has already been work on the definition of languages that allow non-experts entering knowledge on processes into the tools. We propose here the use of one of such BPR languages to enter knowledge on the organisation processes to be used by planning tools. Then, planning tools can be used to semi-automatically generate business process models.
As instances of this domain, we will use the workflow modeling tool SHAMASH, where we have exploded its object oriented structure to
introduce the knowledge through its user-friendly interface and, using a translator transform it into predicate logic terms. After this conversion,
real models can be automatically generated using a planner that integrates planning and scheduling, IPSS. We present results in a real workflow domain, the telephone installation (TI) domain.The SHAMASH project has being carried out in the course of the R&D project funded by the Esprit Program of the Commission of the European Communities as project number 25491. A complementary grant was given by the Spanish research commission, CICYT, under project number
TIC98-1847-CE. We thank the partners of this project, who have originated and contributed to the ideas reported: UF (Unio´n Fenosa), SAGE (Software AG Espan˜ a), SEMA GROUP sae, UC3M (Universidad Carlos III de Madrid), WIP (Wirstchaft und infrastruktur & Co Planungs
KG), and EDP (Electricidade de Portugal). We would
specially like to thank all the UC3M team, the PLANET people and Paul Kearney (BT). Through talks with him we have outlined many ideas. This work has also been partially funded by grant MCyT TIC2002-04146-C05-05 and the UAH project PI2005/084.Publicad",'Elsevier BV',Integrating planning and scheduling in workflow domains,10.1016/j.eswa.2006.05.027,,"[{'title': 'Expert Systems with Applications', 'identifiers': ['0957-4174', 'issn:0957-4174']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
323317294,2011-07-10T00:00:00,"[EN] This paper presents the current situation and future perspectives on virgin olive oil elaboration process control. Regarding the current situation, a review of previous research works on the matter is made. Subsequently, the results of a Spain-wide survey are shown in order to show a precise and realistic degree of the process automation in this area. Finally, the authors present, according to their opinion, the future research lines on the olive oil elaboration process control field.[ES] En este trabajo se presenta la situación actual y perspectivas de futuro del control del proceso de elaboración del aceite de oliva virgen. Dentro del estado actual se muestra, por un lado, un análisis de los trabajos previos de investigación que tratan sobre esta problemática. Por otro lado se recogen los resultados de una encuesta realizada a nivel de toda España para conocer, de forma precisa y real, cuál es el grado de automatización actual de dicho proceso. Finalmente se indican cuáles serán, a juicio de los autores y dentro del campo de la automática, las futuras líneas de investigación de este campo.Los autores quieren agradecer la subvencion parcial de esta investigación a través de los proyectos DPI2008-05798/DPI, TEP2009-5363 y UJA 08 16 31.Cano Marchal, P.; Gómez Ortega, J.; Aguilera Puerto, D.; Gámez García, J. (2011). Situación actual y perspectivas futuras del control del proceso de elaboración del aceite de oliva virgen. Revista Iberoamericana de Automática e Informática industrial. 8(3):258-269. https://doi.org/10.1016/j.riai.2011.06.013OJS25826983Agencia para el Aceite de Oliva, 2009. Datos de información del sector del aceite de oliva en españa. http://aao.mapa.es/.Aguilera, D., Ortega, J.G., 2005. Automatización del proceso de extración del aceite de oliva. situación en la provincia de jaen. XXVI Jornadas de Autom ática.Alba, J., 1997. Elaboración de aceite de oliva virgen. In: Barranco, D., Fernández-Escobar, R., Rallo, L. (Eds.), El cultivo del olivo, 2nd Edition. Mundi-Prensa, Madrid.Bordons, C., Cueli, J., 2004. Predictive controller with estimation of mesurable disturbances. application to an olive oil mill. Journal of Process Control, 305-315.Bordons, C., & Núñez-Reyes, A. (2008). Model based predictive control of an olive oil mill. Journal of Food Engineering, 84(1), 1-11. doi:10.1016/j.jfoodeng.2007.04.011Bordons, C., Zafra, M., 2003. An inferential sensor for the olive oil industry. In: European Control Conference (1). Vol. 1. Cambridge Universtity Press.Cert, A., Alba, J., León-Camacho, M., Moreda, W., & Pérez-Camino, M. C. (1996). Effects of Talc Addition and Operating Mode on the Quality and Oxidative Stability of Virgin Olive Oils Obtained by Centrifugation. Journal of Agricultural and Food Chemistry, 44(12), 3930-3934. doi:10.1021/jf9603386Civantos, L., 1998. Obtención del aceite de oliva virgen. Editorial Agrícola Española, S.A. COI,;1; 2009. Datos de producción mundial de aceite de oliva. http://www.internationaloliveoil.org/.Covas, M.-I., Nyyssönen, K., Poulsen, H. E., Kaikkonen, J., Zunft, H.-J. F., … Kiesewetter, H. (2006). The Effect of Polyphenols in Olive Oil on Heart Disease Risk Factors. Annals of Internal Medicine, 145(5), 333. doi:10.7326/0003-4819-145-5-200609050-00006Esposto, S., GianFrancesco, M., Roberto, S., Ibanez, R., Agnese, T., Stefania, U., Maurizio, S., 2008. Monitoring of virgin olive oil volatile compounds evolution during olive malaxation by an array of metal oxide sensors. Food Chemistry 2000.Fuentes, J.M., Nickel, M.N., 2003. Desarrollo tecnológico en la industria de extracción de aceite de oliva: un análisis dinámico. In: Foro Económico y Social de Expoliva. Jaén.Furferi, R., Carfagni, M., Daou, M., 2007. Artificial neural network software for real-time estimation of olive oil qualitative parameters during continuous extraction. Computers and Electronics in Agriculture 55, 115-131.Di Giovacchino, L., Sestili, S., & Di Vincenzo, D. (2002). European Journal of Lipid Science and Technology, 104(9-10), 587-601. doi:10.1002/1438-9312(200210)104:9/103.0.co;2-mHermoso, M., Jiménez, A., Uceda, M., Morales, J., 1999. Automatizaci ón de almazaras. controles experimentales para la caracterización y regulación del proceso de elaboración www.inia.es/gcontrec/pub/970151058524220453:pdf.Jiménez Marquez, A., Aguilera Herrera, M. P., Uceda Ojeda, M., & Beltrán Maza, G. (2009). Neural network as tool for virgin olive oil elaboration process optimization. Journal of Food Engineering, 95(1), 135-141. doi:10.1016/j.jfoodeng.2009.04.021Jiménez, A., Beltrán, G., Aguilera, M., Uceda, M., 2008. A sensor-software based on artificial neural network for the optimization of olive oil elaboration process. Sensors and Actuators B: Chemical 129 (2), 985-990.Marquez, A. J., Díaz, A. M., & Reguera, M. I. P. (2005). Using optical NIR sensor for on-line virgin olive oils characterization. Sensors and Actuators B: Chemical, 107(1), 64-68. doi:10.1016/j.snb.2004.11.103Ortega Nieto, J., 1943. Cartilla de la almazara. Ministerio de Agricultura.Rodríguez-Mendez, M.L., Apetrei, C., de Saja, J.A., 2008. Evaluation of the polyphenolic content of extra virgin olive oils using an array of voltammetric sensors. Condensed Matter Physics 53, 5867-5872.Tripoli, E., Giammanco, M., Tabacchi, G., Di Majo, D., Giammanco, S., & La Guardia, M. (2005). The phenolic compounds of olive oil: structure, biological activity and beneficial effects on human health. Nutrition Research Reviews, 18(1), 98-112. doi:10.1079/nrr200495Uceda, M., Hermoso, M., 1997. Elaboración de aceite de oliva virgen. In: Barranco, D., Fernández-Escobar, R., Rallo, L. (Eds.), El cultivo del olivo, 2nd Edition. Mundi-Prensa, Madrid",'Elsevier BV',Current situation and future perspectives on virgin olive oil elaboration process control,10.1016/j.riai.2011.06.013,http://hdl.handle.net/10251/144458,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
294766932,2010-04-11T00:00:00,"[EN] In this paper, Maxine, a powerful engine to develop applications with embodied animated agents is presented. The engine, based on the use of open source libraries, enables multimodal real-time interaction with the user: via text, voice, images and gestures. Maxine virtual agents can establish emotional communication with the user through their facial expressions, the modulation of the voice and expressing the answers of the agents according to the information gathered by the system: noise level in the room, observer’s position, emotional state of the observer, etc. Moreover, the user’s emotions are considered and captured through images. For the moment, Maxine virtual agents have been used as virtual presenters for Cultural Heritage and Archaeological shows.This work has been partially financed by the Spanish “Dirección General de Investigación'' (General Directorate of Research), contract
number Nº TIN2007-63025, and by the Regional Government of Aragon through the WALQA agreement.Seron, F.; Baldassarri, S.; Cerezo, E. (2010). Interactive Embodied Agents for Cultural Heritage and Archaeological presentations. Virtual Archaeology Review. 1(1):181-184. https://doi.org/10.4995/var.2010.5143OJS18118411BALDASSARRI, S., CEREZO, E., SERON, F. (2007): An open source engine for embodied animated agents.In Proc. Congreso Español de Informática Gráfica: CEIG'07, pp. 89-98.BERRY, D.et al, (2005). Evaluating a realistic agent in an advice-giving task. In International Journal in Human-Computer Studies, Nº 63, pp. 304-327. http://dx.doi.org/10.1016/j.ijhcs.2005.03.006BOFF, E. et al, (2005). An affective agent-based virtual character for learning environments. Proceedings of the Wokshop on Motivation and Affect in Educational Software, 12th International Conference on Artificial Intelligence in Education. Amsterdam, Holland, pp 1-8.BURLESON, W. et al, (2004). A Platform for Affective Agent Research. Proceedings of the Workshop on Empathetic Agents, International Conference on Autonomous Agents and Multiagent Systems, New York, USA.CEREZO, E., BALDASSARRI, S., SERON, F. (2007): Interactive agents for multimodal emotional user interaction. In Proc. of IADIS International Conference Interfaces and Human Computer Interaction, pp. 35-42.CASELL, J. et al (eds), (2000), in Embodied Conversational Agents. MIT Press, Cambridge, USA.El-NASR, M. S. et al, (1999). A PET with Evolving Emotional Intelligence. Proceedings of the 3rd Annual Conference on Autonomous Agents. Seattle, USA, pp. 9 - 15. http://dx.doi.org/10.1145/301136.301150GRAESSER, A. et al, (2005). AutoTutor: An Intelligent tutoring system with mixed-initiative dialogue. In IEEE Transactions on Education, Vol. 48, Nº 4, pp. 612-618. http://dx.doi.org/10.1109/TE.2005.856149KASAP, Z. and N. MAGNENAT-THALMANN (2007): ""Intelligent virtual humans with autonomy and personality: State-of-the-art"", in IntelligentDecision Technologies. IOS PressMARSELLA S. C et al, (2000). Interactive Pedagogical Drama. Proceedings of the 4th International Conference on Autonomous Agents. Barcelona, Spain, pp. 301-308. http://dx.doi.org/10.1145/336595.337507MIGNONNEAU, L. and SOMMERER, C. (2005). Designing emotional, methaforic, natural and intuitive interfaces for interactive art, edutainment and mobile communications, in Computer & Graphics, Vol. 29, pp. 837-851.PRENDINGER, H. and ISHIZUKA, M., (2005). The Empathic Companion: A Character-Based Interface that Addresses Users' Affective States. In Applied Artificial Intelligence, Vol.19, pp.267-285. http://dx.doi.org/10.1080/08839510590910174ROSIS, F. et al, (2003). From Greta's mind to her face: modelling the dynamics of affective status in a conversational embodied agent. In International Journal of Human-computer Studies. Special Issue on Applications of Affective Computing in HCI, Vol 59, pp 81-118. http://dx.doi.org/10.1016/s1071-5819(03)00020-xYUAN, X. and CHEE, S. (2005). Design and evaluation of Elva: an embodied tour guide in an interactive virtual art gallery. In Computer Animation and Virtual Worlds, Vol. 16, pp.109-119. http://dx.doi.org/10.1002/cav.6",'Universitat Politecnica de Valencia',Interactive Embodied Agents for Cultural Heritage and Archaeological presentations,10.4995/var.2010.5143,https://riunet.upv.es/bitstream/10251/139836/1/Seron%3bBaldassarri%3bCerezp%20-%20Interactive%20Embodied%20Agents%20for%20Cultural%20Heritage%20and%20Archaeological%20p....pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
34058045,1994,"In the context of pattern classification, the success of a classification scheme often depends on the geometrical properties of the pattern classes under consideration. As radial basis functions (RBF) neural networks have largely been applied in pattern classification problems, in this paper we present a brief overview of different trends in radial basis functions neural networks and their applications. The meanings of the weights and the processing units for a RBF network applied for pattern classification are given. A new learning algorithm for a RBF neural network is proposed in this paper. This algorithm gives a solution for classifying configurations of patterns in a feature space providing the minimum number of hidden units for the network implementation. The learning is based on the backpropagation algorithm. The performance of the proposed algorithm is assessed on different artificial and real applications. The algorithm is successfully applied for estimating a distribution, as well as for separating signals in a multiple access communication system and for recognizing static speech. © 1994 Academic Press. All rights reserved",,Minimal topology for a radial basis functions neural network for pattern classification,10.1006/dspr.1994.1016,,"[{'title': None, 'identifiers': ['issn:1051-2004', '1051-2004']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
288530118,2010,"It is known that one of the most critical issues for the implementation of a fully automatic processing dedicated to the detection of oil spills from SAR imagery is the extraction of the oil spill candidate. In fact, the segmentation of the image is the first of three necessary steps, the other two being the characterization of the extracted black spot by using a set of features and the classification between oil spill and look-alike. In this paper we investigate an unsupervised neural network approach for automatically extracting oil spill candidates from ERS and ENVISAT SAR images. The technique is based on the use of Pulse-Coupled Neural Networks (PCNN) which is a relatively novel technique based on models of the visual cortex of small mammals. When applied to image processing, it yields a series of binary pulsed signals, each associated to one pixel or to a cluster. In literature, interesting results have been already reported by several authors in applications of this model to image segmentation, including, in few cases, the use of satellite data. The architecture of PCNN is rather simpler than most other neural network implementations. PCNN do not have multiple layers and receive input directly from the original image, forming a resulting “pulse” image. The network consists of multiple nodes coupled together with their neighbors within a definite distance, forming a grid (2D-vector). The PCNN neuron has two input compartments: linking and feeding. The feeding compartment receives both an external and a local stimulus, whereas the linking compartment only receives a local stimulus. When the internal activity becomes larger than an internal threshold, the neuron fires and the threshold sharply increases. Afterward, it begins to decay until once again the internal activity becomes larger. This process gives rise to the pulsing nature of PCNN, forming a wave signature which is invariant to rotation, scale, shift or skew of an object within the image. This study discusses the use of PCNN technique in a fully automatic chain for oil spill detection from SAR images. The objects segmented by the PCNN are successively processed by a more standard Multi-Layer Perceptron Neural Network, which provides the classification response between real oil spill and look-alike. The performance yielded by the PCNN-MLP chain is evaluated and critically discussed for a set of ERS-SAR and ENVISAT ASAR images. The application of the methodology to the very-high resolution SAR images taken by COSMO-Skymed and TerraSAR-X satellites will be also considered",,Pulse coupled neural networks for automatic oil spill detection from satellite SAR images,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
53861603,2002,"The implementation of an artificial vision algorithm in real time is really attractive in such an application as the field of environment sensing. The SVCNN (stereo vision cellular neural network) chip is an analogue circuit able to compute in real time the Disparity Map from a couple of images by using a stereo visual system algorithm. A ""test-bed"" board for the 16×64 SVCNN chip is presented in this paper. This board is composed of an analogue processing core implemented by two 16×64 SVCNN chips together with a digital high performance pre-processing unit and a video grabbing section",IEEE,Test-bed board for 16X64 stereo vision CNN chip,10.1109/CNNA.2002.1035109,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
326993009,2009-11-26T00:00:00,"Recent research into the acquisition of spoken language has stressed the importance of learning through embodied linguistic interaction with caregivers rather than through passive observation. However the necessity of interaction makes experimental work into the simulation of infant speech acquisition difficult because of the technical complexity of building real-time embodied systems. In this paper we present KLAIR: a software toolkit for building simulations of spoken language acquisition through interactions with a virtual infant. The main part of KLAIR is a sensori-motor server that supplies a client machine learning application with a virtual infant on screen that can see, hear and speak. By encapsulating the real-time complexities of audio and video processing within a server that will run on a modern PC, we hope that KLAIR will encourage and facilitate more experimental research into spoken language acquisition through interaction. Copyright © 2009 ISCA",,KLAIR: A virtual infant for spoken language acquisition research,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
53069361,2014-01-01T00:00:00,"Актуальность исследования обусловлена необходимостью разработки программных средств слежения за объектами в реальном масштабе времени. Цель работы: Создание алгоритма слежения за объектом в кадре в реальном масштабе времени. Методы исследования: Параллельная реализация сигмоидальной нейронной сети на графическом процессоре, замеры временных характеристик параллельного алгоритма и его оптимизация. Результаты: Предложена реализация на графическом процессоре (GPU) нейросетевого алгоритма слежения за объектом, спецификой которого является использование при обучении нейронной сети задачника, устанавливающего однозначное соответствие обрабатываемого кадра в видеопотоке координатам центра объекта в кадре. Благодаря использованию GPU удается решить задачу слежения в реальном масштабе времени (25 кадров в секунду) при размерах обрабатываемого кадра до 1280?960. Алгоритм основан на использовании многослойного персептрона и имеет ряд параметров, которые определены экспериментально. Одним из таких параметров является число нейронов скрытого слоя. В связи с реализацией алгоритма на GPU рассмотрены числа нейронов, кратные 16. В экспериментах установлено, что 16 и 32 нейрона не могут обеспечить даже малой степени запоминания образов, 48 нейронов справлялись с обучением только на малых обучающих выборках, 64 нейрона обеспечили хорошую степень запоминания образов и скорость работы. Дальнейшее увеличение числа нейронов приводит только к уменьшению скорости работы нейронной сети и ее обучения. Также заслуживает внимания частота, с которой нужно брать кадры из видеозаписи, чтобы эффективно обучить нейронную сеть. Экспериментально установлено, что на частоте выборки одного кадра из десяти сумма максимальных отклонений по обеим координатам равна 50 при размерах объекта 300?300; дальнейшее увеличение частоты кадров лишь замедляет процесс обучения, не давая существенного выигрыша в качестве. Получены ускорения процесса слежения в 10 раз по сравнению с центральным процессором персонального компьютера. Процесс обучения нейронной сети ускорился в среднем только в 2 раза. Это обусловлено необходимостью транспонирования матриц весов при реализации обучения нейронной сети на GPU. Для реализации параллельного алгоритма использована программно-аппаратная архитектура CUDA, позволяющая производить вычисления с использованием графических процессоров NVIDIA, поддерживающих технологию GPGPU (произвольных вычислений на видеокартах). Для предварительной обработки изображений и вывода информации использовалась библиотека компьютерного зрения OpenCV.The urgency of the discussed issue is caused by the need to provide software for tracking objects in real time. The main aim of the study: to create an object-tracking algorithm in the frame in real time. The methods used in the study: parallel implementation of the sigmoid neural network on the GPU, measuring the temporal characteristics of the parallel algorithm and its optimization. The results: The authors have proposed implementation of a neural network algorithm on graphic processor (GPU) for tracking an object in a video frame. The specific character of the algorithm is the use of a training set which establish correspondence between the video frame and the object center coordinates in this frame when training a neural network. Owing to GPU application the tracking problem can be solved in real time (25 frames per second) at the processed frame sizes up to 1280?960. The algorithm is based on the use of multilayer perceptron and has a number of parameters, which are determined experimentally. One of such parameters is the number of the hidden layer neurons. Due to the algorithm implementation on GPU the authors considered the number of neurons multiple 16. It was determined experimentally that 16 and 32 neurons cannot provide even a small degree of memorizing images, 48 neurons cope with learning only small training samples, and 64 neurons provided a good degree of memorizing images and speed. Further increase in the number of neurons results only in reducing speed of the neural network functioning and its training. The frequency which is required for taking pictures from a video to train effectively a neural network is worth noticing as well. It is found out experimentally that at a sampling rate of one frame of ten, the sum of the maximum deviations in coordinates is 50, when the object size is 300?300; further increase of the frame rate slows down the process of training without significant gain in quality. The authors obtained the tracking accelerating by 10 times in comparison with the CPU of a personal computer. The neural network training is accelerated only 2 times on average. This is caused by the need to transpose the weight matrices when implementing the neural network training on the GPU. To implement the parallel algorithm, the hardware and software architecture CUDA is used. It allows computation on graphics processors NVIDIA, supporting GPGPU technology (general purpose computations on GPU). For preliminary image processing and data output the computer vision library OpenCV is used",Томский политехнический университет,Neural network parallel algorithm for real-time object tracking,,,"[{'title': None, 'identifiers': ['issn:1684-8519', '1684-8519']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
58795057,2011-11-01T00:00:00,"Autonomy is a prime issue on robotics field and it is closely related to decision making. Last researches on decision making for social robots are focused on biologically inspired mechanisms for taking decisions. Following this approach, we propose a motivational system for decision making, using internal (drives) and external stimuli for learning to choose the right action. Actions are selected from a finite set of skills in order to keep robot's needs within an acceptable range. The robot uses reinforcement learning in order to calculate the suitability of every action in each state. The state of the robot is determined by the dominant motivation and its relation to the objects presents in its environment. The used reinforcement learning method exploits a new algorithm called Object Q-Learning. The proposed reduction of the state space and the new algorithm considering the collateral effects (relationship between different objects) results in a suitable algorithm to be applied to robots living in real environments. In this paper, a first implementation of the decision making system and the learning process is implemented on a social robot showing an improvement in robot's performance. The quality of its performance will be determined by observing the evolution of the robot's wellbeing.The funds provided by the Spanish Government through the project called “Peer
to Peer Robot-Human Interaction” (R2H), of MEC (Ministry of Science and Education), the project “A new approach to social robotics” (AROS), of MICINN (Ministry of Science and Innovation), and the RoboCity2030-II-CM project (S2009/DPI-1559), funded by Programas de Actividades I+D en la Comunidad de Madrid and cofunded by Structural Funds of the EU",'Springer Science and Business Media LLC',Learning the selection of actions for an autonomous social robot by reinforcement learning based on motivations,10.1007/s12369-011-0113-z,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
61623368,[[issued]]2009-10-14T09:37:41Z,"[[abstract]]© 1999 Elsevier - When a speech recognition system is deployed in the real world, environmental interference will make noisy speech signals and reference models mismatched and cause serious degradation in recognition accuracy. To deal with the effect of environmental mismatch, a family of signal limiters has been successfully applied to a template-based DTW recognizer to reduce the variability of speech features in noisy conditions. Though simulation results indicate that heavily smoothing can effectively reduce the variability of speech features in low signal-to-noise ratio (SNR), it would also cause the loss of information in speech features. Therefore, we suggest that the smoothing factor of a signal limiter should be related to SNR and adapted on a frame by frame basis. In this paper, an adaptive signal limiter (ASL) is proposed to smooth the instantaneous and dynamic spectral features of reference models and test speech. By smoothing spectral features, the smoothed covariance matrices of reference models can be obtained by means of maximum likelihood (ML) estimation. A speech recognition task for multispeaker isolated Mandarin digits has been conducted to evaluate the effectiveness and robustness of the proposed method. Experimental results indicate that the adaptive signal limiter can achieve significant improvement in noisy conditions and is more robust than the hard limiter over a wider range of SNR values.[[department]]電機工程學",Elsevier,Smoothing hidden Markov models by using an adaptive signal limiter for noisy speech recognition,10.1016/S0167-6393(99)00011-4,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
151281571,2013-01-01T00:00:00,"International audienceThe Tiber Valley Project aims to create a series of digital applications for 3D reconstructing, visualization and real time browsing of the ancient and current Tiber Valley landscape (particularly for the Villa dei Volusii and Lucus Feroniae areas), in four different historical phases. In this perspective, the first problem to face is the need for a valid methodology for ancient landscape ecosystem reconstruction, before dealing with monuments and building. On the basis of an intense multi-disciplinary discussion and the previous VH Lab experience in this field, in this article we are presenting a scheme for a standardized reconstruction procedure, where the landscape is built using all available sources and elevation data obtained by a photogrammetry process on historical pictures. Ecosystem areas are then calculated through GIS elaboration in GRASS-GIS environment, through a procedure which may be shared for any situation of historical landscape reconstruction, allowing the matching and the mathematical processing of geographical data aimed to the definition of different ecological areas (both in terms of natural vegetation and cultivated lands). Maps are then created to be imported in procedural landscape generation engines: the last part of the paper focuses on the lack of effective open source software in this field, and a possible proposal implementation in this sense1. Il progetto "" Valle del Tevere "" Il presente lavoro illustra la sperimentazione di una metodologia per la ricostruzione del paesaggio storico, con particolare riguardo agli aspetti di definizione delle diverse presenze vegetazionali e antropiche del territorio in determinate epoche del passato. Il caso di studio è rappresentato dal lavoro che l'Istituto per le Tecnologie Applicate ai Beni Culturali (ITABC) del CNR sta svolgendo nell'ambito del Programma "" Arcus "" , finalizzato alla creazione di un sistema integrato di conoscenza, valorizzazione e comunicazione del paesaggio culturale della Valle del Tevere (contesti archeologici, storico-arti-stici, naturalistici, antropici), in particolare dell'area compresa tra il Monte Soratte e Fiano Romano, in direzione N-S, e il tracciato della via Flaminia antica e Palombara Sabina, in direzione E-O. Il progetto prevede una variegata serie di prodotti finali, quali: – un'installazione di realtà virtuale ludico-educativa, caratterizzata da un sistema di natural interaction (interazione attraverso i movimenti del corpo), localizzata all'interno di un museo di Roma, quale porta privilegiata di accesso e promozione del territorio della Valle del Tevere; – una guida multimediale alla Villa dei Volusii e al sito di Lucus Feroniae, da fruire sia su mobile che presso il Museo di Lucus Feroniae; – una guida alla Riserva del Tevere-Farfa, per smartphone o tablet, da fruire durante la visita all'area naturalistica; – un'installazione multimediale-filmica dedicata alla Riserva naturale del Teve-re-Farfa e destinata alle scuole, da fruire nel Museo del Fiume di Nazzano; – un sito web sul paesaggio culturale, basato su un sistema informativo geo-grafico in 3D e dedicato al pubblico di turisti, studiosi, operatori, scuole. Il lavoro comporta una ricostruzione fotorealistica del paesaggio natu-rale e antropico rispetto alle seguenti fasi cronologiche: – fase preistorica (ricostruzione della storia geologica dell'area, formazione della Valle del Tevere e dell'alveo fluviale, tra 3 milioni di anni fa e 12.000 anni fa); – fase pre-romana (focalizzata sull'Età del Ferro e sul periodo Orientaliz-zante); – fase romana (focalizzata, in particolare, sul periodo augusteo); – fase medievale (focalizzata, in particolare, sul XII secolo); – fase contemporanea",All'Insegna del giglio,"Verso una metodologia condivisa per l'analisi del paesaggio antico: il Progetto ""Valle del Tevere""",,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
291301524,,"MOTIVATION: Detecting positive selection in genomic regions is a recurrent topic in natural population genetic studies. However, there is little consistency among the regions detected in several genome-wide scans using different tests and/or populations. Furthermore, few methods address the challenge of classifying selective events according to specific features such as age, intensity or state (completeness). RESULTS: We have developed a machine-learning classification framework that exploits the combined ability of some selection tests to uncover different polymorphism features expected under the hard sweep model, while controlling for population-specific demography. As a result, we achieve high sensitivity toward hard selective sweeps while adding insights about their completeness (whether a selected variant is fixed or not) and age of onset. Our method also determines the relevance of the individual methods implemented so far to detect positive selection under specific selective scenarios. We calibrated and applied the method to three reference human populations from The 1000 Genome Project to generate a genome-wide classification map of hard selective sweeps. This study improves detection of selective sweep by overcoming the classical selection versus no-selection classification strategy, and offers an explanation to the lack of consistency observed among selection tests when applied to real data. Very few signals were observed in the African population studied, while our method presents higher sensitivity in this population demography. AVAILABILITY AND IMPLEMENTATION: The genome-wide results for three human populations from The 1000 Genomes Project and an R-package implementing the 'Hierarchical Boosting' framework are available at http://hsb.upf.edu/.This work was supported by Ministerio de Economía y Competitividad (Spain) [grants BFU2010-19443, BFU2013-43726-P]; and the Secretaria d’Universitats i Recerca del Departament d’Economia i Coneixement de la Generalitat de Catalunya [GRC 2014 SGR 866] to J.B. M.P. and G.D. have been supported by a grant of the FPI program, Ministerio de Economia y Competitividad; P.L. by a grant from the Instituto de Salud Carlos III; J.E. was supported through a Postdoc scholarship from the Volkswagenstiftung [Az: I/85 198",'Oxford University Press (OUP)',Hierarchical boosting: a machine-learning framework to detect and classify hard selective sweeps in human populations,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
162408305,2007-01-01T00:00:00,"This paper focuses on the results of different consumer surveys conducted between 2004 and 2006 with regard to consumers ' perceptions and reactions concerning AI in Vietnam, (mainly in Hanoi). The main results observed are as follows: - A high proportion of consumers consider AI to be a food-related risk. However, over time, there has been a slight shift from a fear of consuming poultry to a fear of preparing it (slaughtering it). - AI has had a profound effect on poultry consumption, even outside peak crisis times, more in terms of the quantity consumed (approximately a third less in 2006) than in terms of the number of consumers (6% less). - Blood and internal organs are considered particularly risky, while eggs are viewed as being safer. Poultry from industrial farms is considered to be more risky than poultry from small farms. - Purchasing practices have also been affected by AI: in Hanoi, consumers declare that they prefer to buy poultry directly from producers that they know, or from supermarkets in the case of the wealthiest consumers. A high proportion still buy live poultry from market traders, but more consumers now ask sellers to slaughter it for them. With a view to lessening market shocks in the wake of the crisis while maintaining the priority of consumer safety, a number of measures should nevertheless be implemented: Risk communication should not over-emphasize AI as a food-related risk. - Reliable safe distribution channels should be promoted (with reliable quality signs and controls) in order to encourage safe production and poultry consumption. Otherwise, a market recovery will only benefit supermarkets and large-scale farmers capable of supplying supermarkets. - As numerous live birds are still slaughtered in urban market places, facilities should be provided for safe slaughter. At the same time, more attention should be paid to the provision of a real ""cold chain"" with a view to promoting the sale of slaughtered poultry. (Résumé d'auteur",'Food and Agriculture Organization of the United Nations (FAO)',Consumer perceptions and reactions concerning AI (Avian Influenza),,http://agritrop.cirad.fr/539844/1/document_539844.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
324194274,2010-04-09T00:00:00,"[ES] La diabetes mellitus tipo 1 es una enfermedad crónica que afecta aproximadamente a 30 millones de personas en el mundo y se caracteriza por niveles de concentración de glucosa en sangre elevados producidos por una deficiencia absoluta de insulina. Ello produce numerosas complicaciones a largo plazo como retinopatía, nefropatía y neuropatía entre otras. Las terapias actuales basadas en el suministro de insulina exógena (por inyecciones o bomba de insulina), no consiguen normalizar los niveles de glucosa de forma eficiente. Los avances tecnológicos en la última década en sistemas de medición continua de glucosa e infusión de insulina, han impulsado el desarrollo del páncreas artificial, o control automático de infusión de insulina. En este trabajo se presentará, a modo de tutorial, el pasado, presente y futuro de esta tecnología, tan esperada por el paciente diabético. Se revisará el estado actual de la tecnología para la sensorización y actuación, principales desafíos desde el punto de vista de control, las diferentes ``escuelas'' y estudios clínicos del desempeño de controladores, así como herramientas de validación de controladores mediante simulación. Dada la complejidad del problema, el desarrollo del páncreas artificial será de forma escalonada, redundando progresivamente en la mejora de la calidad de vida del paciente. Los grandes avances en los últimos cinco años hacen preveer un horizonte cercano para la primera generación de páncreas artificial.[EN] Type 1 diabetes mellitus is a chronic disease that affects approximately to 30 million people worldwide and is characterized by high blood glucose concentration levels produced by an absolute deficiency of insulin. That produces numerous long-term complications like retinopathy, nephropathy and neuropathy among others. Current therapies based on the exogenous delivery of insulin (through injections or an insulin pump), do not manage to normalize the glucose levels efficiently. Technological advances in the last decade in continuous glucose monitoring and insulin infusion have been a springboard for the development of the artificial pancreas, or automatic control of insulin infusion. In this work, the past, present and future of this technology, so long awaited by the diabetic patient, will be presented in the form of a tutorial. Current technology for sensorization and actuation will be reviewed, as well as main challenges from the control point of view, different “schools of thought” and clinical studies for controllers performance evaluation, and tools for the validation of controllers through simulation. Due to the complexity of the problem, the development of the artificial pancreas will be staggered, resulting progressively in an improvement of the patient’s quality of life. The big advances during last five years foresee a close horizon for a first generation of artificial pancreas.Este trabajo ha sido realizado parcialmente gracias al apoyo del Ministerio de Ciencia e Innovación español, a través del proyecto DPI2007-66728-C02, de la Unión Europea a través de fondos FEDER y de la Wellcome Trust.Bondía Company, J.; Vehí, J.; Palerm, CC.; Herrero, P. (2010). El Páncreas Artificial: Control Automático de Infusión de Insulina en Diabetes Mellitus Tipo 1. Revista Iberoamericana de Automática e Informática industrial. 7(2):5-20. https://doi.org/10.1016/S1697-7912(10)70021-2OJS52072Argoud, G. M., Schade, D. S., & Eaton, R. P. (1987). Insulin Suppresses Its Own Secretion In Vivo. Diabetes, 36(8), 959-962. doi:10.2337/diab.36.8.959Arleth, T., Andreassen, S., Federici, M. O., & Benedetti, M. M. (2000). A model of the endogenous glucose balance incorporating the characteristics of glucose transporters. Computer Methods and Programs in Biomedicine, 62(3), 219-234. doi:10.1016/s0169-2607(00)00069-9Atlas, E., Nimri, R., Miller, S., Grunberg, E. A., & Phillip, M. (2010). MD-Logic Artificial Pancreas System: A pilot study in adults with type 1 diabetes. Diabetes Care, 33(5), 1072-1076. doi:10.2337/dc09-1830Bailey, T., Zisser, H., & Chang, A. (2009). New Features and Performance of a Next-Generation SEVEN-Day Continuous Glucose Monitoring System with Short Lag Time. Diabetes Technology & Therapeutics, 11(12), 749-755. doi:10.1089/dia.2009.0075Basu, R., Di Camillo, B., Toffolo, G., Basu, A., Shah, P., Vella, A., … Cobelli, C. (2003). Use of a novel triple-tracer approach to assess  postprandial glucose metabolism. American Journal of Physiology-Endocrinology and Metabolism, 284(1), E55-E69. doi:10.1152/ajpendo.00190.2001Bequette, B. W. (2005). A Critical Assessment of Algorithms and Challenges in the Development of a Closed-Loop Artificial Pancreas. Diabetes Technology & Therapeutics, 7(1), 28-47. doi:10.1089/dia.2005.7.28Bergman, R. N. (2003). The Minimal Model of Glucose Regulation: A Biography. Mathematical Modeling in Nutrition and the Health Sciences, 1-19. doi:10.1007/978-1-4419-9019-8_1Bevier, W. C., Zisser, H. C., Jovanovič, L., Finan, D. A., Palerm, C. C., Seborg, D. E., & Doyle, F. J. (2008). Use of Continuous Glucose Monitoring to Estimate Insulin Requirements in Patients with Type 1 Diabetes Mellitus during a Short Course of Prednisone. Journal of Diabetes Science and Technology, 2(4), 578-583. doi:10.1177/193229680800200408Bliss, M. (2007). The discovery of insulin. 25th anniversary ed. The University of Chicago Press.Bruttomesso, D., Farret, A., Costa, S., Marescotti, M. C., Vettore, M., Avogaro, A., … Maran, A. (2009). Closed-Loop Artificial Pancreas Using Subcutaneous Glucose Sensing and Insulin Delivery and a Model Predictive Control Algorithm: Preliminary Studies in Padova and Montpellier. Journal of Diabetes Science and Technology, 3(5), 1014-1021. doi:10.1177/193229680900300504Campos-Delgado, D. U., Hernandez-Ordonez, M., Femat, R., & Gordillo-Moscoso, A. (2006). Fuzzy-Based Controller for Glucose Regulation in Type-1 Diabetic Patients by Subcutaneous Route. IEEE Transactions on Biomedical Engineering, 53(11), 2201-2210. doi:10.1109/tbme.2006.879461Caumo, A., Bergman, R. N., & Cobelli, C. (2000). Insulin Sensitivity from Meal Tolerance Tests in Normal Subjects: A Minimal Model Index. The Journal of Clinical Endocrinology & Metabolism, 85(11), 4396-4402. doi:10.1210/jcem.85.11.6982Chassin, L. J., Wilinska, M. E., & Hovorka, R. (2004). Evaluation of glucose controllers in virtual environment: methodology and sample application. Artificial Intelligence in Medicine, 32(3), 171-181. doi:10.1016/j.artmed.2004.02.006Clarke, W. L., Anderson, S., Farhy, L., Breton, M., Gonder-Frederick, L., Cox, D., & Kovatchev, B. (2005). Evaluating the Clinical Accuracy of Two Continuous Glucose Sensors Using Continuous Glucose-Error Grid Analysis. Diabetes Care, 28(10), 2412-2417. doi:10.2337/diacare.28.10.2412Clarke, W. L., Anderson, S., Breton, M., Patek, S., Kashmer, L., & Kovatchev, B. (2009). Closed-Loop Artificial Pancreas Using Subcutaneous Glucose Sensing and Insulin Delivery and a Model Predictive Control Algorithm: The Virginia Experience. Journal of Diabetes Science and Technology, 3(5), 1031-1038. doi:10.1177/193229680900300506Cryer, P. (2002). Hypoglycaemia: The limiting factor in the glycaemic management of Type I and Type II Diabetes*. Diabetologia, 45(7), 937-948. doi:10.1007/s00125-002-0822-9Man, C. D., Camilleri, M., & Cobelli, C. (2006). A System Model of Oral Glucose Absorption: Validation on Gold Standard Data. IEEE Transactions on Biomedical Engineering, 53(12), 2472-2478. doi:10.1109/tbme.2006.883792Dalla Man, C., Breton, M. D., & Cobelli, C. (2009). Physical Activity into the Meal Glucose—Insulin Model of Type 1 Diabetes: In Silico Studies. Journal of Diabetes Science and Technology, 3(1), 56-67. doi:10.1177/193229680900300107Dalla Man, C., Rizza, R. A., & Cobelli, C. (2007). Meal Simulation Model of the Glucose-Insulin System. IEEE Transactions on Biomedical Engineering, 54(10), 1740-1749. doi:10.1109/tbme.2007.893506Dassau, E., Zisser, H., Palerm, C. C., Buckingham, B. A., Jovanovič, L., & Doyle, F. J. (2008). Modular Artificial β-Cell System: A Prototype for Clinical Research. Journal of Diabetes Science and Technology, 2(5), 863-872. doi:10.1177/193229680800200518The Effect of Intensive Treatment of Diabetes on the Development and Progression of Long-Term Complications in Insulin-Dependent Diabetes Mellitus. (1993). New England Journal of Medicine, 329(14), 977-986. doi:10.1056/nejm199309303291401(1997). Hypoglycemia in the Diabetes Control and Complications Trial. Diabetes, 46(2), 271-286. doi:10.2337/diab.46.2.271Doyle, F., Jovanovič, L., & Seborg, D. (2007). I. Glucose control strategies for treating type 1 diabetes mellitus. Journal of Process Control, 17(7), 572-576. doi:10.1016/j.jprocont.2007.01.013Ellingsen, C., Dassau, E., Zisser, H., Grosman, B., Percival, M. W., Jovanovič, L., & Doyle, F. J. (2009). Safety Constraints in an Artificial Pancreatic β Cell: An Implementation of Model Predictive Control with Insulin on Board. Journal of Diabetes Science and Technology, 3(3), 536-544. doi:10.1177/193229680900300319Fabietti, P. G., Calabrese, G., Iorio, M., Bistoni, S., Brunetti, P., Sarti, E., & Benedetti, M. M. (2001). A Mathematical Model Describing the Glycemic Response of Diabetic Patients to Meal and i.v. Infusion of Insulin. The International Journal of Artificial Organs, 24(10), 736-742. doi:10.1177/039139880102401006Fabietti, P. G., Canonico, V., Federici, M. O., Benedetti, M. M., & Sarti, E. (2006). Control oriented model of insulin and glucose dynamics in type 1 diabetics. Medical & Biological Engineering & Computing, 44(1-2), 69-78. doi:10.1007/s11517-005-0012-2Facchinetti, A., Sparacino, G., & Cobelli, C. (2010). Modeling the Error of Continuous Glucose Monitoring Sensor Data: Critical Aspects Discussed through Simulation Studies. Journal of Diabetes Science and Technology, 4(1), 4-14. doi:10.1177/193229681000400102Fatourechi, M. M., Kudva, Y. C., Murad, M. H., Elamin, M. B., Tabini, C. C., & Montori, V. M. (2009). Hypoglycemia with Intensive Insulin Therapy: A Systematic Review and Meta-Analyses of Randomized Trials of Continuous Subcutaneous Insulin Infusion Versus Multiple Daily Injections. The Journal of Clinical Endocrinology & Metabolism, 94(3), 729-740. doi:10.1210/jc.2008-1415FDA (2002). General principles of software validation; final guidance for industry and FDA staff. URL: http://www.fda.gov/cdrh/comp/guidance/938.html.FDA: Food & Drug Administration (n.d.). http://fda.gov. Accessed on March 8, 2010.FEND and IDF-Europe (2008). Diabetes. The Policy Puzzle: Is Europe Making Progress? 2nd edition. URL: http://www.fend.org/Garcia-Gabin, W., J. Vehi, J. Bondia, C. Tarin and R. Calm (2008). Robust sliding mode closed-loop glucose control with meal compensation in type 1 diabetes mellitus. In: 17th IFAC World Congress.Gillis, R., Palerm, C. C., Zisser, H., Jovanovic, L., Seborg, D. E., & Doyle, F. J. (2007). Glucose Estimation and Prediction through Meal Responses Using Ambulatory Subject Data for Advisory Mode Model Predictive Control. Journal of Diabetes Science and Technology, 1(6), 825-833. doi:10.1177/193229680700100605Gin, H., Renard, E., Melki, V., Boivin, S., Schaepelynck-Bélicar, P., Guerci, B., … Catargi, B. (2003). Combined improvements in implantable pump technology and insulin stability allow safe and effective long term intraperitoneal insulin delivery in type 1 diabetic patients: the EVADIAC experience. Diabetes & Metabolism, 29(6), 602-607. doi:10.1016/s1262-3636(07)70075-7Guilhem, I., Leguerrier, A., Lecordier, F., Poirier, J., & Maugendre, D. (2006). Technical risks with subcutaneous insulin infusion. Diabetes & Metabolism, 32(3), 279-284. doi:10.1016/s1262-3636(07)70281-1Guyton, J. R., Foster, R. O., Soeldner, J. S., Tan, M. H., Kahn, C. B., Koncz, L., & Gleason, R. E. (1978). A Model of Glucose-insulin Homeostasis in Man that Incorporates the Heterogeneous Fast Pool Theory of Pancreatic Insulin Release. Diabetes, 27(10), 1027-1042. doi:10.2337/diab.27.10.1027Herman, W. H., & Eastman, R. C. (1998). The Effects of Treatment on the Direct Costs of Diabetes. Diabetes Care, 21(Supplement_3), C19-C24. doi:10.2337/diacare.21.3.c19Herrero, P., J. Vehí, R. Corcoy, A. Chico, B. Pons and A. de Leiva (2008). Model based fault detection in the artificial β-cell framework. In: Eighth Diabetes Technology Meeting.Hoshino, M., Haraguchi, Y., Mizushima, I., & Sakai, M. (2009). Recent progress in mechanical artificial pancreas. Journal of Artificial Organs, 12(3), 141-149. doi:10.1007/s10047-009-0463-6Hovorka, R. (2006). Continuous glucose monitoring and closed-loop systems. Diabetic Medicine, 23(1), 1-12. doi:10.1111/j.1464-5491.2005.01672.xHovorka, R. (2008). The Future of Continuous Glucose Monitoring: Closed Loop. Current Diabetes Reviews, 4(3), 269-279. doi:10.2174/157339908785294479Hovorka, R., Shojaee-Moradie, F., Carroll, P. V., Chassin, L. J., Gowrie, I. J., Jackson, N. C., … Jones, R. H. (2002). Partitioning glucose distribution/transport, disposal,  and endogenous production during IVGTT. American Journal of Physiology-Endocrinology and Metabolism, 282(5), E992-E1007. doi:10.1152/ajpendo.00304.2001Hovorka, R., Allen, J. M., Elleri, D., Chassin, L. J., Harris, J., Xing, D., … Dunger, D. B. (2010). Manual closed-loop insulin delivery in children and adolescents with type 1 diabetes: a phase 2 randomised crossover trial. The Lancet, 375(9716), 743-751. doi:10.1016/s0140-6736(09)61998-xHovorka, R., Canonico, V., Chassin, L. J., Haueter, U., Massi-Benedetti, M., Federici, M. O., … Wilinska, M. E. (2004). Nonlinear model predictive control of glucose concentration in subjects with type 1 diabetes. Physiological Measurement, 25(4), 905-920. doi:10.1088/0967-3334/25/4/010Ibbini, M., & Masadeh, M. (2005). A fuzzy logic based closed-loop control system for blood glucose level regulation in diabetics. Journal of Medical Engineering & Technology, 29(2), 64-69. doi:10.1080/03091900410001709088JDRF: Artificial Pancreas Project (n.d.).http://jdrf.org. Accessed on March 8 2010.Jeitler, K., Horvath, K., Berghold, A., Gratzer, T. W., Neeser, K., Pieber, T. R., & Siebenhofer, A. (2008). Continuous subcutaneous insulin infusion versus multiple daily insulin injections in patients with diabetes mellitus: systematic review and meta-analysis. Diabetologia, 51(6), 941-951. doi:10.1007/s00125-008-0974-3Jonsson, B. (1998). The Economic Impact of Diabetes. Diabetes Care, 21(Supplement_3), C7-C10. doi:10.2337/diacare.21.3.c7Continuous Glucose Monitoring and Intensive Treatment of Type 1 Diabetes. (2008). New England Journal of Medicine, 359(14), 1464-1476. doi:10.1056/nejmoa0805017Kanderian, S. S., Weinzimer, S., Voskanyan, G., & Steil, G. M. (2009). Identification of Intraday Metabolic Profiles during Closed-Loop Glucose Control in Individuals with Type 1 Diabetes. Journal of Diabetes Science and Technology, 3(5), 1047-1057. doi:10.1177/193229680900300508Keenan, D. B., Cartaya, R., & Mastrototaro, J. J. (2010). Accuracy of a New Real-Time Continuous Glucose Monitoring Algorithm. Journal of Diabetes Science and Technology, 4(1), 111-118. doi:10.1177/193229681000400114King, C., Anderson, S. M., Breton, M., Clarke, W. L., & Kovatchev, B. P. (2007). Modeling of Calibration Effectiveness and Blood-to-Interstitial Glucose Dynamics as Potential Confounders of the Accuracy of Continuous Glucose Sensors during Hyperinsulinemic Clamp. Journal of Diabetes Science and Technology, 1(3), 317-322. doi:10.1177/193229680700100302Klonoff, D. C., & Schwartz, D. M. (2000). An economic analysis of interventions for diabetes. Diabetes Care, 23(3), 390-404. doi:10.2337/diacare.23.3.390Klonoff, D. C., & Reyes, J. S. (2009). Insulin Pump Safety Meeting: Summary Report. Journal of Diabetes Science and Technology, 3(2), 396-402. doi:10.1177/193229680900300224Kovatchev, B., Anderson, S., Heinemann, L., & Clarke, W. (2008). Comparison of the Numerical and Clinical Accuracy of Four Continuous Glucose Monitors. Diabetes Care, 31(6), 1160-1164. doi:10.2337/dc07-2401Kovatchev, B., Patek, S., Dassau, E., Doyle, F. J., Magni, L., … De Nicolao, G. (2009). Control to Range for Diabetes: Functionality and Modular Architecture. Journal of Diabetes Science and Technology, 3(5), 1058-1065. doi:10.1177/193229680900300509Kovatchev, B. P., Breton, M., Dalla Man, C., & Cobelli, C. (2009). In SilicoPreclinical Trials: A Proof of Concept in Closed-Loop Control of Type 1 Diabetes. Journal of Diabetes Science and Technology, 3(1), 44-55. doi:10.1177/193229680900300106Kowalski, A. J. (2009). Can We Really Close the Loop and How Soon? Accelerating the Availability of an Artificial Pancreas: A Roadmap to Better Diabetes Outcomes. Diabetes Technology & Therapeutics, 11(S1), S-113-S-119. doi:10.1089/dia.2009.0031Kumareswaran, K., Evans, M. L., & Hovorka, R. (2009). Artificial pancreas: an emerging approach to treat Type 1 diabetes. Expert Review of Medical Devices, 6(4), 401-410. doi:10.1586/erd.09.23Leal, Y., Garcia-Gabin, W., Bondia, J., Esteve, E., Ricart, W., Fernandez-Real, J.-M., & Vehi, J. (2010). Real-Time Glucose Estimation Algorithm for Continuous Glucose Monitoring Using Autoregressive Models. Journal of Diabetes Science and Technology, 4(2), 391-403. doi:10.1177/193229681000400221Lee, H., Buckingham, B. A., Wilson, D. M., & Bequette, B. W. (2009). A Closed-Loop Artificial Pancreas Using Model Predictive Control and a Sliding Meal Size Estimator. Journal of Diabetes Science and Technology, 3(5), 1082-1090. doi:10.1177/193229680900300511Lee, S. and E. Hitt (n.d.). Continuous subcutaneous insulin infusion: Intensive treatment, flexible lifestyle. http://cme.medscape.com/viewarticle/460365.Lehmann, E. D., Deutsch, T., Carson, E. R., & Sönksen, P. H. (1994). AIDA: an interactive diabetes advisor. Computer Methods and Programs in Biomedicine, 41(3-4), 183-203. doi:10.1016/0169-2607(94)90054-xMagni, L., Raimondo, D. M., Bossi, L., Dalla Man, C., De Nicolao, G., Kovatchev, B., & Cobelli, C. (2007). Model Predictive Control of Type 1 Diabetes: An in Silico Trial. Journal of Diabetes Science and Technology, 1(6), 804-812. doi:10.1177/193229680700100603Mazze, R. S., Strock, E., Borgman, S., Wesley, D., Stout, P., & Racchini, J. (2009). Evaluating the Accuracy, Reliability, and Clinical Applicability of Continuous Glucose Monitoring (CGM): Is CGM Ready for Real Time? Diabetes Technology & Therapeutics, 11(1), 11-18. doi:10.1089/dia.2008.0041McMahon, S. K., Ferreira, L. D., Ratnam, N., Davey, R. J., Youngs, L. M., Davis, E. A., … Jones, T. W. (2007). Glucose Requirements to Maintain Euglycemia after Moderate-Intensity Afternoon Exercise in Adolescents with Type 1 Diabetes Are Increased in a Biphasic Manner. The Journal of Clinical Endocrinology & Metabolism, 92(3), 963-968. doi:10.1210/jc.2006-2263Mecklenburg, R. S., Guinn, T. S., Sannar, C. A., & Blumenstein, B. A. (1986). Malfunction of Continuous Subcutaneous Insulin Infusion Systems: A One-Year Prospective Study of 127 Patients. Diabetes Care, 9(4), 351-355. doi:10.2337/diacare.9.4.351Mendosa, D. (n.d.). Meter memories: how Tom, Dick, and Charlie did it. http://www.mendosa.com/memories.htm.Menzin, J., Langley-Hawthorne, C., Friedman, M., Boulanger, L., & Cavanaugh, R. (2001). Potential Short-Term Economic Benefits of Improved Glycemic Control: A managed care perspective. Diabetes Care, 24(1), 51-55. doi:10.2337/diacare.24.1.51Monsod, T. P., Flanagan, D. E., Rife, F., Saenz, R., Caprio, S., Sherwin, R. S., & Tamborlane, W. V. (2002). Do Sensor Glucose Levels Accurately Predict Plasma Glucose Concentrations During Hypoglycemia and Hyperinsulinemia? Diabetes Care, 25(5), 889-893. doi:10.2337/diacare.25.5.889Mudaliar, S. R., Lindberg, F. A., Joyce, M., Beerdsen, P., Strange, P., Lin, A., & Henry, R. R. (1999). Insulin aspart (B28 asp-insulin): a fast-acting analog of human insulin: absorption kinetics and action profile compared with regular human insulin in healthy nondiabetic subjects. Diabetes Care, 22(9), 1501-1506. doi:10.2337/diacare.22.9.1501Nilsson, A., Granfeldt, Y., Östman, E., Preston, T., & Björck, I. (2006). Effects of GI and content of indigestible carbohydrates of cereal-based evening meals on glucose tolerance at a subsequent standardised breakfast. European Journal of Clinical Nutrition, 60(9), 1092-1099. doi:10.1038/sj.ejcn.1602423Oliver, N., Georgiou, P., Johnston, D., & Toumazou, C. (2009). A Benchtop Closed-loop System Controlled by a Bio-Inspired Silicon Implementation of the Pancreatic β Cell. Journal of Diabetes Science and Technology, 3(6), 1419-1424. doi:10.1177/193229680900300623Oliver, N. S., Toumazou, C., Cass, A. E. G., & Johnston, D. G. (2009). Glucose sensors: a review of current and emerging technology. Diabetic Medicine, 26(3), 197-210. doi:10.1111/j.1464-5491.2008.02642.xOmnipod Insulin Pump (n.d.). http://www.myomnipod.com/.Accessed on March 13, 2010.Palerm, C. C., Zisser, H., Bevier, W. C., Jovanovic, L., & Doyle, F. J. (2007). Prandial Insulin Dosing Using Run-to-Run Control: Application of clinical data and medical expertise to define a suitable performance metric. Diabetes Care, 30(5), 1131-1136. doi:10.2337/dc06-2115Parker, R. S., Doyle, F. J., & Peppas, N. A. (1999). A model-based algorithm for blood glucose control in Type I diabetic patients. IEEE Transactions on Biomedical Engineering, 46(2), 148-157. doi:10.1109/10.740877Parker, R. S., Doyle, F. J., Ward, J. H., & Peppas, N. A. (2000). RobustH∞ glucose control in diabetes using a physiological model. AIChE Journal, 46(12), 2537-2549. doi:10.1002/aic.690461220Patek, S. D., Bequette, B. W., Breton, M., Buckingham, B. A., Dassau, E., Doyle, F. J., … Zisser, H. (2009). In Silico Preclinical Trials: Methodology and Engineering Guide to Closed-Loop Control in Type 1 Diabetes Mellitus. Journal of Diabetes Science and Technology, 3(2), 269-282. doi:10.1177/1",'Elsevier BV',Artificial pancreas: automatic control of insulin infusion in type 1 diabetes mellitus,10.1016/S1697-7912(10)70021-2,http://hdl.handle.net/10251/144994,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275608464,2011-05-01T00:00:00,"In this paper, we present a novel algorithm for precise eye detection. First, a couple of AdaBoost classifiers trained with Haar-like features are used to preselect possible eye locations. Then, a Support Vector Machine machine that uses Histograms of Oriented Gradients descriptors is used to obtain the best pair of eyes among all possible combinations of preselected eyes. Finally, we compare the eye detection results with three state-of-the-art works and a commercial software. The results show that our algorithm achieves the highest accuracy on the FERET and FRGCv1 databases, which is the most complete comparative presented so far. © Springer-Verlag 2010.This work has been partially supported by the grant TEC2009-09146 of the Spanish Government.Monzó Ferrer, D.; Albiol Colomer, A.; Sastre, J.; Albiol Colomer, AJ. (2011). Precise eye localization using HOG descriptors. Machine Vision and Applications. 22(3):471-480. https://doi.org/10.1007/s00138-010-0273-0S471480223Riopka, T., Boult, T.: The eyes have it. In: Proceedings of ACM SIGMM Multimedia Biometrics Methods and Applications Workshop, Berkeley, CA, pp. 9–16 (2003)Kim C., Choi C.: Image covariance-based subspace method for face recognition. Pattern Recognit. 40(5), 1592–1604 (2007)Wang, P., Green, M., Ji, Q., Wayman, J.: Automatic eye detection and its validation. In: Proceedings of the International Conference on Computer Vision and Pattern Recognition, vol. 3, San Diego, CA, pp. 164–171 (2005)Amir A., Zimet L., Sangiovanni-Vincentelli A., Kao S.: An embedded system for an eye-detection sensor. Comput. Vis. Image Underst. 98(1), 104–123 (2005)Zhu Z., Ji Q.: Robust real-time eye detection and tracking under variable lighting conditions and various face orientations. Comput. Vis. Image Underst. 98(1), 124–154 (2005)Huang, W., Mariani, R.: Face detection and precise eyes location. In: Proceedings of the International Conference on Pattern Recognition, vol. 4, Washington, DC, USA, pp. 722–727 (2000)Brunelli R., Poggio T.: Face recognition: features versus templates. IEEE Trans. Pattern Anal. Mach. Intell. 15(10), 1042–1052 (1993)Guan, Y.: Robust eye detection from facial image based on multi-cue facial information. In: Proceedings of IEEE International Conference on Control and Automation, pp. 1775–1778 (2007)Rizon, M., Kawaguchi, T.: Automatic eye detection using intensity and edge information. In: Proceedings of TENCON, vol. 2, Kuala Lumpur, Malaysia, pp. 415–420 (2000)Han, C., Liao, H., Yu, K., Chen, L.: Fast face detection via morphology-based pre-processing. In: Proceedings of the 9th International Conference on Image Analysis and Processing, vol. 2. Springer, London, UK, pp. 469–476 (1997)Song J., Chi Z., Liu J.: A robust eye detection method using combined binary edge and intensity information. Pattern Recognit. 39(6), 1110–1125 (2006)Campadelli, P., Lanzarotti, R., Lipori, G.: Precise eye localization through a general-to-specific model definition. In: Proceedings of the British Machine Vision Conference, Edinburgh, Scotland, pp. 187–196 (2006)Smeraldi F., Carmona O., Bign J.: Saccadic search with gabor features applied to eye detection and real-time head tracking. Image Vis. Comput. 18(4), 323–329 (1998)Sirohey S. A., Rosenfeld A.: Eye detection in a face image using linear and nonlinear filters. Pattern Recognit. 34(7), 1367–1391 (2001)Ma, Y., Ding, X., Wang, Z., Wang, N.: Robust precise eye location under probabilistic framework. In: Proceedings of the International Conference on Automatic Face and Gesture Recognition, Seoul, Korea, pp. 339–344 (2004)Lu, H., Zhang, W., Yang D.: Eye detection based on rectangle features and pixel-pattern-based texture features. In: Proceedings of the International Symposium on Intelligent Signal Processing and Communication Systems, pp. 746–749 (2007)Jin, L., Yuan, X., Satoh, S., Li, J., Xia, L.: A hybrid classifier for precise and robust eye detection. In: Proceedings of the International Conference on Pattern Recognition, vol. 4, Hong Kong, pp. 731–735 (2006)Vapnik V. N.: The Nature of Statistical Learning Theory. Springer, New York Inc, New York, NY (1995)Viola, P., Jones, M.: Rapid object detection using a boosted cascade of simple features. In: Proceedings of the International Conference on Computer Vision and Pattern Recognition, vol. 1, Hawaii, pp. 511–518 (2001)Fasel I., Fortenberry B., Movellan J.: A generative framework for real time object detection and classification. Comput. Vis. Image Underst. 98(1), 182–210 (2005)Huang J., Wechsler H.: Visual routines for eye location using learning and evolution. IEEE Trans. Evolut. Comput. 4(1), 73–82 (2000)Behnke S.: Face localization and tracking in the neural abstraction pyramid. Neural Comput. Appl. 14(2), 97–103 (2005)Dalal, N., Triggs, B.: Histograms of oriented gradients for human detection. In: Proceedings of the 9th European Conference on Computer Vision, vol. 2, San Diego, CA, pp. 886–893 (2005)Albiol A., Monzo D., Martin A., Sastre J., Albiol A.: Face recognition using hog-ebgm. Pattern Recognit. Lett. 29(10), 1537–1543 (2008)Lowe D.: Distinctive image features from scale-invariant keypoints. Int. J. Comput. Vis. 60(2), 91–110 (2004)Bicego, M., Lagorio, A., Grosso, E., Tistarelli M.: On the use of SIFT features for face authentication. In: Proceedings of the International Conference on Computer Vision and Pattern Recognition Workshop, New York, p. 35 (2006)Yang M.-H., Kriegman D., Ahuja N.: Detecting faces in images: a survey. Trans. Pattern Anal. Mach. Intell. 24(1), 34–58 (2002)Jain A., Murty M., Flynn P.: Data clustering: a review. ACM Comput. Syst. 31(3), 264–323 (1999)Mikolajczyk K., Schmid C.: A performance evaluation of local descriptors. IEEE Trans. Pattern Anal. Mach. Intell. 27(10), 1615–1630 (2005)Humanscan, BioID database. http://www.bioid.comPeer, P.: CVL Face database, University of Ljubjana. http://www.fri.uni-lj.si/enPhillips P. J., Moon H., Rizvi S. A., Rauss P. J.: The feret evaluation methodology for face-recognition algorithms. IEEE Trans. Pattern Anal. Mach. Intell. 22(10), 1090–1104 (2000)Phillips, P.J., Flynn, P.J., Scruggs, T., Bowyer, K.W., Jin, C., Hoffman, K., Marques, J., Jaesik, M., Worek, W.: Overview of the face recognition grand challenge. In: Proceedings of the International Conference on Computer Vision and Pattern Recognition, vol. 1, San Diego, CA, pp. 947–954 (2005)Jesorsky, O., Kirchberg, K.J., Frischholz, R.: Robust face detection using the hausdorff distance. In: Proceedings of the Third International Conference on Audio- and Video-Based Biometric Person Authentication, Springer, London, UK, pp. 90–95 (2001)Neurotechnologija, Biometrical and Artificial Intelligence Technologies, Verilook SDK. http://www.neurotechnologija.comWitten I., Frank E.: Data Mining: Practical Machine Learning Tools and Techniques, 2nd edn: Morgan Kaufmann Series in Data Management Systems. Morgan Kaufmann, San Francisco (2005)Turk M., Pentland A.: Eigenfaces for recognition. J. Cogn. Neurosci. 3(1), 71–86 (1991",'Springer Science and Business Media LLC',Precise eye localization using HOG descriptors,10.1007/s00138-010-0273-0,https://riunet.upv.es/bitstream/10251/58789/7/eyedetection_mva_final_version_autor.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
146029786,2014-04-26T00:00:00,"International audienceWhile single-accelerometers are a common consumer embedded sensors, their use in representing movement data as an intelligent resource remains scarce. Accelerometers have been used in movement recognition systems, but rarely to assess expressive qualities of movement. We present a prototype of wearable system for the real-time detection and classification of movement quality using acceleration data. The system applies Laban Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input using a Machine Learning software that generates classifications in real time. Existing LMA-recognition systems rely on motion capture data and video data, and can only be deployed in controlled settings. Our single- accelerometer system is portable and can be used under a wide range of environmental conditions. We evaluate the performance of the system, present two applications using the system in the digital arts and discuss future directions",'Association for Computing Machinery (ACM)',Designing For Movement: Evaluating Computational Models using LMA Effort Qualities,10.1145/2556288.2557251,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
233912790,2014-05-18T00:00:00,"The article discusses the gesture recognition system based on head distributed multi-agent network. A model of head movement in 3D space. Head position described by the matrix configurations.Developed a method of recognition of fuzzy gestures, based on recognition of the graph constructed on the basis of fuzzy nodes. Graph is generated for each dynamic gesture, perfect head.It is shown that the recognition process can be performed by a fuzzy neural network. Software agents implement recognition system.Presented work distributed recognition system in real time.DOI: http://dx.doi.org/10.12731/2227-930X-2014-1-5В статье рассматривается система распознавания жестов на голову распределены мульти-агентской сети. Модель движения головы в 3D-пространстве. Положение головы описано конфигураций матрицы.Разработан метод распознавания нечетких жестов, основанный на признании графа, построенного на основе нечетких узлов. График генерируется для каждой динамической жест, совершенный голове.Показано, что процесс распознавания может быть выполнена с помощью нечеткой нейронной сети. Программные агенты реализовать систему распознавания.Представленная работа распределенной системы распознавания в реальном времени",Science and Innovation Center Publishing House,МЕТОДА НЕЧЕТКОГО ЖЕСТЫ ПРИЗНАНИЕ В РАЗВИТИИ БЕСКОНТАКТНЫХ ИНТЕРФЕЙСЫ,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
147790303,2012-07-01,"El vertiginoso crecimiento de los centros urbanos, las tecnologías emergentes y la demanda de nuevos servicios por parte de la población plantea encaminar esfuerzos hacia el desarrollo de las ciudades inteligentes. Éste concepto ha tomado fuerza entre los sectores político, económico, social, académico, ambiental y civil; de forma paralela, se han generado iniciativas que conducen hacia la integración de la infraestructura, la tecnología y los servicios para los ciudadanos. En éste contexto, una de las problemáticas con mayor impacto en la sociedad es la seguridad vial. Es necesario contar con mecanismos que disminuyan la accidentalidad, mejoren la atención a incidentes, optimicen la movilidad urbana y planeación municipal, ayuden a reducir el consumo de combustible y la emisión de gases de efecto de invernadero, así como ofrecer información dinámica y efectiva a los viajeros. En este artículo se describen dos (2) enfoques que contribuyen de manera eficiente dicho problema: los videojuegos como juegos serios y los sistemas de transporte inteligente. Ambos enfoques están encaminados a evitar colisiones y su diseño e implementación requieren componentes altamente tecnológicos (e.g. sistemas telemáticos e informáticos, inteligencia artificial, procesamiento de imágenes y modelado 3D).The rapid growth of urban centers, the emerging technologies
and the demand for new services by the increasing population
introduce a new challenge: going towards smart cities. This
concept has taken hold among the political, economic, social,
academic, environmental and civil sectors, and several initiatives
leads to the integration of infrastructure, technology and
services for citizens. In this context, road safety and traffic
efficiency became in key issues to be solved. New mechanisms
are needed in order to reduce accidents and its mortality rate,
also requirements such as the optimization of the urban mobility
and municipal planning, fuel consumption and greenhouse gases
emissions reduction and real-time systems that provide dynamic
and effective information to travelers. This article describes
two (2) approaches that contribute efficiently to the traffic
safety problem: video games used as serious games and vehicular
applications for intelligent transportation systems. Both approaches
aims to reduce collisions and required a highly technological
baseline to be implemented (e.g. telematic and computer systems,
artificial intelligence, image processing and 3D modeling)",Facultad de Ingeniería,Del videojuego a la realidad : sistema interactivo para la seguridad vial,,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
37973387,2012-01-01T00:00:00,"Energy efficiency at the software level has gained much attention in the past decade. This paper presents a performance-aware frequency assignment algorithm for reducing processor energy consumption using Dynamic Voltage and Frequency Scaling (DVFS). Existing energy-saving techniques often rely on simplified predictions or domain knowledge to extract energy savings for specialized software (such as multimedia or mobile applications) or hardware (such as NPU or sensor nodes). We present an innovative framework, known as EClass, for general-purpose DVFS processors by recognizing short and repetitive utilization patterns efficiently using machine learning. Our algorithm is lightweight and can save up to 52.9% of the energy consumption compared with the classical PAST algorithm. It achieves an average savings of 9.1% when compared with an existing online learning algorithm that also utilizes the statistics from the current execution only. We have simulated the algorithms on a cycle-accurate power simulator. Experimental results show that EClass can effectively save energy for real life applications that exhibit mixed CPU utilization patterns during executions. Our research challenges an assumption among previous work in the research community that a simple and efficient heuristic should be used to adjust the processor frequency online. Our empirical result shows that the use of an advanced algorithm such as machine learning can not only compensate for the energy needed to run such an algorithm, but also outperforms prior techniques based on the above assumption. © 2011 Elsevier Inc. All rights reserved.postprin",'Elsevier BV',EClass: An execution classification approach to improving the energy-efficiency of software via machine learning,10.1016/j.jss.2011.11.1010,https://core.ac.uk/download/37973387.pdf,"[{'title': 'Journal of Systems and Software', 'identifiers': ['0164-1212', 'issn:0164-1212']}]",core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
132003587,2014-10-01T00:00:00,"Part 6: Short PapersInternational audiencePerforming server and network experiments on video games                                can be cumbersome because it usually requires a large number of players                                to generate sufficient server and network load. A solution is automated                                artificial intelligence-controlled virtual clients that behave as real players.                                This paper describes an implementation of virtual clients in the open                                source video game Quake III Arena, which converts the game into an                                open source tool for generating server load with realistic network traffic                                for investigating game system scalability",'Springer Science and Business Media LLC',Implementing Virtual Clients in Quake III Arena,10.1007/978-3-662-45212-7_32,,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
226465289,2015-04-21T07:42:35,"none582BACKGROUND: Multi-element interventions for first-episode psychosis (FEP) are promising, but have mostly been conducted in non-epidemiologically representative samples, thereby raising the risk of underestimating the complexities involved in treating FEP in 'real-world' services. METHODS/DESIGN: The Psychosis early Intervention and Assessment of Needs and Outcome (PIANO) trial is part of a larger research program (Genetics, Endophenotypes and Treatment: Understanding early Psychosis - GET UP) which aims to compare, at 9 months, the effectiveness of a multi-component psychosocial intervention versus treatment as usual (TAU) in a large epidemiologically based cohort of patients with FEP and their family members recruited from all public community mental health centers (CMHCs) located in two entire regions of Italy (Veneto and Emilia Romagna), and in the cities of Florence, Milan and Bolzano. The GET UP PIANO trial has a pragmatic cluster randomized controlled design. The randomized units (clusters) are the CMHCs, and the units of observation are the centers' patients and their family members. Patients in the experimental group will receive TAU plus: 1) cognitive behavioral therapy sessions, 2) psycho-educational sessions for family members, and 3) case management. Patient enrollment will take place over a 1-year period. Several psychopathological, psychological, functioning, and service use variables will be assessed at baseline and follow-up. The primary outcomes are: 1) change from baseline to follow-up in positive and negative symptoms' severity and subjective appraisal; 2) relapse occurrences between baseline and follow-up, that is, episodes resulting in admission and/or any case-note records of re-emergence of positive psychotic symptoms. The expected number of recruited patients is about 400, and that of relatives about 300. Owing to the implementation of the intervention at the CMHC level, the blinding of patients, clinicians, and raters is not possible, but every effort will be made to preserve the independency of the raters. We expect that this study will generate evidence on the best treatments for FEP, and will identify barriers that may hinder its feasibility in 'real-world' clinical settings, patient/family conditions that may render this intervention ineffective or inappropriate, and clinical, psychological, environmental, and service organization predictors of treatment effectiveness, compliance, and service satisfaction.Ruggeri M, Bonetto C, Lasalvia A, De Girolamo G, Fioritti A, Rucci P, Santonastaso P, Neri G, Pileggi F, Ghigi D, Miceli M, Scarone S, Cocchi A, Torresani S, Faravelli C, Zimmermann C, Meneghelli A, Cremonese C, Scocco P, Leuci E, Mazzi F, Gennarelli M, Brambilla P, Bissoli S, Bertani ME, Tosato S, De Santi K, Poli S, Cristofalo D, Tansella M; GET UP GROUP, Ruggeri M, Mirella ME, Bissoli S, Bonetto C, Cristofalo D, De Santi K, Lasalvia A, Lunardi S, Negretto V, Poli S, Tosato S, Zamboni MG, Ballarin M, De Girolamo G, Fioritti A, Neri G, Pileggi F, Rucci P, Bocchio Chiavetto L, Scasselatti C, Zanardini R, Brambilla P, Bellani M, Bertoldo A, Marinelli V, Negretto V, Perlini C, Rambaldelli G, Lasalvia A, Bertani M, Bissoli S, Lazzarotto L, Bardella S, Gardellin F, Lamonaca D, Lasalvia A, Lunardon M, Magnabosco R, Martucci M, Nicolau S, Nifosì F, Pavanati M, Rossi M, Piazza C, Piccione G, Sala A, Sale A, Stefan B, Zotos S, Balbo M, Boggian I, Ceccato E, Dall'Agnola R, Gardellin F, Girotto B, Goss C, Lamonaca D, Lasalvia A, Leoni R, Mai A, Pasqualini A, Pavanati M, Piazza C,
Piccione G, Roccato S, Rossi A, Sale A, Strizzolo S, Zotos S, Urbani A, Ald F, Bianchi B, Cappellari P, Conti R, De Battisti L, Lazzarin E, Merlin S, Migliorini G, Pozzan T, Sarto L, Visonà S, Brazzoli A, Campi A, Carmagnani R, Giambelli S, Gianella A, Lunardi L, Madaghiele D, Maestrelli P, Paiola L, Posteri E, Viola L, 
Zamberlan V, Zenari M, Tosato S, Zanoni M, Bonadonna G, Bonomo M, Santonastaso P, Cremonese C, Scocco P, Veronese A, Anderle P, Angelozz A, Amalric I, Baron G, Candeago EB, Castelli F, Chieco M, Cremonese C, Di Costanzo E, Derossi M, Doriguzzi M, Galvano O, Lattanz M, Lezzi R, Marcato M, Marcolin A, Marini F,
Matranga M, Scalabrin D, Zucchetto M, Zadro F, Austoni G, Bianco M, Bordino F, Dario F, De Risio A, Gatto A, Granà S, Favero E, Franceschin A, Friederici S, Marangon V, Pascolo M, Ramon L, Scocco P, Veronese A, Zambolin S, Riolo R, Buffon
A, Cremonese C, Di Bortolo E, Friederici S, Fortin S, Marcato M, Matarrese F, Mogni S, Codemo N, Russi A, Silvestro A, Turella E, Viel P, Dominoni A, Andreose L, Boemio M, Bressan L, Cabbia A, Canesso E, Cian R, Dal Piccol C, Dalla Pasqua MM, Di Prisco A, Mantellato L, Luison M, Morgante S, Santi M, Sacillotto M,
Scabbio M, Sponga P, Sguotto ML, Stach F, Vettorato MG, Martinello G, Dassiè F, Marino S, Cibiniel L, Masetto I, Marcato M, Cabianca O, Valente A, Caberlotto L, Passoni A, Flumian P, Daniel L, Gion M, Stanziale S, Alborino F, Bortolozzo V, Bacelle L, Bicciato L, Basso D, Navaglia F, Manoni F, Ercolin M, Neri G,
Giubilini F, Imbesi M, Leuci E, Mazzi F, Semrov E, Giovanni CS, Taro e Ceno V, Ovest P, Anelli S, Amore M, Bigi L, Britta W, Anna GB, Bonatti U, Borziani M, Crosato I, Galluccio R, Galeotti M, Gozzi M, Greco V, Guagnini E, Pagani S, Maccherozzi M, Marchi F, Melato E, Mazzucchi E, Marzullo F, Pellegrini P, Petrolini N, Volta P, Anelli S, Bonara F, Brusamonti E, Croci R, Flamia I, Fontana F, Losi R, Mazzi F, Marchioro R, Pagani S, Raffaini L, Ruju L, Saginario A, Tondelli MG, Marrama D, Bernardelli L, Bonacini F, Florindo A, Merli M, Nappo P, Sola L, Tondelli O, Tonna M, Torre MT, Tosatti M, Venturelli G, Zampolla D, Bernardi A, Cavalli C, Cigala L, Ciraudo C, Di Bari A, Ferri L, Gombi F, Leurini S, Mandatelli E, Maccaferri S, Oroboncoide M, Pisa B, Ricci C, Poggi E, Zurlini C, Malpeli M, Colla R, Teodori E, Vecchia L, D'Andrea R, Trenti T, Paolini P, Mazzi F, Carpeggiani P, Pileggi F, Ghigi D, Gagliostro M, Pratelli M, Rucci P, Lazzaro S, Antonelli A, Battistini L, Bellini F, Bonini E, Capelli CB, DiDomizio C, Drei C, Fucci G, Gualandi A, Grazia MR, Losi AM, Mazzoni FM, Marangoni D,
Monna G, Morselli M, Oggioni A, Oprandi S, Paganelli W, Passerini M, Piscitelli M, Reggiani G, Rossi G, Salvatori F, Trasforini S, Uslenghi C, Veggetti S, Bartolucci G, Baruffa R, Bellini F, Bertelli R, Borghi L, Ciavarella P, DiDomizio C, Monna G, Oggioni A, Paltrinieri E, Rizzardi F, Serra P, Suzzi D, Carlo U, Piscitelli M, Arienti P, Aureli F, Avanzi R, Callegari V, Corsino A, Host P,
Michetti R, Pratelli M, Rizzo F, Simoncelli P, Soldati E, Succi E, Bertozzi M, Canetti E, Cavicchioli L, Ceccarelli E, Cenni S, Marzola G, Gallina V, Leoni C, Olivieri A, Piccolo E, Ravagli S, Russo R, Tedeschini D, Verenini M, Abram W, Granata V, Curcio A, Guerra G, Granini S, Natali L, Montanari E, Pasi F, Ventura 
U, Valenti S, Francesca M, Farneti R, Ravagli P, Floris R, Maroncelli O, Volpones G, Casali D, Miceli M, Bencini A, Cellini M, De Biase L, Barbara L, Charles L, Pratesi C, Tanini A, Cellini M, Miceli M, Loparrino R, Pratesi C, Ulivelli C, Cussoto C, Dei N, Fumanti E, Pantani M, Zeloni G, Bellini R, Cellesi R, Dorigo N,
Gullì P, Ialeggio L, Pisanu M, Rinaldi G, Konze A, Cocchi A, Meneghelli A, Bianco M, Modignani L, Frova M, Monzani E, Zanobio A, Malagoli M, Pagani R, Barbera S, Morganti C, Monzani E, Amadè ES, Brambilla V, Montanari A, Caterina G, Lopez C,
Marocchi A, Moletta A, Sberna M, Cascio MT, Scarone S, Manzone ML, Barbara B, Mari L, Manzone ML, Razzini E, Bianchi Y, Pellizzer MR, Verdecchia A, Sferrazza MG, Manzone ML, Pismataro R, D'Eril GV, Barassi A, Pacciolla R, Faraci G, Torresani S, Rosmini B, Carpi F, Soelva M, Anderlan M, De Francesco M, Duregger
E, Torresani S, Vettori C, Doimo S, Kompatscher E, Soelva M, Torresani S, Forer M, Kerschbaumer H, Gampe A, Nicoletti M, Acerbi C, Aquilino D, Azzali S, Bensi L, Bissoli S, Cappellari D, Casana E, Campagnola N, Dal Corso E, Di Micco E, Gobbi
E, Ferri L, Gobbi E, Mairaghi L, Malak S, Mesiano L, Paterlini F, Perini M, Puliti EM, Rispoli R, Rizzo E, Sergenti C, Soave M, Alpi A, Bislenghi L, Bolis T, Colnaghi F, Fascendini S, Grignani S, Meneghelli A, Patelli G, Faravelli C, Casale S, Zimmermann C, Deledda G, Goss C, Mazzi M, Rimondini M, Gennarelli M,
Scassellati C, Bonvicini C, Longo S, Bocchio Chiavetto L, Zanardini R, Ventriglia M, Squitti R, Frisoni G, Pievani M, Balestrieri M, Brambilla P, Perlini C, Marinelli V, Bellani M, Rambaldelli G, Bertoldo A, Atzori M, Mazzi F, Carpeggiani
P, Beltramello A, Alessandrini F, Pizzini F, Zoccatelli G, Sberna M, Konze A, Politi P, Emanuele E, Brondino N, Martino G, Bergami A, Zarbo R, Riva MA, Fumagalli F, Molteni R, Calabrese F, Guidotti G, Luoni A, Macchi F, Artioli S, Baldetti M, Bizzocchi M, Bolzon D, Bonello E, Cacciari G, Carraresi C, Cascio MT, Caselli G, Furlato K, Garlassi S, Gavarini A, Lunardi S, Macchetti F, Marteddu V,
Plebiscita G, Poli S, Totaro S, Bebbington P, Birchwood M, Dazzan P, Kuipers E, Thornicroft G, Pariante C, Lawrie S, Pariante C, Soares JCRuggeri, M; Bonetto, C; Lasalvia, A; De Girolamo, G; Fioritti, A; Rucci, P; Santonastaso, P; Neri, G; Pileggi, F; Ghigi, D; Miceli, M; Scarone, S; Cocchi, A; Torresani, S; Faravelli, C; Zimmermann, C; Meneghelli, A; Cremonese, C; Scocco, P; Leuci, E; Mazzi, F; Gennarelli, M; Brambilla, P; Bissoli, S; Bertani, Me; Tosato, S; De Santi, K; Poli, S; Cristofalo, D; Tansella, M; GET UP, Group; Ruggeri, M; Mirella, Me; Bissoli, S; Bonetto, C; Cristofalo, D; De Santi, K; Lasalvia, A; Lunardi, S; Negretto, V; Poli, S; Tosato, S; Zamboni, Mg; Ballarin, M; De Girolamo, G; Fioritti, A; Neri, G; Pileggi, F; Rucci, P; Bocchio Chiavetto, L; Scasselatti, C; Zanardini, R; Brambilla, P; Bellani, M; Bertoldo, A; Marinelli, V; Negretto, V; Perlini, C; Rambaldelli, G; Lasalvia, A; Bertani, M; Bissoli, S; Lazzarotto, L; Bardella, S; Gardellin, F; Lamonaca, D; Lasalvia, A; Lunardon, M; Magnabosco, R; Martucci, M; Nicolau, S; Nifosì, F; Pavanati, M; Rossi, M; Piazza, C; Piccione, G; Sala, A; Sale, A; Stefan, B; Zotos, S; Balbo, M; Boggian, I; Ceccato, E; Dall'Agnola, R; Gardellin, F; Girotto, B; Goss, C; Lamonaca, D; Lasalvia, A; Leoni, R; Mai, A; Pasqualini, A; Pavanati, M; Piazza, C; Piccione, G; Roccato, S; Rossi, A; Sale, A; Strizzolo, S; Zotos, S; Urbani, A; Ald, F; Bianchi, B; Cappellari, P; Conti, R; De Battisti, L; Lazzarin, E; Merlin, S; Migliorini, G; Pozzan, T; Sarto, L; Visonà, S; Brazzoli, A; Campi, A; Carmagnani, R; Giambelli, S; Gianella, A; Lunardi, L; Madaghiele, D; Maestrelli, P; Paiola, L; Posteri, E; Viola, L; Zamberlan, V; Zenari, M; Tosato, S; Zanoni, M; Bonadonna, G; Bonomo, M; Santonastaso, P; Cremonese, C; Scocco, P; Veronese, A; Anderle, P; Angelozz, A; Amalric, I; Baron, G; Candeago, Eb; Castelli, F; Chieco, M; Cremonese, C; Di Costanzo, E; Derossi, M; Doriguzzi, M; Galvano, O; Lattanz, M; Lezzi, R; Marcato, M; Marcolin, A; Marini, F; Matranga, M; Scalabrin, D; Zucchetto, M; Zadro, F; Austoni, G; Bianco, M; Bordino, F; Dario, F; De Risio, A; Gatto, A; Granà, S; Favero, E; Franceschin, A; Friederici, S; Marangon, V; Pascolo, M; Ramon, L; Scocco, P; Veronese, A; Zambolin, S; Riolo, R; Buffon, A; Cremonese, C; Di Bortolo, E; Friederici, S; Fortin, S; Marcato, M; Matarrese, F; Mogni, S; Codemo, N; Russi, A; Silvestro, A; Turella, E; Viel, P; Dominoni, A; Andreose, L; Boemio, M; Bressan, L; Cabbia, A; Canesso, E; Cian, R; Dal Piccol, C; Dalla Pasqua, Mm; Di Prisco, A; Mantellato, L; Luison, M; Morgante, S; Santi, M; Sacillotto, M; Scabbio, M; Sponga, P; Sguotto, Ml; Stach, F; Vettorato, Mg; Martinello, G; Dassiè, F; Marino, S; Cibiniel, L; Masetto, I; Marcato, M; Cabianca, O; Valente, A; Caberlotto, L; Passoni, A; Flumian, P; Daniel, L; Gion, M; Stanziale, S; Alborino, F; Bortolozzo, V; Bacelle, L; Bicciato, L; Basso, D; Navaglia, F; Manoni, F; Ercolin, M; Neri, G; Giubilini, F; Imbesi, M; Leuci, E; Mazzi, F; Semrov, E; Giovanni, Cs; Taro e., Ceno V; Ovest, P; Anelli, S; Amore, M; Bigi, L; Britta, W; Anna, Gb; Bonatti, U; Borziani, M; Crosato, I; Galluccio, R; Galeotti, M; Gozzi, M; Greco, V; Guagnini, E; Pagani, S; Maccherozzi, M; Marchi, F; Melato, E; Mazzucchi, E; Marzullo, F; Pellegrini, P; Petrolini, N; Volta, P; Anelli, S; Bonara, F; Brusamonti, E; Croci, R; Flamia, I; Fontana, F; Losi, R; Mazzi, F; Marchioro, R; Pagani, S; Raffaini, L; Ruju, L; Saginario, A; Tondelli, Mg; Marrama, D; Bernardelli, L; Bonacini, F; Florindo, A; Merli, M; Nappo, P; Sola, L; Tondelli, O; Tonna, M; Torre, Mt; Tosatti, M; Venturelli, G; Zampolla, D; Bernardi, A; Cavalli, C; Cigala, L; Ciraudo, C; Di Bari, A; Ferri, L; Gombi, F; Leurini, S; Mandatelli, E; Maccaferri, S; Oroboncoide, M; Pisa, B; Ricci, C; Poggi, E; Zurlini, C; Malpeli, M; Colla, R; Teodori, E; Vecchia, L; D'Andrea, R; Trenti, T; Paolini, P; Mazzi, F; Carpeggiani, P; Pileggi, F; Ghigi, D; Gagliostro, M; Pratelli, M; Rucci, P; Lazzaro, S; Antonelli, A; Battistini, L; Bellini, F; Bonini, E; Capelli, Cb; Didomizio, C; Drei, C; Fucci, G; Gualandi, A; Grazia, Mr; Losi, Am; Mazzoni, Fm; Marangoni, D; Monna, G; Morselli, M; Oggioni, A; Oprandi, S; Paganelli, W; Passerini, M; Piscitelli, M; Reggiani, G; Rossi, G; Salvatori, F; Trasforini, S; Uslenghi, C; Veggetti, S; Bartolucci, G; Baruffa, R; Bellini, F; Bertelli, R; Borghi, L; Ciavarella, P; Didomizio, C; Monna, G; Oggioni, A; Paltrinieri, E; Rizzardi, F; Serra, P; Suzzi, D; Carlo, U; Piscitelli, M; Arienti, P; Aureli, F; Avanzi, R; Callegari, V; Corsino, A; Host, P; Michetti, R; Pratelli, M; Rizzo, F; Simoncelli, P; Soldati, E; Succi, E; Bertozzi, M; Canetti, E; Cavicchioli, L; Ceccarelli, E; Cenni, S; Marzola, G; Gallina, V; Leoni, C; Olivieri, A; Piccolo, E; Ravagli, S; Russo, R; Tedeschini, D; Verenini, M; Abram, W; Granata, V; Curcio, A; Guerra, G; Granini, S; Natali, L; Montanari, E; Pasi, F; Ventura, U; Valenti, S; Francesca, M; Farneti, R; Ravagli, P; Floris, R; Maroncelli, O; Volpones, G; Casali, D; Miceli, M; Bencini, A; Cellini, M; De Biase, L; Barbara, L; Charles, L; Pratesi, C; Tanini, A; Cellini, M; Miceli, M; Loparrino, R; Pratesi, C; Ulivelli, C; Cussoto, C; Dei, N; Fumanti, E; Pantani, M; Zeloni, G; Bellini, R; Cellesi, R; Dorigo, N; Gullì, P; Ialeggio, L; Pisanu, M; Rinaldi, G; Konze, A; Cocchi, A; Meneghelli, A; Bianco, M; Modignani, L; Frova, M; Monzani, E; Zanobio, A; Malagoli, M; Pagani, R; Barbera, S; Morganti, C; Monzani, E; Amadè, Es; Brambilla, V; Montanari, A; Caterina, G; Lopez, C; Marocchi, A; Moletta, A; Sberna, M; Cascio, Mt; Scarone, S; Manzone, Ml; Barbara, B; Mari, L; Manzone, Ml; Razzini, E; Bianchi, Y; Pellizzer, Mr; Verdecchia, A; Sferrazza, Mg; Manzone, Ml; Pismataro, R; D'Eril, Gv; Barassi, A; Pacciolla, R; Faraci, G; Torresani, S; Rosmini, B; Carpi, F; Soelva, M; Anderlan, M; De Francesco, M; Duregger, E; Torresani, S; Vettori, C; Doimo, S; Kompatscher, E; Soelva, M; Torresani, S; Forer, M; Kerschbaumer, H; Gampe, A; Nicoletti, M; Acerbi, C; Aquilino, D; Azzali, S; Bensi, L; Bissoli, S; Cappellari, D; Casana, E; Campagnola, N; Dal Corso, E; Di Micco, E; Gobbi, E; Ferri, L; Gobbi, E; Mairaghi, L; Malak, S; Mesiano, L; Paterlini, F; Perini, M; Puliti, Em; Rispoli, R; Rizzo, E; Sergenti, C; Soave, M; Alpi, A; Bislenghi, L; Bolis, T; Colnaghi, F; Fascendini, S; Grignani, S; Meneghelli, A; Patelli, G; Faravelli, C; Casale, S; Zimmermann, C; Deledda, G; Goss, C; Mazzi, M; Rimondini, M; Gennarelli, M; Scassellati, C; Bonvicini, C; Longo, S; Bocchio Chiavetto, L; Zanardini, R; Ventriglia, M; Squitti, R; Frisoni, G; Pievani, M; Balestrieri, M; Brambilla, P; Perlini, C; Marinelli, V; Bellani, M; Rambaldelli, G; Bertoldo, A; Atzori, M; Mazzi, F; Carpeggiani, P; Beltramello, A; Alessandrini, F; Pizzini, F; Zoccatelli, G; Sberna, M; Konze, A; Politi, Pierluigi; Emanuele, Enzo; Brondino, Natascia; Martino, G; Bergami, A; Zarbo, R; Riva, Ma; Fumagalli, F; Molteni, R; Calabrese, F; Guidotti, G; Luoni, A; Macchi, F; Artioli, S; Baldetti, M; Bizzocchi, M; Bolzon, D; Bonello, E; Cacciari, G; Carraresi, C; Cascio, Mt; Caselli, G; Furlato, K; Garlassi, S; Gavarini, A; Lunardi, S; Macchetti, F; Marteddu, V; Plebiscita, G; Poli, S; Totaro, S; Bebbington, P; Birchwood, M; Dazzan, P; Kuipers, E; Thornicroft, G; Pariante, C; Lawrie, S; Pariante, C; Soares, J",'Springer Science and Business Media LLC',A multi-element psychosocial intervention for early psychosis (GET UP PIANO TRIAL) conducted in a catchment area of 10 million inhabitants: study protocol for a pragmatic cluster randomized controlled trial,10.1186/1745-6215-13-73,https://core.ac.uk/download/226465289.pdf,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
275613444,2015-11-18T00:00:00,"12th International Conference on Cooperative Design, Visualization, and Engineering, CDVE 2015; Mallorca; Spain; 20 September 2015 through 23 September 2015The proper transport of hit sensitive products, such as fish and fruit,
is very important because their deterioration may cause the value lost and even
the product rejection by the buyer. For this reason, in this paper we present a
cooperative monitoring system for the delivery of fresh products. The system
consists of fixed wireless nodes and a mobile wireless node that is installed in
the packet. This mobile node is able to take data of the internal temperature,
external temperature and the 3 axis movement. With the information stored in
the network, a vendor can know the optimal conditions of the transport. Finally,
we test the maximum distance to the fixed nodes, as well as the data collected by
the sensor.Sendra, S.; Lloret, J.; Lacuesta, R.; Jimenez, JM. (2015). Cooperative Monitoring of the Delivery of Fresh Products. Lecture Notes in Computer Science. 9320:76-86. doi:10.1007/978-3-319-24132-6_10S76869320Derks, H.G., Buehler, W.S., Hall, M.B.: Real-time method and system for locating a mobile object or person in a tracking environment. US Patent 8514071 B2, 20 August 2013Witmond, R., Dutta, R., Charroppin, P.: Method for tracking a mail piece. US Patent 7003376 B2, 21 February 2006Lu, L., Liu, Y., Han, J.: ACTION: breaking the privacy barrier for RFID systems. Ad Hoc Sens. Wirel. Netw. 24(1–2), 135–159 (2015)Dhakal, S., Shin, S.: Precise time system efficiency of a frame slotted aloha based anti-collision algorithm in a RFID system. Netw. Protoc. Algorithms 5(2), 16–27 (2013)Garcia, M., Bri, D., Sendra, S., Lloret, J.: Practical deployments of wireless sensor networks: a survey. Int. J. Adv. Netw. Serv. 3(1&2), 163–178 (2010)Bri, D., Garcia, M., Lloret, J., Dini, P.: Real deployments of wireless sensor networks. In: Third International Conference on Sensor Technologies and Applications (SENSORCOMM 2009), Athens, Greece, 18–23 June 2009, pp. 415–423Karim, L., Anpalagan, A., Nasser, N., Almhana, J.: Sensor-based M2M agriculture monitoring systems for developing countries: state and challenges. Netw. Protoc. Algorithms 5(3), 68–86 (2013)Garcia, M., Lloret, J., Sendra, S., Rodrigues, J.J.: Taking cooperative decisions in group-based wireless sensor networks. In: Luo, Y. (ed.) CDVE 2011. LNCS, vol. 6874, pp. 61–65. Springer, Heidelberg (2011)Garcia-Sabater, J.P., Lloret, J., Marin-Garcia, J.A., Puig-Bernabeu, X.: Coordinating a cooperative automotive manufacturing network – an agent-based model. In: Luo, Y. (ed.) CDVE 2010. LNCS, vol. 6240, pp. 231–238. Springer, Heidelberg (2010)Li, J., Cao, J.: Survey of object tracking in wireless sensor networks. Netw. Protoc. Algorithms 25(1–2), 89–120 (2015)Vock, C.A., Larkin, A.F., Amsbury, B.W., Youngs, P.: Device for monitoring movement of shipped goods. U.S. Patent 8,280,682, 2 October 2012Jedermann, R., Schouten, R., Sklorz, A., Lang, W., Van Kooten, O.: Linking keeping quality models and sensor systems to an autonomous transport supervision system. In: The 2nd International Workshop Cold Chain Management, Bonn, Germany, 8–9 May 2006, pp. 3–18Ko, D., Kwak, Y., Song, S.: Real time traceability and monitoring system for agricultural products based on wireless sensor network. Int. J. Distrib. Sens. Netw. 2014, 1–7 (2014). Article ID 832510Ruiz-Garcia, L., Barreiro, P., Robla, J.I.: Performance of ZigBee-based wireless sensor nodes for real-time monitoring of fruit logistics. J. Food Eng. 87(3), 405–415 (2008)Shamsuzzoha, A., Addo-Tenkorang, R., Phuong, D., Helo, P.: Logistics tracking: an implementation issue for delivery network. In: PICMET 2011Conference Technology Management in the Energy Smart World, Portland, Oregon, USA, July 31–August 4 2011, pp. 1–10Torres, R.V., Sanchez, J.C., Galan, L.M.: Unmarked point and adjacency vertex, mobility models for the generation of emergency and rescue scenarios in urban areas. Ad Hoc Sens. Wirel. Netw. 23(3–4), 211–233 (2014)Waspmote features. In Digi Web Site. http://www.digi.com/products/wireless-wired-embedded-solutions/zigbee-rf-modules/point-multipoint-rfmodules/xbee-series1-module#specs . Accessed 18 April 2015Meghanathan, N., Mumford, P.: Centralized and distributed algorithms for stability-based data gathering in mobile sensor networks. Netw. Protoc. Algorithms 5(4), 84–116 (2013)Alrajeh, N.A., Khan, S., Lloret, J., Loo, J.: Artificial neural network based detection of energy exhaustion attacks in wireless sensor networks capable of energy harvesting. Ad Hoc Sens. Wirel. Netw. 22(3–4), 109–133 (2014)Garcia, M., Sendra, S., Lloret, J., Canovas, A.: Saving energy and improving communications using cooperative group-based wireless sensor networks. Telecommun. Syst. 52(4), 2489–2502 (2013",'Springer Science and Business Media LLC',Cooperative Monitoring of the Delivery of Fresh Products,10.1007/978-3-319-24132-6_10,http://hdl.handle.net/10251/64862,,core,multimedia,'multimedia' AND 'machine learning' AND ('real-world' AND 'deploy')
