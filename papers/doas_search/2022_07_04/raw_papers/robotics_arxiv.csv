id,updated,published,title,summary,database,query_name,query_value
http://arxiv.org/abs/2207.10170v1,2022-07-20T19:49:09Z,2022-07-20T19:49:09Z,Illusionary Attacks on Sequential Decision Makers and Countermeasures,"Autonomous intelligent agents deployed to the real-world need to be robust
against adversarial attacks on sensory inputs. Existing work in reinforcement
learning focuses on minimum-norm perturbation attacks, which were originally
introduced to mimic a notion of perceptual invariance in computer vision. In
this paper, we note that such minimum-norm perturbation attacks can be
trivially detected by victim agents, as these result in observation sequences
that are not consistent with the victim agent's actions. Furthermore, many
real-world agents, such as physical robots, commonly operate under human
supervisors, which are not susceptible to such perturbation attacks. As a
result, we propose to instead focus on illusionary attacks, a novel form of
attack that is consistent with the world model of the victim agent. We provide
a formal definition of this novel attack framework, explore its characteristics
under a variety of conditions, and conclude that agents must seek realism
feedback to be robust to illusionary attacks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.06572v1,2022-07-14T00:26:45Z,2022-07-14T00:26:45Z,"i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight
  Human-Robot Interaction Loops","Sim-to-real transfer is a powerful paradigm for robotic reinforcement
learning. The ability to train policies in simulation enables safe exploration
and large-scale data collection quickly at low cost. However, prior works in
sim-to-real transfer of robotic policies typically do not involve any
human-robot interaction because accurately simulating human behavior is an open
problem. In this work, our goal is to leverage the power of simulation to train
robotic policies that are proficient at interacting with humans upon
deployment. But there is a chicken and egg problem -- how do we gather examples
of a human interacting with a physical robot so as to model human behavior in
simulation without already having a robot that is able to interact with a
human? Our proposed method, Iterative-Sim-to-Real (i-S2R), attempts to address
this. i-S2R bootstraps from a simple model of human behavior and alternates
between training in simulation and deploying in the real world. In each
iteration, both the human behavior model and the policy are refined. We
evaluate our method on a real world robotic table tennis setting, where the
objective for the robot is to play cooperatively with a human player for as
long as possible. Table tennis is a high-speed, dynamic task that requires the
two players to react quickly to each other's moves, making a challenging test
bed for research on human-robot interaction. We present results on an
industrial robotic arm that is able to cooperatively play table tennis with
human players, achieving rallies of 22 successive hits on average and 150 at
best. Further, for 80% of players, rally lengths are 70% to 175% longer
compared to the sim-to-real (S2R) baseline. For videos of our system in action,
please see https://sites.google.com/view/is2r.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.04703v2,2022-07-17T18:53:03Z,2022-07-11T08:31:22Z,"Don't Start From Scratch: Leveraging Prior Data to Automate Robotic
  Reinforcement Learning","Reinforcement learning (RL) algorithms hold the promise of enabling
autonomous skill acquisition for robotic systems. However, in practice,
real-world robotic RL typically requires time consuming data collection and
frequent human intervention to reset the environment. Moreover, robotic
policies learned with RL often fail when deployed beyond the carefully
controlled setting in which they were learned. In this work, we study how these
challenges can all be tackled by effective utilization of diverse offline
datasets collected from previously seen tasks. When faced with a new task, our
system adapts previously learned skills to quickly learn to both perform the
new task and return the environment to an initial state, effectively performing
its own environment reset. Our empirical results demonstrate that incorporating
prior data into robotic reinforcement learning enables autonomous learning,
substantially improves sample-efficiency of learning, and enables better
generalization. Project website: https://sites.google.com/view/ariel-berkeley/",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.03124v1,2022-07-07T07:04:55Z,2022-07-07T07:04:55Z,"Retro-RL: Reinforcing Nominal Controller With Deep Reinforcement
  Learning for Tilting-Rotor Drones","Studies that broaden drone applications into complex tasks require a stable
control framework. Recently, deep reinforcement learning (RL) algorithms have
been exploited in many studies for robot control to accomplish complex tasks.
Unfortunately, deep RL algorithms might not be suitable for being deployed
directly into a real-world robot platform due to the difficulty in interpreting
the learned policy and lack of stability guarantee, especially for a complex
task such as a wall-climbing drone. This paper proposes a novel hybrid
architecture that reinforces a nominal controller with a robust policy learned
using a model-free deep RL algorithm. The proposed architecture employs an
uncertainty-aware control mixer to preserve guaranteed stability of a nominal
controller while using the extended robust performance of the learned policy.
The policy is trained in a simulated environment with thousands of domain
randomizations to achieve robust performance over diverse uncertainties. The
performance of the proposed method was verified through real-world experiments
and then compared with a conventional controller and the state-of-the-art
learning-based controller trained with a vanilla deep RL algorithm.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.02890v1,2022-07-06T18:07:36Z,2022-07-06T18:07:36Z,Humans Social Relationship Classification during Accompaniment,"This paper presents the design of deep learning architectures which allow to
classify the social relationship existing between two people who are walking in
a side-by-side formation into four possible categories --colleagues, couple,
family or friendship. The models are developed using Neural Networks or
Recurrent Neural Networks to achieve the classification and are trained and
evaluated using a database of readings obtained from humans performing an
accompaniment process in an urban environment. The best achieved model
accomplishes a relatively good accuracy in the classification problem and its
results enhance partially the outcomes from a previous study [1]. Furthermore,
the model proposed shows its future potential to improve its efficiency and to
be implemented in a real robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2207.00254v1,2022-07-01T07:56:48Z,2022-07-01T07:56:48Z,"A Survey on Active Simultaneous Localization and Mapping: State of the
  Art and New Frontiers","Active Simultaneous Localization and Mapping (SLAM) is the problem of
planning and controlling the motion of a robot to build the most accurate and
complete model of the surrounding environment. Since the first foundational
work in active perception appeared, more than three decades ago, this field has
received increasing attention across different scientific communities. This has
brought about many different approaches and formulations, and makes a review of
the current trends necessary and extremely valuable for both new and
experienced researchers. In this work, we survey the state-of-the-art in active
SLAM and take an in-depth look at the open challenges that still require
attention to meet the needs of modern applications. % in order to achieve
real-world deployment. After providing a historical perspective, we present a
unified problem formulation and review the classical solution scheme, which
decouples the problem into three stages that identify, select, and execute
potential navigation actions. We then analyze alternative approaches, including
belief-space planning and modern techniques based on deep reinforcement
learning, and review related work on multi-robot coordination. The manuscript
concludes with a discussion of new research directions, addressing reproducible
research, active spatial perception, and practical applications, among other
topics.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.14176v1,2022-06-28T17:44:48Z,2022-06-28T17:44:48Z,DayDreamer: World Models for Physical Robot Learning,"To solve tasks in complex environments, robots need to learn from experience.
Deep reinforcement learning is a common approach to robot learning but requires
a large amount of trial and error to learn, limiting its deployment in the
physical world. As a consequence, many advances in robot learning rely on
simulators. On the other hand, learning inside of simulators fails to capture
the complexity of the real world, is prone to simulator inaccuracies, and the
resulting behaviors do not adapt to changes in the world. The Dreamer algorithm
has recently shown great promise for learning from small amounts of interaction
by planning within a learned world model, outperforming pure reinforcement
learning in video games. Learning a world model to predict the outcomes of
potential actions enables planning in imagination, reducing the amount of trial
and error needed in the real environment. However, it is unknown whether
Dreamer can facilitate faster learning on physical robots. In this paper, we
apply Dreamer to 4 robots to learn online and directly in the real world,
without simulators. Dreamer trains a quadruped robot to roll off its back,
stand up, and walk from scratch and without resets in only 1 hour. We then push
the robot and find that Dreamer adapts within 10 minutes to withstand
perturbations or quickly roll over and stand back up. On two different robotic
arms, Dreamer learns to pick and place multiple objects directly from camera
images and sparse rewards, approaching human performance. On a wheeled robot,
Dreamer learns to navigate to a goal position purely from camera images,
automatically resolving ambiguity about the robot orientation. Using the same
hyperparameters across all experiments, we find that Dreamer is capable of
online learning in the real world, establishing a strong baseline. We release
our infrastructure for future applications of world models to robot learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.11887v1,2022-06-23T17:53:33Z,2022-06-23T17:53:33Z,"VRKitchen2.0-IndoorKit: A Tutorial for Augmented Indoor Scene Building
  in Omniverse","With the recent progress of simulations by 3D modeling software and game
engines, many researchers have focused on Embodied AI tasks in the virtual
environment. However, the research community lacks a platform that can easily
serve both indoor scene synthesis and model benchmarking with various
algorithms. Meanwhile, computer graphics-related tasks need a toolkit for
implementing advanced synthesizing techniques. To facilitate the study of
indoor scene building methods and their potential robotics applications, we
introduce INDOORKIT: a built-in toolkit for NVIDIA OMNIVERSE that provides
flexible pipelines for indoor scene building, scene randomizing, and animation
controls. Besides, combining Python coding in the animation software INDOORKIT
assists researchers in creating real-time training and controlling avatars and
robotics. The source code for this toolkit is available at
https://github.com/realvcla/VRKitchen2.0-Tutorial, and the tutorial along with
the toolkit is available at https://vrkitchen20-tutorial.readthedocs.io/en/",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.11804v4,2022-07-07T05:57:55Z,2022-06-23T16:22:56Z,"Rethinking Surgical Instrument Segmentation: A Background Image Can Be
  All You Need","Data diversity and volume are crucial to the success of training deep
learning models, while in the medical imaging field, the difficulty and cost of
data collection and annotation are especially huge. Specifically in robotic
surgery, data scarcity and imbalance have heavily affected the model accuracy
and limited the design and deployment of deep learning-based surgical
applications such as surgical instrument segmentation. Considering this, we
rethink the surgical instrument segmentation task and propose a one-to-many
data generation solution that gets rid of the complicated and expensive process
of data collection and annotation from robotic surgery. In our method, we only
utilize a single surgical background tissue image and a few open-source
instrument images as the seed images and apply multiple augmentations and
blending techniques to synthesize amounts of image variations. In addition, we
also introduce the chained augmentation mixing during training to further
enhance the data diversities. The proposed approach is evaluated on the real
datasets of the EndoVis-2018 and EndoVis-2017 surgical scene segmentation. Our
empirical analysis suggests that without the high cost of data collection and
annotation, we can achieve decent surgical instrument segmentation performance.
Moreover, we also observe that our method can deal with novel instrument
prediction in the deployment domain. We hope our inspiring results will
encourage researchers to emphasize data-centric methods to overcome demanding
deep learning limitations besides data shortage, such as class imbalance,
domain adaptation, and incremental learning. Our code is available at
https://github.com/lofrienger/Single_SurgicalScene_For_Segmentation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.11623v1,2022-06-23T11:21:04Z,2022-06-23T11:21:04Z,"Waypoint Generation in Row-based Crops with Deep Learning and
  Contrastive Clustering","The development of precision agriculture has gradually introduced automation
in the agricultural process to support and rationalize all the activities
related to field management. In particular, service robotics plays a
predominant role in this evolution by deploying autonomous agents able to
navigate in fields while executing different tasks without the need for human
intervention, such as monitoring, spraying and harvesting. In this context,
global path planning is the first necessary step for every robotic mission and
ensures that the navigation is performed efficiently and with complete field
coverage. In this paper, we propose a learning-based approach to tackle
waypoint generation for planning a navigation path for row-based crops,
starting from a top-view map of the region-of-interest. We present a novel
methodology for waypoint clustering based on a contrastive loss, able to
project the points to a separable latent space. The proposed deep neural
network can simultaneously predict the waypoint position and cluster assignment
with two specialized heads in a single forward pass. The extensive
experimentation on simulated and real-world images demonstrates that the
proposed approach effectively solves the waypoint generation problem for both
straight and curved row-based crops, overcoming the limitations of previous
state-of-the-art methodologies.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.09670v1,2022-06-20T09:22:20Z,2022-06-20T09:22:20Z,Benchmarking Constraint Inference in Inverse Reinforcement Learning,"When deploying Reinforcement Learning (RL) agents into a physical system, we
must ensure that these agents are well aware of the underlying constraints. In
many real-world problems, however, the constraints followed by expert agents
(e.g., humans) are often hard to specify mathematically and unknown to the RL
agents. To tackle these issues, Constraint Inverse Reinforcement Learning
(CIRL) considers the formalism of Constrained Markov Decision Processes (CMDPs)
and estimates constraints from expert demonstrations by learning a constraint
function. As an emerging research topic, CIRL does not have common benchmarks,
and previous works tested their algorithms with hand-crafted environments
(e.g., grid worlds). In this paper, we construct a CIRL benchmark in the
context of two major application domains: robot control and autonomous driving.
We design relevant constraints for each environment and empirically study the
ability of different algorithms to recover those constraints based on expert
trajectories that respect those constraints. To handle stochastic dynamics, we
propose a variational approach that infers constraint distributions, and we
demonstrate its performance by comparing it with other CIRL baselines on our
benchmark. The benchmark, including the information for reproducing the
performance of CIRL algorithms, is publicly available at
https://github.com/Guiliang/CIRL-benchmarks-public",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.09590v1,2022-06-20T06:36:45Z,2022-06-20T06:36:45Z,"From Multi-agent to Multi-robot: A Scalable Training and Evaluation
  Platform for Multi-robot Reinforcement Learning","Multi-agent reinforcement learning (MARL) has been gaining extensive
attention from academia and industries in the past few decades. One of the
fundamental problems in MARL is how to evaluate different approaches
comprehensively. Most existing MARL methods are evaluated in either video games
or simplistic simulated scenarios. It remains unknown how these methods perform
in real-world scenarios, especially multi-robot systems. This paper introduces
a scalable emulation platform for multi-robot reinforcement learning (MRRL)
called SMART to meet this need. Precisely, SMART consists of two components: 1)
a simulation environment that provides a variety of complex interaction
scenarios for training and 2) a real-world multi-robot system for realistic
performance evaluation. Besides, SMART offers agent-environment APIs that are
plug-and-play for algorithm implementation. To illustrate the practicality of
our platform, we conduct a case study on the cooperative driving lane change
scenario. Building off the case study, we summarize several unique challenges
of MRRL, which are rarely considered previously. Finally, we open-source the
simulation environments, associated benchmark tasks, and state-of-the-art
baselines to encourage and empower MRRL research.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.07635v1,2022-06-15T16:25:57Z,2022-06-15T16:25:57Z,AI Ethics Issues in Real World: Evidence from AI Incident Database,"With the powerful performance of Artificial Intelligence (AI) also comes
prevalent ethical issues. Though governments and corporations have curated
multiple AI ethics guidelines to curb unethical behavior of AI, the effect has
been limited, probably due to the vagueness of the guidelines. In this paper,
we take a closer look at how AI ethics issues take place in real world, in
order to have a more in-depth and nuanced understanding of different ethical
issues as well as their social impact. With a content analysis of AI Incident
Database, which is an effort to prevent repeated real world AI failures by
cataloging incidents, we identified 13 application areas which often see
unethical use of AI, with intelligent service robots, language/vision models
and autonomous driving taking the lead. Ethical issues appear in 8 different
forms, from inappropriate use and racial discrimination, to physical safety and
unfair algorithm. With this taxonomy of AI ethics issues, we aim to provide AI
practitioners with a practical guideline when trying to deploy AI applications
ethically.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.06957v2,2022-07-21T09:58:12Z,2022-06-14T16:22:54Z,"Continual-Learning-as-a-Service (CLaaS): On-Demand Efficient Adaptation
  of Predictive Models","Predictive machine learning models nowadays are often updated in a stateless
and expensive way. The two main future trends for companies that want to build
machine learning-based applications and systems are real-time inference and
continual updating. Unfortunately, both trends require a mature infrastructure
that is hard and costly to realize on-premise. This paper defines a novel
software service and model delivery infrastructure termed Continual
Learning-as-a-Service (CLaaS) to address these issues. Specifically, it
embraces continual machine learning and continuous integration techniques. It
provides support for model updating and validation tools for data scientists
without an on-premise solution and in an efficient, stateful and easy-to-use
manner. Finally, this CL model service is easy to encapsulate in any machine
learning infrastructure or cloud system. This paper presents the design and
implementation of a CLaaS instantiation, called LiquidBrain, evaluated in two
real-world scenarios. The former is a robotic object recognition setting using
the CORe50 dataset while the latter is a named category and attribute
prediction using the DeepFashion-C dataset in the fashion domain. Our
preliminary results suggest the usability and efficiency of the Continual
Learning model services and the effectiveness of the solution in addressing
real-world use-cases regardless of where the computation happens in the
continuum Edge-Cloud.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.05096v1,2022-06-10T13:43:03Z,2022-06-10T13:43:03Z,Skill Transfer for Temporally-Extended Task Specifications,"Deploying robots in real-world domains, such as households and flexible
manufacturing lines, requires the robots to be taskable on demand. Linear
temporal logic (LTL) is a widely-used specification language with a
compositional grammar that naturally induces commonalities across tasks.
However, the majority of prior research on reinforcement learning with LTL
specifications treats every new formula independently. We propose LTL-Transfer,
a novel algorithm that enables subpolicy reuse across tasks by segmenting
policies for training tasks into portable transition-centric skills capable of
satisfying a wide array of unseen LTL specifications while respecting
safety-critical constraints. Our experiments in a Minecraft-inspired domain
demonstrate the capability of LTL-Transfer to satisfy over 90% of 500 unseen
tasks while training on only 50 task specifications and never violating a
safety constraint. We also deployed LTL-Transfer on a quadruped mobile
manipulator in a household environment to show its ability to transfer to many
fetch and delivery tasks in a zero-shot fashion.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.03083v1,2022-06-07T07:57:34Z,2022-06-07T07:57:34Z,"Pushing the Limits of Learning-based Traversability Analysis for
  Autonomous Driving on CPU","Self-driving vehicles and autonomous ground robots require a reliable and
accurate method to analyze the traversability of the surrounding environment
for safe navigation. This paper proposes and evaluates a real-time machine
learning-based Traversability Analysis method that combines geometric features
with appearance-based features in a hybrid approach based on a SVM classifier.
In particular, we show that integrating a new set of geometric and visual
features and focusing on important implementation details enables a noticeable
boost in performance and reliability. The proposed approach has been compared
with state-of-the-art Deep Learning approaches on a public dataset of outdoor
driving scenarios. It reaches an accuracy of 89.2% in scenarios of varying
complexity, demonstrating its effectiveness and robustness. The method runs
fully on CPU and reaches comparable results with respect to the other methods,
operates faster, and requires fewer hardware resources.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.02735v1,2022-06-06T16:44:38Z,2022-06-06T16:44:38Z,People Tracking in Panoramic Video for Guiding Robots,"A guiding robot aims to effectively bring people to and from specific places
within environments that are possibly unknown to them. During this operation
the robot should be able to detect and track the accompanied person, trying
never to lose sight of her/him. A solution to minimize this event is to use an
omnidirectional camera: its 360{\deg} Field of View (FoV) guarantees that any
framed object cannot leave the FoV if not occluded or very far from the sensor.
However, the acquired panoramic videos introduce new challenges in perception
tasks such as people detection and tracking, including the large size of the
images to be processed, the distortion effects introduced by the cylindrical
projection and the periodic nature of panoramic images. In this paper, we
propose a set of targeted methods that allow to effectively adapt to panoramic
videos a standard people detection and tracking pipeline originally designed
for perspective cameras. Our methods have been implemented and tested inside a
deep learning-based people detection and tracking framework with a commercial
360{\deg} camera. Experiments performed on datasets specifically acquired for
guiding robot applications and on a real service robot show the effectiveness
of the proposed approach over other state-of-the-art systems. We release with
this paper the acquired and annotated datasets and the open-source
implementation of our method.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.02095v1,2022-06-05T04:49:58Z,2022-06-05T04:49:58Z,ARC -- Actor Residual Critic for Adversarial Imitation Learning,"Adversarial Imitation Learning (AIL) is a class of popular state-of-the-art
Imitation Learning algorithms where an artificial adversary's misclassification
is used as a reward signal and is optimized by any standard Reinforcement
Learning (RL) algorithm. Unlike most RL settings, the reward in AIL is
differentiable but model-free RL algorithms do not make use of this property to
train a policy. In contrast, we leverage the differentiability property of the
AIL reward function and formulate a class of Actor Residual Critic (ARC) RL
algorithms that draw a parallel to the standard Actor-Critic (AC) algorithms in
RL literature and uses a residual critic, C function (instead of the standard Q
function) to approximate only the discounted future return (excluding the
immediate reward). ARC algorithms have similar convergence properties as the
standard AC algorithms with the additional advantage that the gradient through
the immediate reward is exact. For the discrete (tabular) case with finite
states, actions, and known dynamics, we prove that policy iteration with $C$
function converges to an optimal policy. In the continuous case with function
approximation and unknown dynamics, we experimentally show that ARC aided AIL
outperforms standard AIL in simulated continuous-control and real robotic
manipulation tasks. ARC algorithms are simple to implement and can be
incorporated into any existing AIL implementation with an AC algorithm.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2206.01364v1,2022-06-03T02:04:15Z,2022-06-03T02:04:15Z,"Robotic Planning under Uncertainty in Spatiotemporal Environments in
  Expeditionary Science","In the expeditionary sciences, spatiotemporally varying environments --
hydrothermal plumes, algal blooms, lava flows, or animal migrations -- are
ubiquitous. Mobile robots are uniquely well-suited to study these dynamic,
mesoscale natural environments. We formalize expeditionary science as a
sequential decision-making problem, modeled using the language of
partially-observable Markov decision processes (POMDPs). Solving the
expeditionary science POMDP under real-world constraints requires efficient
probabilistic modeling and decision-making in problems with complex dynamics
and observational models. Previous work in informative path planning, adaptive
sampling, and experimental design have shown compelling results, largely in
static environments, using data-driven models and information-based rewards.
However, these methodologies do not trivially extend to expeditionary science
in spatiotemporal environments: they generally do not make use of scientific
knowledge such as equations of state dynamics, they focus on information
gathering as opposed to scientific task execution, and they make use of
decision-making approaches that scale poorly to large, continuous problems with
long planning horizons and real-time operational constraints. In this work, we
discuss these and other challenges related to probabilistic modeling and
decision-making in expeditionary science, and present some of our preliminary
work that addresses these gaps. We ground our results in a real expeditionary
science deployment of an autonomous underwater vehicle (AUV) in the deep ocean
for hydrothermal vent discovery and characterization. Our concluding thoughts
highlight remaining work to be done, and the challenges that merit
consideration by the reinforcement learning and decision-making community.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.15496v1,2022-05-31T01:25:24Z,2022-05-31T01:25:24Z,"Towards Lifelong Federated Learning in Autonomous Mobile Robots with
  Continuous Sim-to-Real Transfer","The role of deep learning (DL) in robotics has significantly deepened over
the last decade. Intelligent robotic systems today are highly connected systems
that rely on DL for a variety of perception, control, and other tasks. At the
same time, autonomous robots are being increasingly deployed as part of fleets,
with collaboration among robots becoming a more relevant factor. From the
perspective of collaborative learning, federated learning (FL) enables
continuous training of models in a distributed, privacy-preserving way. This
paper focuses on vision-based obstacle avoidance for mobile robot navigation.
On this basis, we explore the potential of FL for distributed systems of mobile
robots enabling continuous learning via the engagement of robots in both
simulated and real-world scenarios. We extend previous works by studying the
performance of different image classifiers for FL, compared to centralized,
cloud-based learning with a priori aggregated data. We also introduce an
approach to continuous learning from mobile robots with extended sensor suites
able to provide automatically labeled data while they are completing other
tasks. We show that higher accuracies can be achieved by training the models in
both simulation and reality, enabling continuous updates to deployed models.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.15864v1,2022-05-30T14:30:45Z,2022-05-30T14:30:45Z,"Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern
  Recognition on Neuromorphic Hardware","Spatio-temporal pattern recognition is a fundamental ability of the brain
which is required for numerous real-world applications. Recent deep learning
approaches have reached outstanding accuracy in such tasks, but their
implementation on conventional embedded solutions is still very computationally
and energy expensive. Tactile sensing in robotic applications is a
representative example where real-time processing and energy-efficiency are
required. Following a brain-inspired computing approach, we propose a new
benchmark for spatio-temporal tactile pattern recognition at the edge through
braille letters reading. We recorded a new braille letters dataset based on the
capacitive tactile sensors/fingertip of the iCub robot, then we investigated
the importance of temporal information and the impact of event-based encoding
for spike-based/event-based computation. Afterwards, we trained and compared
feed-forward and recurrent spiking neural networks (SNNs) offline using
back-propagation through time with surrogate gradients, then we deployed them
on the Intel Loihi neuromorphic chip for fast and efficient inference. We
confronted our approach to standard classifiers, in particular to a Long
Short-Term Memory (LSTM) deployed on the embedded Nvidia Jetson GPU in terms of
classification accuracy, power/energy consumption and computational delay. Our
results show that the LSTM outperforms the recurrent SNN in terms of accuracy
by 14%. However, the recurrent SNN on Loihi is 237 times more energy-efficient
than the LSTM on Jetson, requiring an average power of only 31mW. This work
proposes a new benchmark for tactile sensing and highlights the challenges and
opportunities of event-based encoding, neuromorphic hardware and spike-based
computing for spatio-temporal pattern recognition at the edge.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.10330v3,2022-06-04T17:03:49Z,2022-05-20T17:42:38Z,"A Review of Safe Reinforcement Learning: Methods, Theory and
  Applications","Reinforcement learning (RL) has achieved tremendous success in many complex
decision making tasks. When it comes to deploying RL in the real world, safety
concerns are usually raised, leading to a growing demand for safe RL
algorithms, such as in autonomous driving and robotics scenarios. While safety
control has a long history, the study of safe RL algorithms is still in the
early stages. To establish a good foundation for future research in this
thread, in this paper, we provide a review for safe RL from the perspectives of
methods, theory and applications. Firstly, we review the progress of safe RL
from five dimensions and come up with five problems that are crucial for safe
RL being deployed in real-world applications, coined as ""2H3W"". Secondly, we
analyze the theory and algorithm progress from the perspectives of answering
the ""2H3W"" problems. Then, the sample complexity of safe RL methods is reviewed
and discussed, followed by an introduction of the applications and benchmarks
of safe RL algorithms. Finally, we open the discussion of the challenging
problems in safe RL, hoping to inspire more future research on this thread.
  To advance the study of safe RL algorithms, we release a benchmark suite, an
open-sourced repository containing the implementations of major safe RL
algorithms, along with tutorials at the link:
https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines.git.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.10044v1,2022-05-20T09:35:26Z,2022-05-20T09:35:26Z,Towards biologically plausible Dreaming and Planning,"Humans and animals can learn new skills after practicing for a few hours,
while current reinforcement learning algorithms require a large amount of data
to achieve good performances. Recent model-based approaches show promising
results by reducing the number of necessary interactions with the environment
to learn a desirable policy. However, these methods require biological
implausible ingredients, such as the detailed storage of older experiences, and
long periods of offline learning. The optimal way to learn and exploit
word-models is still an open question. Taking inspiration from biology, we
suggest that dreaming might be an efficient expedient to use an inner model. We
propose a two-module (agent and model) neural network in which ""dreaming""
(living new experiences in a model-based simulated environment) significantly
boosts learning. We also explore ""planning"", an online alternative to dreaming,
that shows comparable performances. Importantly, our model does not require the
detailed storage of experiences, and learns online the world-model. This is a
key ingredient for biological plausibility and implementability (e.g., in
neuromorphic hardware). Our network is composed of spiking neurons, further
increasing the energetic efficiency and the plausibility of the model. To our
knowledge, there are no previous works proposing biologically plausible
model-based reinforcement learning in recurrent spiking networks. Our work is a
step toward building efficient neuromorphic systems for autonomous robots,
capable of learning new skills in real-world environments. Even when the
environment is no longer accessible, the robot optimizes learning by
""reasoning"" in its own ""mind"". These approaches are of great relevance when the
acquisition from the environment is slow, expensive (robotics) or unsafe
(autonomous driving).",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.09084v1,2022-05-18T17:19:34Z,2022-05-18T17:19:34Z,"Industry 5.0 is Coming: A Survey on Intelligent NextG Wireless Networks
  as Technological Enablers","Industry 5.0 vision, a step toward the next industrial revolution and
enhancement to Industry 4.0, envisioned the new goals of resilient,
sustainable, and human-centric approaches in diverse emerging applications,
e.g., factories-of-the-future, digital society. The vision seeks to leverage
human intelligence and creativity in nexus with intelligent, efficient, and
reliable cognitive collaborating robots (cobots) to achieve zero waste,
zerodefect, and mass customization-based manufacturing solutions. However, the
vision requires the merging of cyber-physical worlds through utilizing Industry
5.0 technological enablers, e.g., cognitive cobots, person-centric artificial
intelligence (AI), cyberphysical systems, digital twins, hyperconverged data
storage and computing, communication infrastructure, and others. In this
regard, the convergence of the emerging computational intelligence (CI)
paradigm and next-generation wireless networks (NGWNs) can fulfill the
stringent communication and computation requirements of the technological
enablers in the Industry 5.0 vision, which is the aim of this survey-based
tutorial. In this article, we address this issue by reviewing and analyzing
current emerging concepts and technologies, e.g., CI tools and frameworks,
network-in-box architecture, open radio access networks, softwarized service
architectures, potential enabling services, and others, essential for designing
the objectives of CINGWNs to fulfill the Industry 5.0 vision requirements.
Finally, we provide a list of lessons learned from our detailed review,
research challenges, and open issues that should be addressed in CI-NGWNs to
realize Industry 5.0.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.05960v1,2022-05-12T08:58:30Z,2022-05-12T08:58:30Z,"Robot Cooking with Stir-fry: Bimanual Non-prehensile Manipulation of
  Semi-fluid Objects","This letter describes an approach to achieve well-known Chinese cooking art
stir-fry on a bimanual robot system. Stir-fry requires a sequence of highly
dynamic coordinated movements, which is usually difficult to learn for a chef,
let alone transfer to robots. In this letter, we define a canonical stir-fry
movement, and then propose a decoupled framework for learning this deformable
object manipulation from human demonstration. First, the dual arms of the robot
are decoupled into different roles (a leader and follower) and learned with
classical and neural network-based methods separately, then the bimanual task
is transformed into a coordination problem. To obtain general bimanual
coordination, we secondly propose a Graph and Transformer based model --
Structured-Transformer, to capture the spatio-temporal relationship between
dual-arm movements. Finally, by adding visual feedback of content deformation,
our framework can adjust the movements automatically to achieve the desired
stir-fry effect. We verify the framework by a simulator and deploy it on a real
bimanual Panda robot system. The experimental results validate our framework
can realize the bimanual robot stir-fry motion and have the potential to extend
to other deformable objects with bimanual coordination.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.05063v1,2022-05-10T17:42:31Z,2022-05-10T17:42:31Z,"Pipeline for Antarctic Survey Telescope 3-3 in Yaoan, Yunnan","AST3-3 is the third robotic facility of the Antarctic Survey Telescopes
(AST3) for transient surveys to be deployed at Dome A, Antarctica. Due to the
current pandemic, the telescope has been currently deployed at the Yaoan
Observation Station in China, starting the commissioning observation and a
transient survey. This paper presents a fully automatic data processing system
for AST3-3 observations. The transient detection pipeline uses state-of-the-art
image subtraction techniques optimised for GPU devices. Image reduction and
transient photometry are accelerated by concurrent task methods. Our
Python-based system allows for transient detection from wide-field data in a
real-time and accurate way. A ResNet-based rotational-invariant neural network
was employed to classify the transient candidates. As a result, the system
enables auto-generation of transients and their light curves.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.05061v2,2022-05-24T10:50:35Z,2022-05-10T17:37:19Z,"On the Verge of Solving Rocket League using Deep Reinforcement Learning
  and Sim-to-sim Transfer","Autonomously trained agents that are supposed to play video games reasonably
well rely either on fast simulation speeds or heavy parallelization across
thousands of machines running concurrently. This work explores a third way that
is established in robotics, namely sim-to-real transfer, or if the game is
considered a simulation itself, sim-to-sim transfer. In the case of Rocket
League, we demonstrate that single behaviors of goalies and strikers can be
successfully learned using Deep Reinforcement Learning in the simulation
environment and transferred back to the original game. Although the implemented
training simulation is to some extent inaccurate, the goalkeeping agent saves
nearly 100% of its faced shots once transferred, while the striking agent
scores in about 75% of cases. Therefore, the trained agent is robust enough and
able to generalize to the target domain of Rocket League.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.04382v2,2022-07-11T11:38:59Z,2022-05-09T15:35:33Z,"FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated
  Objects","We explore a novel method to perceive and manipulate 3D articulated objects
that generalizes to enable a robot to articulate unseen classes of objects. We
propose a vision-based system that learns to predict the potential motions of
the parts of a variety of articulated objects to guide downstream motion
planning of the system to articulate the objects. To predict the object
motions, we train a neural network to output a dense vector field representing
the point-wise motion direction of the points in the point cloud under
articulation. We then deploy an analytical motion planner based on this vector
field to achieve a policy that yields maximum articulation. We train the vision
system entirely in simulation, and we demonstrate the capability of our system
to generalize to unseen object instances and novel categories in both
simulation and the real world, deploying our policy on a Sawyer robot with no
finetuning. Results show that our system achieves state-of-the-art performance
in both simulated and real-world experiments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.04189v1,2022-05-09T11:08:45Z,2022-05-09T11:08:45Z,"FoReCo: a forecast-based recovery mechanism for real-time remote control
  of robotic manipulators","Wireless communications represent a game changer for future manufacturing
plants, enabling flexible production chains as machinery and other components
are not restricted to a location by the rigid wired connections on the factory
floor. However, the presence of electromagnetic interference in the wireless
spectrum may result in packet loss and delay, making it a challenging
environment to meet the extreme reliability requirements of industrial
applications. In such conditions, achieving real-time remote control, either
from the Edge or Cloud, becomes complex. In this paper, we investigate a
forecast-based recovery mechanism for real-time remote control of robotic
manipulators (FoReCo) that uses Machine Learning (ML) to infer lost commands
caused by interference in the wireless channel. FoReCo is evaluated through
both simulation and experimentation in interference prone IEEE 802.11 wireless
links, and using a commercial research robot that performs pick-and-place
tasks. Results show that in case of interference, FoReCo trajectory error is
decreased by x18 and x2 times in simulation and experimentation, and that
FoReCo is sufficiently lightweight to be deployed in the hardware of already
used in existing solutions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.02421v1,2022-05-05T03:46:19Z,2022-05-05T03:46:19Z,"Towards Real-time Traffic Sign and Traffic Light Detection on Embedded
  Systems","Recent work done on traffic sign and traffic light detection focus on
improving detection accuracy in complex scenarios, yet many fail to deliver
real-time performance, specifically with limited computational resources. In
this work, we propose a simple deep learning based end-to-end detection
framework, which effectively tackles challenges inherent to traffic sign and
traffic light detection such as small size, large number of classes and complex
road scenarios. We optimize the detection models using TensorRT and integrate
with Robot Operating System to deploy on an Nvidia Jetson AGX Xavier as our
embedded device. The overall system achieves a high inference speed of 63
frames per second, demonstrating the capability of our system to perform in
real-time. Furthermore, we introduce CeyRo, which is the first ever large-scale
traffic sign and traffic light detection dataset for the Sri Lankan context.
Our dataset consists of 7984 total images with 10176 traffic sign and traffic
light instances covering 70 traffic sign and 5 traffic light classes. The
images have a high resolution of 1920 x 1080 and capture a wide range of
challenging road scenarios with different weather and lighting conditions. Our
work is publicly available at https://github.com/oshadajay/CeyRo.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.11475v1,2022-04-25T07:18:15Z,2022-04-25T07:18:15Z,"Adaptive actuation of magnetic soft robots using deep reinforcement
  learning","Magnetic soft robots have attracted growing interest due to their unique
advantages in terms of untethered actuation and excellent controllability.
However, finding the required magnetization patterns or magnetic fields to
achieve the desired functions of these robots is quite challenging in many
cases. No unified framework for design has been proposed yet, and existing
methods mainly rely on manual heuristics, which are hard to satisfy the high
complexity level of the desired robotic motion. Here, we develop an intelligent
method to solve the related inverse-design problems, implemented by introducing
a novel simulation platform for magnetic soft robots based on Cosserat rod
models and a deep reinforcement learning framework based on TD3. We demonstrate
that magnetic soft robots with different magnetization patterns can learn to
move without human guidance in simulations, and effective magnetic fields can
be autonomously generated that can then be applied directly to real magnetic
soft robots in an open-loop way.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2205.00831v1,2022-04-24T04:40:44Z,2022-04-24T04:40:44Z,Adaptive Task Planning for Large-Scale Robotized Warehouses,"Robotized warehouses are deployed to automatically distribute millions of
items brought by the massive logistic orders from e-commerce. A key to
automated item distribution is to plan paths for robots, also known as task
planning, where each task is to deliver racks with items to pickers for
processing and then return the rack back. Prior solutions are unfit for
large-scale robotized warehouses due to the inflexibility to time-varying item
arrivals and the low efficiency for high throughput. In this paper, we propose
a new task planning problem called TPRW, which aims to minimize the end-to-end
makespan that incorporates the entire item distribution pipeline, known as a
fulfilment cycle. Direct extensions from state-of-the-art path finding methods
are ineffective to solve the TPRW problem because they fail to adapt to the
bottleneck variations of fulfillment cycles. In response, we propose Efficient
Adaptive Task Planning, a framework for large-scale robotized warehouses with
time-varying item arrivals. It adaptively selects racks to fulfill at each
timestamp via reinforcement learning, accounting for the time-varying
bottleneck of the fulfillment cycles. Then it finds paths for robots to
transport the selected racks. The framework adopts a series of efficient
optimizations on both time and memory to handle large-scale item throughput.
Evaluations on both synthesized and real data show an improvement of $37.1\%$
in effectiveness and $75.5\%$ in efficiency over the state-of-the-arts.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.10183v1,2022-04-20T13:30:04Z,2022-04-20T13:30:04Z,"Multi-Component Optimization and Efficient Deployment of Neural-Networks
  on Resource-Constrained IoT Hardware","The majority of IoT devices like smartwatches, smart plugs, HVAC controllers,
etc., are powered by hardware with a constrained specification (low memory,
clock speed and processor) which is insufficient to accommodate and execute
large, high-quality models. On such resource-constrained devices, manufacturers
still manage to provide attractive functionalities (to boost sales) by
following the traditional approach of programming IoT devices/products to
collect and transmit data (image, audio, sensor readings, etc.) to their
cloud-based ML analytics platforms. For decades, this online approach has been
facing issues such as compromised data streams, non-real-time analytics due to
latency, bandwidth constraints, costly subscriptions, recent privacy issues
raised by users and the GDPR guidelines, etc. In this paper, to enable
ultra-fast and accurate AI-based offline analytics on resource-constrained IoT
devices, we present an end-to-end multi-component model optimization sequence
and open-source its implementation. Researchers and developers can use our
optimization sequence to optimize high memory, computation demanding models in
multiple aspects in order to produce small size, low latency, low-power
consuming models that can comfortably fit and execute on resource-constrained
hardware. The experimental results show that our optimization components can
produce models that are; (i) 12.06 x times compressed; (ii) 0.13% to 0.27% more
accurate; (iii) Orders of magnitude faster unit inference at 0.06 ms. Our
optimization sequence is generic and can be applied to any state-of-the-art
models trained for anomaly detection, predictive maintenance, robotics, voice
recognition, and machine vision.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.07846v1,2022-04-16T17:27:50Z,2022-04-16T17:27:50Z,"On Safety Testing, Validation, and Characterization with
  Scenario-Sampling: A Case Study of Legged Robots","The dynamic response of the legged robot locomotion is non-Lipschitz and can
be stochastic due to environmental uncertainties. To test, validate, and
characterize the safety performance of legged robots, existing solutions on
observed and inferred risk can be incomplete and sampling inefficient. Some
formal verification methods suffer from the model precision and other surrogate
assumptions. In this paper, we propose a scenario sampling based testing
framework that characterizes the overall safety performance of a legged robot
by specifying (i) where (in terms of a set of states) the robot is potentially
safe, and (ii) how safe the robot is within the specified set. The framework
can also help certify the commercial deployment of the legged robot in
real-world environment along with human and compare safety performance among
legged robots with different mechanical structures and dynamic properties. The
proposed framework is further deployed to evaluate a group of state-of-the-art
legged robot locomotion controllers from various model-based, deep neural
network involved, and reinforcement learning based methods in the literature.
Among a series of intended work domains of the studied legged robots (e.g.
tracking speed on sloped surface, with abrupt changes on demanded velocity, and
against adversarial push-over disturbances), we show that the method can
adequately capture the overall safety characterization and the subtle
performance insights. Many of the observed safety outcomes, to the best of our
knowledge, have never been reported by the existing work in the legged robot
literature.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.07373v1,2022-04-15T08:12:15Z,2022-04-15T08:12:15Z,"Revisiting the Adversarial Robustness-Accuracy Tradeoff in Robot
  Learning","Adversarial training (i.e., training on adversarially perturbed input data)
is a well-studied method for making neural networks robust to potential
adversarial attacks during inference. However, the improved robustness does not
come for free but rather is accompanied by a decrease in overall model accuracy
and performance. Recent work has shown that, in practical robot learning
applications, the effects of adversarial training do not pose a fair trade-off
but inflict a net loss when measured in holistic robot performance. This work
revisits the robustness-accuracy trade-off in robot learning by systematically
analyzing if recent advances in robust training methods and theory in
conjunction with adversarial robot learning can make adversarial training
suitable for real-world robot applications. We evaluate a wide variety of robot
learning tasks ranging from autonomous driving in a high-fidelity environment
amenable to sim-to-real deployment, to mobile robot gesture recognition. Our
results demonstrate that, while these techniques make incremental improvements
on the trade-off on a relative scale, the negative side-effects caused by
adversarial training still outweigh the improvements by an order of magnitude.
We conclude that more substantial advances in robust learning methods are
necessary before they can benefit robot learning tasks in practice.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.06949v1,2022-04-14T13:20:52Z,2022-04-14T13:20:52Z,"Federated Learning for Vision-based Obstacle Avoidance in the Internet
  of Robotic Things","Deep learning methods have revolutionized mobile robotics, from advanced
perception models for an enhanced situational awareness to novel control
approaches through reinforcement learning. This paper explores the potential of
federated learning for distributed systems of mobile robots enabling
collaboration on the Internet of Robotic Things. To demonstrate the
effectiveness of such an approach, we deploy wheeled robots in different indoor
environments. We analyze the performance of a federated learning approach and
compare it to a traditional centralized training process with a priori
aggregated data. We show the benefits of collaborative learning across
heterogeneous environments and the potential for sim-to-real knowledge
transfer. Our results demonstrate significant performance benefits of FL and
sim-to-real transfer for vision-based navigation, in addition to the inherent
privacy-preserving nature of FL by keeping computation at the edge. This is, to
the best of our knowledge, the first work to leverage FL for vision-based
navigation that also tests results in real-world settings.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.06716v1,2022-04-14T03:02:27Z,2022-04-14T03:02:27Z,Control-oriented meta-learning,"Real-time adaptation is imperative to the control of robots operating in
complex, dynamic environments. Adaptive control laws can endow even nonlinear
systems with good trajectory tracking performance, provided that any uncertain
dynamics terms are linearly parameterizable with known nonlinear features.
However, it is often difficult to specify such features a priori, such as for
aerodynamic disturbances on rotorcraft or interaction forces between a
manipulator arm and various objects. In this paper, we turn to data-driven
modeling with neural networks to learn, offline from past data, an adaptive
controller with an internal parametric model of these nonlinear features. Our
key insight is that we can better prepare the controller for deployment with
control-oriented meta-learning of features in closed-loop simulation, rather
than regression-oriented meta-learning of features to fit input-output data.
Specifically, we meta-learn the adaptive controller with closed-loop tracking
simulation as the base-learner and the average tracking error as the
meta-objective. With both fully-actuated and underactuated nonlinear planar
rotorcraft subject to wind, we demonstrate that our adaptive controller
outperforms other controllers trained with regression-oriented meta-learning
when deployed in closed-loop for trajectory tracking control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.05509v1,2022-04-12T03:45:48Z,2022-04-12T03:45:48Z,"Learning Design and Construction with Varying-Sized Materials via
  Prioritized Memory Resets","Can a robot autonomously learn to design and construct a bridge from
varying-sized blocks without a blueprint? It is a challenging task with long
horizon and sparse reward -- the robot has to figure out physically stable
design schemes and feasible actions to manipulate and transport blocks. Due to
diverse block sizes, the state space and action trajectories are vast to
explore. In this paper, we propose a hierarchical approach for this problem. It
consists of a reinforcement-learning designer to propose high-level building
instructions and a motion-planning-based action generator to manipulate blocks
at the low level. For high-level learning, we develop a novel technique,
prioritized memory resetting (PMR) to improve exploration. PMR adaptively
resets the state to those most critical configurations from a replay buffer so
that the robot can resume training on partial architectures instead of from
scratch. Furthermore, we augment PMR with auxiliary training objectives and
fine-tune the designer with the locomotion generator. Our experiments in
simulation and on a real deployed robotic system demonstrate that it is able to
effectively construct bridges with blocks of varying sizes at a high success
rate. Demos can be found at https://sites.google.com/view/bridge-pmr.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2204.00898v3,2022-06-05T02:53:15Z,2022-04-02T16:41:17Z,Hierarchical Reinforcement Learning under Mixed Observability,"The framework of mixed observable Markov decision processes (MOMDP) models
many robotic domains in which some state variables are fully observable while
others are not. In this work, we identify a significant subclass of MOMDPs
defined by how actions influence the fully observable components of the state
and how those, in turn, influence the partially observable components and the
rewards. This unique property allows for a two-level hierarchical approach we
call HIerarchical Reinforcement Learning under Mixed Observability (HILMO),
which restricts partial observability to the top level while the bottom level
remains fully observable, enabling higher learning efficiency. The top level
produces desired goals to be reached by the bottom level until the task is
solved. We further develop theoretical guarantees to show that our approach can
achieve optimal and quasi-optimal behavior under mild assumptions. Empirical
results on long-horizon continuous control tasks demonstrate the efficacy and
efficiency of our approach in terms of improved success rate, sample
efficiency, and wall-clock training time. We also deploy policies learned in
simulation on a real robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.16154v1,2022-03-30T08:55:08Z,2022-03-30T08:55:08Z,"Learning to Socially Navigate in Pedestrian-rich Environments with
  Interaction Capacity","Existing navigation policies for autonomous robots tend to focus on collision
avoidance while ignoring human-robot interactions in social life. For instance,
robots can pass along the corridor safer and easier if pedestrians notice them.
Sounds have been considered as an efficient way to attract the attention of
pedestrians, which can alleviate the freezing robot problem. In this work, we
present a new deep reinforcement learning (DRL) based social navigation
approach for autonomous robots to move in pedestrian-rich environments with
interaction capacity. Most existing DRL based methods intend to train a general
policy that outputs both navigation actions, i.e., expected robot's linear and
angular velocities, and interaction actions, i.e., the beep action, in the
context of reinforcement learning. Different from these methods, we intend to
train the policy via both supervised learning and reinforcement learning. In
specific, we first train an interaction policy in the context of supervised
learning, which provides a better understanding of the social situation, then
we use this interaction policy to train the navigation policy via multiple
reinforcement learning algorithms. We evaluate our approach in various
simulation environments and compare it to other methods. The experimental
results show that our approach outperforms others in terms of the success rate.
We also deploy the trained policy on a real-world robot, which shows a nice
performance in crowded environments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.15103v1,2022-03-28T21:17:36Z,2022-03-28T21:17:36Z,"Adversarial Motion Priors Make Good Substitutes for Complex Reward
  Functions","Training a high-dimensional simulated agent with an under-specified reward
function often leads the agent to learn physically infeasible strategies that
are ineffective when deployed in the real world. To mitigate these unnatural
behaviors, reinforcement learning practitioners often utilize complex reward
functions that encourage physically plausible behaviors. However, a tedious
labor-intensive tuning process is often required to create hand-designed
rewards which might not easily generalize across platforms and tasks. We
propose substituting complex reward functions with ""style rewards"" learned from
a dataset of motion capture demonstrations. A learned style reward can be
combined with an arbitrary task reward to train policies that perform tasks
using naturalistic strategies. These natural strategies can also facilitate
transfer to the real world. We build upon Adversarial Motion Priors -- an
approach from the computer graphics domain that encodes a style reward from a
dataset of reference motions -- to demonstrate that an adversarial approach to
training policies can produce behaviors that transfer to a real quadrupedal
robot without requiring complex reward functions. We also demonstrate that an
effective style reward can be learned from a few seconds of motion capture data
gathered from a German Shepherd and leads to energy-efficient locomotion
strategies with natural gait transitions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.15069v1,2022-03-28T20:22:45Z,2022-03-28T20:22:45Z,"Leveraging Tactile Sensors for Low Latency Embedded Smart Hands for
  Prosthetic and Robotic Applications","Tactile sensing is a crucial perception mode for robots and human amputees in
need of controlling a prosthetic device. Today robotic and prosthetic systems
are still missing the important feature of accurate tactile sensing. This lack
is mainly due to the fact that the existing tactile technologies have limited
spatial and temporal resolution and are either expensive or not scalable. In
this paper, we present the design and the implementation of a hardware-software
embedded system called SmartHand. It is specifically designed to enable the
acquisition and the real-time processing of high-resolution tactile information
from a hand-shaped multi-sensor array for prosthetic and robotic applications.
During data collection, our system can deliver a high throughput of 100 frames
per second, which is 13.7x higher than previous related work. We collected a
new tactile dataset while interacting with daily-life objects during five
different sessions. We propose a compact yet accurate convolutional neural
network that requires one order of magnitude less memory and 15.6x fewer
computations compared to related work without degrading classification
accuracy. The top-1 and top-3 cross-validation accuracies are respectively
98.86% and 99.83%. We further analyze the inter-session variability and obtain
the best top-3 leave-one-out-validation accuracy of 77.84%. We deploy the
trained model on a high-performance ARM Cortex-M7 microcontroller achieving an
inference time of only 100 ms minimizing the response latency. The overall
measured power consumption is 505 mW. Finally, we fabricate a new control
sensor and perform additional experiments to provide analyses on sensor
degradation and slip detection. This work is a step forward in giving robotic
and prosthetic devices a sense of touch and demonstrates the practicality of a
smart embedded system empowered by tiny machine learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.12759v3,2022-03-31T12:17:37Z,2022-03-23T23:05:28Z,"Asynchronous Reinforcement Learning for Real-Time Control of Physical
  Robots","An oft-ignored challenge of real-world reinforcement learning is that the
real world does not pause when agents make learning updates. As standard
simulated environments do not address this real-time aspect of learning, most
available implementations of RL algorithms process environment interactions and
learning updates sequentially. As a consequence, when such implementations are
deployed in the real world, they may make decisions based on significantly
delayed observations and not act responsively. Asynchronous learning has been
proposed to solve this issue, but no systematic comparison between sequential
and asynchronous reinforcement learning was conducted using real-world
environments. In this work, we set up two vision-based tasks with a robotic
arm, implement an asynchronous learning system that extends a previous
architecture, and compare sequential and asynchronous reinforcement learning
across different action cycle times, sensory data dimensions, and mini-batch
sizes. Our experiments show that when the time cost of learning updates
increases, the action cycle time in sequential implementation could grow
excessively long, while the asynchronous implementation can always maintain an
appropriate action cycle time. Consequently, when learning updates are
expensive, the performance of sequential learning diminishes and is
outperformed by asynchronous learning by a substantial margin. Our system
learns in real-time to reach and track visual targets from pixels within two
hours of experience and does so directly using real robots, learning completely
from scratch.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.10518v1,2022-03-20T10:21:52Z,2022-03-20T10:21:52Z,"Learning on the Job: Long-Term Behavioural Adaptation in Human-Robot
  Interactions","In this work, we propose a framework for allowing autonomous robots deployed
for extended periods of time in public spaces to adapt their own behaviour
online from user interactions. The robot behaviour planning is embedded in a
Reinforcement Learning (RL) framework, where the objective is maximising the
level of overall user engagement during the interactions. We use the
Upper-Confidence-Bound Value-Iteration (UCBVI) algorithm, which gives a helpful
way of managing the exploration-exploitation trade-off for real-time
interactions. An engagement model trained end-to-end generates the reward
function in real-time during policy execution. We test this approach in a
public museum in Lincoln (UK), where the robot is deployed as a tour guide for
the visitors. Results show that after a couple of months of exploration, the
robot policy learned to maintain the engagement of users for longer, with an
increase of 22.8% over the initial static policy in the number of items visited
during the tour and a 30% increase in the probability of completing the tour.
This work is a promising step toward behavioural adaptation in long-term
scenarios for robotics applications in social settings.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.09637v1,2022-03-17T22:24:38Z,2022-03-17T22:24:38Z,Investigating Compounding Prediction Errors in Learned Dynamics Models,"Accurately predicting the consequences of agents' actions is a key
prerequisite for planning in robotic control. Model-based reinforcement
learning (MBRL) is one paradigm which relies on the iterative learning and
prediction of state-action transitions to solve a task. Deep MBRL has become a
popular candidate, using a neural network to learn a dynamics model that
predicts with each pass from high-dimensional states to actions. These
""one-step"" predictions are known to become inaccurate over longer horizons of
composed prediction - called the compounding error problem. Given the
prevalence of the compounding error problem in MBRL and related fields of
data-driven control, we set out to understand the properties of and conditions
causing these long-horizon errors. In this paper, we explore the effects of
subcomponents of a control problem on long term prediction error: including
choosing a system, collecting data, and training a model. These detailed
quantitative studies on simulated and real-world data show that the underlying
dynamics of a system are the strongest factor determining the shape and
magnitude of prediction error. Given a clearer understanding of compounding
prediction error, researchers can implement new types of models beyond
""one-step"" that are more useful for control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.05360v1,2022-03-10T13:23:33Z,2022-03-10T13:23:33Z,Deep Residual Reinforcement Learning based Autonomous Blimp Control,"Blimps are well suited to perform long-duration aerial tasks as they are
energy efficient, relatively silent and safe. To address the blimp navigation
and control task, in previous work we developed a hardware and
software-in-the-loop framework and a PID-based controller for large blimps in
the presence of wind disturbance. However, blimps have a deformable structure
and their dynamics are inherently non-linear and time-delayed, making PID
controllers difficult to tune. Thus, often resulting in large tracking errors.
Moreover, the buoyancy of a blimp is constantly changing due to variations in
ambient temperature and pressure. To address these issues, in this paper we
present a learning-based framework based on deep residual reinforcement
learning (DRRL), for the blimp control task. Within this framework, we first
employ a PID controller to provide baseline performance. Subsequently, the DRRL
agent learns to modify the PID decisions by interaction with the environment.
We demonstrate in simulation that DRRL agent consistently improves the PID
performance. Through rigorous simulation experiments, we show that the agent is
robust to changes in wind speed and buoyancy. In real-world experiments, we
demonstrate that the agent, trained only in simulation, is sufficiently robust
to control an actual blimp in windy conditions. We openly provide the source
code of our approach at https://github.com/
robot-perception-group/AutonomousBlimpDRL.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.04613v1,2022-03-09T10:00:52Z,2022-03-09T10:00:52Z,"Object-Based Visual Camera Pose Estimation From Ellipsoidal Model and
  3D-Aware Ellipse Prediction","In this paper, we propose a method for initial camera pose estimation from
just a single image which is robust to viewing conditions and does not require
a detailed model of the scene. This method meets the growing need of easy
deployment of robotics or augmented reality applications in any environments,
especially those for which no accurate 3D model nor huge amount of ground truth
data are available. It exploits the ability of deep learning techniques to
reliably detect objects regardless of viewing conditions. Previous works have
also shown that abstracting the geometry of a scene of objects by an ellipsoid
cloud allows to compute the camera pose accurately enough for various
application needs. Though promising, these approaches use the ellipses fitted
to the detection bounding boxes as an approximation of the imaged objects. In
this paper, we go one step further and propose a learning-based method which
detects improved elliptic approximations of objects which are coherent with the
3D ellipsoids in terms of perspective projection. Experiments prove that the
accuracy of the computed pose significantly increases thanks to our method.
This is achieved with very little effort in terms of training data acquisition
- a few hundred calibrated images of which only three need manual object
annotation. Code and models are released at
https://gitlab.inria.fr/tangram/3d-aware-ellipses-for-visual-localization",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.02638v1,2022-03-05T01:49:16Z,2022-03-05T01:49:16Z,Safe Reinforcement Learning for Legged Locomotion,"Designing control policies for legged locomotion is complex due to the
under-actuated and non-continuous robot dynamics. Model-free reinforcement
learning provides promising tools to tackle this challenge. However, a major
bottleneck of applying model-free reinforcement learning in real world is
safety. In this paper, we propose a safe reinforcement learning framework that
switches between a safe recovery policy that prevents the robot from entering
unsafe states, and a learner policy that is optimized to complete the task. The
safe recovery policy takes over the control when the learner policy violates
safety constraints, and hands over the control back when there are no future
safety violations. We design the safe recovery policy so that it ensures safety
of legged locomotion while minimally intervening in the learning process.
Furthermore, we theoretically analyze the proposed framework and provide an
upper bound on the task performance. We verify the proposed framework in four
locomotion tasks on a simulated and real quadrupedal robot: efficient gait,
catwalk, two-leg balance, and pacing. On average, our method achieves 48.6%
fewer falls and comparable or better rewards than the baseline methods in
simulation. When deployed it on real-world quadruped robot, our training
pipeline enables 34% improvement in energy efficiency for the efficient gait,
40.9% narrower of the feet placement in the catwalk, and two times more jumping
duration in the two-leg balance. Our method achieves less than five falls over
the duration of 115 minutes of hardware time.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.02013v1,2022-03-03T20:52:47Z,2022-03-03T20:52:47Z,"DIME: Fine-grained Interpretations of Multimodal Models via Disentangled
  Local Explanations","The ability for a human to understand an Artificial Intelligence (AI) model's
decision-making process is critical in enabling stakeholders to visualize model
behavior, perform model debugging, promote trust in AI models, and assist in
collaborative human-AI decision-making. As a result, the research fields of
interpretable and explainable AI have gained traction within AI communities as
well as interdisciplinary scientists seeking to apply AI in their subject
areas. In this paper, we focus on advancing the state-of-the-art in
interpreting multimodal models - a class of machine learning methods that
tackle core challenges in representing and capturing interactions between
heterogeneous data sources such as images, text, audio, and time-series data.
Multimodal models have proliferated numerous real-world applications across
healthcare, robotics, multimedia, affective computing, and human-computer
interaction. By performing model disentanglement into unimodal contributions
(UC) and multimodal interactions (MI), our proposed approach, DIME, enables
accurate and fine-grained analysis of multimodal models while maintaining
generality across arbitrary modalities, model architectures, and tasks. Through
a comprehensive suite of experiments on both synthetic and real-world
multimodal tasks, we show that DIME generates accurate disentangled
explanations, helps users of multimodal models gain a deeper understanding of
model behavior, and presents a step towards debugging and improving these
models for real-world deployment. Code for our experiments can be found at
https://github.com/lvyiwei1/DIME.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2203.01707v1,2022-03-03T13:30:28Z,2022-03-03T13:30:28Z,Reinforcement Learning in Possibly Nonstationary Environments,"We consider reinforcement learning (RL) methods in offline nonstationary
environments. Many existing RL algorithms in the literature rely on the
stationarity assumption that requires the system transition and the reward
function to be constant over time. However, the stationarity assumption is
restrictive in practice and is likely to be violated in a number of
applications, including traffic signal control, robotics and mobile health. In
this paper, we develop a consistent procedure to test the nonstationarity of
the optimal policy based on pre-collected historical data, without additional
online data collection. Based on the proposed test, we further develop a
sequential change point detection method that can be naturally coupled with
existing state-of-the-art RL methods for policy optimisation in nonstationary
environments. The usefulness of our method is illustrated by theoretical
results, simulation studies, and a real data example from the 2018 Intern
Health Study. A Python implementation of the proposed procedure is available at
https://github.com/limengbinggz/CUSUM-RL",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.13098v1,2022-02-26T09:35:51Z,2022-02-26T09:35:51Z,"Fast and Accurate Data-Driven Simulation Framework for Contact-Intensive
  Tight-Tolerance Robotic Assembly Tasks","We propose a novel fast and accurate simulation framework for
contact-intensive tight-tolerance robotic assembly tasks. The key components of
our framework are as follows: 1) data-driven contact point clustering with a
certain variable-input network, which is explicitly trained for simulation
accuracy (with real experimental data) and able to accommodate
complex/non-convex object shapes; 2) contact force solving, which
precisely/robustly enforces physics of contact (i.e., no penetration, Coulomb
friction, maximum energy dissipation) with contact mechanics of contact nodes
augmented with that of their object; 3) contact detection with a neural
network, which is parallelized for each contact point, thus, can be computed
very quickly even for complex shape objects with no exhaust pair-wise test; and
4) time integration with PMI (passive mid-point integration), whose
discrete-time passivity improves overall simulation accuracy, stability, and
speed. We then implement our proposed framework for two
widely-encountered/benchmarked contact-intensive tight-tolerance tasks, namely,
peg-in-hole assembly and bolt-nut assembly, and validate its speed and accuracy
against real experimental data. It is worthwhile to mention that our proposed
simulation framework is applicable to other general contact-intensive
tight-tolerance robotic assembly tasks as well. We also compare its performance
with other physics engines and manifest its robustness via haptic rendering of
virtual bolting task.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.10459v1,2022-02-21T07:47:43Z,2022-02-21T07:47:43Z,"Towards technological adaptation of advanced farming through AI, IoT,
  and Robotics: A Comprehensive overview","The population explosion of the 21st century has adversely affected the
natural resources with restricted availability of cultivable land, increased
average temperatures due to global warming, and carbon footprint resulting in a
drastic increase in floods as well as droughts thus making food security
significant anxiety for most countries. The traditional methods were no longer
sufficient which paved the way for technological ascents such as a substantial
rise in Artificial Intelligence (AI), Internet of Things (IoT), as well as
Robotics that provides high productivity, functional efficiency, flexibility,
cost-effectiveness in the domain of agriculture. AI, IoT, and Robotics-based
devices and methods have produced new paradigms and opportunities in
agriculture. AI's existing approaches are soil management, crop diseases
identification, weed identification, and management in collaboration with IoT
devices. IoT has utilized automatic agricultural operations and real-time
monitoring with few personnel employed in real-time. The major existing
applications of agricultural robotics are for the function of soil preparation,
planting, monitoring, harvesting, and storage. In this paper, researchers have
explored a comprehensive overview of recent implementation, scopes,
opportunities, challenges, limitations, and future research instructions of AI,
IoT, and Robotics based methodology in the agriculture sector.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.09549v2,2022-07-13T20:33:47Z,2022-02-19T08:21:56Z,"Learning to Detect Slip with Barometric Tactile Sensors and a Temporal
  Convolutional Neural Network","The ability to perceive object slip via tactile feedback enables humans to
accomplish complex manipulation tasks including maintaining a stable grasp.
Despite the utility of tactile information for many applications, tactile
sensors have yet to be widely deployed in industrial robotics settings; part of
the challenge lies in identifying slip and other events from the tactile data
stream. In this paper, we present a learning-based method to detect slip using
barometric tactile sensors. These sensors have many desirable properties
including high durability and reliability, and are built from inexpensive,
off-the-shelf components. We train a temporal convolution neural network to
detect slip, achieving high detection accuracies while displaying robustness to
the speed and direction of the slip motion. Further, we test our detector on
two manipulation tasks involving a variety of common objects and demonstrate
successful generalization to real-world scenarios not seen during training. We
argue that barometric tactile sensing technology, combined with data-driven
learning, is suitable for many manipulation tasks such as slip compensation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.09514v1,2022-02-19T03:44:05Z,2022-02-19T03:44:05Z,"Robust Reinforcement Learning as a Stackelberg Game via
  Adaptively-Regularized Adversarial Training","Robust Reinforcement Learning (RL) focuses on improving performances under
model errors or adversarial attacks, which facilitates the real-life deployment
of RL agents. Robust Adversarial Reinforcement Learning (RARL) is one of the
most popular frameworks for robust RL. However, most of the existing literature
models RARL as a zero-sum simultaneous game with Nash equilibrium as the
solution concept, which could overlook the sequential nature of RL deployments,
produce overly conservative agents, and induce training instability. In this
paper, we introduce a novel hierarchical formulation of robust RL - a
general-sum Stackelberg game model called RRL-Stack - to formalize the
sequential nature and provide extra flexibility for robust training. We develop
the Stackelberg Policy Gradient algorithm to solve RRL-Stack, leveraging the
Stackelberg learning dynamics by considering the adversary's response. Our
method generates challenging yet solvable adversarial environments which
benefit RL agents' robust learning. Our algorithm demonstrates better training
stability and robustness against different testing conditions in the
single-agent robotics control and multi-agent highway merging tasks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.08450v1,2022-02-17T05:33:27Z,2022-02-17T05:33:27Z,"Design-Bench: Benchmarks for Data-Driven Offline Model-Based
  Optimization","Black-box model-based optimization (MBO) problems, where the goal is to find
a design input that maximizes an unknown objective function, are ubiquitous in
a wide range of domains, such as the design of proteins, DNA sequences,
aircraft, and robots. Solving model-based optimization problems typically
requires actively querying the unknown objective function on design proposals,
which means physically building the candidate molecule, aircraft, or robot,
testing it, and storing the result. This process can be expensive and time
consuming, and one might instead prefer to optimize for the best design using
only the data one already has. This setting -- called offline MBO -- poses
substantial and different algorithmic challenges than more commonly studied
online techniques. A number of recent works have demonstrated success with
offline MBO for high-dimensional optimization problems using high-capacity deep
neural networks. However, the lack of standardized benchmarks in this emerging
field is making progress difficult to track. To address this, we present
Design-Bench, a benchmark for offline MBO with a unified evaluation protocol
and reference implementations of recent methods. Our benchmark includes a suite
of diverse and realistic tasks derived from real-world optimization problems in
biology, materials science, and robotics that present distinct challenges for
offline MBO. Our benchmark and reference implementations are released at
github.com/rail-berkeley/design-bench and
github.com/rail-berkeley/design-baselines.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.08004v2,2022-06-15T12:11:37Z,2022-02-16T11:40:36Z,Deep Koopman Operator with Control for Nonlinear Systems,"Recently Koopman operator has become a promising data-driven tool to
facilitate real-time control for unknown nonlinear systems. It maps nonlinear
systems into equivalent linear systems in embedding space, ready for real-time
linear control methods. However, designing an appropriate Koopman embedding
function remains a challenging task. Furthermore, most Koopman-based algorithms
only consider nonlinear systems with linear control input, resulting in lousy
prediction and control performance when the system is fully nonlinear with the
control input. In this work, we propose an end-to-end deep learning framework
to learn the Koopman embedding function and Koopman Operator together to
alleviate such difficulties. We first parameterize the embedding function and
Koopman Operator with the neural network and train them end-to-end with the
K-steps loss function. Then, an auxiliary control network is augmented to
encode the nonlinear state-dependent control term to model the nonlinearity in
the control input. This encoded term is considered the new control variable
instead to ensure linearity of the modeled system in the embedding system.We
next deploy Linear Quadratic Regulator (LQR) on the linear embedding space to
derive the optimal control policy and decode the actual control input from the
control net. Experimental results demonstrate that our approach outperforms
other existing methods, reducing the prediction error by order of magnitude and
achieving superior control performance in several nonlinear dynamic systems
like damping pendulum, CartPole, and the seven DOF robotic manipulator.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.07064v1,2022-02-14T22:08:23Z,2022-02-14T22:08:23Z,"Towards hardware Implementation of WTA for CPG-based control of a
  Spiking Robotic Arm","Biological nervous systems typically perform the control of numerous degrees
of freedom for example in animal limbs. Neuromorphic engineers study these
systems by emulating them in hardware for a deeper understanding and its
possible application to solve complex problems in engineering and robotics.
Central-Pattern-Generators (CPGs) are part of neuro-controllers, typically used
at their last steps to produce rhythmic patterns for limbs movement. Different
patterns and gaits typically compete through winner-take-all (WTA) circuits to
produce the right movements. In this work we present a WTA circuit implemented
in a Spiking-Neural-Network (SNN) processor to produce such patterns for
controlling a robotic arm in real-time. The robot uses spike-based
proportional-integrativederivative (SPID) controllers to keep a commanded joint
position from the winner population of neurons of the WTA circuit. Experiments
demonstrate the feasibility of robotic control with spiking circuits following
brain-inspiration.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.06003v2,2022-02-15T10:35:34Z,2022-02-12T07:04:06Z,Robust Learning from Observation with Model Misspecification,"Imitation learning (IL) is a popular paradigm for training policies in
robotic systems when specifying the reward function is difficult. However,
despite the success of IL algorithms, they impose the somewhat unrealistic
requirement that the expert demonstrations must come from the same domain in
which a new imitator policy is to be learned. We consider a practical setting,
where (i) state-only expert demonstrations from the real (deployment)
environment are given to the learner, (ii) the imitation learner policy is
trained in a simulation (training) environment whose transition dynamics is
slightly different from the real environment, and (iii) the learner does not
have any access to the real environment during the training phase beyond the
batch of demonstrations given. Most of the current IL methods, such as
generative adversarial imitation learning and its state-only variants, fail to
imitate the optimal expert behavior under the above setting. By leveraging
insights from the Robust reinforcement learning (RL) literature and building on
recent adversarial imitation approaches, we propose a robust IL algorithm to
learn policies that can effectively transfer to the real environment without
fine-tuning. Furthermore, we empirically demonstrate on continuous-control
benchmarks that our method outperforms the state-of-the-art state-only IL
method in terms of the zero-shot transfer performance in the real environment
and robust performance under different testing conditions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.05811v1,2022-02-11T18:21:18Z,2022-02-11T18:21:18Z,Overhead Image Factors for Underwater Sonar-based SLAM,"Simultaneous localization and mapping (SLAM) is a critical capability for any
autonomous underwater vehicle (AUV). However, robust, accurate state estimation
is still a work in progress when using low-cost sensors. We propose enhancing a
typical low-cost sensor package using widely available and often free prior
information; overhead imagery. Given an AUV's sonar image and a partially
overlapping, globally-referenced overhead image, we propose using a
convolutional neural network (CNN) to generate a synthetic overhead image
predicting the above-surface appearance of the sonar image contents. We then
use this synthetic overhead image to register our observations to the provided
global overhead image. Once registered, the transformation is introduced as a
factor into a pose SLAM factor graph. We use a state-of-the-art simulation
environment to perform validation over a series of benchmark trajectories and
quantitatively show the improved accuracy of robot state estimation using the
proposed approach. We also show qualitative outcomes from a real AUV field
deployment. Video attachment: https://youtu.be/_uWljtp58ks",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.04628v2,2022-02-13T21:23:07Z,2022-02-09T18:45:40Z,"Reinforcement Learning with Sparse Rewards using Guidance from Offline
  Demonstration","A major challenge in real-world reinforcement learning (RL) is the sparsity
of reward feedback. Often, what is available is an intuitive but sparse reward
function that only indicates whether the task is completed partially or fully.
However, the lack of carefully designed, fine grain feedback implies that most
existing RL algorithms fail to learn an acceptable policy in a reasonable time
frame. This is because of the large number of exploration actions that the
policy has to perform before it gets any useful feedback that it can learn
from. In this work, we address this challenging problem by developing an
algorithm that exploits the offline demonstration data generated by a
sub-optimal behavior policy for faster and efficient online RL in such sparse
reward settings. The proposed algorithm, which we call the Learning Online with
Guidance Offline (LOGO) algorithm, merges a policy improvement step with an
additional policy guidance step by using the offline demonstration data. The
key idea is that by obtaining guidance from - not imitating - the offline data,
LOGO orients its policy in the manner of the sub-optimal policy, while yet
being able to learn beyond and approach optimality. We provide a theoretical
analysis of our algorithm, and provide a lower bound on the performance
improvement in each learning episode. We also extend our algorithm to the even
more challenging incomplete observation setting, where the demonstration data
contains only a censored version of the true state observation. We demonstrate
the superior performance of our algorithm over state-of-the-art approaches on a
number of benchmark environments with sparse rewards and censored state.
Further, we demonstrate the value of our approach via implementing LOGO on a
mobile robot for trajectory tracking and obstacle avoidance, where it shows
excellent performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.03028v2,2022-03-01T14:15:45Z,2022-02-07T09:41:24Z,QUARK: A Framework for Quantum Computing Application Benchmarking,"Quantum computing (QC) is anticipated to provide a speedup over classical HPC
approaches for specific problems in optimization, simulation, and machine
learning. With the advances in quantum computing toward practical applications,
the need to analyze and compare different quantum solutions increases. While
different low-level benchmarks for QC exist, these benchmarks do not provide
sufficient insights into real-world application-level performance. We propose
an application-centric benchmark method and the QUantum computing Application
benchmaRK (QUARK) framework to foster the investigation and creation of
application benchmarks for QC. This paper establishes three significant
contributions: (1) it makes a case for application-level benchmarks and
provides an in-depth ""pen and paper"" benchmark formulation of two reference
problems: robot path and vehicle option optimization from the industrial
domain; (2) it proposes the open-source QUARK framework for designing,
implementing, executing, and analyzing benchmarks; (3) it provides multiple
reference implementations for these two reference problems based on different
known, and where needed, extended, classical and quantum algorithmic approaches
and analyzes their performance on different types of infrastructures.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.02656v1,2022-02-05T23:27:46Z,2022-02-05T23:27:46Z,A survey of top-down approaches for human pose estimation,"Human pose estimation in two-dimensional images videos has been a hot topic
in the computer vision problem recently due to its vast benefits and potential
applications for improving human life, such as behaviors recognition, motion
capture and augmented reality, training robots, and movement tracking. Many
state-of-the-art methods implemented with Deep Learning have addressed several
challenges and brought tremendous remarkable results in the field of human pose
estimation. Approaches are classified into two kinds: the two-step framework
(top-down approach) and the part-based framework (bottom-up approach). While
the two-step framework first incorporates a person detector and then estimates
the pose within each box independently, detecting all body parts in the image
and associating parts belonging to distinct persons is conducted in the
part-based framework. This paper aims to provide newcomers with an extensive
review of deep learning methods-based 2D images for recognizing the pose of
people, which only focuses on top-down approaches since 2016. The discussion
through this paper presents significant detectors and estimators depending on
mathematical background, the challenges and limitations, benchmark datasets,
evaluation metrics, and comparison between methods.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.02352v2,2022-05-15T21:24:49Z,2022-02-04T19:20:58Z,"Learning Interpretable, High-Performing Policies for Autonomous Driving","Gradient-based approaches in reinforcement learning (RL) have achieved
tremendous success in learning policies for autonomous vehicles. While the
performance of these approaches warrants real-world adoption, these policies
lack interpretability, limiting deployability in the safety-critical and
legally-regulated domain of autonomous driving (AD). AD requires interpretable
and verifiable control policies that maintain high performance. We propose
Interpretable Continuous Control Trees (ICCTs), a tree-based model that can be
optimized via modern, gradient-based, RL approaches to produce high-performing,
interpretable policies. The key to our approach is a procedure for allowing
direct optimization in a sparse decision-tree-like representation. We validate
ICCTs against baselines across six domains, showing that ICCTs are capable of
learning interpretable policy representations that parity or outperform
baselines by up to 33% in AD scenarios while achieving a 300x-600x reduction in
the number of policy parameters against deep learning baselines. Furthermore,
we demonstrate the interpretability and utility of our ICCTs through a 14-car
physical robot demonstration.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.01862v2,2022-03-08T00:59:35Z,2022-02-03T21:43:06Z,Practical Imitation Learning in the Real World via Task Consistency Loss,"Recent work in visual end-to-end learning for robotics has shown the promise
of imitation learning across a variety of tasks. Such approaches are expensive
both because they require large amounts of real world training demonstrations
and because identifying the best model to deploy in the real world requires
time-consuming real-world evaluations. These challenges can be mitigated by
simulation: by supplementing real world data with simulated demonstrations and
using simulated evaluations to identify high performing policies. However, this
introduces the well-known ""reality gap"" problem, where simulator inaccuracies
decorrelate performance in simulation from that of reality. In this paper, we
build on top of prior work in GAN-based domain adaptation and introduce the
notion of a Task Consistency Loss (TCL), a self-supervised loss that encourages
sim and real alignment both at the feature and action-prediction levels. We
demonstrate the effectiveness of our approach by teaching a mobile manipulator
to autonomously approach a door, turn the handle to open the door, and enter
the room. The policy performs control from RGB and depth images and generalizes
to doors not encountered in training data. We achieve 72% success across
sixteen seen and unseen scenes using only ~16.2 hours of teleoperated
demonstrations in sim and real. To the best of our knowledge, this is the first
work to tackle latched door opening from a purely end-to-end learning approach,
where the task of navigation and manipulation are jointly modeled by a single
neural network.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2202.00617v1,2022-02-01T18:05:31Z,2022-02-01T18:05:31Z,"A General, Evolution-Inspired Reward Function for Social Robotics","The field of social robotics will likely need to depart from a paradigm of
designed behaviours and imitation learning and adopt modern reinforcement
learning (RL) methods to enable robots to interact fluidly and efficaciously
with humans. In this paper, we present the Social Reward Function as a
mechanism to provide (1) a real-time, dense reward function necessary for the
deployment of RL agents in social robotics, and (2) a standardised objective
metric for comparing the efficacy of different social robots. The Social Reward
Function is designed to closely mimic those genetically endowed social
perception capabilities of humans in an effort to provide a simple, stable and
culture-agnostic reward function. Presently, datasets used in social robotics
are either small or significantly out-of-domain with respect to social
robotics. The use of the Social Reward Function will allow larger in-domain
datasets to be collected close to the behaviour policy of social robots, which
will allow both further improvements to reward functions and to the behaviour
policies of social robots. We believe this will be the key enabler to
developing efficacious social robots in the future.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.09857v5,2022-07-22T04:26:06Z,2022-01-24T18:29:23Z,"STOPS: Short-Term-based Volatility-controlled Policy Search and its
  Global Convergence","It remains challenging to deploy existing risk-averse approaches to
real-world applications. The reasons are multi-fold, including the lack of
global optimality guarantee and the necessity of learning from long-term
consecutive trajectories. Long-term consecutive trajectories are prone to
involving visiting hazardous states, which is a major concern in the
risk-averse setting. This paper proposes Short-Term VOlatility-controlled
Policy Search (STOPS), a novel algorithm that solves risk-averse problems by
learning from short-term trajectories instead of long-term trajectories.
Short-term trajectories are more flexible to generate, and can avoid the danger
of hazardous state visitations. By using an actor-critic scheme with an
overparameterized two-layer neural network, our algorithm finds a globally
optimal policy at a sublinear rate with proximal policy optimization and
natural policy gradient, with effectiveness comparable to the state-of-the-art
convergence rate of risk-neutral policy-search methods. The algorithm is
evaluated on challenging Mujoco robot simulation tasks under the mean-variance
evaluation metric. Both theoretical analysis and experimental results
demonstrate a state-of-the-art level of STOPS' performance among existing
risk-averse policy search methods.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.05753v1,2022-01-15T04:07:51Z,2022-01-15T04:07:51Z,"Parameter Identification and Motion Control for Articulated Rigid Body
  Robots Using Differentiable Position-based Dynamics","Simulation modeling of robots, objects, and environments is the backbone for
all model-based control and learning. It is leveraged broadly across dynamic
programming and model-predictive control, as well as data generation for
imitation, transfer, and reinforcement learning. In addition to fidelity, key
features of models in these control and learning contexts are speed, stability,
and native differentiability. However, many popular simulation platforms for
robotics today lack at least one of the features above. More recently,
position-based dynamics (PBD) has become a very popular simulation tool for
modeling complex scenes of rigid and non-rigid object interactions, due to its
speed and stability, and is starting to gain significant interest in robotics
for its potential use in model-based control and learning. Thus, in this paper,
we present a mathematical formulation for coupling position-based dynamics
(PBD) simulation and optimal robot design, model-based motion control and
system identification. Our framework breaks down PBD definitions and
derivations for various types of joint-based articulated rigid bodies. We
present a back-propagation method with automatic differentiation, which can
integrate both positional and angular geometric constraints. Our framework can
critically provide the native gradient information and perform gradient-based
optimization tasks. We also propose articulated joint model representations and
simulation workflow for our differentiable framework. We demonstrate the
capability of the framework in efficient optimal robot design, accurate
trajectory torque estimation and supporting spring stiffness estimation, where
we achieve minor errors. We also implement impedance control in real robots to
demonstrate the potential of our differentiable framework in human-in-the-loop
applications.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.05518v1,2022-01-14T15:41:05Z,2022-01-14T15:41:05Z,UGV-UAV Object Geolocation in Unstructured Environments,"A robotic system of multiple unmanned ground vehicles (UGVs) and unmanned
aerial vehicles (UAVs) has the potential for advancing autonomous object
geolocation performance. Much research has focused on algorithmic improvements
on individual components, such as navigation, motion planning, and perception.
In this paper, we present a UGV-UAV object detection and geolocation system,
which performs perception, navigation, and planning autonomously in real scale
in unstructured environment. We designed novel sensor pods equipped with
multispectral (visible, near-infrared, thermal), high resolution (181.6 Mega
Pixels), stereo (near-infrared pair), wide field of view (192 degree HFOV)
array. We developed a novel on-board software-hardware architecture to process
the high volume sensor data in real-time, and we built a custom AI subsystem
composed of detection, tracking, navigation, and planning for autonomous
objects geolocation in real-time.
  This research is the first real scale demonstration of such high speed data
processing capability. Our novel modular sensor pod can boost relevant computer
vision and machine learning research. Our novel hardware-software architecture
is a solid foundation for system-level and component-level research. Our system
is validated through data-driven offline tests as well as a series of field
tests in unstructured environments. We present quantitative results as well as
discussions on key robotic system level challenges which manifest when we build
and test the system. This system is the first step toward a UGV-UAV cooperative
reconnaissance system in the future.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.01943v1,2022-01-06T07:14:02Z,2022-01-06T07:14:02Z,"Machine Learning: Algorithms, Models, and Applications","Recent times are witnessing rapid development in machine learning algorithm
systems, especially in reinforcement learning, natural language processing,
computer and robot vision, image processing, speech, and emotional processing
and understanding. In tune with the increasing importance and relevance of
machine learning models, algorithms, and their applications, and with the
emergence of more innovative uses cases of deep learning and artificial
intelligence, the current volume presents a few innovative research works and
their applications in real world, such as stock trading, medical and healthcare
systems, and software automation. The chapters in the book illustrate how
machine learning and deep learning algorithms and models are designed,
optimized, and deployed. The volume will be useful for advanced graduate and
doctoral students, researchers, faculty members of universities, practicing
data scientists and data engineers, professionals, and consultants working on
the broad areas of machine learning, deep learning, and artificial
intelligence.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2201.01369v1,2022-01-04T22:32:05Z,2022-01-04T22:32:05Z,"Using Simulation Optimization to Improve Zero-shot Policy Transfer of
  Quadrotors","In this work, we show that it is possible to train low-level control policies
with reinforcement learning entirely in simulation and, then, deploy them on a
quadrotor robot without using real-world data to fine-tune. To render zero-shot
policy transfers feasible, we apply simulation optimization to narrow the
reality gap. Our neural network-based policies use only onboard sensor data and
run entirely on the embedded drone hardware. In extensive real-world
experiments, we compare three different control structures ranging from
low-level pulse-width-modulated motor commands to high-level attitude control
based on nested proportional-integral-derivative controllers. Our experiments
show that low-level controllers trained with reinforcement learning require a
more accurate simulation than higher-level control policies.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.11532v1,2021-12-21T21:31:54Z,2021-12-21T21:31:54Z,Off Environment Evaluation Using Convex Risk Minimization,"Applying reinforcement learning (RL) methods on robots typically involves
training a policy in simulation and deploying it on a robot in the real world.
Because of the model mismatch between the real world and the simulator, RL
agents deployed in this manner tend to perform suboptimally. To tackle this
problem, researchers have developed robust policy learning algorithms that rely
on synthetic noise disturbances. However, such methods do not guarantee
performance in the target environment. We propose a convex risk minimization
algorithm to estimate the model mismatch between the simulator and the target
domain using trajectory data from both environments. We show that this
estimator can be used along with the simulator to evaluate performance of an RL
agents in the target domain, effectively bridging the gap between these two
environments. We also show that the convergence rate of our estimator to be of
the order of ${n^{-1/4}}$, where $n$ is the number of training samples. In
simulation, we demonstrate how our method effectively approximates and
evaluates performance on Gridworld, Cartpole, and Reacher environments on a
range of policies. We also show that the our method is able to estimate
performance of a 7 DOF robotic arm using the simulator and remotely collected
data from the robot in the real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.10513v1,2021-12-20T13:13:05Z,2021-12-20T13:13:05Z,"Learning Robust Policy against Disturbance in Transition Dynamics via
  State-Conservative Policy Optimization","Deep reinforcement learning algorithms can perform poorly in real-world tasks
due to the discrepancy between source and target environments. This discrepancy
is commonly viewed as the disturbance in transition dynamics. Many existing
algorithms learn robust policies by modeling the disturbance and applying it to
source environments during training, which usually requires prior knowledge
about the disturbance and control of simulators. However, these algorithms can
fail in scenarios where the disturbance from target environments is unknown or
is intractable to model in simulators. To tackle this problem, we propose a
novel model-free actor-critic algorithm -- namely, state-conservative policy
optimization (SCPO) -- to learn robust policies without modeling the
disturbance in advance. Specifically, SCPO reduces the disturbance in
transition dynamics to that in state space and then approximates it by a simple
gradient-based regularizer. The appealing features of SCPO include that it is
simple to implement and does not require additional knowledge about the
disturbance or specially designed simulators. Experiments in several robot
control tasks demonstrate that SCPO learns robust policies against the
disturbance in transition dynamics.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.05660v1,2021-12-10T16:44:47Z,2021-12-10T16:44:47Z,"DPU: DAG Processing Unit for Irregular Graphs with Precision-Scalable
  Posit Arithmetic in 28nm","Computation in several real-world applications like probabilistic machine
learning, sparse linear algebra, and robotic navigation, can be modeled as
irregular directed acyclic graphs (DAGs). The irregular data dependencies in
DAGs pose challenges to parallel execution on general-purpose CPUs and GPUs,
resulting in severe under-utilization of the hardware. This paper proposes DPU,
a specialized processor designed for the efficient execution of irregular DAGs.
The DPU is equipped with parallel compute units that execute different
subgraphs of a DAG independently. The compute units can synchronize within a
cycle using a hardware-supported synchronization primitive, and communicate via
an efficient interconnect to a global banked scratchpad. Furthermore, a
precision-scalable posit arithmetic unit is developed to enable
application-dependent precision. The DPU is taped-out in 28nm CMOS, achieving a
speedup of 5.1$\times$ and 20.6$\times$ over state-of-the-art CPU and GPU
implementations on DAGs of sparse linear algebra and probabilistic machine
learning workloads. This performance is achieved while operating at a power
budget of 0.23W, as opposed to 55W and 98W of the CPU and GPU, resulting in a
peak efficiency of 538 GOPS/W with DPU, which is 1350$\times$ and 9000$\times$
higher than the CPU and GPU, respectively. Thus, with specialized architecture,
DPU enables low-power execution of irregular DAG workloads.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.05299v1,2021-12-10T02:13:01Z,2021-12-10T02:13:01Z,"Zero-Shot Uncertainty-Aware Deployment of Simulation Trained Policies on
  Real-World Robots","While deep reinforcement learning (RL) agents have demonstrated incredible
potential in attaining dexterous behaviours for robotics, they tend to make
errors when deployed in the real world due to mismatches between the training
and execution environments. In contrast, the classical robotics community have
developed a range of controllers that can safely operate across most states in
the real world given their explicit derivation. These controllers however lack
the dexterity required for complex tasks given limitations in analytical
modelling and approximations. In this paper, we propose Bayesian Controller
Fusion (BCF), a novel uncertainty-aware deployment strategy that combines the
strengths of deep RL policies and traditional handcrafted controllers. In this
framework, we can perform zero-shot sim-to-real transfer, where our uncertainty
based formulation allows the robot to reliably act within out-of-distribution
states by leveraging the handcrafted controller while gaining the dexterity of
the learned system otherwise. We show promising results on two real-world
continuous control tasks, where BCF outperforms both the standalone policy and
controller, surpassing what either can achieve independently. A supplementary
video demonstrating our system is provided at https://bit.ly/bcf_deploy.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.03149v1,2021-12-06T16:35:08Z,2021-12-06T16:35:08Z,Distilled Domain Randomization,"Deep reinforcement learning is an effective tool to learn robot control
policies from scratch. However, these methods are notorious for the enormous
amount of required training data which is prohibitively expensive to collect on
real robots. A highly popular alternative is to learn from simulations,
allowing to generate the data much faster, safer, and cheaper. Since all
simulators are mere models of reality, there are inevitable differences between
the simulated and the real data, often referenced as the 'reality gap'. To
bridge this gap, many approaches learn one policy from a distribution over
simulators. In this paper, we propose to combine reinforcement learning from
randomized physics simulations with policy distillation. Our algorithm, called
Distilled Domain Randomization (DiDoR), distills so-called teacher policies,
which are experts on domains that have been sampled initially, into a student
policy that is later deployed. This way, DiDoR learns controllers which
transfer directly from simulation to reality, i.e., without requiring data from
the target domain. We compare DiDoR against three baselines in three sim-to-sim
as well as two sim-to-real experiments. Our results show that the target domain
performance of policies trained with DiDoR is en par or better than the
baselines'. Moreover, our approach neither increases the required memory
capacity nor the time to compute an action, which may well be a point of
failure for successfully deploying the learned controller.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2112.01270v1,2021-11-30T15:58:19Z,2021-11-30T15:58:19Z,"Multi-Object Grasping -- Estimating the Number of Objects in a Robotic
  Grasp","A human hand can grasp a desired number of objects at once from a pile based
solely on tactile sensing. To do so, a robot needs to grasp within a pile,
sense the number of objects in the grasp before lifting, and predict the number
of objects that will remain in the grasp after lifting. It is a challenging
problem because when making the prediction, the robotic hand is still in the
pile and the objects in the grasp are not observable to vision systems.
Moreover, some objects that are grasped by the hand before lifting from the
pile may fall out of the grasp when the hand is lifted. This occurs because
they were supported by other objects in the pile instead of the fingers of the
hand. Therefore, a robotic hand should sense the number of objects in a grasp
using its tactile sensors before lifting. This paper presents novel
multi-object grasping analyzing methods for solving this problem. They include
a grasp volume calculation, tactile force analysis, and a data-driven deep
learning approach. The methods have been implemented on a Barrett hand and then
evaluated in simulations and a real setup with a robotic system. The evaluation
results conclude that once the Barrett hand grasps multiple objects in the
pile, the data-driven model can predict, before lifting, the number of objects
that will remain in the hand after lifting. The root-mean-square errors for our
approach are 0.74 for balls and 0.58 for cubes in simulations, and 1.06 for
balls, and 1.45 for cubes in the real system.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.15438v2,2021-12-09T14:05:48Z,2021-11-30T14:30:44Z,"FMD-cGAN: Fast Motion Deblurring using Conditional Generative
  Adversarial Networks","In this paper, we present a Fast Motion Deblurring-Conditional Generative
Adversarial Network (FMD-cGAN) that helps in blind motion deblurring of a
single image. FMD-cGAN delivers impressive structural similarity and visual
appearance after deblurring an image. Like other deep neural network
architectures, GANs also suffer from large model size (parameters) and
computations. It is not easy to deploy the model on resource constraint devices
such as mobile and robotics. With the help of MobileNet based architecture that
consists of depthwise separable convolution, we reduce the model size and
inference time, without losing the quality of the images. More specifically, we
reduce the model size by 3-60x compare to the nearest competitor. The resulting
compressed Deblurring cGAN faster than its closest competitors and even
qualitative and quantitative results outperform various recently proposed
state-of-the-art blind motion deblurring models. We can also use our model for
real-time image deblurring tasks. The current experiment on the standard
datasets shows the effectiveness of the proposed method.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.13969v1,2021-11-27T19:07:45Z,2021-11-27T19:07:45Z,"Reinforcement Learning-based Switching Controller for a Milliscale Robot
  in a Constrained Environment","This work presents a reinforcement learning-based switching control mechanism
to autonomously move a ferromagnetic object (representing a milliscale robot)
around obstacles within a constrained environment in the presence of
disturbances. This mechanism can be used to navigate objects (e.g., capsule
endoscopy, swarms of drug particles) through complex environments when active
control is a necessity but where direct manipulation can be hazardous. The
proposed control scheme consists of a switching control architecture
implemented by two sub-controllers. The first sub-controller is designed to
employs the robot's inverse kinematic solutions to do an environment search of
the to-be-carried ferromagnetic particle while being robust to disturbances.
The second sub-controller uses a customized rainbow algorithm to control a
robotic arm, i.e., the UR5 robot, to carry a ferromagnetic particle to a
desired position through a constrained environment. For the customized Rainbow
algorithm, Quantile Huber loss from the Implicit Quantile Networks (IQN)
algorithm and ResNet are employed. The proposed controller is first trained and
tested in a real-time physics simulation engine (PyBullet). Afterward, the
trained controller is transferred to a UR5 robot to remotely transport a
ferromagnetic particle in a real-world scenario to demonstrate the
applicability of the proposed approach. The experimental results show an
average success rate of 98.86\% calculated over 30 episodes for randomly
generated trajectories.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.12142v1,2021-11-23T20:28:07Z,2021-11-23T20:28:07Z,"Phenomenological classification of the Zwicky Transient Facility
  astronomical event alerts","The Zwicky Transient Facility (ZTF), a state-of-the-art optical robotic sky
survey, registers on the order of a million transient events - such as
supernova explosions, changes in brightness of variable sources, or moving
object detections - every clear night, and generates associated real-time
alerts. We present Alert-Classifying Artificial Intelligence (ACAI), an
open-source deep-learning framework for the phenomenological classification of
ZTF alerts. ACAI uses a set of five binary classifiers to characterize objects
which, in combination with the auxiliary/contextual event information available
from alert brokers, provides a powerful tool for alert stream filtering
tailored to different science cases, including early identification of
supernova-like and anomalous transient events. We report on the performance of
ACAI during the first months of deployment in a production setting.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.07125v1,2021-11-13T14:50:48Z,2021-11-13T14:50:48Z,"MC-CIM: Compute-in-Memory with Monte-Carlo Dropouts for Bayesian Edge
  Intelligence","We propose MC-CIM, a compute-in-memory (CIM) framework for robust, yet low
power, Bayesian edge intelligence. Deep neural networks (DNN) with
deterministic weights cannot express their prediction uncertainties, thereby
pose critical risks for applications where the consequences of mispredictions
are fatal such as surgical robotics. To address this limitation, Bayesian
inference of a DNN has gained attention. Using Bayesian inference, not only the
prediction itself, but the prediction confidence can also be extracted for
planning risk-aware actions. However, Bayesian inference of a DNN is
computationally expensive, ill-suited for real-time and/or edge deployment. An
approximation to Bayesian DNN using Monte Carlo Dropout (MC-Dropout) has shown
high robustness along with low computational complexity. Enhancing the
computational efficiency of the method, we discuss a novel CIM module that can
perform in-memory probabilistic dropout in addition to in-memory weight-input
scalar product to support the method. We also propose a compute-reuse
reformulation of MC-Dropout where each successive instance can utilize the
product-sum computations from the previous iteration. Even more, we discuss how
the random instances can be optimally ordered to minimize the overall
MC-Dropout workload by exploiting combinatorial optimization methods.
Application of the proposed CIM-based MC-Dropout execution is discussed for
MNIST character recognition and visual odometry (VO) of autonomous drones. The
framework reliably gives prediction confidence amidst non-idealities imposed by
MC-CIM to a good extent. Proposed MC-CIM with 16x31 SRAM array, 0.85 V supply,
16nm low-standby power (LSTP) technology consumes 27.8 pJ for 30 MC-Dropout
instances of probabilistic inference in its most optimal computing and
peripheral configuration, saving 43% energy compared to typical execution.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.06953v1,2021-11-12T21:38:25Z,2021-11-12T21:38:25Z,"Distributed on-line reinforcement learning in a swarm of sterically
  interacting robots","While naturally occurring swarms thrive when crowded, physical interactions
in robotic swarms are either avoided or carefully controlled, thus limiting
their operational density. Designing behavioral strategies under such
circumstances remains a challenge, even though it may offer an opportunity for
exploring morpho-functional self-organized behaviors. In this paper, we
explicitly consider dense swarms of robots where physical interactions are
inevitable. We demonstrate experimentally that an a priori minor difference in
the mechanical design of the robots leads to important differences in their
dynamical behaviors when they evolve in crowded environments. We design
Morphobots, which are Kilobots augmented with a 3D-printed exoskeleton. The
exoskeleton not only significantly improves the motility and stability of the
Kilobots, it also allows to encode physically two contrasting dynamical
behaviors in response to an external force or a collision. This difference
translates into distinct performances during self-organized aggregation when
addressing a phototactic task. Having characterized the dynamical mechanism at
the root of these differences, we implement a decentralized on-line
evolutionary reinforcement learning algorithm in a swarm of Morphobots. We
demonstrate the learning efficiency and show that the learning reduces the
dependency on the morphology. We present a kinetic model that links the reward
function to an effective phototactic policy. Our results are of relevance for
the deployment of robust swarms of robots in a real environment, where robots
are deemed to collide, and to be exposed to external forces.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.05934v1,2021-11-10T20:46:23Z,2021-11-10T20:46:23Z,"A soft thumb-sized vision-based sensor with accurate all-round force
  perception","Vision-based haptic sensors have emerged as a promising approach to robotic
touch due to affordable high-resolution cameras and successful computer-vision
techniques. However, their physical design and the information they provide do
not yet meet the requirements of real applications. We present a robust, soft,
low-cost, vision-based, thumb-sized 3D haptic sensor named Insight: it
continually provides a directional force-distribution map over its entire
conical sensing surface. Constructed around an internal monocular camera, the
sensor has only a single layer of elastomer over-molded on a stiff frame to
guarantee sensitivity, robustness, and soft contact. Furthermore, Insight is
the first system to combine photometric stereo and structured light using a
collimator to detect the 3D deformation of its easily replaceable flexible
outer shell. The force information is inferred by a deep neural network that
maps images to the spatial distribution of 3D contact force (normal and shear).
Insight has an overall spatial resolution of 0.4 mm, force magnitude accuracy
around 0.03 N, and force direction accuracy around 5 degrees over a range of
0.03--2 N for numerous distinct contacts with varying contact area. The
presented hardware and software design concepts can be transferred to a wide
variety of robot parts.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.02580v3,2022-03-25T18:04:15Z,2021-11-04T01:43:26Z,Deep Direct Visual Servoing of Tendon-Driven Continuum Robots,"Vision-based control provides a significant potential for the end-point
positioning of continuum robots under physical sensing limitations. Traditional
visual servoing requires feature extraction and tracking followed by full or
partial pose estimation, limiting the controller's efficiency. We hypothesize
that employing deep learning models and implementing direct visual servoing can
effectively resolve the issue by eliminating such intermediate steps, enabling
control of a continuum robot without requiring an exact system model. This
paper presents the control of a single-section tendon-driven continuum robot
using a modified VGG-16 deep learning network and an eye-in-hand direct visual
servoing approach. The proposed algorithm is first developed in Blender
software using only one input image of the target and then implemented on a
real robot. The convergence and accuracy of the results in normal, shadowed,
and occluded scenes demonstrate the effectiveness and robustness of the
proposed controller.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.02156v1,2021-11-03T11:53:57Z,2021-11-03T11:53:57Z,"Continual Learning of Semantic Segmentation using Complementary 2D-3D
  Data Representations","Semantic segmentation networks are usually pre-trained and not updated during
deployment. As a consequence, misclassifications commonly occur if the
distribution of the training data deviates from the one encountered during the
robot's operation. We propose to mitigate this problem by adapting the neural
network to the robot's environment during deployment, without any need for
external supervision. Leveraging complementary data representations, we
generate a supervision signal, by probabilistically accumulating consecutive 2D
semantic predictions in a volumetric 3D map. We then retrain the network on
renderings of the accumulated semantic map, effectively resolving ambiguities
and enforcing multi-view consistency through the 3D representation. To preserve
the previously-learned knowledge while performing network adaptation, we employ
a continual learning strategy based on experience replay. Through extensive
experimental evaluation, we show successful adaptation to real-world indoor
scenes both on the ScanNet dataset and on in-house data recorded with an RGB-D
sensor. Our method increases the segmentation performance on average by 11.8%
compared to the fixed pre-trained neural network, while effectively retaining
knowledge from the pre-training dataset.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2111.00789v1,2021-11-01T09:37:34Z,2021-11-01T09:37:34Z,Learning Inertial Odometry for Dynamic Legged Robot State Estimation,"This paper introduces a novel proprioceptive state estimator for legged
robots based on a learned displacement measurement from IMU data. Recent
research in pedestrian tracking has shown that motion can be inferred from
inertial data using convolutional neural networks. A learned inertial
displacement measurement can improve state estimation in challenging scenarios
where leg odometry is unreliable, such as slipping and compressible terrains.
Our work learns to estimate a displacement measurement from IMU data which is
then fused with traditional leg odometry. Our approach greatly reduces the
drift of proprioceptive state estimation, which is critical for legged robots
deployed in vision and lidar denied environments such as foggy sewers or dusty
mines. We compared results from an EKF and an incremental fixed-lag factor
graph estimator using data from several real robot experiments crossing
challenging terrains. Our results show a reduction of relative pose error by
37% in challenging scenarios when compared to a traditional kinematic-inertial
estimator without learned measurement. We also demonstrate a 22% reduction in
error when used with vision systems in visually degraded environments such as
an underground mine.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.15245v1,2021-10-28T16:04:01Z,2021-10-28T16:04:01Z,"From Machine Learning to Robotics: Challenges and Opportunities for
  Embodied Intelligence","Machine learning has long since become a keystone technology, accelerating
science and applications in a broad range of domains. Consequently, the notion
of applying learning methods to a particular problem set has become an
established and valuable modus operandi to advance a particular field. In this
article we argue that such an approach does not straightforwardly extended to
robotics -- or to embodied intelligence more generally: systems which engage in
a purposeful exchange of energy and information with a physical environment. In
particular, the purview of embodied intelligent agents extends significantly
beyond the typical considerations of main-stream machine learning approaches,
which typically (i) do not consider operation under conditions significantly
different from those encountered during training; (ii) do not consider the
often substantial, long-lasting and potentially safety-critical nature of
interactions during learning and deployment; (iii) do not require ready
adaptation to novel tasks while at the same time (iv) effectively and
efficiently curating and extending their models of the world through targeted
and deliberate actions. In reality, therefore, these limitations result in
learning-based systems which suffer from many of the same operational
shortcomings as more traditional, engineering-based approaches when deployed on
a robot outside a well defined, and often narrow operating envelope. Contrary
to viewing embodied intelligence as another application domain for machine
learning, here we argue that it is in fact a key driver for the advancement of
machine learning technology. In this article our goal is to highlight
challenges and opportunities that are specific to embodied intelligence and to
propose research directions which may significantly advance the
state-of-the-art in robot learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.12706v1,2021-10-25T07:36:54Z,2021-10-25T07:36:54Z,"A Nearly Optimal Chattering Reduction Method of Sliding Mode Control
  With an Application to a Two-wheeled Mobile Robot","The problem we focus on in this paper is to find a nearly optimal sliding
mode controller of continuous-time nonlinear multiple-input multiple-output
(MIMO) systems that can both reduce chattering and minimize the cost function,
which is a measure of the performance index of dynamics systems. First, the
deficiency of chattering in traditional SMC and the quasi-SMC method are
analyzed in this paper. In quasi-SMC, the signum function of the traditional
SMC is replaced with a continuous saturation function. Then, a chattering
reduction algorithm based on integral reinforcement learning (IRL) is proposed.
Under an initial sliding mode controller, the proposed method can learn the
nearly optimal saturation function using policy iteration. To satisfy the
requirement of the learned saturation function, we treat the problem of
training the saturation function as the constraint of an optimization problem.
The online neural network implementation of the proposed algorithm is presented
based on symmetric radius basis functions and a regularized batch least-squares
(BLS) algorithm to train the control law in this paper. Finally, two examples
are simulated to verify the effectiveness of the proposed method. The second
example is an application to a real-world dynamics model -- a two-wheeled
variable structure robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.05457v1,2021-10-11T17:48:18Z,2021-10-11T17:48:18Z,"Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies in
  the Real World","Legged robots are physically capable of traversing a wide range of
challenging environments, but designing controllers that are sufficiently
robust to handle this diversity has been a long-standing challenge in robotics.
Reinforcement learning presents an appealing approach for automating the
controller design process and has been able to produce remarkably robust
controllers when trained in a suitable range of environments. However, it is
difficult to predict all likely conditions the robot will encounter during
deployment and enumerate them at training-time. What if instead of training
controllers that are robust enough to handle any eventuality, we enable the
robot to continually learn in any setting it finds itself in? This kind of
real-world reinforcement learning poses a number of challenges, including
efficiency, safety, and autonomy. To address these challenges, we propose a
practical robot reinforcement learning system for fine-tuning locomotion
policies in the real world. We demonstrate that a modest amount of real-world
training can substantially improve performance during deployment, and this
enables a real A1 quadrupedal robot to autonomously fine-tune multiple
locomotion skills in a range of environments, including an outdoor lawn and a
variety of indoor terrains.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.04697v1,2021-10-10T03:51:39Z,2021-10-10T03:51:39Z,"An Augmented Reality Platform for Introducing Reinforcement Learning to
  K-12 Students with Robots","Interactive reinforcement learning, where humans actively assist during an
agent's learning process, has the promise to alleviate the sample complexity
challenges of practical algorithms. However, the inner workings and state of
the robot are typically hidden from the teacher when humans provide feedback.
To create a common ground between the human and the learning robot, in this
paper, we propose an Augmented Reality (AR) system that reveals the hidden
state of the learning to the human users. This paper describes our system's
design and implementation and concludes with a discussion on two directions for
future work which we are pursuing: 1) use of our system in AI education
activities at the K-12 level; and 2) development of a framework for an AR-based
human-in-the-loop reinforcement learning, where the human teacher can see
sensory and cognitive representations of the robot overlaid in the real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.04003v2,2021-12-06T15:10:15Z,2021-10-08T09:59:12Z,Learning to Centralize Dual-Arm Assembly,"Robotic manipulators are widely used in modern manufacturing processes.
However, their deployment in unstructured environments remains an open problem.
To deal with the variety, complexity, and uncertainty of real-world
manipulation tasks, it is essential to develop a flexible framework with
reduced assumptions on the environment characteristics. In recent years,
reinforcement learning (RL) has shown great results for single-arm robotic
manipulation. However, research focusing on dual-arm manipulation is still
rare. From a classical control perspective, solving such tasks often involves
complex modeling of interactions between two manipulators and the objects
encountered in the tasks, as well as the two robots coupling at a control
level. Instead, in this work, we explore the applicability of model-free RL to
dual-arm assembly. As we aim to contribute towards an approach that is not
limited to dual-arm assembly, but dual-arm manipulation in general, we keep
modeling efforts at a minimum. Hence, to avoid modeling the interaction between
the two robots and the used assembly tools, we present a modular approach with
two decentralized single-arm controllers which are coupled using a single
centralized learned policy. We reduce modeling effort to a minimum by using
sparse rewards only. Our architecture enables successful assembly and simple
transfer from simulation to the real world. We demonstrate the effectiveness of
the framework on dual-arm peg-in-hole and analyze sample efficiency and success
rates for different action spaces. Moreover, we compare results on different
clearances and showcase disturbance recovery and robustness, when dealing with
position uncertainties. Finally we zero-shot transfer policies trained in
simulation to the real world and evaluate their performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.02414v1,2021-10-05T23:38:31Z,2021-10-05T23:38:31Z,"Imaginary Hindsight Experience Replay: Curious Model-based Learning for
  Sparse Reward Tasks","Model-based reinforcement learning is a promising learning strategy for
practical robotic applications due to its improved data-efficiency versus
model-free counterparts. However, current state-of-the-art model-based methods
rely on shaped reward signals, which can be difficult to design and implement.
To remedy this, we propose a simple model-based method tailored for
sparse-reward multi-goal tasks that foregoes the need for complicated reward
engineering. This approach, termed Imaginary Hindsight Experience Replay,
minimises real-world interactions by incorporating imaginary data into policy
updates. To improve exploration in the sparse-reward setting, the policy is
trained with standard Hindsight Experience Replay and endowed with
curiosity-based intrinsic rewards. Upon evaluation, this approach provides an
order of magnitude increase in data-efficiency on average versus the
state-of-the-art model-free method in the benchmark OpenAI Gym Fetch Robotics
tasks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2110.00336v1,2021-10-01T11:59:33Z,2021-10-01T11:59:33Z,Learning from Demonstrations for Autonomous Soft-tissue Retraction,"The current research focus in Robot-Assisted Minimally Invasive Surgery
(RAMIS) is directed towards increasing the level of robot autonomy, to place
surgeons in a supervisory position. Although Learning from Demonstrations (LfD)
approaches are among the preferred ways for an autonomous surgical system to
learn expert gestures, they require a high number of demonstrations and show
poor generalization to the variable conditions of the surgical environment. In
this work, we propose an LfD methodology based on Generative Adversarial
Imitation Learning (GAIL) that is built on a Deep Reinforcement Learning (DRL)
setting. GAIL combines generative adversarial networks to learn the
distribution of expert trajectories with a DRL setting to ensure generalisation
of trajectories providing human-like behaviour. We consider automation of
tissue retraction, a common RAMIS task that involves soft tissues manipulation
to expose a region of interest. In our proposed methodology, a small set of
expert trajectories can be acquired through the da Vinci Research Kit (dVRK)
and used to train the proposed LfD method inside a simulated environment.
Results indicate that our methodology can accomplish the tissue retraction task
with human-like behaviour while being more sample-efficient than the baseline
DRL method. Towards the end, we show that the learnt policies can be
successfully transferred to the real robotic platform and deployed for soft
tissue retraction on a synthetic phantom.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.14549v2,2022-07-24T01:55:19Z,2021-09-29T16:48:05Z,"Vision-Guided Quadrupedal Locomotion in the Wild with Multi-Modal Delay
  Randomization","Developing robust vision-guided controllers for quadrupedal robots in complex
environments, with various obstacles, dynamical surroundings and uneven
terrains, is very challenging. While Reinforcement Learning (RL) provides a
promising paradigm for agile locomotion skills with vision inputs in
simulation, it is still very challenging to deploy the RL policy in the real
world. Our key insight is that aside from the discrepancy in the domain gap, in
visual appearance between the simulation and the real world, the latency from
the control pipeline is also a major cause of difficulty. In this paper, we
propose Multi-Modal Delay Randomization (MMDR) to address this issue when
training RL agents. Specifically, we simulate the latency of real hardware by
using past observations, sampled with randomized periods, for both
proprioception and vision. We train the RL policy for end-to-end control in a
physical simulator without any predefined controller or reference motion, and
directly deploy it on the real A1 quadruped robot running in the wild. We
evaluate our method in different outdoor environments with complex terrains and
obstacles. We demonstrate the robot can smoothly maneuver at a high speed,
avoid the obstacles, and show significant improvement over the baselines. Our
project page with videos is at https://mehooz.github.io/mmdr-wild/.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.13751v2,2021-11-25T14:01:38Z,2021-09-28T14:11:36Z,StereoSpike: Depth Learning with a Spiking Neural Network,"Depth estimation is an important computer vision task, useful in particular
for navigation in autonomous vehicles, or for object manipulation in robotics.
Here we solved it using an end-to-end neuromorphic approach, combining two
event-based cameras and a Spiking Neural Network (SNN) with a slightly modified
U-Net-like encoder-decoder architecture, that we named StereoSpike. More
specifically, we used the Multi Vehicle Stereo Event Camera Dataset (MVSEC). It
provides a depth ground-truth, which was used to train StereoSpike in a
supervised manner, using surrogate gradient descent. We propose a novel readout
paradigm to obtain a dense analog prediction -- the depth of each pixel -- from
the spikes of the decoder. We demonstrate that this architecture generalizes
very well, even better than its non-spiking counterparts, leading to
state-of-the-art test accuracy. To the best of our knowledge, it is the first
time that such a large-scale regression problem is solved by a fully spiking
network. Finally, we show that low firing rates (<10%) can be obtained via
regularization, with a minimal cost in accuracy. This means that StereoSpike
could be efficiently implemented on neuromorphic chips, opening the door for
low power and real time embedded systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.13570v2,2022-03-03T13:22:21Z,2021-09-28T09:00:55Z,"Adaptive Informative Path Planning Using Deep Reinforcement Learning for
  UAV-based Active Sensing","Aerial robots are increasingly being utilized for environmental monitoring
and exploration. However, a key challenge is efficiently planning paths to
maximize the information value of acquired data as an initially unknown
environment is explored. To address this, we propose a new approach for
informative path planning based on deep reinforcement learning (RL). Combining
recent advances in RL and robotic applications, our method combines tree search
with an offline-learned neural network predicting informative sensing actions.
We introduce several components making our approach applicable for robotic
tasks with high-dimensional state and large action spaces. By deploying the
trained network during a mission, our method enables sample-efficient online
replanning on platforms with limited computational resources. Simulations show
that our approach performs on par with existing methods while reducing runtime
by 8-10x. We validate its performance using real-world surface temperature
data.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.13162v1,2021-09-27T16:21:46Z,2021-09-27T16:21:46Z,"Precision fruit tree pruning using a learned hybrid vision/interaction
  controller","Robotic tree pruning requires highly precise manipulator control in order to
accurately align a cutting implement with the desired pruning point at the
correct angle. Simultaneously, the robot must avoid applying excessive force to
rigid parts of the environment such as trees, support posts, and wires. In this
paper, we propose a hybrid control system that uses a learned vision-based
controller to initially align the cutter with the desired pruning point, taking
in images of the environment and outputting control actions. This controller is
trained entirely in simulation, but transfers easily to real trees via a neural
network which transforms raw images into a simplified, segmented
representation. Once contact is established, the system hands over control to
an interaction controller that guides the cutter pivot point to the branch
while minimizing interaction forces. With this simple, yet novel, approach we
demonstrate an improvement of over 30 percentage points in accuracy over a
baseline controller that uses camera depth data.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.11093v2,2021-09-26T07:38:44Z,2021-09-23T01:07:22Z,"Prediction of Metacarpophalangeal joint angles and Classification of
  Hand configurations based on Ultrasound Imaging of the Forearm","With the advancement in computing and robotics, it is necessary to develop
fluent and intuitive methods for interacting with digital systems, AR/VR
interfaces, and physical robotic systems. Hand movement recognition is widely
used to enable this interaction. Hand configuration classification and
Metacarpophalangeal (MCP) joint angle detection are important for a
comprehensive reconstruction of the hand motion. Surface electromyography and
other technologies have been used for the detection of hand motions. Ultrasound
images of the forearm offer a way to visualize the internal physiology of the
hand from a musculoskeletal perspective. Recent work has shown that these
images can be classified using machine learning to predict various hand
configurations. In this paper, we propose a Convolutional Neural Network (CNN)
based deep learning pipeline for predicting the MCP joint angles. We supplement
our results by using a Support Vector Classifier (SVC) to classify the
ultrasound information into several predefined hand configurations based on
activities of daily living (ADL). Ultrasound data from the forearm was obtained
from 6 subjects who were instructed to move their hands according to predefined
hand configurations relevant to ADLs. Motion capture data was acquired as the
ground truth for hand movements at different speeds (0.5 Hz, 1 Hz, & 2 Hz) for
the index, middle, ring, and pinky fingers. We were able to get promising SVC
classification results on a subset of our collected data set. We demonstrated a
correspondence between the predicted MCP joint angles and the actual MCP joint
angles for the fingers, with an average root mean square error of 7.35 degrees.
We implemented a low latency (6.25 - 9.1 Hz) pipeline for the prediction of
both MCP joint angles and hand configuration estimation aimed at real-time
control of digital devices, AR/VR interfaces, and physical robots.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.10719v2,2021-09-27T10:56:50Z,2021-09-22T13:22:40Z,Autonomous Blimp Control using Deep Reinforcement Learning,"Aerial robot solutions are becoming ubiquitous for an increasing number of
tasks. Among the various types of aerial robots, blimps are very well suited to
perform long-duration tasks while being energy efficient, relatively silent and
safe. To address the blimp navigation and control task, in our recent work, we
have developed a software-in-the-loop simulation and a PID-based controller for
large blimps in the presence of wind disturbance. However, blimps have a
deformable structure and their dynamics are inherently non-linear and
time-delayed, often resulting in large trajectory tracking errors. Moreover,
the buoyancy of a blimp is constantly changing due to changes in the ambient
temperature and pressure. In the present paper, we explore a deep reinforcement
learning (DRL) approach to address these issues. We train only in simulation,
while keeping conditions as close as possible to the real-world scenario. We
derive a compact state representation to reduce the training time and a
discrete action space to enforce control smoothness. Our initial results in
simulation show a significant potential of DRL in solving the blimp control
task and robustness against moderate wind and parameter uncertainty. Extensive
experiments are presented to study the robustness of our approach. We also
openly provide the source code of our approach.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.10460v1,2021-09-21T23:46:37Z,2021-09-21T23:46:37Z,"Graph-based Cluttered Scene Generation and Interactive Exploration using
  Deep Reinforcement Learning","We introduce a novel method to teach a robotic agent to interactively explore
cluttered yet structured scenes, such as kitchen pantries and grocery shelves,
by leveraging the physical plausibility of the scene. We propose a novel
learning framework to train an effective scene exploration policy to discover
hidden objects with minimal interactions. First, we define a novel scene
grammar to represent structured clutter. Then we train a Graph Neural Network
(GNN) based Scene Generation agent using deep reinforcement learning (deep RL),
to manipulate this Scene Grammar to create a diverse set of stable scenes, each
containing multiple hidden objects. Given such cluttered scenes, we then train
a Scene Exploration agent, using deep RL, to uncover hidden objects by
interactively rearranging the scene. We show that our learned agents hide and
discover significantly more objects than the baselines. We present quantitative
results that prove the generalization capabilities of our agents. We also
demonstrate sim-to-real transfer by successfully deploying the learned policy
on a real UR10 robot to explore real-world cluttered scenes. The supplemental
video can be found at https://www.youtube.com/watch?v=T2Jo7wwaXss.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.08642v1,2021-09-17T16:52:03Z,2021-09-17T16:52:03Z,Efficient State Representation Learning for Dynamic Robotic Scenarios,"While the rapid progress of deep learning fuels end-to-end reinforcement
learning (RL), direct application, especially in high-dimensional space like
robotic scenarios still suffers from high sample efficiency. Therefore State
Representation Learning (SRL) is proposed to specifically learn to encode
task-relevant features from complex sensory data into low-dimensional states.
However, the pervasive implementation of SRL is usually conducted by a
decoupling strategy in which the observation-state mapping is learned
separately, which is prone to over-fit. To handle such problem, we present a
new algorithm called Policy Optimization via Abstract Representation which
integrates SRL into the original RL scale. Firstly, We engage RL loss to assist
in updating SRL model so that the states can evolve to meet the demand of
reinforcement learning and maintain a good physical interpretation. Secondly,
we introduce a dynamic parameter adjustment mechanism so that both models can
efficiently adapt to each other. Thirdly, we introduce a new prior called
domain resemblance to leverage expert demonstration to train the SRL model.
Finally, we provide a real-time access by state graph to monitor the course of
learning. Results show that our algorithm outperforms the PPO baselines and
decoupling strategies in terms of sample efficiency and final rewards. Thus our
model can efficiently deal with tasks in high dimensions and facilitate
training real-life robots directly from scratch.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.07165v1,2021-09-15T09:00:56Z,2021-09-15T09:00:56Z,3D Annotation Of Arbitrary Objects In The Wild,"Recent years have produced a variety of learning based methods in the context
of computer vision and robotics. Most of the recently proposed methods are
based on deep learning, which require very large amounts of data compared to
traditional methods. The performance of the deep learning methods are largely
dependent on the data distribution they were trained on, and it is important to
use data from the robot's actual operating domain during training. Therefore,
it is not possible to rely on pre-built, generic datasets when deploying robots
in real environments, creating a need for efficient data collection and
annotation in the specific operating conditions the robots will operate in. The
challenge is then: how do we reduce the cost of obtaining such datasets to a
point where we can easily deploy our robots in new conditions, environments and
to support new sensors? As an answer to this question, we propose a data
annotation pipeline based on SLAM, 3D reconstruction, and 3D-to-2D geometry.
The pipeline allows creating 3D and 2D bounding boxes, along with per-pixel
annotations of arbitrary objects without needing accurate 3D models of the
objects prior to data collection and annotation. Our results showcase almost
90% Intersection-over-Union (IoU) agreement on both semantic segmentation and
2D bounding box detection across a variety of objects and scenes, while
speeding up the annotation process by several orders of magnitude compared to
traditional manual annotation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.08521v2,2022-02-04T14:45:40Z,2021-09-14T18:00:07Z,Focus on Impact: Indoor Exploration with Intrinsic Motivation,"Exploration of indoor environments has recently experienced a significant
interest, also thanks to the introduction of deep neural agents built in a
hierarchical fashion and trained with Deep Reinforcement Learning (DRL) on
simulated environments. Current state-of-the-art methods employ a dense
extrinsic reward that requires the complete a priori knowledge of the layout of
the training environment to learn an effective exploration policy. However,
such information is expensive to gather in terms of time and resources. In this
work, we propose to train the model with a purely intrinsic reward signal to
guide exploration, which is based on the impact of the robot's actions on its
internal representation of the environment. So far, impact-based rewards have
been employed for simple tasks and in procedurally generated synthetic
environments with countable states. Since the number of states observable by
the agent in realistic indoor environments is non-countable, we include a
neural-based density model and replace the traditional count-based
regularization with an estimated pseudo-count of previously visited states. The
proposed exploration approach outperforms DRL-based competitors relying on
intrinsic rewards and surpasses the agents trained with a dense extrinsic
reward computed with the environment layouts. We also show that a robot
equipped with the proposed approach seamlessly adapts to point-goal navigation
and real-world deployment.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.06668v4,2022-07-12T18:27:19Z,2021-09-14T13:16:33Z,Exploration in Deep Reinforcement Learning: A Comprehensive Survey,"Deep Reinforcement Learning (DRL) and Deep Multi-agent Reinforcement Learning
(MARL) have achieved significant successes across a wide range of domains,
including game AI, autonomous vehicles, robotics, and so on. However, DRL and
deep MARL agents are widely known to be sample inefficient that millions of
interactions are usually needed even for relatively simple problem settings,
thus preventing the wide application and deployment in real-industry scenarios.
One bottleneck challenge behind is the well-known exploration problem, i.e.,
how efficiently exploring the environment and collecting informative
experiences that could benefit policy learning towards the optimal ones. This
problem becomes more challenging in complex environments with sparse rewards,
noisy distractions, long horizons, and non-stationary co-learners. In this
paper, we conduct a comprehensive survey on existing exploration methods for
both single-agent and multi-agent RL. We start the survey by identifying
several key challenges to efficient exploration. Beyond the above two main
branches, we also include other notable exploration methods with different
ideas and techniques. In addition to algorithmic analysis, we provide a
comprehensive and unified empirical comparison of different exploration methods
for DRL on a set of commonly used benchmarks. According to our algorithmic and
empirical investigation, we finally summarize the open problems of exploration
in DRL and deep MARL and point out a few future directions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.06523v3,2022-07-07T08:31:35Z,2021-09-14T08:42:29Z,"Dependability Analysis of Deep Reinforcement Learning based Robotics and
  Autonomous Systems through Probabilistic Model Checking","While Deep Reinforcement Learning (DRL) provides transformational
capabilities to the control of Robotics and Autonomous Systems (RAS), the
black-box nature of DRL and uncertain deployment environments of RAS pose new
challenges on its dependability. Although existing works impose constraints on
the DRL policy to ensure successful completion of the mission, it is far from
adequate to assess the DRL-driven RAS in a holistic way considering all
dependability properties. In this paper, we formally define a set of
dependability properties in temporal logic and construct a Discrete-Time Markov
Chain (DTMC) to model the dynamics of risk/failures of a DRL-driven RAS
interacting with the stochastic environment. We then conduct Probabilistic
Model Checking (PMC) on the designed DTMC to verify those properties. Our
experimental results show that the proposed method is effective as a holistic
assessment framework while uncovering conflicts between the properties that may
need trade-offs in training. Moreover, we find that the standard DRL training
cannot improve dependability properties, thus requiring bespoke optimisation
objectives. Finally, our method offers sensitivity analysis of dependability
properties to disturbance levels from environments, providing insights for the
assurance of real RAS.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.06325v3,2022-02-25T16:12:56Z,2021-09-13T21:09:28Z,"safe-control-gym: a Unified Benchmark Suite for Safe Learning-based
  Control and Reinforcement Learning","In recent years, both reinforcement learning and learning-based control -- as
well as the study of their safety, which is crucial for deployment in
real-world robots -- have gained significant traction. However, to adequately
gauge the progress and applicability of new results, we need the tools to
equitably compare the approaches proposed by the controls and reinforcement
learning communities. Here, we propose a new open-source benchmark suite,
called safe-control-gym, supporting both model-based and data-based control
techniques. We provide implementations for three dynamic systems -- the
cart-pole, the 1D, and 2D quadrotor -- and two control tasks -- stabilization
and trajectory tracking. We propose to extend OpenAI's Gym API -- the de facto
standard in reinforcement learning research -- with (i) the ability to specify
(and query) symbolic dynamics and (ii) constraints, and (iii) (repeatably)
inject simulated disturbances in the control inputs, state measurements, and
inertial properties. To demonstrate our proposal and in an attempt to bring
research communities closer together, we show how to use safe-control-gym to
quantitatively compare the control performance, data efficiency, and safety of
multiple approaches from the fields of traditional control, learning-based
control, and reinforcement learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.05795v1,2021-09-13T09:17:11Z,2021-09-13T09:17:11Z,"A Q-learning Control Method for a Soft Robotic Arm Utilizing Training
  Data from a Rough Simulator","It is challenging to control a soft robot, where reinforcement learning
methods have been applied with promising results. However, due to the poor
sample efficiency, reinforcement learning methods require a large collection of
training data, which limits their applications. In this paper, we propose a
Q-learning controller for a physical soft robot, in which pre-trained models
using data from a rough simulator are applied to improve the performance of the
controller. We implement the method on our soft robot, i.e., Honeycomb
Pneumatic Network (HPN) arm. The experiments show that the usage of pre-trained
models can not only reduce the amount of the real-world training data, but also
greatly improve its accuracy and convergence rate.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.04966v2,2021-09-15T00:57:42Z,2021-09-10T16:04:54Z,"Binarized P-Network: Deep Reinforcement Learning of Robot Control from
  Raw Images on FPGA","This paper explores a Deep Reinforcement Learning (DRL) approach for
designing image-based control for edge robots to be implemented on Field
Programmable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than
CPUs and GPUs, a typical DRL method cannot be applied since they are composed
of many Logic Blocks (LBs) for high-speed logical operations but low-speed
real-number operations. To cope with this problem, we propose a novel DRL
algorithm called Binarized P-Network (BPN), which learns image-input control
policies using Binarized Convolutional Neural Networks (BCNNs). To alleviate
the instability of reinforcement learning caused by a BCNN with low function
approximation accuracy, our BPN adopts a robust value update scheme called
Conservative Value Iteration, which is tolerant of function approximation
errors. We confirmed the BPN's effectiveness through applications to a visual
tracking task in simulation and real-robot experiments with FPGA.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.04205v2,2022-07-07T16:10:20Z,2021-09-09T12:26:04Z,"DAN: Decentralized Attention-based Neural Network for the MinMax
  Multiple Traveling Salesman Problem","The multiple traveling salesman problem (mTSP) is a well-known NP-hard
problem with numerous real-world applications. In particular, this work
addresses MinMax mTSP, where the objective is to minimize the max tour length
among all agents. Many robotic deployments require recomputing potentially
large mTSP instances frequently, making the natural trade-off between computing
time and solution quality of great importance. However, exact and heuristic
algorithms become inefficient as the number of cities increases, due to their
computational complexity. Encouraged by the recent developments in deep
reinforcement learning (dRL), this work approaches the mTSP as a cooperative
task and introduces DAN, a decentralized attention-based neural method that
aims at tackling this key trade-off. In DAN, agents learn fully decentralized
policies to collaboratively construct a tour, by predicting each other's future
decisions. Our model relies on the Transformer architecture and is trained
using multi-agent RL with parameter sharing, providing natural scalability to
the numbers of agents and cities. Our experimental results on small- to
large-scale mTSP instances ($50$ to $1000$ cities and $5$ to $20$ agents) show
that DAN is able to match or outperform state-of-the-art solvers while keeping
planning times low. In particular, given the same computation time budget, DAN
outperforms all conventional and dRL-based baselines on larger-scale instances
(more than 100 cities, more than 5 agents), and exhibits enhanced agent
collaboration. A video explaining our approach and presenting our results is
available at \url{https://youtu.be/xi3cLsDsLvs}.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2109.02823v2,2022-04-28T22:19:48Z,2021-09-07T02:26:54Z,Learning Visual-Audio Representations for Voice-Controlled Robots,"Inspired by sensorimotor theory, we propose a novel pipeline for
task-oriented voice-controlled robots. Previous method relies on a large amount
of labels as well as task-specific reward functions. Not only can such an
approach hardly be improved after the deployment, but also has limited
generalization across robotic platforms and tasks. To address these problems,
we learn a visual-audio representation (VAR) that associates images and sound
commands with minimal supervision. Using this representation, we generate an
intrinsic reward function to learn robot policies with reinforcement learning,
which eliminates the laborious reward engineering process. We demonstrate our
approach on various robotic platforms, where the robots hear an audio command,
identify the associated target object, and perform precise control to fulfill
the sound command. We show that our method outperforms previous work across
various sound types and robotic tasks even with fewer amount of labels. We
successfully deploy the policy learned in a simulator to a real Kinova Gen3. We
also demonstrate that our VAR and the intrinsic reward function allows the
robot to improve itself using only a small amount of labeled data collected in
the real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.13680v2,2021-09-07T01:18:16Z,2021-08-31T08:37:58Z,Learning Practically Feasible Policies for Online 3D Bin Packing,"We tackle the Online 3D Bin Packing Problem, a challenging yet practically
useful variant of the classical Bin Packing Problem. In this problem, the items
are delivered to the agent without informing the full sequence information.
Agent must directly pack these items into the target bin stably without
changing their arrival order, and no further adjustment is permitted. Online
3D-BPP can be naturally formulated as Markov Decision Process (MDP). We adopt
deep reinforcement learning, in particular, the on-policy actor-critic
framework, to solve this MDP with constrained action space. To learn a
practically feasible packing policy, we propose three critical designs. First,
we propose an online analysis of packing stability based on a novel stacking
tree. It attains a high analysis accuracy while reducing the computational
complexity from $O(N^2)$ to $O(N \log N)$, making it especially suited for RL
training. Second, we propose a decoupled packing policy learning for different
dimensions of placement which enables high-resolution spatial discretization
and hence high packing precision. Third, we introduce a reward function that
dictates the robot to place items in a far-to-near order and therefore
simplifies the collision avoidance in movement planning of the robotic arm.
Furthermore, we provide a comprehensive discussion on several key implemental
issues. The extensive evaluation demonstrates that our learned policy
outperforms the state-of-the-art methods significantly and is practically
usable for real-world applications.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.13268v3,2022-05-21T10:59:15Z,2021-08-30T14:29:57Z,Sensor-Based Navigation Using Hierarchical Reinforcement Learning,"Robotic systems are nowadays capable of solving complex navigation tasks.
However, their capabilities are limited to the knowledge of the designer and
consequently lack generalizability to initially unconsidered situations. This
makes deep reinforcement learning (DRL) especially interesting, as these
algorithms promise a self-learning system only relying on feedback from the
environment. In this paper, we consider the problem of lidar-based robot
navigation in continuous action space using DRL without providing any
goal-oriented or global information. By relying solely on local sensor data to
solve navigation tasks, we design an agent that assigns its own waypoints based
on intrinsic motivation. Our agent is able to learn goal-directed navigation
behavior even when facing only sparse feedback, i.e., delayed rewards when
reaching the target. To address this challenge and the complexity of the
continuous action space, we deploy a hierarchical agent structure in which the
exploration is distributed across multiple layers. Within the hierarchical
structure, our agent self-assigns internal goals and learns to extract
reasonable waypoints to reach the desired target position only based on local
sensor data. In our experiments, we demonstrate the navigation capabilities of
our agent in two environments and show that the hierarchical structure
seriously improves the performance in terms of success rate and success
weighted by path length in comparison to a flat structure. Furthermore, we
provide a real-robot experiment to illustrate that the trained agent can be
easily transferred to a real-world scenario.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.13035v1,2021-08-30T07:43:47Z,2021-08-30T07:43:47Z,"SurRoL: An Open-source Reinforcement Learning Centered and dVRK
  Compatible Platform for Surgical Robot Learning","Autonomous surgical execution relieves tedious routines and surgeon's
fatigue. Recent learning-based methods, especially reinforcement learning (RL)
based methods, achieve promising performance for dexterous manipulation, which
usually requires the simulation to collect data efficiently and reduce the
hardware cost. The existing learning-based simulation platforms for medical
robots suffer from limited scenarios and simplified physical interactions,
which degrades the real-world performance of learned policies. In this work, we
designed SurRoL, an RL-centered simulation platform for surgical robot learning
compatible with the da Vinci Research Kit (dVRK). The designed SurRoL
integrates a user-friendly RL library for algorithm development and a real-time
physics engine, which is able to support more PSM/ECM scenarios and more
realistic physical interactions. Ten learning-based surgical tasks are built in
the platform, which are common in the real autonomous surgical execution. We
evaluate SurRoL using RL algorithms in simulation, provide in-depth analysis,
deploy the trained policies on the real dVRK, and show that our SurRoL achieves
better transferability in the real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.07019v1,2021-08-16T11:13:55Z,2021-08-16T11:13:55Z,"Towards a Safety Case for Hardware Fault Tolerance in Convolutional
  Neural Networks Using Activation Range Supervision","Convolutional neural networks (CNNs) have become an established part of
numerous safety-critical computer vision applications, including human robot
interactions and automated driving. Real-world implementations will need to
guarantee their robustness against hardware soft errors corrupting the
underlying platform memory. Based on the previously observed efficacy of
activation clipping techniques, we build a prototypical safety case for
classifier CNNs by demonstrating that range supervision represents a highly
reliable fault detector and mitigator with respect to relevant bit flips,
adopting an eight-exponent floating point data representation. We further
explore novel, non-uniform range restriction methods that effectively suppress
the probability of silent data corruptions and uncorrectable errors. As a
safety-relevant end-to-end use case, we showcase the benefit of our approach in
a vehicle classification scenario, using ResNet-50 and the traffic camera data
set MIOVision. The quantitative evidence provided in this work can be leveraged
to inspire further and possibly more complex CNN safety arguments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.06266v2,2021-12-06T19:25:37Z,2021-08-13T14:22:02Z,"Safe Learning in Robotics: From Learning-Based Control to Safe
  Reinforcement Learning","The last half-decade has seen a steep rise in the number of contributions on
safe learning methods for real-world robotic deployments from both the control
and reinforcement learning communities. This article provides a concise but
holistic review of the recent advances made in using machine learning to
achieve safe decision making under uncertainties, with a focus on unifying the
language and frameworks used in control theory and reinforcement learning
research. Our review includes: learning-based control approaches that safely
improve performance by learning the uncertain dynamics, reinforcement learning
approaches that encourage safety or robustness, and methods that can formally
certify the safety of a learned control policy. As data- and learning-based
robot control methods continue to gain traction, researchers must understand
when and how to best leverage them in real-world scenarios where safety is
imperative, such as when operating in close proximity to humans. We highlight
some of the open challenges that will drive the field of robot learning in the
coming years, and emphasize the need for realistic physics-based benchmarks to
facilitate fair comparisons between control and reinforcement learning
approaches.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.05962v1,2021-08-12T21:03:44Z,2021-08-12T21:03:44Z,DRQN-based 3D Obstacle Avoidance with a Limited Field of View,"In this paper, we propose a map-based end-to-end DRL approach for
three-dimensional (3D) obstacle avoidance in a partially observed environment,
which is applied to achieve autonomous navigation for an indoor mobile robot
using a depth camera with a narrow field of view. We first train a neural
network with LSTM units in a 3D simulator of mobile robots to approximate the
Q-value function in double DRQN. We also use a curriculum learning strategy to
accelerate and stabilize the training process. Then we deploy the trained model
to a real robot to perform 3D obstacle avoidance in its navigation. We evaluate
the proposed approach both in the simulated environment and on a robot in the
real world. The experimental results show that the approach is efficient and
easy to be deployed, and it performs well for 3D obstacle avoidance with a
narrow observation angle, which outperforms other existing DRL-based models by
15.5% on success rate.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.05713v2,2022-06-02T15:22:32Z,2021-08-08T11:29:16Z,Towards real-world navigation with deep differentiable planners,"We train embodied neural networks to plan and navigate unseen complex 3D
environments, emphasising real-world deployment. Rather than requiring prior
knowledge of the agent or environment, the planner learns to model the state
transitions and rewards. To avoid the potentially hazardous trial-and-error of
reinforcement learning, we focus on differentiable planners such as Value
Iteration Networks (VIN), which are trained offline from safe expert
demonstrations. Although they work well in small simulations, we address two
major limitations that hinder their deployment. First, we observed that current
differentiable planners struggle to plan long-term in environments with a high
branching complexity. While they should ideally learn to assign low rewards to
obstacles to avoid collisions, we posit that the constraints imposed on the
network are not strong enough to guarantee the network to learn sufficiently
large penalties for every possible collision. We thus impose a structural
constraint on the value iteration, which explicitly learns to model any
impossible actions. Secondly, we extend the model to work with a limited
perspective camera under translation and rotation, which is crucial for real
robot deployment. Many VIN-like planners assume a 360 degrees or overhead view
without rotation. In contrast, our method uses a memory-efficient lattice map
to aggregate CNN embeddings of partial observations, and models the rotational
dynamics explicitly using a 3D state-space grid (translation and rotation). Our
proposals significantly improve semantic navigation and exploration on several
2D and 3D environments, succeeding in settings that are otherwise challenging
for this class of methods. As far as we know, we are the first to successfully
perform differentiable planning on the difficult Active Vision Dataset,
consisting of real images captured from a robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.03298v2,2021-09-25T00:37:01Z,2021-08-06T20:48:30Z,"What Matters in Learning from Offline Human Demonstrations for Robot
  Manipulation","Imitating human demonstrations is a promising approach to endow robots with
various manipulation capabilities. While recent advances have been made in
imitation learning and batch (offline) reinforcement learning, a lack of
open-source human datasets and reproducible learning methods make assessing the
state of the field difficult. In this paper, we conduct an extensive study of
six offline learning algorithms for robot manipulation on five simulated and
three real-world multi-stage manipulation tasks of varying complexity, and with
datasets of varying quality. Our study analyzes the most critical challenges
when learning from offline human data for manipulation. Based on the study, we
derive a series of lessons including the sensitivity to different algorithmic
design choices, the dependence on the quality of the demonstrations, and the
variability based on the stopping criteria due to the different objectives in
training and evaluation. We also highlight opportunities for learning from
human datasets, such as the ability to learn proficient policies on
challenging, multi-stage tasks beyond the scope of current reinforcement
learning methods, and the ability to easily scale to natural, real-world
manipulation scenarios where only raw sensory signals are available. We have
open-sourced our datasets and all algorithm implementations to facilitate
future research and fair comparisons in learning from human demonstration data.
Codebase, datasets, trained models, and more available at
https://arise-initiative.github.io/robomimic-web/",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.03272v4,2021-11-03T18:51:07Z,2021-08-06T18:41:39Z,"iGibson 2.0: Object-Centric Simulation for Robot Learning of Everyday
  Household Tasks","Recent research in embodied AI has been boosted by the use of simulation
environments to develop and train robot learning approaches. However, the use
of simulation has skewed the attention to tasks that only require what robotics
simulators can simulate: motion and physical contact. We present iGibson 2.0,
an open-source simulation environment that supports the simulation of a more
diverse set of household tasks through three key innovations. First, iGibson
2.0 supports object states, including temperature, wetness level, cleanliness
level, and toggled and sliced states, necessary to cover a wider range of
tasks. Second, iGibson 2.0 implements a set of predicate logic functions that
map the simulator states to logic states like Cooked or Soaked. Additionally,
given a logic state, iGibson 2.0 can sample valid physical states that satisfy
it. This functionality can generate potentially infinite instances of tasks
with minimal effort from the users. The sampling mechanism allows our scenes to
be more densely populated with small objects in semantically meaningful
locations. Third, iGibson 2.0 includes a virtual reality (VR) interface to
immerse humans in its scenes to collect demonstrations. As a result, we can
collect demonstrations from humans on these new types of tasks, and use them
for imitation learning. We evaluate the new capabilities of iGibson 2.0 to
enable robot learning of novel tasks, in the hope of demonstrating the
potential of this new simulator to support new research in embodied AI. iGibson
2.0 and its new dataset are publicly available at
http://svl.stanford.edu/igibson/.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.02439v1,2021-08-05T08:17:22Z,2021-08-05T08:17:22Z,Learning to Design and Construct Bridge without Blueprint,"Autonomous assembly has been a desired functionality of many intelligent
robot systems. We study a new challenging assembly task, designing and
constructing a bridge without a blueprint. In this task, the robot needs to
first design a feasible bridge architecture for arbitrarily wide cliffs and
then manipulate the blocks reliably to construct a stable bridge according to
the proposed design. In this paper, we propose a bi-level approach to tackle
this task. At the high level, the system learns a bridge blueprint policy in a
physical simulator using deep reinforcement learning and curriculum learning. A
policy is represented as an attention-based neural network with object-centric
input, which enables generalization to different numbers of blocks and cliff
widths. For low-level control, we implement a motion-planning-based policy for
real-robot motion control, which can be directly combined with a trained
blueprint policy for real-world bridge construction without tuning. In our
field study, our bi-level robot system demonstrates the capability of
manipulating blocks to construct a diverse set of bridges with different
architectures.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2108.00516v1,2021-08-01T18:14:46Z,2021-08-01T18:14:46Z,"BundleTrack: 6D Pose Tracking for Novel Objects without Instance or
  Category-Level 3D Models","Tracking the 6D pose of objects in video sequences is important for robot
manipulation. Most prior efforts, however, often assume that the target
object's CAD model, at least at a category-level, is available for offline
training or during online template matching. This work proposes BundleTrack, a
general framework for 6D pose tracking of novel objects, which does not depend
upon 3D models, either at the instance or category-level. It leverages the
complementary attributes of recent advances in deep learning for segmentation
and robust feature extraction, as well as memory-augmented pose graph
optimization for spatiotemporal consistency. This enables long-term, low-drift
tracking under various challenging scenarios, including significant occlusions
and object motions. Comprehensive experiments given two public benchmarks
demonstrate that the proposed approach significantly outperforms state-of-art,
category-level 6D tracking or dynamic SLAM methods. When compared against
state-of-art methods that rely on an object instance CAD model, comparable
performance is achieved, despite the proposed method's reduced information
requirements. An efficient implementation in CUDA provides a real-time
performance of 10Hz for the entire framework. Code is available at:
https://github.com/wenbowen123/BundleTrack",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.14598v1,2021-07-23T13:17:32Z,2021-07-23T13:17:32Z,"SmartHand: Towards Embedded Smart Hands for Prosthetic and Robotic
  Applications","The sophisticated sense of touch of the human hand significantly contributes
to our ability to safely, efficiently, and dexterously manipulate arbitrary
objects in our environment. Robotic and prosthetic devices lack refined,
tactile feedback from their end-effectors, leading to counterintuitive and
complex control strategies. To address this lack, tactile sensors have been
designed and developed, but they often offer an insufficient spatial and
temporal resolution. This paper focuses on overcoming these issues by designing
a smart embedded system, called SmartHand, enabling the acquisition and
real-time processing of high-resolution tactile information from a hand-shaped
multi-sensor array for prosthetic and robotic applications. We acquire a new
tactile dataset consisting of 340,000 frames while interacting with 16 everyday
objects and the empty hand, i.e., a total of 17 classes. The design of the
embedded system minimizes response latency in classification, by deploying a
small yet accurate convolutional neural network on a high-performance ARM
Cortex-M7 microcontroller. Compared to related work, our model requires one
order of magnitude less memory and 15.6x fewer computations while achieving
similar inter-session accuracy and up to 98.86% and 99.83% top-1 and top-3
cross-validation accuracy, respectively. Experimental results show a total
power consumption of 505mW and a latency of only 100ms.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.09822v2,2021-07-22T05:48:12Z,2021-07-21T00:43:32Z,"Bayesian Controller Fusion: Leveraging Control Priors in Deep
  Reinforcement Learning for Robotics","We present Bayesian Controller Fusion (BCF): a hybrid control strategy that
combines the strengths of traditional hand-crafted controllers and model-free
deep reinforcement learning (RL). BCF thrives in the robotics domain, where
reliable but suboptimal control priors exist for many tasks, but RL from
scratch remains unsafe and data-inefficient. By fusing uncertainty-aware
distributional outputs from each system, BCF arbitrates control between them,
exploiting their respective strengths. We study BCF on two real-world robotics
tasks involving navigation in a vast and long-horizon environment, and a
complex reaching task that involves manipulability maximisation. For both these
domains, there exist simple handcrafted controllers that can solve the task at
hand in a risk-averse manner but do not necessarily exhibit the optimal
solution given limitations in analytical modelling, controller miscalibration
and task variation. As exploration is naturally guided by the prior in the
early stages of training, BCF accelerates learning, while substantially
improving beyond the performance of the control prior, as the policy gains more
experience. More importantly, given the risk-aversity of the control prior, BCF
ensures safe exploration and deployment, where the control prior naturally
dominates the action distribution in states unknown to the policy. We
additionally show BCF's applicability to the zero-shot sim-to-real setting and
its ability to deal with out-of-distribution states in the real-world. BCF is a
promising approach for combining the complementary strengths of deep RL and
traditional robotic control, surpassing what either can achieve independently.
The code and supplementary video material are made publicly available at
https://krishanrana.github.io/bcf.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.08325v1,2021-07-18T00:00:48Z,2021-07-18T00:00:48Z,"Vision-Based Autonomous Car Racing Using Deep Imitative Reinforcement
  Learning","Autonomous car racing is a challenging task in the robotic control area.
Traditional modular methods require accurate mapping, localization and
planning, which makes them computationally inefficient and sensitive to
environmental changes. Recently, deep-learning-based end-to-end systems have
shown promising results for autonomous driving/racing. However, they are
commonly implemented by supervised imitation learning (IL), which suffers from
the distribution mismatch problem, or by reinforcement learning (RL), which
requires a huge amount of risky interaction data. In this work, we present a
general deep imitative reinforcement learning approach (DIRL), which
successfully achieves agile autonomous racing using visual inputs. The driving
knowledge is acquired from both IL and model-based RL, where the agent can
learn from human teachers as well as perform self-improvement by safely
interacting with an offline world model. We validate our algorithm both in a
high-fidelity driving simulation and on a real-world 1/20-scale RC-car with
limited onboard computation. The evaluation results demonstrate that our method
outperforms previous IL and RL methods in terms of sample efficiency and task
performance. Demonstration videos are available at
https://caipeide.github.io/autorace-dirl/",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.07931v1,2021-07-16T14:47:44Z,2021-07-16T14:47:44Z,Learning Locomotion Controllers for Walking Using Deep FBSDE,"In this paper, we propose a deep forward-backward stochastic differential
equation (FBSDE) based control algorithm for locomotion tasks. We also include
state constraints in the FBSDE formulation to impose stable walking solutions
or other constraints that one may want to consider (e.g., energy). Our approach
utilizes a deep neural network (i.e., LSTM) to solve, in general,
high-dimensional Hamilton-Jacobi-Bellman (HJB) equation resulting from the
stated optimal control problem. As compared to traditional methods, our
proposed method provides a higher computational efficiency in real-time; thus
yielding higher frequency implementation of the closed-loop controllers. The
efficacy of our approach is shown on a linear inverted pendulum model (LIPM)
for walking. Even though we are deploying a simplified model of walking, the
methodology is applicable to generalized and complex models for walking and
other control/optimization tasks in robotic systems. Simulation studies have
been provided to show the effectiveness of the proposed methodology.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.07502v2,2021-11-10T07:31:56Z,2021-07-15T17:54:36Z,MultiBench: Multiscale Benchmarks for Multimodal Representation Learning,"Learning multimodal representations involves integrating information from
multiple heterogeneous sources of data. It is a challenging yet crucial area
with numerous real-world applications in multimedia, affective computing,
robotics, finance, human-computer interaction, and healthcare. Unfortunately,
multimodal research has seen limited resources to study (1) generalization
across domains and modalities, (2) complexity during training and inference,
and (3) robustness to noisy and missing modalities. In order to accelerate
progress towards understudied modalities and tasks while ensuring real-world
robustness, we release MultiBench, a systematic and unified large-scale
benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6
research areas. MultiBench provides an automated end-to-end machine learning
pipeline that simplifies and standardizes data loading, experimental setup, and
model evaluation. To enable holistic evaluation, MultiBench offers a
comprehensive methodology to assess (1) generalization, (2) time and space
complexity, and (3) modality robustness. MultiBench introduces impactful
challenges for future research, including scalability to large-scale multimodal
datasets and robustness to realistic imperfections. To accompany this
benchmark, we also provide a standardized implementation of 20 core approaches
in multimodal learning. Simply applying methods proposed in different research
areas can improve the state-of-the-art performance on 9/15 datasets. Therefore,
MultiBench presents a milestone in unifying disjoint efforts in multimodal
research and paves the way towards a better understanding of the capabilities
and limitations of multimodal models, all the while ensuring ease of use,
accessibility, and reproducibility. MultiBench, our standardized code, and
leaderboards are publicly available, will be regularly updated, and welcomes
inputs from the community.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.07191v2,2021-07-20T13:42:37Z,2021-07-15T08:36:54Z,Deep Learning based Food Instance Segmentation using Synthetic Data,"In the process of intelligently segmenting foods in images using deep neural
networks for diet management, data collection and labeling for network training
are very important but labor-intensive tasks. In order to solve the
difficulties of data collection and annotations, this paper proposes a food
segmentation method applicable to real-world through synthetic data. To perform
food segmentation on healthcare robot systems, such as meal assistance robot
arm, we generate synthetic data using the open-source 3D graphics software
Blender placing multiple objects on meal plate and train Mask R-CNN for
instance segmentation. Also, we build a data collection system and verify our
segmentation model on real-world food data. As a result, on our real-world
dataset, the model trained only synthetic data is available to segment food
instances that are not trained with 52.2% mask AP@all, and improve performance
by +6.4%p after fine-tuning comparing to the model trained from scratch. In
addition, we also confirm the possibility and performance improvement on the
public dataset for fair analysis. Our code and pre-trained weights are
avaliable online at: https://github.com/gist-ailab/Food-Instance-Segmentation",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.06882v1,2021-07-14T17:55:28Z,2021-07-14T17:55:28Z,"Conservative Objective Models for Effective Offline Model-Based
  Optimization","Computational design problems arise in a number of settings, from synthetic
biology to computer architectures. In this paper, we aim to solve data-driven
model-based optimization (MBO) problems, where the goal is to find a design
input that maximizes an unknown objective function provided access to only a
static dataset of prior experiments. Such data-driven optimization procedures
are the only practical methods in many real-world domains where active data
collection is expensive (e.g., when optimizing over proteins) or dangerous
(e.g., when optimizing over aircraft designs). Typical methods for MBO that
optimize the design against a learned model suffer from distributional shift:
it is easy to find a design that ""fools"" the model into predicting a high
value. To overcome this, we propose conservative objective models (COMs), a
method that learns a model of the objective function that lower bounds the
actual value of the ground-truth objective on out-of-distribution inputs, and
uses it for optimization. Structurally, COMs resemble adversarial training
methods used to overcome adversarial examples. COMs are simple to implement and
outperform a number of existing methods on a wide range of MBO problems,
including optimizing protein sequences, robot morphologies, neural network
weights, and superconducting materials.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.06629v2,2022-01-24T14:40:52Z,2021-07-14T12:07:19Z,"Model-free Reinforcement Learning for Robust Locomotion using
  Demonstrations from Trajectory Optimization","We present a general, two-stage reinforcement learning approach to create
robust policies that can be deployed on real robots without any additional
training using a single demonstration generated by trajectory optimization. The
demonstration is used in the first stage as a starting point to facilitate
initial exploration. In the second stage, the relevant task reward is optimized
directly and a policy robust to environment uncertainties is computed. We
demonstrate and examine in detail the performance and robustness of our
approach on highly dynamic hopping and bounding tasks on a quadruped robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.01281v3,2022-03-28T16:14:51Z,2021-07-02T21:10:35Z,Prescient teleoperation of humanoid robots,"Humanoid robots could be versatile and intuitive human avatars that operate
remotely in inaccessible places: the robot could reproduce in the remote
location the movements of an operator equipped with a wearable motion capture
device while sending visual feedback to the operator. While substantial
progress has been made on transferring (""retargeting"") human motions to
humanoid robots, a major problem preventing the deployment of such systems in
real applications is the presence of communication delays between the human
input and the feedback from the robot: even a few hundred milliseconds of delay
can irreversibly disturb the operator, let alone a few seconds. To overcome
these delays, we introduce a system in which a humanoid robot executes commands
before it actually receives them, so that the visual feedback appears to be
synchronized to the operator, whereas the robot executed the commands in the
past. To do so, the robot continuously predicts future commands by querying a
machine learning model that is trained on past trajectories and conditioned on
the last received commands. In our experiments, an operator was able to
successfully control a humanoid robot (32 degrees of freedom) with stochastic
delays up to 2 seconds in several whole-body manipulation tasks, including
reaching different targets, picking up a bottle, and placing a box at distinct
locations.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.00401v1,2021-07-01T12:20:48Z,2021-07-01T12:20:48Z,"CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous
  Cars on the Loihi Neuromorphic Research Processor","Autonomous Driving (AD) related features provide new forms of mobility that
are also beneficial for other kind of intelligent and autonomous systems like
robots, smart transportation, and smart industries. For these applications, the
decisions need to be made fast and in real-time. Moreover, in the quest for
electric mobility, this task must follow low power policy, without affecting
much the autonomy of the mean of transport or the robot. These two challenges
can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed
on a specialized neuromorphic hardware, SNNs can achieve high performance with
low latency and low power consumption. In this paper, we use an SNN connected
to an event-based camera for facing one of the key problems for AD, i.e., the
classification between cars and other objects. To consume less power than
traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The
experiments are made following an offline supervised learning rule, followed by
mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our
best experiment achieves an accuracy on offline implementation of 86%, that
drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware
implementation has maximum 0.72 ms of latency for every sample, and consumes
only 310 mW. To the best of our knowledge, this work is the first
implementation of an event-based car classifier on a Neuromorphic Chip.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2107.00127v1,2021-06-30T22:18:49Z,2021-06-30T22:18:49Z,"SQRP: Sensing Quality-aware Robot Programming System for Non-expert
  Programmers","Robot programming typically makes use of a set of mechanical skills that is
acquired by machine learning. Because there is in general no guarantee that
machine learning produces robot programs that are free of surprising behavior,
the safe execution of a robot program must utilize monitoring modules that take
sensor data as inputs in real time to ensure the correctness of the skill
execution. Owing to the fact that sensors and monitoring algorithms are usually
subject to physical restrictions and that effective robot programming is
sensitive to the selection of skill parameters, these considerations may lead
to different sensor input qualities such as the view coverage of a vision
system that determines whether a skill can be successfully deployed in
performing a task. Choosing improper skill parameters may cause the monitoring
modules to delay or miss the detection of important events such as a mechanical
failure. These failures may reduce the throughput in robotic manufacturing and
could even cause a destructive system crash. To address above issues, we
propose a sensing quality-aware robot programming system that automatically
computes the sensing qualities as a function of the robot's environment and
uses the information to guide non-expert users to select proper skill
parameters in the programming phase. We demonstrate our system framework on a
6DOF robot arm for an object pick-up task.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.15965v1,2021-06-30T10:25:19Z,2021-06-30T10:25:19Z,Embedded out-of-distribution detection on an autonomous robot platform,"Machine learning (ML) is actively finding its way into modern cyber-physical
systems (CPS), many of which are safety-critical real-time systems. It is well
known that ML outputs are not reliable when testing data are novel with regards
to model training and validation data, i.e., out-of-distribution (OOD) test
data. We implement an unsupervised deep neural network-based OOD detector on a
real-time embedded autonomous Duckiebot and evaluate detection performance. Our
OOD detector produces a success rate of 87.5% for emergency stopping a
Duckiebot on a braking test bed we designed. We also provide case analysis on
computing resource challenges specific to the Robot Operating System (ROS)
middleware on the Duckiebot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.14739v1,2021-06-28T14:11:48Z,2021-06-28T14:11:48Z,"Real-Time Human Pose Estimation on a Smart Walker using Convolutional
  Neural Networks","Rehabilitation is important to improve quality of life for mobility-impaired
patients. Smart walkers are a commonly used solution that should embed
automatic and objective tools for data-driven human-in-the-loop control and
monitoring. However, present solutions focus on extracting few specific metrics
from dedicated sensors with no unified full-body approach. We investigate a
general, real-time, full-body pose estimation framework based on two RGB+D
camera streams with non-overlapping views mounted on a smart walker equipment
used in rehabilitation. Human keypoint estimation is performed using a
two-stage neural network framework. The 2D-Stage implements a detection module
that locates body keypoints in the 2D image frames. The 3D-Stage implements a
regression module that lifts and relates the detected keypoints in both cameras
to the 3D space relative to the walker. Model predictions are low-pass filtered
to improve temporal consistency. A custom acquisition method was used to obtain
a dataset, with 14 healthy subjects, used for training and evaluating the
proposed framework offline, which was then deployed on the real walker
equipment. An overall keypoint detection error of 3.73 pixels for the 2D-Stage
and 44.05mm for the 3D-Stage were reported, with an inference time of 26.6ms
when deployed on the constrained hardware of the walker. We present a novel
approach to patient monitoring and data-driven human-in-the-loop control in the
context of smart walkers. It is able to extract a complete and compact body
representation in real-time and from inexpensive sensors, serving as a common
base for downstream metrics extraction solutions, and Human-Robot interaction
applications. Despite promising results, more data should be collected on users
with impairments, to assess its performance as a rehabilitation tool in
real-world scenarios.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.14597v1,2021-06-28T12:09:36Z,2021-06-28T12:09:36Z,"Dataset and Benchmarking of Real-Time Embedded Object Detection for
  RoboCup SSL","When producing a model to object detection in a specific context, the first
obstacle is to have a dataset labeling the desired classes. In RoboCup, some
leagues already have more than one dataset to train and evaluate a model.
However, in the Small Size League (SSL), there is not such dataset available
yet. This paper presents an open-source dataset to be used as a benchmark for
real-time object detection in SSL. This work also presented a pipeline to
train, deploy, and evaluate Convolutional Neural Networks (CNNs) models in a
low-power embedded system. This pipeline was used to evaluate the proposed
dataset with state-of-art optimized models. In this dataset, the MobileNet SSD
v1 achieves 44.88% AP (68.81% AP50) at 94 Frames Per Second (FPS) while running
on an SSL robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.15409v2,2021-06-30T20:05:23Z,2021-06-28T08:07:31Z,"Efficient Realistic Data Generation Framework leveraging Deep
  Learning-based Human Digitization","The performance of supervised deep learning algorithms depends significantly
on the scale, quality and diversity of the data used for their training.
Collecting and manually annotating large amount of data can be both
time-consuming and costly tasks to perform. In the case of tasks related to
visual human-centric perception, the collection and distribution of such data
may also face restrictions due to legislation regarding privacy. In addition,
the design and testing of complex systems, e.g., robots, which often employ
deep learning-based perception models, may face severe difficulties as even
state-of-the-art methods trained on real and large-scale datasets cannot always
perform adequately due to not having been adapted to the visual differences
between the virtual and the real world data. As an attempt to tackle and
mitigate the effect of these issues, we present a method that automatically
generates realistic synthetic data with annotations for a) person detection, b)
face recognition, and c) human pose estimation. The proposed method takes as
input real background images and populates them with human figures in various
poses. Instead of using hand-made 3D human models, we propose the use of models
generated through deep learning methods, further reducing the dataset creation
costs, while maintaining a high level of realism. In addition, we provide
open-source and easy to use tools that implement the proposed pipeline,
allowing for generating highly-realistic synthetic datasets for a variety of
tasks. A benchmarking and evaluation in the corresponding tasks shows that
synthetic data can be effectively used as a supplement to real data.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.10251v4,2022-05-06T11:03:26Z,2021-06-18T17:33:13Z,Active Offline Policy Selection,"This paper addresses the problem of policy selection in domains with abundant
logged data, but with a restricted interaction budget. Solving this problem
would enable safe evaluation and deployment of offline reinforcement learning
policies in industry, robotics, and recommendation domains among others.
Several off-policy evaluation (OPE) techniques have been proposed to assess the
value of policies using only logged data. However, there is still a big gap
between the evaluation by OPE and the full online evaluation. Yet, large
amounts of online interactions are often not possible in practice. To overcome
this problem, we introduce active offline policy selection - a novel sequential
decision approach that combines logged data with online interaction to identify
the best policy. We use OPE estimates to warm start the online evaluation.
Then, in order to utilize the limited environment interactions wisely we decide
which policy to evaluate next based on a Bayesian optimization method with a
kernel that represents policy similarity. We use multiple benchmarks, including
real-world robotics, with a large number of candidate policies to show that the
proposed approach improves upon state-of-the-art OPE estimates and pure online
policy evaluation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.09357v1,2021-06-17T10:20:45Z,2021-06-17T10:20:45Z,"Cat-like Jumping and Landing of Legged Robots in Low-gravity Using Deep
  Reinforcement Learning","In this article, we show that learned policies can be applied to solve legged
locomotion control tasks with extensive flight phases, such as those
encountered in space exploration. Using an off-the-shelf deep reinforcement
learning algorithm, we trained a neural network to control a jumping quadruped
robot while solely using its limbs for attitude control. We present tasks of
increasing complexity leading to a combination of three-dimensional
(re-)orientation and landing locomotion behaviors of a quadruped robot
traversing simulated low-gravity celestial bodies. We show that our approach
easily generalizes across these tasks and successfully trains policies for each
case. Using sim-to-real transfer, we deploy trained policies in the real world
on the SpaceBok robot placed on an experimental testbed designed for
two-dimensional micro-gravity experiments. The experimental results demonstrate
that repetitive, controlled jumping and landing with natural agility is
possible.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2106.08796v2,2021-10-31T15:30:34Z,2021-06-16T13:58:35Z,Tactile Sim-to-Real Policy Transfer via Real-to-Sim Image Translation,"Simulation has recently become key for deep reinforcement learning to safely
and efficiently acquire general and complex control policies from visual and
proprioceptive inputs. Tactile information is not usually considered despite
its direct relation to environment interaction. In this work, we present a
suite of simulated environments tailored towards tactile robotics and
reinforcement learning. A simple and fast method of simulating optical tactile
sensors is provided, where high-resolution contact geometry is represented as
depth images. Proximal Policy Optimisation (PPO) is used to learn successful
policies across all considered tasks. A data-driven approach enables
translation of the current state of a real tactile sensor to corresponding
simulated depth images. This policy is implemented within a real-time control
loop on a physical robot to demonstrate zero-shot sim-to-real policy transfer
on several physically-interactive tasks requiring a sense of touch.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.11914v2,2021-08-24T13:58:11Z,2021-05-25T13:17:35Z,Theory and Design of Super-resolution Haptic Skins,"Haptic feedback is important to make robots more dexterous and effective in
unstructured environments. High-resolution haptic sensors are still not widely
available, and their application is often bound by the resolution-robustness
dilemma. A route towards high-resolution and robust skin embeds a few sensor
units (taxels) into a flexible surface material and uses signal processing to
achieve sensing with super-resolution accuracy. We propose a theory for
geometric super-resolution to guide the development of haptic sensors of this
kind and link it to machine learning techniques for signal processing. This
theory is based on sensor isolines and allows us to predict force sensitivity
and accuracy in contact position and force magnitude as a spatial quantity. We
evaluate the influence of different factors, such as elastic properties of the
material, structure design, and transduction methods, using finite element
simulations and by implementing real sensors. We empirically determine sensor
isolines and validate the theory in two custom-built sensors with barometric
units for 1D and 2D measurement surfaces. Using machine learning methods for
the inference of contact information, our sensors obtain an unparalleled
average super-resolution factor of over 100 and 1200, respectively. Our theory
can guide future haptic sensor designs and inform various design choices.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.11494v1,2021-05-24T18:40:18Z,2021-05-24T18:40:18Z,3D-Aware Ellipse Prediction for Object-Based Camera Pose Estimation,"In this paper, we propose a method for coarse camera pose computation which
is robust to viewing conditions and does not require a detailed model of the
scene. This method meets the growing need of easy deployment of robotics or
augmented reality applications in any environments, especially those for which
no accurate 3D model nor huge amount of ground truth data are available. It
exploits the ability of deep learning techniques to reliably detect objects
regardless of viewing conditions. Previous works have also shown that
abstracting the geometry of a scene of objects by an ellipsoid cloud allows to
compute the camera pose accurately enough for various application needs. Though
promising, these approaches use the ellipses fitted to the detection bounding
boxes as an approximation of the imaged objects. In this paper, we go one step
further and propose a learning-based method which detects improved elliptic
approximations of objects which are coherent with the 3D ellipsoid in terms of
perspective projection. Experiments prove that the accuracy of the computed
pose significantly increases thanks to our method and is more robust to the
variability of the boundaries of the detection boxes. This is achieved with
very little effort in terms of training data acquisition -- a few hundred
calibrated images of which only three need manual object annotation. Code and
models are released at
https://github.com/zinsmatt/3D-Aware-Ellipses-for-Visual-Localization.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.10389v4,2022-01-06T03:58:19Z,2021-05-21T15:03:29Z,Learning Visible Connectivity Dynamics for Cloth Smoothing,"Robotic manipulation of cloth remains challenging for robotics due to the
complex dynamics of the cloth, lack of a low-dimensional state representation,
and self-occlusions. In contrast to previous model-based approaches that learn
a pixel-based dynamics model or a compressed latent vector dynamics, we propose
to learn a particle-based dynamics model from a partial point cloud
observation. To overcome the challenges of partial observability, we infer
which visible points are connected on the underlying cloth mesh. We then learn
a dynamics model over this visible connectivity graph. Compared to previous
learning-based approaches, our model poses strong inductive bias with its
particle based representation for learning the underlying cloth physics; it is
invariant to visual features; and the predictions can be more easily
visualized. We show that our method greatly outperforms previous
state-of-the-art model-based and model-free reinforcement learning methods in
simulation. Furthermore, we demonstrate zero-shot sim-to-real transfer where we
deploy the model trained in simulation on a Franka arm and show that the model
can successfully smooth different types of cloth from crumpled configurations.
Videos can be found on our project website.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.05873v1,2021-05-12T18:00:14Z,2021-05-12T18:00:14Z,Out of the Box: Embodied Navigation in the Real World,"The research field of Embodied AI has witnessed substantial progress in
visual navigation and exploration thanks to powerful simulating platforms and
the availability of 3D data of indoor and photorealistic environments. These
two factors have opened the doors to a new generation of intelligent agents
capable of achieving nearly perfect PointGoal Navigation. However, such
architectures are commonly trained with millions, if not billions, of frames
and tested in simulation. Together with great enthusiasm, these results yield a
question: how many researchers will effectively benefit from these advances? In
this work, we detail how to transfer the knowledge acquired in simulation into
the real world. To that end, we describe the architectural discrepancies that
damage the Sim2Real adaptation ability of models trained on the Habitat
simulator and propose a novel solution tailored towards the deployment in
real-world scenarios. We then deploy our models on a LoCoBot, a Low-Cost Robot
equipped with a single Intel RealSense camera. Different from previous work,
our testing scene is unavailable to the agent in simulation. The environment is
also inaccessible to the agent beforehand, so it cannot count on scene-specific
semantic priors. In this way, we reproduce a setting in which a research group
(potentially from other fields) needs to employ the agent visual navigation
capabilities as-a-Service. Our experiments indicate that it is possible to
achieve satisfying results when deploying the obtained model in the real world.
Our code and models are available at https://github.com/aimagelab/LoCoNav.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.01777v1,2021-05-04T21:48:18Z,2021-05-04T21:48:18Z,"PathBench: A Benchmarking Platform for Classical and Learned Path
  Planning Algorithms","Path planning is a key component in mobile robotics. A wide range of path
planning algorithms exist, but few attempts have been made to benchmark the
algorithms holistically or unify their interface. Moreover, with the recent
advances in deep neural networks, there is an urgent need to facilitate the
development and benchmarking of such learning-based planning algorithms. This
paper presents PathBench, a platform for developing, visualizing, training,
testing, and benchmarking of existing and future, classical and learned 2D and
3D path planning algorithms, while offering support for Robot Oper-ating System
(ROS). Many existing path planning algorithms are supported; e.g. A*,
wavefront, rapidly-exploring random tree, value iteration networks, gated path
planning networks; and integrating new algorithms is easy and clearly
specified. We demonstrate the benchmarking capability of PathBench by comparing
implemented classical and learned algorithms for metrics, such as path length,
success rate, computational time and path deviation. These evaluations are done
on built-in PathBench maps and external path planning environments from video
games and real world databases. PathBench is open source.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2105.00368v2,2021-05-29T22:41:12Z,2021-05-02T01:09:13Z,"MarkerPose: Robust Real-time Planar Target Tracking for Accurate Stereo
  Pose Estimation","Despite the attention marker-less pose estimation has attracted in recent
years, marker-based approaches still provide unbeatable accuracy under
controlled environmental conditions. Thus, they are used in many fields such as
robotics or biomedical applications but are primarily implemented through
classical approaches, which require lots of heuristics and parameter tuning for
reliable performance under different environments. In this work, we propose
MarkerPose, a robust, real-time pose estimation system based on a planar target
of three circles and a stereo vision system. MarkerPose is meant for
high-accuracy pose estimation applications. Our method consists of two deep
neural networks for marker point detection. A SuperPoint-like network for
pixel-level accuracy keypoint localization and classification, and we introduce
EllipSegNet, a lightweight ellipse segmentation network for sub-pixel-level
accuracy keypoint detection. The marker's pose is estimated through stereo
triangulation. The target point detection is robust to low lighting and motion
blur conditions. We compared MarkerPose with a detection method based on
classical computer vision techniques using a robotic arm for validation. The
results show our method provides better accuracy than the classical technique.
Finally, we demonstrate the suitability of MarkerPose in a 3D freehand
ultrasound system, which is an application where highly accurate pose
estimation is required. Code is available in Python and C++ at
https://github.com/jhacsonmeza/MarkerPose.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.14870v1,2021-04-30T09:53:28Z,2021-04-30T09:53:28Z,"Action in Mind: A Neural Network Approach to Action Recognition and
  Segmentation","Recognizing and categorizing human actions is an important task with
applications in various fields such as human-robot interaction, video analysis,
surveillance, video retrieval, health care system and entertainment industry.
This thesis presents a novel computational approach for human action
recognition through different implementations of multi-layer architectures
based on artificial neural networks. Each system level development is designed
to solve different aspects of the action recognition problem including online
real-time processing, action segmentation and the involvement of objects. The
analysis of the experimental results are illustrated and described in six
articles. The proposed action recognition architecture of this thesis is
composed of several processing layers including a preprocessing layer, an
ordered vector representation layer and three layers of neural networks. It
utilizes self-organizing neural networks such as Kohonen feature maps and
growing grids as the main neural network layers. Thus the architecture presents
a biological plausible approach with certain features such as topographic
organization of the neurons, lateral interactions, semi-supervised learning and
the ability to represent high dimensional input space in lower dimensional
maps. For each level of development the system is trained with the input data
consisting of consecutive 3D body postures and tested with generalized input
data that the system has never met before. The experimental results of
different system level developments show that the system performs well with
quite high accuracy for recognizing human actions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.14534v1,2021-04-29T17:49:20Z,2021-04-29T17:49:20Z,"On the Emergence of Whole-body Strategies from Humanoid Robot
  Push-recovery Learning","Balancing and push-recovery are essential capabilities enabling humanoid
robots to solve complex locomotion tasks. In this context, classical control
systems tend to be based on simplified physical models and hard-coded
strategies. Although successful in specific scenarios, this approach requires
demanding tuning of parameters and switching logic between
specifically-designed controllers for handling more general perturbations. We
apply model-free Deep Reinforcement Learning for training a general and robust
humanoid push-recovery policy in a simulation environment. Our method targets
high-dimensional whole-body humanoid control and is validated on the iCub
humanoid. Reward components incorporating expert knowledge on humanoid control
enable fast learning of several robust behaviors by the same policy, spanning
the entire body. We validate our method with extensive quantitative analyses in
simulation, including out-of-sample tasks which demonstrate policy robustness
and generalization, both key requirements towards real-world robot deployment.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.11008v1,2021-04-22T12:10:38Z,2021-04-22T12:10:38Z,"Unsupervised anomaly detection for a Smart Autonomous Robotic Assistant
  Surgeon (SARAS)using a deep residual autoencoder","Anomaly detection in Minimally-Invasive Surgery (MIS) traditionally requires
a human expert monitoring the procedure from a console. Data scarcity, on the
other hand, hinders what would be a desirable migration towards autonomous
robotic-assisted surgical systems. Automated anomaly detection systems in this
area typically rely on classical supervised learning. Anomalous events in a
surgical setting, however, are rare, making it difficult to capture data to
train a detection model in a supervised fashion. In this work we thus propose
an unsupervised approach to anomaly detection for robotic-assisted surgery
based on deep residual autoencoders. The idea is to make the autoencoder learn
the 'normal' distribution of the data and detect abnormal events deviating from
this distribution by measuring the reconstruction error. The model is trained
and validated upon both the publicly available Cholec80 dataset, provided with
extra annotation, and on a set of videos captured on procedures using
artificial anatomies ('phantoms') produced as part of the Smart Autonomous
Robotic Assistant Surgeon (SARAS) project. The system achieves recall and
precision equal to 78.4%, 91.5%, respectively, on Cholec80 and of 95.6%, 88.1%
on the SARAS phantom dataset. The end-to-end system was developed and deployed
as part of the SARAS demonstration platform for real-time anomaly detection
with a processing time of about 25 ms per frame.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.07282v1,2021-04-15T07:40:27Z,2021-04-15T07:40:27Z,"Rule-Based Reinforcement Learning for Efficient Robot Navigation with
  Space Reduction","For real-world deployments, it is critical to allow robots to navigate in
complex environments autonomously. Traditional methods usually maintain an
internal map of the environment, and then design several simple rules, in
conjunction with a localization and planning approach, to navigate through the
internal map. These approaches often involve a variety of assumptions and prior
knowledge. In contrast, recent reinforcement learning (RL) methods can provide
a model-free, self-learning mechanism as the robot interacts with an initially
unknown environment, but are expensive to deploy in real-world scenarios due to
inefficient exploration. In this paper, we focus on efficient navigation with
the RL technique and combine the advantages of these two kinds of methods into
a rule-based RL (RuRL) algorithm for reducing the sample complexity and cost of
time. First, we use the rule of wall-following to generate a closed-loop
trajectory. Second, we employ a reduction rule to shrink the trajectory, which
in turn effectively reduces the redundant exploration space. Besides, we give
the detailed theoretical guarantee that the optimal navigation path is still in
the reduced space. Third, in the reduced space, we utilize the Pledge rule to
guide the exploration strategy for accelerating the RL process at the early
stage. Experiments conducted on real robot navigation problems in hex-grid
environments demonstrate that RuRL can achieve improved navigation performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.03657v1,2021-04-08T10:18:52Z,2021-04-08T10:18:52Z,"Dynamic Object Aware LiDAR SLAM based on Automatic Generation of
  Training Data","Highly dynamic environments, with moving objects such as cars or humans, can
pose a performance challenge for LiDAR SLAM systems that assume largely static
scenes. To overcome this challenge and support the deployment of robots in real
world scenarios, we propose a complete solution for a dynamic object aware
LiDAR SLAM algorithm. This is achieved by leveraging a real-time capable neural
network that can detect dynamic objects, thus allowing our system to deal with
them explicitly. To efficiently generate the necessary training data which is
key to our approach, we present a novel end-to-end occupancy grid based
pipeline that can automatically label a wide variety of arbitrary dynamic
objects. Our solution can thus generalize to different environments without the
need for expensive manual labeling and at the same time avoids assumptions
about the presence of a predefined set of known objects in the scene. Using
this technique, we automatically label over 12000 LiDAR scans collected in an
urban environment with a large amount of pedestrians and use this data to train
a neural network, achieving an average segmentation IoU of 0.82. We show that
explicitly dealing with dynamic objects can improve the LiDAR SLAM odometry
performance by 39.6% while yielding maps which better represent the
environments. A supplementary video as well as our test data are available
online.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2104.02737v1,2021-04-06T18:08:09Z,2021-04-06T18:08:09Z,"Neural Network-based Control for Multi-Agent Systems from
  Spatio-Temporal Specifications","We propose a framework for solving control synthesis problems for multi-agent
networked systems required to satisfy spatio-temporal specifications. We use
Spatio-Temporal Reach and Escape Logic (STREL) as a specification language. For
this logic, we define smooth quantitative semantics, which captures the degree
of satisfaction of a formula by a multi-agent team. We use the novel
quantitative semantics to map control synthesis problems with STREL
specifications to optimization problems and propose a combination of heuristic
and gradient-based methods to solve such problems. As this method might not
meet the requirements of a real-time implementation, we develop a machine
learning technique that uses the results of the off-line optimizations to train
a neural network that gives the control inputs at current states. We illustrate
the effectiveness of the proposed framework by applying it to a model of a
robotic team required to satisfy a spatial-temporal specification under
communication constraints.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.15004v3,2021-04-05T16:10:19Z,2021-03-27T22:12:06Z,"eXtended Artificial Intelligence: New Prospects of Human-AI Interaction
  Research","Artificial Intelligence (AI) covers a broad spectrum of computational
problems and use cases. Many of those implicate profound and sometimes
intricate questions of how humans interact or should interact with AIs.
Moreover, many users or future users do have abstract ideas of what AI is,
significantly depending on the specific embodiment of AI applications.
Human-centered-design approaches would suggest evaluating the impact of
different embodiments on human perception of and interaction with AI. An
approach that is difficult to realize due to the sheer complexity of
application fields and embodiments in reality. However, here XR opens new
possibilities to research human-AI interactions. The article's contribution is
twofold: First, it provides a theoretical treatment and model of human-AI
interaction based on an XR-AI continuum as a framework for and a perspective of
different approaches of XR-AI combinations. It motivates XR-AI combinations as
a method to learn about the effects of prospective human-AI interfaces and
shows why the combination of XR and AI fruitfully contributes to a valid and
systematic investigation of human-AI interactions and interfaces. Second, the
article provides two exemplary experiments investigating the aforementioned
approach for two distinct AI-systems. The first experiment reveals an
interesting gender effect in human-robot interaction, while the second
experiment reveals an Eliza effect of a recommender system. Here the article
introduces two paradigmatic implementations of the proposed XR testbed for
human-AI interactions and interfaces and shows how a valid and systematic
investigation can be conducted. In sum, the article opens new perspectives on
how XR benefits human-centered AI design and development.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.14407v2,2021-04-13T12:48:31Z,2021-03-26T11:32:27Z,Bellman: A Toolbox for Model-Based Reinforcement Learning in TensorFlow,"In the past decade, model-free reinforcement learning (RL) has provided
solutions to challenging domains such as robotics. Model-based RL shows the
prospect of being more sample-efficient than model-free methods in terms of
agent-environment interactions, because the model enables to extrapolate to
unseen situations. In the more recent past, model-based methods have shown
superior results compared to model-free methods in some challenging domains
with non-linear state transitions. At the same time, it has become apparent
that RL is not market-ready yet and that many real-world applications are going
to require model-based approaches, because model-free methods are too
sample-inefficient and show poor performance in early stages of training. The
latter is particularly important in industry, e.g. in production systems that
directly impact a company's revenue. This demonstrates the necessity for a
toolbox to push the boundaries for model-based RL. While there is a plethora of
toolboxes for model-free RL, model-based RL has received little attention in
terms of toolbox development. Bellman aims to fill this gap and introduces the
first thoroughly designed and tested model-based RL toolbox using
state-of-the-art software engineering practices. Our modular approach enables
to combine a wide range of environment models with generic model-based agent
classes that recover state-of-the-art algorithms. We also provide an experiment
harness to compare both model-free and model-based agents in a systematic
fashion w.r.t. user-defined evaluation metrics (e.g. cumulative reward). This
paves the way for new research directions, e.g. investigating uncertainty-aware
environment models that are not necessarily neural-network-based, or developing
algorithms to solve industrially-motivated benchmarks that share
characteristics with real-world problems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.13834v2,2021-03-26T21:41:14Z,2021-03-25T13:28:38Z,Self-Imitation Learning by Planning,"Imitation learning (IL) enables robots to acquire skills quickly by
transferring expert knowledge, which is widely adopted in reinforcement
learning (RL) to initialize exploration. However, in long-horizon motion
planning tasks, a challenging problem in deploying IL and RL methods is how to
generate and collect massive, broadly distributed data such that these methods
can generalize effectively. In this work, we solve this problem using our
proposed approach called {self-imitation learning by planning (SILP)}, where
demonstration data are collected automatically by planning on the visited
states from the current policy. SILP is inspired by the observation that
successfully visited states in the early reinforcement learning stage are
collision-free nodes in the graph-search based motion planner, so we can plan
and relabel robot's own trials as demonstrations for policy learning. Due to
these self-generated demonstrations, we relieve the human operator from the
laborious data preparation process required by IL and RL methods in solving
complex motion planning tasks. The evaluation results show that our SILP method
achieves higher success rates and enhances sample efficiency compared to
selected baselines, and the policy learned in simulation performs well in a
real-world placement task with changing goals and obstacles.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.13477v2,2021-03-26T02:49:43Z,2021-03-24T20:52:23Z,A Survey of Multimedia Technologies and Robust Algorithms,"Multimedia technologies are now more practical and deployable in real life,
and the algorithms are widely used in various researching areas such as deep
learning, signal processing, haptics, computer vision, robotics, and medical
multimedia processing. This survey provides an overview of multimedia
technologies and robust algorithms in multimedia data processing, medical
multimedia processing, human facial expression tracking and pose recognition,
and multimedia in education and training. This survey will also analyze and
propose a future research direction based on the overview of current robust
algorithms and multimedia technologies. We want to thank the research and
previous work done by the Multimedia Research Centre (MRC), the University of
Alberta, which is the inspiration and starting point for future research.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.12321v1,2021-03-23T05:33:59Z,2021-03-23T05:33:59Z,Learning 6DoF Grasping Using Reward-Consistent Demonstration,"As the number of the robot's degrees of freedom increases, the implementation
of robot motion becomes more complex and difficult. In this study, we focus on
learning 6DOF-grasping motion and consider dividing the grasping motion into
multiple tasks. We propose to combine imitation and reinforcement learning in
order to facilitate a more efficient learning of the desired motion. In order
to collect demonstration data as teacher data for the imitation learning, we
created a virtual reality (VR) interface that allows humans to operate the
robot intuitively. Moreover, by dividing the motion into simpler tasks, we
simplify the design of reward functions for reinforcement learning and show in
our experiments a reduction in the steps required to learn the grasping motion.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.10873v1,2021-03-19T15:56:58Z,2021-03-19T15:56:58Z,"Fully Onboard AI-powered Human-Drone Pose Estimation on Ultra-low Power
  Autonomous Flying Nano-UAVs","Artificial intelligence-powered pocket-sized air robots have the potential to
revolutionize the Internet-of-Things ecosystem, acting as autonomous,
unobtrusive, and ubiquitous smart sensors. With a few cm$^{2}$ form-factor,
nano-sized unmanned aerial vehicles (UAVs) are the natural befit for indoor
human-drone interaction missions, as the pose estimation task we address in
this work. However, this scenario is challenged by the nano-UAVs' limited
payload and computational power that severely relegates the onboard brain to
the sub-100 mW microcontroller unit-class. Our work stands at the intersection
of the novel parallel ultra-low-power (PULP) architectural paradigm and our
general development methodology for deep neural network (DNN) visual pipelines,
i.e., covering from perception to control. Addressing the DNN model design,
from training and dataset augmentation to 8-bit quantization and deployment, we
demonstrate how a PULP-based processor, aboard a nano-UAV, is sufficient for
the real-time execution (up to 135 frame/s) of our novel DNN, called
PULP-Frontnet. We showcase how, scaling our model's memory and computational
requirement, we can significantly improve the onboard inference (top energy
efficiency of 0.43 mJ/frame) with no compromise in the quality-of-result vs. a
resource-unconstrained baseline (i.e., full-precision DNN). Field experiments
demonstrate a closed-loop top-notch autonomous navigation capability, with a
heavily resource-constrained 27-gram Crazyflie 2.1 nano-quadrotor. Compared
against the control performance achieved using an ideal sensing setup, onboard
relative pose inference yields excellent drone behavior in terms of median
absolute errors, such as positional (onboard: 41 cm, ideal: 26 cm) and angular
(onboard: 3.7$^{\circ}$, ideal: 4.1$^{\circ}$).",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.10804v1,2021-03-19T13:48:25Z,2021-03-19T13:48:25Z,"Enhancing Human-in-the-Loop Adaptive Systems through Digital Twins and
  VR Interfaces","Self-adaptation approaches usually rely on closed-loop controllers that avoid
human intervention from adaptation. While such fully automated approaches have
proven successful in many application domains, there are situations where human
involvement in the adaptation process is beneficial or even necessary. For such
""human-in-the-loop"" adaptive systems, two major challenges, namely transparency
and controllability, have to be addressed to include the human in the
self-adaptation loop. Transparency means that relevant context information
about the adaptive systems and its context is represented based on a digital
twin enabling the human an immersive and realistic view. Concerning
controllability, the decision-making and adaptation operations should be
managed in a natural and interactive way. As existing human-in-the-loop
adaptation approaches do not fully cover these aspects, we investigate
alternative human-in-the-loop strategies by using a combination of digital
twins and virtual reality (VR) interfaces. Based on the concept of the digital
twin, we represent a self-adaptive system and its respective context in a
virtual environment. With the help of a VR interface, we support an immersive
and realistic human involvement in the self-adaptation loop by mirroring the
physical entities of the real world to the VR interface. For integrating the
human in the decision-making and adaptation process, we have implemented and
analyzed two different human-in-the-loop strategies in VR: a procedural control
where the human can control the decision making-process and adaptations through
VR interactions (human-controlled) and a declarative control where the human
specifies the goal state and the configuration is delegated to an AI planner
(mixed-initiative). We illustrate and evaluate our approach based on an
autonomic robot system that is accessible and controlled through a VR
interface.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.10562v1,2021-03-18T23:15:35Z,2021-03-18T23:15:35Z,Dynamic Grasping with Reachability and Motion Awareness,"Grasping in dynamic environments presents a unique set of challenges. A
stable and reachable grasp can become unreachable and unstable as the target
object moves, motion planning needs to be adaptive and in real time, the delay
in computation makes prediction necessary. In this paper, we present a dynamic
grasping framework that is reachability-aware and motion-aware. Specifically,
we model the reachability space of the robot using a signed distance field
which enables us to quickly screen unreachable grasps. Also, we train a neural
network to predict the grasp quality conditioned on the current motion of the
target. Using these as ranking functions, we quickly filter a large grasp
database to a few grasps in real time. In addition, we present a seeding
approach for arm motion generation that utilizes solution from previous time
step. This quickly generates a new arm trajectory that is close to the previous
plan and prevents fluctuation. We implement a recurrent neural network (RNN)
for modelling and predicting the object motion. Our extensive experiments
demonstrate the importance of each of these components and we validate our
pipeline on a real robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.09720v2,2021-03-31T14:13:29Z,2021-03-17T15:24:02Z,Few-Shot Visual Grounding for Natural Human-Robot Interaction,"Natural Human-Robot Interaction (HRI) is one of the key components for
service robots to be able to work in human-centric environments. In such
dynamic environments, the robot needs to understand the intention of the user
to accomplish a task successfully. Towards addressing this point, we propose a
software architecture that segments a target object from a crowded scene,
indicated verbally by a human user. At the core of our system, we employ a
multi-modal deep neural network for visual grounding. Unlike most grounding
methods that tackle the challenge using pre-trained object detectors via a
two-stepped process, we develop a single stage zero-shot model that is able to
provide predictions in unseen data. We evaluate the performance of the proposed
model on real RGB-D data collected from public scene datasets. Experimental
results showed that the proposed model performs well in terms of accuracy and
speed, while showcasing robustness to variation in the natural language input.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.08022v1,2021-03-14T20:13:06Z,2021-03-14T20:13:06Z,"Success Weighted by Completion Time: A Dynamics-Aware Evaluation
  Criteria for Embodied Navigation","We present Success weighted by Completion Time (SCT), a new metric for
evaluating navigation performance for mobile robots. Several related works on
navigation have used Success weighted by Path Length (SPL) as the primary
method of evaluating the path an agent makes to a goal location, but SPL is
limited in its ability to properly evaluate agents with complex dynamics. In
contrast, SCT explicitly takes the agent's dynamics model into consideration,
and aims to accurately capture how well the agent has approximated the fastest
navigation behavior afforded by its dynamics. While several embodied navigation
works use point-turn dynamics, we focus on unicycle-cart dynamics for our
agent, which better exemplifies the dynamics model of popular mobile robotics
platforms (e.g., LoCoBot, TurtleBot, Fetch, etc.). We also present
RRT*-Unicycle, an algorithm for unicycle dynamics that estimates the fastest
collision-free path and completion time from a starting pose to a goal location
in an environment containing obstacles. We experiment with deep reinforcement
learning and reward shaping to train and compare the navigation performance of
agents with different dynamics models. In evaluating these agents, we show that
in contrast to SPL, SCT is able to capture the advantages in navigation speed a
unicycle model has over a simpler point-turn model of dynamics. Lastly, we show
that we can successfully deploy our trained models and algorithms outside of
simulation in the real world. We embody our agents in an real robot to navigate
an apartment, and show that they can generalize in a zero-shot manner.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.07492v4,2021-08-02T14:06:51Z,2021-03-12T19:25:28Z,"Continual Learning for Recurrent Neural Networks: an Empirical
  Evaluation","Learning continuously during all model lifetime is fundamental to deploy
machine learning solutions robust to drifts in the data distribution. Advances
in Continual Learning (CL) with recurrent neural networks could pave the way to
a large number of applications where incoming data is non stationary, like
natural language processing and robotics. However, the existing body of work on
the topic is still fragmented, with approaches which are application-specific
and whose assessment is based on heterogeneous learning protocols and datasets.
In this paper, we organize the literature on CL for sequential data processing
by providing a categorization of the contributions and a review of the
benchmarks. We propose two new benchmarks for CL with sequential data based on
existing datasets, whose characteristics resemble real-world applications. We
also provide a broad empirical evaluation of CL and Recurrent Neural Networks
in class-incremental scenario, by testing their ability to mitigate forgetting
with a number of different strategies which are not specific to sequential data
processing. Our results highlight the key role played by the sequence length
and the importance of a clear specification of the CL scenario.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.06326v2,2021-07-05T03:46:03Z,2021-03-10T20:13:21Z,"S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement
  Learning","Offline reinforcement learning proposes to learn policies from large
collected datasets without interacting with the physical environment. These
algorithms have made it possible to learn useful skills from data that can then
be deployed in the environment in real-world settings where interactions may be
costly or dangerous, such as autonomous driving or factories. However, current
algorithms overfit to the dataset they are trained on and exhibit poor
out-of-distribution generalization to the environment when deployed. In this
paper, we study the effectiveness of performing data augmentations on the state
space, and study 7 different augmentation schemes and how they behave with
existing offline RL algorithms. We then combine the best data performing
augmentation scheme with a state-of-the-art Q-learning technique, and improve
the function approximation of the Q-networks by smoothening out the learned
state-action space. We experimentally show that using this Surprisingly Simple
Self-Supervision technique in RL (S4RL), we significantly improve over the
current state-of-the-art algorithms on offline robot learning environments such
as MetaWorld [1] and RoboSuite [2,3], and benchmark datasets such as D4RL [4].",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.05349v1,2021-03-09T10:58:51Z,2021-03-09T10:58:51Z,"I am Robot: Neuromuscular Reinforcement Learning to Actuate Human Limbs
  through Functional Electrical Stimulation","Human movement disorders or paralysis lead to the loss of control of muscle
activation and thus motor control. Functional Electrical Stimulation (FES) is
an established and safe technique for contracting muscles by stimulating the
skin above a muscle to induce its contraction. However, an open challenge
remains on how to restore motor abilities to human limbs through FES, as the
problem of controlling the stimulation is unclear. We are taking a robotics
perspective on this problem, by developing robot learning algorithms that
control the ultimate humanoid robot, the human body, through electrical muscle
stimulation. Human muscles are not trivial to control as actuators due to their
force production being non-stationary as a result of fatigue and other internal
state changes, in contrast to robot actuators which are well-understood and
stationary over broad operation ranges. We present our Deep Reinforcement
Learning approach to the control of human muscles with FES, using a recurrent
neural network for dynamic state representation, to overcome the unobserved
elements of the behaviour of human muscles under external stimulation. We
demonstrate our technique both in neuromuscular simulations but also
experimentally on a human. Our results show that our controller can learn to
manipulate human muscles, applying appropriate levels of stimulation to achieve
the given tasks while compensating for advancing muscle fatigue which arises
throughout the tasks. Additionally, our technique can learn quickly enough to
be implemented in real-world human-in-the-loop settings.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.05293v1,2021-03-09T08:38:28Z,2021-03-09T08:38:28Z,"Decentralized Circle Formation Control for Fish-like Robots in the
  Real-world via Reinforcement Learning","In this paper, the circle formation control problem is addressed for a group
of cooperative underactuated fish-like robots involving unknown nonlinear
dynamics and disturbances. Based on the reinforcement learning and cognitive
consistency theory, we propose a decentralized controller without the knowledge
of the dynamics of the fish-like robots. The proposed controller can be
transferred from simulation to reality. It is only trained in our established
simulation environment, and the trained controller can be deployed to real
robots without any manual tuning. Simulation results confirm that the proposed
model-free robust formation control method is scalable with respect to the
group size of the robots and outperforms other representative RL algorithms.
Several experiments in the real world verify the effectiveness of our RL-based
approach for circle formation control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.05225v3,2021-03-29T20:57:58Z,2021-03-09T05:06:47Z,A Scavenger Hunt for Service Robots,"Creating robots that can perform general-purpose service tasks in a
human-populated environment has been a longstanding grand challenge for AI and
Robotics research. One particularly valuable skill that is relevant to a wide
variety of tasks is the ability to locate and retrieve objects upon request.
This paper models this skill as a Scavenger Hunt (SH) game, which we formulate
as a variation of the NP-hard stochastic traveling purchaser problem. In this
problem, the goal is to find a set of objects as quickly as possible, given
probability distributions of where they may be found. We investigate the
performance of several solution algorithms for the SH problem, both in
simulation and on a real mobile robot. We use Reinforcement Learning (RL) to
train an agent to plan a minimal cost path, and show that the RL agent can
outperform a range of heuristic algorithms, achieving near optimal performance.
In order to stimulate research on this problem, we introduce a publicly
available software stack and associated website that enable users to upload
scavenger hunts which robots can download, perform, and learn from to
continually improve their performance on future hunts.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2103.04490v2,2021-06-19T20:57:34Z,2021-03-07T23:49:59Z,Adaptive-Control-Oriented Meta-Learning for Nonlinear Systems,"Real-time adaptation is imperative to the control of robots operating in
complex, dynamic environments. Adaptive control laws can endow even nonlinear
systems with good trajectory tracking performance, provided that any uncertain
dynamics terms are linearly parameterizable with known nonlinear features.
However, it is often difficult to specify such features a priori, such as for
aerodynamic disturbances on rotorcraft or interaction forces between a
manipulator arm and various objects. In this paper, we turn to data-driven
modeling with neural networks to learn, offline from past data, an adaptive
controller with an internal parametric model of these nonlinear features. Our
key insight is that we can better prepare the controller for deployment with
control-oriented meta-learning of features in closed-loop simulation, rather
than regression-oriented meta-learning of features to fit input-output data.
Specifically, we meta-learn the adaptive controller with closed-loop tracking
simulation as the base-learner and the average tracking error as the
meta-objective. With a nonlinear planar rotorcraft subject to wind, we
demonstrate that our adaptive controller outperforms other controllers trained
with regression-oriented meta-learning when deployed in closed-loop for
trajectory tracking control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.08080v1,2021-02-16T11:06:45Z,2021-02-16T11:06:45Z,Learning the Noise of Failure: Intelligent System Tests for Robots,"Roboticists usually test new control software in simulation environments
before evaluating its functionality on real-world robots. Simulations reduce
the risk of damaging the hardware and can significantly increase the
development process's efficiency in the form of automated system tests.
  However, many flaws in the software remain undetected in simulation data,
revealing their harmful effects on the system only in time-consuming
experiments. In reality, such irregularities are often easily recognized solely
by the robot's airborne noise during operation. We propose a simulated noise
estimate for the detection of failures in automated system tests of robots. The
classification of flaws uses classical machine learning - a support vector
machine - to identify different failure classes from the scalar noise estimate.
  The methodology is evaluated on simulation data from the humanoid robot LOLA.
The approach yields high failure detection accuracy with a low false-positive
rate, enabling its use for stricter automated system tests. Results indicate
that a single trained model may work for different robots. The proposed
technique is provided to the community in the form of the open-source tool
NoisyTest, making it easy to test data from any robot. In a broader scope, the
technique may empower real-world automated system tests without human
evaluation of success or failure.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.07353v2,2021-04-01T02:16:38Z,2021-02-15T05:36:34Z,"SkyMapper Optical Follow-up of Gravitational Wave Triggers: Alert
  Science Data Pipeline and LIGO/Virgo O3 Run","We present an overview of the SkyMapper optical follow-up program for
gravitational-wave event triggers from the LIGO/Virgo observatories, which aims
at identifying early GW170817-like kilonovae out to $\sim 200$ Mpc distance. We
describe our robotic facility for rapid transient follow-up, which can target
most of the sky at $\delta<+10\deg $ to a depth of $i_\mathrm{AB}\approx 20$
mag. We have implemented a new software pipeline to receive LIGO/Virgo alerts,
schedule observations and examine the incoming real-time data stream for
transient candidates. We adopt a real-bogus classifier using ensemble-based
machine learning techniques, attaining high completeness ($\sim$98%) and purity
($\sim$91%) over our whole magnitude range. Applying further filtering to
remove common image artefacts and known sources of transients, such as
asteroids and variable stars, reduces the number of candidates by a factor of
more than 10. We demonstrate the system performance with data obtained for
GW190425, a binary neutron star merger detected during the LIGO/Virgo O3
observing campaign. In time for the LIGO/Virgo O4 run, we will have deeper
reference images allowing transient detection to $i_\mathrm{AB}\approx $21 mag.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.03923v2,2021-08-04T11:14:28Z,2021-02-07T21:33:39Z,"DroneTrap: Drone Catching in Midair by Soft Robotic Hand with
  Color-Based Force Detection and Hand Gesture Recognition","The paper proposes a novel concept of docking drones to make this process as
safe and fast as possible. The idea behind the project is that a robot with a
soft gripper grasps the drone in midair. The human operator navigates the
robotic arm with the ML-based gesture recognition interface. The 3-finger robot
hand with soft fingers is equipped with touch sensors, making it possible to
achieve safe drone catching and avoid inadvertent damage to the drone's
propellers and motors. Additionally, the soft hand is featured with a unique
color-based force estimation technology based on a computer vision (CV) system.
Moreover, the visual color-changing system makes it easier for the human
operator to interpret the applied forces.
  Without any additional programming, the operator has full real-time control
of the robot's motion and task execution by wearing a mocap glove with gesture
recognition, which was developed and applied for the high-level control of
DroneTrap. The experimental results revealed that the developed color-based
force estimation can be applied for rigid object capturing with high precision
(95.3\%). The proposed technology can potentially revolutionize the landing and
deployment of drones for parcel delivery on uneven ground, structure
maintenance and inspection, risque operations, and etc.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2102.03705v1,2021-02-07T03:14:12Z,2021-02-07T03:14:12Z,"An Analytic Layer-wise Deep Learning Framework with Applications to
  Robotics","Deep learning has achieved great success in many applications, but it has
been less well analyzed from the theoretical perspective. To deploy deep
learning algorithms in a predictable and stable manner is particularly
important in robotics, as robots are active agents that need to interact safely
with the physical world. This paper presents an analytic deep learning
framework for fully connected neural networks, which can be applied for both
regression problems and classification problems. Examples for regression and
classification problems include online robot control and robot vision. We
present two layer-wise learning algorithms such that the convergence of the
learning systems can be analyzed. Firstly, an inverse layer-wise learning
algorithm for multilayer networks with convergence analysis for each layer is
presented to understand the problems of layer-wise deep learning. Secondly, a
forward progressive learning algorithm where the deep networks are built
progressively by using single hidden layer networks is developed to achieve
better accuracy. It is shown that the progressive learning method can be used
for fine-tuning of weights from convergence point of view. The effectiveness of
the proposed framework is illustrated based on classical benchmark recognition
tasks using the MNIST and CIFAR-10 datasets and the results show a good balance
between performance and explainability. The proposed method is subsequently
applied for online learning of robot kinematics and experimental results on
kinematic control of UR5e robot with unknown model are presented.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.11451v1,2021-01-27T14:35:52Z,2021-01-27T14:35:52Z,"Controlling by Showing: i-Mimic: A Video-based Method to Control Robotic
  Arms","A novel concept of vision-based intelligent control of robotic arms is
developed here in this work. This work enables the controlling of robotic arms
motion only with visual inputs, that is, controlling by showing the videos of
correct movements. This work can broadly be sub-divided into two segments. The
first part of this work is to develop an unsupervised vision-based method to
control robotic arm in 2-D plane, and the second one is with deep CNN in the
same task in 3-D plane. The first method is unsupervised, where our aim is to
perform mimicking of human arm motion in real-time by a manipulator. We
developed a network, namely the vision-to-motion optical network (DON), where
the input should be a video stream containing hand movements of human, the the
output would be out the velocity and torque information of the hand movements
shown in the videos. The output information of the DON is then fed to the
robotic arm by enabling it to generate motion according to the real hand
videos. The method has been tested with both live-stream video feed as well as
on recorded video obtained from a monocular camera even by intelligently
predicting the trajectory of human hand hand when it gets occluded. This is why
the mimicry of the arm incorporates some intelligence to it and becomes
intelligent mimic (i-mimic). Alongside the unsupervised method another method
has also been developed deploying the deep neural network technique with CNN
(Convolutional Neural Network) to perform the mimicking, where labelled
datasets are used for training. The same dataset, as used in the unsupervised
DON-based method, is used in the deep CNN method, after manual annotations.
Both the proposed methods are validated with off-line as well as with on-line
video datasets in real-time. The entire methodology is validated with real-time
1-link and simulated n-link manipulators alongwith suitable comparisons.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.10463v2,2021-01-27T02:22:33Z,2021-01-25T22:34:06Z,"RTGPU: Real-Time GPU Scheduling of Hard Deadline Parallel Tasks with
  Fine-Grain Utilization","Many emerging cyber-physical systems, such as autonomous vehicles and robots,
rely heavily on artificial intelligence and machine learning algorithms to
perform important system operations. Since these highly parallel applications
are computationally intensive, they need to be accelerated by graphics
processing units (GPUs) to meet stringent timing constraints. However, despite
the wide adoption of GPUs, efficiently scheduling multiple GPU applications
while providing rigorous real-time guarantees remains a challenge. In this
paper, we propose RTGPU, which can schedule the execution of multiple GPU
applications in real-time to meet hard deadlines. Each GPU application can have
multiple CPU execution and memory copy segments, as well as GPU kernels. We
start with a model to explicitly account for the CPU and memory copy segments
of these applications. We then consider the GPU architecture in the development
of a precise timing model for the GPU kernels and leverage a technique known as
persistent threads to implement fine-grained kernel scheduling with improved
performance through interleaved execution. Next, we propose a general method
for scheduling parallel GPU applications in real time. Finally, to schedule
multiple parallel GPU applications, we propose a practical real-time scheduling
algorithm based on federated scheduling and grid search (for GPU kernel
segments) with uniprocessor fixed priority scheduling (for multiple CPU and
memory copy segments). Our approach provides superior schedulability compared
with previous work, and gives real-time guarantees to meet hard deadlines for
multiple GPU applications according to comprehensive validation and evaluation
on a real NVIDIA GTX1080Ti GPU system.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.06409v1,2021-01-16T09:00:34Z,2021-01-16T09:00:34Z,Shape Back-Projection In 3D Scenes,"In this work, we propose a novel framework shape back-projection for
computationally efficient point cloud processing in a probabilistic manner. The
primary component of the technique is shape histogram and a back-projection
procedure. The technique measures similarity between 3D surfaces, by analyzing
their geometrical properties. It is analogous to color back-projection which
measures similarity between images, simply by looking at their color
distributions. In the overall process, first, shape histogram of a sample
surface (e.g. planar) is computed, which captures the profile of surface
normals around a point in form of a probability distribution. Later, the
histogram is back-projected onto a test surface and a likelihood score is
obtained. The score depicts that how likely a point in the test surface behaves
similar to the sample surface, geometrically. Shape back-projection finds its
application in binary surface classification, high curvature edge detection in
unorganized point cloud, automated point cloud labeling for 3D-CNNs
(convolutional neural network) etc. The algorithm can also be used for
real-time robotic operations such as autonomous object picking in warehouse
automation, ground plane extraction for autonomous vehicles and can be deployed
easily on computationally limited platforms (UAVs).",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.06405v1,2021-01-16T08:50:36Z,2021-01-16T08:50:36Z,Semi Supervised Deep Quick Instance Detection and Segmentation,"In this paper, we present a semi supervised deep quick learning framework for
instance detection and pixel-wise semantic segmentation of images in a dense
clutter of items. The framework can quickly and incrementally learn novel items
in an online manner by real-time data acquisition and generating corresponding
ground truths on its own. To learn various combinations of items, it can
synthesize cluttered scenes, in real time. The overall approach is based on the
tutor-child analogy in which a deep network (tutor) is pretrained for
class-agnostic object detection which generates labeled data for another deep
network (child). The child utilizes a customized convolutional neural network
head for the purpose of quick learning. There are broadly four key components
of the proposed framework semi supervised labeling, occlusion aware clutter
synthesis, a customized convolutional neural network head, and instance
detection. The initial version of this framework was implemented during our
participation in Amazon Robotics Challenge (ARC), 2017. Our system was ranked
3rd, 4th and 5th worldwide in pick, stow-pick and stow task respectively. The
proposed framework is an improved version over ARC17 where novel features such
as instance detection and online learning has been added.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2101.02073v1,2021-01-06T14:49:29Z,2021-01-06T14:49:29Z,Shallow-UWnet : Compressed Model for Underwater Image Enhancement,"Over the past few decades, underwater image enhancement has attracted
increasing amount of research effort due to its significance in underwater
robotics and ocean engineering. Research has evolved from implementing
physics-based solutions to using very deep CNNs and GANs. However, these
state-of-art algorithms are computationally expensive and memory intensive.
This hinders their deployment on portable devices for underwater exploration
tasks. These models are trained on either synthetic or limited real world
datasets making them less practical in real-world scenarios. In this paper we
propose a shallow neural network architecture, \textbf{Shallow-UWnet} which
maintains performance and has fewer parameters than the state-of-art models. We
also demonstrated the generalization of our model by benchmarking its
performance on combination of synthetic and real-world datasets.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.12142v1,2020-12-22T16:25:12Z,2020-12-22T16:25:12Z,High-Speed Robot Navigation using Predicted Occupancy Maps,"Safe and high-speed navigation is a key enabling capability for real world
deployment of robotic systems. A significant limitation of existing approaches
is the computational bottleneck associated with explicit mapping and the
limited field of view (FOV) of existing sensor technologies. In this paper, we
study algorithmic approaches that allow the robot to predict spaces extending
beyond the sensor horizon for robust planning at high speeds. We accomplish
this using a generative neural network trained from real-world data without
requiring human annotated labels. Further, we extend our existing control
algorithms to support leveraging the predicted spaces to improve collision-free
planning and navigation at high speeds. Our experiments are conducted on a
physical robot based on the MIT race car using an RGBD sensor where were able
to demonstrate improved performance at 4 m/s compared to a controller not
operating on predicted regions of the map.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.09812v2,2021-03-26T11:12:28Z,2020-12-17T18:22:32Z,ViNG: Learning Open-World Navigation with Visual Goals,"We propose a learning-based navigation system for reaching visually indicated
goals and demonstrate this system on a real mobile robot platform. Learning
provides an appealing alternative to conventional methods for robotic
navigation: instead of reasoning about environments in terms of geometry and
maps, learning can enable a robot to learn about navigational affordances,
understand what types of obstacles are traversable (e.g., tall grass) or not
(e.g., walls), and generalize over patterns in the environment. However, unlike
conventional planning algorithms, it is harder to change the goal for a learned
policy during deployment. We propose a method for learning to navigate towards
a goal image of the desired destination. By combining a learned policy with a
topological graph constructed out of previously observed data, our system can
determine how to reach this visually indicated goal even in the presence of
variable appearance and lighting. Three key insights, waypoint proposal, graph
pruning and negative mining, enable our method to learn to navigate in
real-world environments using only offline data, a setting where prior methods
struggle. We instantiate our method on a real outdoor ground robot and show
that our system, which we call ViNG, outperforms previously-proposed methods
for goal-conditioned reinforcement learning, including other methods that
incorporate reinforcement learning and search. We also study how \sysName
generalizes to unseen environments and evaluate its ability to adapt to such an
environment with growing experience. Finally, we demonstrate ViNG on a number
of real-world applications, such as last-mile delivery and warehouse
inspection. We encourage the reader to visit the project website for videos of
our experiments and demonstrations sites.google.com/view/ving-robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.08456v2,2022-02-10T22:47:52Z,2020-12-15T17:54:07Z,"TACTO: A Fast, Flexible, and Open-source Simulator for High-Resolution
  Vision-based Tactile Sensors","Simulators perform an important role in prototyping, debugging, and
benchmarking new advances in robotics and learning for control. Although many
physics engines exist, some aspects of the real world are harder than others to
simulate. One of the aspects that have so far eluded accurate simulation is
touch sensing. To address this gap, we present TACTO - a fast, flexible, and
open-source simulator for vision-based tactile sensors. This simulator allows
to render realistic high-resolution touch readings at hundreds of frames per
second, and can be easily configured to simulate different vision-based tactile
sensors, including DIGIT and OmniTact. In this paper, we detail the principles
that drove the implementation of TACTO and how they are reflected in its
architecture. We demonstrate TACTO on a perceptual task, by learning to predict
grasp stability using touch from 1 million grasps, and on a marble manipulation
control task. Moreover, we provide a proof-of-concept that TACTO can be
successfully used for Sim2Real applications. We believe that TACTO is a step
towards the widespread adoption of touch sensing in robotic applications, and
to enable machine learning practitioners interested in multi-modal learning and
control. TACTO is open-source at https://github.com/facebookresearch/tacto.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.08174v2,2021-03-29T17:15:00Z,2020-12-15T09:49:22Z,"Towards open and expandable cognitive AI architectures for large-scale
  multi-agent human-robot collaborative learning","Learning from Demonstration (LfD) constitutes one of the most robust
methodologies for constructing efficient cognitive robotic systems. Despite the
large body of research works already reported, current key technological
challenges include those of multi-agent learning and long-term autonomy.
Towards this direction, a novel cognitive architecture for multi-agent LfD
robotic learning is introduced, targeting to enable the reliable deployment of
open, scalable and expandable robotic systems in large-scale and complex
environments. In particular, the designed architecture capitalizes on the
recent advances in the Artificial Intelligence (AI) field, by establishing a
Federated Learning (FL)-based framework for incarnating a multi-human
multi-robot collaborative learning environment. The fundamental
conceptualization relies on employing multiple AI-empowered cognitive processes
(implementing various robotic tasks) that operate at the edge nodes of a
network of robotic platforms, while global AI models (underpinning the
aforementioned robotic tasks) are collectively created and shared among the
network, by elegantly combining information from a large number of human-robot
interaction instances. Regarding pivotal novelties, the designed cognitive
architecture a) introduces a new FL-based formalism that extends the
conventional LfD learning paradigm to support large-scale multi-agent
operational settings, b) elaborates previous FL-based self-learning robotic
schemes so as to incorporate the human in the learning loop and c) consolidates
the fundamental principles of FL with additional sophisticated AI-enabled
learning methodologies for modelling the multi-level inter-dependencies among
the robotic tasks. The applicability of the proposed framework is explained
using an example of a real-world industrial case study for agile
production-based Critical Raw Materials (CRM) recovery.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.06413v1,2020-12-11T15:11:18Z,2020-12-11T15:11:18Z,A Vision-based Sensing Approach for a Spherical Soft Robotic Arm,"Sensory feedback is essential for the control of soft robotic systems and to
enable deployment in a variety of different tasks. Proprioception refers to
sensing the robot's own state and is of crucial importance in order to deploy
soft robotic systems outside of laboratory environments, i.e. where no external
sensing, such as motion capture systems, is available.
  A vision-based sensing approach for a soft robotic arm made from fabric is
presented, leveraging the high-resolution sensory feedback provided by cameras.
No mechanical interaction between the sensor and the soft structure is required
and consequently, the compliance of the soft system is preserved. The
integration of a camera into an inflatable, fabric-based bellow actuator is
discussed. Three actuators, each featuring an integrated camera, are used to
control the spherical robotic arm and simultaneously provide sensory feedback
of the two rotational degrees of freedom. A convolutional neural network
architecture predicts the two angles describing the robot's orientation from
the camera images. Ground truth data is provided by a motion capture system
during the training phase of the supervised learning approach and its
evaluation thereafter.
  The camera-based sensing approach is able to provide estimates of the
orientation in real-time with an accuracy of about one degree. The reliability
of the sensing approach is demonstrated by using the sensory feedback to
control the orientation of the robotic arm in closed-loop.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.06268v3,2022-05-31T20:23:16Z,2020-12-11T12:03:56Z,Motion Mappings for Continuous Bilateral Teleoperation,"Mapping operator motions to a robot is a key problem in teleoperation. Due to
differences between workspaces, such as object locations, it is particularly
challenging to derive smooth motion mappings that fulfill different goals (e.g.
picking objects with different poses on the two sides or passing through key
points). Indeed, most state-of-the-art methods rely on mode switches, leading
to a discontinuous, low-transparency experience. In this paper, we propose a
unified formulation for position, orientation and velocity mappings based on
the poses of objects of interest in the operator and robot workspaces. We apply
it in the context of bilateral teleoperation. Two possible implementations to
achieve the proposed mappings are studied: an iterative approach based on
locally-weighted translations and rotations, and a neural network approach.
Evaluations are conducted both in simulation and using two torque-controlled
Franka Emika Panda robots. Our results show that, despite longer training
times, the neural network approach provides faster mapping evaluations and
lower interaction forces for the operator, which are crucial for continuous,
real-time teleoperation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.04746v2,2021-04-02T22:28:33Z,2020-12-08T21:20:54Z,"Robust Neural Routing Through Space Partitions for Camera Relocalization
  in Dynamic Indoor Environments","Localizing the camera in a known indoor environment is a key building block
for scene mapping, robot navigation, AR, etc. Recent advances estimate the
camera pose via optimization over the 2D/3D-3D correspondences established
between the coordinates in 2D/3D camera space and 3D world space. Such a
mapping is estimated with either a convolution neural network or a decision
tree using only the static input image sequence, which makes these approaches
vulnerable to dynamic indoor environments that are quite common yet challenging
in the real world. To address the aforementioned issues, in this paper, we
propose a novel outlier-aware neural tree which bridges the two worlds, deep
learning and decision tree approaches. It builds on three important blocks: (a)
a hierarchical space partition over the indoor scene to construct the decision
tree; (b) a neural routing function, implemented as a deep classification
network, employed for better 3D scene understanding; and (c) an outlier
rejection module used to filter out dynamic points during the hierarchical
routing process. Our proposed algorithm is evaluated on the RIO-10 benchmark
developed for camera relocalization in dynamic indoor environments. It achieves
robust neural routing through space partitions and outperforms the
state-of-the-art approaches by around 30% on camera pose accuracy, while
running comparably fast for evaluation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.04406v1,2020-12-08T12:51:14Z,2020-12-08T12:51:14Z,"NavRep: Unsupervised Representations for Reinforcement Learning of Robot
  Navigation in Dynamic Human Environments","Robot navigation is a task where reinforcement learning approaches are still
unable to compete with traditional path planning. State-of-the-art methods
differ in small ways, and do not all provide reproducible, openly available
implementations. This makes comparing methods a challenge. Recent research has
shown that unsupervised learning methods can scale impressively, and be
leveraged to solve difficult problems. In this work, we design ways in which
unsupervised learning can be used to assist reinforcement learning for robot
navigation. We train two end-to-end, and 18 unsupervised-learning-based
architectures, and compare them, along with existing approaches, in unseen test
cases. We demonstrate our approach working on a real life robot. Our results
show that unsupervised learning methods are competitive with end-to-end
methods. We also highlight the importance of various components such as input
representation, predictive unsupervised learning, and latent features. We make
all our models publicly available, as well as training and testing
environments, and tools. This release also includes OpenAI-gym-compatible
environments designed to emulate the training conditions described by other
papers, with as much fidelity as possible. Our hope is that this helps in
bringing together the field of RL for robot navigation, and allows meaningful
comparisons across state-of-the-art methods.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.04210v1,2020-12-08T04:50:05Z,2020-12-08T04:50:05Z,"The Architectural Implications of Distributed Reinforcement Learning on
  CPU-GPU Systems","With deep reinforcement learning (RL) methods achieving results that exceed
human capabilities in games, robotics, and simulated environments, continued
scaling of RL training is crucial to its deployment in solving complex
real-world problems. However, improving the performance scalability and power
efficiency of RL training through understanding the architectural implications
of CPU-GPU systems remains an open problem. In this work we investigate and
improve the performance and power efficiency of distributed RL training on
CPU-GPU systems by approaching the problem not solely from the GPU
microarchitecture perspective but following a holistic system-level analysis
approach. We quantify the overall hardware utilization on a state-of-the-art
distributed RL training framework and empirically identify the bottlenecks
caused by GPU microarchitectural, algorithmic, and system-level design choices.
We show that the GPU microarchitecture itself is well-balanced for
state-of-the-art RL frameworks, but further investigation reveals that the
number of actors running the environment interactions and the amount of
hardware resources available to them are the primary performance and power
efficiency limiters. To this end, we introduce a new system design metric,
CPU/GPU ratio, and show how to find the optimal balance between CPU and GPU
resources when designing scalable and efficient CPU-GPU systems for RL
training.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.02417v2,2020-12-07T02:34:05Z,2020-12-04T06:02:26Z,"Autonomous Navigation with Mobile Robots using Deep Learning and the
  Robot Operating System","Autonomous navigation is a long-standing field of robotics research, which
provides an essential capability for mobile robots to execute a series of tasks
on the same environments performed by human everyday. In this chapter, we
present a set of algorithms to train and deploy deep networks for autonomous
navigation of mobile robots using the Robot Operation System (ROS). We describe
three main steps to tackle this problem: i) collecting data in simulation
environments using ROS and Gazebo; ii) designing deep network for autonomous
navigation, and iii) deploying the learned policy on mobile robots in both
simulation and real-world. Theoretically, we present deep learning
architectures for robust navigation in normal environments (e.g., man-made
houses, roads) and complex environments (e.g., collapsed cities, or natural
caves). We further show that the use of visual modalities such as RGB, Lidar,
and point cloud is essential to improve the autonomy of mobile robots. Our
project website and demonstration video can be found at
https://sites.google.com/site/autonomousnavigationros.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.01913v1,2020-12-03T13:51:05Z,2020-12-03T13:51:05Z,Transfer Learning as an Enabler of the Intelligent Digital Twin,"Digital Twins have been described as beneficial in many areas, such as
virtual commissioning, fault prediction or reconfiguration planning. Equipping
Digital Twins with artificial intelligence functionalities can greatly expand
those beneficial applications or open up altogether new areas of application,
among them cross-phase industrial transfer learning. In the context of machine
learning, transfer learning represents a set of approaches that enhance
learning new tasks based upon previously acquired knowledge. Here, knowledge is
transferred from one lifecycle phase to another in order to reduce the amount
of data or time needed to train a machine learning algorithm. Looking at common
challenges in developing and deploying industrial machinery with deep learning
functionalities, embracing this concept would offer several advantages: Using
an intelligent Digital Twin, learning algorithms can be designed, configured
and tested in the design phase before the physical system exists and real data
can be collected. Once real data becomes available, the algorithms must merely
be fine-tuned, significantly speeding up commissioning and reducing the
probability of costly modifications. Furthermore, using the Digital Twin's
simulation capabilities virtually injecting rare faults in order to train an
algorithm's response or using reinforcement learning, e.g. to teach a robot,
become practically feasible. This article presents several cross-phase
industrial transfer learning use cases utilizing intelligent Digital Twins. A
real cyber physical production system consisting of an automated welding
machine and an automated guided vehicle equipped with a robot arm is used to
illustrate the respective benefits.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2012.01356v1,2020-12-02T17:56:44Z,2020-12-02T17:56:44Z,"Coinbot: Intelligent Robotic Coin Bag Manipulation Using Deep
  Reinforcement Learning And Machine Teaching","Given the laborious difficulty of moving heavy bags of physical currency in
the cash center of the bank, there is a large demand for training and deploying
safe autonomous systems capable of conducting such tasks in a collaborative
workspace. However, the deformable properties of the bag along with the large
quantity of rigid-body coins contained within it, significantly increases the
challenges of bag detection, grasping and manipulation by a robotic gripper and
arm. In this paper, we apply deep reinforcement learning and machine learning
techniques to the task of controlling a collaborative robot to automate the
unloading of coin bags from a trolley. To accomplish the task-specific process
of gripping flexible materials like coin bags where the center of the mass
changes during manipulation, a special gripper was implemented in simulation
and designed in physical hardware. Leveraging a depth camera and object
detection using deep learning, a bag detection and pose estimation has been
done for choosing the optimal point of grasping. An intelligent approach based
on deep reinforcement learning has been introduced to propose the best
configuration of the robot end-effector to maximize successful grasping. A
boosted motion planning is utilized to increase the speed of motion planning
during robot operation. Real-world trials with the proposed pipeline have
demonstrated success rates over 96\% in a real-world setting.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.15100v1,2020-11-30T18:32:20Z,2020-11-30T18:32:20Z,"From the DESK (Dexterous Surgical Skill) to the Battlefield -- A
  Robotics Exploratory Study","Short response time is critical for future military medical operations in
austere settings or remote areas. Such effective patient care at the point of
injury can greatly benefit from the integration of semi-autonomous robotic
systems. To achieve autonomy, robots would require massive libraries of
maneuvers. While this is possible in controlled settings, obtaining surgical
data in austere settings can be difficult. Hence, in this paper, we present the
Dexterous Surgical Skill (DESK) database for knowledge transfer between robots.
The peg transfer task was selected as it is one of 6 main tasks of laparoscopic
training. Also, we provide a ML framework to evaluate novel transfer learning
methodologies on this database. The collected DESK dataset comprises a set of
surgical robotic skills using the four robotic platforms: Taurus II, simulated
Taurus II, YuMi, and the da Vinci Research Kit. Then, we explored two different
learning scenarios: no-transfer and domain-transfer. In the no-transfer
scenario, the training and testing data were obtained from the same domain;
whereas in the domain-transfer scenario, the training data is a blend of
simulated and real robot data that is tested on a real robot. Using simulation
data enhances the performance of the real robot where limited or no real data
is available. The transfer model showed an accuracy of 81% for the YuMi robot
when the ratio of real-to-simulated data was 22%-78%. For Taurus II and da
Vinci robots, the model showed an accuracy of 97.5% and 93% respectively,
training only with simulation data. Results indicate that simulation can be
used to augment training data to enhance the performance of models in real
scenarios. This shows the potential for future use of surgical data from the
operating room in deployable surgical robots in remote areas.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.12421v2,2021-02-26T17:20:31Z,2020-11-24T22:04:00Z,"Bi-directional Domain Adaptation for Sim2Real Transfer of Embodied
  Navigation Agents","Deep reinforcement learning models are notoriously data hungry, yet
real-world data is expensive and time consuming to obtain. The solution that
many have turned to is to use simulation for training before deploying the
robot in a real environment. Simulation offers the ability to train large
numbers of robots in parallel, and offers an abundance of data. However, no
simulation is perfect, and robots trained solely in simulation fail to
generalize to the real-world, resulting in a ""sim-vs-real gap"". How can we
overcome the trade-off between the abundance of less accurate, artificial data
from simulators and the scarcity of reliable, real-world data? In this paper,
we propose Bi-directional Domain Adaptation (BDA), a novel approach to bridge
the sim-vs-real gap in both directions -- real2sim to bridge the visual domain
gap, and sim2real to bridge the dynamics domain gap. We demonstrate the
benefits of BDA on the task of PointGoal Navigation. BDA with only 5k
real-world (state, action, next-state) samples matches the performance of a
policy fine-tuned with ~600k samples, resulting in a speed-up of ~120x.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.09241v1,2020-11-18T12:30:36Z,2020-11-18T12:30:36Z,"Indoor Point-to-Point Navigation with Deep Reinforcement Learning and
  Ultra-wideband","Indoor autonomous navigation requires a precise and accurate localization
system able to guide robots through cluttered, unstructured and dynamic
environments. Ultra-wideband (UWB) technology, as an indoor positioning system,
offers precise localization and tracking, but moving obstacles and
non-line-of-sight occurrences can generate noisy and unreliable signals. That,
combined with sensors noise, unmodeled dynamics and environment changes can
result in a failure of the guidance algorithm of the robot. We demonstrate how
a power-efficient and low computational cost point-to-point local planner,
learnt with deep reinforcement learning (RL), combined with UWB localization
technology can constitute a robust and resilient to noise short-range guidance
system complete solution. We trained the RL agent on a simulated environment
that encapsulates the robot dynamics and task constraints and then, we tested
the learnt point-to-point navigation policies in a real setting with more than
two-hundred experimental evaluations using UWB localization. Our results show
that the computational efficient end-to-end policy learnt in plain simulation,
that directly maps low-range sensors signals to robot controls, deployed in
combination with ultra-wideband noisy localization in a real environment, can
provide a robust, scalable and at-the-edge low-cost navigation system solution.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.08811v2,2020-12-10T02:25:19Z,2020-11-17T18:14:21Z,"Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its
  Limbs","Quadrupedal robots are skillful at locomotion tasks while lacking
manipulation skills, not to mention dexterous manipulation abilities. Inspired
by the animal behavior and the duality between multi-legged locomotion and
multi-fingered manipulation, we showcase a circus ball challenge on a
quadrupedal robot, ANYmal. We employ a model-free reinforcement learning
approach to train a deep policy that enables the robot to balance and
manipulate a light-weight ball robustly using its limbs without any contact
measurement sensor. The policy is trained in the simulation, in which we
randomize many physical properties with additive noise and inject random
disturbance force during manipulation, and achieves zero-shot deployment on the
real robot without any adjustment. In the hardware experiments, dynamic
performance is achieved with a maximum rotation speed of 15 deg/s, and robust
recovery is showcased under external poking. To our best knowledge, it is the
first work that demonstrates the dexterous dynamic manipulation on a real
quadrupedal robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.08728v2,2020-11-30T06:30:25Z,2020-11-17T16:01:06Z,Fault-Aware Robust Control via Adversarial Reinforcement Learning,"Robots have limited adaptation ability compared to humans and animals in the
case of damage. However, robot damages are prevalent in real-world
applications, especially for robots deployed in extreme environments. The
fragility of robots greatly limits their widespread application. We propose an
adversarial reinforcement learning framework, which significantly increases
robot robustness over joint damage cases in both manipulation tasks and
locomotion tasks. The agent is trained iteratively under the joint damage cases
where it has poor performance. We validate our algorithm on a three-fingered
robot hand and a quadruped robot. Our algorithm can be trained only in
simulation and directly deployed on a real robot without any fine-tuning. It
also demonstrates exceeding success rates over arbitrary joint damage cases.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.07713v1,2020-11-16T04:05:32Z,2020-11-16T04:05:32Z,"DARE: AI-based Diver Action Recognition System using Multi-Channel CNNs
  for AUV Supervision","With the growth of sensing, control and robotic technologies, autonomous
underwater vehicles (AUVs) have become useful assistants to human divers for
performing various underwater operations. In the current practice, the divers
are required to carry expensive, bulky, and waterproof keyboards or
joystick-based controllers for supervision and control of AUVs. Therefore,
diver action-based supervision is becoming increasingly popular because it is
convenient, easier to use, faster, and cost effective. However, the various
environmental, diver and sensing uncertainties present underwater makes it
challenging to train a robust and reliable diver action recognition system. In
this regard, this paper presents DARE, a diver action recognition system, that
is trained based on Cognitive Autonomous Driving Buddy (CADDY) dataset, which
is a rich set of data containing images of different diver gestures and poses
in several different and realistic underwater environments. DARE is based on
fusion of stereo-pairs of camera images using a multi-channel convolutional
neural network supported with a systematically trained tree-topological deep
neural network classifier to enhance the classification performance. DARE is
fast and requires only a few milliseconds to classify one stereo-pair, thus
making it suitable for real-time underwater implementation. DARE is
comparatively evaluated against several existing classifier architectures and
the results show that DARE supersedes the performance of all classifiers for
diver action recognition in terms of overall as well as individual class
accuracies and F1-scores.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.06910v1,2020-11-13T13:49:01Z,2020-11-13T13:49:01Z,"Real time implementation of CTRNN and BPTT algorithm to learn on-line
  biped robot balance: Experiments on the standing posture","This paper describes experimental results regarding the real time
implementation of continuous time recurrent neural networks (CTRNN) and the
dynamic back-propagation through time (BPTT) algorithm for the on-line learning
control laws. Experiments are carried out to control the balance of a biped
robot prototype in its standing posture. The neural controller is trained to
compensate for external perturbations by controlling the torso's joint motions.
Algorithms are embedded in the real time electronic unit of the robot. On-line
learning implementations are presented in detail. The results on learning
behavior and control performance demonstrate the strength and the efficiency of
the proposed approach.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.05748v2,2021-03-28T14:15:04Z,2020-11-11T13:10:11Z,End-To-End Semi-supervised Learning for Differentiable Particle Filters,"Recent advances in incorporating neural networks into particle filters
provide the desired flexibility to apply particle filters in large-scale
real-world applications. The dynamic and measurement models in this framework
are learnable through the differentiable implementation of particle filters.
Past efforts in optimising such models often require the knowledge of true
states which can be expensive to obtain or even unavailable in practice. In
this paper, in order to reduce the demand for annotated data, we present an
end-to-end learning objective based upon the maximisation of a
pseudo-likelihood function which can improve the estimation of states when
large portion of true states are unknown. We assess performance of the proposed
method in state estimation tasks in robotics with simulated and real-world
datasets.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.04813v2,2021-05-24T01:05:25Z,2020-11-09T22:49:19Z,"Bimanual Regrasping for Suture Needles using Reinforcement Learning for
  Rapid Motion Planning","Regrasping a suture needle is an important yet time-consuming process in
suturing. To bring efficiency into regrasping, prior work either designs a
task-specific mechanism or guides the gripper toward some specific pick-up
point for proper grasping of a needle. Yet, these methods are usually not
deployable when the working space is changed. Therefore, in this work, we
present rapid trajectory generation for bimanual needle regrasping via
reinforcement learning (RL). Demonstrations from a sampling-based motion
planning algorithm is incorporated to speed up the learning. In addition, we
propose the ego-centric state and action spaces for this bimanual planning
problem, where the reference frames are on the end-effectors instead of some
fixed frame. Thus, the learned policy can be directly applied to any feasible
robot configuration. Our experiments in simulation show that the success rate
of a single pass is 97%, and the planning time is 0.0212s on average, which
outperforms other widely used motion planning algorithms. For the real-world
experiments, the success rate is 73.3% if the needle pose is reconstructed from
an RGB image, with a planning time of 0.0846s and a run time of 5.1454s. If the
needle pose is known beforehand, the success rate becomes 90.5%, with a
planning time of 0.0807s and a run time of 2.8801s.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.03881v1,2020-11-08T01:02:33Z,2020-11-08T01:02:33Z,"Online Multi-Objective Model-Independent Adaptive Tracking Mechanism for
  Dynamical Systems","The optimal tracking problem is addressed in the robotics literature by using
a variety of robust and adaptive control approaches. However, these schemes are
associated with implementation limitations such as applicability in uncertain
dynamical environments with complete or partial model-based control structures,
complexity and integrity in discrete-time environments, and scalability in
complex coupled dynamical systems. An online adaptive learning mechanism is
developed to tackle the above limitations and provide a generalized solution
platform for a class of tracking control problems. This scheme minimizes the
tracking errors and optimizes the overall dynamical behavior using simultaneous
linear feedback control strategies. Reinforcement learning approaches based on
value iteration processes are adopted to solve the underlying Bellman
optimality equations. The resulting control strategies are updated in real time
in an interactive manner without requiring any information about the dynamics
of the underlying systems. Means of adaptive critics are employed to
approximate the optimal solving value functions and the associated control
strategies in real time. The proposed adaptive tracking mechanism is
illustrated in simulation to control a flexible wing aircraft under uncertain
aerodynamic learning environment.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.03790v1,2020-11-07T15:14:03Z,2020-11-07T15:14:03Z,"Rapid Pose Label Generation through Sparse Representation of Unknown
  Objects","Deep Convolutional Neural Networks (CNNs) have been successfully deployed on
robots for 6-DoF object pose estimation through visual perception. However,
obtaining labeled data on a scale required for the supervised training of CNNs
is a difficult task - exacerbated if the object is novel and a 3D model is
unavailable. To this end, this work presents an approach for rapidly generating
real-world, pose-annotated RGB-D data for unknown objects. Our method not only
circumvents the need for a prior 3D object model (textured or otherwise) but
also bypasses complicated setups of fiducial markers, turntables, and sensors.
With the help of a human user, we first source minimalistic labelings of an
ordered set of arbitrarily chosen keypoints over a set of RGB-D videos. Then,
by solving an optimization problem, we combine these labels under a world frame
to recover a sparse, keypoint-based representation of the object. The sparse
representation leads to the development of a dense model and the pose labels
for each image frame in the set of scenes. We show that the sparse model can
also be efficiently used for scaling to a large number of new scenes. We
demonstrate the practicality of the generated labeled dataset by training a
pipeline for 6-DoF object pose estimation and a pixel-wise segmentation
network.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.03148v2,2021-07-03T23:21:26Z,2020-11-06T00:30:53Z,RetinaGAN: An Object-aware Approach to Sim-to-Real Transfer,"The success of deep reinforcement learning (RL) and imitation learning (IL)
in vision-based robotic manipulation typically hinges on the expense of large
scale data collection. With simulation, data to train a policy can be collected
efficiently at scale, but the visual gap between sim and real makes deployment
in the real world difficult. We introduce RetinaGAN, a generative adversarial
network (GAN) approach to adapt simulated images to realistic ones with
object-detection consistency. RetinaGAN is trained in an unsupervised manner
without task loss dependencies, and preserves general object structure and
texture in adapted images. We evaluate our method on three real world tasks:
grasping, pushing, and door opening. RetinaGAN improves upon the performance of
prior sim-to-real methods for RL-based object instance grasping and continues
to be effective even in the limited data regime. When applied to a pushing task
in a similar visual domain, RetinaGAN demonstrates transfer with no additional
real data requirements. We also show our method bridges the visual gap for a
novel door opening task using imitation learning in a new visual domain. Visit
the project website at https://retinagan.github.io/",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.02373v1,2020-11-04T16:05:07Z,2020-11-04T16:05:07Z,"Moving Forward in Formation: A Decentralized Hierarchical Learning
  Approach to Multi-Agent Moving Together","Multi-agent path finding in formation has many potential real-world
applications like mobile warehouse robots. However, previous multi-agent path
finding (MAPF) methods hardly take formation into consideration. Furthermore,
they are usually centralized planners and require the whole state of the
environment. Other decentralized partially observable approaches to MAPF are
reinforcement learning (RL) methods. However, these RL methods encounter
difficulties when learning path finding and formation problem at the same time.
In this paper, we propose a novel decentralized partially observable RL
algorithm that uses a hierarchical structure to decompose the multi objective
task into unrelated ones. It also calculates a theoretical weight that makes
every task reward has equal influence on the final RL value function.
Additionally, we introduce a communication method that helps agents cooperate
with each other. Experiments in simulation show that our method outperforms
other end-to-end RL methods and our method can naturally scale to large world
sizes where centralized planner struggles. We also deploy and validate our
method in a real world scenario.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.02920v1,2020-11-04T14:58:58Z,2020-11-04T14:58:58Z,Asynchronous Deep Model Reference Adaptive Control,"In this paper, we present Asynchronous implementation of Deep Neural
Network-based Model Reference Adaptive Control (DMRAC). We evaluate this new
neuro-adaptive control architecture through flight tests on a small quadcopter.
We demonstrate that a single DMRAC controller can handle significant
nonlinearities due to severe system faults and deliberate wind disturbances
while executing high-bandwidth attitude control. We also show that the
architecture has long-term learning abilities across different flight regimes,
and can generalize to fly different flight trajectories than those on which it
was trained. These results demonstrating the efficacy of this architecture for
high bandwidth closed-loop attitude control of unstable and nonlinear robots
operating in adverse situations. To achieve these results, we designed a
software+communication architecture to ensure online real-time inference of the
deep network on a high-bandwidth computation-limited platform. We expect that
this architecture will benefit other deep learning in the closed-loop
experiments on robots.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2011.00446v2,2021-06-29T15:01:51Z,2020-11-01T08:06:46Z,"Efficient Learning of Control Policies for Robust Quadruped Bounding
  using Pretrained Neural Networks","Bounding is one of the important gaits in quadrupedal locomotion for
negotiating obstacles. However, due to a large number of robot and
environmental constraints, conventional planning and control has limited
ability to adapt bounding gaits on various terrains in real-time. We proposed
an efficient approach to learn robust bounding gaits by first pretraining the
deep neural network (DNN) using data from a robot that used conventional
model-based controllers. Next, the pretrained DNN weights are optimized further
via deep reinforcement learning (DRL). Also, we designed a reward function
considering contact points to enforce the gait symmetry and periodicity, and
used feature engineering to improve input features of the DRL model and the
bounding performance. The DNN-based feedback controller was learned in
simulation first and deployed directly on the real Jueying-Mini robot
successfully, which was computationally more efficient and performed much
better than the previous model-based control in terms of robustness and
stability in both indoor and outdoor experiments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.15033v1,2020-10-28T15:12:56Z,2020-10-28T15:12:56Z,The Amazing Race TM: Robot Edition,"State-of-the-art natural-language-driven autonomous-navigation systems
generally lack the ability to operate in real unknown environments without
crutches, such as having a map of the environment in advance or requiring a
strict syntactic structure for natural-language commands. Practical
artificial-intelligent systems should not have to depend on such prior
knowledge. To encourage effort towards this goal, we propose The Amazing Race
TM: Robot Edition, a new task of finding a room in an unknown and unmodified
office environment by following instructions obtained in spoken dialog from an
untrained person. We present a solution that treats this challenge as a series
of sub-tasks: natural-language interpretation, autonomous navigation, and
semantic mapping. The solution consists of a finite-state-machine system design
whose states solve these sub-tasks to complete The Amazing Race TM. Our design
is deployed on a real robot and its performance is demonstrated in 52 trials on
4 floors of each of 3 different previously unseen buildings with 13 untrained
volunteers.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.14575v1,2020-10-27T19:32:44Z,2020-10-27T19:32:44Z,"Learning Time Reduction Using Warm Start Methods for a Reinforcement
  Learning Based Supervisory Control in Hybrid Electric Vehicle Applications","Reinforcement Learning (RL) is widely utilized in the field of robotics, and
as such, it is gradually being implemented in the Hybrid Electric Vehicle (HEV)
supervisory control. Even though RL exhibits excellent performance in terms of
fuel consumption minimization in simulation, the large learning iteration
number needs a long learning time, making it hardly applicable in real-world
vehicles. In addition, the fuel consumption of initial learning phases is much
worse than baseline controls. This study aims to reduce the learning iterations
of Q-learning in HEV application and improve fuel consumption in initial
learning phases utilizing warm start methods. Different from previous studies,
which initiated Q-learning with zero or random Q values, this study initiates
the Q-learning with different supervisory controls (i.e., Equivalent
Consumption Minimization Strategy control and heuristic control), and detailed
analysis is given. The results show that the proposed warm start Q-learning
requires 68.8% fewer iterations than cold start Q-learning. The trained
Q-learning is validated in two different driving cycles, and the results show
10-16% MPG improvement when compared to Equivalent Consumption Minimization
Strategy control. Furthermore, real-time feasibility is analyzed, and the
guidance of vehicle implementation is provided. The results of this study can
be used to facilitate the deployment of RL in vehicle supervisory control
applications.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.13439v1,2020-10-26T09:19:07Z,2020-10-26T09:19:07Z,On Embodied Visual Navigation in Real Environments Through Habitat,"Visual navigation models based on deep learning can learn effective policies
when trained on large amounts of visual observations through reinforcement
learning. Unfortunately, collecting the required experience in the real world
requires the deployment of a robotic platform, which is expensive and
time-consuming. To deal with this limitation, several simulation platforms have
been proposed in order to train visual navigation policies on virtual
environments efficiently. Despite the advantages they offer, simulators present
a limited realism in terms of appearance and physical dynamics, leading to
navigation policies that do not generalize in the real world.
  In this paper, we propose a tool based on the Habitat simulator which
exploits real world images of the environment, together with sensor and
actuator noise models, to produce more realistic navigation episodes. We
perform a range of experiments to assess the ability of such policies to
generalize using virtual and real-world images, as well as observations
transformed with unsupervised domain adaptation approaches. We also assess the
impact of sensor and actuation noise on the navigation performance and
investigate whether it allows to learn more robust navigation policies. We show
that our tool can effectively help to train and evaluate navigation policies on
real-world observations without running navigation pisodes in the real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.10903v1,2020-10-21T11:22:30Z,2020-10-21T11:22:30Z,"Visual Navigation in Real-World Indoor Environments Using End-to-End
  Deep Reinforcement Learning","Visual navigation is essential for many applications in robotics, from
manipulation, through mobile robotics to automated driving. Deep reinforcement
learning (DRL) provides an elegant map-free approach integrating image
processing, localization, and planning in one module, which can be trained and
therefore optimized for a given environment. However, to date, DRL-based visual
navigation was validated exclusively in simulation, where the simulator
provides information that is not available in the real world, e.g., the robot's
position or image segmentation masks. This precludes the use of the learned
policy on a real robot. Therefore, we propose a novel approach that enables a
direct deployment of the trained policy on real robots. We have designed visual
auxiliary tasks, a tailored reward scheme, and a new powerful simulator to
facilitate domain randomization. The policy is fine-tuned on images collected
from real-world environments. We have evaluated the method on a mobile robot in
a real office environment. The training took ~30 hours on a single GPU. In 30
navigation experiments, the robot reached a 0.3-meter neighborhood of the goal
in more than 86.7% of cases. This result makes the proposed method directly
applicable to tasks like mobile manipulation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.09635v1,2020-10-19T16:20:45Z,2020-10-19T16:20:45Z,"Deep Reinforcement Learning with Population-Coded Spiking Neural Network
  for Continuous Control","The energy-efficient control of mobile robots is crucial as the complexity of
their real-world applications increasingly involves high-dimensional
observation and action spaces, which cannot be offset by limited on-board
resources. An emerging non-Von Neumann model of intelligence, where spiking
neural networks (SNNs) are run on neuromorphic processors, is regarded as an
energy-efficient and robust alternative to the state-of-the-art real-time
robotic controllers for low dimensional control tasks. The challenge now for
this new computing paradigm is to scale so that it can keep up with real-world
tasks. To do so, SNNs need to overcome the inherent limitations of their
training, namely the limited ability of their spiking neurons to represent
information and the lack of effective learning algorithms. Here, we propose a
population-coded spiking actor network (PopSAN) trained in conjunction with a
deep critic network using deep reinforcement learning (DRL). The population
coding scheme dramatically increased the representation capacity of the network
and the hybrid learning combined the training advantages of deep networks with
the energy-efficient inference of spiking networks. To show the general
applicability of our approach, we integrated it with a spectrum of both
on-policy and off-policy DRL algorithms. We deployed the trained PopSAN on
Intel's Loihi neuromorphic chip and benchmarked our method against the
mainstream DRL algorithms for continuous control. To allow for a fair
comparison among all methods, we validated them on OpenAI gym tasks. Our
Loihi-run PopSAN consumed 140 times less energy per inference when compared
against the deep actor network on Jetson TX2, and had the same level of
performance. Our results support the efficiency of neuromorphic controllers and
suggest our hybrid RL as an alternative to deep learning, when both
energy-efficiency and robustness are important.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.08600v2,2020-11-16T06:26:16Z,2020-10-16T19:40:08Z,"Robot Navigation in Constrained Pedestrian Environments using
  Reinforcement Learning","Navigating fluently around pedestrians is a necessary capability for mobile
robots deployed in human environments, such as buildings and homes. While
research on social navigation has focused mainly on the scalability with the
number of pedestrians in open spaces, typical indoor environments present the
additional challenge of constrained spaces such as corridors and doorways that
limit maneuverability and influence patterns of pedestrian interaction. We
present an approach based on reinforcement learning (RL) to learn policies
capable of dynamic adaptation to the presence of moving pedestrians while
navigating between desired locations in constrained environments. The policy
network receives guidance from a motion planner that provides waypoints to
follow a globally planned trajectory, whereas RL handles the local
interactions. We explore a compositional principle for multi-layout training
and find that policies trained in a small set of geometrically simple layouts
successfully generalize to more complex unseen layouts that exhibit composition
of the structural elements available during training. Going beyond walls-world
like domains, we show transfer of the learned policy to unseen 3D
reconstructions of two real environments. These results support the
applicability of the compositional principle to navigation in real-world
buildings and indicate promising usage of multi-agent simulation within
reconstructed environments for tasks that involve interaction.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.08311v2,2022-05-21T22:29:31Z,2020-10-16T11:06:50Z,"Formal Verification of Robustness and Resilience of Learning-Enabled
  State Estimation Systems for Robotics","This paper presents a formal verification guided approach for a principled
design and implementation of robust and resilient learning-enabled systems. We
focus on learning-enabled state estimation systems (LE-SESs), which have been
widely used in robotics applications to determine the current state (e.g.,
location, speed, direction, etc.) of a complex system. The LE-SESs are
networked systems composed of a set of connected components including Bayes
filters for localisation, and neural networks for processing sensory input. We
study LE-SESs from the perspective of formal verification, which determines the
satisfiability of a system model against the specified properties. Over
LE-SESs, we investigate two key properties - robustness and resilience - and
provide their formal definitions. To enable formal verification, we reduce the
LE-SESs to a novel class of labelled transition systems, named {PO}2-LTS in the
paper, and formally express the properties as constrained optimisation
objectives. We prove that the robustness verification is NP-complete. Based on
{PO}2-LTS and the optimisation objectives, practical verification algorithms
are developed to check the satisfiability of the properties on the LE-SESs. As
a major case study, we interrogate a real-world dynamic tracking system which
uses a single Kalman Filter (KF) - a special case of Bayes filter - to localise
and track a ground vehicle. Its perception system, based on convolutional
neural networks, processes a high-resolution Wide Area Motion Imagery (WAMI)
data stream. Experimental results show that our algorithms can not only verify
the properties of the WAMI tracking system but also provide representative
examples, the latter of which inspired us to take an enhanced LE-SESs design
where runtime monitors or joint-KFs are required. Experimental results confirm
the improvement of the robustness of the enhanced design.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.08184v3,2021-03-04T14:28:56Z,2020-10-16T06:23:53Z,"PRIMAL2: Pathfinding via Reinforcement and Imitation Multi-Agent
  Learning -- Lifelong","Multi-agent path finding (MAPF) is an indispensable component of large-scale
robot deployments in numerous domains ranging from airport management to
warehouse automation. In particular, this work addresses lifelong MAPF (LMAPF)
- an online variant of the problem where agents are immediately assigned a new
goal upon reaching their current one - in dense and highly structured
environments, typical of real-world warehouse operations. Effectively solving
LMAPF in such environments requires expensive coordination between agents as
well as frequent replanning abilities, a daunting task for existing coupled and
decoupled approaches alike. With the purpose of achieving considerable agent
coordination without any compromise on reactivity and scalability, we introduce
PRIMAL2, a distributed reinforcement learning framework for LMAPF where agents
learn fully decentralized policies to reactively plan paths online in a
partially observable world. We extend our previous work, which was effective in
low-density sparsely occupied worlds, to highly structured and constrained
worlds by identifying behaviors and conventions which improve implicit agent
coordination, and enable their learning through the construction of a novel
local agent observation and various training aids. We present extensive results
of PRIMAL2 in both MAPF and LMAPF environments and compare its performance to
state-of-the-art planners in terms of makespan and throughput. We show that
PRIMAL2 significantly surpasses our previous work and performs comparably to
these baselines, while allowing real-time re-planning and scaling up to 2048
agents.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.08098v2,2021-03-07T17:28:22Z,2020-10-16T02:04:45Z,"Agile Robot Navigation through Hallucinated Learning and Sober
  Deployment","Learning from Hallucination (LfH) is a recent machine learning paradigm for
autonomous navigation, which uses training data collected in completely safe
environments and adds numerous imaginary obstacles to make the environment
densely constrained, to learn navigation planners that produce feasible
navigation even in highly constrained (more dangerous) spaces. However, LfH
requires hallucinating the robot perception during deployment to match with the
hallucinated training data, which creates a need for sometimes-infeasible prior
knowledge and tends to generate very conservative planning. In this work, we
propose a new LfH paradigm that does not require runtime hallucination -- a
feature we call ""sober deployment"" -- and can therefore adapt to more realistic
navigation scenarios. This novel Hallucinated Learning and Sober Deployment
(HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation
environments with a wide range of difficulty levels, and in the real-world. In
most cases, HLSD outperforms both the original LfH method and a classical
navigation planner.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.06626v2,2020-12-29T01:09:57Z,2020-10-13T18:37:38Z,"On Deep Learning Techniques to Boost Monocular Depth Estimation for
  Autonomous Navigation","Inferring the depth of images is a fundamental inverse problem within the
field of Computer Vision since depth information is obtained through 2D images,
which can be generated from infinite possibilities of observed real scenes.
Benefiting from the progress of Convolutional Neural Networks (CNNs) to explore
structural features and spatial image information, Single Image Depth
Estimation (SIDE) is often highlighted in scopes of scientific and
technological innovation, as this concept provides advantages related to its
low implementation cost and robustness to environmental conditions. In the
context of autonomous vehicles, state-of-the-art CNNs optimize the SIDE task by
producing high-quality depth maps, which are essential during the autonomous
navigation process in different locations. However, such networks are usually
supervised by sparse and noisy depth data, from Light Detection and Ranging
(LiDAR) laser scans, and are carried out at high computational cost, requiring
high-performance Graphic Processing Units (GPUs). Therefore, we propose a new
lightweight and fast supervised CNN architecture combined with novel feature
extraction models which are designed for real-world autonomous navigation. We
also introduce an efficient surface normals module, jointly with a simple
geometric 2.5D loss function, to solve SIDE problems. We also innovate by
incorporating multiple Deep Learning techniques, such as the use of
densification algorithms and additional semantic, surface normals and depth
information to train our framework. The method introduced in this work focuses
on robotic applications in indoor and outdoor environments and its results are
evaluated on the competitive and publicly available NYU Depth V2 and KITTI
Depth datasets.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2010.01200v1,2020-10-02T21:02:35Z,2020-10-02T21:02:35Z,FPGA Implementation of Simplified Spiking Neural Network,"Spiking Neural Networks (SNN) are third-generation Artificial Neural Networks
(ANN) which are close to the biological neural system. In recent years SNN has
become popular in the area of robotics and embedded applications, therefore, it
has become imperative to explore its real-time and energy-efficient
implementations. SNNs are more powerful than their predecessors because they
encode temporal information and use biologically plausible plasticity rules. In
this paper, a simpler and computationally efficient SNN model using FPGA
architecture is described. The proposed model is validated on a Xilinx Virtex 6
FPGA and analyzes a fully connected network which consists of 800 neurons and
12,544 synapses in real-time.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2009.14756v1,2020-09-30T15:43:44Z,2020-09-30T15:43:44Z,"A Plausibility-based Fault Detection Method for High-level Fusion
  Perception Systems","Trustworthy environment perception is the fundamental basis for the safe
deployment of automated agents such as self-driving vehicles or intelligent
robots. The problem remains that such trust is notoriously difficult to
guarantee in the presence of systematic faults, e.g. non-traceable errors
caused by machine learning functions. One way to tackle this issue without
making rather specific assumptions about the perception process is plausibility
checking. Similar to the reasoning of human intuition, the final outcome of a
complex black-box procedure is verified against given expectations of an
object's behavior. In this article, we apply and evaluate collaborative,
sensor-generic plausibility checking as a mean to detect empirical perception
faults from their statistical fingerprints. Our real use case is
next-generation automated driving that uses a roadside sensor infrastructure
for perception augmentation, represented here by test scenarios at a German
highway and a city intersection. The plausibilization analysis is integrated
naturally in the object fusion process, and helps to diagnose known and
possibly yet unknown faults in distributed sensing systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.13485v1,2020-08-31T10:58:45Z,2020-08-31T10:58:45Z,"ROS-Neuro Integration of Deep Convolutional Autoencoders for EEG Signal
  Compression in Real-time BCIs","Typical EEG-based BCI applications require the computation of complex
functions over the noisy EEG channels to be carried out in an efficient way.
Deep learning algorithms are capable of learning flexible nonlinear functions
directly from data, and their constant processing latency is perfect for their
deployment into online BCI systems. However, it is crucial for the jitter of
the processing system to be as low as possible, in order to avoid unpredictable
behaviour that can ruin the system's overall usability. In this paper, we
present a novel encoding method, based on on deep convolutional autoencoders,
that is able to perform efficient compression of the raw EEG inputs. We deploy
our model in a ROS-Neuro node, thus making it suitable for the integration in
ROS-based BCI and robotic systems in real world scenarios. The experimental
results show that our system is capable to generate meaningful compressed
encoding preserving to original information contained in the raw input. They
also show that the ROS-Neuro node is able to produce such encodings at a steady
rate, with minimal jitter. We believe that our system can represent an
important step towards the development of an effective BCI processing pipeline
fully standardized in ROS-Neuro framework.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.13223v2,2020-10-25T17:47:42Z,2020-08-30T17:29:43Z,"Deep Reinforcement Learning for Contact-Rich Skills Using Compliant
  Movement Primitives","In recent years, industrial robots have been installed in various industries
to handle advanced manufacturing and high precision tasks. However, further
integration of industrial robots is hampered by their limited flexibility,
adaptability and decision making skills compared to human operators. Assembly
tasks are especially challenging for robots since they are contact-rich and
sensitive to even small uncertainties. While reinforcement learning (RL) offers
a promising framework to learn contact-rich control policies from scratch, its
applicability to high-dimensional continuous state-action spaces remains rather
limited due to high brittleness and sample complexity. To address those issues,
we propose different pruning methods that facilitate convergence and
generalization. In particular, we divide the task into free and contact-rich
sub-tasks, perform the control in Cartesian rather than joint space, and
parameterize the control policy. Those pruning methods are naturally
implemented within the framework of dynamic movement primitives (DMP). To
handle contact-rich tasks, we extend the DMP framework by introducing a
coupling term that acts like the human wrist and provides active compliance
under contact with the environment. We demonstrate that the proposed method can
learn insertion skills that are invariant to space, size, shape, and closely
related scenarios, while handling large uncertainties. Finally we demonstrate
that the learned policy can be easily transferred from simulations to real
world and achieve similar performance on UR5e robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.12949v2,2021-01-14T12:55:11Z,2020-08-29T09:54:05Z,VR-Caps: A Virtual Environment for Capsule Endoscopy,"Current capsule endoscopes and next-generation robotic capsules for diagnosis
and treatment of gastrointestinal diseases are complex cyber-physical platforms
that must orchestrate complex software and hardware functions. The desired
tasks for these systems include visual localization, depth estimation, 3D
mapping, disease detection and segmentation, automated navigation, active
control, path realization and optional therapeutic modules such as targeted
drug delivery and biopsy sampling. Data-driven algorithms promise to enable
many advanced functionalities for capsule endoscopes, but real-world data is
challenging to obtain. Physically-realistic simulations providing synthetic
data have emerged as a solution to the development of data-driven algorithms.
In this work, we present a comprehensive simulation platform for capsule
endoscopy operations and introduce VR-Caps, a virtual active capsule
environment that simulates a range of normal and abnormal tissue conditions
(e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope
designs (e.g., mono, stereo, dual and 360{\deg}camera), and the type, number,
strength, and placement of internal and external magnetic sources that enable
active locomotion. VR-Caps makes it possible to both independently or jointly
develop, optimize, and test medical imaging and analysis software for the
current and next-generation endoscopic capsule systems. To validate this
approach, we train state-of-the-art deep neural networks to accomplish various
medical image analysis tasks using simulated data from VR-Caps and evaluate the
performance of these models on real medical data. Results demonstrate the
usefulness and effectiveness of the proposed virtual platform in developing
algorithms that quantify fractional coverage, camera trajectory, 3D map
reconstruction, and disease classification.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.13585v1,2020-08-26T14:03:25Z,2020-08-26T14:03:25Z,At Your Service: Coffee Beans Recommendation From a Robot Assistant,"With advances in the field of machine learning, precisely algorithms for
recommendation systems, robot assistants are envisioned to become more present
in the hospitality industry. Additionally, the COVID-19 pandemic has also
highlighted the need to have more service robots in our everyday lives, to
minimise the risk of human to-human transmission. One such example would be
coffee shops, which have become intrinsic to our everyday lives. However,
serving an excellent cup of coffee is not a trivial feat as a coffee blend
typically comprises rich aromas, indulgent and unique flavours and a lingering
aftertaste. Our work addresses this by proposing a computational model which
recommends optimal coffee beans resulting from the user's preferences.
Specifically, given a set of coffee bean properties (objective features), we
apply different supervised learning techniques to predict coffee qualities
(subjective features). We then consider an unsupervised learning method to
analyse the relationship between coffee beans in the subjective feature space.
Evaluated on a real coffee beans dataset based on digitised reviews, our
results illustrate that the proposed computational model gives up to 92.7
percent recommendation accuracy for coffee beans prediction. From this, we
propose how this computational model can be deployed on a service robot to
reliably predict customers' coffee bean preferences, starting from the user
inputting their coffee preferences to the robot recommending the coffee beans
that best meet the user's likings.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.11383v1,2020-08-26T05:44:07Z,2020-08-26T05:44:07Z,"Applying Surface Normal Information in Drivable Area and Road Anomaly
  Detection for Ground Mobile Robots","The joint detection of drivable areas and road anomalies is a crucial task
for ground mobile robots. In recent years, many impressive semantic
segmentation networks, which can be used for pixel-level drivable area and road
anomaly detection, have been developed. However, the detection accuracy still
needs improvement. Therefore, we develop a novel module named the Normal
Inference Module (NIM), which can generate surface normal information from
dense depth images with high accuracy and efficiency. Our NIM can be deployed
in existing convolutional neural networks (CNNs) to refine the segmentation
performance. To evaluate the effectiveness and robustness of our NIM, we embed
it in twelve state-of-the-art CNNs. The experimental results illustrate that
our NIM can greatly improve the performance of the CNNs for drivable area and
road anomaly detection. Furthermore, our proposed NIM-RTFNet ranks 8th on the
KITTI road benchmark and exhibits a real-time inference speed.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.12624v1,2020-08-18T23:52:32Z,2020-08-18T23:52:32Z,"A Framework for Studying Reinforcement Learning and Sim-to-Real in Robot
  Soccer","This article introduces an open framework, called VSSS-RL, for studying
Reinforcement Learning (RL) and sim-to-real in robot soccer, focusing on the
IEEE Very Small Size Soccer (VSSS) league. We propose a simulated environment
in which continuous or discrete control policies can be trained to control the
complete behavior of soccer agents and a sim-to-real method based on domain
adaptation to adapt the obtained policies to real robots. Our results show that
the trained policies learned a broad repertoire of behaviors that are difficult
to implement with handcrafted control policies. With VSSS-RL, we were able to
beat human-designed policies in the 2019 Latin American Robotics Competition
(LARC), achieving 4th place out of 21 teams, being the first to apply
Reinforcement Learning (RL) successfully in this competition. Both environment
and hardware specifications are available open-source to allow reproducibility
of our results and further studies.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.06189v1,2020-08-14T04:35:10Z,2020-08-14T04:35:10Z,"An Improved Deep Convolutional Neural Network-Based Autonomous Road
  Inspection Scheme Using Unmanned Aerial Vehicles","Advancements in artificial intelligence (AI) gives a great opportunity to
develop an autonomous devices. The contribution of this work is an improved
convolutional neural network (CNN) model and its implementation for the
detection of road cracks, potholes, and yellow lane in the road. The purpose of
yellow lane detection and tracking is to realize autonomous navigation of
unmanned aerial vehicle (UAV) by following yellow lane while detecting and
reporting the road cracks and potholes to the server through WIFI or 5G medium.
The fabrication of own data set is a hectic and time-consuming task. The data
set is created, labeled and trained using default and an improved model. The
performance of both these models is benchmarked with respect to accuracy, mean
average precision (mAP) and detection time. In the testing phase, it was
observed that the performance of the improved model is better in respect of
accuracy and mAP. The improved model is implemented in UAV using the robot
operating system for the autonomous detection of potholes and cracks in roads
via UAV front camera vision in real-time.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.03596v2,2021-01-21T20:00:13Z,2020-08-08T20:54:30Z,TriFinger: An Open-Source Robot for Learning Dexterity,"Dexterous object manipulation remains an open problem in robotics, despite
the rapid progress in machine learning during the past decade. We argue that a
hindrance is the high cost of experimentation on real systems, in terms of both
time and money. We address this problem by proposing an open-source robotic
platform which can safely operate without human supervision. The hardware is
inexpensive (about \SI{5000}[\$]{}) yet highly dynamic, robust, and capable of
complex interaction with external objects. The software operates at 1-kilohertz
and performs safety checks to prevent the hardware from breaking. The
easy-to-use front-end (in C++ and Python) is suitable for real-time control as
well as deep reinforcement learning. In addition, the software framework is
largely robot-agnostic and can hence be used independently of the hardware
proposed herein. Finally, we illustrate the potential of the proposed platform
through a number of experiments, including real-time optimal control, deep
reinforcement learning from scratch, throwing, and writing.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.02321v2,2021-02-25T03:04:37Z,2020-08-05T19:00:36Z,"Can I Pour into It? Robot Imagining Open Containability Affordance of
  Previously Unseen Objects via Physical Simulations","Open containers, i.e., containers without covers, are an important and
ubiquitous class of objects in human life. In this letter, we propose a novel
method for robots to ""imagine"" the open containability affordance of a
previously unseen object via physical simulations. We implement our imagination
method on a UR5 manipulator. The robot autonomously scans the object with an
RGB-D camera. The scanned 3D model is used for open containability imagination
which quantifies the open containability affordance by physically simulating
dropping particles onto the object and counting how many particles are retained
in it. This quantification is used for open-container vs. non-open-container
binary classification (hereafter referred to as open container classification).
If the object is classified as an open container, the robot further imagines
pouring into the object, again using physical simulations, to obtain the
pouring position and orientation for real robot autonomous pouring. We evaluate
our method on open container classification and autonomous pouring of granular
material on a dataset containing 130 previously unseen objects with 57 object
categories. Although our proposed method uses only 11 objects for simulation
calibration (training), its open container classification aligns well with
human judgements. In addition, our method endows the robot with the capability
to autonomously pour into the 55 containers in the dataset with a very high
success rate. We also compare to a deep learning method. Results show that our
method achieves the same performance as the deep learning method on open
container classification and outperforms it on autonomous pouring. Moreover,
our method is fully explainable.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2008.00376v1,2020-08-02T01:18:18Z,2020-08-02T01:18:18Z,"Velocity Regulation of 3D Bipedal Walking Robots with Uncertain Dynamics
  Through Adaptive Neural Network Controller","This paper presents a neural-network based adaptive feedback control
structure to regulate the velocity of 3D bipedal robots under dynamics
uncertainties. Existing Hybrid Zero Dynamics (HZD)-based controllers regulate
velocity through the implementation of heuristic regulators that do not
consider model and environmental uncertainties, which may significantly affect
the tracking performance of the controllers. In this paper, we address the
uncertainties in the robot dynamics from the perspective of the reduced
dimensional representation of virtual constraints and propose the integration
of an adaptive neural network-based controller to regulate the robot velocity
in the presence of model parameter uncertainties. The proposed approach yields
improved tracking performance under dynamics uncertainties. The shallow
adaptive neural network used in this paper does not require training a priori
and has the potential to be implemented on the real-time robotic controller. A
comparative simulation study of a 3D Cassie robot is presented to illustrate
the performance of the proposed approach under various scenarios.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.15724v1,2020-07-30T20:14:42Z,2020-07-30T20:14:42Z,"MAPPER: Multi-Agent Path Planning with Evolutionary Reinforcement
  Learning in Mixed Dynamic Environments","Multi-agent navigation in dynamic environments is of great industrial value
when deploying a large scale fleet of robot to real-world applications. This
paper proposes a decentralized partially observable multi-agent path planning
with evolutionary reinforcement learning (MAPPER) method to learn an effective
local planning policy in mixed dynamic environments. Reinforcement
learning-based methods usually suffer performance degradation on long-horizon
tasks with goal-conditioned sparse rewards, so we decompose the long-range
navigation task into many easier sub-tasks under the guidance of a global
planner, which increases agents' performance in large environments. Moreover,
most existing multi-agent planning approaches assume either perfect information
of the surrounding environment or homogeneity of nearby dynamic agents, which
may not hold in practice. Our approach models dynamic obstacles' behavior with
an image-based representation and trains a policy in mixed dynamic environments
without homogeneity assumption. To ensure multi-agent training stability and
performance, we propose an evolutionary training approach that can be easily
scaled to large and complex environments. Experiments show that MAPPER is able
to achieve higher success rates and more stable performance when exposed to a
large number of non-cooperative dynamic obstacles compared with traditional
reaction-based planner LRA* and the state-of-the-art learning-based method.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.14545v2,2020-07-30T07:13:17Z,2020-07-29T01:09:27Z,"Learning Object-conditioned Exploration using Distributed Soft Actor
  Critic","Object navigation is defined as navigating to an object of a given label in a
complex, unexplored environment. In its general form, this problem poses
several challenges for Robotics: semantic exploration of unknown environments
in search of an object and low-level control. In this work we study
object-guided exploration and low-level control, and present an end-to-end
trained navigation policy achieving a success rate of 0.68 and SPL of 0.58 on
unseen, visually complex scans of real homes. We propose a highly scalable
implementation of an off-policy Reinforcement Learning algorithm, distributed
Soft Actor Critic, which allows the system to utilize 98M experience steps in
24 hours on 8 GPUs. Our system learns to control a differential drive mobile
base in simulation from a stack of high dimensional observations commonly used
on robotic platforms. The learned policy is capable of object-guided
exploratory behaviors and low-level control learned from pure experiences in
realistic environments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.13404v2,2020-10-29T16:23:12Z,2020-07-27T09:50:11Z,"YOLOpeds: Efficient Real-Time Single-Shot Pedestrian Detection for Smart
  Camera Applications","Deep Learning-based object detectors can enhance the capabilities of smart
camera systems in a wide spectrum of machine vision applications including
video surveillance, autonomous driving, robots and drones, smart factory, and
health monitoring. Pedestrian detection plays a key role in all these
applications and deep learning can be used to construct accurate
state-of-the-art detectors. However, such complex paradigms do not scale easily
and are not traditionally implemented in resource-constrained smart cameras for
on-device processing which offers significant advantages in situations when
real-time monitoring and robustness are vital. Efficient neural networks can
not only enable mobile applications and on-device experiences but can also be a
key enabler of privacy and security allowing a user to gain the benefits of
neural networks without needing to send their data to the server to be
evaluated. This work addresses the challenge of achieving a good trade-off
between accuracy and speed for efficient deployment of deep-learning-based
pedestrian detection in smart camera applications. A computationally efficient
architecture is introduced based on separable convolutions and proposes
integrating dense connections across layers and multi-scale feature fusion to
improve representational capacity while decreasing the number of parameters and
operations. In particular, the contributions of this work are the following: 1)
An efficient backbone combining multi-scale feature operations, 2) a more
elaborate loss function for improved localization, 3) an anchor-less approach
for detection, The proposed approach called YOLOpeds is evaluated using the
PETS2009 surveillance dataset on 320x320 images. Overall, YOLOpeds provides
real-time sustained operation of over 30 frames per second with detection rates
in the range of 86% outperforming existing deep learning models.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.12640v1,2020-07-24T16:50:41Z,2020-07-24T16:50:41Z,"Autonomous Exploration Under Uncertainty via Deep Reinforcement Learning
  on Graphs","We consider an autonomous exploration problem in which a range-sensing mobile
robot is tasked with accurately mapping the landmarks in an a priori unknown
environment efficiently in real-time; it must choose sensing actions that both
curb localization uncertainty and achieve information gain. For this problem,
belief space planning methods that forward-simulate robot sensing and
estimation may often fail in real-time implementation, scaling poorly with
increasing size of the state, belief and action spaces. We propose a novel
approach that uses graph neural networks (GNNs) in conjunction with deep
reinforcement learning (DRL), enabling decision-making over graphs containing
exploration information to predict a robot's optimal sensing action in belief
space. The policy, which is trained in different random environments without
human intervention, offers a real-time, scalable decision-making process whose
high-performance exploratory sensing actions yield accurate maps and high rates
of information gain.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.10675v4,2022-01-10T06:24:14Z,2020-07-21T09:28:18Z,"Trade-off on Sim2Real Learning: Real-world Learning Faster than
  Simulations","Deep Reinforcement Learning (DRL) experiments are commonly performed in
simulated environments due to the tremendous training sample demands from deep
neural networks. In contrast, model-based Bayesian Learning allows a robot to
learn good policies within a few trials in the real world. Although it takes
fewer iterations, Bayesian methods pay a relatively higher computational cost
per trial, and the advantage of such methods is strongly tied to dimensionality
and noise. In here, we compare a Deep Bayesian Learning algorithm with a
model-free DRL algorithm while analyzing our results collected from both
simulations and real-world experiments. While considering Sim and Real
learning, our experiments show that the sample-efficient Deep Bayesian RL
performance is better than DRL even when computation time (as opposed to number
of iterations) is taken in consideration. Additionally, the difference in
computation time between Deep Bayesian RL performed in simulation and in
experiments point to a viable path to traverse the reality gap. We also show
that a mix between Sim and Real does not outperform a purely Real approach,
pointing to the possibility that reality can provide the best prior knowledge
to a Bayesian Learning. Roboticists design and build robots every day, and our
results show that a higher learning efficiency in the real-world will shorten
the time between design and deployment by skipping simulations.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.10227v2,2020-08-29T19:38:40Z,2020-07-20T16:17:27Z,"Nengo and low-power AI hardware for robust, embedded neurorobotics","In this paper we demonstrate how the Nengo neural modeling and simulation
libraries enable users to quickly develop robotic perception and action neural
networks for simulation on neuromorphic hardware using familiar tools, such as
Keras and Python. We identify four primary challenges in building robust,
embedded neurorobotic systems: 1) developing infrastructure for interfacing
with the environment and sensors; 2) processing task specific sensory signals;
3) generating robust, explainable control signals; and 4) compiling neural
networks to run on target hardware. Nengo helps to address these challenges by:
1) providing the NengoInterfaces library, which defines a simple but powerful
API for users to interact with simulations and hardware; 2) providing the
NengoDL library, which lets users use the Keras and TensorFlow API to develop
Nengo models; 3) implementing the Neural Engineering Framework, which provides
white-box methods for implementing known functions and circuits; and 4)
providing multiple backend libraries, such as NengoLoihi, that enable users to
compile the same model to different hardware. We present two examples using
Nengo to develop neural networks that run on CPUs, GPUs, and Intel's
neuromorphic chip, Loihi, to demonstrate this workflow. The first example is an
end-to-end spiking neural network that controls a rover simulated in Mujoco.
The network integrates a deep convolutional network that processes visual input
from mounted cameras to track a target, and a control system implementing
steering and drive functions to guide the rover to the target. The second
example augments a force-based operational space controller with neural
adaptive control to improve performance during a reaching task using a
real-world Kinova Jaco2 robotic arm. Code and details are provided with the
intent of enabling other researchers to build their own neurorobotic systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.04309v3,2021-04-09T02:47:39Z,2020-07-08T17:56:27Z,Self-Supervised Policy Adaptation during Deployment,"In most real world scenarios, a policy trained by reinforcement learning in
one environment needs to be deployed in another, potentially quite different
environment. However, generalization across different environments is known to
be hard. A natural solution would be to keep training after deployment in the
new environment, but this cannot be done if the new environment offers no
reward signal. Our work explores the use of self-supervision to allow the
policy to continue training after deployment without using any rewards. While
previous methods explicitly anticipate changes in the new environment, we
assume no prior knowledge of those changes yet still obtain significant
improvements. Empirical evaluations are performed on diverse simulation
environments from DeepMind Control suite and ViZDoom, as well as real robotic
manipulation tasks in continuously changing environments, taking observations
from an uncalibrated camera. Our method improves generalization in 31 out of 36
environments across various tasks and outperforms domain randomization on a
majority of environments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2007.03274v1,2020-07-07T08:22:56Z,2020-07-07T08:22:56Z,"Multi-Tones' Phase Coding (MTPC) of Interaural Time Difference by
  Spiking Neural Network","Inspired by the mammal's auditory localization pathway, in this paper we
propose a pure spiking neural network (SNN) based computational model for
precise sound localization in the noisy real-world environment, and implement
this algorithm in a real-time robotic system with a microphone array. The key
of this model relies on the MTPC scheme, which encodes the interaural time
difference (ITD) cues into spike patterns. This scheme naturally follows the
functional structures of the human auditory localization system, rather than
artificially computing of time difference of arrival. Besides, it highlights
the advantages of SNN, such as event-driven and power efficiency. The MTPC is
pipelined with two different SNN architectures, the convolutional SNN and
recurrent SNN, by which it shows the applicability to various SNNs. This
proposal is evaluated by the microphone collected location-dependent acoustic
data, in a real-world environment with noise, obstruction, reflection, or other
affects. The experiment results show a mean error azimuth of 1~3 degrees, which
surpasses the accuracy of the other biologically plausible neuromorphic
approach for sound source localization.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.07129v2,2021-01-12T18:03:54Z,2020-06-12T12:37:03Z,"Federated and continual learning for classification tasks in a society
  of devices","Today we live in a context in which devices are increasingly interconnected
and sensorized and are almost ubiquitous. Deep learning has become in recent
years a popular way to extract knowledge from the huge amount of data that
these devices are able to collect. Nevertheless, centralized state-of-the-art
learning methods have a number of drawbacks when facing real distributed
problems, in which the available information is usually private, partial,
biased and evolving over time. Federated learning is a popular framework that
allows multiple distributed devices to train models remotely, collaboratively,
and preserving data privacy. However, the current proposals in federated
learning focus on deep architectures that in many cases are not feasible to
implement in non-dedicated devices such as smartphones. Also, little research
has been done regarding the scenario where data distribution changes over time
in unforeseen ways, causing what is known as concept drift. Therefore, in this
work we want to present Light Federated and Continual Consensus (LFedCon2), a
new federated and continual architecture that uses light, traditional learners.
Our method allows powerless devices (such as smartphones or robots) to learn in
real time, locally, continuously, autonomously and from users, but also
improving models globally, in the cloud, combining what is learned locally, in
the devices. In order to test our proposal, we have applied it in a
heterogeneous community of smartphone users to solve the problem of walking
recognition. The results show the advantages that LFedCon2 provides with
respect to other state-of-the-art methods.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.04343v1,2020-06-08T03:53:54Z,2020-06-08T03:53:54Z,"Deep Neural Network Based Real-time Kiwi Fruit Flower Detection in an
  Orchard Environment","In this paper, we present a novel approach to kiwi fruit flower detection
using Deep Neural Networks (DNNs) to build an accurate, fast, and robust
autonomous pollination robot system. Recent work in deep neural networks has
shown outstanding performance on object detection tasks in many areas. Inspired
this, we aim for exploiting DNNs for kiwi fruit flower detection and present
intensive experiments and their analysis on two state-of-the-art object
detectors; Faster R-CNN and Single Shot Detector (SSD) Net, and feature
extractors; Inception Net V2 and NAS Net with real-world orchard datasets. We
also compare those approaches to find an optimal model which is suitable for a
real-time agricultural pollination robot system in terms of accuracy and
processing speed. We perform experiments with dataset collected from different
seasons and locations (spatio-temporal consistency) in order to demonstrate the
performance of the generalized model. The proposed system demonstrates
promising results of 0.919, 0.874, and 0.889 for precision, recall, and
F1-score respectively on our real-world dataset, and the performance satisfies
the requirement for deploying the system onto an autonomous pollination
robotics system.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.04271v1,2020-06-07T21:18:36Z,2020-06-07T21:18:36Z,"Multi-Task Reinforcement Learning based Mobile Manipulation Control for
  Dynamic Object Tracking and Grasping","Agile control of mobile manipulator is challenging because of the high
complexity coupled by the robotic system and the unstructured working
environment. Tracking and grasping a dynamic object with a random trajectory is
even harder. In this paper, a multi-task reinforcement learning-based mobile
manipulation control framework is proposed to achieve general dynamic object
tracking and grasping. Several basic types of dynamic trajectories are chosen
as the task training set. To improve the policy generalization in practice,
random noise and dynamics randomization are introduced during the training
process. Extensive experiments show that our policy trained can adapt to unseen
random dynamic trajectories with about 0.1m tracking error and 75\% grasping
success rate of dynamic objects. The trained policy can also be successfully
deployed on a real mobile manipulator.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.04225v1,2020-06-07T18:36:56Z,2020-06-07T18:36:56Z,"Unsupervised Learning for Subterranean Junction Recognition Based on 2D
  Point Cloud","This article proposes a novel unsupervised learning framework for detecting
the number of tunnel junctions in subterranean environments based on acquired
2D point clouds. The implementation of the framework provides valuable
information for high level mission planners to navigate an aerial platform in
unknown areas or robot homing missions. The framework utilizes spectral
clustering, which is capable of uncovering hidden structures from connected
data points lying on non-linear manifolds. The spectral clustering algorithm
computes a spectral embedding of the original 2D point cloud by utilizing the
eigen decomposition of a matrix that is derived from the pairwise similarities
of these points. We validate the developed framework using multiple data-sets,
collected from multiple realistic simulations, as well as from real flights in
underground environments, demonstrating the performance and merits of the
proposed methodology.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2006.03647v2,2020-06-23T16:54:09Z,2020-06-05T19:33:19Z,"Deployment-Efficient Reinforcement Learning via Model-Based Offline
  Optimization","Most reinforcement learning (RL) algorithms assume online access to the
environment, in which one may readily interleave updates to the policy with
experience collection using that policy. However, in many real-world
applications such as health, education, dialogue agents, and robotics, the cost
or potential risk of deploying a new data-collection policy is high, to the
point that it can become prohibitive to update the data-collection policy more
than a few times during learning. With this view, we propose a novel concept of
deployment efficiency, measuring the number of distinct data-collection
policies that are used during policy learning. We observe that na\""{i}vely
applying existing model-free offline RL algorithms recursively does not lead to
a practical deployment-efficient and sample-efficient algorithm. We propose a
novel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN) that
can effectively optimize a policy offline using 10-20 times fewer data than
prior works. Furthermore, the recursive application of BREMEN is able to
achieve impressive deployment efficiency while maintaining the same or better
sample efficiency, learning successful policies from scratch on simulated
robotic environments with only 5-10 deployments, compared to typical values of
hundreds to millions in standard RL baselines. Codes and pre-trained models are
available at https://github.com/matsuolab/BREMEN .",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.14302v1,2020-05-28T21:25:21Z,2020-05-28T21:25:21Z,Monocular Depth Estimators: Vulnerabilities and Attacks,"Recent advancements of neural networks lead to reliable monocular depth
estimation. Monocular depth estimated techniques have the upper hand over
traditional depth estimation techniques as it only needs one image during
inference. Depth estimation is one of the essential tasks in robotics, and
monocular depth estimation has a wide variety of safety-critical applications
like in self-driving cars and surgical devices. Thus, the robustness of such
techniques is very crucial. It has been shown in recent works that these deep
neural networks are highly vulnerable to adversarial samples for tasks like
classification, detection and segmentation. These adversarial samples can
completely ruin the output of the system, making their credibility in real-time
deployment questionable. In this paper, we investigate the robustness of the
most state-of-the-art monocular depth estimation networks against adversarial
attacks. Our experiments show that tiny perturbations on an image that are
invisible to the naked eye (perturbation attack) and corruption less than about
1% of an image (patch attack) can affect the depth estimation drastically. We
introduce a novel deep feature annihilation loss that corrupts the hidden
feature space representation forcing the decoder of the network to output poor
depth maps. The white-box and black-box test compliments the effectiveness of
the proposed attack. We also perform adversarial example transferability tests,
mainly cross-data transferability.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.13857v1,2020-05-28T09:15:14Z,2020-05-28T09:15:14Z,"Deep Reinforcement learning for real autonomous mobile robot navigation
  in indoor environments","Deep Reinforcement Learning has been successfully applied in various computer
games [8]. However, it is still rarely used in real-world applications,
especially for the navigation and continuous control of real mobile robots
[13]. Previous approaches lack safety and robustness and/or need a structured
environment. In this paper we present our proof of concept for autonomous
self-learning robot navigation in an unknown environment for a real robot
without a map or planner. The input for the robot is only the fused data from a
2D laser scanner and a RGB-D camera as well as the orientation to the goal. The
map of the environment is unknown. The output actions of an Asynchronous
Advantage Actor-Critic network (GA3C) are the linear and angular velocities for
the robot. The navigator/controller network is pretrained in a high-speed,
parallel, and self-implemented simulation environment to speed up the learning
process and then deployed to the real robot. To avoid overfitting, we train
relatively small networks, and we add random Gaussian noise to the input laser
data. The sensor data fusion with the RGB-D camera allows the robot to navigate
in real environments with real 3D obstacle avoidance and without the need to
fit the environment to the sensory capabilities of the robot. To further
increase the robustness, we train on environments of varying difficulties and
run 32 training instances simultaneously. Video: supplementary File / YouTube,
Code: GitHub",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.13131v1,2020-05-27T02:17:54Z,2020-05-27T02:17:54Z,"Efficient Pig Counting in Crowds with Keypoints Tracking and
  Spatial-aware Temporal Response Filtering","Pig counting is a crucial task for large-scale pig farming, which is usually
completed by human visually. But this process is very time-consuming and
error-prone. Few studies in literature developed automated pig counting method.
Existing methods only focused on pig counting using single image, and its
accuracy is challenged by several factors, including pig movements, occlusion
and overlapping. Especially, the field of view of a single image is very
limited, and could not meet the requirements of pig counting for large pig
grouping houses. To that end, we presented a real-time automated pig counting
system in crowds using only one monocular fisheye camera with an inspection
robot. Our system showed that it produces accurate results surpassing human.
Our pipeline began with a novel bottom-up pig detection algorithm to avoid
false negatives due to overlapping, occlusion and deformation of pigs. A deep
convolution neural network (CNN) is designed to detect keypoints of pig body
part and associate the keypoints to identify individual pigs. After that, an
efficient on-line tracking method is used to associate pigs across video
frames. Finally, a novel spatial-aware temporal response filtering (STRF)
method is proposed to predict the counts of pigs, which is effective to
suppress false positives caused by pig or camera movements or tracking
failures. The whole pipeline has been deployed in an edge computing device, and
demonstrated the effectiveness.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.11711v1,2020-05-24T10:32:49Z,2020-05-24T10:32:49Z,Learning Camera Miscalibration Detection,"Self-diagnosis and self-repair are some of the key challenges in deploying
robotic platforms for long-term real-world applications. One of the issues that
can occur to a robot is miscalibration of its sensors due to aging,
environmental transients, or external disturbances. Precise calibration lies at
the core of a variety of applications, due to the need to accurately perceive
the world. However, while a lot of work has focused on calibrating the sensors,
not much has been done towards identifying when a sensor needs to be
recalibrated. This paper focuses on a data-driven approach to learn the
detection of miscalibration in vision sensors, specifically RGB cameras. Our
contributions include a proposed miscalibration metric for RGB cameras and a
novel semi-synthetic dataset generation pipeline based on this metric.
Additionally, by training a deep convolutional neural network, we demonstrate
the effectiveness of our pipeline to identify whether a recalibration of the
camera's intrinsic parameters is required or not. The code is available at
http://github.com/ethz-asl/camera_miscalib_detection.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.13976v1,2020-05-22T19:00:38Z,2020-05-22T19:00:38Z,"Towards Automated Safety Coverage and Testing for Autonomous Vehicles
  with Reinforcement Learning","The kind of closed-loop verification likely to be required for autonomous
vehicle (AV) safety testing is beyond the reach of traditional test
methodologies and discrete verification. Validation puts the autonomous vehicle
system to the test in scenarios or situations that the system would likely
encounter in everyday driving after its release. These scenarios can either be
controlled directly in a physical (closed-course proving ground) or virtual
(simulation of predefined scenarios) environment, or they can arise
spontaneously during operation in the real world (open-road testing or
simulation of randomly generated scenarios).
  In AV testing, simulation serves primarily two purposes: to assist the
development of a robust autonomous vehicle and to test and validate the AV
before release. A challenge arises from the sheer number of scenario variations
that can be constructed from each of the above sources due to the high number
of variables involved (most of which are continuous). Even with continuous
variables discretized, the possible number of combinations becomes practically
infeasible to test. To overcome this challenge we propose using reinforcement
learning (RL) to generate failure examples and unexpected traffic situations
for the AV software implementation. Although reinforcement learning algorithms
have achieved notable results in games and some robotic manipulations, this
technique has not been widely scaled up to the more challenging real world
applications like autonomous driving.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.07541v1,2020-05-15T13:46:55Z,2020-05-15T13:46:55Z,Simple Sensor Intentions for Exploration,"Modern reinforcement learning algorithms can learn solutions to increasingly
difficult control problems while at the same time reduce the amount of prior
knowledge needed for their application. One of the remaining challenges is the
definition of reward schemes that appropriately facilitate exploration without
biasing the solution in undesirable ways, and that can be implemented on real
robotic systems without expensive instrumentation. In this paper we focus on a
setting in which goal tasks are defined via simple sparse rewards, and
exploration is facilitated via agent-internal auxiliary tasks. We introduce the
idea of simple sensor intentions (SSIs) as a generic way to define auxiliary
tasks. SSIs reduce the amount of prior knowledge that is required to define
suitable rewards. They can further be computed directly from raw sensor streams
and thus do not require expensive and possibly brittle state estimation on real
systems. We demonstrate that a learning system based on these rewards can solve
complex robotic tasks in simulation and in real world settings. In particular,
we show that a real robotic arm can learn to grasp and lift and solve a
Ball-in-a-Cup task from scratch, when only raw sensor streams are used for both
controller input and in the auxiliary reward definition.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.03813v1,2020-05-08T01:17:59Z,2020-05-08T01:17:59Z,"Using Taint Analysis and Reinforcement Learning (TARL) to Repair
  Autonomous Robot Software","It is important to be able to establish formal performance bounds for
autonomous systems. However, formal verification techniques require a model of
the environment in which the system operates; a challenge for autonomous
systems, especially those expected to operate over longer timescales. This
paper describes work in progress to automate the monitor and repair of
ROS-based autonomous robot software written for an a-priori partially known and
possibly incorrect environment model. A taint analysis method is used to
automatically extract the data-flow sequence from input topic to publish topic,
and instrument that code. A unique reinforcement learning approximation of MDP
utility is calculated, an empirical and non-invasive characterization of the
inherent objectives of the software designers. By comparing off-line (a-priori)
utility with on-line (deployed system) utility, we show, using a small but real
ROS example, that it's possible to monitor a performance criterion and relate
violations of the criterion to parts of the software. The software is then
patched using automated software repair techniques and evaluated against the
original off-line utility.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2005.04106v1,2020-04-23T14:02:53Z,2020-04-23T14:02:53Z,"Brain experiments imply adaptation mechanisms which outperform common AI
  learning algorithms","Attempting to imitate the brain functionalities, researchers have bridged
between neuroscience and artificial intelligence for decades; however,
experimental neuroscience has not directly advanced the field of machine
learning. Here, using neuronal cultures, we demonstrate that increased training
frequency accelerates the neuronal adaptation processes. This mechanism was
implemented on artificial neural networks, where a local learning step-size
increases for coherent consecutive learning steps and tested on a simple
dataset of handwritten digits, MNIST. Based on our online learning results with
a few handwriting examples, success rates for brain-inspired algorithms
substantially outperform the commonly used machine learning algorithms. We
speculate this emerging bridge from slow brain function to machine learning
will promote ultrafast decision making under limited examples, which is the
reality in many aspects of human activity, robotic control, and network
optimization.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.10251v1,2020-04-21T19:40:16Z,2020-04-21T19:40:16Z,"Industrial Robot Grasping with Deep Learning using a Programmable Logic
  Controller (PLC)","Universal grasping of a diverse range of previously unseen objects from heaps
is a grand challenge in e-commerce order fulfillment, manufacturing, and home
service robotics. Recently, deep learning based grasping approaches have
demonstrated results that make them increasingly interesting for industrial
deployments. This paper explores the problem from an automation systems
point-of-view. We develop a robotics grasping system using Dex-Net, which is
fully integrated at the controller level. Two neural networks are deployed on a
novel industrial AI hardware acceleration module close to a PLC with a power
footprint of less than 10 W for the overall system. The software is tightly
integrated with the hardware allowing for fast and efficient data processing
and real-time communication. The success rate of grasping an object form a bin
is up to 95 percent with more than 350 picks per hour, if object and receptive
bins are in close proximity. The system was presented at the Hannover Fair 2019
(world s largest industrial trade fair) and other events, where it performed
over 5,000 grasps per event.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.10190v2,2020-07-31T13:43:53Z,2020-04-21T17:57:04Z,"Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic
  Reinforcement Learning","One of the great promises of robot learning systems is that they will be able
to learn from their mistakes and continuously adapt to ever-changing
environments. Despite this potential, most of the robot learning systems today
are deployed as a fixed policy and they are not being adapted after their
deployment. Can we efficiently adapt previously learned behaviors to new
environments, objects and percepts in the real world? In this paper, we present
a method and empirical evidence towards a robot learning framework that
facilitates continuous adaption. In particular, we demonstrate how to adapt
vision-based robotic manipulation policies to new variations by fine-tuning via
off-policy reinforcement learning, including changes in background, object
shape and appearance, lighting conditions, and robot morphology. Further, this
adaptation uses less than 0.2% of the data necessary to learn the task from
scratch. We find that our approach of adapting pre-trained policies leads to
substantial performance gains over the course of fine-tuning, and that
pre-training via RL is essential: training from scratch or adapting from
supervised ImageNet features are both unsuccessful with such small amounts of
data. We also find that these positive results hold in a limited continual
learning setting, in which we repeatedly fine-tune a single lineage of policies
using data from a succession of new tasks. Our empirical conclusions are
consistently supported by experiments on simulated manipulation tasks, and by
52 unique fine-tuning experiments on a real robotic grasping system pre-trained
on 580,000 grasps.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.09218v1,2020-04-20T11:48:24Z,2020-04-20T11:48:24Z,"A Practical Guide to Studying Emergent Communication through Grounded
  Language Games","The question of how an effective and efficient communication system can
emerge in a population of agents that need to solve a particular task attracts
more and more attention from researchers in many fields, including artificial
intelligence, linguistics and statistical physics. A common methodology for
studying this question consists of carrying out multi-agent experiments in
which a population of agents takes part in a series of scripted and
task-oriented communicative interactions, called 'language games'. While each
individual language game is typically played by two agents in the population, a
large series of games allows the population to converge on a shared
communication system. Setting up an experiment in which a rich system for
communicating about the real world emerges is a major enterprise, as it
requires a variety of software components for running multi-agent experiments,
for interacting with sensors and actuators, for conceptualising and
interpreting semantic structures, and for mapping between these semantic
structures and linguistic utterances. The aim of this paper is twofold. On the
one hand, it introduces a high-level robot interface that extends the Babel
software system, presenting for the first time a toolkit that provides flexible
modules for dealing with each subtask involved in running advanced grounded
language game experiments. On the other hand, it provides a practical guide to
using the toolkit for implementing such experiments, taking a grounded colour
naming game experiment as a didactic example.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.00784v3,2020-07-21T00:59:24Z,2020-04-02T02:56:16Z,Learning Agile Robotic Locomotion Skills by Imitating Animals,"Reproducing the diverse and agile locomotion skills of animals has been a
longstanding challenge in robotics. While manually-designed controllers have
been able to emulate many complex behaviors, building such controllers involves
a time-consuming and difficult development process, often requiring substantial
expertise of the nuances of each skill. Reinforcement learning provides an
appealing alternative for automating the manual effort involved in the
development of controllers. However, designing learning objectives that elicit
the desired behaviors from an agent can also require a great deal of
skill-specific expertise. In this work, we present an imitation learning system
that enables legged robots to learn agile locomotion skills by imitating
real-world animals. We show that by leveraging reference motion data, a single
learning-based approach is able to automatically synthesize controllers for a
diverse repertoire behaviors for legged robots. By incorporating sample
efficient domain adaptation techniques into the training process, our system is
able to learn adaptive policies in simulation that can then be quickly adapted
for real-world deployment. To demonstrate the effectiveness of our system, we
train an 18-DoF quadruped robot to perform a variety of agile behaviors ranging
from different locomotion gaits to dynamic hops and turns.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2004.00136v1,2020-03-31T21:57:09Z,2020-03-31T21:57:09Z,Sim-to-Real Transfer for Optical Tactile Sensing,"Deep learning and reinforcement learning methods have been shown to enable
learning of flexible and complex robot controllers. However, the reliance on
large amounts of training data often requires data collection to be carried out
in simulation, with a number of sim-to-real transfer methods being developed in
recent years. In this paper, we study these techniques for tactile sensing
using the TacTip optical tactile sensor, which consists of a deformable tip
with a camera observing the positions of pins inside this tip. We designed a
model for soft body simulation which was implemented using the Unity physics
engine, and trained a neural network to predict the locations and angles of
edges when in contact with the sensor. Using domain randomisation techniques
for sim-to-real transfer, we show how this framework can be used to accurately
predict edges with less than 1 mm prediction error in real-world testing,
without any real-world data at all.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.12228v1,2020-03-27T04:10:06Z,2020-03-27T04:10:06Z,Mechanism Design for Wireless Powered Spatial Crowdsourcing Networks,"Wireless power transfer (WPT) is a promising technology to prolong the
lifetime of the sensors and communication devices, i.e., workers, in completing
crowdsourcing tasks by providing continuous and cost-effective energy supplies.
In this paper, we propose a wireless powered spatial crowdsourcing framework
which consists of two mutually dependent phases: task allocation phase and data
crowdsourcing phase. In the task allocation phase, we propose a Stackelberg
game based mechanism for the spatial crowdsourcing platform to efficiently
allocate spatial tasks and wireless charging power to each worker. In the data
crowdsourcing phase, the workers may have an incentive to misreport its real
working location to improve its utility, which causes adverse effects to the
spatial crowdsourcing platform. To address this issue, we present three
strategyproof deployment mechanisms for the spatial crowdsourcing platform to
place a mobile base station, e.g., vehicle or robot, which is responsible for
transferring the wireless power and collecting the crowdsourced data. As the
benchmark, we first apply the classical median mechanism and evaluate its
worst-case performance. Then, we design a conventional strategyproof deployment
mechanism to improve the expected utility of the spatial crowdsourcing platform
under the condition that the workers' locations follow a known geographical
distribution. For a more general case with only the historical location data
available, we propose a deep learning based strategyproof deployment mechanism
to maximize the spatial crowdsourcing platform's utility. Extensive
experimental results based on synthetic and real-world datasets reveal the
effectiveness of the proposed framework in allocating tasks and charging power
to workers while avoiding the dishonest worker's manipulation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.11334v3,2020-11-09T09:39:59Z,2020-03-25T11:28:12Z,"ACNMP: Skill Transfer and Task Extrapolation through Learning from
  Demonstration and Reinforcement Learning via Representation Sharing","To equip robots with dexterous skills, an effective approach is to first
transfer the desired skill via Learning from Demonstration (LfD), then let the
robot improve it by self-exploration via Reinforcement Learning (RL). In this
paper, we propose a novel LfD+RL framework, namely Adaptive Conditional Neural
Movement Primitives (ACNMP), that allows efficient policy improvement in novel
environments and effective skill transfer between different agents. This is
achieved through exploiting the latent representation learned by the underlying
Conditional Neural Process (CNP) model, and simultaneous training of the model
with supervised learning (SL) for acquiring the demonstrated trajectories and
via RL for new trajectory discovery. Through simulation experiments, we show
that (i) ACNMP enables the system to extrapolate to situations where pure LfD
fails; (ii) Simultaneous training of the system through SL and RL preserves the
shape of demonstrations while adapting to novel situations due to the shared
representations used by both learners; (iii) ACNMP enables order-of-magnitude
sample-efficient RL in extrapolation of reaching tasks compared to the existing
approaches; (iv) ACNMPs can be used to implement skill transfer between robots
having different morphology, with competitive learning speeds and importantly
with less number of assumptions compared to the state-of-the-art approaches.
Finally, we show the real-world suitability of ACNMPs through real robot
experiments that involve obstacle avoidance, pick and place and pouring
actions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.10315v1,2020-03-23T15:04:30Z,2020-03-23T15:04:30Z,Adversarial Attacks on Monocular Depth Estimation,"Recent advances of deep learning have brought exceptional performance on many
computer vision tasks such as semantic segmentation and depth estimation.
However, the vulnerability of deep neural networks towards adversarial examples
have caused grave concerns for real-world deployment. In this paper, we present
to the best of our knowledge the first systematic study of adversarial attacks
on monocular depth estimation, an important task of 3D scene understanding in
scenarios such as autonomous driving and robot navigation. In order to
understand the impact of adversarial attacks on depth estimation, we first
define a taxonomy of different attack scenarios for depth estimation, including
non-targeted attacks, targeted attacks and universal attacks. We then adapt
several state-of-the-art attack methods for classification on the field of
depth estimation. Besides, multi-task attacks are introduced to further improve
the attack performance for universal attacks. Experimental results show that it
is possible to generate significant errors on depth estimation. In particular,
we demonstrate that our methods can conduct targeted attacks on given objects
(such as a car), resulting in depth estimation 3-4x away from the ground truth
(e.g., from 20m to 80m).",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.08876v3,2020-08-04T10:41:38Z,2020-03-19T15:55:39Z,Learning to Fly via Deep Model-Based Reinforcement Learning,"Learning to control robots without requiring engineered models has been a
long-term goal, promising diverse and novel applications. Yet, reinforcement
learning has only achieved limited impact on real-time robot control due to its
high demand of real-world interactions. In this work, by leveraging a learnt
probabilistic model of drone dynamics, we learn a thrust-attitude controller
for a quadrotor through model-based reinforcement learning. No prior knowledge
of the flight dynamics is assumed; instead, a sequential latent variable model,
used generatively and as an online filter, is learnt from raw sensory input.
The controller and value function are optimised entirely by propagating
stochastic analytic gradients through generated latent trajectories. We show
that ""learning to fly"" can be achieved with less than 30 minutes of experience
with a single drone, and can be deployed solely using onboard computational
resources and sensors, on a self-built drone.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.05861v1,2020-03-12T15:52:49Z,2020-03-12T15:52:49Z,"The Chef's Hat Simulation Environment for Reinforcement-Learning-Based
  Agents","To achieve social interactions within Human-Robot Interaction (HRI)
environments is a very challenging task. Most of the current research focuses
on Wizard-of-Oz approaches, which neglect the recent development of intelligent
robots. On the other hand, real-world scenarios usually do not provide the
necessary control and reproducibility which are needed for learning algorithms.
In this paper, we propose a virtual simulation environment that implements the
Chef's Hat card game, designed to be used in HRI scenarios, to provide a
controllable and reproducible scenario for reinforcement-learning algorithms.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.05117v3,2020-07-27T07:02:39Z,2020-03-11T05:12:26Z,"Multiplicative Controller Fusion: Leveraging Algorithmic Priors for
  Sample-efficient Reinforcement Learning and Safe Sim-To-Real Transfer","Learning-based approaches often outperform hand-coded algorithmic solutions
for many problems in robotics. However, learning long-horizon tasks on real
robot hardware can be intractable, and transferring a learned policy from
simulation to reality is still extremely challenging. We present a novel
approach to model-free reinforcement learning that can leverage existing
sub-optimal solutions as an algorithmic prior during training and deployment.
During training, our gated fusion approach enables the prior to guide the
initial stages of exploration, increasing sample-efficiency and enabling
learning from sparse long-horizon reward signals. Importantly, the policy can
learn to improve beyond the performance of the sub-optimal prior since the
prior's influence is annealed gradually. During deployment, the policy's
uncertainty provides a reliable strategy for transferring a simulation-trained
policy to the real world by falling back to the prior controller in uncertain
states. We show the efficacy of our Multiplicative Controller Fusion approach
on the task of robot navigation and demonstrate safe transfer from simulation
to the real world without any fine-tuning. The code for this project is made
publicly available at https://sites.google.com/view/mcf-nav/home",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.04956v1,2020-03-10T20:26:26Z,2020-03-10T20:26:26Z,"SQUIRL: Robust and Efficient Learning from Video Demonstration of
  Long-Horizon Robotic Manipulation Tasks","Recent advances in deep reinforcement learning (RL) have demonstrated its
potential to learn complex robotic manipulation tasks. However, RL still
requires the robot to collect a large amount of real-world experience. To
address this problem, recent works have proposed learning from expert
demonstrations (LfD), particularly via inverse reinforcement learning (IRL),
given its ability to achieve robust performance with only a small number of
expert demonstrations. Nevertheless, deploying IRL on real robots is still
challenging due to the large number of robot experiences it requires. This
paper aims to address this scalability challenge with a robust,
sample-efficient, and general meta-IRL algorithm, SQUIRL, that performs a new
but related long-horizon task robustly given only a single video demonstration.
First, this algorithm bootstraps the learning of a task encoder and a
task-conditioned policy using behavioral cloning (BC). It then collects
real-robot experiences and bypasses reward learning by directly recovering a
Q-function from the combined robot and expert trajectories. Next, this
algorithm uses the Q-function to re-evaluate all cumulative experiences
collected by the robot to improve the policy quickly. In the end, the policy
performs more robustly (90%+ success) than BC on new tasks while requiring no
trial-and-errors at test time. Finally, our real-robot and simulated
experiments demonstrate our algorithm's generality across different state
spaces, action spaces, and vision-based manipulation tasks, e.g.,
pick-pour-place and pick-carry-drop.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.03200v2,2020-04-20T09:12:58Z,2020-03-06T13:40:44Z,"Practical Reinforcement Learning For MPC: Learning from sparse
  objectives in under an hour on a real robot","Model Predictive Control (MPC) is a powerful control technique that handles
constraints, takes the system's dynamics into account, and optimizes for a
given cost function. In practice, however, it often requires an expert to craft
and tune this cost function and find trade-offs between different state
penalties to satisfy simple high level objectives. In this paper, we use
Reinforcement Learning and in particular value learning to approximate the
value function given only high level objectives, which can be sparse and
binary. Building upon previous works, we present improvements that allowed us
to successfully deploy the method on a real world unmanned ground vehicle. Our
experiments show that our method can learn the cost function from scratch and
without human intervention, while reaching a performance level similar to that
of an expert-tuned MPC. We perform a quantitative comparison of these methods
with standard MPC approaches both in simulation and on the real robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.02372v1,2020-03-04T23:46:45Z,2020-03-04T23:46:45Z,Dynamic Experience Replay,"We present a novel technique called Dynamic Experience Replay (DER) that
allows Reinforcement Learning (RL) algorithms to use experience replay samples
not only from human demonstrations but also successful transitions generated by
RL agents during training and therefore improve training efficiency. It can be
combined with an arbitrary off-policy RL algorithm, such as DDPG or DQN, and
their distributed versions. We build upon Ape-X DDPG and demonstrate our
approach on robotic tight-fitting joint assembly tasks, based on force/torque
and Cartesian pose observations. In particular, we run experiments on two
different tasks: peg-in-hole and lap-joint. In each case, we compare different
replay buffer structures and how DER affects them. Our ablation studies show
that Dynamic Experience Replay is a crucial ingredient that either largely
shortens the training time in these challenging environments or solves the
tasks that the vanilla Ape-X DDPG cannot solve. We also show that our policies
learned purely in simulation can be deployed successfully on the real robot.
The video presenting our experiments is available at
https://sites.google.com/site/dynamicexperiencereplay",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.01825v3,2020-06-05T15:59:15Z,2020-03-03T23:02:37Z,Scaling MAP-Elites to Deep Neuroevolution,"Quality-Diversity (QD) algorithms, and MAP-Elites (ME) in particular, have
proven very useful for a broad range of applications including enabling real
robots to recover quickly from joint damage, solving strongly deceptive maze
tasks or evolving robot morphologies to discover new gaits. However, present
implementations of MAP-Elites and other QD algorithms seem to be limited to
low-dimensional controllers with far fewer parameters than modern deep neural
network models. In this paper, we propose to leverage the efficiency of
Evolution Strategies (ES) to scale MAP-Elites to high-dimensional controllers
parameterized by large neural networks. We design and evaluate a new hybrid
algorithm called MAP-Elites with Evolution Strategies (ME-ES) for post-damage
recovery in a difficult high-dimensional control task where traditional ME
fails. Additionally, we show that ME-ES performs efficient exploration, on par
with state-of-the-art exploration algorithms in high-dimensional control tasks
with strongly deceptive rewards.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.01157v2,2020-07-31T22:25:13Z,2020-03-02T19:39:16Z,"Reinforcement co-Learning of Deep and Spiking Neural Networks for
  Energy-Efficient Mapless Navigation with Neuromorphic Hardware","Energy-efficient mapless navigation is crucial for mobile robots as they
explore unknown environments with limited on-board resources. Although the
recent deep reinforcement learning (DRL) approaches have been successfully
applied to navigation, their high energy consumption limits their use in
several robotic applications. Here, we propose a neuromorphic approach that
combines the energy-efficiency of spiking neural networks with the optimality
of DRL and benchmark it in learning control policies for mapless navigation.
Our hybrid framework, spiking deep deterministic policy gradient (SDDPG),
consists of a spiking actor network (SAN) and a deep critic network, where the
two networks were trained jointly using gradient descent. The co-learning
enabled synergistic information exchange between the two networks, allowing
them to overcome each other's limitations through a shared representation
learning. To evaluate our approach, we deployed the trained SAN on Intel's
Loihi neuromorphic processor. When validated on simulated and real-world
complex environments, our method on Loihi consumed 75 times less energy per
inference as compared to DDPG on Jetson TX2, and also exhibited a higher rate
of successful navigation to the goal, which ranged from 1% to 4.2% and depended
on the forward-propagation timestep size. These results reinforce our ongoing
efforts to design brain-inspired algorithms for controlling autonomous robots
with neuromorphic hardware.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2003.00628v3,2020-07-20T02:39:28Z,2020-03-02T01:58:03Z,"Learning Force Control for Contact-rich Manipulation Tasks with Rigid
  Position-controlled Robots","Reinforcement Learning (RL) methods have been proven successful in solving
manipulation tasks autonomously. However, RL is still not widely adopted on
real robotic systems because working with real hardware entails additional
challenges, especially when using rigid position-controlled manipulators. These
challenges include the need for a robust controller to avoid undesired
behavior, that risk damaging the robot and its environment, and constant
supervision from a human operator. The main contributions of this work are,
first, we proposed a learning-based force control framework combining RL
techniques with traditional force control. Within said control scheme, we
implemented two different conventional approaches to achieve force control with
position-controlled robots; one is a modified parallel position/force control,
and the other is an admittance control. Secondly, we empirically study both
control schemes when used as the action space of the RL agent. Thirdly, we
developed a fail-safe mechanism for safely training an RL agent on manipulation
tasks using a real rigid robot manipulator. The proposed methods are validated
on simulation and a real robot, an UR3 e-series robotic arm.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.11573v2,2020-10-02T17:02:25Z,2020-02-26T15:47:11Z,"Efficient reinforcement learning control for continuum robots based on
  Inexplicit Prior Knowledge","Compared to rigid robots that are generally studied in reinforcement
learning, the physical characteristics of some sophisticated robots such as
soft or continuum robots are higher complicated. Moreover, recent reinforcement
learning methods are data-inefficient and can not be directly deployed to the
robot without simulation. In this paper, we propose an efficient reinforcement
learning method based on inexplicit prior knowledge in response to such
problems. We first corroborate the method by simulation and employed directly
in the real world. By using our method, we can achieve active visual tracking
and distance maintenance of a tendon-driven robot which will be critical in
minimally invasive procedures. Codes are available at
https://github.com/Skylark0924/TendonTrack.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.10853v1,2020-02-25T13:36:15Z,2020-02-25T13:36:15Z,Learning Machines from Simulation to Real World,"Learning Machines is developing a flexible, cross-industry, advanced
analytics platform, targeted during stealth-stage at a limited number of
specific vertical applications. In this paper, we aim to integrate a general
machine system to learn a variant of tasks from simulation to real world. In
such a machine system, it involves real-time robot vision, sensor fusion, and
learning algorithms (reinforcement learning). To this end, we demonstrate the
general machine system on three fundamental tasks including obstacle avoidance,
foraging, and predator-prey robot. The proposed solutions are implemented on
Robobo robots with mobile device (smartphone with camera) as interface and
built-in infrared (IR) sensors. The agent is trained in a virtual environment.
In order to assess its performance, the learned agent is tested in the virtual
environment and reproduce the same results in a real environment. The results
show that the reinforcement learning algorithm can be reliably used for a
variety of tasks in unknown environments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.10718v2,2020-06-26T07:43:00Z,2020-02-25T08:04:31Z,"Denoising IMU Gyroscopes with Deep Learning for Open-Loop Attitude
  Estimation","This paper proposes a learning method for denoising gyroscopes of Inertial
Measurement Units (IMUs) using ground truth data, and estimating in real time
the orientation (attitude) of a robot in dead reckoning. The obtained algorithm
outperforms the state-of-the-art on the (unseen) test sequences. The obtained
performances are achieved thanks to a well-chosen model, a proper loss function
for orientation increments, and through the identification of key points when
training with high-frequency inertial data. Our approach builds upon a neural
network based on dilated convolutions, without requiring any recurrent neural
network. We demonstrate how efficient our strategy is for 3D attitude
estimation on the EuRoC and TUM-VI datasets. Interestingly, we observe our dead
reckoning algorithm manages to beat top-ranked visual-inertial odometry systems
in terms of attitude estimation although it does not use vision sensors. We
believe this paper offers new perspectives for visual-inertial localization and
constitutes a step toward more efficient learning methods involving IMUs. Our
open-source implementation is available at
https://github.com/mbrossar/denoise-imu-gyro.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.09676v1,2020-02-22T10:15:53Z,2020-02-22T10:15:53Z,"Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot
  Locomotion","Deep reinforcement learning (RL) uses model-free techniques to optimize
task-specific control policies. Despite having emerged as a promising approach
for complex problems, RL is still hard to use reliably for real-world
applications. Apart from challenges such as precise reward function tuning,
inaccurate sensing and actuation, and non-deterministic response, existing RL
methods do not guarantee behavior within required safety constraints that are
crucial for real robot scenarios. In this regard, we introduce guided
constrained policy optimization (GCPO), an RL framework based upon our
implementation of constrained proximal policy optimization (CPPO) for tracking
base velocity commands while following the defined constraints. We also
introduce schemes which encourage state recovery into constrained regions in
case of constraint violations. We present experimental results of our training
method and test it on the real ANYmal quadruped robot. We compare our approach
against the unconstrained RL method and show that guided constrained RL offers
faster convergence close to the desired optimum resulting in an optimal, yet
physically feasible, robotic control behavior without the need for precise
reward function tuning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.04700v4,2020-03-15T03:27:52Z,2020-02-11T21:42:22Z,"A Single RGB Camera Based Gait Analysis with a Mobile Tele-Robot for
  Healthcare","With the increasing awareness of high-quality life, there is a growing need
for health monitoring devices running robust algorithms in home environment.
Health monitoring technologies enable real-time analysis of users' health
status, offering long-term healthcare support and reducing hospitalization
time. The purpose of this work is twofold, the software focuses on the analysis
of gait, which is widely adopted for joint correction and assessing any lower
limb or spinal problem. On the hardware side, we design a novel marker-less
gait analysis device using a low-cost RGB camera mounted on a mobile
tele-robot. As gait analysis with a single camera is much more challenging
compared to previous works utilizing multi-cameras, a RGB-D camera or wearable
sensors, we propose using vision-based human pose estimation approaches. More
specifically, based on the output of two state-of-the-art human pose estimation
models (Openpose and VNect), we devise measurements for four bespoke gait
parameters: inversion/eversion, dorsiflexion/plantarflexion, ankle and foot
progression angles. We thereby classify walking patterns into normal,
supination, pronation and limp. We also illustrate how to run the purposed
machine learning models in low-resource environments such as a single
entry-level CPU. Experiments show that our single RGB camera method achieves
competitive performance compared to state-of-the-art methods based on depth
cameras or multi-camera motion capture system, at smaller hardware costs.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.08333v1,2020-02-11T15:32:28Z,2020-02-11T15:32:28Z,"Towards Intelligent Pick and Place Assembly of Individualized Products
  Using Reinforcement Learning","Individualized manufacturing is becoming an important approach as a means to
fulfill increasingly diverse and specific consumer requirements and
expectations. While there are various solutions to the implementation of the
manufacturing process, such as additive manufacturing, the subsequent automated
assembly remains a challenging task. As an approach to this problem, we aim to
teach a collaborative robot to successfully perform pick and place tasks by
implementing reinforcement learning. For the assembly of an individualized
product in a constantly changing manufacturing environment, the simulated
geometric and dynamic parameters will be varied. Using reinforcement learning
algorithms capable of meta-learning, the tasks will first be trained in
simulation. They will then be performed in a real-world environment where new
factors are introduced that were not simulated in training to confirm the
robustness of the algorithms. The robot will gain its input data from tactile
sensors, area scan cameras, and 3D cameras used to generate heightmaps of the
environment and the objects. The selection of machine learning algorithms and
hardware components as well as further research questions to realize the
outlined production scenario are the results of the presented work.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.04349v1,2020-02-11T12:41:01Z,2020-02-11T12:41:01Z,Robot Navigation with Map-Based Deep Reinforcement Learning,"This paper proposes an end-to-end deep reinforcement learning approach for
mobile robot navigation with dynamic obstacles avoidance. Using experience
collected in a simulation environment, a convolutional neural network (CNN) is
trained to predict proper steering actions of a robot from its egocentric local
occupancy maps, which accommodate various sensors and fusion algorithms. The
trained neural network is then transferred and executed on a real-world mobile
robot to guide its local path planning. The new approach is evaluated both
qualitatively and quantitatively in simulation and real-world robot
experiments. The results show that the map-based end-to-end navigation model is
easy to be deployed to a robotic platform, robust to sensor noise and
outperforms other existing DRL-based models in many indicators.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.08242v1,2020-02-11T08:23:14Z,2020-02-11T08:23:14Z,AI Online Filters to Real World Image Recognition,"Deep artificial neural networks, trained with labeled data sets are widely
used in numerous vision and robotics applications today. In terms of AI, these
are called reflex models, referring to the fact that they do not self-evolve or
actively adapt to environmental changes. As demand for intelligent robot
control expands to many high level tasks, reinforcement learning and state
based models play an increasingly important role. Herein, in computer vision
and robotics domain, we study a novel approach to add reinforcement controls
onto the image recognition reflex models to attain better overall performance,
specifically to a wider environment range beyond what is expected of the task
reflex models. Follow a common infrastructure with environment sensing and AI
based modeling of self-adaptive agents, we implement multiple types of AI
control agents. To the end, we provide comparative results of these agents with
baseline, and an insightful analysis of their benefit to improve overall image
recognition performance in real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2002.03197v3,2020-07-28T20:11:01Z,2020-02-08T16:36:44Z,"Recurrent Neural Network Control of a Hybrid Dynamic Transfemoral
  Prosthesis with EdgeDRNN Accelerator","Lower leg prostheses could improve the life quality of amputees by increasing
comfort and reducing energy to locomote, but currently control methods are
limited in modulating behaviors based upon the human's experience. This paper
describes the first steps toward learning complex controllers for dynamical
robotic assistive devices. We provide the first example of behavioral cloning
to control a powered transfemoral prostheses using a Gated Recurrent Unit (GRU)
based recurrent neural network (RNN) running on a custom hardware accelerator
that exploits temporal sparsity. The RNN is trained on data collected from the
original prosthesis controller. The RNN inference is realized by a novel
EdgeDRNN accelerator in real-time. Experimental results show that the RNN can
replace the nominal PD controller to realize end-to-end control of the AMPRO3
prosthetic leg walking on flat ground and unforeseen slopes with comparable
tracking accuracy. EdgeDRNN computes the RNN about 240 times faster than real
time, opening the possibility of running larger networks for more complex tasks
in the future. Implementing an RNN on this real-time dynamical system with
impacts sets the ground work to incorporate other learned elements of the
human-prosthesis system into prosthesis control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.11710v2,2020-11-13T04:38:34Z,2020-01-31T08:50:22Z,"Context-Aware Deep Q-Network for Decentralized Cooperative
  Reconnaissance by a Robotic Swarm","One of the crucial problems in robotic swarm-based operation is to search and
neutralize heterogeneous targets in an unknown and uncertain environment,
without any communication within the swarm. Here, some targets can be
neutralized by a single robot, while others need multiple robots in a
particular sequence to neutralize them. The complexity in the problem arises
due to the scalability and information uncertainty, which restricts the robot's
awareness of the swarm and the target distribution. In this paper, this problem
is addressed by proposing a novel Context-Aware Deep Q-Network (CA-DQN)
framework to obtain communication free cooperation between the robots in the
swarm. Each robot maintains an adaptive grid representation of the vicinity
with the context information embedded into it to keep the swarm intact while
searching and neutralizing the targets. The problem formulation uses a
reinforcement learning framework where two Deep Q-Networks (DQNs) handle
'conflict' and 'conflict-free' scenarios separately. The self-play-in-based
approach is used to determine the optimal policy for the DQNs. Monte-Carlo
simulations and comparison studies with a state-of-the-art coalition formation
algorithm are performed to verify the performance of CA-DQN with varying
environmental parameters. The results show that the approach is invariant to
the number of detected targets and the number of robots in the swarm. The paper
also presents the real-time implementation of CA-DQN for different scenarios
using ground robots in a laboratory environment to demonstrate the working of
CA-DQN with low-power computing devices.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.10249v1,2020-01-28T10:30:20Z,2020-01-28T10:30:20Z,"Online LiDAR-SLAM for Legged Robots with Robust Registration and
  Deep-Learned Loop Closure","In this paper, we present a factor-graph LiDAR-SLAM system which incorporates
a state-of-the-art deeply learned feature-based loop closure detector to enable
a legged robot to localize and map in industrial environments. These facilities
can be badly lit and comprised of indistinct metallic structures, thus our
system uses only LiDAR sensing and was developed to run on the quadruped
robot's navigation PC. Point clouds are accumulated using an inertial-kinematic
state estimator before being aligned using ICP registration. To close loops we
use a loop proposal mechanism which matches individual segments between clouds.
We trained a descriptor offline to match these segments. The efficiency of our
method comes from carefully designing the network architecture to minimize the
number of parameters such that this deep learning method can be deployed in
real-time using only the CPU of a legged robot, a major contribution of this
work. The set of odometry and loop closure factors are updated using pose graph
optimization. Finally we present an efficient risk alignment prediction method
which verifies the reliability of the registrations. Experimental results at an
industrial facility demonstrated the robustness and flexibility of our system,
including autonomous following paths derived from the SLAM map.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.09778v2,2020-02-06T14:46:51Z,2020-01-22T15:39:42Z,"Artificial intelligence in medicine and healthcare: a review and
  classification of current and near-future applications and their ethical and
  social Impact","This paper provides an overview of the current and near-future applications
of Artificial Intelligence (AI) in Medicine and Health Care and presents a
classification according to their ethical and societal aspects, potential
benefits and pitfalls, and issues that can be considered controversial and are
not deeply discussed in the literature.
  This work is based on an analysis of the state of the art of research and
technology, including existing software, personal monitoring devices, genetic
tests and editing tools, personalized digital models, online platforms,
augmented reality devices, and surgical and companion robotics. Motivated by
our review, we present and describe the notion of 'extended personalized
medicine', we then review existing applications of AI in medicine and
healthcare and explore the public perception of medical AI systems, and how
they show, simultaneously, extraordinary opportunities and drawbacks that even
question fundamental medical concepts. Many of these topics coincide with
urgent priorities recently defined by the World Health Organization for the
coming decade. In addition, we study the transformations of the roles of
doctors and patients in an age of ubiquitous information, identify the risk of
a division of Medicine into 'fake-based', 'patient-generated', and
'scientifically tailored', and draw the attention of some aspects that need
further thorough analysis and public debate.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.05703v1,2020-01-16T09:13:31Z,2020-01-16T09:13:31Z,"A Markerless Deep Learning-based 6 Degrees of Freedom PoseEstimation for
  with Mobile Robots using RGB Data","Augmented Reality has been subject to various integration efforts within
industries due to its ability to enhance human machine interaction and
understanding. Neural networks have achieved remarkable results in areas of
computer vision, which bear great potential to assist and facilitate an
enhanced Augmented Reality experience. However, most neural networks are
computationally intensive and demand huge processing power thus, are not
suitable for deployment on Augmented Reality devices. In this work we propose a
method to deploy state of the art neural networks for real time 3D object
localization on augmented reality devices. As a result, we provide a more
automated method of calibrating the AR devices with mobile robotic systems. To
accelerate the calibration process and enhance user experience, we focus on
fast 2D detection approaches which are extracting the 3D pose of the object
fast and accurately by using only 2D input. The results are implemented into an
Augmented Reality application for intuitive robot control and sensor data
visualization. For the 6D annotation of 2D images, we developed an annotation
tool, which is, to our knowledge, the first open source tool to be available.
We achieve feasible results which are generally applicable to any AR device
thus making this work promising for further research in combining high
demanding neural networks with Internet of Things devices.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.03855v1,2020-01-12T05:25:02Z,2020-01-12T05:25:02Z,"Hyperparameters optimization for Deep Learning based emotion prediction
  for Human Robot Interaction","To enable humanoid robots to share our social space we need to develop
technology for easy interaction with the robots using multiple modes such as
speech, gestures and share our emotions with them. We have targeted this
research towards addressing the core issue of emotion recognition problem which
would require less computation resources and much lesser number of network
hyperparameters which will be more adaptive to be computed on low resourced
social robots for real time communication. More specifically, here we have
proposed an Inception module based Convolutional Neural Network Architecture
which has achieved improved accuracy of upto 6% improvement over the existing
network architecture for emotion classification when combinedly tested over
multiple datasets when tried over humanoid robots in real - time. Our proposed
model is reducing the trainable Hyperparameters to an extent of 94% as compared
to vanilla CNN model which clearly indicates that it can be used in real time
based application such as human robot interaction. Rigorous experiments have
been performed to validate our methodology which is sufficiently robust and
could achieve high level of accuracy. Finally, the model is implemented in a
humanoid robot, NAO in real time and robustness of the model is evaluated.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.02307v1,2020-01-07T22:33:12Z,2020-01-07T22:33:12Z,"Aggressive Perception-Aware Navigation using Deep Optical Flow Dynamics
  and PixelMPC","Recently, vision-based control has gained traction by leveraging the power of
machine learning. In this work, we couple a model predictive control (MPC)
framework to a visual pipeline. We introduce deep optical flow (DOF) dynamics,
which is a combination of optical flow and robot dynamics. Using the DOF
dynamics, MPC explicitly incorporates the predicted movement of relevant pixels
into the planned trajectory of a robot. Our implementation of DOF is
memory-efficient, data-efficient, and computationally cheap so that it can be
computed in real-time for use in an MPC framework. The suggested Pixel Model
Predictive Control (PixelMPC) algorithm controls the robot to accomplish a
high-speed racing task while maintaining visibility of the important features
(gates). This improves the reliability of vision-based estimators for
localization and can eventually lead to safe autonomous flight. The proposed
algorithm is tested in a photorealistic simulation with a high-speed drone
racing task.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.02103v1,2020-01-06T13:13:21Z,2020-01-06T13:13:21Z,Self learning robot using real-time neural networks,"With the advancements in high volume, low precision computational technology
and applied research on cognitive artificially intelligent heuristic systems,
machine learning solutions through neural networks with real-time learning has
seen an immense interest in the research community as well the industry. This
paper involves research, development and experimental analysis of a neural
network implemented on a robot with an arm through which evolves to learn to
walk in a straight line or as required. The neural network learns using the
algorithms of Gradient Descent and Backpropagation. Both the implementation and
training of the neural network is done locally on the robot on a raspberry pi 3
so that its learning process is completely independent. The neural network is
first tested on a custom simulator developed on MATLAB and then implemented on
the raspberry computer. Data at each generation of the evolving network is
stored, and analysis both mathematical and graphical is done on the data.
Impact of factors like the learning rate and error tolerance on the learning
process and final output is analyzed.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.05837v2,2020-02-16T16:56:09Z,2020-01-04T15:58:06Z,"Human Action Recognition and Assessment via Deep Neural Network
  Self-Organization","The robust recognition and assessment of human actions are crucial in
human-robot interaction (HRI) domains. While state-of-the-art models of action
perception show remarkable results in large-scale action datasets, they mostly
lack the flexibility, robustness, and scalability needed to operate in natural
HRI scenarios which require the continuous acquisition of sensory information
as well as the classification or assessment of human body patterns in real
time. In this chapter, I introduce a set of hierarchical models for the
learning and recognition of actions from depth maps and RGB images through the
use of neural network self-organization. A particularity of these models is the
use of growing self-organizing networks that quickly adapt to non-stationary
distributions and implement dedicated mechanisms for continual learning from
temporally correlated input.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.00048v1,2019-12-31T19:41:59Z,2019-12-31T19:41:59Z,"MIR-Vehicle: Cost-Effective Research Platform for Autonomous Vehicle
  Applications","This paper illustrates the MIR (Mobile Intelligent Robotics) Vehicle: a
feasible option of transforming an electric ride-on-car into a modular Graphics
Processing Unit (GPU) powered autonomous platform equipped with the capability
that supports test and deployment of various intelligent autonomous vehicles
algorithms. To use a platform for research, two components must be provided:
perception and control. The sensors such as incremental encoders, an Inertial
Measurement Unit (IMU), a camera, and a LIght Detection And Ranging (LIDAR)
must be able to be installed on the platform to add the capability of
environmental perception. A microcontroller-powered control box is designed to
properly respond to the environmental changes by regulating drive and steering
motors. This drive-by-wire capability is controlled by a GPU powered laptop
computer where high-level perception algorithms are processed and complex
actions are generated by various methods including behavior cloning using deep
neural networks. The main goal of this paper is to provide an adequate and
comprehensive approach for fabricating a cost-effective platform that would
contribute to the research quality from the wider community. The proposed
platform is to use a modular and hierarchical software architecture where the
lower and simpler motor controls are taken care of by microcontroller programs,
and the higher and complex algorithms are processed by a GPU powered laptop
computer. The platform uses the Robot Operating System (ROS) as middleware to
maintain the modularity of the perceptions and decision-making modules. It is
expected that the level three and above autonomous vehicle systems and Advanced
Driver Assistance Systems (ADAS) can be tested on and deployed to the platform
with a decent real-time system behavior due to the capabilities and
affordability of the proposed platform.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.02153v2,2020-05-05T21:49:55Z,2019-12-31T00:29:22Z,Information Theoretic Model Predictive Q-Learning,"Model-free Reinforcement Learning (RL) works well when experience can be
collected cheaply and model-based RL is effective when system dynamics can be
modeled accurately. However, both assumptions can be violated in real world
problems such as robotics, where querying the system can be expensive and
real-world dynamics can be difficult to model. In contrast to RL, Model
Predictive Control (MPC) algorithms use a simulator to optimize a simple policy
class online, constructing a closed-loop controller that can effectively
contend with real-world dynamics. MPC performance is usually limited by factors
such as model bias and the limited horizon of optimization. In this work, we
present a novel theoretical connection between information theoretic MPC and
entropy regularized RL and develop a Q-learning algorithm that can leverage
biased models. We validate the proposed algorithm on sim-to-sim control tasks
to demonstrate the improvements over optimal control and reinforcement learning
from scratch. Our approach paves the way for deploying reinforcement learning
algorithms on real systems in a systematic manner.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.12907v1,2019-12-30T12:39:56Z,2019-12-30T12:39:56Z,Gait Library Synthesis for Quadruped Robots via Augmented Random Search,"In this paper, with a view toward fast deployment of learned locomotion gaits
in low-cost hardware, we generate a library of walking trajectories, namely,
forward trot, backward trot, side-step, and turn in our custom-built quadruped
robot, Stoch 2, using reinforcement learning. There are existing approaches
that determine optimal policies for each time step, whereas we determine an
optimal policy, in the form of end-foot trajectories, for each half walking
step i.e., swing phase and stance phase. The way-points for the foot
trajectories are obtained from a linear policy, i.e., a linear function of the
states of the robot, and cubic splines are used to interpolate between these
points. Augmented Random Search, a model-free and gradient-free learning
algorithm is used to learn the policy in simulation. This learned policy is
then deployed on hardware, yielding a trajectory in every half walking step.
Different locomotion patterns are learned in simulation by enforcing a
preconfigured phase shift between the trajectories of different legs. The
transition from one gait to another is achieved by using a low-pass filter for
the phase, and the sim-to-real transfer is improved by a linear transformation
of the states obtained through regression.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.12555v1,2019-12-29T00:30:59Z,2019-12-29T00:30:59Z,"Visual Perception and Modelling in Unstructured Orchard for Apple
  Harvesting Robots","Vision perception and modelling are the essential tasks of robotic harvesting
in the unstructured orchard. This paper develops a framework of visual
perception and modelling for robotic harvesting of fruits in the orchard
environments. The developed framework includes visual perception, scenarios
mapping, and fruit modelling. The Visual perception module utilises a
deep-learning model to perform multi-purpose visual perception task within the
working scenarios; The scenarios mapping module applies OctoMap to represent
the multiple classes of objects or elements within the environment; The fruit
modelling module estimates the geometry property of objects and estimates the
proper access pose of each fruit. The developed framework is implemented and
evaluated in the apple orchards. The experiment results show that visual
perception and modelling algorithm can accurately detect and localise the
fruits, and modelling working scenarios in real orchard environments. The
$F_{1}$ score and mean intersection of union of visual perception module on
fruit detection and segmentation are 0.833 and 0.852, respectively. The
accuracy of the fruit modelling in terms of centre localisation and pose
estimation are 0.955 and 0.923, respectively. Overall, an accurate visual
perception and modelling algorithm are presented in this paper.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.08324v2,2020-02-17T20:53:30Z,2019-12-18T00:18:17Z,"Analysing Deep Reinforcement Learning Agents Trained with Domain
  Randomisation","Deep reinforcement learning has the potential to train robots to perform
complex tasks in the real world without requiring accurate models of the robot
or its environment. A practical approach is to train agents in simulation, and
then transfer them to the real world. One popular method for achieving
transferability is to use domain randomisation, which involves randomly
perturbing various aspects of a simulated environment in order to make trained
agents robust to the reality gap. However, less work has gone into
understanding such agents - which are deployed in the real world - beyond task
performance. In this work we examine such agents, through qualitative and
quantitative comparisons between agents trained with and without visual domain
randomisation. We train agents for Fetch and Jaco robots on a visuomotor
control task and evaluate how well they generalise using different testing
conditions. Finally, we investigate the internals of the trained agents by
using a suite of interpretability techniques. Our results show that the primary
outcome of domain randomisation is more robust, entangled representations,
accompanied with larger weights with greater spatial structure; moreover, the
types of changes are heavily influenced by the task setup and presence of
additional proprioceptive inputs. Additionally, we demonstrate that our domain
randomised agents require higher sample complexity, can overfit and more
heavily rely on recurrent processing. Furthermore, even with an improved
saliency method introduced in this work, we show that qualitative studies may
not always correspond with quantitative measures, necessitating the combination
of inspection tools in order to provide sufficient insights into the behaviour
of trained agents.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.08116v1,2019-12-17T16:18:32Z,2019-12-17T16:18:32Z,When Your Robot Breaks: Active Learning During Plant Failure,"Detecting and adapting to catastrophic failures in robotic systems requires a
robot to learn its new dynamics quickly and safely to best accomplish its
goals. To address this challenging problem, we propose probabilistically-safe,
online learning techniques to infer the altered dynamics of a robot at the
moment a failure (e.g., physical damage) occurs. We combine model predictive
control and active learning within a chance-constrained optimization framework
to safely and efficiently learn the new plant model of the robot. We leverage a
neural network for function approximation in learning the latent dynamics of
the robot under failure conditions. Our framework generalizes to various damage
conditions while being computationally light-weight to advance real-time
deployment. We empirically validate within a virtual environment that we can
regain control of a severely damaged aircraft in seconds and require only 0.1
seconds to find safe, information-rich trajectories, outperforming
state-of-the-art approaches.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.07067v1,2019-12-15T16:33:16Z,2019-12-15T16:33:16Z,"Aggressive Online Control of a Quadrotor via Deep Network
  Representations of Optimality Principles","Optimal control holds great potential to improve a variety of robotic
applications. The application of optimal control on-board limited platforms has
been severely hindered by the large computational requirements of current state
of the art implementations. In this work, we make use of a deep neural network
to directly map the robot states to control actions. The network is trained
offline to imitate the optimal control computed by a time consuming direct
nonlinear method. A mixture of time optimality and power optimality is
considered with a continuation parameter used to select the predominance of
each objective. We apply our networks (termed G\&CNets) to aggressive quadrotor
control, first in simulation and then in the real world. We give insight into
the factors that influence the `reality gap' between the quadrotor model used
by the offline optimal control method and the real quadrotor. Furthermore, we
explain how we set up the model and the control structure on-board of the real
quadrotor to successfully close this gap and perform time-optimal maneuvers in
the real world. Finally, G\&CNet's performance is compared to state-of-the-art
differential-flatness-based optimal control methods. We show, in the
experiments, that G\&CNets lead to significantly faster trajectory execution
due to, in part, the less restrictive nature of the allowed state-to-input
mappings.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.06449v1,2019-12-13T12:57:33Z,2019-12-13T12:57:33Z,"Solving Visual Object Ambiguities when Pointing: An Unsupervised
  Learning Approach","Whenever we are addressing a specific object or refer to a certain spatial
location, we are using referential or deictic gestures usually accompanied by
some verbal description. Especially pointing gestures are necessary to dissolve
ambiguities in a scene and they are of crucial importance when verbal
communication may fail due to environmental conditions or when two persons
simply do not speak the same language. With the currently increasing advances
of humanoid robots and their future integration in domestic domains, the
development of gesture interfaces complementing human-robot interaction
scenarios is of substantial interest. The implementation of an intuitive
gesture scenario is still challenging because both the pointing intention and
the corresponding object have to be correctly recognized in real-time. The
demand increases when considering pointing gestures in a cluttered environment,
as is the case in households. Also, humans perform pointing in many different
ways and those variations have to be captured. Research in this field often
proposes a set of geometrical computations which do not scale well with the
number of gestures and objects, use specific markers or a predefined set of
pointing directions. In this paper, we propose an unsupervised learning
approach to model the distribution of pointing gestures using a
growing-when-required (GWR) network. We introduce an interaction scenario with
a humanoid robot and define so-called ambiguity classes. Our implementation for
the hand and object detection is independent of any markers or skeleton models,
thus it can be easily reproduced. Our evaluation comparing a baseline computer
vision approach with our GWR model shows that the pointing-object association
is well learned even in cases of ambiguities resulting from close object
proximity.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.06321v2,2020-08-17T03:26:55Z,2019-12-13T04:29:38Z,"Sim2Real Predictivity: Does Evaluation in Simulation Predict Real-World
  Performance?","Does progress in simulation translate to progress on robots? If one method
outperforms another in simulation, how likely is that trend to hold in reality
on a robot? We examine this question for embodied PointGoal navigation,
developing engineering tools and a research paradigm for evaluating a simulator
by its sim2real predictivity. First, we develop Habitat-PyRobot Bridge (HaPy),
a library for seamless execution of identical code on simulated agents and
robots, transferring simulation-trained agents to a LoCoBot platform with a
one-line code change. Second, we investigate the sim2real predictivity of
Habitat-Sim for PointGoal navigation. We 3D-scan a physical lab space to create
a virtualized replica, and run parallel tests of 9 different models in reality
and simulation. We present a new metric called Sim-vs-Real Correlation
Coefficient (SRCC) to quantify predictivity. We find that SRCC for Habitat as
used for the CVPR19 challenge is low (0.18 for the success metric), suggesting
that performance differences in this simulator-based challenge do not persist
after physical deployment. This gap is largely due to AI agents learning to
exploit simulator imperfections, abusing collision dynamics to 'slide' along
walls, leading to shortcuts through otherwise non-navigable space. Naturally,
such exploits do not work in the real world. Our experiments show that it is
possible to tune simulation parameters to improve sim2real predictivity (e.g.
improving $SRCC_{Succ}$ from 0.18 to 0.844), increasing confidence that
in-simulation comparisons will translate to deployed systems in reality.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.02059v2,2020-06-28T20:20:33Z,2019-12-04T15:32:53Z,"Learning to Dynamically Coordinate Multi-Robot Teams in Graph Attention
  Networks","Increasing interest in integrating advanced robotics within manufacturing has
spurred a renewed concentration in developing real-time scheduling solutions to
coordinate human-robot collaboration in this environment. Traditionally, the
problem of scheduling agents to complete tasks with temporal and spatial
constraints has been approached either with exact algorithms, which are
computationally intractable for large-scale, dynamic coordination, or
approximate methods that require domain experts to craft heuristics for each
application. We seek to overcome the limitations of these conventional methods
by developing a novel graph attention network formulation to automatically
learn features of scheduling problems to allow their deployment. To learn
effective policies for combinatorial optimization problems via machine
learning, we combine imitation learning on smaller problems with deep
Q-learning on larger problems, in a non-parametric framework, to allow for
fast, near-optimal scheduling of robot teams. We show that our network-based
policy finds at least twice as many solutions over prior state-of-the-art
methods in all testing scenarios.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.01100v2,2020-03-04T09:50:32Z,2019-12-02T22:16:32Z,Latent Replay for Real-Time Continual Learning,"Training deep neural networks at the edge on light computational devices,
embedded systems and robotic platforms is nowadays very challenging. Continual
learning techniques, where complex models are incrementally trained on small
batches of new data, can make the learning problem tractable even for CPU-only
embedded devices enabling remarkable levels of adaptiveness and autonomy.
However, a number of practical problems need to be solved: catastrophic
forgetting before anything else. In this paper we introduce an original
technique named ""Latent Replay"" where, instead of storing a portion of past
data in the input space, we store activations volumes at some intermediate
layer. This can significantly reduce the computation and storage required by
native rehearsal. To keep the representation stable and the stored activations
valid we propose to slow-down learning at all the layers below the latent
replay one, leaving the layers above free to learn at full pace. In our
experiments we show that Latent Replay, combined with existing continual
learning techniques, achieves state-of-the-art performance on complex video
benchmarks such as CORe50 NICv2 (with nearly 400 small and highly non-i.i.d.
batches) and OpenLORIS. Finally, we demonstrate the feasibility of nearly
real-time continual learning on the edge through the deployment of the proposed
technique on a smartphone device.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1912.01715v1,2019-12-02T12:07:23Z,2019-12-02T12:07:23Z,"Human-Robot Collaboration via Deep Reinforcement Learning of Real-World
  Interactions","We present a robotic setup for real-world testing and evaluation of
human-robot and human-human collaborative learning. Leveraging the
sample-efficiency of the Soft Actor-Critic algorithm, we have implemented a
robotic platform able to learn a non-trivial collaborative task with a human
partner, without pre-training in simulation, and using only 30 minutes of
real-world interactions. This enables us to study Human-Robot and Human-Human
collaborative learning through real-world interactions. We present preliminary
results, showing that state-of-the-art deep learning methods can take
human-robot collaborative learning a step closer to that of humans interacting
with each other.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.10290v1,2019-11-23T01:11:29Z,2019-11-23T01:11:29Z,Scalable sim-to-real transfer of soft robot designs,"The manual design of soft robots and their controllers is notoriously
challenging, but it could be augmented---or, in some cases, entirely
replaced---by automated design tools. Machine learning algorithms can
automatically propose, test, and refine designs in simulation, and the most
promising ones can then be manufactured in reality (sim2real). However, it is
currently not known how to guarantee that behavior generated in simulation can
be preserved when deployed in reality. Although many previous studies have
devised training protocols that facilitate sim2real transfer of control
polices, little to no work has investigated the simulation-reality gap as a
function of morphology. This is due in part to an overall lack of tools capable
of systematically designing and rapidly manufacturing robots. Here we introduce
a low cost, open source, and modular soft robot design and construction kit,
and use it to simulate, fabricate, and measure the simulation-reality gap of
minimally complex yet soft, locomoting machines. We prove the scalability of
this approach by transferring an order of magnitude more robot designs from
simulation to reality than any other method. The kit and its instructions can
be found here: https://github.com/skriegman/sim2real4designs",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.07919v1,2019-11-15T18:44:25Z,2019-11-15T18:44:25Z,ASV: Accelerated Stereo Vision System,"Estimating depth from stereo vision cameras, i.e., ""depth from stereo"", is
critical to emerging intelligent applications deployed in energy- and
performance-constrained devices, such as augmented reality headsets and mobile
autonomous robots. While existing stereo vision systems make trade-offs between
accuracy, performance and energy-efficiency, we describe ASV, an accelerated
stereo vision system that simultaneously improves both performance and
energy-efficiency while achieving high accuracy. The key to ASV is to exploit
unique characteristics inherent to stereo vision, and apply stereo-specific
optimizations, both algorithmically and computationally. We make two
contributions. Firstly, we propose a new stereo algorithm, invariant-based
stereo matching (ISM), that achieves significant speedup while retaining high
accuracy. The algorithm combines classic ""hand-crafted"" stereo algorithms with
recent developments in Deep Neural Networks (DNNs), by leveraging the
correspondence invariant unique to stereo vision systems. Secondly, we observe
that the bottleneck of the ISM algorithm is the DNN inference, and in
particular the deconvolution operations that introduce massive
compute-inefficiencies. We propose a set of software optimizations that
mitigate these inefficiencies. We show that with less than 0.5% hardware area
overhead, these algorithmic and computational optimizations can be effectively
integrated within a conventional DNN accelerator. Overall, ASV achieves 5x
speedup and 85% energy saving with 0.02% accuracy loss compared to today
DNN-based stereo vision systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.06636v2,2020-06-16T09:13:58Z,2019-11-15T13:57:35Z,"Catch & Carry: Reusable Neural Controllers for Vision-Guided Whole-Body
  Tasks","We address the longstanding challenge of producing flexible, realistic
humanoid character controllers that can perform diverse whole-body tasks
involving object interactions. This challenge is central to a variety of
fields, from graphics and animation to robotics and motor neuroscience. Our
physics-based environment uses realistic actuation and first-person perception
-- including touch sensors and egocentric vision -- with a view to producing
active-sensing behaviors (e.g. gaze direction), transferability to real robots,
and comparisons to the biology. We develop an integrated neural-network based
approach consisting of a motor primitive module, human demonstrations, and an
instructed reinforcement learning regime with curricula and task variations. We
demonstrate the utility of our approach for several tasks, including
goal-conditioned box carrying and ball catching, and we characterize its
behavioral robustness. The resulting controllers can be deployed in real-time
on a standard PC. See overview video, https://youtu.be/2rQAW-8gQQk .",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.03848v1,2019-11-10T04:36:59Z,2019-11-10T04:36:59Z,Embedded Neural Networks for Robot Autonomy,"We present a library to automatically embed signal processing and neural
network predictions into the material robots are made of. Deep and shallow
neural network models are first trained offline using state-of-the-art machine
learning tools and then transferred onto general purpose microcontrollers that
are co-located with a robot's sensors and actuators. We validate this approach
using multiple examples: a smart robotic tire for terrain classification, a
robotic finger sensor for load classification and a smart composite capable of
regressing impact source localization. In each example, sensing and computation
are embedded inside the material, creating artifacts that serve as stand-in
replacement for otherwise inert conventional parts. The open source software
library takes as inputs trained model files from higher level learning
software, such as Tensorflow/Keras, and outputs code that is readable in a
microcontroller that supports C. We compare the performance of this approach
for various embedded platforms. In particular, we show that low-cost
off-the-shelf microcontrollers can match the accuracy of a desktop computer,
while being fast enough for real-time applications at different neural network
configurations. We provide means to estimate the maximum number of parameters
that the hardware will support based on the microcontroller's specifications.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.01715v2,2019-12-02T08:23:41Z,2019-11-05T11:19:58Z,"Gym-Ignition: Reproducible Robotic Simulations for Reinforcement
  Learning","This paper presents Gym-Ignition, a new framework to create reproducible
robotic environments for reinforcement learning research. It interfaces with
the new generation of Gazebo, part of the Ignition Robotics suite, which
provides three main improvements for reinforcement learning applications
compared to the alternatives: 1) the modular architecture enables using the
simulator as a C++ library, simplifying the interconnection with external
software; 2) multiple physics and rendering engines are supported as plugins,
simplifying their selection during the execution; 3) the new distributed
simulation capability allows simulating complex scenarios while sharing the
load on multiple workers and machines. The core of Gym-Ignition is a component
that contains the Ignition Gazebo simulator and exposes a simple interface for
its configuration and execution. We provide a Python package that allows
developers to create robotic environments simulated in Ignition Gazebo.
Environments expose the common OpenAI Gym interface, making them compatible
out-of-the-box with third-party frameworks containing reinforcement learning
algorithms. Simulations can be executed in both headless and GUI mode, the
physics engine can run in accelerated mode, and instances can be parallelized.
Furthermore, the Gym-Ignition software architecture provides abstraction of the
Robot and the Task, making environments agnostic on the specific runtime. This
abstraction allows their execution also in a real-time setting on actual
robotic platforms, even if driven by different middlewares.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1911.01562v1,2019-11-05T01:40:42Z,2019-11-05T01:40:42Z,"DeepRacer: Educational Autonomous Racing Platform for Experimentation
  with Sim2Real Reinforcement Learning","DeepRacer is a platform for end-to-end experimentation with RL and can be
used to systematically investigate the key challenges in developing intelligent
control systems. Using the platform, we demonstrate how a 1/18th scale car can
learn to drive autonomously using RL with a monocular camera. It is trained in
simulation with no additional tuning in physical world and demonstrates: 1)
formulation and solution of a robust reinforcement learning algorithm, 2)
narrowing the reality gap through joint perception and dynamics, 3) distributed
on-demand compute architecture for training optimal policies, and 4) a robust
evaluation method to identify when to stop training. It is the first successful
large-scale deployment of deep reinforcement learning on a robotic control
agent that uses only raw camera images as observations and a model-free
learning method to perform robust path planning. We open source our code and
video demo on GitHub: https://git.io/fjxoJ.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.14540v1,2019-10-31T15:36:34Z,2019-10-31T15:36:34Z,"Team NCTU: Toward AI-Driving for Autonomous Surface Vehicles -- From
  Duckietown to RobotX","Robotic software and hardware systems of autonomous surface vehicles have
been developed in transportation, military, and ocean researches for decades.
Previous efforts in RobotX Challenges 2014 and 2016 facilitates the
developments for important tasks such as obstacle avoidance and docking. Team
NCTU is motivated by the AI Driving Olympics (AI-DO) developed by the
Duckietown community, and adopts the principles to RobotX challenge. With the
containerization (Docker) and uniformed AI agent (with observations and
actions), we could better 1) integrate solutions developed in different
middlewares (ROS and MOOS), 2) develop essential functionalities of from
simulation (Gazebo) to real robots (either miniaturized or full-sized WAM-V),
and 3) compare different approaches either from classic model-based or
learning-based. Finally, we setup an outdoor on-surface platform with
localization services for evaluation. Some of the preliminary results will be
presented for the Team NCTU participations of the RobotX competition in Hawaii
in 2018.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.13676v1,2019-10-30T05:13:33Z,2019-10-30T05:13:33Z,Multi Modal Semantic Segmentation using Synthetic Data,"Semantic understanding of scenes in three-dimensional space (3D) is a
quintessential part of robotics oriented applications such as autonomous
driving as it provides geometric cues such as size, orientation and true
distance of separation to objects which are crucial for taking mission critical
decisions. As a first step, in this work we investigate the possibility of
semantically classifying different parts of a given scene in 3D by learning the
underlying geometric context in addition to the texture cues BUT in the absence
of labelled real-world datasets. To this end we generate a large number of
synthetic scenes, their pixel-wise labels and corresponding 3D representations
using CARLA software framework. We then build a deep neural network that learns
underlying category specific 3D representation and texture cues from color
information of the rendered synthetic scenes. Further on we apply the learned
model on different real world datasets to evaluate its performance. Our
preliminary investigation of results show that the neural network is able to
learn the geometric context from synthetic scenes and effectively apply this
knowledge to classify each point of a 3D representation of a scene in
real-world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.12750v1,2019-10-28T15:21:48Z,2019-10-28T15:21:48Z,"Deep-Learning-Based Image Segmentation Integrated with Optical
  Microscopy for Automatically Searching for Two-Dimensional Materials","Deep-learning algorithms enable precise image recognition based on
high-dimensional hierarchical image features. Here, we report the development
and implementation of a deep-learning-based image segmentation algorithm in an
autonomous robotic system to search for two-dimensional (2D) materials. We
trained the neural network based on Mask-RCNN on annotated optical microscope
images of 2D materials (graphene, hBN, MoS2, and WTe2). The inference algorithm
is run on a 1024 x 1024 px2 optical microscope images for 200 ms, enabling the
real-time detection of 2D materials. The detection process is robust against
changes in the microscopy conditions, such as illumination and color balance,
which obviates the parameter-tuning process required for conventional
rule-based detection algorithms. Integrating the algorithm with a motorized
optical microscope enables the automated searching and cataloging of 2D
materials. This development will allow researchers to utilize unlimited amounts
of 2D materials simply by exfoliating and running the automated searching
process.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.11109v3,2020-09-13T14:55:16Z,2019-10-24T13:48:52Z,"Attention-Guided Lightweight Network for Real-Time Segmentation of
  Robotic Surgical Instruments","The real-time segmentation of surgical instruments plays a crucial role in
robot-assisted surgery. However, it is still a challenging task to implement
deep learning models to do real-time segmentation for surgical instruments due
to their high computational costs and slow inference speed. In this paper, we
propose an attention-guided lightweight network (LWANet), which can segment
surgical instruments in real-time. LWANet adopts encoder-decoder architecture,
where the encoder is the lightweight network MobileNetV2, and the decoder
consists of depthwise separable convolution, attention fusion block, and
transposed convolution. Depthwise separable convolution is used as the basic
unit to construct the decoder, which can reduce the model size and
computational costs. Attention fusion block captures global contexts and
encodes semantic dependencies between channels to emphasize target regions,
contributing to locating the surgical instrument. Transposed convolution is
performed to upsample feature maps for acquiring refined edges. LWANet can
segment surgical instruments in real-time while takes little computational
costs. Based on 960*544 inputs, its inference speed can reach 39 fps with only
3.39 GFLOPs. Also, it has a small model size and the number of parameters is
only 2.06 M. The proposed network is evaluated on two datasets. It achieves
state-of-the-art performance 94.10% mean IOU on Cata7 and obtains a new record
on EndoVis 2017 with a 4.10% increase on mean IOU.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/2001.09938v1,2019-10-22T15:57:20Z,2019-10-22T15:57:20Z,"Autonomous discovery of battery electrolytes with robotic
  experimentation and machine-learning","Innovations in batteries take years to formulate and commercialize, requiring
extensive experimentation during the design and optimization phases. We
approached the design and selection of a battery electrolyte through a
black-box optimization algorithm directly integrated into a robotic test-stand.
We report here the discovery of a novel battery electrolyte by this experiment
completely guided by the machine-learning software without human intervention.
Motivated by the recent trend toward super-concentrated aqueous electrolytes
for high-performance batteries, we utilize Dragonfly - a Bayesian
machine-learning software package - to search mixtures of commonly used lithium
and sodium salts for super-concentrated aqueous electrolytes with wide
electrochemical stability windows. Dragonfly autonomously managed the robotic
test-stand, recommending electrolyte designs to test and receiving experimental
feedback in real time. In 40 hours of continuous experimentation over a
four-dimensional design space with millions of potential candidates, Dragonfly
discovered a novel, mixed-anion aqueous sodium electrolyte with a wider
electrochemical stability window than state-of-the-art sodium electrolyte. A
human-guided design process may have missed this optimal electrolyte. This
result demonstrates the possibility of integrating robotics with
machine-learning to rapidly and autonomously discover novel battery materials.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.09998v3,2020-06-03T07:15:15Z,2019-10-22T14:15:20Z,Learning Resilient Behaviors for Navigation Under Uncertainty,"Deep reinforcement learning has great potential to acquire complex, adaptive
behaviors for autonomous agents automatically. However, the underlying neural
network polices have not been widely deployed in real-world applications,
especially in these safety-critical tasks (e.g., autonomous driving). One of
the reasons is that the learned policy cannot perform flexible and resilient
behaviors as traditional methods to adapt to diverse environments. In this
paper, we consider the problem that a mobile robot learns adaptive and
resilient behaviors for navigating in unseen uncertain environments while
avoiding collisions. We present a novel approach for uncertainty-aware
navigation by introducing an uncertainty-aware predictor to model the
environmental uncertainty, and we propose a novel uncertainty-aware navigation
network to learn resilient behaviors in the prior unknown environments. To
train the proposed uncertainty-aware network more stably and efficiently, we
present the temperature decay training paradigm, which balances exploration and
exploitation during the training process. Our experimental evaluation
demonstrates that our approach can learn resilient behaviors in diverse
environments and generate adaptive trajectories according to environmental
uncertainties.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.09667v1,2019-10-21T21:44:15Z,2019-10-21T21:44:15Z,"Combining Benefits from Trajectory Optimization and Deep Reinforcement
  Learning","Recent breakthroughs both in reinforcement learning and trajectory
optimization have made significant advances towards real world robotic system
deployment. Reinforcement learning (RL) can be applied to many problems without
needing any modeling or intuition about the system, at the cost of high sample
complexity and the inability to prove any metrics about the learned policies.
Trajectory optimization (TO) on the other hand allows for stability and
robustness analyses on generated motions and trajectories, but is only as good
as the often over-simplified derived model, and may have prohibitively
expensive computation times for real-time control. This paper seeks to combine
the benefits from these two areas while mitigating their drawbacks by (1)
decreasing RL sample complexity by using existing knowledge of the problem with
optimal control, and (2) providing an upper bound estimate on the
time-to-arrival of the combined learned-optimized policy, allowing online
policy deployment at any point in the training process by using the TO as a
worst-case scenario action. This method is evaluated for a car model, with
applicability to any mobile robotic system. A video showing policy execution
comparisons can be found at https://youtu.be/mv2xw83NyWU .",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.04335v2,2020-03-02T10:24:13Z,2019-10-10T02:34:34Z,"CityLearn: Diverse Real-World Environments for Sample-Efficient
  Navigation Policy Learning","Visual navigation tasks in real-world environments often require both
self-motion and place recognition feedback. While deep reinforcement learning
has shown success in solving these perception and decision-making problems in
an end-to-end manner, these algorithms require large amounts of experience to
learn navigation policies from high-dimensional data, which is generally
impractical for real robots due to sample complexity. In this paper, we address
these problems with two main contributions. We first leverage place recognition
and deep learning techniques combined with goal destination feedback to
generate compact, bimodal image representations that can then be used to
effectively learn control policies from a small amount of experience. Second,
we present an interactive framework, CityLearn, that enables for the first time
training and deployment of navigation algorithms across city-sized, realistic
environments with extreme visual appearance changes. CityLearn features more
than 10 benchmark datasets, often used in visual place recognition and
autonomous driving research, including over 100 recorded traversals across 60
cities around the world. We evaluate our approach on two CityLearn
environments, training our navigation policy on a single traversal. Results
show our method can be over 2 orders of magnitude faster than when using raw
images, and can also generalize across extreme visual changes including day to
night and summer to winter transitions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1910.02078v4,2020-08-13T12:21:07Z,2019-10-04T16:43:06Z,"I'm sorry Dave, I'm afraid I can't do that, Deep Q-learning from
  forbidden action","The use of Reinforcement Learning (RL) is still restricted to simulation or
to enhance human-operated systems through recommendations. Real-world
environments (e.g. industrial robots or power grids) are generally designed
with safety constraints in mind implemented in the shape of valid actions masks
or contingency controllers. For example, the range of motion and the angles of
the motors of a robot can be limited to physical boundaries. Violating
constraints thus results in rejected actions or entering in a safe mode driven
by an external controller, making RL agents incapable of learning from their
mistakes. In this paper, we propose a simple modification of a state-of-the-art
deep RL algorithm (DQN), enabling learning from forbidden actions. To do so,
the standard Q-learning update is enhanced with an extra safety loss inspired
by structured classification. We empirically show that it reduces the number of
hit constraints during the learning phase and accelerates convergence to
near-optimal policies compared to using standard DQN. Experiments are done on a
Visual Grid World Environment and Text-World domain.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.13875v2,2019-11-18T12:58:34Z,2019-09-30T17:56:24Z,"Expressive Inverse Kinematics Solving in Real-time for Virtual and
  Robotic Interactive Characters","With new advancements in interaction techniques, character animation also
requires new methods, to support fields such as robotics, and VR/AR.
Interactive characters in such fields are becoming driven by AI which opens up
the possibility of non-linear and open-ended narratives that may even include
interaction with the real, physical world. This paper presents and describes
ERIK, an expressive inverse kinematics technique aimed at such applications.
Our technique allows an arbitrary kinematic chain, such as an arm, snake, or
robotic manipulator, to exhibit an expressive posture while aiming its
end-point towards a given target orientation. The technique runs in
interactive-time and does not require any pre-processing step such as e.g.
training in machine learning techniques, in order to support new embodiments or
new postures. That allows it to be integrated in an artist-friendly workflow,
bringing artists closer to the development of such AI-driven expressive
characters, by allowing them to use their typical animation tools of choice,
and to properly pre-visualize the animation during design-time, even on a real
robot. The full algorithmic specification is presented and described so that it
can be implemented and used throughout the communities of the various fields we
address. We demonstrate ERIK on different virtual kinematic structures, and
also on a low-fidelity robot that was crafted using wood and hobby-grade
servos, to show how well the technique performs even on a low-grade robot. Our
evaluation shows how well the technique performs, i.e., how well the character
is able to point at the target orientation, while minimally disrupting its
target expressive posture, and respecting its mechanical rotation limits.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.12217v4,2021-01-25T21:19:51Z,2019-09-26T16:15:37Z,"Visual Exploration and Energy-aware Path Planning via Reinforcement
  Learning","Visual exploration and smart data collection via autonomous vehicles is an
attractive topic in various disciplines. Disturbances like wind significantly
influence both the power consumption of the flying robots and the performance
of the camera. We propose a reinforcement learning approach which combines the
effects of the power consumption and the object detection modules to develop a
policy for object detection in large areas with limited battery life. The
learning model enables dynamic learning of the negative rewards of each action
based on the drag forces that is resulted by the motion of the flying robot
with respect to the wind field. The algorithm is implemented in a near-real
world simulation environment both for the planar motion and flight in different
altitudes. The trained agent often performed a trade-off between detecting the
objects with high accuracy and increasing the area coverage within its battery
life. The developed exploration policy outperformed the complete coverage
algorithm by minimizing the traveled path while finding the target objects. The
performance of the algorithms under various wind fields was evaluated in planar
and 3D motion. During an exploration task with sparsely distributed goals and
within a UAV's battery life, the proposed architecture could detect more than
twice the amount of goal objects compared to the coverage path planning
algorithm in moderate wind field. In high wind intensities, the energy-aware
algorithm could detect 4 times the amount of goal objects when compared to its
complete coverage counterpart.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.10972v2,2020-03-11T05:46:37Z,2019-09-24T14:55:00Z,"Residual Reactive Navigation: Combining Classical and Learned Navigation
  Strategies For Deployment in Unknown Environments","In this work we focus on improving the efficiency and generalisation of
learned navigation strategies when transferred from its training environment to
previously unseen ones. We present an extension of the residual reinforcement
learning framework from the robotic manipulation literature and adapt it to the
vast and unstructured environments that mobile robots can operate in. The
concept is based on learning a residual control effect to add to a typical
sub-optimal classical controller in order to close the performance gap, whilst
guiding the exploration process during training for improved data efficiency.
We exploit this tight coupling and propose a novel deployment strategy,
switching Residual Reactive Navigation (sRRN), which yields efficient
trajectories whilst probabilistically switching to a classical controller in
cases of high policy uncertainty. Our approach achieves improved performance
over end-to-end alternatives and can be incorporated as part of a complete
navigation stack for cluttered indoor navigation tasks in the real world. The
code and training environment for this project is made publicly available at
https://sites.google.com/view/srrn/home.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.10707v6,2020-07-05T03:19:06Z,2019-09-24T04:34:58Z,"Invariant Transform Experience Replay: Data Augmentation for Deep
  Reinforcement Learning","Deep Reinforcement Learning (RL) is a promising approach for adaptive robot
control, but its current application to robotics is currently hindered by high
sample requirements. To alleviate this issue, we propose to exploit the
symmetries present in robotic tasks. Intuitively, symmetries from observed
trajectories define transformations that leave the space of feasible RL
trajectories invariant and can be used to generate new feasible trajectories,
which could be used for training. Based on this data augmentation idea, we
formulate a general framework, called Invariant Transform Experience Replay
that we present with two techniques: (i) Kaleidoscope Experience Replay
exploits reflectional symmetries and (ii) Goal-augmented Experience Replay
which takes advantage of lax goal definitions. In the Fetch tasks from OpenAI
Gym, our experimental results show significant increases in learning rates and
success rates. Particularly, we attain a 13, 3, and 5 times speedup in the
pushing, sliding, and pick-and-place tasks respectively in the multi-goal
setting. Performance gains are also observed in similar tasks with obstacles
and we successfully deployed a trained policy on a real Baxter robot. Our work
demonstrates that invariant transformations on RL trajectories are a promising
methodology to speed up learning in deep RL.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.12906v1,2019-09-16T11:59:40Z,2019-09-16T11:59:40Z,Meta Reinforcement Learning for Sim-to-real Domain Adaptation,"Modern reinforcement learning methods suffer from low sample efficiency and
unsafe exploration, making it infeasible to train robotic policies entirely on
real hardware. In this work, we propose to address the problem of sim-to-real
domain transfer by using meta learning to train a policy that can adapt to a
variety of dynamic conditions, and using a task-specific trajectory generation
model to provide an action space that facilitates quick exploration. We
evaluate the method by performing domain adaptation in simulation and analyzing
the structure of the latent space during adaptation. We then deploy this policy
on a KUKA LBR 4+ robot and evaluate its performance on a task of hitting a
hockey puck to a target. Our method shows more consistent and stable domain
adaptation than the baseline, resulting in better overall performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.06491v2,2020-08-18T23:38:30Z,2019-09-14T00:13:05Z,Selfie Drone Stick: A Natural Interface for Quadcopter Photography,"A physical selfie stick extends the user's reach, enabling the acquisition of
personal photos that include more of the background scene. Similarly, a
quadcopter can capture photos from vantage points unattainable by the user; but
teleoperating a quadcopter to good viewpoints is a difficult task. This paper
presents a natural interface for quadcopter photography, the SelfieDroneStick
that allows the user to guide the quadcopter to the optimal vantage point based
on the phone's sensors. Users specify the composition of their desired
long-range selfies using their smartphone, and the quadcopter autonomously
flies to a sequence of vantage points from where the desired shots can be
taken. The robot controller is trained from a combination of real-world images
and simulated flight data. This paper describes two key innovations required to
deploy deep reinforcement learning models on a real robot: 1) an abstract state
representation for transferring learning from simulation to the hardware
platform, and 2) reward shaping and staging paradigms for training the
controller. Both of these improvements were found to be essential in learning a
robot controller from simulation that transfers successfully to the real robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.04812v2,2019-09-19T14:29:10Z,2019-09-11T01:49:14Z,Proceedings of the AI-HRI Symposium at AAAI-FSS 2019,"The past few years have seen rapid progress in the development of service
robots. Universities and companies alike have launched major research efforts
toward the deployment of ambitious systems designed to aid human operators
performing a variety of tasks. These robots are intended to make those who may
otherwise need to live in assisted care facilities more independent, to help
workers perform their jobs, or simply to make life more convenient. Service
robots provide a powerful platform on which to study Artificial Intelligence
(AI) and Human-Robot Interaction (HRI) in the real world. Research sitting at
the intersection of AI and HRI is crucial to the success of service robots if
they are to fulfill their mission.
  This symposium seeks to highlight research enabling robots to effectively
interact with people autonomously while modeling, planning, and reasoning about
the environment that the robot operates in and the tasks that it must perform.
AI-HRI deals with the challenge of interacting with humans in environments that
are relatively unstructured or which are structured around people rather than
machines, as well as the possibility that the robot may need to interact
naturally with people rather than through teach pendants, programming, or
similar interfaces.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1909.02129v1,2019-09-04T21:50:03Z,2019-09-04T21:50:03Z,"Towards Precise Robotic Grasping by Probabilistic Post-grasp
  Displacement Estimation","Precise robotic grasping is important for many industrial applications, such
as assembly and palletizing, where the location of the object needs to be
controlled and known. However, achieving precise grasps is challenging due to
noise in sensing and control, as well as unknown object properties. We propose
a method to plan robotic grasps that are both robust and precise by training
two convolutional neural networks - one to predict the robustness of a grasp
and another to predict a distribution of post-grasp object displacements. Our
networks are trained with depth images in simulation on a dataset of over 1000
industrial parts and were successfully deployed on a real robot without having
to be further fine-tuned. The proposed displacement estimator achieves a mean
prediction errors of 0.68cm and 3.42deg on novel objects in real world
experiments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.10398v1,2019-08-27T18:30:49Z,2019-08-27T18:30:49Z,"A Data-Efficient Deep Learning Approach for Deployable Multimodal Social
  Robots","The deep supervised and reinforcement learning paradigms (among others) have
the potential to endow interactive multimodal social robots with the ability of
acquiring skills autonomously. But it is still not very clear yet how they can
be best deployed in real world applications. As a step in this direction, we
propose a deep learning-based approach for efficiently training a humanoid
robot to play multimodal games---and use the game of `Noughts & Crosses' with
two variants as a case study. Its minimum requirements for learning to perceive
and interact are based on a few hundred example images, a few example
multimodal dialogues and physical demonstrations of robot manipulation, and
automatic simulations. In addition, we propose novel algorithms for robust
visual game tracking and for competitive policy learning with high winning
rates, which substantially outperform DQN-based baselines. While an automatic
evaluation shows evidence that the proposed approach can be easily extended to
new games with competitive robot behaviours, a human evaluation with 130 humans
playing with the Pepper robot confirms that highly accurate visual perception
is required for successful game play.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.06422v1,2019-08-18T11:17:19Z,2019-08-18T11:17:19Z,"Scene Classification in Indoor Environments for Robots using Context
  Based Word Embeddings","Scene Classification has been addressed with numerous techniques in computer
vision literature. However, with the increasing number of scene classes in
datasets in the field, it has become difficult to achieve high accuracy in the
context of robotics. In this paper, we implement an approach which combines
traditional deep learning techniques with natural language processing methods
to generate a word embedding based Scene Classification algorithm. We use the
key idea that context (objects in the scene) of an image should be
representative of the scene label meaning a group of objects could assist to
predict the scene class. Objects present in the scene are represented by
vectors and the images are re-classified based on the objects present in the
scene to refine the initial classification by a Convolutional Neural Network
(CNN). In our approach we address indoor Scene Classification task using a
model trained with a reduced pre-processed version of the Places365 dataset and
an empirical analysis is done on a real-world dataset that we built by
capturing image sequences using a GoPro camera. We also report results obtained
on a subset of the Places365 dataset using our approach and additionally show a
deployment of our approach on a robot operating in a real-world environment.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.03057v2,2019-08-09T15:37:31Z,2019-08-08T13:25:00Z,"Sim-to-Real Learning for Casualty Detection from Ground Projected Point
  Cloud Data","This paper addresses the problem of human body detection---particularly a
human body lying on the ground (a.k.a. casualty)---using point cloud data. This
ability to detect a casualty is one of the most important features of mobile
rescue robots, in order for them to be able to operate autonomously. We propose
a deep-learning-based casualty detection method using a deep convolutional
neural network (CNN). This network is trained to be able to detect a casualty
using a point-cloud data input. In the method we propose, the point cloud input
is pre-processed to generate a depth image-like ground-projected heightmap.
This heightmap is generated based on the projected distance of each point onto
the detected ground plane within the point cloud data. The generated heightmap
-- in image form -- is then used as an input for the CNN to detect a human body
lying on the ground. To train the neural network, we propose a novel
sim-to-real approach, in which the network model is trained using synthetic
data obtained in simulation and then tested on real sensor data. To make the
model transferable to real data implementations, during the training we adopt
specific data augmentation strategies with the synthetic training data. The
experimental results show that data augmentation introduced during the training
process is essential for improving the performance of the trained model on real
data. More specifically, the results demonstrate that the data augmentations on
raw point-cloud data have contributed to a considerable improvement of the
trained model performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1908.01862v1,2019-08-05T21:10:12Z,2019-08-05T21:10:12Z,Semi-Automatic Labeling for Deep Learning in Robotics,"In this paper, we propose Augmented Reality Semi-automatic labeling (ARS), a
semi-automatic method which leverages on moving a 2D camera by means of a
robot, proving precise camera tracking, and an augmented reality pen to define
initial object bounding box, to create large labeled datasets with minimal
human intervention. By removing the burden of generating annotated data from
humans, we make the Deep Learning technique applied to computer vision, that
typically requires very large datasets, truly automated and reliable. With the
ARS pipeline, we created effortlessly two novel datasets, one on
electromechanical components (industrial scenario) and one on fruits
(daily-living scenario), and trained robustly two state-of-the-art object
detectors, based on convolutional neural networks, such as YOLO and SSD. With
respect to the conventional manual annotation of 1000 frames that takes us
slightly more than 10 hours, the proposed approach based on ARS allows
annotating 9 sequences of about 35000 frames in less than one hour, with a gain
factor of about 450. Moreover, both the precision and recall of object
detection is increased by about 15\% with respect to manual labeling. All our
software is available as a ROS package in a public repository alongside the
novel annotated datasets.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.13098v1,2019-07-28T02:03:08Z,2019-07-28T02:03:08Z,"Making Sense of Vision and Touch: Learning Multimodal Representations
  for Contact-Rich Tasks","Contact-rich manipulation tasks in unstructured environments often require
both haptic and visual feedback. It is non-trivial to manually design a robot
controller that combines these modalities which have very different
characteristics. While deep reinforcement learning has shown success in
learning control policies for high-dimensional inputs, these algorithms are
generally intractable to deploy on real robots due to sample complexity. In
this work, we use self-supervision to learn a compact and multimodal
representation of our sensory inputs, which can then be used to improve the
sample efficiency of our policy learning. Evaluating our method on a peg
insertion task, we show that it generalizes over varying geometries,
configurations, and clearances, while being robust to external perturbations.
We also systematically study different self-supervised learning objectives and
representation learning architectures. Results are presented in simulation and
on a physical robot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.11259v1,2019-07-25T18:10:28Z,2019-07-25T18:10:28Z,"Real-bogus classification for the Zwicky Transient Facility using deep
  learning","Efficient automated detection of flux-transient, reoccurring flux-variable,
and moving objects is increasingly important for large-scale astronomical
surveys. We present braai, a convolutional-neural-network, deep-learning
real/bogus classifier designed to separate genuine astrophysical events and
objects from false positive, or bogus, detections in the data of the Zwicky
Transient Facility (ZTF), a new robotic time-domain survey currently in
operation at the Palomar Observatory in California, USA. Braai demonstrates a
state-of-the-art performance as quantified by its low false negative and false
positive rates. We describe the open-source software tools used internally at
Caltech to archive and access ZTF's alerts and light curves (Kowalski), and to
label the data (Zwickyverse). We also report the initial results of the
classifier deployment on the Edge Tensor Processing Units (TPUs) that show
comparable performance in terms of accuracy, but in a much more (cost-)
efficient manner, which has significant implications for current and future
surveys.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.09209v1,2019-07-22T10:04:22Z,2019-07-22T10:04:22Z,"Automatic Calibration of Artificial Neural Networks for Zebrafish
  Collective Behaviours using a Quality Diversity Algorithm","During the last two decades, various models have been proposed for fish
collective motion. These models are mainly developed to decipher the biological
mechanisms of social interaction between animals. They consider very simple
homogeneous unbounded environments and it is not clear that they can simulate
accurately the collective trajectories. Moreover when the models are more
accurate, the question of their scalability to either larger groups or more
elaborate environments remains open. This study deals with learning how to
simulate realistic collective motion of collective of zebrafish, using
real-world tracking data. The objective is to devise an agent-based model that
can be implemented on an artificial robotic fish that can blend into a
collective of real fish. We present a novel approach that uses Quality
Diversity algorithms, a class of algorithms that emphasise exploration over
pure optimisation. In particular, we use CVT-MAP-Elites, a variant of the
state-of-the-art MAP-Elites algorithm for high dimensional search space.
Results show that Quality Diversity algorithms not only outperform classic
evolutionary reinforcement learning methods at the macroscopic level (i.e.
group behaviour), but are also able to generate more realistic biomimetic
behaviours at the microscopic level (i.e. individual behaviour).",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.07958v1,2019-07-18T09:58:27Z,2019-07-18T09:58:27Z,Transfer Learning Across Simulated Robots With Different Sensors,"For a robot to learn a good policy, it often requires expensive equipment
(such as sophisticated sensors) and a prepared training environment conducive
to learning. However, it is seldom possible to perfectly equip robots for
economic reasons, nor to guarantee ideal learning conditions, when deployed in
real-life environments. A solution would be to prepare the robot in the lab
environment, when all necessary material is available to learn a good policy.
After training in the lab, the robot should be able to get by without the
expensive equipment that used to be available to it, and yet still be
guaranteed to perform well on the field. The transition between the lab
(source) and the real-world environment (target) is related to transfer
learning, where the state-space between the source and target tasks differ. We
tackle a simulated task with continuous states and discrete actions presenting
this challenge, using Bootstrapped Dual Policy Iteration, a model-free
actor-critic reinforcement learning algorithm, and Policy Shaping.
Specifically, we train a BDPI agent, embodied by a virtual robot performing a
task in the V-Rep simulator, sensing its environment through several proximity
sensors. The resulting policy is then used by a second agent learning the same
task in the same environment, but with camera images as input. The goal is to
obtain a policy able to perform the task relying on merely camera images.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.07210v1,2019-07-16T18:33:20Z,2019-07-16T18:33:20Z,Real-time Vision-based Depth Reconstruction with NVidia Jetson,"Vision-based depth reconstruction is a challenging problem extensively
studied in computer vision but still lacking universal solution. Reconstructing
depth from single image is particularly valuable to mobile robotics as it can
be embedded to the modern vision-based simultaneous localization and mapping
(vSLAM) methods providing them with the metric information needed to construct
accurate maps in real scale. Typically, depth reconstruction is done nowadays
via fully-convolutional neural networks (FCNNs). In this work we experiment
with several FCNN architectures and introduce a few enhancements aimed at
increasing both the effectiveness and the efficiency of the inference. We
experimentally determine the solution that provides the best
performance/accuracy tradeoff and is able to run on NVidia Jetson with the
framerates exceeding 16FPS for 320 x 240 input. We also evaluate the suggested
models by conducting monocular vSLAM of unknown indoor environment on NVidia
Jetson TX2 in real-time. Open-source implementation of the models and the
inference node for Robot Operating System (ROS) are available at
https://github.com/CnnDepth/tx2_fcnn_node.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1907.06916v2,2019-07-22T13:04:27Z,2019-07-16T09:42:02Z,"Single-bit-per-weight deep convolutional neural networks without
  batch-normalization layers for embedded systems","Batch-normalization (BN) layers are thought to be an integrally important
layer type in today's state-of-the-art deep convolutional neural networks for
computer vision tasks such as classification and detection. However, BN layers
introduce complexity and computational overheads that are highly undesirable
for training and/or inference on low-power custom hardware implementations of
real-time embedded vision systems such as UAVs, robots and Internet of Things
(IoT) devices. They are also problematic when batch sizes need to be very small
during training, and innovations such as residual connections introduced more
recently than BN layers could potentially have lessened their impact. In this
paper we aim to quantify the benefits BN layers offer in image classification
networks, in comparison with alternative choices. In particular, we study
networks that use shifted-ReLU layers instead of BN layers. We found, following
experiments with wide residual networks applied to the ImageNet, CIFAR 10 and
CIFAR 100 image classification datasets, that BN layers do not consistently
offer a significant advantage. We found that the accuracy margin offered by BN
layers depends on the data set, the network size, and the bit-depth of weights.
We conclude that in situations where BN layers are undesirable due to speed,
memory or complexity costs, that using shifted-ReLU layers instead should be
considered; we found they can offer advantages in all these areas, and often do
not impose a significant accuracy cost.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.11392v2,2019-09-22T19:29:40Z,2019-06-27T00:01:54Z,From self-tuning regulators to reinforcement learning and back again,"Machine and reinforcement learning (RL) are increasingly being applied to
plan and control the behavior of autonomous systems interacting with the
physical world. Examples include self-driving vehicles, distributed sensor
networks, and agile robots. However, when machine learning is to be applied in
these new settings, the algorithms had better come with the same type of
reliability, robustness, and safety bounds that are hallmarks of control
theory, or failures could be catastrophic. Thus, as learning algorithms are
increasingly and more aggressively deployed in safety critical settings, it is
imperative that control theorists join the conversation. The goal of this
tutorial paper is to provide a starting point for control theorists wishing to
work on learning related problems, by covering recent advances bridging
learning and control theory, and by placing these results within an appropriate
historical context of system identification and adaptive control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.06969v1,2019-06-17T11:44:15Z,2019-06-17T11:44:15Z,Robotic Navigation using Entropy-Based Exploration,"Robotic navigation concerns the task in which a robot should be able to find
a safe and feasible path and traverse between two points in a complex
environment. We approach the problem of robotic navigation using reinforcement
learning and use deep $Q$-networks to train agents to solve the task of robotic
navigation. We compare the Entropy-Based Exploration (EBE) with the widely used
$\epsilon$-greedy exploration strategy by training agents using both of them in
simulation. The trained agents are then tested on different versions of the
environment to test the generalization ability of the learned policies. We also
implement the learned policies on a real robot in complex real environment
without any fine tuning and compare the effectiveness of the above-mentioned
exploration strategies in the real world setting. Video showing experiments on
TurtleBot3 platform is available at \url{https://youtu.be/NHT-EiN_4n8}.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.04161v1,2019-06-10T17:58:32Z,2019-06-10T17:58:32Z,Self-Supervised Exploration via Disagreement,"Efficient exploration is a long-standing problem in sensorimotor learning.
Major advances have been demonstrated in noise-free, non-stochastic domains
such as video games and simulation. However, most of these formulations either
get stuck in environments with stochastic dynamics or are too inefficient to be
scalable to real robotics setups. In this paper, we propose a formulation for
exploration inspired by the work in active learning literature. Specifically,
we train an ensemble of dynamics models and incentivize the agent to explore
such that the disagreement of those ensembles is maximized. This allows the
agent to learn skills by exploring in a self-supervised manner without any
external reward. Notably, we further leverage the disagreement objective to
optimize the agent's policy in a differentiable manner, without using
reinforcement learning, which results in a sample-efficient exploration. We
demonstrate the efficacy of this formulation across a variety of benchmark
environments including stochastic-Atari, Mujoco and Unity. Finally, we
implement our differentiable exploration on a real robot which learns to
interact with objects completely from scratch. Project videos and code are at
https://pathak22.github.io/exploration-by-disagreement/",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1906.02003v1,2019-06-05T12:54:27Z,2019-06-05T12:54:27Z,"Machine Learning and System Identification for Estimation in Physical
  Systems","In this thesis, we draw inspiration from both classical system identification
and modern machine learning in order to solve estimation problems for
real-world, physical systems. The main approach to estimation and learning
adopted is optimization based. Concepts such as regularization will be utilized
for encoding of prior knowledge and basis-function expansions will be used to
add nonlinear modeling power while keeping data requirements practical. The
thesis covers a wide range of applications, many inspired by applications
within robotics, but also extending outside this already wide field. Usage of
the proposed methods and algorithms are in many cases illustrated in the
real-world applications that motivated the research. Topics covered include
dynamics modeling and estimation, model-based reinforcement learning, spectral
estimation, friction modeling and state estimation and calibration in robotic
machining. In the work on modeling and identification of dynamics, we develop
regularization strategies that allow us to incorporate prior domain knowledge
into flexible, overparameterized models. We make use of classical control
theory to gain insight into training and regularization while using flexible
tools from modern deep learning. A particular focus of the work is to allow use
of modern methods in scenarios where gathering data is associated with a high
cost. In the robotics-inspired parts of the thesis, we develop methods that are
practically motivated and ensure that they are implementable also outside the
research setting. We demonstrate this by performing experiments in realistic
settings and providing open-source implementations of all proposed methods and
algorithms.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.12612v2,2019-10-15T08:10:25Z,2019-05-29T17:50:19Z,Learning Navigation Subroutines from Egocentric Videos,"Planning at a higher level of abstraction instead of low level torques
improves the sample efficiency in reinforcement learning, and computational
efficiency in classical planning. We propose a method to learn such
hierarchical abstractions, or subroutines from egocentric video data of experts
performing tasks. We learn a self-supervised inverse model on small amounts of
random interaction data to pseudo-label the expert egocentric videos with agent
actions. Visuomotor subroutines are acquired from these pseudo-labeled videos
by learning a latent intent-conditioned policy that predicts the inferred
pseudo-actions from the corresponding image observations. We demonstrate our
proposed approach in context of navigation, and show that we can successfully
learn consistent and diverse visuomotor subroutines from passive egocentric
videos. We demonstrate the utility of our acquired visuomotor subroutines by
using them as is for exploration, and as sub-policies in a hierarchical RL
framework for reaching point goals and semantic goals. We also demonstrate
behavior of our subroutines in the real world, by deploying them on a real
robotic platform. Project website:
https://ashishkumar1993.github.io/subroutines/.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.05212v1,2019-05-13T18:01:01Z,2019-05-13T18:01:01Z,"Lightweight Monocular Depth Estimation Model by Joint End-to-End Filter
  pruning","Convolutional neural networks (CNNs) have emerged as the state-of-the-art in
multiple vision tasks including depth estimation. However, memory and computing
power requirements remain as challenges to be tackled in these models.
Monocular depth estimation has significant use in robotics and virtual reality
that requires deployment on low-end devices. Training a small model from
scratch results in a significant drop in accuracy and it does not benefit from
pre-trained large models. Motivated by the literature of model pruning, we
propose a lightweight monocular depth model obtained from a large trained
model. This is achieved by removing the least important features with a novel
joint end-to-end filter pruning. We propose to learn a binary mask for each
filter to decide whether to drop the filter or not. These masks are trained
jointly to exploit relations between filters at different layers as well as
redundancy within the same layer. We show that we can achieve around 5x
compression rate with small drop in accuracy on the KITTI driving dataset. We
also show that masking can improve accuracy over the baseline with fewer
parameters, even without enforcing compression loss.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1905.04166v1,2019-05-10T13:34:18Z,2019-05-10T13:34:18Z,"An Open Source and Open Hardware Deep Learning-powered Visual Navigation
  Engine for Autonomous Nano-UAVs","Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter
and sub-10 Watts of total power budget, have so far been considered incapable
of running sophisticated visual-based autonomous navigation software without
external aid from base-stations, ad-hoc local positioning infrastructure, and
powerful external computation servers. In this work, we present what is, to the
best of our knowledge, the first 27g nano-UAV system able to run aboard an
end-to-end, closed-loop visual pipeline for autonomous navigation based on a
state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie
2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination
of an ultra-low power computing device (the GAP8 system-on-chip) with a novel
methodology for the deployment of deep convolutional neural networks (CNNs). We
enable onboard real-time execution of a state-of-the-art deep CNN at up to
18Hz. Field experiments demonstrate that the system's high responsiveness
prevents collisions with unexpected dynamic obstacles up to a flight speed of
1.5m/s. In addition, we also demonstrate the capability of our visual
navigation engine of fully autonomous indoor navigation on a 113m previously
unseen path. To share our key findings with the embedded and robotics
communities and foster further developments in autonomous nano-UAVs, we
publicly release all our code, datasets, and trained networks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.11243v1,2019-04-25T09:55:50Z,2019-04-25T09:55:50Z,NeuroPod: a real-time neuromorphic spiking CPG applied to robotics,"Initially, robots were developed with the aim of making our life easier,
carrying out repetitive or dangerous tasks for humans. Although they were able
to perform these tasks, the latest generation of robots are being designed to
take a step further, by performing more complex tasks that have been carried
out by smart animals or humans up to date. To this end, inspiration needs to be
taken from biological examples. For instance, insects are able to optimally
solve complex environment navigation problems, and many researchers have
started to mimic how these insects behave. Recent interest in neuromorphic
engineering has motivated us to present a real-time, neuromorphic, spike-based
Central Pattern Generator of application in neurorobotics, using an
arthropod-like robot. A Spiking Neural Network was designed and implemented on
SpiNNaker. The network models a complex, online-change capable Central Pattern
Generator which generates three gaits for a hexapod robot locomotion.
Reconfigurable hardware was used to manage both the motors of the robot and the
real-time communication interface with the Spiking Neural Networks. Real-time
measurements confirm the simulation results, and locomotion tests show that
NeuroPod can perform the gaits without any balance loss or added delay.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.11082v1,2019-04-24T21:41:04Z,2019-04-24T21:41:04Z,"How You Act Tells a Lot: Privacy-Leakage Attack on Deep Reinforcement
  Learning","Machine learning has been widely applied to various applications, some of
which involve training with privacy-sensitive data. A modest number of data
breaches have been studied, including credit card information in natural
language data and identities from face dataset. However, most of these studies
focus on supervised learning models. As deep reinforcement learning (DRL) has
been deployed in a number of real-world systems, such as indoor robot
navigation, whether trained DRL policies can leak private information requires
in-depth study. To explore such privacy breaches in general, we mainly propose
two methods: environment dynamics search via genetic algorithm and candidate
inference based on shadow policies. We conduct extensive experiments to
demonstrate such privacy vulnerabilities in DRL under various settings. We
leverage the proposed algorithms to infer floor plans from some trained Grid
World navigation DRL agents with LiDAR perception. The proposed algorithm can
correctly infer most of the floor plans and reaches an average recovery rate of
95.83% using policy gradient trained agents. In addition, we are able to
recover the robot configuration in continuous control environments and an
autonomous driving simulator with high accuracy. To the best of our knowledge,
this is the first work to investigate privacy leakage in DRL settings and we
show that DRL-based agents do potentially leak privacy-sensitive information
from the trained policies.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.06933v3,2019-04-21T13:39:00Z,2019-04-15T09:47:38Z,"Learning to Navigate in Indoor Environments: from Memorizing to
  Reasoning","Autonomous navigation is an essential capability of smart mobility for mobile
robots. Traditional methods must have the environment map to plan a
collision-free path in workspace. Deep reinforcement learning (DRL) is a
promising technique to realize the autonomous navigation task without a map,
with which deep neural network can fit the mapping from observation to
reasonable action through explorations. It should not only memorize the trained
target, but more importantly, the planner can reason out the unseen goal. We
proposed a new motion planner based on deep reinforcement learning that can
arrive at new targets that have not been trained before in the indoor
environment with RGB image and odometry only. The model has a structure of
stacked Long Short-Term memory (LSTM). Finally, experiments were implemented in
both simulated and real environments. The source code is available:
https://github.com/marooncn/navbot.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1904.01080v5,2022-07-05T04:40:27Z,2019-04-01T19:38:56Z,"Learning Matchable Image Transformations for Long-term Metric Visual
  Localization","Long-term metric self-localization is an essential capability of autonomous
mobile robots, but remains challenging for vision-based systems due to
appearance changes caused by lighting, weather, or seasonal variations. While
experience-based mapping has proven to be an effective technique for bridging
the `appearance gap,' the number of experiences required for reliable metric
localization over days or months can be very large, and methods for reducing
the necessary number of experiences are needed for this approach to scale.
Taking inspiration from color constancy theory, we learn a nonlinear
RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature
matches for images captured under different lighting and weather conditions,
and use it as a pre-processing step in a conventional single-experience
localization pipeline to improve its robustness to appearance change. We train
this mapping by approximating the target non-differentiable localization
pipeline with a deep neural network, and find that incorporating a learned
low-dimensional context feature can further improve cross-appearance feature
matching. Using synthetic and real-world datasets, we demonstrate substantial
improvements in localization performance across day-night cycles, enabling
continuous metric localization over a 30-hour period using a single mapping
experience, and allowing experience-based localization to scale to long
deployments with dramatically reduced data requirements.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.11524v1,2019-03-27T16:22:48Z,2019-03-27T16:22:48Z,"Autoregressive Policies for Continuous Control Deep Reinforcement
  Learning","Reinforcement learning algorithms rely on exploration to discover new
behaviors, which is typically achieved by following a stochastic policy. In
continuous control tasks, policies with a Gaussian distribution have been
widely adopted. Gaussian exploration however does not result in smooth
trajectories that generally correspond to safe and rewarding behaviors in
practical tasks. In addition, Gaussian policies do not result in an effective
exploration of an environment and become increasingly inefficient as the action
rate increases. This contributes to a low sample efficiency often observed in
learning continuous control tasks. We introduce a family of stationary
autoregressive (AR) stochastic processes to facilitate exploration in
continuous control domains. We show that proposed processes possess two
desirable features: subsequent process observations are temporally coherent
with continuously adjustable degree of coherence, and the process stationary
distribution is standard normal. We derive an autoregressive policy (ARP) that
implements such processes maintaining the standard agent-environment interface.
We show how ARPs can be easily used with the existing off-the-shelf learning
algorithms. Empirically we demonstrate that using ARPs results in improved
exploration and sample efficiency in both simulated and real world domains,
and, furthermore, provides smooth exploration trajectories that enable safe
operation of robotic hardware.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.09870v2,2019-08-28T19:32:23Z,2019-03-23T19:36:11Z,Long Range Neural Navigation Policies for the Real World,"Learned Neural Network based policies have shown promising results for robot
navigation. However, most of these approaches fall short of being used on a
real robot due to the extensive simulated training they require. These
simulations lack the visuals and dynamics of the real world, which makes it
infeasible to deploy on a real robot. We present a novel Neural Net based
policy, NavNet, which allows for easy deployment on a real robot. It consists
of two sub policies -- a high level policy which can understand real images and
perform long range planning expressed in high level commands; a low level
policy that can translate the long range plan into low level commands on a
specific platform in a safe and robust manner. For every new deployment, the
high level policy is trained on an easily obtainable scan of the environment
modeling its visuals and layout. We detail the design of such an environment
and how one can use it for training a final navigation policy. Further, we
demonstrate a learned low-level policy. We deploy the model in a large office
building and test it extensively, achieving $0.80$ success rate over long
navigation runs and outperforming SLAM-based models in the same settings.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.06278v2,2019-03-18T05:32:11Z,2019-03-14T22:05:20Z,"gym-gazebo2, a toolkit for reinforcement learning using ROS 2 and Gazebo","This paper presents an upgraded, real world application oriented version of
gym-gazebo, the Robot Operating System (ROS) and Gazebo based Reinforcement
Learning (RL) toolkit, which complies with OpenAI Gym. The content discusses
the new ROS 2 based software architecture and summarizes the results obtained
using Proximal Policy Optimization (PPO). Ultimately, the output of this work
presents a benchmarking system for robotics that allows different techniques
and algorithms to be compared using the same virtual conditions. We have
evaluated environments with different levels of complexity of the Modular
Articulated Robotic Arm (MARA), reaching accuracies in the millimeter scale.
The converged results show the feasibility and usefulness of the gym-gazebo 2
toolkit, its potential and applicability in industrial use cases, using modular
robots.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.04824v1,2019-03-12T10:28:36Z,2019-03-12T10:28:36Z,"Proceedings of the Fifth International Conference on Cloud and Robotics
  (ICCR2018)","The 5th edition of the International Conference on Cloud and Robotics (ICCR
2018 - http://cloudrobotics.info) will be held on November 12-14 2018 in Paris
and Saint-Quentin, France. The conference is a co-event with GDR ALROB and the
industry exposition Robonumerique (http://www.robonumerique.fr).
  The domain of cloud robotics aims to converge robots with computation,
storage and communication resources provided by the cloud. The cloud may
complement robotic resources in several ways, including crowd-sourcing
knowledge databases, context information, computational offloading or
data-intensive information processing for artificial intelligence. Today, the
paradigms of cloud/fog/edge computing propose software architecture solutions
for robots to share computations or offload them to ambiant and networked
resources. Yet, combining distant computations with the real time constraints
of robotics is very challenging. As the challenges in this domain are
multi-disciplinary and similar in other research areas, Cloud Robotics aims at
building bridges among experts from academia and industry working in different
fields, such as robotics, cyber-physical systems, automotive, aerospace,
machine learning, artificial intelligence, software architecture, big data
analytics, Internet-of-Things, networked control and distributed cloud systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.02503v1,2019-03-06T17:24:11Z,2019-03-06T17:24:11Z,The AI Driving Olympics at NeurIPS 2018,"Despite recent breakthroughs, the ability of deep learning and reinforcement
learning to outperform traditional approaches to control physically embodied
robotic agents remains largely unproven. To help bridge this gap, we created
the 'AI Driving Olympics' (AI-DO), a competition with the objective of
evaluating the state of the art in machine learning and artificial intelligence
for mobile robotics. Based on the simple and well specified autonomous driving
and navigation environment called 'Duckietown', AI-DO includes a series of
tasks of increasing complexity -- from simple lane-following to fleet
management. For each task, we provide tools for competitors to use in the form
of simulators, logs, code templates, baseline implementations and low-cost
access to robotic hardware. We evaluate submissions in simulation online, on
standardized hardware environments, and finally at the competition event. The
first AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems
(NeurIPS) conference in December 2018. The results of AI-DO 1 highlight the
need for better benchmarks, which are lacking in robotics, as well as improved
mechanisms to bridge the gap between simulation and reality.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.02219v1,2019-03-06T07:39:11Z,2019-03-06T07:39:11Z,Training in Task Space to Speed Up and Guide Reinforcement Learning,"Recent breakthroughs in the reinforcement learning (RL) community have made
significant advances towards learning and deploying policies on real world
robotic systems. However, even with the current state-of-the-art algorithms and
computational resources, these algorithms are still plagued with high sample
complexity, and thus long training times, especially for high degree of freedom
(DOF) systems. There are also concerns arising from lack of perceived stability
or robustness guarantees from emerging policies. This paper aims at mitigating
these drawbacks by: (1) modeling a complex, high DOF system with a
representative simple one, (2) making explicit use of forward and inverse
kinematics without forcing the RL algorithm to ""learn"" them on its own, and (3)
learning locomotion policies in Cartesian space instead of joint space. In this
paper these methods are applied to JPL's Robosimian, but can be readily used on
any system with a base and end effector(s). These locomotion policies can be
produced in just a few minutes, trained on a single laptop. We compare the
robustness of the resulting learned policies to those of other control methods.
An accompanying video for this paper can be found at
https://youtu.be/xDxxSw5ahnc .",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.02090v2,2020-01-27T17:51:39Z,2019-03-05T22:21:13Z,Open-Sourced Reinforcement Learning Environments for Surgical Robotics,"Reinforcement Learning (RL) is a machine learning framework for artificially
intelligent systems to solve a variety of complex problems. Recent years has
seen a surge of successes solving challenging games and smaller domain
problems, including simple though non-specific robotic manipulation and
grasping tasks. Rapid successes in RL have come in part due to the strong
collaborative effort by the RL community to work on common, open-sourced
environment simulators such as OpenAI's Gym that allow for expedited
development and valid comparisons between different, state-of-art strategies.
In this paper, we aim to start the bridge between the RL and the surgical
robotics communities by presenting the first open-sourced reinforcement
learning environments for surgical robots, called dVRL[3]{dVRL available at
https://github.com/ucsdarclab/dVRL}. Through the proposed RL environments,
which are functionally equivalent to Gym, we show that it is easy to prototype
and implement state-of-art RL algorithms on surgical robotics problems that aim
to introduce autonomous robotic precision and accuracy to assisting,
collaborative, or repetitive tasks during surgery. Learned policies are
furthermore successfully transferable to a real robot. Finally, combining dVRL
with the over 40+ international network of da Vinci Surgical Research Kits in
active use at academic institutions, we see dVRL as enabling the broad surgical
robotics community to fully leverage the newest strategies in reinforcement
learning, and for reinforcement learning scientists with no knowledge of
surgical robotics to test and develop new algorithms that can solve the
real-world, high-impact challenges in autonomous surgery.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1903.01804v2,2019-07-12T10:59:11Z,2019-03-05T13:09:18Z,"Robot Localization in Floor Plans Using a Room Layout Edge Extraction
  Network","Indoor localization is one of the crucial enablers for deployment of service
robots. Although several successful techniques for indoor localization have
been proposed, the majority of them relies on maps generated from data gathered
with the same sensor modality used for localization. Typically, tedious labor
by experts is needed to acquire this data, thus limiting the readiness of the
system as well as its ease of installation for inexperienced operators. In this
paper, we propose a memory and computationally efficient monocular camera-based
localization system that allows a robot to estimate its pose given an
architectural floor plan. Our method employs a convolutional neural network to
predict room layout edges from a single camera image and estimates the robot
pose using a particle filter that matches the extracted edges to the given
floor plan. We evaluate our localization system using multiple real-world
experiments and demonstrate that it has the robustness and accuracy required
for reliable indoor navigation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1902.09157v1,2019-02-25T09:20:20Z,2019-02-25T09:20:20Z,"Quickly Inserting Pegs into Uncertain Holes using Multi-view Images and
  Deep Network Trained on Synthetic Data","This paper uses robots to assemble pegs into holes on surfaces with different
colors and textures. It especially targets at the problem of peg-in-hole
assembly with initial position uncertainty. Two in-hand cameras and a
force-torque sensor are used to account for the position uncertainty. A program
sequence comprising learning-based visual servoing, spiral search, and
impedance control is implemented to perform the peg-in-hole task with feedback
from the above sensors. Contributions are mainly made in the learning-based
visual servoing of the sequence, where a deep neural network is trained with
various sets of synthetic data generated using the concept of domain
randomization to predict where a hole is. In the experiments and analysis
section, the network is analyzed and compared, and a real-world robotic system
to insert pegs to holes using the proposed method is implemented. The results
show that the implemented peg-in-hole assembly system can perform successful
peg-in-hole insertions on surfaces with various colors and textures. It can
generally speed up the entire peg-in-hole process.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1902.04992v1,2019-02-13T16:32:32Z,2019-02-13T16:32:32Z,Learning to see across Domains and Modalities,"Deep learning has raised hopes and expectations as a general solution for
many applications; indeed it has proven effective, but it also showed a strong
dependence on large quantities of data. Luckily, it has been shown that, even
when data is scarce, a successful model can be trained by reusing prior
knowledge. Thus, developing techniques for transfer learning, in its broadest
definition, is a crucial element towards the deployment of effective and
accurate intelligent systems. This thesis will focus on a family of transfer
learning methods applied to the task of visual object recognition, specifically
image classification. Transfer learning is a general term, and specific
settings have been given specific names: when the learner has only access to
unlabeled data from the a target domain and labeled data from a different
domain (the source), the problem is known as that of ""unsupervised domain
adaptation"" (DA). The first part of this work will focus on three methods for
this setting: one of these methods deals with features, one with images while
the third one uses both. The second part will focus on the real life issues of
robotic perception, specifically RGB-D recognition. Robotic platforms are
usually not limited to color perception; very often they also carry a Depth
camera. Unfortunately, the depth modality is rarely used for visual recognition
due to the lack of pretrained models from which to transfer and little data to
train one on from scratch. Two methods for dealing with this scenario will be
presented: one using synthetic data and the other exploiting cross-modality
transfer learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1902.01670v2,2020-11-24T09:33:55Z,2019-02-05T13:26:53Z,Interactively shaping robot behaviour with unlabeled human instructions,"In this paper, we propose a framework that enables a human teacher to shape a
robot behaviour by interactively providing it with unlabeled instructions. We
ground the meaning of instruction signals in the task-learning process, and use
them simultaneously for guiding the latter. We implement our framework as a
modular architecture, named TICS (Task-Instruction-Contingency-Shaping) that
combines different information sources: a predefined reward function, human
evaluative feedback and unlabeled instructions. This approach provides a novel
perspective for robotic task learning that lies between Reinforcement Learning
and Supervised Learning paradigms. We evaluate our framework both in simulation
and with a real robot. The experimental results demonstrate the effectiveness
of our framework in accelerating the task-learning process and in reducing the
number of required teaching signals.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1901.10281v1,2019-01-29T13:43:57Z,2019-01-29T13:43:57Z,Structural Material Property Tailoring Using Deep Neural Networks,"Advances in robotics, artificial intelligence, and machine learning are
ushering in a new age of automation, as machines match or outperform human
performance. Machine intelligence can enable businesses to improve performance
by reducing errors, improving sensitivity, quality and speed, and in some cases
achieving outcomes that go beyond current resource capabilities. Relevant
applications include new product architecture design, rapid material
characterization, and life-cycle management tied with a digital strategy that
will enable efficient development of products from cradle to grave. In
addition, there are also challenges to overcome that must be addressed through
a major, sustained research effort that is based solidly on both inferential
and computational principles applied to design tailoring of functionally
optimized structures. Current applications of structural materials in the
aerospace industry demand the highest quality control of material
microstructure, especially for advanced rotational turbomachinery in aircraft
engines in order to have the best tailored material property. In this paper,
deep convolutional neural networks were developed to accurately predict
processing-structure-property relations from materials microstructures images,
surpassing current best practices and modeling efforts. The models
automatically learn critical features, without the need for manual
specification and/or subjective and expensive image analysis. Further, in
combination with generative deep learning models, a framework is proposed to
enable rapid material design space exploration and property identification and
optimization. The implementation must take account of real-time decision cycles
and the trade-offs between speed and accuracy.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1901.08652v1,2019-01-24T21:50:29Z,2019-01-24T21:50:29Z,Learning agile and dynamic motor skills for legged robots,"Legged robots pose one of the greatest challenges in robotics. Dynamic and
agile maneuvers of animals cannot be imitated by existing methods that are
crafted by humans. A compelling alternative is reinforcement learning, which
requires minimal craftsmanship and promotes the natural evolution of a control
policy. However, so far, reinforcement learning research for legged robots is
mainly limited to simulation, and only few and comparably simple examples have
been deployed on real systems. The primary reason is that training with real
robots, particularly with dynamically balancing systems, is complicated and
expensive. In the present work, we introduce a method for training a neural
network policy in simulation and transferring it to a state-of-the-art legged
system, thereby leveraging fast, automated, and cost-effective data generation
schemes. The approach is applied to the ANYmal robot, a sophisticated
medium-dog-sized quadrupedal system. Using policies trained in simulation, the
quadrupedal machine achieves locomotion skills that go beyond what had been
achieved with prior methods: ANYmal is capable of precisely and
energy-efficiently following high-level body velocity commands, running faster
than before, and recovering from falling even in complex configurations.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1901.07517v1,2019-01-22T18:45:42Z,2019-01-22T18:45:42Z,"Robust Recovery Controller for a Quadrupedal Robot using Deep
  Reinforcement Learning","The ability to recover from a fall is an essential feature for a legged robot
to navigate in challenging environments robustly. Until today, there has been
very little progress on this topic. Current solutions mostly build upon
(heuristically) predefined trajectories, resulting in unnatural behaviors and
requiring considerable effort in engineering system-specific components. In
this paper, we present an approach based on model-free Deep Reinforcement
Learning (RL) to control recovery maneuvers of quadrupedal robots using a
hierarchical behavior-based controller. The controller consists of four neural
network policies including three behaviors and one behavior selector to
coordinate them. Each of them is trained individually in simulation and
deployed directly on a real system. We experimentally validate our approach on
the quadrupedal robot ANYmal, which is a dog-sized quadrupedal system with 12
degrees of freedom. With our method, ANYmal manifests dynamic and reactive
recovery behaviors to recover from an arbitrary fall configuration within less
than 5 seconds. We tested the recovery maneuver more than 100 times, and the
success rate was higher than 97 %.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1901.01989v1,2019-01-06T19:57:24Z,2019-01-06T19:57:24Z,"Towards Self-constructive Artificial Intelligence: Algorithmic basis
  (Part I)","Artificial Intelligence frameworks should allow for ever more autonomous and
general systems in contrast to very narrow and restricted (human pre-defined)
domain systems, in analogy to how the brain works. Self-constructive Artificial
Intelligence ($SCAI$) is one such possible framework. We herein propose that
$SCAI$ is based on three principles of organization: self-growing,
self-experimental and self-repairing. Self-growing: the ability to autonomously
and incrementally construct structures and functionality as needed to solve
encountered (sub)problems. Self-experimental: the ability to internally
simulate, anticipate and take decisions based on these expectations.
Self-repairing: the ability to autonomously re-construct a previously
successful functionality or pattern of interaction lost from a possible
sub-component failure (damage). To implement these principles of organization,
a constructive architecture capable of evolving adaptive autonomous agents is
required. We present Schema-based learning as one such architecture capable of
incrementally constructing a myriad of internal models of three kinds:
predictive schemas, dual (inverse models) schemas and goal schemas as they are
necessary to autonomously develop increasing functionality.
  We claim that artificial systems, whether in the digital or in the physical
world, can benefit very much form this constructive architecture and should be
organized around these principles of organization. To illustrate the generality
of the proposed framework, we include several test cases in structural adaptive
navigation in artificial intelligence systems in Paper II of this series, and
resilient robot motor control in Paper III of this series. Paper IV of this
series will also include $SCAI$ for problem structural discovery in predictive
Business Intelligence.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.07221v1,2018-12-18T08:11:00Z,2018-12-18T08:11:00Z,"Continuous Trajectory Planning Based on Learning Optimization in High
  Dimensional Input Space for Serial Manipulators","To continuously generate trajectories for serial manipulators with high
dimensional degrees of freedom (DOF) in the dynamic environment, a real-time
optimal trajectory generation method based on machine learning aiming at high
dimensional inputs is presented in this paper. First, a learning optimization
(LO) framework is established, and implementations with different sub-methods
are discussed. Additionally, multiple criteria are defined to evaluate the
performance of LO models. Furthermore, aiming at high dimensional inputs, a
database generation method based on input space dimension-reducing mapping is
proposed. At last, this method is validated on motion planning for haptic
feedback manipulators (HFM) in virtual reality systems. Results show that the
input space dimension-reducing method can significantly elevate the efficiency
and quality of database generation and consequently improve the performance of
the LO. Moreover, using this LO method, real-time trajectory generation with
high dimensional inputs can be achieved, which lays a foundation for continuous
trajectory planning for high-DOF-robots in complex environments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.05659v1,2018-12-09T19:46:00Z,2018-12-09T19:46:00Z,"Artificial Intelligence Assisted Infrastructure Assessment Using Mixed
  Reality Systems","Conventional methods for visual assessment of civil infrastructures have
certain limitations, such as subjectivity of the collected data, long
inspection time, and high cost of labor. Although some new technologies i.e.
robotic techniques that are currently in practice can collect objective,
quantified data, the inspectors own expertise is still critical in many
instances since these technologies are not designed to work interactively with
human inspector. This study aims to create a smart, human centered method that
offers significant contributions to infrastructure inspection, maintenance,
management practice, and safety for the bridge owners. By developing a smart
Mixed Reality framework, which can be integrated into a wearable holographic
headset device, a bridge inspector, for example, can automatically analyze a
certain defect such as a crack that he or she sees on an element, display its
dimension information in real-time along with the condition state. Such systems
can potentially decrease the time and cost of infrastructure inspections by
accelerating essential tasks of the inspector such as defect measurement,
condition assessment and data processing to management systems. The human
centered artificial intelligence will help the inspector collect more
quantified and objective data while incorporating inspectors professional
judgement. This study explains in detail the described system and related
methodologies of implementing attention guided semi supervised deep learning
into mixed reality technology, which interacts with the human inspector during
assessment. Thereby, the inspector and the AI will collaborate or communicate
for improved visual inspection.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1812.03201v2,2018-12-18T23:40:20Z,2018-12-07T20:10:23Z,Residual Reinforcement Learning for Robot Control,"Conventional feedback control methods can solve various types of robot
control problems very efficiently by capturing the structure with explicit
models, such as rigid body equations of motion. However, many control problems
in modern manufacturing deal with contacts and friction, which are difficult to
capture with first-order physical modeling. Hence, applying control design
methodologies to these kinds of problems often results in brittle and
inaccurate controllers, which have to be manually tuned for deployment.
Reinforcement learning (RL) methods have been demonstrated to be capable of
learning continuous robot controllers from interactions with the environment,
even for problems that include friction and contacts. In this paper, we study
how we can solve difficult control problems in the real world by decomposing
them into a part that is solved efficiently by conventional feedback control
methods, and the residual which is solved with RL. The final control policy is
a superposition of both control signals. We demonstrate our approach by
training an agent to successfully perform a real-world block assembly task
involving contacts and unstable objects.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.10800v4,2020-01-30T05:49:50Z,2018-11-27T04:27:40Z,Probabilistic Object Detection: Definition and Evaluation,"We introduce Probabilistic Object Detection, the task of detecting objects in
images and accurately quantifying the spatial and semantic uncertainties of the
detections. Given the lack of methods capable of assessing such probabilistic
object detections, we present the new Probability-based Detection Quality
measure (PDQ).Unlike AP-based measures, PDQ has no arbitrary thresholds and
rewards spatial and label quality, and foreground/background separation quality
while explicitly penalising false positive and false negative detections. We
contrast PDQ with existing mAP and moLRP measures by evaluating
state-of-the-art detectors and a Bayesian object detector based on Monte Carlo
Dropout. Our experiments indicate that conventional object detectors tend to be
spatially overconfident and thus perform poorly on the task of probabilistic
object detection. Our paper aims to encourage the development of new object
detection approaches that provide detections with accurately estimated spatial
and label uncertainties and are of critical importance for deployment on robots
and embodied AI systems in the real world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.08955v1,2018-11-21T21:20:24Z,2018-11-21T21:20:24Z,"Integrating Task-Motion Planning with Reinforcement Learning for Robust
  Decision Making in Mobile Robots","Task-motion planning (TMP) addresses the problem of efficiently generating
executable and low-cost task plans in a discrete space such that the (initially
unknown) action costs are determined by motion plans in a corresponding
continuous space. However, a task-motion plan can be sensitive to unexpected
domain uncertainty and changes, leading to suboptimal behaviors or execution
failures. In this paper, we propose a novel framework, TMP-RL, which is an
integration of TMP and reinforcement learning (RL) from the execution
experience, to solve the problem of robust task-motion planning in dynamic and
uncertain domains. TMP-RL features two nested planning-learning loops. In the
inner TMP loop, the robot generates a low-cost, feasible task-motion plan by
iteratively planning in the discrete space and updating relevant action costs
evaluated by the motion planner in continuous space. In the outer loop, the
plan is executed, and the robot learns from the execution experience via
model-free RL, to further improve its task-motion plans. RL in the outer loop
is more accurate to the current domain but also more expensive, and using less
costly task and motion planning leads to a jump-start for learning in the real
world. Our approach is evaluated on a mobile service robot conducting
navigation tasks in an office area. Results show that TMP-RL approach
significantly improves adaptability and robustness (in comparison to TMP
methods) and leads to rapid convergence (in comparison to task planning (TP)-RL
methods). We also show that TMP-RL can reuse learned values to smoothly adapt
to new scenarios during long-term deployments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.08716v1,2018-11-21T13:19:28Z,2018-11-21T13:19:28Z,Autonomous Dual-Arm Manipulation of Familiar Objects,"Autonomous dual-arm manipulation is an essential skill to deploy robots in
unstructured scenarios. However, this is a challenging undertaking,
particularly in terms of perception and planning. Unstructured scenarios are
full of objects with different shapes and appearances that have to be grasped
in a very specific manner so they can be functionally used. In this paper we
present an integrated approach to perform dual-arm pick tasks autonomously. Our
method consists of semantic segmentation, object pose estimation, deformable
model registration, grasp planning and arm trajectory optimization. The entire
pipeline can be executed on-board and is suitable for on-line grasping
scenarios. For this, our approach makes use of accumulated knowledge expressed
as convolutional neural network models and low-dimensional latent shape spaces.
For manipulating objects, we propose a stochastic trajectory optimization that
includes a kinematic chain closure constraint. Evaluation in simulation and on
the real robot corroborates the feasibility and applicability of the proposed
methods on a task of picking up unknown watering cans and drills using both
arms.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.07738v3,2019-04-23T07:51:28Z,2018-11-19T14:51:56Z,"M2U-Net: Effective and Efficient Retinal Vessel Segmentation for
  Resource-Constrained Environments","In this paper, we present a novel neural network architecture for retinal
vessel segmentation that improves over the state of the art on two benchmark
datasets, is the first to run in real time on high resolution images, and its
small memory and processing requirements make it deployable in mobile and
embedded systems. The M2U-Net has a new encoder-decoder architecture that is
inspired by the U-Net. It adds pretrained components of MobileNetV2 in the
encoder part and novel contractive bottleneck blocks in the decoder part that,
combined with bilinear upsampling, drastically reduce the parameter count to
0.55M compared to 31.03M in the original U-Net. We have evaluated its
performance against a wide body of previously published results on three public
datasets. On two of them, the M2U-Net achieves new state-of-the-art performance
by a considerable margin. When implemented on a GPU, our method is the first to
achieve real-time inference speeds on high-resolution fundus images. We also
implemented our proposed network on an ARM-based embedded system where it
segments images in between 0.6 and 15 sec, depending on the resolution. Thus,
the M2U-Net enables a number of applications of retinal vessel structure
extraction, such as early diagnosis of eye diseases, retinal biometric
authentication systems, and robot assisted microsurgery.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.02213v1,2018-11-06T08:05:24Z,2018-11-06T08:05:24Z,"Hybrid Approach to Automation, RPA and Machine Learning: a Method for
  the Human-centered Design of Software Robots","One of the more prominent trends within Industry 4.0 is the drive to employ
Robotic Process Automation (RPA), especially as one of the elements of the Lean
approach. The full implementation of RPA is riddled with challenges relating
both to the reality of everyday business operations, from SMEs to SSCs and
beyond, and the social effects of the changing job market. To successfully
address these points there is a need to develop a solution that would adjust to
the existing business operations and at the same time lower the negative social
impact of the automation process.
  To achieve these goals we propose a hybrid, human-centered approach to the
development of software robots. This design and implementation method combines
the Living Lab approach with empowerment through participatory design to
kick-start the co-development and co-maintenance of hybrid software robots
which, supported by variety of AI methods and tools, including interactive and
collaborative ML in the cloud, transform menial job posts into higher-skilled
positions, allowing former employees to stay on as robot co-designers and
maintainers, i.e. as co-programmers who supervise the machine learning
processes with the use of tailored high-level RPA Domain Specific Languages
(DSLs) to adjust the functioning of the robots and maintain operational
flexibility.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1811.00506v1,2018-11-01T17:20:03Z,2018-11-01T17:20:03Z,Navigation by Imitation in a Pedestrian-Rich Environment,"Deep neural networks trained on demonstrations of human actions give robot
the ability to perform self-driving on the road. However, navigation in a
pedestrian-rich environment, such as a campus setup, is still challenging---one
needs to take frequent interventions to the robot and take control over the
robot from early steps leading to a mistake. An arduous burden is, hence,
placed on the learning framework design and data acquisition. In this paper, we
propose a new learning-from-intervention Dataset Aggregation (DAgger) algorithm
to overcome the limitations brought by applying imitation learning to
navigation in the pedestrian-rich environment. Our new learning algorithm
implements an error backtrack function that is able to effectively learn from
expert interventions. Combining our new learning algorithm with deep
convolutional neural networks and a hierarchically-nested policy-selection
mechanism, we show that our robot is able to map pixels direct to control
commands and navigate successfully in real world without explicitly modeling
the pedestrian behaviors or the world model.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.12541v1,2018-10-30T06:19:58Z,2018-10-30T06:19:58Z,"Robots Learn Social Skills: End-to-End Learning of Co-Speech Gesture
  Generation for Humanoid Robots","Co-speech gestures enhance interaction experiences between humans as well as
between humans and robots. Existing robots use rule-based speech-gesture
association, but this requires human labor and prior knowledge of experts to be
implemented. We present a learning-based co-speech gesture generation that is
learned from 52 h of TED talks. The proposed end-to-end neural network model
consists of an encoder for speech text understanding and a decoder to generate
a sequence of gestures. The model successfully produces various gestures
including iconic, metaphoric, deictic, and beat gestures. In a subjective
evaluation, participants reported that the gestures were human-like and matched
the speech content. We also demonstrate a co-speech gesture with a NAO robot
working in real time.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.10191v2,2019-03-08T03:52:36Z,2018-10-24T05:21:22Z,"Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal
  Representations for Contact-Rich Tasks","Contact-rich manipulation tasks in unstructured environments often require
both haptic and visual feedback. However, it is non-trivial to manually design
a robot controller that combines modalities with very different
characteristics. While deep reinforcement learning has shown success in
learning control policies for high-dimensional inputs, these algorithms are
generally intractable to deploy on real robots due to sample complexity. We use
self-supervision to learn a compact and multimodal representation of our
sensory inputs, which can then be used to improve the sample efficiency of our
policy learning. We evaluate our method on a peg insertion task, generalizing
over different geometry, configurations, and clearances, while being robust to
external perturbations. Results for simulated and real robot experiments are
presented.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.08395v1,2018-10-19T08:29:25Z,2018-10-19T08:29:25Z,NimbRo-OP2X: Adult-sized Open-source 3D Printed Humanoid Robot,"Humanoid robotics research depends on capable robot platforms, but recently
developed advanced platforms are often not available to other research groups,
expensive, dangerous to operate, or closed-source. The lack of available
platforms forces researchers to work with smaller robots, which have less
strict dynamic constraints or with simulations, which lack many real-world
effects. We developed NimbRo-OP2X to address this need. At a height of 135 cm
our robot is large enough to interact in a human environment. Its low weight of
only 19 kg makes the operation of the robot safe and easy, as no special
operational equipment is necessary. Our robot is equipped with a fast onboard
computer and a GPU to accelerate parallel computations. We extend our already
open-source software by a deep-learning based vision system and gait parameter
optimisation. The NimbRo-OP2X was evaluated during RoboCup 2018 in Montr\'eal,
Canada, where it won all possible awards in the Humanoid AdultSize class.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.07167v1,2018-10-16T17:49:43Z,2018-10-16T17:49:43Z,"Composable Action-Conditioned Predictors: Flexible Off-Policy Learning
  for Robot Navigation","A general-purpose intelligent robot must be able to learn autonomously and be
able to accomplish multiple tasks in order to be deployed in the real world.
However, standard reinforcement learning approaches learn separate
task-specific policies and assume the reward function for each task is known a
priori. We propose a framework that learns event cues from off-policy data, and
can flexibly combine these event cues at test time to accomplish different
tasks. These event cue labels are not assumed to be known a priori, but are
instead labeled using learned models, such as computer vision detectors, and
then `backed up' in time using an action-conditioned predictive model. We show
that a simulated robotic car and a real-world RC car can gather data and train
fully autonomously without any human-provided labels beyond those needed to
train the detectors, and then at test-time be able to accomplish a variety of
different tasks. Videos of the experiments and code can be found at
https://github.com/gkahn13/CAPs",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.06637v2,2019-05-02T15:03:20Z,2018-10-15T19:46:00Z,"Nonlinear System Identification of Soft Robot Dynamics Using Koopman
  Operator Theory","Soft robots are challenging to model due in large part to the nonlinear
properties of soft materials. Fortunately, this softness makes it possible to
safely observe their behavior under random control inputs, making them amenable
to large-scale data collection and system identification. This paper implements
and evaluates a system identification method based on Koopman operator theory
in which models of nonlinear dynamical systems are constructed via linear
regression of observed data by exploiting the fact that every nonlinear system
has a linear representation in the infinite-dimensional space of real-valued
functions called observables. The approach does not suffer from some of the
shortcomings of other nonlinear system identification methods, which typically
require the manual tuning of training parameters and have limited convergence
guarantees. A dynamic model of a pneumatic soft robot arm is constructed via
this method, and used to predict the behavior of the real system. The total
normalized-root-mean-square error (NRMSE) of its predictions is lower than that
of several other identified models including a neural network, NLARX, nonlinear
Hammerstein-Wiener, and linear state space model.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.05726v3,2019-02-14T11:20:57Z,2018-10-09T05:53:26Z,DeepWeeds: A Multiclass Weed Species Image Dataset for Deep Learning,"Robotic weed control has seen increased research of late with its potential
for boosting productivity in agriculture. Majority of works focus on developing
robotics for croplands, ignoring the weed management problems facing rangeland
stock farmers. Perhaps the greatest obstacle to widespread uptake of robotic
weed control is the robust classification of weed species in their natural
environment. The unparalleled successes of deep learning make it an ideal
candidate for recognising various weed species in the complex rangeland
environment. This work contributes the first large, public, multiclass image
dataset of weed species from the Australian rangelands; allowing for the
development of robust classification methods to make robotic weed control
viable. The DeepWeeds dataset consists of 17,509 labelled images of eight
nationally significant weed species native to eight locations across northern
Australia. This paper presents a baseline for classification performance on the
dataset using the benchmark deep learning models, Inception-v3 and ResNet-50.
These models achieved an average classification accuracy of 95.1% and 95.7%,
respectively. We also demonstrate real time performance of the ResNet-50
architecture, with an average inference time of 53.4 ms per image. These strong
results bode well for future field implementation of robotic weed control
methods in the Australian rangelands.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.02422v3,2021-01-27T21:59:18Z,2018-10-04T20:59:35Z,"Simulator Predictive Control: Using Learned Task Representations and MPC
  for Zero-Shot Generalization and Sequencing","Simulation-to-real transfer is an important strategy for making reinforcement
learning practical with real robots. Successful sim-to-real transfer systems
have difficulty producing policies which generalize across tasks, despite
training for thousands of hours equivalent real robot time. To address this
shortcoming, we present a novel approach to efficiently learning new robotic
skills directly on a real robot, based on model-predictive control (MPC) and an
algorithm for learning task representations. In short, we show how to reuse the
simulation from the pre-training step of sim-to-real methods as a tool for
foresight, allowing the sim-to-real policy adapt to unseen tasks. Rather than
end-to-end learning policies for single tasks and attempting to transfer them,
we first use simulation to simultaneously learn (1) a continuous
parameterization (i.e. a skill embedding or latent) of task-appropriate
primitive skills, and (2) a single policy for these skills which is conditioned
on this representation. We then directly transfer our multi-skill policy to a
real robot, and actuate the robot by choosing sequences of skill latents which
actuate the policy, with each latent corresponding to a pre-learned primitive
skill controller. We complete unseen tasks by choosing new sequences of skill
latents to control the robot using MPC, where our MPC model is composed of the
pre-trained skill policy executed in the simulation environment, run in
parallel with the real robot. We discuss the background and principles of our
method, detail its practical implementation, and evaluate its performance by
using our method to train a real Sawyer Robot to achieve motion tasks such as
drawing and block pushing.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1810.01977v1,2018-10-03T21:12:28Z,2018-10-03T21:12:28Z,"Reinforcement Learning Meets Hybrid Zero Dynamics: A Case Study for
  RABBIT","The design of feedback controllers for bipedal robots is challenging due to
the hybrid nature of its dynamics and the complexity imposed by
high-dimensional bipedal models. In this paper, we present a novel approach for
the design of feedback controllers using Reinforcement Learning (RL) and Hybrid
Zero Dynamics (HZD). Existing RL approaches for bipedal walking are inefficient
as they do not consider the underlying physics, often requires substantial
training, and the resulting controller may not be applicable to real robots.
HZD is a powerful tool for bipedal control with local stability guarantees of
the walking limit cycles. In this paper, we propose a non traditional RL
structure that embeds the HZD framework into the policy learning. More
specifically, we propose to use RL to find a control policy that maps from the
robot's reduced order states to a set of parameters that define the desired
trajectories for the robot's joints through the virtual constraints. Then,
these trajectories are tracked using an adaptive PD controller. The method
results in a stable and robust control policy that is able to track variable
speed within a continuous interval. Robustness of the policy is evaluated by
applying external forces to the torso of the robot. The proposed RL framework
is implemented and demonstrated in OpenAI Gym with the MuJoCo physics engine
based on the well-known RABBIT robot model.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.09759v2,2019-02-15T10:08:16Z,2018-09-25T23:45:14Z,"Fast and Continuous Foothold Adaptation for Dynamic Locomotion through
  CNNs","Legged robots can outperform wheeled machines for most navigation tasks
across unknown and rough terrains. For such tasks, visual feedback is a
fundamental asset to provide robots with terrain-awareness. However, robust
dynamic locomotion on difficult terrains with real-time performance guarantees
remains a challenge. We present here a real-time, dynamic foothold adaptation
strategy based on visual feedback. Our method adjusts the landing position of
the feet in a fully reactive manner, using only on-board computers and sensors.
The correction is computed and executed continuously along the swing phase
trajectory of each leg. To efficiently adapt the landing position, we implement
a self-supervised foothold classifier based on a Convolutional Neural Network
(CNN). Our method results in an up to 200 times faster computation with respect
to the full-blown heuristics. Our goal is to react to visual stimuli from the
environment, bridging the gap between blind reactive locomotion and purely
vision-based planning strategies. We assess the performance of our method on
the dynamic quadruped robot HyQ, executing static and dynamic gaits (at speeds
up to 0.5 m/s) in both simulated and real scenarios; the benefit of safe
foothold adaptation is clearly demonstrated by the overall robot behavior.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.07731v1,2018-09-20T16:46:04Z,2018-09-20T16:46:04Z,Benchmarking Reinforcement Learning Algorithms on Real-World Robots,"Through many recent successes in simulation, model-free reinforcement
learning has emerged as a promising approach to solving continuous control
robotic tasks. The research community is now able to reproduce, analyze and
build quickly on these results due to open source implementations of learning
algorithms and simulated benchmark tasks. To carry forward these successes to
real-world applications, it is crucial to withhold utilizing the unique
advantages of simulations that do not transfer to the real world and experiment
directly with physical robots. However, reinforcement learning research with
physical robots faces substantial resistance due to the lack of benchmark tasks
and supporting source code. In this work, we introduce several reinforcement
learning tasks with multiple commercially available robots that present varying
levels of learning difficulty, setup, and repeatability. On these tasks, we
test the learning performance of off-the-shelf implementations of four
reinforcement learning algorithms and analyze sensitivity to their
hyper-parameters to determine their readiness for applications in various
real-world tasks. Our results show that with a careful setup of the task
interface and computations, some of these implementations can be readily
applicable to physical robots. We find that state-of-the-art learning
algorithms are highly sensitive to their hyper-parameters and their relative
ordering does not transfer across tasks, indicating the necessity of re-tuning
them for each task for best performance. On the other hand, the best
hyper-parameter configuration from one task may often result in effective
learning on held-out tasks even with different robots, providing a reasonable
default. We make the benchmark tasks publicly available to enhance
reproducibility in real-world reinforcement learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.07480v2,2019-10-09T00:21:04Z,2018-09-20T05:09:00Z,Sim-to-Real Transfer of Robot Learning with Variable Length Inputs,"Current end-to-end deep Reinforcement Learning (RL) approaches require
jointly learning perception, decision-making and low-level control from very
sparse reward signals and high-dimensional inputs, with little capability of
incorporating prior knowledge. This results in prohibitively long training
times for use on real-world robotic tasks. Existing algorithms capable of
extracting task-level representations from high-dimensional inputs, e.g. object
detection, often produce outputs of varying lengths, restricting their use in
RL methods due to the need for neural networks to have fixed length inputs. In
this work, we propose a framework that combines deep sets encoding, which
allows for variable-length abstract representations, with modular RL that
utilizes these representations, decoupling high-level decision making from
low-level control. We successfully demonstrate our approach on the robot
manipulation task of object sorting, showing that this method can learn
effective policies within mere minutes of highly simplified simulation. The
learned policies can be directly deployed on a robot without further training,
and generalize to variations of the task unseen during training.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.06716v1,2018-09-16T07:58:09Z,2018-09-16T07:58:09Z,A Fog Robotic System for Dynamic Visual Servoing,"Cloud Robotics is a paradigm where distributed robots are connected to cloud
services via networks to access unlimited computation power, at the cost of
network communication. However, due to limitations such as network latency and
variability, it is difficult to control dynamic, human compliant service robots
directly from the cloud. In this work, by leveraging asynchronous protocol with
a heartbeat signal, we combine cloud robotics with a smart edge device to build
a Fog Robotic system. We use the system to enable robust teleoperation of a
dynamic self-balancing robot from the cloud. We first use the system to pick up
boxes from static locations, a task commonly performed in warehouse logistics.
To make cloud teleoperation more efficient, we deploy image based visual
servoing (IBVS) to perform box pickups automatically. Visual feedbacks,
including apriltag recognition and tracking, are performed in the cloud to
emulate a Fog Robotic object recognition system for IBVS. We demonstrate the
feasibility of real-time dynamic automation system using this cloud-edge
hybrid, which opens up possibilities of deploying dynamic robotic control with
deep-learning recognition systems in Fog Robotics. Finally, we show that Fog
Robotics enables the self-balancing service robot to pick up a box
automatically from a person under unstructured environments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.06244v2,2019-01-25T11:15:56Z,2018-09-14T14:29:47Z,"A Virtual Testbed for Critical Incident Investigation with Autonomous
  Remote Aerial Vehicle Surveying, Artificial Intelligence, and Decision
  Support","Autonomous robotics and artificial intelligence techniques can be used to
support human personnel in the event of critical incidents. These incidents can
pose great danger to human life. Some examples of such assistance include:
multi-robot surveying of the scene; collection of sensor data and scene
imagery, real-time risk assessment and analysis; object identification and
anomaly detection; and retrieval of relevant supporting documentation such as
standard operating procedures (SOPs). These incidents, although often rare, can
involve chemical, biological, radiological/nuclear or explosive (CBRNE)
substances and can be of high consequence. Real-world training and deployment
of these systems can be costly and sometimes not feasible. For this reason, we
have developed a realistic 3D model of a CBRNE scenario to act as a testbed for
an initial set of assisting AI tools that we have developed.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.04766v2,2019-02-27T05:53:59Z,2018-09-13T04:19:26Z,"Real-Time Joint Semantic Segmentation and Depth Estimation Using
  Asymmetric Annotations","Deployment of deep learning models in robotics as sensory information
extractors can be a daunting task to handle, even using generic GPU cards.
Here, we address three of its most prominent hurdles, namely, i) the adaptation
of a single model to perform multiple tasks at once (in this work, we consider
depth estimation and semantic segmentation crucial for acquiring geometric and
semantic understanding of the scene), while ii) doing it in real-time, and iii)
using asymmetric datasets with uneven numbers of annotations per each modality.
To overcome the first two issues, we adapt a recently proposed real-time
semantic segmentation network, making changes to further reduce the number of
floating point operations. To approach the third issue, we embrace a simple
solution based on hard knowledge distillation under the assumption of having
access to a powerful `teacher' network. We showcase how our system can be
easily extended to handle more tasks, and more datasets, all at once,
performing depth estimation and segmentation both indoors and outdoors with a
single model. Quantitatively, we achieve results equivalent to (or better than)
current state-of-the-art approaches with one forward pass costing just 13ms and
6.5 GFLOPs on 640x480 inputs. This efficiency allows us to directly incorporate
the raw predictions of our network into the SemanticFusion framework for dense
3D semantic reconstruction of the scene.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1809.03548v2,2018-09-14T11:39:07Z,2018-09-10T18:55:19Z,VPE: Variational Policy Embedding for Transfer Reinforcement Learning,"Reinforcement Learning methods are capable of solving complex problems, but
resulting policies might perform poorly in environments that are even slightly
different. In robotics especially, training and deployment conditions often
vary and data collection is expensive, making retraining undesirable.
Simulation training allows for feasible training times, but on the other hand
suffers from a reality-gap when applied in real-world settings. This raises the
need of efficient adaptation of policies acting in new environments. We
consider this as a problem of transferring knowledge within a family of similar
Markov decision processes.
  For this purpose we assume that Q-functions are generated by some
low-dimensional latent variable. Given such a Q-function, we can find a master
policy that can adapt given different values of this latent variable. Our
method learns both the generative mapping and an approximate posterior of the
latent variables, enabling identification of policies for new tasks by
searching only in the latent space, rather than the space of all policies. The
low-dimensional space, and master policy found by our method enables policies
to quickly adapt to new environments. We demonstrate the method on both a
pendulum swing-up task in simulation, and for simulation-to-real transfer on a
pushing task.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.07921v3,2019-04-19T19:02:53Z,2018-08-23T19:49:53Z,"SOTER: A Runtime Assurance Framework for Programming Safe Robotics
  Systems","The recent drive towards achieving greater autonomy and intelligence in
robotics has led to high levels of complexity. Autonomous robots increasingly
depend on third party off-the-shelf components and complex machine-learning
techniques. This trend makes it challenging to provide strong design-time
certification of correct operation.
  To address these challenges, we present SOTER, a robotics programming
framework with two key components: (1) a programming language for implementing
and testing high-level reactive robotics software and (2) an integrated runtime
assurance (RTA) system that helps enable the use of uncertified components,
while still providing safety guarantees. SOTER provides language primitives to
declaratively construct a RTA module consisting of an advanced,
high-performance controller (uncertified), a safe, lower-performance controller
(certified), and the desired safety specification. The framework provides a
formal guarantee that a well-formed RTA module always satisfies the safety
specification, without completely sacrificing performance by using higher
performance uncertified components whenever safe. SOTER allows the complex
robotics software stack to be constructed as a composition of RTA modules,
where each uncertified component is protected using a RTA module.
  To demonstrate the efficacy of our framework, we consider a real-world
case-study of building a safe drone surveillance system. Our experiments both
in simulation and on actual drones show that the SOTER-enabled RTA ensures the
safety of the system, including when untrusted third-party components have bugs
or deviate from the desired behavior.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.07692v1,2018-08-23T10:44:35Z,2018-08-23T10:44:35Z,"A Directionally Selective Neural Network with Separated ON and OFF
  Pathways for Translational Motion Perception in a Visually Cluttered
  Environment","With respect to biological findings underlying fly's physiology in the past
decade, we present a directionally selective neural network, with a
feed-forward structure and entirely low-level visual processing, so as to
implement direction selective neurons in the fly's visual system, which are
mainly sensitive to wide-field translational movements in four cardinal
directions. In this research, we highlight the functionality of ON and OFF
pathways, separating motion information for parallel computation corresponding
to light-on and light-off selectivity. Through this modeling study, we
demonstrate several achievements compared with former bio-plausible
translational motion detectors, like the elementary motion detectors. First, we
thoroughly mimic the fly's preliminary motion-detecting pathways with newly
revealed fly's physiology. Second, we improve the speed response to moving
dark/light features via the design of ensembles of same polarity cells in the
dual-pathways. Moreover, we alleviate the impact of irrelevant motion in a
visually cluttered environment like the shifting of background and windblown
vegetation, via the modeling of spatiotemporal dynamics. We systematically
tested the DSNN against stimuli ranging from synthetic and real-world scenes,
to notably a visual modality of a ground micro robot. The results demonstrated
that the DSNN outperforms former bio-plausible translational motion detectors.
Importantly, we verified its computational simplicity and effectiveness
benefiting the building of neuromorphic vision sensor for robots.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.06352v1,2018-08-20T09:06:21Z,2018-08-20T09:06:21Z,"Navigating the Landscape for Real-time Localisation and Mapping for
  Robotics and Virtual and Augmented Reality","Visual understanding of 3D environments in real-time, at low power, is a huge
computational challenge. Often referred to as SLAM (Simultaneous Localisation
and Mapping), it is central to applications spanning domestic and industrial
robotics, autonomous vehicles, virtual and augmented reality. This paper
describes the results of a major research effort to assemble the algorithms,
architectures, tools, and systems software needed to enable delivery of SLAM,
by supporting applications specialists in selecting and configuring the
appropriate algorithm and the appropriate hardware, and compilation pathway, to
meet their performance, accuracy, and energy consumption goals. The major
contributions we present are (1) tools and methodology for systematic
quantitative evaluation of SLAM algorithms, (2) automated,
machine-learning-guided exploration of the algorithmic and implementation
design space with respect to multiple objectives, (3) end-to-end simulation
tools to enable optimisation of heterogeneous, accelerated architectures for
the specific algorithmic requirements of the various SLAM algorithmic
approaches, and (4) tools for delivering, where appropriate, accelerated,
adaptive SLAM solutions in a managed, JIT-compiled, adaptive runtime context.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.03841v1,2018-08-11T17:33:40Z,2018-08-11T17:33:40Z,"Fully Distributed Multi-Robot Collision Avoidance via Deep Reinforcement
  Learning for Safe and Efficient Navigation in Complex Scenarios","In this paper, we present a decentralized sensor-level collision avoidance
policy for multi-robot systems, which shows promising results in practical
applications. In particular, our policy directly maps raw sensor measurements
to an agent's steering commands in terms of the movement velocity. As a first
step toward reducing the performance gap between decentralized and centralized
methods, we present a multi-scenario multi-stage training framework to learn an
optimal policy. The policy is trained over a large number of robots in rich,
complex environments simultaneously using a policy gradient based reinforcement
learning algorithm. The learning algorithm is also integrated into a hybrid
control framework to further improve the policy's robustness and effectiveness.
  We validate the learned sensor-level collision avoidance policy in a variety
of simulated and real-world scenarios with thorough performance evaluations for
large-scale multi-robot systems. The generalization of the learned policy is
verified in a set of unseen scenarios including the navigation of a group of
heterogeneous robots and a large-scale scenario with 100 robots. Although the
policy is trained using simulation data only, we have successfully deployed it
on physical robots with shapes and dynamics characteristics that are different
from the simulated agents, in order to demonstrate the controller's robustness
against the sim-to-real modeling error. Finally, we show that the
collision-avoidance policy learned from multi-robot navigation tasks provides
an excellent solution to the safe and effective autonomous navigation for a
single robot working in a dense real human crowd. Our learned policy enables a
robot to make effective progress in a crowd without getting stuck. Videos are
available at https://sites.google.com/view/hybridmrca",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1808.03405v2,2019-02-12T09:20:10Z,2018-08-10T04:04:19Z,"End-to-end Active Object Tracking and Its Real-world Deployment via
  Reinforcement Learning","We study active object tracking, where a tracker takes visual observations
(i.e., frame sequences) as input and produces the corresponding camera control
signals as output (e.g., move forward, turn left, etc.). Conventional methods
tackle tracking and camera control tasks separately, and the resulting system
is difficult to tune jointly. These methods also require significant human
efforts for image labeling and expensive trial-and-error system tuning in the
real world. To address these issues, we propose, in this paper, an end-to-end
solution via deep reinforcement learning. A ConvNet-LSTM function approximator
is adopted for the direct frame-to-action prediction. We further propose an
environment augmentation technique and a customized reward function, which are
crucial for successful training. The tracker trained in simulators (ViZDoom and
Unreal Engine) demonstrates good generalization behaviors in the case of unseen
object moving paths, unseen object appearances, unseen backgrounds, and
distracting objects. The system is robust and can restore tracking after
occasional lost of the target being tracked. We also find that the tracking
ability, obtained solely from simulators, can potentially transfer to
real-world scenarios. We demonstrate successful examples of such transfer, via
experiments over the VOT dataset and the deployment of a real-world robot using
the proposed active tracker trained in simulation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.11249v1,2018-07-30T09:27:14Z,2018-07-30T09:27:14Z,Modular Sensor Fusion for Semantic Segmentation,"Sensor fusion is a fundamental process in robotic systems as it extends the
perceptual range and increases robustness in real-world operations. Current
multi-sensor deep learning based semantic segmentation approaches do not
provide robustness to under-performing classes in one modality, or require a
specific architecture with access to the full aligned multi-sensor training
data. In this work, we analyze statistical fusion approaches for semantic
segmentation that overcome these drawbacks while keeping a competitive
performance. The studied approaches are modular by construction, allowing to
have different training sets per modality and only a much smaller subset is
needed to calibrate the statistical models. We evaluate a range of statistical
fusion approaches and report their performance against state-of-the-art
baselines on both real-world and simulated data. In our experiments, the
approach improves performance in IoU over the best single modality segmentation
results by up to 5%. We make all implementations and configurations publicly
available.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.11150v1,2018-07-30T02:39:10Z,2018-07-30T02:39:10Z,"Learning to Interrupt: A Hierarchical Deep Reinforcement Learning
  Framework for Efficient Exploration","To achieve scenario intelligence, humans must transfer knowledge to robots by
developing goal-oriented algorithms, which are sometimes insensitive to
dynamically changing environments. While deep reinforcement learning achieves
significant success recently, it is still extremely difficult to be deployed in
real robots directly. In this paper, we propose a hybrid structure named
Option-Interruption in which human knowledge is embedded into a hierarchical
reinforcement learning framework. Our architecture has two key components:
options, represented by existing human-designed methods, can significantly
speed up the training process and interruption mechanism, based on learnable
termination functions, enables our system to quickly respond to the external
environment. To implement this architecture, we derive a set of update rules
based on policy gradient methods and present a complete training process. In
the experiment part, our method is evaluated in Four-room navigation and
exploration task, which shows the efficiency and flexibility of our framework.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.08931v1,2018-07-24T07:16:54Z,2018-07-24T07:16:54Z,"CReaM: Condensed Real-time Models for Depth Prediction using
  Convolutional Neural Networks","Since the resurgence of CNNs the robotic vision community has developed a
range of algorithms that perform classification, semantic segmentation and
structure prediction (depths, normals, surface curvature) using neural
networks. While some of these models achieve state-of-the art results and super
human level performance, deploying these models in a time critical robotic
environment remains an ongoing challenge. Real-time frameworks are of paramount
importance to build a robotic society where humans and robots integrate
seamlessly. To this end, we present a novel real-time structure prediction
framework that predicts depth at 30fps on an NVIDIA-TX2. At the time of
writing, this is the first piece of work to showcase such a capability on a
mobile platform. We also demonstrate with extensive experiments that neural
networks with very large model capacities can be leveraged in order to train
accurate condensed model architectures in a ""from teacher to student"" style
knowledge transfer.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1807.05211v1,2018-07-11T11:05:12Z,2018-07-11T11:05:12Z,"Learning Deployable Navigation Policies at Kilometer Scale from a Single
  Traversal","Model-free reinforcement learning has recently been shown to be effective at
learning navigation policies from complex image input. However, these
algorithms tend to require large amounts of interaction with the environment,
which can be prohibitively costly to obtain on robots in the real world. We
present an approach for efficiently learning goal-directed navigation policies
on a mobile robot, from only a single coverage traversal of recorded data. The
navigation agent learns an effective policy over a diverse action space in a
large heterogeneous environment consisting of more than 2km of travel, through
buildings and outdoor regions that collectively exhibit large variations in
visual appearance, self-similarity, and connectivity. We compare pretrained
visual encoders that enable precomputation of visual embeddings to achieve a
throughput of tens of thousands of transitions per second at training time on a
commodity desktop computer, allowing agents to learn from millions of
trajectories of experience in a matter of hours. We propose multiple forms of
computationally efficient stochastic augmentation to enable the learned policy
to generalise beyond these precomputed embeddings, and demonstrate successful
deployment of the learned policy on the real robot without fine tuning, despite
environmental appearance differences at test time. The dataset and code
required to reproduce these results and apply the technique to other datasets
and robots is made publicly available at rl-navigation.github.io/deployable.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1806.11430v3,2018-07-31T10:31:36Z,2018-06-29T14:18:24Z,Towards real-time unsupervised monocular depth estimation on CPU,"Unsupervised depth estimation from a single image is a very attractive
technique with several implications in robotic, autonomous navigation,
augmented reality and so on. This topic represents a very challenging task and
the advent of deep learning enabled to tackle this problem with excellent
results. However, these architectures are extremely deep and complex. Thus,
real-time performance can be achieved only by leveraging power-hungry GPUs that
do not allow to infer depth maps in application fields characterized by
low-power constraints. To tackle this issue, in this paper we propose a novel
architecture capable to quickly infer an accurate depth map on a CPU, even of
an embedded system, using a pyramid of features extracted from a single input
image. Similarly to state-of-the-art, we train our network in an unsupervised
manner casting depth estimation as an image reconstruction problem. Extensive
experimental results on the KITTI dataset show that compared to the top
performing approach our network has similar accuracy but a much lower
complexity (about 6% of parameters) enabling to infer a depth map for a KITTI
image in about 1.7 s on the Raspberry Pi 3 and at more than 8 Hz on a standard
CPU. Moreover, by trading accuracy for efficiency, our network allows to infer
maps at about 2 Hz and 40 Hz respectively, still being more accurate than most
state-of-the-art slower methods. To the best of our knowledge, it is the first
method enabling such performance on CPUs paving the way for effective
deployment of unsupervised monocular depth estimation even on embedded systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1806.07851v2,2018-10-08T01:32:02Z,2018-06-20T17:22:12Z,Sim-to-Real Reinforcement Learning for Deformable Object Manipulation,"We have seen much recent progress in rigid object manipulation, but
interaction with deformable objects has notably lagged behind. Due to the large
configuration space of deformable objects, solutions using traditional
modelling approaches require significant engineering work. Perhaps then,
bypassing the need for explicit modelling and instead learning the control in
an end-to-end manner serves as a better approach? Despite the growing interest
in the use of end-to-end robot learning approaches, only a small amount of work
has focused on their applicability to deformable object manipulation. Moreover,
due to the large amount of data needed to learn these end-to-end solutions, an
emerging trend is to learn control policies in simulation and then transfer
them over to the real world. To-date, no work has explored whether it is
possible to learn and transfer deformable object policies. We believe that if
sim-to-real methods are to be employed further, then it should be possible to
learn to interact with a wide variety of objects, and not only rigid objects.
In this work, we use a combination of state-of-the-art deep reinforcement
learning algorithms to solve the problem of manipulating deformable objects
(specifically cloth). We evaluate our approach on three tasks --- folding a
towel up to a mark, folding a face towel diagonally, and draping a piece of
cloth over a hanger. Our agents are fully trained in simulation with domain
randomisation, and then successfully deployed in the real world without having
seen any real deformable objects.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1805.07708v1,2018-05-20T05:12:04Z,2018-05-20T05:12:04Z,A Lyapunov-based Approach to Safe Reinforcement Learning,"In many real-world reinforcement learning (RL) problems, besides optimizing
the main objective function, an agent must concurrently avoid violating a
number of constraints. In particular, besides optimizing performance it is
crucial to guarantee the safety of an agent during training as well as
deployment (e.g. a robot should avoid taking actions - exploratory or not -
which irrevocably harm its hardware). To incorporate safety in RL, we derive
algorithms under the framework of constrained Markov decision problems (CMDPs),
an extension of the standard Markov decision problems (MDPs) augmented with
constraints on expected cumulative costs. Our approach hinges on a novel
\emph{Lyapunov} method. We define and present a method for constructing
Lyapunov functions, which provide an effective way to guarantee the global
safety of a behavior policy during training via a set of local, linear
constraints. Leveraging these theoretical underpinnings, we show how to use the
Lyapunov approach to systematically transform dynamic programming (DP) and RL
algorithms into their safe counterparts. To illustrate their effectiveness, we
evaluate these algorithms in several CMDP planning and decision-making tasks on
a safety benchmark domain. Our results show that our proposed method
significantly outperforms existing baselines in balancing constraint
satisfaction and performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1805.01956v1,2018-05-04T22:45:08Z,2018-05-04T22:45:08Z,"Motion Planning Among Dynamic, Decision-Making Agents with Deep
  Reinforcement Learning","Robots that navigate among pedestrians use collision avoidance algorithms to
enable safe and efficient operation. Recent works present deep reinforcement
learning as a framework to model the complex interactions and cooperation.
However, they are implemented using key assumptions about other agents'
behavior that deviate from reality as the number of agents in the environment
increases. This work extends our previous approach to develop an algorithm that
learns collision avoidance among a variety of types of dynamic agents without
assuming they follow any particular behavior rules. This work also introduces a
strategy using LSTM that enables the algorithm to use observations of an
arbitrary number of other agents, instead of previous methods that have a fixed
observation size. The proposed algorithm outperforms our previous approach in
simulation as the number of agents increases, and the algorithm is demonstrated
on a fully autonomous robotic vehicle traveling at human walking speed, without
the use of a 3D Lidar.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1805.01831v4,2019-05-14T08:40:00Z,2018-05-04T15:47:33Z,A 64mW DNN-based Visual Navigation Engine for Autonomous Nano-Drones,"Fully-autonomous miniaturized robots (e.g., drones), with artificial
intelligence (AI) based visual navigation capabilities are extremely
challenging drivers of Internet-of-Things edge intelligence capabilities.
Visual navigation based on AI approaches, such as deep neural networks (DNNs)
are becoming pervasive for standard-size drones, but are considered out of
reach for nanodrones with size of a few cm${}^\mathrm{2}$. In this work, we
present the first (to the best of our knowledge) demonstration of a navigation
engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based
visual navigation. To achieve this goal we developed a complete methodology for
parallel execution of complex DNNs directly on-bard of resource-constrained
milliwatt-scale nodes. Our system is based on GAP8, a novel parallel
ultra-low-power computing platform, and a 27 g commercial, open-source
CrazyFlie 2.0 nano-quadrotor. As part of our general methodology we discuss the
software mapping techniques that enable the state-of-the-art deep convolutional
neural network presented in [1] to be fully executed on-board within a strict 6
fps real-time constraint with no compromise in terms of flight results, while
all processing is done with only 64 mW on average. Our navigation engine is
flexible and can be used to span a wide performance range: at its peak
performance corner it achieves 18 fps while still consuming on average just
3.5% of the power envelope of the deployed nano-aircraft.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.10332v2,2018-05-16T20:35:34Z,2018-04-27T03:42:55Z,Sim-to-Real: Learning Agile Locomotion For Quadruped Robots,"Designing agile locomotion for quadruped robots often requires extensive
expertise and tedious manual tuning. In this paper, we present a system to
automate this process by leveraging deep reinforcement learning techniques. Our
system can learn quadruped locomotion from scratch using simple reward signals.
In addition, users can provide an open loop reference to guide the learning
process when more control over the learned gait is needed. The control policies
are learned in a physics simulator and then deployed on real robots. In
robotics, policies trained in simulation often do not transfer to the real
world. We narrow this reality gap by improving the physics simulator and
learning robust policies. We improve the simulation using system
identification, developing an accurate actuator model and simulating latency.
We learn robust controllers by randomizing the physical environments, adding
perturbations and designing a compact observation space. We evaluate our system
on two agile locomotion gaits: trotting and galloping. After learning in
simulation, a quadruped robot can successfully perform both gaits in the real
world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.10134v2,2018-07-28T10:33:47Z,2018-04-26T16:04:30Z,Detection-Tracking for Efficient Person Analysis: The DetTA Pipeline,"In the past decade many robots were deployed in the wild, and people
detection and tracking is an important component of such deployments. On top of
that, one often needs to run modules which analyze persons and extract higher
level attributes such as age and gender, or dynamic information like gaze and
pose. The latter ones are especially necessary for building a reactive, social
robot-person interaction.
  In this paper, we combine those components in a fully modular
detection-tracking-analysis pipeline, called DetTA. We investigate the benefits
of such an integration on the example of head and skeleton pose, by using the
consistent track ID for a temporal filtering of the analysis modules'
observations, showing a slight improvement in a challenging real-world
scenario. We also study the potential of a so-called ""free-flight"" mode, where
the analysis of a person attribute only relies on the filter's predictions for
certain frames. Here, our study shows that this boosts the runtime
dramatically, while the prediction quality remains stable. This insight is
especially important for reducing power consumption and sharing precious
(GPU-)memory when running many analysis components on a mobile platform,
especially so in the era of expensive deep learning methods.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.09364v3,2018-12-13T15:42:35Z,2018-04-25T06:20:12Z,Driving Policy Transfer via Modularity and Abstraction,"End-to-end approaches to autonomous driving have high sample complexity and
are difficult to scale to realistic urban driving. Simulation can help
end-to-end driving systems by providing a cheap, safe, and diverse training
environment. Yet training driving policies in simulation brings up the problem
of transferring such policies to the real world. We present an approach to
transferring driving policies from simulation to reality via modularity and
abstraction. Our approach is inspired by classic driving systems and aims to
combine the benefits of modular architectures and end-to-end deep learning
approaches. The key idea is to encapsulate the driving policy such that it is
not directly exposed to raw perceptual input or low-level vehicle dynamics. We
evaluate the presented approach in simulated urban environments and in the real
world. In particular, we transfer a driving policy trained in simulation to a
1/5-scale robotic truck that is deployed in a variety of conditions, with no
finetuning, on two continents. The supplementary video can be viewed at
https://youtu.be/BrMDJqI6H5U",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.03547v3,2022-03-24T11:04:37Z,2018-04-10T14:07:45Z,"A real-time and unsupervised face Re-Identification system for
  Human-Robot Interaction","In the context of Human-Robot Interaction (HRI), face Re-Identification (face
Re-ID) aims to verify if certain detected faces have already been observed by
robots. The ability of distinguishing between different users is crucial in
social robots as it will enable the robot to tailor the interaction strategy
toward the users' individual preferences. So far face recognition research has
achieved great success, however little attention has been paid to the realistic
applications of Face Re-ID in social robots. In this paper, we present an
effective and unsupervised face Re-ID system which simultaneously re-identifies
multiple faces for HRI. This Re-ID system employs Deep Convolutional Neural
Networks to extract features, and an online clustering algorithm to determine
the face's ID. Its performance is evaluated on two datasets: the TERESA video
dataset collected by the TERESA robot, and the YouTube Face Dataset (YTF
Dataset). We demonstrate that the optimised combination of techniques achieves
an overall 93.55% accuracy on TERESA dataset and an overall 90.41% accuracy on
YTF dataset. We have implemented the proposed method into a software module in
the HCI^2 Framework for it to be further integrated into the TERESA robot, and
has achieved real-time performance at 10~26 Frames per second.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.03289v1,2018-04-10T00:44:29Z,2018-04-10T00:44:29Z,"Planning Multi-Fingered Grasps as Probabilistic Inference in a Learned
  Deep Network","We propose a novel approach to multi-fingered grasp planning leveraging
learned deep neural network models. We train a convolutional neural network to
predict grasp success as a function of both visual information of an object and
grasp configuration. We can then formulate grasp planning as inferring the
grasp configuration which maximizes the probability of grasp success. We
efficiently perform this inference using a gradient-ascent optimization inside
the neural network using the backpropagation algorithm. Our work is the first
to directly plan high quality multifingered grasps in configuration space using
a deep neural network without the need of an external planner. We validate our
inference method performing both multifinger and two-finger grasps on real
robots. Our experimental results show that our planning method outperforms
existing planning methods for neural networks; while offering several other
benefits including being data-efficient in learning and fast enough to be
deployed in real robotic applications.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.02395v2,2018-06-12T14:52:29Z,2018-04-06T15:25:14Z,"Structured Evolution with Compact Architectures for Scalable Policy
  Optimization","We present a new method of blackbox optimization via gradient approximation
with the use of structured random orthogonal matrices, providing more accurate
estimators than baselines and with provable theoretical guarantees. We show
that this algorithm can be successfully applied to learn better quality compact
policies than those using standard gradient estimation techniques. The compact
policies we learn have several advantages over unstructured ones, including
faster training algorithms and faster inference. These benefits are important
when the policy is deployed on real hardware with limited resources. Further,
compact policies provide more scalable architectures for derivative-free
optimization (DFO) in high-dimensional spaces. We show that most robotics tasks
from the OpenAI Gym can be solved using neural networks with less than 300
parameters, with almost linear time complexity of the inference phase, with up
to 13x fewer parameters relative to the Evolution Strategies (ES) algorithm
introduced by Salimans et al. (2017). We do not need heuristics such as fitness
shaping to learn good quality policies, resulting in a simple and theoretically
motivated training mechanism.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1804.00736v1,2018-04-02T21:38:56Z,2018-04-02T21:38:56Z,"Deep Spatiotemporal Models for Robust Proprioceptive Terrain
  Classification","Terrain classification is a critical component of any autonomous mobile robot
system operating in unknown real-world environments. Over the years, several
proprioceptive terrain classification techniques have been introduced to
increase robustness or act as a fallback for traditional vision based
approaches. However, they lack widespread adaptation due to various factors
that include inadequate accuracy, robustness and slow run-times. In this paper,
we use vehicle-terrain interaction sounds as a proprioceptive modality and
propose a deep Long-Short Term Memory (LSTM) based recurrent model that
captures both the spatial and temporal dynamics of such a problem, thereby
overcoming these past limitations. Our model consists of a new Convolution
Neural Network (CNN) architecture that learns deep spatial features,
complemented with LSTM units that learn complex temporal dynamics. Experiments
on two extensive datasets collected with different microphones on various
indoor and outdoor terrains demonstrate state-of-the-art performance compared
to existing techniques. We additionally evaluate the performance in adverse
acoustic conditions with high ambient noise and propose a noise-aware training
scheme that enables learning of more generalizable models that are essential
for robust real-world deployments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.08554v1,2018-03-22T19:23:32Z,2018-03-22T19:23:32Z,Neuronal Circuit Policies,"We propose an effective way to create interpretable control agents, by
re-purposing the function of a biological neural circuit model, to govern
simulated and real world reinforcement learning (RL) test-beds. We model the
tap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit
responsible for the worm's reflexive response to external mechanical touch
stimulations, and learn its synaptic and neuronal parameters as a policy for
controlling basic RL tasks. We also autonomously park a real rover robot on a
pre-defined trajectory, by deploying such neuronal circuit policies learned in
a simulated environment. For reconfiguration of the purpose of the TW neural
circuit, we adopt a search-based RL algorithm. We show that our neuronal
policies perform as good as deep neural network policies with the advantage of
realizing interpretable dynamics at the cell level.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.08501v1,2018-03-22T14:59:16Z,2018-03-22T14:59:16Z,DOP: Deep Optimistic Planning with Approximate Value Function Evaluation,"Research on reinforcement learning has demonstrated promising results in
manifold applications and domains. Still, efficiently learning effective robot
behaviors is very difficult, due to unstructured scenarios, high uncertainties,
and large state dimensionality (e.g. multi-agent systems or hyper-redundant
robots). To alleviate this problem, we present DOP, a deep model-based
reinforcement learning algorithm, which exploits action values to both (1)
guide the exploration of the state space and (2) plan effective policies.
Specifically, we exploit deep neural networks to learn Q-functions that are
used to attack the curse of dimensionality during a Monte-Carlo tree search.
Our algorithm, in fact, constructs upper confidence bounds on the learned value
function to select actions optimistically. We implement and evaluate DOP on
different scenarios: (1) a cooperative navigation problem, (2) a fetching task
for a 7-DOF KUKA robot, and (3) a human-robot handover with a humanoid robot
(both in simulation and real). The obtained results show the effectiveness of
DOP in the chosen applications, where action values drive the exploration and
reduce the computational demand of the planning process while achieving good
performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.04873v2,2018-03-14T15:30:00Z,2018-03-13T15:17:30Z,"Using Convolutional Neural Networks for Determining Reticulocyte
  Percentage in Cats","Recent advances in artificial intelligence (AI), specifically in computer
vision (CV) and deep learning (DL), have created opportunities for novel
systems in many fields. In the last few years, deep learning applications have
demonstrated impressive results not only in fields such as autonomous driving
and robotics, but also in the field of medicine, where they have, in some
cases, even exceeded human-level performance. However, despite the huge
potential, adoption of deep learning-based methods is still slow in many areas,
especially in veterinary medicine, where we haven't been able to find any
research papers using modern convolutional neural networks (CNNs) in medical
image processing. We believe that using deep learning-based medical imaging can
enable more accurate, faster and less expensive diagnoses in veterinary
medicine. In order to do so, however, these methods have to be accessible to
everyone in this field, not just to computer scientists. To show the potential
of this technology, we present results on a real-world task in veterinary
medicine that is usually done manually: feline reticulocyte percentage. Using
an open source Keras implementation of the Single-Shot MultiBox Detector (SSD)
model architecture and training it on only 800 labeled images, we achieve an
accuracy of 98.7% at predicting the correct number of aggregate reticulocytes
in microscope images of cat blood smears. The main motivation behind this paper
is to show not only that deep learning can approach or even exceed human-level
performance on a task like this, but also that anyone in the field can
implement it, even without a background in computer science.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1803.02665v4,2018-09-25T09:00:03Z,2018-03-07T14:16:59Z,"A Neural Network Approach to Missing Marker Reconstruction in Human
  Motion Capture","Optical motion capture systems have become a widely used technology in
various fields, such as augmented reality, robotics, movie production, etc.
Such systems use a large number of cameras to triangulate the position of
optical markers.The marker positions are estimated with high accuracy. However,
especially when tracking articulated bodies, a fraction of the markers in each
timestep is missing from the reconstruction. In this paper, we propose to use a
neural network approach to learn how human motion is temporally and spatially
correlated, and reconstruct missing markers positions through this model. We
experiment with two different models, one LSTM-based and one time-window-based.
Both methods produce state-of-the-art results, while working online, as opposed
to most of the alternative methods, which require the complete sequence to be
known. The implementation is publicly available at
https://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction .",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.10408v3,2018-09-24T20:22:52Z,2018-02-28T13:49:18Z,"A Neurorobotic Experiment for Crossmodal Conflict Resolution in Complex
  Environments","Crossmodal conflict resolution is crucial for robot sensorimotor coupling
through the interaction with the environment, yielding swift and robust
behaviour also in noisy conditions. In this paper, we propose a neurorobotic
experiment in which an iCub robot exhibits human-like responses in a complex
crossmodal environment. To better understand how humans deal with multisensory
conflicts, we conducted a behavioural study exposing 33 subjects to congruent
and incongruent dynamic audio-visual cues. In contrast to previous studies
using simplified stimuli, we designed a scenario with four animated avatars and
observed that the magnitude and extension of the visual bias are related to the
semantics embedded in the scene, i.e., visual cues that are congruent with
environmental statistics (moving lips and vocalization) induce the strongest
bias. We implement a deep learning model that processes stereophonic sound,
facial features, and body motion to trigger a discrete behavioural response.
After training the model, we exposed the iCub to the same experimental
conditions as the human subjects, showing that the robot can replicate similar
responses in real time. Our interdisciplinary work provides important insights
into how crossmodal conflict resolution can be modelled in robots and
introduces future research directions for the efficient combination of sensory
observations with internally generated knowledge and expectations.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.08960v2,2019-02-01T17:08:34Z,2018-02-25T06:47:30Z,"Bonnet: An Open-Source Training and Deployment Framework for Semantic
  Segmentation in Robotics using CNNs","The ability to interpret a scene is an important capability for a robot that
is supposed to interact with its environment. The knowledge of what is in front
of the robot is, for example, relevant for navigation, manipulation, or
planning. Semantic segmentation labels each pixel of an image with a class
label and thus provides a detailed semantic annotation of the surroundings to
the robot. Convolutional neural networks (CNNs) are popular methods for
addressing this type of problem. The available software for training and the
integration of CNNs for real robots, however, is quite fragmented and often
difficult to use for non-experts, despite the availability of several
high-quality open-source frameworks for neural network implementation and
training. In this paper, we propose a tool called Bonnet, which addresses this
fragmentation problem by building a higher abstraction that is specific for the
semantic segmentation task. It provides a modular approach to simplify the
training of a semantic segmentation CNN independently of the used dataset and
the intended task. Furthermore, we also address the deployment on a real
robotic platform. Thus, we do not propose a new CNN approach in this paper.
Instead, we provide a stable and easy-to-use tool to make this technology more
approachable in the context of autonomous systems. In this sense, we aim at
closing a gap between computer vision research and its use in robotics
research. We provide an open-source codebase for training and deployment. The
training interface is implemented in Python using TensorFlow and the deployment
interface provides a C++ library that can be easily integrated in an existing
robotics codebase, a ROS node, and two standalone applications for label
prediction in images and videos.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.08857v2,2018-03-02T17:06:45Z,2018-02-24T14:54:13Z,Visual Manipulation Relationship Network,"Robotic grasping detection is one of the most important fields in robotics,
in which great progress has been made recent years with the help of
convolutional neural network (CNN). However, including multiple objects in one
scene can invalidate the existing CNN-based grasping detection algorithms,
because manipulation relationships among objects are not considered, which are
required to guide the robot to grasp things in the right order. This paper
presents a new CNN architecture called Visual Manipulation Relationship Network
(VMRN) to help robot detect targets and predict the manipulation relationships
in real time. To implement end-to-end training and meet real-time requirements
in robot tasks, we propose the Object Pairing Pooling Layer (OP2L) to help to
predict all manipulation relationships in one forward process. Moreover, in
order to train VMRN, we collect a dataset named Visual Manipulation
Relationship Dataset (VMRD) consisting of 5185 images with more than 17000
object instances and the manipulation relationships between all possible pairs
of objects in every image, which is labeled by the manipulation relationship
tree. The experimental results show that the new network architecture can
detect objects and predict manipulation relationships simultaneously and meet
the real-time requirements in robot tasks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.08678v2,2018-02-26T11:03:21Z,2018-02-23T18:53:44Z,"Verifying Controllers Against Adversarial Examples with Bayesian
  Optimization","Recent successes in reinforcement learning have lead to the development of
complex controllers for real-world robots. As these robots are deployed in
safety-critical applications and interact with humans, it becomes critical to
ensure safety in order to avoid causing harm. A first step in this direction is
to test the controllers in simulation. To be able to do this, we need to
capture what we mean by safety and then efficiently search the space of all
behaviors to see if they are safe. In this paper, we present an active-testing
framework based on Bayesian Optimization. We specify safety constraints using
logic and exploit structure in the problem in order to test the system for
adversarial counter examples that violate the safety specifications. These
specifications are defined as complex boolean combinations of smooth functions
on the trajectories and, unlike reward functions in reinforcement learning, are
expressive and impose hard constraints on the system. In our framework, we
exploit regularity assumptions on individual functions in form of a Gaussian
Process (GP) prior. We combine these into a coherent optimization framework
using problem structure. The resulting algorithm is able to provably verify
complex safety specifications or alternatively find counter examples.
Experimental results show that the proposed method is able to find adversarial
examples quickly.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.04181v2,2018-06-05T13:52:23Z,2018-02-12T16:53:48Z,State Representation Learning for Control: An Overview,"Representation learning algorithms are designed to learn abstract features
that characterize data. State representation learning (SRL) focuses on a
particular kind of representation learning where learned features are in low
dimension, evolve through time, and are influenced by actions of an agent. The
representation is learned to capture the variation in the environment generated
by the agent's actions; this kind of representation is particularly suitable
for robotics and control scenarios. In particular, the low dimension
characteristic of the representation helps to overcome the curse of
dimensionality, provides easier interpretation and utilization by humans and
can help improve performance and speed in policy learning algorithms such as
reinforcement learning.
  This survey aims at covering the state-of-the-art on state representation
learning in the most recent years. It reviews different SRL methods that
involve interaction with the environment, their implementations and their
applications in robotics control tasks (simulated or real). In particular, it
highlights how generic learning objectives are differently exploited in the
reviewed algorithms. Finally, it discusses evaluation methods to assess the
representation learned and summarizes current and future lines of research.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.02395v1,2018-02-07T12:01:13Z,2018-02-07T12:01:13Z,Evaluation of Deep Reinforcement Learning Methods for Modular Robots,"We propose a novel framework for Deep Reinforcement Learning (DRL) in modular
robotics using traditional robotic tools that extend state-of-the-art DRL
implementations and provide an end-to-end approach which trains a robot
directly from joint states. Moreover, we present a novel technique to transfer
these DLR methods into the real robot, aiming to close the simulation-reality
gap. We demonstrate the robustness of the performance of state-of-the-art DRL
methods for continuous action spaces in modular robots, with an empirical study
both in simulation and in the real robot where we also evaluate how
accelerating the simulation time affects the robot's performance. Our results
show that extending the modular robot from 3 degrees-of-freedom (DoF), to 4
DoF, does not affect the robot's learning. This paves the way towards training
modular robots using DRL techniques.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.00285v4,2018-10-28T04:56:58Z,2018-02-01T13:52:38Z,Virtual-to-Real: Learning to Control in Visual Semantic Segmentation,"Collecting training data from the physical world is usually time-consuming
and even dangerous for fragile robots, and thus, recent advances in robot
learning advocate the use of simulators as the training platform.
Unfortunately, the reality gap between synthetic and real visual data prohibits
direct migration of the models trained in virtual worlds to the real world.
This paper proposes a modular architecture for tackling the virtual-to-real
problem. The proposed architecture separates the learning model into a
perception module and a control policy module, and uses semantic image
segmentation as the meta representation for relating these two modules. The
perception module translates the perceived RGB image to semantic image
segmentation. The control policy module is implemented as a deep reinforcement
learning agent, which performs actions based on the translated image
segmentation. Our architecture is evaluated in an obstacle avoidance task and a
target following task. Experimental results show that our architecture
significantly outperforms all of the baseline methods in both virtual and real
environments, and demonstrates a faster learning curve than them. We also
present a detailed analysis for a variety of variant configurations, and
validate the transferability of our modular architecture.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1802.00265v4,2019-01-16T09:04:06Z,2018-02-01T12:42:02Z,VR-Goggles for Robots: Real-to-sim Domain Adaptation for Visual Control,"In this paper, we deal with the reality gap from a novel perspective,
targeting transferring Deep Reinforcement Learning (DRL) policies learned in
simulated environments to the real-world domain for visual control tasks.
Instead of adopting the common solutions to the problem by increasing the
visual fidelity of synthetic images output from simulators during the training
phase, we seek to tackle the problem by translating the real-world image
streams back to the synthetic domain during the deployment phase, to make the
robot feel at home. We propose this as a lightweight, flexible, and efficient
solution for visual control, as 1) no extra transfer steps are required during
the expensive training of DRL agents in simulation; 2) the trained DRL agents
will not be constrained to being deployable in only one specific real-world
environment; 3) the policy training and the transfer operations are decoupled,
and can be conducted in parallel. Besides this, we propose a simple yet
effective shift loss that is agnostic to the downstream task, to constrain the
consistency between subsequent frames which is important for consistent policy
outputs. We validate the shift loss for artistic style transfer for videos and
domain adaptation, and validate our visual control approach in indoor and
outdoor robotics experiments.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.08757v1,2018-01-26T11:11:18Z,2018-01-26T11:11:18Z,Safe Exploration in Continuous Action Spaces,"We address the problem of deploying a reinforcement learning (RL) agent on a
physical system such as a datacenter cooling unit or robot, where critical
constraints must never be violated. We show how to exploit the typically smooth
dynamics of these systems and enable RL algorithms to never violate constraints
during learning. Our technique is to directly add to the policy a safety layer
that analytically solves an action correction formulation per each state. The
novelty of obtaining an elegant closed-form solution is attained due to a
linearized model, learned on past trajectories consisting of arbitrary actions.
This is to mimic the real-world circumstances where data logs were generated
with a behavior policy that is implausible to describe mathematically; such
cases render the known safety-aware off-policy methods inapplicable. We
demonstrate the efficacy of our approach on new representative physics-based
environments, and prevail where reward shaping fails by maintaining zero
constraint violations.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.05132v1,2018-01-16T06:42:15Z,2018-01-16T06:42:15Z,"Learning to Navigate: Exploiting Deep Networks to Inform Sample-Based
  Planning During Vision-Based Navigation","Recent applications of deep learning to navigation have generated end-to-end
navigation solutions whereby visual sensor input is mapped to control signals
or to motion primitives. The resulting visual navigation strategies work very
well at collision avoidance and have performance that matches traditional
reactive navigation algorithms while operating in real-time. It is accepted
that these solutions cannot provide the same level of performance as a global
planner. However, it is less clear how such end-to-end systems should be
integrated into a full navigation pipeline. We evaluate the typical end-to-end
solution within a full navigation pipeline in order to expose its weaknesses.
Doing so illuminates how to better integrate deep learning methods into the
navigation pipeline. In particular, we show that they are an efficient means to
provide informed samples for sample-based planners. Controlled simulations with
comparison against traditional planners show that the number of samples can be
reduced by an order of magnitude while preserving navigation performance.
Implementation on a mobile robot matches the simulated performance outcomes.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.02854v3,2018-07-25T07:54:52Z,2018-01-09T09:44:21Z,Riemannian Motion Policies,"We introduce the Riemannian Motion Policy (RMP), a new mathematical object
for modular motion generation. An RMP is a second-order dynamical system
(acceleration field or motion policy) coupled with a corresponding Riemannian
metric. The motion policy maps positions and velocities to accelerations, while
the metric captures the directions in the space important to the policy. We
show that RMPs provide a straightforward and convenient method for combining
multiple motion policies and transforming such policies from one space (such as
the task space) to another (such as the configuration space) in geometrically
consistent ways. The operators we derive for these combinations and
transformations are provably optimal, have linearity properties making them
agnostic to the order of application, and are strongly analogous to the
covariant transformations of natural gradients popular in the machine learning
literature. The RMP framework enables the fusion of motion policies from
different motion generation paradigms, such as dynamical systems, dynamic
movement primitives (DMPs), optimal control, operational space control,
nonlinear reactive controllers, motion optimization, and model predictive
control (MPC), thus unifying these disparate techniques from the literature.
RMPs are easy to implement and manipulate, facilitate controller design,
simplify handling of joint limits, and clarify a number of open questions
regarding the proper fusion of motion generation methods (such as incorporating
local reactive policies into long-horizon optimizers). We demonstrate the
effectiveness of RMPs on both simulation and real robots, including their
ability to naturally and efficiently solve complicated collision avoidance
problems previously handled by more complex planners.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.02190v1,2018-01-07T13:46:03Z,2018-01-07T13:46:03Z,Approximate FPGA-based LSTMs under Computation Time Constraints,"Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)
networks have demonstrated state-of-the-art accuracy in several emerging
Artificial Intelligence tasks. However, the models are becoming increasingly
demanding in terms of computational and memory load. Emerging latency-sensitive
applications including mobile robots and autonomous vehicles often operate
under stringent computation time constraints. In this paper, we address the
challenge of deploying computationally demanding LSTMs at a constrained time
budget by introducing an approximate computing scheme that combines iterative
low-rank compression and pruning, along with a novel FPGA-based LSTM
architecture. Combined in an end-to-end framework, the approximation method's
parameters are optimised and the architecture is configured to address the
problem of high-performance LSTM execution in time-constrained applications.
Quantitative evaluation on a real-life image captioning application indicates
that the proposed methods required up to 6.5x less time to achieve the same
application-level accuracy compared to a baseline method, while achieving an
average of 25x higher accuracy under the same computation time constraints.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1712.07452v2,2019-08-13T20:41:40Z,2017-12-20T12:47:39Z,"Self-Supervised Damage-Avoiding Manipulation Strategy Optimization via
  Mental Simulation","Everyday robotics are challenged to deal with autonomous product handling in
applications like logistics or retail, possibly causing damage on the items
during manipulation. Traditionally, most approaches try to minimize physical
interaction with goods. However, this paper proposes to take into account any
unintended object motion and to learn damage-minimizing manipulation strategies
in a self-supervised way. The presented approach consists of a simulation-based
planning method for an optimal manipulation sequence with respect to possible
damage. The planned manipulation sequences are generalized to new, unseen
scenes in the same application scenario using machine learning. This learned
manipulation strategy is continuously refined in a self-supervised,
simulation-in-the-loop optimization cycle during load-free times of the system,
commonly known as mental simulation. In parallel, the generated manipulation
strategies can be deployed in near-real time in an anytime fashion. The
approach is validated on an industrial container-unloading scenario and on a
retail shelf-replenishment scenario.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1801.01444v2,2018-10-15T20:34:00Z,2017-12-06T02:45:04Z,"Deep Anticipation: Light Weight Intelligent Mobile Sensing in IoT by
  Recurrent Architecture","The rapid growth of IoT era is shaping the future of mobile services.
Advanced communication technology enables a heterogeneous connectivity where
mobile devices broadcast information to everything. Mobile applications such as
robotics and vehicles connecting to cloud and surroundings transfer the
short-range on-board sensor perception system to long-range mobile-sensing
perception system. However, the mobile sensing perception brings new challenges
for how to efficiently analyze and intelligently interpret the deluge of IoT
data in mission- critical services. In this article, we model the challenges as
latency, packet loss and measurement noise which severely deteriorate the
reliability and quality of IoT data. We integrate the artificial intelligence
into IoT to tackle these challenges. We propose a novel architecture that
leverages recurrent neural networks (RNN) and Kalman filtering to anticipate
motions and interac- tions between objects. The basic idea is to learn
environment dynamics by recurrent networks. To improve the robustness of IoT
communication, we use the idea of Kalman filtering and deploy a prediction and
correction step. In this way, the architecture learns to develop a biased
belief between prediction and measurement in the different situation. We
demonstrate our approach with synthetic and real-world datasets with noise that
mimics the challenges of IoT communications. Our method brings a new level of
IoT intelligence. It is also lightweight compared to other state-of-the-art
convolutional recurrent architecture and is ideally suitable for the
resource-limited mobile applications.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1711.07404v1,2017-11-20T16:47:28Z,2017-11-20T16:47:28Z,Non-Contextual Modeling of Sarcasm using a Neural Network Benchmark,"One of the most crucial components of natural human-robot interaction is
artificial intuition and its influence on dialog systems. The intuitive
capability that humans have is undeniably extraordinary, and so remains one of
the greatest challenges for natural communicative dialogue between humans and
robots. In this paper, we introduce a novel probabilistic modeling framework of
identifying, classifying and learning features of sarcastic text via training a
neural network with human-informed sarcastic benchmarks. This is necessary for
establishing a comprehensive sentiment analysis schema that is sensitive to the
nuances of sarcasm-ridden text by being trained on linguistic cues. We show
that our model provides a good fit for this type of real-world informed data,
with potential to achieve as accurate, if not more, than alternatives. Though
the implementation and benchmarking is an extensive task, it can be extended
via the same method that we present to capture different forms of nuances in
communication and making for much more natural and engaging dialogue systems.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.11319v2,2018-06-07T21:16:06Z,2017-10-31T04:19:20Z,"Learning Motion Predictors for Smart Wheelchair using Autoregressive
  Sparse Gaussian Process","Constructing a smart wheelchair on a commercially available powered
wheelchair (PWC) platform avoids a host of seating, mechanical design and
reliability issues but requires methods of predicting and controlling the
motion of a device never intended for robotics. Analog joystick inputs are
subject to black-box transformations which may produce intuitive and adaptable
motion control for human operators, but complicate robotic control approaches;
furthermore, installation of standard axle mounted odometers on a commercial
PWC is difficult. In this work, we present an integrated hardware and software
system for predicting the motion of a commercial PWC platform that does not
require any physical or electronic modification of the chair beyond plugging
into an industry standard auxiliary input port. This system uses an RGB-D
camera and an Arduino interface board to capture motion data, including visual
odometry and joystick signals, via ROS communication. Future motion is
predicted using an autoregressive sparse Gaussian process model. We evaluate
the proposed system on real-world short-term path prediction experiments.
Experimental results demonstrate the system's efficacy when compared to a
baseline neural network model.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.08893v3,2018-06-13T13:03:41Z,2017-10-24T17:08:20Z,"Fast Model Identification via Physics Engines for Data-Efficient Policy
  Search","This paper presents a method for identifying mechanical parameters of robots
or objects, such as their mass and friction coefficients. Key features are the
use of off-the-shelf physics engines and the adaptation of a Bayesian
optimization technique towards minimizing the number of real-world experiments
needed for model-based reinforcement learning. The proposed framework
reproduces in a physics engine experiments performed on a real robot and
optimizes the model's mechanical parameters so as to match real-world
trajectories. The optimized model is then used for learning a policy in
simulation, before real-world deployment. It is well understood, however, that
it is hard to exactly reproduce real trajectories in simulation. Moreover, a
near-optimal policy can be frequently found with an imperfect model. Therefore,
this work proposes a strategy for identifying a model that is just good enough
to approximate the value of a locally optimal policy with a certain confidence,
instead of wasting effort on identifying the most accurate model. Evaluations,
performed both in simulation and on a real robotic manipulation task, indicate
that the proposed strategy results in an overall time-efficient, integrated
model identification and learning solution, which significantly improves the
data-efficiency of existing policy search algorithms.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.07557v1,2017-10-20T14:53:57Z,2017-10-20T14:53:57Z,"Real-time Convolutional Neural Networks for Emotion and Gender
  Classification","In this paper we propose an implement a general convolutional neural network
(CNN) building framework for designing real-time CNNs. We validate our models
by creating a real-time vision system which accomplishes the tasks of face
detection, gender classification and emotion classification simultaneously in
one blended step using our proposed CNN architecture. After presenting the
details of the training procedure setup we proceed to evaluate on standard
benchmark sets. We report accuracies of 96% in the IMDB gender dataset and 66%
in the FER-2013 emotion dataset. Along with this we also introduced the very
recent real-time enabled guided back-propagation visualization technique.
Guided back-propagation uncovers the dynamics of the weight changes and
evaluates the learned features. We argue that the careful implementation of
modern CNN architectures, the use of the current regularization methods and the
visualization of previously hidden features are necessary in order to reduce
the gap between slow performances and real-time architectures. Our system has
been validated by its deployment on a Care-O-bot 3 robot used during
RoboCup@Home competitions. All our code, demos and pre-trained architectures
have been released under an open-source license in our public repository.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1710.06270v2,2017-10-18T06:46:05Z,2017-10-17T13:38:16Z,"Procedural Modeling and Physically Based Rendering for Synthetic Data
  Generation in Automotive Applications","We present an overview and evaluation of a new, systematic approach for
generation of highly realistic, annotated synthetic data for training of deep
neural networks in computer vision tasks. The main contribution is a procedural
world modeling approach enabling high variability coupled with physically
accurate image synthesis, and is a departure from the hand-modeled virtual
worlds and approximate image synthesis methods used in real-time applications.
The benefits of our approach include flexible, physically accurate and scalable
image synthesis, implicit wide coverage of classes and features, and complete
data introspection for annotations, which all contribute to quality and cost
efficiency. To evaluate our approach and the efficacy of the resulting data, we
use semantic segmentation for autonomous vehicles and robotic navigation as the
main application, and we train multiple deep learning architectures using
synthetic data with and without fine tuning on organic (i.e. real-world) data.
The evaluation shows that our approach improves the neural network's
performance and that even modest implementation efforts produce
state-of-the-art results.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1709.10089v2,2018-02-25T07:48:19Z,2017-09-28T17:51:48Z,Overcoming Exploration in Reinforcement Learning with Demonstrations,"Exploration in environments with sparse rewards has been a persistent problem
in reinforcement learning (RL). Many tasks are natural to specify with a sparse
reward, and manually shaping a reward function can result in suboptimal
performance. However, finding a non-zero reward is exponentially more difficult
with increasing task horizon or action dimensionality. This puts many
real-world tasks out of practical reach of RL methods. In this work, we use
demonstrations to overcome the exploration problem and successfully learn to
perform long-horizon, multi-step robotics tasks with continuous control such as
stacking blocks with a robot arm. Our method, which builds on top of Deep
Deterministic Policy Gradients and Hindsight Experience Replay, provides an
order of magnitude of speedup over RL on simulated robotics tasks. It is simple
to implement and makes only the additional assumption that we can collect a
small set of demonstrations. Furthermore, our method is able to solve tasks not
solvable by either RL or behavior cloning alone, and often ends up
outperforming the demonstrator policy.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1709.08945v1,2017-09-26T11:26:08Z,2017-09-26T11:26:08Z,"Gesture-based Human-robot Interaction for Field Programmable Autonomous
  Underwater Robots","The uncertainty and variability of underwater environment propose the request
to control underwater robots in real time and dynamically, especially in the
scenarios where human and robots need to work collaboratively in the field.
However, the underwater environment imposes harsh restrictions on the
application of typical control and communication methods. Considering that
gestures are a natural and efficient interactive way for human, we, utilizing
convolution neural network, implement a real-time gesture-based recognition
system, who can recognize 50 kinds of gestures from images captured by one
normal monocular camera, and apply this recognition system in human and
underwater robot interaction. We design A Flexible and Extendable Interaction
Scheme (AFEIS) through which underwater robots can be programmed in situ
underwater by human operators using customized gesture-based sign language.
This paper elaborates the design of gesture recognition system and AFEIS, and
presents our field trial results when applying this system and scheme on
underwater robots.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1706.06696v1,2017-06-20T22:53:16Z,2017-06-20T22:53:16Z,"The NAO Backpack: An Open-hardware Add-on for Fast Software Development
  with the NAO Robot","We present an open-source accessory for the NAO robot, which enables to test
computationally demanding algorithms in an external platform while preserving
robot's autonomy and mobility. The platform has the form of a backpack, which
can be 3D printed and replicated, and holds an ODROID XU4 board to process
algorithms externally with ROS compatibility. We provide also a software bridge
between the B-Human's framework and ROS to have access to the robot's sensors
close to real-time. We tested the platform in several robotics applications
such as data logging, visual SLAM, and robot vision with deep learning
techniques. The CAD model, hardware specifications and software are available
online for the benefit of the community:
https://github.com/uchile-robotics/nao-backpack",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1706.06695v1,2017-06-20T22:52:10Z,2017-06-20T22:52:10Z,"Toward Real-Time Decentralized Reinforcement Learning using Finite
  Support Basis Functions","This paper addresses the design and implementation of complex Reinforcement
Learning (RL) behaviors where multi-dimensional action spaces are involved, as
well as the need to execute the behaviors in real-time using robotic platforms
with limited computational resources and training times. For this purpose, we
propose the use of decentralized RL, in combination with finite support basis
functions as alternatives to Gaussian RBF, in order to alleviate the effects of
the curse of dimensionality on the action and state spaces respectively, and to
reduce the computation time. As testbed, a RL based controller for the in-walk
kick in NAO robots, a challenging and critical problem for soccer robotics, is
used. The reported experiments show empirically that our solution saves up to
99.94% of execution time and 98.82% of memory consumption during execution,
without diminishing performance compared to classical approaches.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1706.02501v1,2017-06-08T10:10:44Z,2017-06-08T10:10:44Z,Unlocking the Potential of Simulators: Design with RL in Mind,"Using Reinforcement Learning (RL) in simulation to construct policies useful
in real life is challenging. This is often attributed to the sequential
decision making aspect: inaccuracies in simulation accumulate over multiple
steps, hence the simulated trajectories diverge from what would happen in
reality.
  In our work we show the need to consider another important aspect: the
mismatch in simulating control. We bring attention to the need for modeling
control as well as dynamics, since oversimplifying assumptions about applying
actions of RL policies could make the policies fail on real-world systems.
  We design a simulator for solving a pivoting task (of interest in Robotics)
and demonstrate that even a simple simulator designed with RL in mind
outperforms high-fidelity simulators when it comes to learning a policy that is
to be deployed on a real robotic system. We show that a phenomenon that is hard
to model - friction - could be exploited successfully, even when RL is
performed using a simulator with a simple dynamics and noise model. Hence, we
demonstrate that as long as the main sources of uncertainty are identified, it
could be possible to learn policies applicable to real systems even using a
simple simulator.
  RL-compatible simulators could open the possibilities for applying a wide
range of RL algorithms in various fields. This is important, since currently
data sparsity in fields like healthcare and education frequently forces
researchers and engineers to only consider sample-efficient RL approaches.
Successful simulator-aided RL could increase flexibility of experimenting with
RL algorithms and help applying RL policies to real-world settings in fields
where data is scarce. We believe that lessons learned in Robotics could help
other fields design RL-compatible simulators, so we summarize our experience
and conclude with suggestions.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.05853v1,2017-03-17T00:17:50Z,2017-03-17T00:17:50Z,"Towards Closing the Energy Gap Between HOG and CNN Features for Embedded
  Vision","Computer vision enables a wide range of applications in robotics/drones,
self-driving cars, smart Internet of Things, and portable/wearable electronics.
For many of these applications, local embedded processing is preferred due to
privacy and/or latency concerns. Accordingly, energy-efficient embedded vision
hardware delivering real-time and robust performance is crucial. While deep
learning is gaining popularity in several computer vision algorithms, a
significant energy consumption difference exists compared to traditional
hand-crafted approaches. In this paper, we provide an in-depth analysis of the
computation, energy and accuracy trade-offs between learned features such as
deep Convolutional Neural Networks (CNN) and hand-crafted features such as
Histogram of Oriented Gradients (HOG). This analysis is supported by
measurements from two chips that implement these algorithms. Our goal is to
understand the source of the energy discrepancy between the two approaches and
to provide insight about the potential areas where CNNs can be improved and
eventually approach the energy-efficiency of HOG while maintaining its
outstanding performance accuracy.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.04550v1,2017-03-13T20:08:39Z,2017-03-13T20:08:39Z,Sensor Fusion for Robot Control through Deep Reinforcement Learning,"Deep reinforcement learning is becoming increasingly popular for robot
control algorithms, with the aim for a robot to self-learn useful feature
representations from unstructured sensory input leading to the optimal
actuation policy. In addition to sensors mounted on the robot, sensors might
also be deployed in the environment, although these might need to be accessed
via an unreliable wireless connection. In this paper, we demonstrate deep
neural network architectures that are able to fuse information coming from
multiple sensors and are robust to sensor failures at runtime. We evaluate our
method on a search and pick task for a robot both in simulation and the real
world.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.04368v1,2017-03-13T13:06:49Z,2017-03-13T13:06:49Z,Symbol Grounding via Chaining of Morphisms,"A new model of symbol grounding is presented, in which the structures of
natural language, logical semantics, perception and action are represented
categorically, and symbol grounding is modeled via the composition of morphisms
between the relevant categories. This model gives conceptual insight into the
fundamentally systematic nature of symbol grounding, and also connects
naturally to practical real-world AI systems in current research and commercial
use. Specifically, it is argued that the structure of linguistic syntax can be
modeled as a certain asymmetric monoidal category, as e.g. implicit in the link
grammar formalism; the structure of spatiotemporal relationships and action
plans can be modeled similarly using ""image grammars"" and ""action grammars"";
and common-sense logical semantic structure can be modeled using
dependently-typed lambda calculus with uncertain truth values. Given these
formalisms, the grounding of linguistic descriptions in spatiotemporal
perceptions and coordinated actions consists of following morphisms from
language to logic through to spacetime and body (for comprehension), and vice
versa (for generation). The mapping is indicated between the spatial
relationships in the Region Connection Calculus and Allen Interval Algebra and
corresponding entries in the link grammar syntax parsing dictionary. Further,
the abstractions introduced here are shown to naturally model the structures
and systems currently being deployed in the context of using the OpenCog
cognitive architecture to control Hanson Robotics humanoid robots.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.00835v3,2017-08-13T11:40:32Z,2017-03-02T15:41:48Z,Autonomous Skill-centric Testing using Deep Learning,"Software testing is an important tool to ensure software quality. This is a
hard task in robotics due to dynamic environments and the expensive development
and time-consuming execution of test cases. Most testing approaches use
model-based and / or simulation-based testing to overcome these problems. We
propose model-free skill-centric testing in which a robot autonomously executes
skills in the real world and compares it to previous experiences. The skills
are selected by maximising the expected information gain on the distribution of
erroneous software functions. We use deep learning to model the sensor data
observed during previous successful skill executions and to detect
irregularities. Sensor data is connected to function call profiles such that
certain misbehaviour can be related to specific functions. We evaluate our
approach in simulation and in experiments with a KUKA LWR 4+ robot by
purposefully introducing bugs to the software. We demonstrate that these bugs
can be detected with high accuracy and without the need for the implementation
of specific tests or task-specific models.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1703.00727v1,2017-03-02T11:29:57Z,2017-03-02T11:29:57Z,Deep Predictive Policy Training using Reinforcement Learning,"Skilled robot task learning is best implemented by predictive action policies
due to the inherent latency of sensorimotor processes. However, training such
predictive policies is challenging as it involves finding a trajectory of motor
activations for the full duration of the action. We propose a data-efficient
deep predictive policy training (DPPT) framework with a deep neural network
policy architecture which maps an image observation to a sequence of motor
activations. The architecture consists of three sub-networks referred to as the
perception, policy and behavior super-layers. The perception and behavior
super-layers force an abstraction of visual and motor data trained with
synthetic and simulated training samples, respectively. The policy super-layer
is a small sub-network with fewer parameters that maps data in-between the
abstracted manifolds. It is trained for each task using methods for policy
search reinforcement learning. We demonstrate the suitability of the proposed
architecture and learning framework by training predictive policies for skilled
object grasping and ball throwing on a PR2 robot. The effectiveness of the
method is illustrated by the fact that these tasks are trained using only about
180 real robot attempts with qualitative terminal rewards.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1702.06329v1,2017-02-21T11:07:27Z,2017-02-21T11:07:27Z,"Towards a Common Implementation of Reinforcement Learning for Multiple
  Robotic Tasks","Mobile robots are increasingly being employed for performing complex tasks in
dynamic environments. Reinforcement learning (RL) methods are recognized to be
promising for specifying such tasks in a relatively simple manner. However, the
strong dependency between the learning method and the task to learn is a
well-known problem that restricts practical implementations of RL in robotics,
often requiring major modifications of parameters and adding other techniques
for each particular task. In this paper we present a practical core
implementation of RL which enables the learning process for multiple robotic
tasks with minimal per-task tuning or none. Based on value iteration methods,
this implementation includes a novel approach for action selection, called
Q-biased softmax regression (QBIASSR), which avoids poor performance of the
learning process when the robot reaches new unexplored states. Our approach
takes advantage of the structure of the state space by attending the physical
variables involved (e.g., distances to obstacles, X,Y,{\theta} pose, etc.),
thus experienced sets of states may favor the decision-making process of
unexplored or rarely-explored states. This improvement has a relevant role in
reducing the tuning of the algorithm for particular tasks. Experiments with
real and simulated robots, performed with the software framework also
introduced here, show that our implementation is effectively able to learn
different robotic tasks without tuning the learning method. Results also
suggest that the combination of true online SARSA({\lambda}) with QBIASSR can
outperform the existing RL core algorithms in low-dimensional robotic tasks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1702.01182v1,2017-02-03T21:57:13Z,2017-02-03T21:57:13Z,Uncertainty-Aware Reinforcement Learning for Collision Avoidance,"Reinforcement learning can enable complex, adaptive behavior to be learned
automatically for autonomous robotic platforms. However, practical deployment
of reinforcement learning methods must contend with the fact that the training
process itself can be unsafe for the robot. In this paper, we consider the
specific case of a mobile robot learning to navigate an a priori unknown
environment while avoiding collisions. In order to learn collision avoidance,
the robot must experience collisions at training time. However, high-speed
collisions, even at training time, could damage the robot. A successful
learning method must therefore proceed cautiously, experiencing only low-speed
collisions until it gains confidence. To this end, we present an
uncertainty-aware model-based learning algorithm that estimates the probability
of collision together with a statistical estimate of uncertainty. By
formulating an uncertainty-dependent cost function, we show that the algorithm
naturally chooses to proceed cautiously in unfamiliar environments, and
increases the velocity of the robot in settings where it has high confidence.
Our predictive model is based on bootstrapped neural networks using dropout,
allowing it to process raw sensory inputs from high-bandwidth sensors such as
cameras. Our experimental evaluation demonstrates that our method effectively
minimizes dangerous collisions at training time in an obstacle avoidance task
for a simulated and real-world quadrotor, and a real-world RC car. Videos of
the experiments can be found at https://sites.google.com/site/probcoll.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1701.08878v1,2017-01-31T00:16:15Z,2017-01-31T00:16:15Z,"Deep Reinforcement Learning for Robotic Manipulation-The state of the
  art","The focus of this work is to enumerate the various approaches and algorithms
that center around application of reinforcement learning in robotic ma-
]]nipulation tasks. Earlier methods utilized specialized policy representations
and human demonstrations to constrict the policy. Such methods worked well with
continuous state and policy space of robots but failed to come up with
generalized policies. Subsequently, high dimensional non-linear function
approximators like neural networks have been used to learn policies from
scratch. Several novel and recent approaches have also embedded control policy
with efficient perceptual representation using deep learning. This has led to
the emergence of a new branch of dynamic robot control system called deep r
inforcement learning(DRL). This work embodies a survey of the most recent
algorithms, architectures and their implementations in simulations and real
world robotic platforms. The gamut of DRL architectures are partitioned into
two different branches namely, discrete action space algorithms(DAS) and
continuous action space algorithms(CAS). Further, the CAS algorithms are
divided into stochastic continuous action space(SCAS) and deterministic
continuous action space(DCAS) algorithms. Along with elucidating an organ-
isation of the DRL algorithms this work also manifests some of the state of the
art applications of these approaches in robotic manipulation tasks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1612.06699v3,2017-06-12T21:38:17Z,2016-12-20T15:04:38Z,Unsupervised Perceptual Rewards for Imitation Learning,"Reward function design and exploration time are arguably the biggest
obstacles to the deployment of reinforcement learning (RL) agents in the real
world. In many real-world tasks, designing a reward function takes considerable
hand engineering and often requires additional sensors to be installed just to
measure whether the task has been executed successfully. Furthermore, many
interesting tasks consist of multiple implicit intermediate steps that must be
executed in sequence. Even when the final outcome can be measured, it does not
necessarily provide feedback on these intermediate steps. To address these
issues, we propose leveraging the abstraction power of intermediate visual
representations learned by deep models to quickly infer perceptual reward
functions from small numbers of demonstrations. We present a method that is
able to identify key intermediate steps of a task from only a handful of
demonstration sequences, and automatically identify the most discriminative
features for identifying these steps. This method makes use of the features in
a pre-trained deep model, but does not require any explicit specification of
sub-goals. The resulting reward functions can then be used by an RL agent to
learn to perform the task in real-world settings. To evaluate the learned
reward, we present qualitative results on two real-world tasks and a
quantitative evaluation against a human-designed reward function. We also show
that our method can be used to learn a real-world door opening skill using a
real robot, even when the demonstration used for reward learning is provided by
a human using their own hand. To our knowledge, these are the first results
showing that complex robotic manipulation skills can be learned directly and
without supervised labels from a video of a human performing the task.
Supplementary material and data are available at
https://sermanet.github.io/rewards",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1612.00429v2,2017-03-09T19:46:12Z,2016-12-01T20:48:39Z,Generalizing Skills with Semi-Supervised Reinforcement Learning,"Deep reinforcement learning (RL) can acquire complex behaviors from low-level
inputs, such as images. However, real-world applications of such methods
require generalizing to the vast variability of the real world. Deep networks
are known to achieve remarkable generalization when provided with massive
amounts of labeled data, but can we provide this breadth of experience to an RL
agent, such as a robot? The robot might continuously learn as it explores the
world around it, even while deployed. However, this learning requires access to
a reward function, which is often hard to measure in real-world domains, where
the reward could depend on, for example, unknown positions of objects or the
emotional state of the user. Conversely, it is often quite practical to provide
the agent with reward functions in a limited set of situations, such as when a
human supervisor is present or in a controlled setting. Can we make use of this
limited supervision, and still benefit from the breadth of experience an agent
might collect on its own? In this paper, we formalize this problem as
semisupervised reinforcement learning, where the reward function can only be
evaluated in a set of ""labeled"" MDPs, and the agent must generalize its
behavior to the wide range of states it might encounter in a set of ""unlabeled""
MDPs, by using experience from both settings. Our proposed method infers the
task objective in the unlabeled MDPs through an algorithm that resembles
inverse RL, using the agent's own prior experience in the labeled MDPs as a
kind of demonstration of optimal behavior. We evaluate our method on
challenging tasks that require control directly from images, and show that our
approach can improve the generalization of a learned deep neural network policy
by using experience for which no reward function is available. We also show
that our method outperforms direct supervised learning of the reward.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1611.05136v1,2016-11-16T03:45:12Z,2016-11-16T03:45:12Z,"Machine Learning Approach for Skill Evaluation in Robotic-Assisted
  Surgery","Evaluating surgeon skill has predominantly been a subjective task.
Development of objective methods for surgical skill assessment are of increased
interest. Recently, with technological advances such as robotic-assisted
minimally invasive surgery (RMIS), new opportunities for objective and
automated assessment frameworks have arisen. In this paper, we applied machine
learning methods to automatically evaluate performance of the surgeon in RMIS.
Six important movement features were used in the evaluation including
completion time, path length, depth perception, speed, smoothness and
curvature. Different classification methods applied to discriminate expert and
novice surgeons. We test our method on real surgical data for suturing task and
compare the classification result with the ground truth data (obtained by
manual labeling). The experimental results show that the proposed framework can
classify surgical skill level with relatively high accuracy of 85.7%. This
study demonstrates the ability of machine learning methods to automatically
classify expert and novice surgeons using movement features for different RMIS
tasks. Due to the simplicity and generalizability of the introduced
classification method, it is easy to implement in existing trainers.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1611.02695v1,2016-11-08T09:50:30Z,2016-11-08T09:50:30Z,"Automatic recognition of child speech for robotic applications in noisy
  environments","Automatic speech recognition (ASR) allows a natural and intuitive interface
for robotic educational applications for children. However there are a number
of challenges to overcome to allow such an interface to operate robustly in
realistic settings, including the intrinsic difficulties of recognising child
speech and high levels of background noise often present in classrooms. As part
of the EU EASEL project we have provided several contributions to address these
challenges, implementing our own ASR module for use in robotics applications.
We used the latest deep neural network algorithms which provide a leap in
performance over the traditional GMM approach, and apply data augmentation
methods to improve robustness to noise and speaker variation. We provide a
close integration between the ASR module and the rest of the dialogue system,
allowing the ASR to receive in real-time the language models relevant to the
current section of the dialogue, greatly improving the accuracy. We integrated
our ASR module into an interactive, multimodal system using a small humanoid
robot to help children learn about exercise and energy. The system was
installed at a public museum event as part of a research study where 320
children (aged 3 to 14) interacted with the robot, with our ASR achieving 90%
accuracy for fluent and near-fluent speech.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1611.01235v1,2016-11-04T01:10:07Z,2016-11-04T01:10:07Z,"A Self-Driving Robot Using Deep Convolutional Neural Networks on
  Neuromorphic Hardware","Neuromorphic computing is a promising solution for reducing the size, weight
and power of mobile embedded systems. In this paper, we introduce a realization
of such a system by creating the first closed-loop battery-powered
communication system between an IBM TrueNorth NS1e and an autonomous
Android-Based Robotics platform. Using this system, we constructed a dataset of
path following behavior by manually driving the Android-Based robot along steep
mountain trails and recording video frames from the camera mounted on the robot
along with the corresponding motor commands. We used this dataset to train a
deep convolutional neural network implemented on the TrueNorth NS1e. The NS1e,
which was mounted on the robot and powered by the robot's battery, resulted in
a self-driving robot that could successfully traverse a steep mountain path in
real time. To our knowledge, this represents the first time the TrueNorth NS1e
neuromorphic chip has been embedded on a mobile platform under closed-loop
control.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1610.04213v4,2017-12-12T08:02:31Z,2016-10-13T19:39:58Z,Reset-free Trial-and-Error Learning for Robot Damage Recovery,"The high probability of hardware failures prevents many advanced robots
(e.g., legged robots) from being confidently deployed in real-world situations
(e.g., post-disaster rescue). Instead of attempting to diagnose the failures,
robots could adapt by trial-and-error in order to be able to complete their
tasks. In this situation, damage recovery can be seen as a Reinforcement
Learning (RL) problem. However, the best RL algorithms for robotics require the
robot and the environment to be reset to an initial state after each episode,
that is, the robot is not learning autonomously. In addition, most of the RL
methods for robotics do not scale well with complex robots (e.g., walking
robots) and either cannot be used at all or take too long to converge to a
solution (e.g., hours of learning). In this paper, we introduce a novel
learning algorithm called ""Reset-free Trial-and-Error"" (RTE) that (1) breaks
the complexity by pre-generating hundreds of possible behaviors with a dynamics
simulator of the intact robot, and (2) allows complex robots to quickly recover
from damage while completing their tasks and taking the environment into
account. We evaluate our algorithm on a simulated wheeled robot, a simulated
six-legged robot, and a real six-legged walking robot that are damaged in
several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and
whose objective is to reach a sequence of targets in an arena. Our experiments
show that the robots can recover most of their locomotion abilities in an
environment with obstacles, and without any human intervention.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1610.03518v1,2016-10-11T20:24:31Z,2016-10-11T20:24:31Z,"Transfer from Simulation to Real World through Learning Deep Inverse
  Dynamics Model","Developing control policies in simulation is often more practical and safer
than directly running experiments in the real world. This applies to policies
obtained from planning and optimization, and even more so to policies obtained
from reinforcement learning, which is often very data demanding. However, a
policy that succeeds in simulation often doesn't work when deployed on a real
robot. Nevertheless, often the overall gist of what the policy does in
simulation remains valid in the real world. In this paper we investigate such
settings, where the sequence of states traversed in simulation remains
reasonable for the real world, even if the details of the controls are not, as
could be the case when the key differences lie in detailed friction, contact,
mass and geometry properties. During execution, at each time step our approach
computes what the simulation-based control policy would do, but then, rather
than executing these controls on the real robot, our approach computes what the
simulation expects the resulting next state(s) will be, and then relies on a
learned deep inverse dynamics model to decide which real-world action is most
suitable to achieve those next states. Deep models are only as good as their
training data, and we also propose an approach for data collection to
(incrementally) learn the deep inverse dynamics model. Our experiments shows
our approach compares favorably with various baselines that have been developed
for dealing with simulation to real world model discrepancy, including output
error control and Gaussian dynamics adaptation.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1607.08131v1,2016-07-27T14:54:47Z,2016-07-27T14:54:47Z,Neuromorphic Robot Dream,"In this paper we present the next step in our approach to neurobiologically
plausible implementation of emotional reactions and behaviors for real-time
autonomous robotic systems. The working metaphor we use is the ""day"" and the
""night"" phases of mammalian life. During the ""day phase"" a robotic system
stores the inbound information and is controlled by a light-weight rule-based
system in real time. In contrast to that, during the ""night phase"" information
that has been stored is transferred to a supercomputing system to update the
realistic neural network: emotional and behavioral strategies.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1604.05091v2,2016-04-19T14:09:26Z,2016-04-18T11:15:56Z,"End-to-End Tracking and Semantic Segmentation Using Recurrent Neural
  Networks","In this work we present a novel end-to-end framework for tracking and
classifying a robot's surroundings in complex, dynamic and only partially
observable real-world environments. The approach deploys a recurrent neural
network to filter an input stream of raw laser measurements in order to
directly infer object locations, along with their identity in both visible and
occluded areas. To achieve this we first train the network using unsupervised
Deep Tracking, a recently proposed theoretical framework for end-to-end space
occupancy prediction. We show that by learning to track on a large amount of
unsupervised data, the network creates a rich internal representation of its
environment which we in turn exploit through the principle of inductive
transfer of knowledge to perform the task of it's semantic classification. As a
result, we show that only a small amount of labelled data suffices to steer the
network towards mastering this additional task. Furthermore we propose a novel
recurrent neural network architecture specifically tailored to tracking and
semantic classification in real-world robotics applications. We demonstrate the
tracking and classification performance of the method on real-world data
collected at a busy road junction. Our evaluation shows that the proposed
end-to-end framework compares favourably to a state-of-the-art, model-free
tracking solution and that it outperforms a conventional one-shot training
scheme for semantic classification.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1604.04764v1,2016-04-16T15:09:44Z,2016-04-16T15:09:44Z,"Closed loop interactions between spiking neural network and robotic
  simulators based on MUSIC and ROS","In order to properly assess the function and computational properties of
simulated neural systems, it is necessary to account for the nature of the
stimuli that drive the system. However, providing stimuli that are rich and yet
both reproducible and amenable to experimental manipulations is technically
challenging, and even more so if a closed-loop scenario is required. In this
work, we present a novel approach to solve this problem, connecting robotics
and neural network simulators. We implement a middleware solution that bridges
the Robotic Operating System (ROS) to the Multi-Simulator Coordinator (MUSIC).
This enables any robotic and neural simulators that implement the corresponding
interfaces to be efficiently coupled, allowing real-time performance for a wide
range of configurations. This work extends the toolset available for
researchers in both neurorobotics and computational neuroscience, and creates
the opportunity to perform closed-loop experiments of arbitrary complexity to
address questions in multiple areas, including embodiment, agency, and
reinforcement learning.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1604.04384v2,2016-10-14T08:13:52Z,2016-04-15T07:35:32Z,The STRANDS Project: Long-Term Autonomy in Everyday Environments,"Thanks to the efforts of the robotics and autonomous systems community,
robots are becoming ever more capable. There is also an increasing demand from
end-users for autonomous service robots that can operate in real environments
for extended periods. In the STRANDS project we are tackling this demand
head-on by integrating state-of-the-art artificial intelligence and robotics
research into mobile service robots, and deploying these systems for long-term
installations in security and care environments. Over four deployments, our
robots have been operational for a combined duration of 104 days autonomously
performing end-user defined tasks, covering 116km in the process. In this
article we describe the approach we have used to enable long-term autonomous
operation in everyday environments, and how our robots are able to use their
long run times to improve their own performance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1604.00921v1,2016-03-16T11:00:23Z,2016-03-16T11:00:23Z,"A Review of Theoretical and Practical Challenges of Trusted Autonomy in
  Big Data","Despite the advances made in artificial intelligence, software agents, and
robotics, there is little we see today that we can truly call a fully
autonomous system. We conjecture that the main inhibitor for advancing autonomy
is lack of trust. Trusted autonomy is the scientific and engineering field to
establish the foundations and ground work for developing trusted autonomous
systems (robotics and software agents) that can be used in our daily life, and
can be integrated with humans seamlessly, naturally and efficiently.
  In this paper, we review this literature to reveal opportunities for
researchers and practitioners to work on topics that can create a leap forward
in advancing the field of trusted autonomy. We focus the paper on the `trust'
component as the uniting technology between humans and machines. Our inquiry
into this topic revolves around three sub-topics: (1) reviewing and positioning
the trust modelling literature for the purpose of trusted autonomy; (2)
reviewing a critical subset of sensor technologies that allow a machine to
sense human states; and (3) distilling some critical questions for advancing
the field of trusted autonomy. The inquiry is augmented with conceptual models
that we propose along the way by recompiling and reshaping the literature into
forms that enables trusted autonomous systems to become a reality. The paper
offers a vision for a Trusted Cyborg Swarm, an extension of our previous
Cognitive Cyber Symbiosis concept, whereby humans and machines meld together in
a harmonious, seamless, and coordinated manner.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1603.03007v1,2016-03-09T19:14:27Z,2016-03-09T19:14:27Z,Robot Dream,"In this position paper we present a novel approach to neurobiologically
plausible implementation of emotional reactions and behaviors for real-time
autonomous robotic systems. The working metaphor we use is the ""day"" and
""night"" phases of mammalian life. During the ""day"" phase a robotic system
stores the inbound information and is controlled by a light-weight rule-based
system in real time. In contrast to that, during the ""night"" phase the stored
information is been transferred to the supercomputing system to update the
realistic neural network: emotional and behavioral strategies.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1602.01208v3,2016-05-07T11:59:51Z,2016-02-03T06:56:51Z,"Spatial Concept Acquisition for a Mobile Robot that Integrates
  Self-Localization and Unsupervised Word Discovery from Spoken Sentences","In this paper, we propose a novel unsupervised learning method for the
lexical acquisition of words related to places visited by robots, from human
continuous speech signals. We address the problem of learning novel words by a
robot that has no prior knowledge of these words except for a primitive
acoustic model. Further, we propose a method that allows a robot to effectively
use the learned words and their meanings for self-localization tasks. The
proposed method is nonparametric Bayesian spatial concept acquisition method
(SpCoA) that integrates the generative model for self-localization and the
unsupervised word segmentation in uttered sentences via latent variables
related to the spatial concept. We implemented the proposed method SpCoA on
SIGVerse, which is a simulation environment, and TurtleBot2, which is a mobile
robot in a real environment. Further, we conducted experiments for evaluating
the performance of SpCoA. The experimental results showed that SpCoA enabled
the robot to acquire the names of places from speech sentences. They also
revealed that the robot could effectively utilize the acquired spatial concepts
and reduce the uncertainty in self-localization.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1601.06473v2,2016-01-26T04:43:20Z,2016-01-25T03:31:24Z,Teaching Robots to Do Object Assembly using Multi-modal 3D Vision,"The motivation of this paper is to develop a smart system using multi-modal
vision for next-generation mechanical assembly. It includes two phases where in
the first phase human beings teach the assembly structure to a robot and in the
second phase the robot finds objects and grasps and assembles them using AI
planning. The crucial part of the system is the precision of 3D visual
detection and the paper presents multi-modal approaches to meet the
requirements: AR markers are used in the teaching phase since human beings can
actively control the process. Point cloud matching and geometric constraints
are used in the robot execution phase to avoid unexpected noises. Experiments
are performed to examine the precision and correctness of the approaches. The
study is practical: The developed approaches are integrated with graph
model-based motion planning, implemented on an industrial robots and applicable
to real-world scenarios.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1601.04862v1,2016-01-19T10:29:12Z,2016-01-19T10:29:12Z,Scalability in Neural Control of Musculoskeletal Robots,"Anthropomimetic robots are robots that sense, behave, interact and feel like
humans. By this definition, anthropomimetic robots require human-like physical
hardware and actuation, but also brain-like control and sensing. The most
self-evident realization to meet those requirements would be a human-like
musculoskeletal robot with a brain-like neural controller. While both
musculoskeletal robotic hardware and neural control software have existed for
decades, a scalable approach that could be used to build and control an
anthropomimetic human-scale robot has not been demonstrated yet. Combining
Myorobotics, a framework for musculoskeletal robot development, with SpiNNaker,
a neuromorphic computing platform, we present the proof-of-principle of a
system that can scale to dozens of neurally-controlled, physically compliant
joints. At its core, it implements a closed-loop cerebellar model which
provides real-time low-level neural control at minimal power consumption and
maximal extensibility: higher-order (e.g., cortical) neural networks and
neuromorphic sensors like silicon-retinae or -cochleae can naturally be
incorporated.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1512.05665v2,2016-01-05T10:55:02Z,2015-12-17T16:46:10Z,Probabilistic Programming with Gaussian Process Memoization,"Gaussian Processes (GPs) are widely used tools in statistics, machine
learning, robotics, computer vision, and scientific computation. However,
despite their popularity, they can be difficult to apply; all but the simplest
classification or regression applications require specification and inference
over complex covariance functions that do not admit simple analytical
posteriors. This paper shows how to embed Gaussian processes in any
higher-order probabilistic programming language, using an idiom based on
memoization, and demonstrates its utility by implementing and extending classic
and state-of-the-art GP applications. The interface to Gaussian processes,
called gpmem, takes an arbitrary real-valued computational process as input and
returns a statistical emulator that automatically improve as the original
process is invoked and its input-output behavior is recorded. The flexibility
of gpmem is illustrated via three applications: (i) robust GP regression with
hierarchical hyper-parameter learning, (ii) discovering symbolic expressions
from time-series data by fully Bayesian structure learning over kernels
generated by a stochastic grammar, and (iii) a bandit formulation of Bayesian
optimization with automatic inference and action selection. All applications
share a single 50-line Python library and require fewer than 20 lines of
probabilistic code each.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1411.6326v1,2014-11-24T02:09:59Z,2014-11-24T02:09:59Z,Vision and Learning for Deliberative Monocular Cluttered Flight,"Cameras provide a rich source of information while being passive, cheap and
lightweight for small and medium Unmanned Aerial Vehicles (UAVs). In this work
we present the first implementation of receding horizon control, which is
widely used in ground vehicles, with monocular vision as the only sensing mode
for autonomous UAV flight in dense clutter. We make it feasible on UAVs via a
number of contributions: novel coupling of perception and control via relevant
and diverse, multiple interpretations of the scene around the robot, leveraging
recent advances in machine learning to showcase anytime budgeted cost-sensitive
feature selection, and fast non-linear regression for monocular depth
prediction. We empirically demonstrate the efficacy of our novel pipeline via
real world experiments of more than 2 kms through dense trees with a quadrotor
built from off-the-shelf parts. Moreover our pipeline is designed to combine
information from other modalities like stereo and lidar as well if available.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1411.3895v1,2014-11-14T13:11:32Z,2014-11-14T13:11:32Z,"Learning Fuzzy Controllers in Mobile Robotics with Embedded
  Preprocessing","The automatic design of controllers for mobile robots usually requires two
stages. In the first stage,sensorial data are preprocessed or transformed into
high level and meaningful values of variables whichare usually defined from
expert knowledge. In the second stage, a machine learning technique is applied
toobtain a controller that maps these high level variables to the control
commands that are actually sent tothe robot. This paper describes an algorithm
that is able to embed the preprocessing stage into the learningstage in order
to get controllers directly starting from sensorial raw data with no expert
knowledgeinvolved. Due to the high dimensionality of the sensorial data, this
approach uses Quantified Fuzzy Rules(QFRs), that are able to transform
low-level input variables into high-level input variables, reducingthe
dimensionality through summarization. The proposed learning algorithm, called
Iterative QuantifiedFuzzy Rule Learning (IQFRL), is based on genetic
programming. IQFRL is able to learn rules with differentstructures, and can
manage linguistic variables with multiple granularities. The algorithm has been
testedwith the implementation of the wall-following behavior both in several
realistic simulated environmentswith different complexity and on a Pioneer 3-AT
robot in two real environments. Results have beencompared with several
well-known learning algorithms combined with different data
preprocessingtechniques, showing that IQFRL exhibits a better and statistically
significant performance. Moreover,three real world applications for which IQFRL
plays a central role are also presented: path and objecttracking with static
and moving obstacles avoidance.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1408.1913v1,2014-08-08T16:57:22Z,2014-08-08T16:57:22Z,"Using Learned Predictions as Feedback to Improve Control and
  Communication with an Artificial Limb: Preliminary Findings","Many people suffer from the loss of a limb. Learning to get by without an arm
or hand can be very challenging, and existing prostheses do not yet fulfil the
needs of individuals with amputations. One promising solution is to provide
greater communication between a prosthesis and its user. Towards this end, we
present a simple machine learning interface to supplement the control of a
robotic limb with feedback to the user about what the limb will be experiencing
in the near future. A real-time prediction learner was implemented to predict
impact-related electrical load experienced by a robot limb; the learning
system's predictions were then communicated to the device's user to aid in
their interactions with a workspace. We tested this system with five
able-bodied subjects. Each subject manipulated the robot arm while receiving
different forms of vibrotactile feedback regarding the arm's contact with its
workspace. Our trials showed that communicable predictions could be learned
quickly during human control of the robot arm. Using these predictions as a
basis for feedback led to a statistically significant improvement in task
performance when compared to purely reactive feedback from the device. Our
study therefore contributes initial evidence that prediction learning and
machine intelligence can benefit not just control, but also feedback from an
artificial limb. We expect that a greater level of acceptance and ownership can
be achieved if the prosthesis itself takes an active role in transmitting
learned knowledge about its state and its situation of use.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1405.4378v2,2016-03-03T02:43:03Z,2014-05-17T10:31:22Z,Area Coverage Under Low Sensor Density,"This paper presents a solution to the problem of monitoring a region of
interest (RoI) using a set of nodes that is not sufficient to achieve the
required degree of monitoring coverage. In particular, sensing coverage of
wireless sensor networks (WSNs) is a crucial issue in projects due to failure
of sensors. The lack of sensor equipment resources hinders the traditional
method of using mobile robots to move around the RoI to collect readings.
Instead, our solution employs supervised neural networks to produce the values
of the uncovered locations by extracting the non-linear relation among randomly
deployed sensor nodes throughout the area. Moreover, we apply a hybrid
backpropagation method to accelerate the learning convergence speed to a local
minimum solution. We use a real-world data set from meteorological deployment
for experimental validation and analysis.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1308.3015v1,2013-08-14T02:30:40Z,2013-08-14T02:30:40Z,"On Generalized Bayesian Data Fusion with Complex Models in Large Scale
  Networks","Recent advances in communications, mobile computing, and artificial
intelligence have greatly expanded the application space of intelligent
distributed sensor networks. This in turn motivates the development of
generalized Bayesian decentralized data fusion (DDF) algorithms for robust and
efficient information sharing among autonomous agents using probabilistic
belief models. However, DDF is significantly challenging to implement for
general real-world applications requiring the use of dynamic/ad hoc network
topologies and complex belief models, such as Gaussian mixtures or hybrid
Bayesian networks. To tackle these issues, we first discuss some new key
mathematical insights about exact DDF and conservative approximations to DDF.
These insights are then used to develop novel generalized DDF algorithms for
complex beliefs based on mixture pdfs and conditional factors. Numerical
examples motivated by multi-robot target search demonstrate that our methods
lead to significantly better fusion results, and thus have great potential to
enhance distributed intelligent reasoning in sensor networks.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1305.7432v1,2013-05-31T14:50:36Z,2013-05-31T14:50:36Z,"Real-world Transfer of Evolved Artificial Immune System Behaviours
  between Small and Large Scale Robotic Platforms","In mobile robotics, a solid test for adaptation is the ability of a control
system to function not only in a diverse number of physical environments, but
also on a number of different robotic platforms. This paper demonstrates that a
set of behaviours evolved in simulation on a miniature robot (epuck) can be
transferred to a much larger-scale platform (Pioneer), both in simulation and
in the real world. The chosen architecture uses artificial evolution of epuck
behaviours to obtain a genetic sequence, which is then employed to seed an
idiotypic, artificial immune system (AIS) on the Pioneers. Despite numerous
hardware and software differences between the platforms, navigation and
target-finding experiments show that the evolved behaviours transfer very well
to the larger robot when the idiotypic AIS technique is used. In contrast,
transferability is poor when reinforcement learning alone is used, which
validates the adaptability of the chosen architecture.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1210.3569v2,2013-05-14T15:07:35Z,2012-10-12T16:41:58Z,Autonomous Reinforcement of Behavioral Sequences in Neural Dynamics,"We introduce a dynamic neural algorithm called Dynamic Neural (DN)
SARSA(\lambda) for learning a behavioral sequence from delayed reward.
DN-SARSA(\lambda) combines Dynamic Field Theory models of behavioral sequence
representation, classical reinforcement learning, and a computational
neuroscience model of working memory, called Item and Order working memory,
which serves as an eligibility trace. DN-SARSA(\lambda) is implemented on both
a simulated and real robot that must learn a specific rewarding sequence of
elementary behaviors from exploration. Results show DN-SARSA(\lambda) performs
on the level of the discrete SARSA(\lambda), validating the feasibility of
general reinforcement learning without compromising neural dynamics.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
http://arxiv.org/abs/1202.4261v1,2012-02-20T09:14:12Z,2012-02-20T09:14:12Z,Immuno-inspired robotic applications: a review,"Artificial immune systems primarily mimic the adaptive nature of biological
immune functions. Their ability to adapt to varying pathogens makes such
systems a suitable choice for various robotic applications. Generally,
AIS-based robotic applications map local instantaneous sensory information into
either an antigen or a co-stimulatory signal, according to the choice of
representation schema. Algorithms then use relevant immune functions to output
either evolved antibodies or maturity of dendritic cells, in terms of actuation
signals. It is observed that researchers, in an attempt to solve the problem in
hand, do not try to replicate the biological immunity but select necessary
immune functions instead, resulting in an ad-hoc manner these applications are
reported. Authors, therefore, present a comprehensive review of immuno-inspired
robotic applications in an attempt to categorize them according to underlying
immune definitions. Implementation details are tabulated in terms of
corresponding mathematical expressions and their representation schema that
include binary, real or hybrid data. Limitations of reported applications are
also identified in light of modern immunological interpretations. As a result
of this study, authors suggest a renewed focus on innate immunity and also
emphasize that immunological representations should benefit from robot
embodiment and must be extended to include modern trends.",arxiv,robotics,'robotics' AND 'machine learning' AND ('real-world' AND 'deploy')
