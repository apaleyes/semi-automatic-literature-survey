contentType,identifier,title,publicationName,doi,publisher,publicationDate,abstract,url,database,query_name,query_value
Chapter,doi:10.1007/978-3-031-06870-6_5,"Generated Data, Artificial Intelligence, Power Asymmetries and Quality of Experience",Effects of Data Overload on User Quality of Experience,10.1007/978-3-031-06870-6_5,Springer,2023-01-01,"AI and big data systems are often referred to as smart information systems, where the AI technology makes use of big data to develop and use new technological products across many areas such as education, governance, healthcare, etc. After introducing the idea of smart information systems, the chapter discusses the challenges of such systems. For instance, training an AI model requires a huge amount of data, which is not always available. A solution to using existing datasets as they are is to use generated/synthetic data. This is further investigated and modelled in this chapter.",http://dx.doi.org/10.1007/978-3-031-06870-6_5,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98546-2_29,Defining Machine Learning,Digital Phenotyping and Mobile Sensing,10.1007/978-3-030-98546-2_29,Springer,2023-01-01,Machine learning is a dynamic concept that has been (and continues to be) developed and theorized from multiple perspectives within different disciplines. It defies attempts to arrive at a single fixed definition.,http://dx.doi.org/10.1007/978-3-030-98546-2_29,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-031-07322-9_38,A Review on Technological Advancements in the Field of Data Driven Structural Health Monitoring,European Workshop on Structural Health Monitoring,10.1007/978-3-031-07322-9_38,Springer,2023-01-01,"Recent advancements in sensor technology, as well as fast progress in internet-based cloud computation; data-driven approaches in structural health monitoring (SHM) are gaining prominence. The majority of time is utilized for reviewing & analyzing the data received from various sensors deployed in structures. This data analysis helps in understating the structural stability and its current state with certain limitations. Considering this fact, integration with Machine Learning (ML) in SHM has attracted significant attention among researchers. This paper is principally aimed at understanding and reviewing of vast literature available in sensor-based data-driven approaches using ML. The implementation and methodology of vibration-based, vision-based monitoring, along with some of the ML algorithms used for SHM are discussed. Nevertheless, a perspective on the importance of data-driven SHM in the future is also presented. Conclusions are drawn from the review discuss the prospects and potential limitations of ML approaches in data-driven SHM applications.",http://dx.doi.org/10.1007/978-3-031-07322-9_38,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-3-030-94285-4_2,On-Phone CNN Model-Based Implicit Authentication to Secure IoT Wearables,The Fifth International Conference on Safety and Security with IoT,10.1007/978-3-030-94285-4_2,Springer,2023-01-01,"The connectivity of smart technologies, such as smartphones and smart wearables, is ever-increasing with the emergence of the internet of things (IoT). This technological advancement makes it possible to serve emerging applications, such as financial transactions, healthcare check-ups, and property access, easily through smart wearables, such as Apple Watch. This also presents a new vulnerability as hackers have more opportunities to attack users via the wearables. As the current knowledge-based wearable authentication schemes, such as passwords, PINs, or pattern locks, are overwhelming for users, we need an authentication system that can validate a user implicitly, i.e., without the need for active user interaction. In this work, we present an authentication system for the wearables leveraging the sensing and computation power of smartphones and IoT connectivity. We develop a smartphone application ( TFL Auth app) using the TensorFlow Lite framework and an on-phone convolutional neural network (CNN) model that listens to a user’s breathing patterns through the microphone and verifies the user’s identity in real-time before sending the acceptance/rejection notification to a paired wearable that we want to secure. From a detailed analysis, we are able to achieve an average accuracy of 0.92 ± 0.01 using the Mel-frequency cepstral coefficients.",http://dx.doi.org/10.1007/978-3-030-94285-4_2,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0151-5_29,Design and Analysis of Adversarial Samples in Safety–Critical Environment: Disease Prediction System,Artificial Intelligence on Medical Data,10.1007/978-981-19-0151-5_29,Springer,2023-01-01,"Deep learning is a part of machine learning applied in many applications, from object detection to disease prediction. In 2013, deep neural networks were vulnerable to perturbed samples during the testing/deployment stage. Deep learning becomes a significant issue when we apply such algorithms in designing safety–critical applications. Deep neural networks are fooled by adding some noise intentionally in the image such that the changes are sometimes not noticeable to the human eye and are known as an adversarial mechanism. The noise adds in such a direction that the difference between the original and perturbed images should be minimal. This work demonstrates the designing of adversarial images and analyzing them on the disease prediction using a chest X-ray prototype system. This work illustrates the design of adversarial samples using three different methods: an image augmentation scheme, filtering, and patches and analysis of how adversarial samples affect the result in real-world clinical settings. The change in the clinical setting not only affects the healthcare economy but also raises technical vulnerability. This work attempts to design and improve a more robust medical learning system. The analysis shows if patches applied in specific regions give expected results to the adversary. In this work, after the successful attack model shows 71% of confidence.",http://dx.doi.org/10.1007/978-981-19-0151-5_29,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-030-98546-2_21,Optimizing mHealth Interventions with a Bandit,Digital Phenotyping and Mobile Sensing,10.1007/978-3-030-98546-2_21,Springer,2023-01-01,"Mobile health (mHealth) interventions can improve health outcomes by intervening in the moment of need or in the right life circumstance. mHealth interventions are now technologically feasible because current off-the-shelf mobile phones can acquire and process data in real time to deliver relevant interventions in the moment. Learning which intervention to provide in the moment, however, is an optimization problem. This book chapter describes one algorithmic approach, a “bandit algorithm,” to optimize mHealth interventions. Bandit algorithms are well-studied and are commonly used in online recommendations (e.g., Google’s ad placement, or news recommendations). Below, we walk through simulated and real-world examples to demonstrate how bandit algorithms can be used to personalize and contextualize mHealth interventions. We conclude by discussing challenges in developing bandit-based mhealth interventions.",http://dx.doi.org/10.1007/978-3-030-98546-2_21,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02063-6_13,Critical Infrastructure Protection: Where Convergence of Logical and Physical Security Technologies is a Must,System Dependability and Analytics,10.1007/978-3-031-02063-6_13,Springer,2023-01-01,"Security monitoring is a number one priority, especially in Critical Infrastructure Protection (CIP), where cyber attacks may have dramatic safety impacts, in that they may well result in major damage to assets and/or harm to people. Since effective protection requires that the right actions be taken at the right time, the results of the monitoring process must: (i) be made available in a timely fashion (i.e. in near real-time), and (ii) include detailed diagnostic information (i.e. clearly identify the nature of the problem and the extent of the damage). In this chapter, we: (1) propose an approach for dependable (i.e. accurate, timely, and trustworthy) security monitoring, based on correlation of logical and physical events, (2) implement the approach in a distributed architecture integrating cutting-edge commercial off-the-shelf (COTS) technologies, and (3) validate the approach with respect to a handful of case studies, characterized by challenging—and quite diverse—requirements.",http://dx.doi.org/10.1007/978-3-031-02063-6_13,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-2394-4_5,Different Applications and Technologies of Internet of Things (IoT),Proceedings of Seventh International Congress on Information and Communication Technology,10.1007/978-981-19-2394-4_5,Springer,2023-01-01,"Internet of things (IoT) has significantly altered the traditional lifestyle to a highly technologically advanced society. Some of the significant transformations that have been achieved through IoT are smart homes, smart transportation, smart city, and control of pollution. A considerable number of studies have been conducted and continues to be done to increase the use of technology through IoT. Furthermore, the research about IoT has not been done fully in improving the application of technology through IoT. Besides, IoT experiences several problems that need to be considered in order to get the full capability of IoT in changing society. This research paper addresses the key applications of IoT, the architecture of IoT, and the key issues affecting IoT. In addition, the paper highlights how big data analytics is essential in improving the effectiveness of IoT in various applications within society.",http://dx.doi.org/10.1007/978-981-19-2394-4_5,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0095-2_46,A Study of Emerging IoT Technologies for Handling Pandemic Challenges,Information and Communication Technology for Competitive Strategies (ICTCS 2021),10.1007/978-981-19-0095-2_46,Springer,2023-01-01,"Modern years, the Internet of Things (IoT) is mechanizing in abundant real-world functions such as smart transportation, smart business to build an individual life more accessible. IoT is the mainly used method in the previous decade in different functions. Deadly diseases always had severe effects unless they were well controlled. The latest knowledge with COVID-19 explains that by using a neat and speedy approach to deal with deadly diseases, avoid devastating of healthcare structures, and reduce the loss of valuable life. The elegant things are associated with wireless or wired communication, processing, computing, and monitoring dissimilar real-time situations. These things are varied and have low remembrance, less processing control. This article explains a summary of the system and the field of its function. The recent technology has supplied to manage previous closest diseases. From years ago, scientists, investigators, physicians, and healthcare specialists are using novel computer methods to resolve the mysteries of disease. The major objective is to study dissimilar innovation-based methods and methods that support handling deadly disease challenges that are further appropriate developments that can probably be utilized.",http://dx.doi.org/10.1007/978-981-19-0095-2_46,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0105-8_29,Rapid Diagnosis of COVID-19 Using Radiographic Images,Proceedings of International Conference on Frontiers in Computing and Systems,10.1007/978-981-19-0105-8_29,Springer,2023-01-01,"A COVID-19 patient suffers from blockage of breathing and chest pain at a critical condition due to the formation of fibrosis in the lungs and needs emergency lifesaving treatment. Before starting an adequate treatment, a confirmed diagnosis of COVID-19 is a mandatory criterion. For a patient with critical respiratory syndrome, rapid and precise diagnosis is a prime challenge. Different manual methods of clinical diagnosis are in practice. However, these manual techniques suffer from serious drawbacks such as poor sensitivity, false negative results, and high turn-around time. The diagnosis based on the radiographic image (X-ray or computed tomography) of infected lungs is another clinical method for rapid diagnosis of COVID-19. However, it requires an expert radiologist for precise diagnosis. Instead of a prolonged clinical process, an alternative way of rapid diagnosis is the only way of some lifesaving. As an elegant solution, some radiographic image-based automated diagnostic systems have been suggested using deep learning techniques. However, they suffer from some unavoidable limitations concerned with deep learning. This paper suggests a user-friendly system for instant diagnosis of COVID-19 using radiographic images of infected lungs of a critical patient. The model is designed based on classical image processing techniques and machine learning techniques that have provided low complexity but a very high accuracy of 98.51%. In this pandemic situation, such a simple and instantaneous diagnostic system can become a silver lining to compensate for the scarcity of expert radiologists.",http://dx.doi.org/10.1007/978-981-19-0105-8_29,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-06829-4_2,The Application of Blockchain of Things (BCoT) in the Construction Industry,Blockchain of Things and Deep Learning Applications in Construction,10.1007/978-3-031-06829-4_2,Springer,2023-01-01,"Various applications integrating blockchain with the Internet of Things (IoT) have emerged in recent years. While industries such as automotive have embraced this integration, application in other areas such as construction remains limited. The scientometric analysis is applied to 648 papers, identifying the use of IoT and blockchain in engineering and evaluating the progress of research in the construction industry. The qualitative critical review is applied to 88 papers and analyses successful IoT and blockchain application cases in construction while highlighting challenges and limitations. Blockchain of Things (BCoT) was introduced to exploit the advantages of IoT and Blockchain as a new concept. This chapter presents the potential uses of BCoT in the construction industry. This chapter provides researchers with a comprehensive view of related literature and gaps and indicates future research.",http://dx.doi.org/10.1007/978-3-031-06829-4_2,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0095-2_60,Automatic Waste Segregation System: An IOT Approach,Information and Communication Technology for Competitive Strategies (ICTCS 2021),10.1007/978-981-19-0095-2_60,Springer,2023-01-01,"Effective waste management and disposal are major issues in today’s world, especially in countries like India where a majority of individuals do not use separate trash bins for recyclable and non-recyclable waste. This is a major cause of pollution and diseases in the country. However, separating them manually is a tedious process and also not efficient. Improper segregation results in pollution and affects the environment. We have developed an automated trash bin which autonomously classifies and segregates wastes as biodegradable and non-biodegradable and places them in the respective bin. We have achieved the same using IOT by passing the image data to the cloud to perform analytics and return the classified output to the controller of the bin and trigger it to place the waste in the correct container. We also send the usage data to the cloud to perform analytics about the bin usage and deploy it in a Web app to report the live status.",http://dx.doi.org/10.1007/978-981-19-0095-2_60,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-0151-5_28,Channel-Based Similarity Learning Using 2D Channel-Based Convolutional Neural Network,Artificial Intelligence on Medical Data,10.1007/978-981-19-0151-5_28,Springer,2023-01-01,"Object identification is one of the major aspects of computer vision. In recent years, the development the computing as well as the storage capacity has increased drastically. These breakthroughs in the technology have blessed us with various data storage technologies and computational engines. Because of the breakthrough in recent years, we are generating humongous amounts of data of which 80% of data is unstructured data and only 20% of data is structured. Unstructured data are mainly composed of images, video and as well as the natural language, i.e. text. These 80% unstructured data consist of the enormous information, but it is difficult to unravel the information contained in these data. Convolution neural network (CNN) is backbone of computer vision and deals with extracting information from the image and video, before the invention of recurrent neural network (RNN), CNN was also employed for natural language processing (NLP) task such as classification and text generation, but the specialty of CNN lies where the dataset consists of sound signals, images or sequence of frames. On Internet, we can find 60% of the unstructured dataset consists of images or sequence of image or text. Basically, image consists of the features which is the orientation of the pixels in a well-defined pattern which can be extracted by using kernel’s known as the feature maps and Maxpooling layers to extract the underlying feature present in the image to train the neural network. CNN is one of the parts of supervised learning techniques which uses labelled data, but it is difficult to label huge number of images. The similarity-based learning enables us to control the similarity percentage as well as it has minimum labelling procedure, i.e. labelling of the dataset is to be labelled 0 or 1. Similarity learning is used to compute the percentage of the features which are similar in the target image with respect to the input image. Image consists of three channels, i.e. red, green and blue channels, which is basically a 2D vector with pixel values in range of 0–255. These individual channels contribute to the features present in the images, and if we can calculate the similarity between input image and the query image, then we can be able to present the unstructured images in relation to the similarity with respect to the input image by using the channels in channel-based CNN tower.",http://dx.doi.org/10.1007/978-981-19-0151-5_28,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-2065-3_68,Application of Ontologies in the Enterprise—Overview and Critical Analysis,Proceedings of the Third International Conference on Information Management and Machine Intelligence,10.1007/978-981-19-2065-3_68,Springer,2023-01-01,"For many years, it was claimed that semantics should provide foundation of knowledge management in the enterprise. Today, it is easy to realize that this vision did not materialize. The aim of this work is to critically analyse the state of the art of use of semantic technologies in the enterprise and an attempt at diagnosing key problem(s).",http://dx.doi.org/10.1007/978-981-19-2065-3_68,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-02063-6_10,Providing Compliance in Critical Computing Systems,System Dependability and Analytics,10.1007/978-3-031-02063-6_10,Springer,2023-01-01,"Critical services such as health care, finance, power, public utility, are being hosted in critical computing systems like cloud, big data and AI platforms. Compliance is one of the main instruments governments exert on such computing systems for regulating security and reliability so that governments and the public can obtain the assurance that no severe unacceptable impacts or incidents may occur. This article gives a comprehensive discussion on the compliance problem in critical computing systems, and describes state-of-the-art technologies and practices of compliance validation/enforcement. This article is very helpful for those professionals working on critical computing systems and services.",http://dx.doi.org/10.1007/978-3-031-02063-6_10,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-1844-5_59,Wireless Sensor Networks (WSNs) in Air Pollution Monitoring: A Review,Intelligent Communication Technologies and Virtual Mobile Networks,10.1007/978-981-19-1844-5_59,Springer,2023-01-01,Air pollution is the major concern in urban areas due to the impacts of air pollution on health and environment. A number of studies reveal the importance to be aware of air pollution and air pollution monitoring systems. This paper is a review article based on different methods implemented by the researchers to know about the concentration levels of particles and gases in air. The paper focuses on the different networks that are used for the pollution monitoring system and how they work effectively.,http://dx.doi.org/10.1007/978-981-19-1844-5_59,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-1142-2_63,Preserving Privacy in Internet of Things (IoT)-Based Devices,"Proceedings of Third International Conference on Computing, Communications, and Cyber-Security",10.1007/978-981-19-1142-2_63,Springer,2023-01-01,"According to the global risk reports, data breaches and cyberattacks are in the top 5 deliberate risks. We all are aware of the rapid advancement and deployment of the IoT. Because these technologies are so tightly linked to individuals, privacy and security are important problems in today’s world. Attackers who try to target IoT must constantly expose communication relations to capture transferred data and identify subtle data since they always rely on formerly gathered information to launch their attacks. Sleep is one of the crucial activities to our health. Depression, difficulty in concentrating, and irritability are a few important concerns that are caused by sleeping disorders. Using a sleep tracker may help a person understand their sleeping behavior and detect many important concerns. There are several dangers connected with information gathering since these IoT-based gadgets, including tracking device stowage, data transmission across a system, and information storage in the cloud. The information gathered by IoT instruments can expose the users’ everyday activities, location, and other delicate statistics. Hackers usually try to attack these and when gadgets or the stowage is hewed, they may get confidential information and facts about their personal belonging and that data can be future used for phishing or advertisements. As a result, the privacy of data gathered by IoT-based devices must be protected.",http://dx.doi.org/10.1007/978-981-19-1142-2_63,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter,doi:10.1007/978-3-031-06870-6_1,Responsible Innovation in Technology and Quality of Experience,Effects of Data Overload on User Quality of Experience,10.1007/978-3-031-06870-6_1,Springer,2023-01-01,"Quality of experience (QoE) is an assessment of the human experience when interacting with technology and organizations within a specific context (Laghari and Connelly 2012). Arguably, the quality of experience is subjective. It depends on the experience of a given human user, on how they perceive, for example, a service, software, an application, etc. However, the quality of experience is the only criterion that actually counts to a user of a service. Although a perceived experience is subjective, in order for any system to be successful (i.e. the user accepts to use it), it is still imperative to identify, quantify and improve the perception of QoE for the user, throughout the system’s use. QoE is the collective effect of service performance determining a user’s degree of satisfaction – what a user experiences of the service’s accessibility, usability, retainability and integrity (Dillon et al. 2009). Ultimately, QoE is a measurement of the whole performance of a system at the user level, and it is an indication of the level a system satisfies the user’s (perceived) needs and expectations. Moreover, technology is not value-neutral (van de Poel 2012); value-sensitive design (Brey, 2010) is an approach that claims that designed artefacts are not morally neutral but harbour tendencies to promote or violate certain values. For example, web browsers and apps may be either designed to protect the user’s privacy or they may offer no such protection, or may even violate user privacy (Brey 2016).",http://dx.doi.org/10.1007/978-3-031-06870-6_1,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Chapter ConferencePaper,doi:10.1007/978-981-19-1844-5_62,The Web-Based History Learning Application for 6th-Grade Students,Intelligent Communication Technologies and Virtual Mobile Networks,10.1007/978-981-19-1844-5_62,Springer,2023-01-01,"A great nation is a nation that upholds the services of its predecessors, namely the nation's heroes who fought for the independence of this Indonesian state in 1945. The current generation is expected to appreciate the services of heroes by respecting this nation's history and the current generation's duty to fill this independence by continuing its values. It is essential for the transformation of knowledge to each generation to seriously study the history of this nation through the delivery of historical subject matter. Therefore in this paper, a web-based history learning application is developed which is limited to 6th-grade elementary school students where the proposed system is modeled using use case diagrams, and after that by using class diagrams, the relationship between database tables is displayed, and in the end, the user interface is shown as implementation using software Personal Home Pages (PHP) and MySQL database.",http://dx.doi.org/10.1007/978-981-19-1844-5_62,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12065-021-00608-8,MRMR-SSA: a hybrid approach for optimal feature selection,Evolutionary Intelligence,10.1007/s12065-021-00608-8,Springer,2022-09-01,"A critical issue in data mining and machine learning is feature selection. The crucial part is how to specify the eminent problem-relevant features out of a collection of features contained in a dataset. Feature selection process goes with the pre processing steps in knowledge revelation (KDD process). It aids in eliminating the unnecessary (redundant) and unrelated (irrelevant) features in order to improve the fulfillment of classifying algorithms. It chooses the most optimal count of features that is best suited to classification model which in turn advance the learning process. As such, the correctness (accuracy) of classification increases. Thus, in this paper we have proposed a two-staged hybrid arrangement of model that contains filter-based approach in the first stage to filter out the unnecessary and unrelated features and then providing these acquired features as input to the next stage that is the wrapper method by availing the recent swarm based algorithm, namely, salp swarm algorithm or SSA. The proposed model is named as MRMR-SSA. The binary version of SSA is utilized to evaluate the features that can either take the feature as 1 or discard it as 0. Specific classifiers like XGBoost, AdaBoost, Random forests and Logistic Regression are made in use in this paper. Accuracy is considered to measure the performance of each classifier. An analogy is made for the proposed hybrid feature selection approach with a few familiar algorithms specifically MRMR-PSO, MRMR-GA, MRMR-ALO and MRMR-ACO. The proposed hybrid approach leaves behind other given hybrid methods.",http://dx.doi.org/10.1007/s12065-021-00608-8,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12065-021-00598-7,Predicting the pandemic: sentiment evaluation and predictive analysis from large-scale tweets on Covid-19 by deep convolutional neural network,Evolutionary Intelligence,10.1007/s12065-021-00598-7,Springer,2022-09-01,"Engaging deep neural networks for textual sentiment analysis is an extensively practiced domain of research. Textual sentiment classification harnesses the full computational potential of deep learning models. Typically, these research works are carried either with a popular open-source data corpus, or self-extracted short phrase texts from Twitter, Reddit, or web-scrapped text data from other resources. Rarely do we see a large amount of data on a current ongoing event is being collected and cultured further. Also, an even more complex task would be to model the data from a currently ongoing event, not only for scaling the sentiment accuracy but also for making a predictive analysis for the same. In this paper, we propose a novel approach for achieving sentiment evaluation accuracy by using a deep neural network on live-streamed tweets on Coronavirus and future case growth prediction. We develop a large tweet corpus exclusively based on the Coronavirus tweets. We split the data into train and test sets, alongside we perform polarity classification and trend analysis. The refined outcome from the trend analysis helps to train the data to provide an incremental learning curvature for our neural network, and we obtain an accuracy of 90.67%. Finally, we provide a statistical-based future prediction for Coronavirus cases growth. Not only our model outperforms several previous state-of-art experiments in overall sentiment accuracy comparison for similar tasks, but it also maintains a throughout performance stability among all the test cases when tested with several popular open-source text corpora.",http://dx.doi.org/10.1007/s12065-021-00598-7,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41403-022-00338-y,Passenger Surveillance Using Deep Learning in Post-COVID-19 Intelligent Transportation System,Transactions of the Indian National Academy of Engineering,10.1007/s41403-022-00338-y,Springer,2022-09-01,"Intelligent Transport System should be renovated in many aspects in post-pandemic situation like COVID-19. The passenger-count inside a car will be restricted based on the vehicle capacity and the COVID-19 hot-spot zone. Traffic rules will be impacted to align with a similar contagious outbreak. The on-road ‘Yellow-Vulture’ cameras need to incorporate such surveillance rules to monitor related anomalies for preventing contamination. To maintain safe-distance, an automatic surveillance system will be preferred by the Government very soon. Moreover, facial mask usage during the journey has become an essential habit to stop the spread of the infection. In this article, we have proposed a deep-Learning based framework that employs an augmented image data set to provide proper surveillance in the transport system to maintain the health protocols. Fast and accurate detection of the number of passengers inside a car and their face masks from the traffic inspection camera feed has been demonstrated. We have exploited the advantages of the popular Transfer Learning approach with novel variations of images while performing the training. To the best of our knowledge, this is the first attempt to watch over in-vehicle social-distancing in post-pandemic circumstances through deep-Learning based image analysis. The superiority of the proposed framework has been established over several state-of-the-art techniques using different numerical metrics and visual comparisons along with a support of statistical hypothesis test. Our technique has achieved $$98.5\%$$ 98.5 % testing accuracy in various adverse conditions. Zero-shot evaluation has been explored for the Real-Time-Medical-Mask-Detection data set Wang et al. (Real-Time-Medical-Mask-Detection, 2020a https://github.com/TheSSJ2612/Real-Time-Medical-Mask-Detection/ , Accessed 14 Nov 2020), where we have attained $$96.4\%$$ 96.4 % accuracy that manifests the generalization of the network.",http://dx.doi.org/10.1007/s41403-022-00338-y,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s13042-022-01556-0,Learning to share by masking the non-shared for multi-domain sentiment classification,International Journal of Machine Learning and Cybernetics,10.1007/s13042-022-01556-0,Springer,2022-09-01,"Multi-domain sentiment classification deals with the scenario where labeled data exists for multiple domains but is insufficient for training effective sentiment classifiers that work across domains. Thus, fully exploiting sentiment knowledge shared across domains is crucial for real-world applications. While many existing works try to extract domain-invariant features in high-dimensional space, such models fail to explicitly distinguish between shared and private features at the text level, which to some extent lacks interpretability. Based on the assumption that removing domain-related tokens from texts would help improve their domain invariance, we instead first transform original sentences to be domain-agnostic . To this end, we propose the BERTMasker model which explicitly masks domain-related words from texts, learns domain-invariant sentiment features from these domain-agnostic texts and uses those masked words to form domain-aware sentence representations. Empirical experiments on the benchmark multiple domain sentiment classification datasets demonstrate the effectiveness of our proposed model, which improves the accuracy on multi-domain and cross-domain settings by 1.91% and 3.31% respectively. Further analysis on masking proves that removing those domain-related and sentiment irrelevant tokens decreases texts’ domain separability, resulting in the performance degradation of a BERT-based domain classifier by over 12%.",http://dx.doi.org/10.1007/s13042-022-01556-0,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00125-022-05755-w,58th EASD Annual Meeting of the European Association for the Study of Diabetes,Diabetologia,10.1007/s00125-022-05755-w,Springer,2022-08-03,,http://dx.doi.org/10.1007/s00125-022-05755-w,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1186/s42400-022-00129-6,Sarve: synthetic data and local differential privacy for private frequency estimation,Cybersecurity,10.1186/s42400-022-00129-6,Springer,2022-08-03,"The collection of user attributes by service providers is a double-edged sword. They are instrumental in driving statistical analysis to train more accurate predictive models like recommenders. The analysis of the collected user data includes frequency estimation for categorical attributes. Nonetheless, the users deserve privacy guarantees against inadvertent identity disclosures. Therefore algorithms called frequency oracles were developed to randomize or perturb user attributes and estimate the frequencies of their values. We propose Sarve , a frequency oracle that used Randomized Aggregatable Privacy-Preserving Ordinal Response (RAPPOR) and Hadamard Response (HR) for randomization in combination with fake data. The design of a service-oriented architecture must consider two types of complexities, namely computational and communication. The functions of such systems aim to minimize the two complexities and therefore, the choice of privacy-enhancing methods must be a calculated decision. The variant of RAPPOR we had used was realized through bloom filters. A bloom filter is a memory-efficient data structure that offers time complexity of O(1). On the other hand, HR has been proven to give the best communication costs of the order of log(b) for b-bits communication. Therefore, Sarve is a step towards frequency oracles that exhibit how privacy provisions of existing methods can be combined with those of fake data to achieve statistical results comparable to the original data. Sarve also implemented an adaptive solution enhanced from the work of Arcolezi et al. The use of RAPPOR was found to provide better privacy-utility tradeoffs for specific privacy budgets in both high and general privacy regimes.",http://dx.doi.org/10.1186/s42400-022-00129-6,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10207-022-00599-2,The SAINT observatory subsystem: an open-source intelligence tool for uncovering cybersecurity threats,International Journal of Information Security,10.1007/s10207-022-00599-2,Springer,2022-08-03,"Data from Online Social Networks, search engines, and the World Wide Web are forms of unstructured knowledge that are not regularly used in cybersecurity systems. The main reason for the reluctance to utilize them is the difficulty to process them effectively and extract valuable information. In this paper, we present the Systemic Analyzer In Network Threats (SAINT) Observatory Subsystem or SAINToS for short, a novel platform for the acquisition and analysis of Open-Source Intelligence feeds. The proposed framework integrates different information pools to create a supplementary view of the evolving cybercriminal activity. The aim of SAINToS, is to provide additional models, methodologies, and mechanisms to enrich existing cybersecurity analysis. As a significant amount of related information is not standardized in the form of structured data tables or machine-processable formats (e.g., XML or JSON), secondary data sources, such as social networks and blogs, are expected to expand the scope and effectiveness of existing approaches. The emphasis of this work, is placed on the harmonization and visualization of data from different sources. As a result, these sources can be better understood and reused. In addition, the SAINToS, besides its standalone functionality and capabilities, can provide input, in standard formats, to additional major threat intelligence platforms.",http://dx.doi.org/10.1007/s10207-022-00599-2,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s42979-022-01341-4,Chinese Sign Language Recognition with Batch Sampling ResNet-Bi-LSTM,SN Computer Science,10.1007/s42979-022-01341-4,Nature,2022-08-03,"Sign language has served as a communication medium between the Deaf community and society. Nonetheless, the practice of sign language is not common in Chinese society, along with a lack of professional sign language interpreters. Most existing studies on sign language recognition have only considered basic, simple, and static handshapes, which have not been practically implemented as real-world applications. To resolve the shortage of sign language interpreters, a sign language recognition application that interprets the sign language is required. Thus, the aim of this study was to develop and evaluate a sign language recognition framework using multi-modalities approach and spatio-temporal features that include dynamic handshapes. The proposed framework consists of three main parts, namely handshape recognition, movement tracking, and sign recognition. In this study, the use of hand skeletal data as features was also investigated, which were input to a bi-directional long short-term memory (Bi-LSTM) model for sign recognition. The proposed model was evaluated on a continuous Chinese sign language (CSL) dataset of 8 subjects with 1200 sample videos covering 100 signs. The experimental results demonstrated a true recognition rate of 98.75%, outperforming most of the state-of-the-art alternatives used for sign language recognition. The proposed sign recognition application can be deployed in public service sectors such as banks, hospitals, and police stations.",http://dx.doi.org/10.1007/s42979-022-01341-4,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10586-022-03677-1,An adaptive and secure routes migration model for the sustainable cloud of things,Cluster Computing,10.1007/s10586-022-03677-1,Springer,2022-08-03,"Software-defined networks (SDN) have gained a lot of attention in recent years as a technique to develop smart systems with a help of the Internet of Things (IoT). Its powerful and centralized architecture makes a balanced contribution to the management of sustainable applications through efficient processes. These networks also systematically keep track of mobile devices and decrease the extra overheads in the communication cost. Many solutions are proposed to cope with data transferring for the critical system, however, mobile devices, on the other hand, require long-distance communication links with minimal retransmissions. Furthermore, the mobile network is highly infected by security attacks and compromised the IoT architecture for both the intermediate layers and end-users. Therefore, this paper presents an adaptive routes migration model for sustainable applications with the collaboration of SDN architecture and limits the disconnectivity time in data transporting along with efficient management of network services. Moreover, its centralized controller fetches the updated information from low-level smart devices and supervised their monitoring efficiently. The proposed model also secures the cloud of things (CoTs) from network threats and protects private data. It provides three levels of security algorithms and supports adaptive computing systems. The proposed model was tested using simulations, and the findings showed that it outperformed other existing studies in terms of packet delivery ratio by 13%, packet loss rate by 15%, transmission error by 22%, computing cost by 17%, and latency by 18%.",http://dx.doi.org/10.1007/s10586-022-03677-1,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10994-022-06218-4,Explainable online ensemble of deep neural network pruning for time series forecasting,Machine Learning,10.1007/s10994-022-06218-4,Springer,2022-08-02,"Both the complex and evolving nature of time series data make forecasting among one of the most challenging tasks in machine learning. Typical methods for forecasting are designed to model time-evolving dependencies between data observations. However, it is generally accepted that none of them are universally valid for every application. Therefore, methods for learning heterogeneous ensembles by combining a diverse set of forecasters together appears as a promising solution to tackle this task. While several approaches in the context of time series forecasting have focused on how to combine individual models in an ensemble, ranging from simple and enhanced averaging tactics to applying meta-learning methods, few works have tackled the task of ensemble pruning, i.e. individual model selection to take part in the ensemble. In addition, in classical ML literature, ensemble pruning techniques are mostly restricted to operate in a static manner. To deal with changes in the relative performance of models as well as changes in the data distribution, we employ gradient-based saliency maps for online ensemble pruning of deep neural networks. This method consists of generating individual models’ performance saliency maps that are subsequently used to prune the ensemble by taking into account both aspects of accuracy and diversity. In addition, the saliency maps can be exploited to provide suitable explanations for the reason behind selecting specific models to construct an ensemble that plays the role of a forecaster at a certain time interval or instant. An extensive empirical study on many real-world datasets demonstrates that our method achieves excellent or on par results in comparison to the state-of-the-art approaches as well as several baselines. Our code is available on Github ( https://github.com/MatthiasJakobs/os-pgsm/tree/ecml_journal_2022 ).",http://dx.doi.org/10.1007/s10994-022-06218-4,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10209-022-00903-w,A systematic literature review of mobile application usability: addressing the design perspective,Universal Access in the Information Society,10.1007/s10209-022-00903-w,Springer,2022-08-02,"Advances in mobile technologies and wireless Internet services have accelerated the growth of the mobile app market. To nurture such growth, the usability of mobile apps must be addressed as a priority. Indeed, the unique characteristics of mobile phones, such as the screen size, connectivity, processing capabilities, and context of use, require a high level of usability for mobile apps. Mobile app usability requirements vary with the category of the app. However, mobile app usability is not well understood, and this may lead to the ineffective design of mobile apps and may thus influence users’ acceptance of mobile apps. This study systematically reviews and discusses mobile app usability. It identifies and interprets the relationships among the usability principles, attributes, and design features with the objective of informing mobile app usability design. It also identifies and discusses a set of common usability design features in mobile app design and a set of usability design features that are required in specific mobile app categories.",http://dx.doi.org/10.1007/s10209-022-00903-w,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00521-022-07633-3,An integrated spatiotemporal-based methodology for deepfake detection,Neural Computing and Applications,10.1007/s00521-022-07633-3,Springer,2022-08-02,"Rapid advances in deep learning models have made it easier for public and crackers to generate hyper-realistic deepfake videos in which faces are swapped. Such deepfake videos may constitute a significant threat to the world if they are misused to blackmail public figures and to deceive systems of face recognition. As a result, distinguishing these fake videos from real ones has become fundamental. This paper introduces a new deepfake video detection method. You Only Look Once (YOLO) face detector is used to detect faces from video frames. A proposed hybrid method based on proposing two different feature extraction methods is applied to these faces. The first feature extraction method, a proposed Convolution Neural Network (CNN), is based on the Histogram of Oriented Gradient (HOG) method. The second one is an ameliorated XceptionNet CNN. The two extracted sets of features are merged together and fed as input to a sequence of Gated Recurrent Units (GRUs) to extract the spatial and temporal features and then individuate the authenticity of videos. The proposed method is trained on the CelebDF-FaceForencics++ (c23) dataset and evaluated on the CelebDF test set. The experimental results and analysis confirm the superiority of the suggested method over the state-of-the-art methods.",http://dx.doi.org/10.1007/s00521-022-07633-3,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10055-022-00677-9,Effects of physical walking on eyes-engaged target selection with ray-casting pointing in virtual reality,Virtual Reality,10.1007/s10055-022-00677-9,Springer,2022-08-02,"Target selection in virtual reality (VR) is usually carried out with the need of visual attention. While target selection in VR has been extensively investigated in non-walking activities (e.g., sitting or standing), there have been few studies about eyes-engaged target selection during walking in virtual environments. Therefore, we conducted a comprehensive study to explore the effects of physical walking (as an independent variable with low, medium and high speeds) on eyes-engaged selection tasks with targets (three target sizes and three target depths) in two experiments: targets fixed in the virtual environment (Experiment One) and targets fixed to the virtual body (Experiment Two), respectively. Results showed that for Experiment One, the low walking speed led to the significantly longest task completion time, while the medium and high speeds had similar task completion time. For Experiment Two, higher walking speed led to longer task completion time. In both tasks, error rate significantly increased as walking speed increased. The effects of walking speed also varied across target size and target depth. We conclude our study with a set of design implications for target selection tasks when walking in VR environments.",http://dx.doi.org/10.1007/s10055-022-00677-9,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s10479-022-04844-8,Reconceptualizing cybersecurity awareness capability in the data-driven digital economy,Annals of Operations Research,10.1007/s10479-022-04844-8,Springer,2022-08-02,"Data breaches have become a formidable challenge for business operations in the twenty-first century. The emergence of big data in the ever-growing digital economy has created the necessity to secure critical organizational information. The lack of cybersecurity awareness exposes organizations to potential cyber threats. Thus, this research aims to identify the various dimensions of cybersecurity awareness capabilities. Drawing on the dynamic capabilities framework, the findings of the study show personnel (knowledge, attitude and learning), management (training, culture and strategic orientation) and infrastructure capabilities (technology and data governance) as thematic dimensions to tackle cybersecurity awareness challenges.",http://dx.doi.org/10.1007/s10479-022-04844-8,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1557/s43577-022-00364-9,The status and prospects of materials for carbon capture technologies,MRS Bulletin,10.1557/s43577-022-00364-9,Springer,2022-08-02,"In order to combat climate change, carbon dioxide (CO 2 ) emissions from industry, transportation, buildings, and other sources need to be captured and long-term stored. Decarbonization of these sources requires special types of materials that have high affinities for CO 2 . Potassium hydroxide is a benchmark aqueous sorbent that reacts with CO 2 to convert it into K 2 CO 3 and subsequently precipitated as CaCO 3 . Another class of carbon capture materials is solid sorbents that are usually functionalized with amines or have natural affinities for CO 2 . The next wave of materials for carbon capture under investigation includes activated carbon, metal–organic frameworks, zeolites, carbon nanotubes, and ionic liquids. In this issue of MRS Bulletin , some of these materials are highlighted, including solvents and sorbents, membranes, ionic liquids, and hydrides. Other materials that can capture CO 2 from low concentrations of gas streams, such as air (direct air capture) are also discussed. Also covered in this issue are machine learning-based computer algorithms developed with the goal to speed up the progress of carbon capture materials development, and to design advanced materials with high CO 2 capacity, improved capture and release kinetics, and improved cyclic durability. Graphical abstract ",http://dx.doi.org/10.1557/s43577-022-00364-9,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11042-022-13510-x,Analysis of the optimal number of clusters and probability in homogeneous unreliable WSNs,Multimedia Tools and Applications,10.1007/s11042-022-13510-x,Springer,2022-08-02,"In this paper, we propose a simple simulation model for analyzing and evaluating the low energy adaptive clustering hierarchy (LEACH) protocol’s performance in a noisy realistic wireless environment. A general parameter called probability of reception ( p r ) describes the noise level in this model. The success or failure of packet reception between sender and receiver can be used to assess the impact of network noise. The LEACH algorithm’s energy model has been modified to include the noise factor ( p r ). Based on the new modified energy model, new analytical formulas for the optimal number of clusters and the optimal probability of a node becoming a cluster head are derived. Furthermore, we investigate what network dimensions are required to achieve the optimal number of clusters in a noisy environment, as this will increase the network’s lifetime. It is demonstrated that the optimal number of clusters, and thus the optimal probability of CHs, are shown to be achieved by two factors: short wireless links formed within the clusters and equal network layout dimensions. Noise is shown to have a significant negative impact on the LEACH protocol’s operation, particularly on network life time, throughput, and the protocol’s stability and instability periods.",http://dx.doi.org/10.1007/s11042-022-13510-x,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s41348-022-00612-9,"Classification of weed using machine learning techniques: a review—challenges, current and future potential techniques",Journal of Plant Diseases and Protection,10.1007/s41348-022-00612-9,Springer,2022-08-01,"Weed detection and classification are considered one of the most vital tools in identifying and recognizing plants in agricultural fields. Recently, machine learning techniques have been rapidly growing in the precision farming area related to plants, as well as weed detection and classification techniques. In digital agricultural analysis, these techniques have played and will continue to play a vital role in mitigating health, agricultural, and environmental impacts, improving sustainability, and reducing herbicides. Deep learning-based models are employed to solve the more sophisticated agricultural issues using individual CNN networks and hybrid models. Such models showed promising results. This paper highlights the major trends from the particular review of detection and classification approaches for weed plants. This review elaborates on the aspects of using traditional methods and deep learning-based methods to solve weed detection problems. It provides an overview of various methods for weed detection in recent years, analyzes the benefits and limitations of existing machine learning techniques, including deep learning techniques, and introduces several related plant leaves, weed datasets, and weeding machinery. Evaluation of the existing techniques has been compared, taking into account the real-world dataset used, images’ capacity, and shortcomings. Furthermore, this study helps to introduce the promising results and identify critically the remaining challenges in achieving robust weed detection, which could support noteworthy agricultural problems and assist researchers in the future. The significance of this study is to provide the potential techniques for solving illumination, overlapping, and occlusion issues of leafy plants, as well as other plant issues.",http://dx.doi.org/10.1007/s41348-022-00612-9,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s40593-022-00298-y,AI + Ethics Curricula for Middle School Youth: Lessons Learned from Three Project-Based Curricula,International Journal of Artificial Intelligence in Education,10.1007/s40593-022-00298-y,Springer,2022-08-01,"Artificial Intelligence (AI) is revolutionizing many industries and becoming increasingly ubiquitous in everyday life. To empower children growing up with AI to navigate society’s evolving sociotechnical context, we developed three middle school AI literacy curricula: Creative AI, Dancing with AI, and How to Train Your Robot. In this paper we discuss how we leveraged three design principles—active learning, embedded ethics, and low barriers to access – to effectively engage students in learning to create and critique AI artifacts. During the summer of 2020, we recruited and trained in-service, middle school teachers from across the United States to co-instruct online workshops with students from their schools. In the workshops, a combination of hands-on unplugged and programming activities facilitated students’ understanding of AI. As students explored technical concepts in tandem with ethical ones, they developed a critical lens to better grasp how AI systems work and how they impact society. We sought to meet the specified needs of students from a range of backgrounds by minimizing the prerequisite knowledge and technology resources students needed to participate. Finally, we conclude with lessons learned and design recommendations for future AI curricula, especially for K-12 in-person and virtual learning.",http://dx.doi.org/10.1007/s40593-022-00298-y,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00530-020-00736-8,"Leveraging big data analytics in healthcare enhancement: trends, challenges and opportunities",Multimedia Systems,10.1007/s00530-020-00736-8,Springer,2022-08-01,"Clinical decisions are more promising and evidence-based, hence, big data analytics to assist clinical decision-making has been expressed for a variety of clinical fields. Due to the sheer size and availability of healthcare data, big data analytics has revolutionized this industry and promises us a world of opportunities. It promises us the power of early detection, prediction, prevention, and helps us to improve the quality of life. Researchers and clinicians are working to inhibit big data from having a positive impact on health in the future. Different tools and techniques are being used to analyze, process, accumulate, assimilate, and manage large amount of healthcare data either in structured or unstructured form. In this review, we address the need of big data analytics in healthcare: why and how can it help to improve life?. We present the emerging landscape of big data and analytical techniques in the five sub-disciplines of healthcare, i.e., medical image analysis and imaging informatics, bioinformatics, clinical informatics, public health informatics and medical signal analytics. We present different architectures, advantages and repositories of each discipline that draws an integrated depiction of how distinct healthcare activities are accomplished in the pipeline to facilitate individual patients from multiple perspectives. Finally, the paper ends with the notable applications and challenges in adoption of big data analytics in healthcare.",http://dx.doi.org/10.1007/s00530-020-00736-8,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-021-09676-6,A Review on Automated Cancer Detection in Medical Images using Machine Learning and Deep Learning based Computational Techniques: Challenges and Opportunities,Archives of Computational Methods in Engineering,10.1007/s11831-021-09676-6,Springer,2022-08-01,"Cancer is one of the most deadly diseases diagnosed among the population across the globe so far. The number of cases is increasing at a high pace each year that subsequently leads to the advancement in different diagnosis tools and technologies to handle this pandemic. Significant increase in the mortality rate worldwide leads tremendous scope to device and implement latest computer aided diagnostic systems for its early detection. The one among such techniques is machine learning coupled with medical imaging modalities. This combination has proven to be efficient in diagnosing various medical conditions in cancer diagnosis. Current study presents a review of different machine learning techniques applied on imaging modalities for cancer diagnosis from 2008 to 2019. This study focuses on diagnosis of five most prevalent and deadly cancers i.e., cervical cancer, oral cancer, breast cancer, brain cancer and skin cancer. Extensive and exhaustive review was carried out after going through different research papers, research articles and book chapters published by reputed international and national publishers such as Springer Link, Science Direct, IEEE Xplore Digital library and PubMed. A number of conference proceedings have also been included subject to the fulfilling of our quality evaluation criteria. This review article provides a comprehensive overview of machine learning approaches using image modalities for cancer detection and diagnosis with main focus on challenges being faced during their research. Majority of the challenges are identified based on the use of potential machine learning based approaches, image modalities, features and evaluation metrics. This review not only identified challenges but also ear mark and present the new research opportunities for researchers working in this field. It has been widely observed that traditional machine learning algorithms Like SVM, GMM performed excellent in classification whereas the deep learning has dominated the field of medical image analysis to a greater extent. It is evident from the literature survey that the researchers have achieved the accuracies of 100% in classification of cancerous and normal tissue images using different machine learning techniques. This article will provide an insight to the researchers working in this domain to identify which machine learning technique work best on what type of data set, selection of features, various challenges and their proposed solutions in solving this complex problem. Limitations and future research opportunities in the field of implementing different machine learning techniques in cancer diagnosis and classification is also presented at the end of this review article.",http://dx.doi.org/10.1007/s11831-021-09676-6,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11831-021-09682-8,Artificial Intelligence Based Techniques for the Detection of Socio-Behavioral Disorders: A Systematic Review,Archives of Computational Methods in Engineering,10.1007/s11831-021-09682-8,Springer,2022-08-01,"In new era of emerging technologies, diagnosing the neurodevelopmental disorders at the primitive stage has led to a rise in the development of automated diagnostic systems. Socio-behavioral disorder (SBD),a subtype of NDDs, being amongst the most complex behavioral impairments is the root cause for disability, specifically in young children. Under the term SBD, falls a group of heterogeneous disorders; Autism Spectrum Disorder (ASD) and Attention Deficit Hyperactivity Disorder (ADHD) whose diagnosis remains a challenging task due to the spectrum of conditions associated to it and also due to their high comorbidity with each other. Traditional based recognition of SBD is based on qualitative parameters which make diagnosis more time consuming. Hence, diagnosis of SBD is a preeminent area that demands deliberations from the researchers, scientists as well as academicians to introduce more automated diagnostic systems based on quantitative parameters that not only provides reliability and accuracy besides affordable for everyone. Motivated by these facts,this article seeks to provide a thorough investigation of efforts on the subject of automated diagnostic systems using artificial intelligence techniques based on quantitative parameters (biomarkers and multimodal data) for early ASD or ADHD detection. An extensive survey of AI based diagnostic systems for ASD, ADHD are also presented. Furthermore, the studies of various automated AI based diagnostic systems for the detection of ASD, ADHD and ASD+ADHD are presented in this research work. Finally, this article highlights the open issues existing in the literature that needs to be explored further for providing more effective SBD analysis and also presented an outline of the proposed work which will be an aid in the diagnostic field of ASD, ADHD and comorbid ASD.",http://dx.doi.org/10.1007/s11831-021-09682-8,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11892-022-01477-w,Machine Learning Models for Inpatient Glucose Prediction,Current Diabetes Reports,10.1007/s11892-022-01477-w,Springer,2022-08-01,"Purpose of Review Glucose management in the hospital is difficult due to non-static factors such as antihyperglycemic and steroid doses, renal function, infection, surgical status, and diet. Given these complex and dynamic factors, machine learning approaches can be leveraged for prediction of glucose trends in the hospital to mitigate and prevent suboptimal hypoglycemic and hyperglycemic outcomes. Our aim was to review the clinical evidence for the role of machine learning–based models in predicting hospitalized patients’ glucose trajectory. Recent Findings The published literature on machine learning algorithms has varied in terms of population studied, outcomes of interest, and validation methods. There have been tools developed that utilize data from both continuous glucose monitors and large electronic health records (EHRs). With increasing sample sizes, inclusion of a greater number of predictor variables, and use of more advanced machine learning algorithms, there has been a trend in recent years towards increasing predictive accuracy for glycemic outcomes in the hospital setting. While current models predicting glucose trajectory offer promising results, they have not been tested prospectively in the clinical setting. Summary Accurate machine learning algorithms have been developed and validated for prediction of hypoglycemia and hyperglycemia in the hospital. Further work is needed in implementation/integration of machine learning models into EHR systems, with prospective studies to evaluate effectiveness and safety of such clinical decision support on glycemic and other clinical outcomes.",http://dx.doi.org/10.1007/s11892-022-01477-w,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11277-022-09658-2,"A Contemporary Survey on IoT Based Smart Cities: Architecture, Applications, and Open Issues",Wireless Personal Communications,10.1007/s11277-022-09658-2,Springer,2022-08-01,"Internet of Things (IoT) is one of the emerging technologies, which is widely used across the globe. As the idea of a smart city was founded, IoT has been acknowledged as the key foundation in smart city paradigms. Technology makes a person smart, and to make the world smart, we have to make the country smart. To make the country smart, we have to make cities smart and to make smart cities, we have to be smart. In short, to create a smart environment, one must be equipped and familiar with the current trends. The integration of various smart devices and systems facilitates IoT for a smart city. The interdependent and interwoven nature of smart cities puts notable legislative, socioeconomic, and technical challenges for integrators, organizations, and designers committed to administrating these novel entities. The goal of this paper is to illustrate a contemporary survey of IoT-based smart cities with their potential, current trends and developments, amenity architecture, application area, real-world involvement, and open challenges. In addition, key elements with potential implementation constraints and integration of various IoT-based application areas that play a key role in building a smarter city have also been discussed. This extensive study contributes a useful panorama on various key points and gives a critical direction for forthcoming investigations. This study will also provide a reference point for practitioners and academics in the near future.",http://dx.doi.org/10.1007/s11277-022-09658-2,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12325-022-02192-4,Improved Prediction of Body Mass Index in Real-World Administrative Healthcare Claims Databases,Advances in Therapy,10.1007/s12325-022-02192-4,Springer,2022-08-01,"Introduction To continue closing the gap between the predictive modeling and its real-world application, we report a new data-to-prediction pipeline that advanced the state-of-the-art predictive performance of body mass index (BMI) classifications by integrating siloed claims databases via a common data model. Methods This study adapted the ensemble-based methodology of the baseline prediction model and focused on removing the silos in the claims databases. We applied the Super Learner machine learning algorithm (SLA) to learn a combined dataset consisting of 50% data from the Optum Date of Death database and 50% data from the IBM MarketScan Commercial Claims and Encounters (CCAE), and omitted the commonly used one-hot-encoding step and used multi-categorical variables directly in the feature engineering process. These developments were then optimized via a standard cross-validation scheme and the performance was evaluated on a holdout test set. Results Sociodemographic and clinical characteristics were used with (denoted as SLA 1 ) and without (denoted as SLA 2 ) baseline BMI values to predict BMI classifications (≥ 30, ≥ 35, and ≥ 40 kg/m 2 ). Although the newly implemented SLA 1 performed similarly to the previous model, with the area under the receiver operating characteristic curve (ROC AUC) being approximately 88% for all BMI classifications, specificity ranging from 90% to 96%, and accuracy ranging from 88% to 93%. The new SLA 2 achieved consistently better performance on all metrics across all BMI classes. In particular, the new SLA 2 achieved 77–79% in ROC AUC, increasing from the previously reported level (73%). Its specificity improved to the range of 76–90% from 71–86%. Its accuracy improved to the range of 77–86% from 73–80%. Its recall (i.e., sensitivity) improved to the range of 64–78% from 60–76%. Conclusions This study demonstrates dramatic improvements in the prediction of BMI across classifications using integrated databases in a common data model for the generation of real-world evidence.",http://dx.doi.org/10.1007/s12325-022-02192-4,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00500-022-07194-6,Estimation of fault probability in medium voltage feeders through calibration techniques in classification models,Soft Computing,10.1007/s00500-022-07194-6,Springer,2022-08-01,"Machine Learning is currently a well-suited approach widely adopted for solving data-driven problems in predictive maintenance. Data-driven approaches can be used as the main building block in risk-based assessment and analysis tools for Transmission and Distribution System Operators in modern Smart Grids. For this purpose, a suitable Decision Support System should be able of providing not only early warnings, such as the detection of faults in real time, but even an accurate probability estimate of outages and failures. In other words, the performance of classification systems, at least in these cases, needs to be assessed even in terms of reliable outputting posterior probabilities, a really important feature that, in general, classifiers very often do not offer. In this paper are compared several state-of-the-art calibration techniques along with a set of simple new proposed techniques, with the aim of calibrating fuzzy scoring values of a custom-made evolutionary-cluster-based hybrid classifier trained on a set of a real-world dataset of faults collected within the power grid that feeds the city of Rome, Italy. Comparison results show that in real-world cases calibration techniques need to be assessed carefully depending on the scores distribution and the proposed techniques are a valid alternative to the ones existing in the technical literature in terms of calibration performance, computational efficiency and flexibility.",http://dx.doi.org/10.1007/s00500-022-07194-6,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s12652-021-03317-3,A proof-of-concept and feasibility analysis of using social sensors in the context of causal machine learning-based emergency management,Journal of Ambient Intelligence and Humanized Computing,10.1007/s12652-021-03317-3,Springer,2022-08-01,"The goals of emergency management are to restore human safety and security, and to help the authorities understand what causes such events. It requires information that is both highly accurate, and can be generated very quickly. This research addresses these concerns with a machine learning model based on cause-and-effect using a Bayesian belief network. This employs human critical thinking and amplified context to encode the model structures, which contribute towards its imitation of human-intelligent understanding, and the model parameters are fitted using social media data. The results show that our model is a natural fit for a real-world environment required emergency management.",http://dx.doi.org/10.1007/s12652-021-03317-3,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00530-021-00818-1,"Fusion of AI techniques to tackle COVID-19 pandemic: models, incidence rates, and future trends",Multimedia Systems,10.1007/s00530-021-00818-1,Springer,2022-08-01,"The COVID-19 pandemic is rapidly spreading across the globe and infected millions of people that take hundreds of thousands of lives. Over the years, the role of Artificial intelligence (AI) has been on the rise as its algorithms are getting more and more accurate and it is thought that its role in strengthening the existing healthcare system will be the most profound. Moreover, the pandemic brought an opportunity to showcase AI and healthcare integration potentials as the current infrastructure worldwide is overwhelmed and crumbling. Due to AI’s flexibility and adaptability, it can be used as a tool to tackle COVID-19. Motivated by these facts, in this paper, we surveyed how the AI techniques can handle the COVID-19 pandemic situation and present the merits and demerits of these techniques. This paper presents a comprehensive end-to-end review of all the AI-techniques that can be used to tackle all areas of the pandemic. Further, we systematically discuss the issues of the COVID-19, and based on the literature review, we suggest their potential countermeasures using AI techniques. In the end, we analyze various open research issues and challenges associated with integrating the AI techniques in the COVID-19.",http://dx.doi.org/10.1007/s00530-021-00818-1,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00366-020-01249-8,Cloud evolutionary computation system for advanced engineering analytics,Engineering with Computers,10.1007/s00366-020-01249-8,Springer,2022-08-01,"The range of applications of artificial intelligence (AI) that is based on nature-inspired metaheuristics is rapidly increasing across various scientific fields as it is used to solve complex engineering problems. This work develops a cloud evolutionary machine learning system, called the nature-inspired metaheuristic optimization and prediction system (NiMOPS) that is composed of metaheuristic AI and web modules. The objective of the proposed system is to provide a user-friendly web analytics for making efficient, effective, and accurate predictions as solutions to engineering problems. For the purposes of web development, this work connects two programming languages, which are MATLAB and Java. A MATLAB Compiler is used to package the system into Java Archive (JAR) files, which provide the core modules for the development of the NiMOPS website using an integrated development environment (IDE). IDE compiles the JAR files, and web utilities (JavaScript, CSS, Servlet, and other utility files) to form the response-request connection between the user and the server. Therefore, the web-based system does not require the installation of an application by the users because they can access the cloud computing system ubiquitously with a browser or mobile device. Furthermore, it has many functions, including export—import file, train model, optimize prediction, save model and visualize results. Several case studies of this system, involving classification and regression problems, were examined. The analytic results of using the system to solve classification problems revealed that the system had a fault diagnosis accuracy of 96.5% and an accidental small fire accuracy of 52.4%. In solving regression problems, the root mean square errors were 28.58–68.82% better than those of previous methods. In particular, the proposed system performed multiple performance measures that were utilized in a regression analysis and were found to be more reliable evaluation metrics than used in elsewhere. The numerical experiments verified that cloud computing provides an innovative way to enable decision-makers to solve engineering problems.",http://dx.doi.org/10.1007/s00366-020-01249-8,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s11633-022-1338-z,A Weighted Average Consensus Approach for Decentralized Federated Learning,Machine Intelligence Research,10.1007/s11633-022-1338-z,Springer,2022-08-01,"Federated learning (FedL) is a machine learning (ML) technique utilized to train deep neural networks (DeepNNs) in a distributed way without the need to share data among the federated training clients. FedL was proposed for edge computing and Internet of things (IoT) tasks in which a centralized server was responsible for coordinating and governing the training process. To remove the design limitation implied by the centralized entity, this work proposes two different solutions to decentralize existing FedL algorithms, enabling the application of FedL on networks with arbitrary communication topologies, and thus extending the domain of application of FedL to more complex scenarios and new tasks. Of the two proposed algorithms, one, called FedLCon, is developed based on results from discrete-time weighted average consensus theory and is able to reconstruct the performances of the standard centralized FedL solutions, as also shown by the reported validation tests.",http://dx.doi.org/10.1007/s11633-022-1338-z,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00170-022-09632-z,Industry application of digital twin: from concept to implementation,The International Journal of Advanced Manufacturing Technology,10.1007/s00170-022-09632-z,Springer,2022-08-01,"With the development of artificial intelligence, big data, Internet of Things, and other technologies, digital twin has gained great attention and become a current research topic. Using digital twin technology, the digital twin model can be constructed in the cyber space that is fully equivalent to the physical entity. It is always consistent with the physical entity in the operation process, which greatly improves the dynamic perception and prediction ability of the real world. After the development in recent years, digital twin has gradually changed from the initial concept discussion to the study of model framework and implementation method. However, because the research objects in different industries have great differences in their own composition, service conditions, and application scenarios, they have personalized characteristics in modeling strategies and usage methods. Therefore, based on different industries, this paper reviews the current articles on digital twins and distinguishes the focus of digital twin modeling research; subsequently, the relevant supporting techniques and methods are summarized according to their different importance for digital twin modeling. Based on the review in this paper, future researchers can conduct targeted research on digital twin technology in term of the characteristics of the objects in their industry.",http://dx.doi.org/10.1007/s00170-022-09632-z,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
Article,doi:10.1007/s00371-021-02166-7,"A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets",The Visual Computer,10.1007/s00371-021-02166-7,Springer,2022-08-01,"The research progress in multimodal learning has grown rapidly over the last decade in several areas, especially in computer vision. The growing potential of multimodal data streams and deep learning algorithms has contributed to the increasing universality of deep multimodal learning. This involves the development of models capable of processing and analyzing the multimodal information uniformly. Unstructured real-world data can inherently take many forms, also known as modalities, often including visual and textual content. Extracting relevant patterns from this kind of data is still a motivating goal for researchers in deep learning. In this paper, we seek to improve the understanding of key concepts and algorithms of deep multimodal learning for the computer vision community by exploring how to generate deep models that consider the integration and combination of heterogeneous visual cues across sensory modalities. In particular, we summarize six perspectives from the current literature on deep multimodal learning, namely: multimodal data representation, multimodal fusion (i.e., both traditional and deep learning-based schemes), multitask learning, multimodal alignment, multimodal transfer learning, and zero-shot learning. We also survey current multimodal applications and present a collection of benchmark datasets for solving problems in various vision domains. Finally, we highlight the limitations and challenges of deep multimodal learning and provide insights and directions for future research.",http://dx.doi.org/10.1007/s00371-021-02166-7,springer,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
