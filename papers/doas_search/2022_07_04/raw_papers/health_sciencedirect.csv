id,type,publication,publisher,publication_date,database,title,url,abstract,query_name,query_value
10.1016/j.eswa.2022.117634,Journal,Expert Systems with Applications,scopus,2022-10-15,sciencedirect,RADIS: A real-time anomaly detection intelligent system for fault diagnosis of marine machinery,https://api.elsevier.com/content/abstract/scopus_id/85131074045,"By enhancing data accessibility, the implementation of data-driven models has been made possible to empower strategies in relation to O&M activities. Such models have been extensively applied to perform anomaly detection tasks, with the express purpose of detecting data patterns that deviate significantly from normal operational behaviour. Due to its preeminent importance in the maritime industry to adequately identify the behaviour of marine systems, the Real-time Anomaly Detection Intelligent System (RADIS) framework, constituted by a Long Short-Term Memory-based Variational Autoencoder in tandem with multi-level Otsu’s thresholding, is proposed. RADIS aims to address the current gaps identified within the maritime industry in relation to data-driven model applications for enabling smart maintenance. To assess the performance of such a framework, a case study on a total of 14 parameters obtained from sensors installed on a diesel generator of a tanker ship is introduced to highlight the implementation of RADIS. Results demonstrated the capability of RADIS to be part of a diagnostic analytics tool that will promote the implementation of smart maintenance within the maritime industry, as RADIS detected an average of 92.5% of anomalous instances in the presented case study.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2022.114475,Journal,Biosensors and Bioelectronics,scopus,2022-10-01,sciencedirect,Biosensor prototype for rapid detection and quantification of DNase activity,https://api.elsevier.com/content/abstract/scopus_id/85132387568,"DNases are enzymes that cleave phosphodiesteric bonds of deoxyribonucleic acid molecules and are found everywhere in nature, especially in bodily fluids, i.e., saliva, blood, or sweat. Rapid and sensitive detection of DNase activity is highly important for quality control in the pharmaceutical and biotechnology industries. For clinical diagnostics, recent reports indicate that increased DNase activity could be related to various diseases, such as cancers. In this paper, we report a new bioelectronic device for the determination of nuclease activity in various fluids. The system consists of a sensor electrode, a custom design DNA target to maximize the DNase cleavage rate, a signal analysis algorithm, and supporting electronics. The developed sensor enables the determination of DNase activity in the range of 3.4 × 10−4 – 3.0 × 10−2 U mL−1 with a limit of detection of up to 3.4 × 10−4 U mL−1. The sensor was tested by measuring nuclease activity in real human saliva samples and found to demonstrate high accuracy and reproducibility compared to the industry standard DNaseAlert™️. Finally, the entire detection system was implemented as a prototype device system utilizing single-use electrodes, custom-made cells, and electronics. The developed technology can improve nuclease quality control processes in the pharmaceutical/biotechnology industry and provide new insights into the importance of nucleases for medical applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2022.05.006,Journal,Future Generation Computer Systems,scopus,2022-10-01,sciencedirect,A multi-sensor architecture combining human pose estimation and real-time location systems for workflow monitoring on hybrid operating suites,https://api.elsevier.com/content/abstract/scopus_id/85130825694,"Despite the advancements to improve patient safety, a significant number of errors still occur in Operating Suites (OS). To improve medical decision-making and the resulting quality of care, it is essential to monitor and understand medical activities’ workflow and interactions. Although some strategies employ different sensor devices, their focus is not on generating complete workflow information. They only combine different data sources to generate their final output, lacking at least one piece of information from a workflow. To tackle this challenge, this paper presents 
                        
                     
 , a distributed architecture model for sensor data acquisition and processing. 
                        
                     
 ’s main contribution lies in its multi-sensor data fusion algorithms to extract a computational representation of activities in surgical procedures. In addition, 
                        
                     
 is flexible to accommodate different deployment configurations,combining depth cameras, Ultra-Wideband positioning systems,and deep learning-based human pose estimation (HPE) mechanisms. The workflow monitoring mechanism was deployed in an actual hybrid OS for an extensive evaluation of the proposal. Our experiments demonstrate that the architecture can capture the information required to monitor the surgical workflow. In particular, the proposed HPE methodology accurately detects the poses of medical staff members, with a maximum error of 5cm.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.117356,Journal,Expert Systems with Applications,scopus,2022-10-01,sciencedirect,On the limits of Conditional Generative Adversarial Neural Networks to reconstruct the identification of inhabitants from IoT low-resolution thermal sensors,https://api.elsevier.com/content/abstract/scopus_id/85130365841,"One of the main objectives of smart homes is to facilitate daily life by increasing user comfort, with the potential to play a key role in revolutionizing healthcare for the elderly, the disabled and people with functional limitations. To achieve this end, smart homes will have to be able to distinguish the identity of users, their location and the activities they are performing, while also being implemented in a non-invasive way that protects the privacy of these users. Computer vision is one of the main technologies included in smart homes. However, there are drawbacks to traditional cameras, given their dependence on light and privacy-related concerns. Thermal cameras provide a solution, as they operate regardless of light conditions (e.g. at night) while respecting users’ privacy. In this work, image reconstruction and identification of inhabitants from facial images collected by low-resolution thermal sensors has been carried out by using Conditional Generative Adversarial Neural Networks (CGANs). The system has been implemented through an IoT device with raspberry Pi and dual-vision thermal and visible-spectrum sensors installed in a real smart home to automatically collect paired visible-spectrum and thermal images. Thus, different configurations of CGANs have been implemented and analyzed to achieve the following outcomes: (1) inhabitant identification (normal and masked face) with enhanced user privacy and (2) transfer from thermal to color images in the visible spectrum. Results show that the proposed CGAN achieves a recognition rate of 95% and 94% for uncovered and masked faces. This enables user identification without registering accurate facial expressions in the color image reconstruction, protecting user privacy. Furthermore, the developed system outperformed similar approaches using low-resolution datasets and has demonstrated that the accuracy of image reconstruction depends on the resolution of the input visible-spectrum images. In addition, a contribution to high-performance computing has been made by designing a CGAN that runs efficiently on multiple GPUs, achieving increased performance and response speed of the network, as well as applicability to larger problems.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.117362,Journal,Expert Systems with Applications,scopus,2022-09-15,sciencedirect,Mobile and wearable sensors for data-driven health monitoring system: State-of-the-art and future prospect,https://api.elsevier.com/content/abstract/scopus_id/85129976791,"Mobile and wearable devices embedded with multiple sensors for health monitoring and disease diagnosis are growing fields with the potential to provide efficient means for remote health management. A sensor-based health monitoring system offers an essential mechanism for real-time diagnosis and management to detect/predict, recommend treatment and prevent the onset of diseases. This paper aims to synthesize the research efforts on mobile and wearable sensors for health monitoring. It will investigate sensors, components of health monitoring systems, major application areas, challenges, and solutions faced during the implementation of health monitoring systems by researchers and practitioners. It was observed that sensors embedded in mobile and wearable devices for health monitoring are broadly categorized into homogeneous, dual, and heterogeneous sensors. In health monitoring, heterogeneous sensor-based is widely implemented and the most effective due to its ability to combine multiple sensors from various domains. The fusion of multiple sensors provides reliability, credibility, and better accuracy for monitoring multiple health parameters. We observed that researchers follow established procedures such as data collection, data transmission, preprocessing, feature extraction and development, data analysis, and evaluation of different algorithms for implementation of the health monitoring system. Supervised machine learning algorithms such as support vector machine, decision tree, k-nearest neighbors, and deep learning methods were the most implemented methods, while accuracy was the favored evaluation measure for health monitoring. Generally, we found that a health monitoring system is implemented to resolve health issues in the areas of human activity and posture monitoring, sleep disorder, sleep stage detection, fall monitoring in the elderly, depression, and mood swing detection. Other important areas include Parkinson’s disease management, cardiac diseases monitoring, disease diagnosis, and well-being, and Corona virus detection and contact tracing to minimize infection rate. Furthermore, the review succinctly highlights various challenges impeding the development of sensor-based health monitoring systems with significant solutions that were recommended in the literature to ameliorate these challenges discussed. From the review, it can be acknowledged that various research efforts have been conducted to develop effective health monitoring systems, and many new systems have been implemented. However, there is still much work to be done which we have also discussed under future prospects.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.techfore.2022.121778,Journal,Technological Forecasting and Social Change,scopus,2022-09-01,sciencedirect,A metaverse assessment model for sustainable transportation using ordinal priority approach and Aczel-Alsina norms,https://api.elsevier.com/content/abstract/scopus_id/85132442768,"Metaverse comes from the meta-universe, and it is the integration of physical and digital space into a virtual universe. Metaverse technologies will change the transportation system as we know it. Preparations for the transition of the transportation systems into the world of metaverse are underway. This study considers four alternative metaverses: auto-driving algorithm testing for training autonomous driving artificial intelligence, public transportation operation and safety, traffic operation, and sharing economy applications to obtain sustainable transportation. These alternatives are evaluated on thirteen sub-criteria, grouped under four main aspects: efficiency, operation, social and health, and legislation and regulation. A novel Rough Aczel–Alsa (RAA) function and the Ordinal Priority Approach (OPA) method are used in the assessment model. We also present a case study to demonstrate the applicability and exhibit the efficacy of the assessment framework in prioritizing the metaverse implementation alternatives.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neuroimage.2022.119348,Journal,NeuroImage,scopus,2022-09-01,sciencedirect,A benchmark for prediction of psychiatric multimorbidity from resting EEG data in a large pediatric sample,https://api.elsevier.com/content/abstract/scopus_id/85131691120,"Psychiatric disorders are among the most common and debilitating illnesses across the lifespan and begin usually during childhood and adolescence, which emphasizes the importance of studying the developing brain. Most of the previous pediatric neuroimaging studies employed traditional univariate statistics on relatively small samples. Multivariate machine learning approaches have a great potential to overcome the limitations of these approaches. On the other hand, the vast majority of existing multivariate machine learning studies have focused on differentiating between children with an isolated psychiatric disorder and typically developing children. However, this line of research does not reflect the real-life situation as the majority of children with a clinical diagnosis have multiple psychiatric disorders (multimorbidity), and consequently, a clinician has the task to choose between different diagnoses and/or the combination of multiple diagnoses. Thus, the goal of the present benchmark is to predict psychiatric multimorbidity in children and adolescents. For this purpose, we implemented two kinds of machine learning benchmark challenges: The first challenge targets the prediction of the seven most prevalent DSM-V psychiatric diagnoses for the available data set, of which each individual can exhibit multiple ones concurrently (i.e. multi-task multi-label classification). Based on behavioral and cognitive measures, a second challenge focuses on predicting psychiatric symptom severity on a dimensional level (i.e. multiple regression task). For the present benchmark challenges, we will leverage existing and future data from the biobank of the Healthy Brain Network (HBN) initiative, which offers a unique large-sample dataset (N = 2042) that provides a wide array of different psychiatric developmental disorders and true hidden data sets. Due to limited real-world practicability and economic viability of MRI measurements, the present challenge will permit only resting state EEG data and demographic information to derive predictive models. We believe that a community driven effort to derive predictive markers from these data using advanced machine learning algorithms can help to improve the diagnosis of psychiatric developmental disorders.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpowsour.2022.231582,Journal,Journal of Power Sources,scopus,2022-09-01,sciencedirect,Failure mode diagnosis in proton exchange membrane fuel cells using local electrochemical noise,https://api.elsevier.com/content/abstract/scopus_id/85131646698,"Early diagnosis of fuel cell failure modes is a very active research topic, as it improves robustness and durability of fuel cells used in commercial applications. The diagnosis method should be suited for being applied in real time, without interfering with the fuel cell operation, and it should be implemented using inexpensive hardware and light equipment. A novel method of failure diagnosis in PEM fuel cells, based on the analysis of local electrochemical noise, is proposed. Seven electrochemical noise signals are acquired in different parts of the cell, significantly increasing the information for an effective diagnosis, since previous studies have only analyzed a single signal from the electrochemical noise in the cell.
                  Each electrochemical noise signal is frequency decomposed using wavelet transform to create a characteristic pattern. These patterns are used in a deep learning neural network to perform the cell state classification. The proposed method has been successfully applied to the classification of 26 different states achieved in experiments where the following factors have been varied: (1) average current density; (2) airflow; (3) drying; and (4) air pressure. The mean successful identification rate of the 26 states is above 85%. The proposed diagnosis method is well-suited for real-time diagnosis, and it can be implemented using lightweight and inexpensive hardware.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.117104,Journal,Expert Systems with Applications,scopus,2022-09-01,sciencedirect,MFCC-based descriptor for bee queen presence detection,https://api.elsevier.com/content/abstract/scopus_id/85129475070,"Monitoring and detecting hive health are essential for the development of ecosystem conservation strategies and sustainable beekeeping. The absence of the queen bee is a warning signal and indicates an anomalous situation. The literature contains promising machine learning and deep learning techniques for detecting the presence of the queen bee through the spectral temporal analysis of hive sounds. Despite works that consider handcrafted and deep features to describe the problem, there is a lack of feature selection to evaluate which descriptors could better discriminate the presence/absence of queen bee. Additionally, deep learning techniques lead to high-dimension descriptors and a high computational cost. In this context, we explore feature extraction and selection techniques to obtain efficient and compact descriptors that can perform classification in a real-time monitoring scenario. The results reveal that combining cepstral, time, and frequency features achieve 0.99 for accuracy, kappa, area under curve, specificity, and sensibility metrics, outperforming most state-of-the-art models for queen bee presence classification, including convolution neural network models. The feature selection step notably reduces the descriptor size and maintains classification performance. The 15 and 31 mel-frequency cepstrum coefficients descriptors have a low dimension and are based on only one feature, which reduces the number of calculation and library dependencies. Given this, we believe that our findings can support deployment in low-computational devices for non-intrusive and real-time hive health diagnoses.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.117026,Journal,Expert Systems with Applications,scopus,2022-09-01,sciencedirect,Improving chronic disease management for children with knowledge graphs and artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85128476469,"Chronic diseases for children pose serious challenges from a health management perspective. When not implemented in a well-designed manner, an inefficient management platform can have a significant negative impact on patients and the utilization of health care resources. Innovations of recent years in information technology, artificial intelligence and machine learning provide possibilities to design and implement knowledge-based systems and platforms that follow-up, monitor and advise child patients with a chronic disease in an automated manner. In this article we propose the Artificial Intelligence Chronic Management System that combines artificial intelligence, knowledge graph, big data and internet of things in a platform to offer an optimized solution from the perspective of treatment and utilization of resources. The system includes patient and hospital clients, data storage and analytic tools for decision support relying on AI-based services. We illustrate the functionality of the system through different situations frequently occurring in pediatric wards. To assess the feasibility of the AI component, we utilize real life health care data from a hospital in China to develop a classification model for patients with asthma. To provide a more qualitative assessment at the same time, we discuss how the Artificial Intelligence Chronic Management System conforms to the requirements set forth by the standard Chronic Care Model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.suscom.2022.100704,Journal,Sustainable Computing: Informatics and Systems,scopus,2022-09-01,sciencedirect,Traffic Load Estimation from Structural Health Monitoring sensors using supervised learning,https://api.elsevier.com/content/abstract/scopus_id/85126297707,"Traffic Load Estimation (TLE) is increasingly adopted in public road infrastructures to regulate the access and limit heavy vehicles circulation. Standard approaches to TLE are based either on installing dedicated sensors such as intelligent cameras or infrared sensors or using existing smartphone sensors. However, both approaches have severe limitations, as often dedicated sensors are power-hungry and expensive to install and maintain, whereas smartphone-based approaches critically rely massively on users collaboration. More recently, researchers have started investigating TLE approaches using networks of accelerometers that are often already installed on critical road elements such as viaducts and bridges for Structural Health Monitoring (SHM) purposes. Specifically, in previous solutions, the detection and counting of vehicles was based on unsupervised anomaly detection and did not use any labeled data. While this simplifies the system’s setup, it also makes full validation impossible. In this work, we investigate the TLE problem using a supervised learning approach for SHM-sensor-based TLE for the first time. In particular, we use a relatively short recording session from a smart camera to label acceleration data with the corresponding number (and type) of passing vehicles. Labeled data are then fed to a Machine Learning (ML) model trained as a regressor to estimate the vehicle count corresponding to each input sample. We perform an extensive comparison among different types of ML models, both classic and deep. Our experiments find that the highest accuracy is achieved by a Support Vector Regressor (SVR) combined with simple feature extraction, which can reach a Mean Absolute Error (MAE) of 0.47 light vehicles and 0.21 heavy vehicles. This corresponds to a 
                        
                           9
                           .
                           8
                           ×
                        
                      and 
                        
                           8
                           .
                           1
                           ×
                        
                      error reduction compared to previous unsupervised solutions, respectively. Lastly, we show that our approach lends itself to an energy-efficient implementation on a real SHM gateway.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2022.105801,Journal,Computers in Biology and Medicine,scopus,2022-08-01,sciencedirect,A new approach to automatic measure fetal head circumference in ultrasound images using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85133265110,"Fetal head circumference (HC) is an important biological index in prenatal ultrasound screening. In the clinic, fetal HC is usually measured manually by sonographers in two dimensional (2D) ultrasound images. The manual method is significantly affected by the inter/intra-observer difference and the process of manual measurement is inconvenient and time-consuming for sonographers. Although several artificial intelligence (AI) approaches had been applied to fetal HC measurement, they had weak generalization ability, especially for the incomplete or blurred skull edge. In this study, a fast and accurate method for fetal HC auto-measurement was proposed. Different from the common region segmentation method, an end-to-end convolutional neural network (CNN) for fetal skull boundary segmentation in 2D ultrasound images is proposed, which is an efficient method to directly segment the boundary of fetal skull by using the proposed double-branch structure. The segmentation results can be directly used to calculate fetal HC without complex post-processing. The proposed approach achieved excellent results: Mean Dice Sore (MDS)
                        ±
                     std: 97.98 ± 1.30, Mean Hausdorff Distance (MHD)
                        ±
                     std: 1.20 ± 0.68 mm, Mean Absolute Difference (MAD)
                        ±
                     std: 1.75 ± 1.60 mm, Mean Difference (MD)
                        ±
                     std: 0.08 ± 2.37 mm. Additionally, we drew a Bland–Altman plot to demonstrate that HC measured by the proposed approach has high agreement with the real value. Comprehensive results show that the proposed approach is comparable to the state-of-the-art methods for fetal HC measurement. Meanwhile, our approach belongs to a lightweight network with less parameters, which is convenient for deployment. We hope it could provide help for precision medicine in prenatal ultrasound screening.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compchemeng.2022.107884,Journal,Computers and Chemical Engineering,scopus,2022-08-01,sciencedirect,One step forward for smart chemical process fault detection and diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85132568028,"Process fault detection and diagnosis (FDD) is an essential tool to ensure safe production in chemical industries. After decades of development, despite the promising performance of some FDD methods on specific tasks, most FDD methods are not smart enough to tackle the complex challenges in real industrial processes, rendering an absence of commercialized FDD tools. Therefore, the implementation of smart FDD becomes an ambitious goal for process safety. In this paper, we provide an overview of the concept and major challenges of smart FDD. Recent FDD methods are comprehensively evaluated with respect to the characteristics of smart FDD. We also present the researches done by our group, which we believe would be a step forward for smart FDD. A range of future opportunities and new perspectives are further discussed. This review aims to illuminate potential directions for process safety and to contribute to the realization of commercial FDD tools.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejmp.2022.06.003,Journal,Physica Medica,scopus,2022-08-01,sciencedirect,Current challenges of implementing artificial intelligence in medical imaging,https://api.elsevier.com/content/abstract/scopus_id/85131966574,"The idea of using artificial intelligence (AI) in medical practice has gained vast interest due to its potential to revolutionise healthcare systems. However, only some AI algorithms are utilised due to systems’ uncertainties, besides the never-ending list of ethical and legal concerns. This paper intends to provide an overview of current AI challenges in medical imaging with an ultimate aim to foster better and effective communication among various stakeholders to encourage AI technology development. We identify four main challenges in implementing AI in medical imaging, supported with consequences and past events when these problems fail to mitigate. Among them is the creation of a robust AI algorithm that is fair, trustable and transparent. Another issue is on data governance, in which best practices in data sharing must be established to promote trust and protect the patients’ privacy. Next, stakeholders, such as the government, technology companies and hospital management, should come to a consensus in creating trustworthy AI policies and regulatory frameworks, which is the fourth challenge, to support, encourage and spur innovation in digital AI healthcare technology. Lastly, we discussed the efforts of various organizations such as the World Health Organisation (WHO), American College of Radiology (ACR), European Society of Radiology (ESR) and Radiological Society of North America (RSNA), who are already actively pursuing ethical developments in AI. The efforts by various stakeholders will eventually overcome hurdles and the deployment of AI-driven healthcare applications in clinical practice will become a reality and hence lead to better healthcare services and outcomes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2022.105559,Journal,Computers in Biology and Medicine,scopus,2022-08-01,sciencedirect,Prediction of serious outcomes based on continuous vital sign monitoring of high-risk patients,https://api.elsevier.com/content/abstract/scopus_id/85130843468,"Continuous monitoring of high-risk patients and early prediction of severe outcomes is crucial to prevent avoidable deaths. Current clinical monitoring is primarily based on intermittent observation of vital signs and the early warning scores (EWS). The drawback is lack of time series dynamics and correlations among vital signs. This study presents an approach to real-time outcome prediction based on machine learning from continuous recording of vital signs. Systolic blood pressure, diastolic blood pressure, heart rate, pulse rate, respiration rate and peripheral blood oxygen saturation were continuously acquired by wearable devices from 292 post-operative high-risk patients. The outcomes from serious complications were evaluated based on review of patients’ medical record. The descriptive statistics of vital signs and patient demographic information were used as features. Four machine learning models K-Nearest-Neighbors (KNN), Decision Trees (DT), Random Forest (RF), and Boosted Ensemble (BE) were trained and tested. In static evaluation, all four models had comparable prediction performance to that of the state of the art. In dynamic evaluation, the models trained from the static evaluation were tested with continuous data. RF and BE obtained the lower false positive rate (FPR) of 0.073 and 0.055 on no-outcome patients respectively. The four models KNN, DT, RF and BE had area under receiver operating characteristic curve (AUROC) of 0.62, 0.64, 0.65 and 0.64 respectively on outcome patients. RF was found to be optimal model with lower FPR on no-outcome patients and a higher AUROC on outcome patients. These findings are encouraging and indicate that additional investigations must focus on validating performance in a clinical setting before deployment of the real-time outcome prediction.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemosphere.2022.134585,Journal,Chemosphere,scopus,2022-08-01,sciencedirect,Simultaneous determination of 16 urinary metabolites of organophosphate flame retardants and organophosphate pesticides by solid phase extraction and ultra performance liquid chromatography coupled to tandem mass spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85128525379,"Organophosphate flame retardants (OPFRs) and organophosphate pesticides (OPPs), pertaining to organophosphate esters, are ubiquitous in environment and have been verified to pose noticeable risks to human health. To evaluate human exposures to OPFRs and OPPs, a fast and sensitive approach based on a solid phase extraction (SPE) followed by the ultra-high-performance liquid chromatography coupled to tandem mass spectrometry (UPLC-MS/MS) detection has been developed for the simultaneous analysis of multiple organophosphorus metabolites in urine. The method allows the identification and quantification of ten metabolites of the most common OPFRs and all six dialkylphosphates (DAPs) of OPPs concerning the population exposure characteristics. The method provided good linearities (R2 = 0.998–0.999), satisfactory method detection limits (MDLs) (0.030–1.129 ng/mL) and only needed a small volume (200 μL) of urine. Recovery rates ranged 73.4–127.1% at three spiking levels (2, 10 and 25 ng/mL urine), with both intra- and inter-day precision less than 14%. The good correlations for DAPs in a cross-validation test with a previous gas chromatography-mass spectrometry (GC-MS) method and a good inter-laboratory agreement for several OPFR metabolites in a standard reference material (SRM 3673) re-enforced the precision and validity of our method. Finally, the established method was successfully applied to analyze 16 organophosphorus metabolites in 35 Chinese children's urine samples. Overall, by validating the method's sensitivity, accuracy, precision, reproducibility, etc., data reliability and robustness were ensured; and the satisfactory pilot application on real urine samples demonstrated feasibility and acceptability of this method for being implemented in large population-based studies.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2022.105766,Journal,Safety Science,scopus,2022-08-01,sciencedirect,Industrial internet of things and unsupervised deep learning enabled real-time occupational safety monitoring in cold storage warehouse,https://api.elsevier.com/content/abstract/scopus_id/85127200076,"Occupational safety and health (OSH) has always been a big concern in the labor-intensive warehouse industry, especially under peculiar circumstances like a low temperature. Accordingly, this paper aims to propose a framework of a smart system using the Industrial Internet of Things (IIoT) and digital twin (DT) technologies to realize real-time occupational safety monitoring in the warehouse and ensure synchronized cyber-physical spaces for information traceability and visibility. The unsupervised deep neural structure of stacked auto-encoder (SAE) is designed to identify abnormal stationary from human motion status, which is perceived as a sign of potential accident. The model is developed to automatically update online by cooperating with calibration samples so as to keep in accordance with the evolution of surroundings. The Bluetooth low energy (BLE) and a log-distance path loss model are used to fulfill indoor localization in order for managers to promptly respond to an incident on site. Besides, some intelligent services are enabled to promote the efficiency of safety management. A real-life case study is carried out in an air cargo cold storage warehouse to illustrate the viability and rationality of the proposed system and methods. The elaboration of the implementation is envisioned to facilitate replication and reproduction effectively. The impact of learning features concerned with distance and vibration on the performance of anomaly detection has also been analyzed by experiments. The insights and lessons gained in this study hold the promise of providing a reference or sparking new ideas for researchers and practitioners to meet similar needs in practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymeth.2022.03.005,Journal,Methods,scopus,2022-08-01,sciencedirect,A federated learning method for real-time emotion state classification from multi-modal streaming,https://api.elsevier.com/content/abstract/scopus_id/85126905773,"Emotional and physical health are strongly connected and should be taken care of simultaneously to ensure completely healthy persons. A person’s emotional health can be determined by detecting emotional states from various physiological measurements (EDA, RB, EEG, etc.). Affective Computing has become the field of interest, which uses software and hardware to detect emotional states. In the IoT era, wearable sensor-based real-time multi-modal emotion state classification has become one of the hottest topics. In such setting, a data stream is generated from wearable-sensor devices, data accessibility is restricted to those devices only and usually a high data generation rate should be processed to achieve real-time emotion state responses. Additionally, protecting the users’ data privacy makes the processing of such data even more challenging. Traditional classifiers have limitations to achieve high accuracy of emotional state detection under demanding requirements of decentralized data and protecting users’ privacy of sensitive information as such classifiers need to see all data. Here comes the federated learning, whose main idea is to create a global classifier without accessing the users’ local data. Therefore, we have developed a federated learning framework for real-time emotion state classification using multi-modal physiological data streams from wearable sensors, called Fed-ReMECS. The main findings of our Fed-ReMECS framework are the development of an efficient and scalable real-time emotion classification system from distributed multimodal physiological data streams, where the global classifier is built without accessing (privacy protection) the users’ data in an IoT environment. The experimental study is conducted using the popularly used multi-modal benchmark DEAP dataset for emotion classification. The results show the effectiveness of our developed approach in terms of accuracy, efficiency, scalability and users’ data privacy protection.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.remn.2021.12.001,Journal,Revista Espanola de Medicina Nuclear e Imagen Molecular,scopus,2022-07-01,sciencedirect,"Survey of the Radioguided Surgery Working Group (GTCRG-RGSWG) of the Spanish Society of Nuclear Medicine and Molecular Imaging (SEMNIM): Radioguided localization of non-palpable breast lesions with or without indication for selective sentinel node biopsy: ROLL, SNOLL and <sup>125</sup>I seeds",https://api.elsevier.com/content/abstract/scopus_id/85132240142,"Objetivo
                  Conocer el estado actual de la técnica de localización radioguiada de lesiones no palpables de mama con o sin indicación de biopsia selectiva de ganglio centinela —ROLL, SNOLL y semillas de 125I— mediante la realización de una encuesta nacional elaborada por el Grupo de Trabajo de Cirugía Radioguiada (GTCRG) de la Sociedad Española de Medicina Nuclear e Imagen Molecular (SEMNIM).
               
                  Material y métodos
                  En octubre del 2020 se envió la encuesta, en formato digital, a los distintos servicios de Medicina Nuclear de nuestra geografía. Se dio un tiempo de respuesta de 2meses con prórroga de 15 días. Se ha obtenido el número de procedimientos ROLL/SNOLL de cada centro y la metodología utilizada, recogiendo importantes detalles técnicos. Además, se ha incluido un apartado específico sobre las semillas de 125I. Los resultados se volcaron de forma automática en una hoja de cálculo Excel 2007 para su posterior análisis con el mismo programa.
               
                  Resultados
                  La encuesta fue contestada por 55 centros; 21 utilizan arpón mientras que los 34 restantes emplean distintas técnicas de cirugía radioguiada (CRG) para la localización de lesiones no palpables de mama, desglosando los resultados en 13apartados. La dosis de trazador habitualmente utilizada es de 111 MBq para la técnica ROLL y de 222 MBq para la técnica SNOLL, con un volumen de 0,2ml. El protocolo más habitual es el de 2días. El 26% de los centros que realiza CRG utiliza semillas de 125I tanto para la detección de lesiones mamarias como de ganglios sospechosos/patológicos, siendo el tiempo entre la implantación y la extirpación es de unos 3 días, con posterior control radiológico en la mayoría de los casos.
               
                  Conclusión
                  La encuesta pone de manifiesto la relevancia de la cirugía radioguiada en el manejo de los pacientes con cáncer de mama en las diferentes etapas de la enfermedad, con disparidad en la implementación de las nuevas técnicas y herramientas, que responde a las múltiples realidades asistenciales de los servicios de Medicina Nuclear.
               
                  Objective
                  To know the current status of the technique of radioguided localisation of non-palpable breast lesions with or without indication for selective sentinel node biopsy -ROLL, SNOLL and 125I seeds- by conducting a national survey developed by the Working Group on Radioguided Surgery (GTCRG) of the Spanish Society of Nuclear Medicine and Molecular Imaging (SEMNIM).
               
                  Material and methods
                  In October 2020, the form was sent in digital format to the different nuclear medicine services in Spain. A response time of 2months with an overtime of 15 days was given. The number of ROLL/SNOLL procedures in each centre and the methodology used were obtained, including important technical details. In addition, a specific section on 125I seeds was included. The results were automatically downloaded into an Excel 2007 spreadsheet for subsequent analysis with the same program.
               
                  Results
                  The survey was answered by 55 centres; 21 use wire-guided localisation while the remaining 34 use different radioguided surgery techniques (RGS) for the localisation of non-palpable breast lesions, with the results itemized into thirteen sections. The commonly used tracer dose is 111 MBq for the ROLL technique and 222 MBq for the SNOLL technique, with a volume of 0.2ml. The most common protocol is the two-day protocol. 26% of centres performing CRG use 125I seeds for both breast lesion and suspicious/pathological node detection, with the time between implantation and removal being about 3 days, with subsequent radiological control in most cases.
               
                  Conclusion
                  The survey shows the relevance of radioguided surgery in the management of breast cancer patients at different stages of the disease, with disparity in the implementation of new techniques and tools, which responds to the multiple healthcare realities of Nuclear Medicine services.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2022.102090,Journal,Computerized Medical Imaging and Graphics,scopus,2022-07-01,sciencedirect,DXM‐TransFuse U-net: Dual cross-modal transformer fusion U-net for automated nerve identification,https://api.elsevier.com/content/abstract/scopus_id/85131838717,"Accurate nerve identification is critical during surgical procedures to prevent damage to nerve tissues. Nerve injury can cause long-term adverse effects for patients, as well as financial overburden. Birefringence imaging is a noninvasive technique derived from polarized images that have successfully identified nerves that can assist during intraoperative surgery. Furthermore, birefringence images can be processed under 20 ms with a GPGPU implementation, making it a viable image modality option for real-time processing. In this study, we first comprehensively investigate the usage of birefringence images combined with deep learning, which can automatically detect nerves with gains upwards of 14% over its color image-based (RGB) counterparts on the F2 score. Additionally, we develop a deep learning network framework using the U-Net architecture with a Transformer based fusion module at the bottleneck that leverages both birefringence and RGB modalities. The dual-modality framework achieves 76.12 on the F2 score, a gain of 19.6 % over single-modality networks using only RGB images. By leveraging and extracting the feature maps of each modality independently and using each modality’s information for cross-modal interactions, we aim to provide a solution that would further increase the effectiveness of imaging systems for enabling noninvasive intraoperative nerve identification.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2022.102324,Journal,Artificial Intelligence in Medicine,scopus,2022-07-01,sciencedirect,Distributed application of guideline-based decision support through mobile devices: Implementation and evaluation,https://api.elsevier.com/content/abstract/scopus_id/85130571980,"Background
                  Traditionally guideline (GL)-based Decision Support Systems (DSSs) use a centralized infrastructure to generate recommendations to care providers, rather than to patients at home. However, managing patients at home is often preferable, reducing costs and empowering patients. Thus, we wanted to explore an option in which patients, in particular chronic patients, might be assisted by a local DSS, which interacts as needed with the central DSS engine, to manage their disease outside the standard clinical settings.
               
                  Objectives
                  To design, implement, and demonstrate the technical and clinical feasibility of a new architecture for a distributed DSS that provides patients with evidence-based guidance, offered through applications running on the patients' mobile devices, monitoring and reacting to changes in the patient's personal environment, and providing the patients with appropriate GL-based alerts and personalized recommendations; and increase the overall robustness of the distributed application of the GL.
               
                  Methods
                  We have designed and implemented a novel projection–callback (PCB) model, in which small portions of the evidence-based guideline's procedural knowledge are projected from a projection engine within the central DSS server, to a local DSS that resides on each patient's mobile device. The local DSS applies the knowledge using the mobile device's local resources. The GL projections generated by the projection engine are adapted to the patient's previously defined preferences and, implicitly, to the patient's current context, in a manner that is embodied in the projected therapy plans. When appropriate, as defined by a temporal pattern within the projected plan, the local DSS calls back the central DSS, requesting further assistance, possibly another projection. To support the new model, the initial specification of the GL includes two levels: one for the central DSS, and one for the local DSS. We have implemented a distributed GL-based DSS using the projection–callback model within the MobiGuide EU project, which automatically manages chronic patients at home using sensors on the patients and their mobile phone.
                  We assessed the new GL specification process, by specifying two very different, complex GLs: for Gestational Diabetes Mellitus, and for Atrial Fibrillation. Then, we evaluated the new computational architecture by applying the two GLs to the automated clinical management, at real time, of patients in two different countries: Spain and Italy, respectively.
               
                  Results
                  The specification using the new projection-callback model was found to be quite feasible. We found significant differences between the distributed versions of the two GLs, suggesting further research directions and possibly additional ways to analyze and characterize GLs. Applying the two GLs to the two patient populations proved highly feasible as well. The mean time between the central and local interactions was quite different for the two GLs: 3.95 ± 1.95 days in the case of the gestational diabetes domain, and 23.80 ± 12.47 days, in the case of the atrial fibrillation domain, probably corresponding to the difference in the distributed specifications of the two GLs. Most of the interaction types were due to projections to the local DSS (83%); others were data notifications, mostly to change context (17%). Some of the data notifications were triggered due to technical errors. The robustness of the distributed architecture was demonstrated through the successful recovery from multiple crashes of the local DSS.
               
                  Conclusions
                  The new projection-callback model has been demonstrated to be feasible, from specification to distributed application. Different GLs might significantly differ, however, in their distributed specification and application characteristics. Distributed medical DSSs can facilitate the remote management of chronic patients by enabling the central DSSs to delegate, in a dynamic fashion, determined by the patient's context, much of the monitoring and treatment management decisions to the mobile device. Patients can be kept in their home environment, while still maintaining, through the projection-callback mechanism, several of the advantages of a central DSS, such as access to the patient's longitudinal record, and to an up-to-date evidence-based GL repository.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.agwat.2022.107686,Journal,Agricultural Water Management,scopus,2022-07-01,sciencedirect,An ICT-based decision support system for precision irrigation management in outdoor orange and greenhouse tomato crops,https://api.elsevier.com/content/abstract/scopus_id/85129700977,"The digitalization of the agricultural sector through the implementation of cutting-edge technologies allows for the optimization of the use of water, whose scarcity has become one of the most relevant and complex environmental global problems. Water consumption data collected on site using different technologies is key to achieving optimal irrigation scheduling. Technology is also a useful tool that provides a real and transparent inventory of water use in irrigated crops. The water footprint obtained in accordance with ISO standard 14046 (using the Life Cycle Analysis methodology) and jointly with irrigation management information allows determining water use efficiency with great accuracy. This work presents a decision support system developed for precision irrigation management at farm scale called DSSPIM. The system provides a verifiable inventory of water use and an analysis/diagnosis of the adequacy of the irrigation performed using information and communication technologies (ICTs), as well as real-time knowledge of water inputs and outputs during crop development based on data received from water meters and soil moisture sensors installed in the field. Additionally, to achieve both purposes, a methodology is proposed to more accurately estimate rainwater use (green water) based on real measurements and the use of ICTs. The proposed methodology was applied during one season in two organic crops (greenhouse tomatoes and orange trees) located in southern Spain. The model allowed detecting inefficiencies in irrigation water use. A comparison between the actual management practices and the practices recommended by the DSSPIM underlines the importance of irrigation management in improving water use. In the case of orange trees, different irrigation system management scenarios were compared and showed that the application of controlled deficit irrigation strategies using DSSPIM can reduce irrigation water use by 20%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2022.103705,Journal,Biomedical Signal Processing and Control,scopus,2022-07-01,sciencedirect,Time series signal forecasting using artificial neural networks: An application on ECG signal,https://api.elsevier.com/content/abstract/scopus_id/85129554512,"Time Series Forecasting is the prediction of future values of a signal based on the observed past values. It has various applications in signal processing, especially in the medical field which needs high accuracy. This paper presents an MLP (Multilayer Perceptron), a class of FFNN (Feedforward Neural Network) for highly accurate time series forecasting. There are various methods of signal processing that are used in time series forecasting but each method is specific to the particular problem it solves. The current methods involve the use of different types of adaptive filters out of which the most common method is LMS (Least Mean Square) algorithm. Although the adaptive filters give a decent accuracy, but neural networks (NN) give the results more than satisfactory. On performing time series forecasting on a simulated ECG (Electrocardiogram) signal, an accuracy of 95.72% was achieved using ANNs (Artificial Neural Networks) competing with the LMS filter, which gave only 79% accuracy. When the same was implemented on real ECG data of a person suffering from Sleep Apnea, the ANNs offered 98.68% while LMS filter displayed only 91% accuracy. Additionally, the neural network was also denoising the signal while predicting. A signal-to-noise ratio of 29.71 dB and 16.33 dB for Neural Network prediction and LMS filter prediction was attained, respectively. In the case of the real data, the aforementioned values stand at 22.8 dB and 3.8 dB, respectively. Simulated results show that the neural networks give superior performance in time series forecasting than Adaptive Filters.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2022.103692,Journal,Biomedical Signal Processing and Control,scopus,2022-07-01,sciencedirect,A wavelet-based capsule neural network for ECG biometric identification,https://api.elsevier.com/content/abstract/scopus_id/85129448927,"Electrocardiogram (ECG) signals have received a high level of attention from the biometric research community due to their unique nature for each person, which makes them suitable for developing accurate and reliable human identification systems. Although most existing ECG-based biometric recognition methods have received prominent results, several consecutive heartbeat segments are used in their approaches to achieve high accuracy, which is challenging to apply in biometric systems deployed in real-world applications. This paper proposes a new approach for human identification via ECG, based on a combination of Continuous Wavelet Transform (CWT), Discrete Wavelet Transform (DWT) along with a novel kind of deep learning technique known as Capsule network. The CWT is used to transform a single heartbeat signal into the time–frequency domain, and the DWT is adopted to extract spectral information of 2D frequency-time scalogram images to further improve accuracy. The discrete wavelet coefficients are then used as input to the capsule network promoting the recognition performance due to its high learning capacities. To support real-life practicality of ECG biometric identification system, the effectiveness and efficiency of our approach were evaluated over four databases that include normal and abnormal ECG records: PTB Diagnosis ECG (PTB), MIT-BIH Arrhythmia, MIT-BIH Normal Sinus Rhythm (NSRDB), and the MIT-BIH ST Change (STDB) databases. Experimental results demonstrate that our proposed method was able to achieve high identification accuracies and outperforming other state-of-the-art methods, by achieving an accuracy of 99.5%, 98.1%, 98.2%, and 100% on the PTB, MIT-BIH arrhythmia, STDB, and NSRDB respectively. Furthermore, the approach showed very good generalization ability since the training and test sets were completely different, which demonstrates the feasibility to promote the application of our approach in practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2022.103715,Journal,Biomedical Signal Processing and Control,scopus,2022-07-01,sciencedirect,IoMT-fog-cloud based architecture for Covid-19 detection,https://api.elsevier.com/content/abstract/scopus_id/85129411587,"Limitations of available literature
                  Nowadays, coronavirus disease 2019 (COVID-19) is the world-wide pandemic due to its mutation over time. Several works done for covid-19 detection using different techniques however, the use of small datasets and the lack of validation tests still limit their works. Also, they depend only on the increasing the accuracy and the precision of the model without giving attention to their complexity which is one of the main conditions in the healthcare application. Moreover, the majority of healthcare applications with cloud computing use centralization transmission process of various and vast volumes of information what make the privacy and security of personal patient’s data easy for hacking. Furthermore, the traditional architecture of the cloud showed many weaknesses such as the latency and the low persistent performance.
               
                  Method proposed by the author with technical information
                  In our system, we used Discrete Wavelet transform (DWT) and Principal Component Analysis (PCA) and different energy tracking methods such as Teager Kaiser Energy Operator (TKEO), Shannon Wavelet Entropy Energy (SWEE), Log Energy Entropy (LEE) for preprocessing the dataset. For the first step, DWT used to decompose the image into coefficients where each coefficient is vector of features. Then, we apply PCA for reduction the dimension by choosing the most essential features in features map. Moreover, we used TKEO, SHEE, LEE to track the energy in the features in order to select the best and the most optimal features to reduce the complexity of the model. Also, we used CNN model that contains convolution and pooling layers due to its efficacity in image processing. Furthermore, we depend on deep neurons using small kernel windows which provide better features learning and minimize the model's complexity.
                  The used DWT-PCA technique with TKEO filtering technique showed great results in terms of noise measure where the Peak Signal-to-Noise Ratio (PSNR) was 3.14 dB and the Signal-to-Noise Ratio (SNR) of original and preprocessed image was 1.48, 1.47 respectively which guaranteed the performance of the filtering techniques.
                  The experimental results of the CNN model ensure the high performance of the proposed system in classifying the covid-19, pneumonia and normal cases with 97% of accuracy, 100% of precession, 97% of recall, 99% of F1-score, and 98% of AUC.
               
                  Advantages and application of proposed method
                  The use of DWT-PCA and TKEO optimize the selection of the optimal features and reduce the complexity of the model.
                  The proposed system achieves good results in identifying covid-19, pneumonia and normal cases.
                  The implementation of fog computing as an intermediate layer to solve the latency problem and computational cost which improve the Quality of Service (QoS) of the cloud.
                  Fog computing ensure the privacy and security of the patients’ data.
                  With further refinement and validation, the IFC-Covid system will be real-time and effective application for covid-19 detection, which is user friendly and costless.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2022.103637,Journal,Biomedical Signal Processing and Control,scopus,2022-07-01,sciencedirect,Real time detection and forecasting technique for asthma disease using speech signal and DENN classifier,https://api.elsevier.com/content/abstract/scopus_id/85127475224,"Abnormal sound of the lungs associated with asthma and respiratory disease. On the spectrogram, it exhibits continuous sinusoidal qualities across time as well as significant computer properties. In this article, a voice signal and an optimum classifier is used to present a real-time detection and forecasting (RTDF) approach for Asthma illness. For asthma diagnosis and forecasting, the suggested RTDF approach employs the improved whale optimization (IWO) algorithm. RTDF technology is used to classify normal and asthmatic diseases based on changes in voice signals. RTDF technology integrates a variety of working Differential evolutionary neural network (DENN) classifiers that are superior to current SVM classifiers and help prevent the development of asthma suppression. In addition, the digital detection gateway-based secondary output can detect or reject the primary output, making breath detection more reliable for weak respiratory sounds. Implementation is done in conjunction with MATLAB tools and performs performance analysis based on the probability of correct classification. The presentation of the planned process was evaluated using a special signal-to-noise ratio (SNR) using lung sounds from patients and normal subjects.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2022.108990,Journal,Mechanical Systems and Signal Processing,scopus,2022-07-01,sciencedirect,A domain generalization network combing invariance and specificity towards real-time intelligent fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85126637085,"Domain adaptation-based fault diagnosis (DAFD) methods have been explored to address cross-domain fault diagnosis problems, where distribution discrepancy exists between the training and testing data. However, the indispensable priori target distribution needed by DAFD methods hinders their application on real-time cross-domain fault diagnosis, where target data are not accessible in advance. To tackle this challenge, this paper proposes a novel domain generalization network for fault diagnosis under unknown working conditions. The main idea is to exploit domain invariance and retain domain specificity simultaneously, enabling deep models to benefit from the universal applicability of domain-invariant features while retaining the predictive power of specialized domain structures. Global distribution alignment and local class cluster are implemented to learn domain-invariant knowledge and obtain discriminant representations. Predictions of multiple task classifiers that preserve domain structures are optimally merged based on selected similarities for final diagnostic decisions. Extensive cross-domain fault diagnostic experiments validated the effectiveness of the proposed method.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2022.02.020,Journal,Future Generation Computer Systems,scopus,2022-07-01,sciencedirect,Leveraging conditional generative models in a general explanation framework of classifier decisions,https://api.elsevier.com/content/abstract/scopus_id/85125945590,"With the increase in use of machine learning classifiers in several fields, providing human- understandable explanation of their outputs has become an imperative. It is essential to generate trust for day-to-day tasks, especially in the sensible domains as medical imaging. Although many works have addressed this problem by generating visual explanation maps, they often provide noisy and inaccurate results forcing heuristic regularization unrelated to the classifier in question. In this paper, we propose a general perspective of the visual explanation problem overcoming these limitations. We show that visual explanation can be produced as the difference between two generated images obtained via two specific conditional generative models. Both generative models are trained using the classifier to explain and a database to enforce the following properties: (i) All images generated by the first generator are classified similarly to the input image, whereas the second generator’s outputs are classified oppositely. (ii) All generated images belong to the distribution of real images. (iii) The distances between the input image and the corresponding generated images are minimal so that the difference between the generated elements only reveals relevant information for the studied classifier. Using symmetrical and cyclic constraints, we present two different approximations and implementations of the general formulation. Experimentally, we demonstrate significant improvements with respect to the state-of-the-art on three different public data sets. In particular, the localization of regions influencing the classifier is consistent with human annotations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.116680,Journal,Expert Systems with Applications,scopus,2022-07-01,sciencedirect,Genetic programming for automatic skin cancer image classification,https://api.elsevier.com/content/abstract/scopus_id/85125466814,"Developing a computer-aided diagnostic system for detecting various types of skin malignancies from images has attracted many researchers. However, analyzing the behaviors of algorithms is as important as developing new systems in order to establish the effectiveness of a system in real-time situations which impacts greatly how well it can assist the dermatologist in making a diagnosis. Unlike many machine learning approaches such as Artificial Neural Networks, Genetic Programming (GP) automatically evolves models with its dynamic representation and flexibility. This study aims at analyzing recently developed GP-based approaches to skin image classification. These approaches have utilized the intrinsic feature selection and feature construction ability of GP to effectively construct informative features from a variety of pre-extracted features. These features encompass local, global, texture, color and multi-scale image properties of skin images. The performance of these GP methods is assessed using two real-world skin image datasets captured from standard camera and specialized instruments, and compared with six commonly used classification algorithms as well as existing GP methods. The results reveal that these constructed features greatly help improve the performance of the machine learning classification algorithms. Unlike “black-box” algorithms like deep neural networks, GP models are interpretable, therefore, our analysis shows that these methods can help dermatologists identify prominent skin image features. Further, it can help researchers identify suitable feature extraction methods for images captured from a specific instrument. Being fast, these methods can be deployed for making a quick and effective diagnosis in actual clinic situations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2022.116634,Journal,Expert Systems with Applications,scopus,2022-07-01,sciencedirect,Evolutionary inspired approach for mental stress detection using EEG signal,https://api.elsevier.com/content/abstract/scopus_id/85125009707,"Stress is a pensive issue in our competitive world and it has a huge impact on physical and mental health. Severe health issues may arise due to long exposure of stress. Hence, its timed detection can be helpful in managing stress periods. In this regard, electroencephalogram (EEG) based techniques have been widely explored, as stress severely impact the functioning and structure of brain. These non-invasive methods for stress detection need improvement in terms of predictive accuracy and reliability. In this work, a novel approach for stress detection has been presented using short duration of EEG signal. Entropy based features were extracted from EEG signal decomposed using stationary wavelet transform. Selected features were used for classification using different supervised machine learning algorithms. Further, different evolutionary inspired approaches were deployed to optimize the parameters of support vector machines (SVM) and perform feature weighting, simultaneously. SVM optimized using whale optimization algorithm resulted in an accuracy of 97.2559%. Accurate detection using short duration EEG signal shows potential of this technique for timed and reliable detection of stress.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2022.108743,Journal,Knowledge-Based Systems,scopus,2022-06-21,sciencedirect,Boosting chameleon swarm algorithm with consumption AEO operator for global optimization and feature selection,https://api.elsevier.com/content/abstract/scopus_id/85129505712,"Feature selection (FS) plays a crucial role as a pre-processing tool in data mining, especially for real-world applications in medical fields; it has been utilized exponentially and becomes very interesting to detect beneficial medical decisions. FS is deemed to be an NP-hard optimization problem that seeks to reduce feature size while maximizing the generalization of machine learning (ML) models. Chameleon swarm algorithm (CSA) is a recent devised metaheuristic algorithm inspired by chameleons’ intelligent behavior in nature. Because of its simplicity and ease of implementation, it has piqued the interest of numerous researchers to apply it in different fields. However, it suffers from premature convergence, the inadequate balance between exploration and exploitation, and being trapped in local optima. Accordingly, this paper develops an improved version of the CSA for FS, referred to as modified chameleon swarm algorithm (mCSA). This improvement was achieved by introducing three modifications to the original CSA to improve how well it performed. Firstly, we propose a non-linear transfer operator to achieve a better balance between exploration and exploitation. Secondly, we introduce a randomization Lévy flight control parameter to avoid stagnation and early convergence. Thirdly, we boost the global search strategy of the original CSA by the consumption operator of the Artificial ecosystem-based optimization (AEO) algorithm. The performance of the proposed mCSA method is assessed by employing the CEC2020 test suite for numerical optimization and fourteen UCI datasets, including real-world application (breast cancer diagnosis) for feature selection, and compared with several well-known algorithms and sophisticated approaches. The experimental results indicate that the proposed mCSA performs significantly better and outperforms existing comparative methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dsp.2021.103129,Journal,Digital Signal Processing: A Review Journal,scopus,2022-06-15,sciencedirect,Classification of fall directions via wearable motion sensors,https://api.elsevier.com/content/abstract/scopus_id/85125840335,"Effective fall-detection and classification systems are vital in mitigating severe medical and economical consequences of falls to people in the fall risk groups. One class of such systems is based on wearable sensors. While there is a vast amount of academic work on this class of systems, not much effort has been devoted to the investigation of effective and robust algorithms and like-for-like comparison of state-of-the-art algorithms using a sufficiently large dataset. In this article, fall-direction classification algorithms are presented and compared on an extensive dataset, comprising a total of 1600 fall trials. Eight machine learning classifiers are implemented for fall-direction classification into four basic directions (forward, backward, right, and left). These are, namely, Bayesian decision making (BDM), least squares method (LSM), k-nearest neighbor classifier (k-NN), artificial neural networks (ANNs), support vector machines (SVMs), decision-tree classifier (DTC), random forest (RF), and adaptive boosting or AdaBoost (AB). BDM achieves perfect classification, followed by k-NN, SVM, and RF. Data acquired from only a single motion sensor unit, worn at the waist of the subject, are processed for experimental verification. Four of the classifiers (BDM, LSM, k-NN, and ANN) are modified to handle the presence of data from an unknown class and evaluated on the same dataset. In this robustness analysis, ANN and k-NN yield accuracies above 96.2%. The results obtained in this study are promising in developing real-world fall-classification systems as they enable fast and reliable classification of fall directions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.heliyon.2022.e09634,Journal,Heliyon,scopus,2022-06-01,sciencedirect,Smart deployment of IoT-TelosB service care StreamRobot using software-defined reliability optimisation design,https://api.elsevier.com/content/abstract/scopus_id/85131417211,"Intelligent service care robots have increasingly been developed in mission-critical sectors such as healthcare systems, transportation, manufacturing, and environmental applications. The major drawbacks include the open-source Internet of Things (IoT) platform vulnerabilities, node failures, computational latency, and small memory capacity in IoT sensing nodes. This article provides reliable predictive analytics with the optimisation of data transmission characteristics in StreamRobot. Software-defined reliable optimisation design is applied in the system architecture. For the IoT implementation, the edge system model formulation is presented with a focus on edge cluster log-normality distribution, reliability, and equilibrium stability considerations. A real-world scenario for accurate data streams generation from in-built TelosB sensing nodes is converged at a sink-analytic dashboard. Two-phase configurations, namely off-taker and on-demand, link-state protocols are mapped for deterministic data stream offloading. An orphan reconnection trigger mechanism is used for reliable node-to-sink resilient data transmissions. Data collection is achieved, using component-based programming in the experimental testbed. Measurement parameters are derived with TelosB IoT nodes. Reliability validations on remote monitoring and prediction processes are studied considering neural constrained software-defined networking (SDN) intelligence. An OpenFlow-SDN construct is deployed to offload traffic from the edge to the fog layer. At the core, fog detection-to-cloud predictive machine learning (FD-CPML) is used to predict real-time data streams. Prediction accuracy is validated with decision tree, logistic regression, and the proposed FD-CPML. The data streams latency gave 40.00%, 33.33%, and 26.67%, respectively. Similarly, linear predictive scalability behaviour on the network plane gave 30.12%, 33.73%, and 36.15% respectively. The results show satisfactory responses in terms of reliable communication and intelligent monitoring of node failures.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(22)00049-8,Journal,The Lancet Digital Health,scopus,2022-06-01,sciencedirect,Recurrent neural network models (CovRNN) for predicting outcomes of patients with COVID-19 on admission to hospital: model development and validation using electronic health record data,https://api.elsevier.com/content/abstract/scopus_id/85130627855,"Background
                  Predicting outcomes of patients with COVID-19 at an early stage is crucial for optimised clinical care and resource management, especially during a pandemic. Although multiple machine learning models have been proposed to address this issue, because of their requirements for extensive data preprocessing and feature engineering, they have not been validated or implemented outside of their original study site. Therefore, we aimed to develop accurate and transferrable predictive models of outcomes on hospital admission for patients with COVID-19.
               
                  Methods
                  In this study, we developed recurrent neural network-based models (CovRNN) to predict the outcomes of patients with COVID-19 by use of available electronic health record data on admission to hospital, without the need for specific feature selection or missing data imputation. CovRNN was designed to predict three outcomes: in-hospital mortality, need for mechanical ventilation, and prolonged hospital stay (>7 days). For in-hospital mortality and mechanical ventilation, CovRNN produced time-to-event risk scores (survival prediction; evaluated by the concordance index) and all-time risk scores (binary prediction; area under the receiver operating characteristic curve [AUROC] was the main metric); we only trained a binary classification model for prolonged hospital stay. For binary classification tasks, we compared CovRNN against traditional machine learning algorithms: logistic regression and light gradient boost machine. Our models were trained and validated on the heterogeneous, deidentified data of 247 960 patients with COVID-19 from 87 US health-care systems derived from the Cerner Real-World COVID-19 Q3 Dataset up to September 2020. We held out the data of 4175 patients from two hospitals for external validation. The remaining 243 785 patients from the 85 health systems were grouped into training (n=170 626), validation (n=24 378), and multi-hospital test (n=48 781) sets. Model performance was evaluated in the multi-hospital test set. The transferability of CovRNN was externally validated by use of deidentified data from 36 140 patients derived from the US-based Optum deidentified COVID-19 electronic health record dataset (version 1015; from January, 2007, to Oct 15, 2020). Exact dates of data extraction were masked by the databases to ensure patient data safety.
               
                  Findings
                  CovRNN binary models achieved AUROCs of 93·0% (95% CI 92·6–93·4) for the prediction of in-hospital mortality, 92·9% (92·6–93·2) for the prediction of mechanical ventilation, and 86·5% (86·2–86·9) for the prediction of a prolonged hospital stay, outperforming light gradient boost machine and logistic regression algorithms. External validation confirmed AUROCs in similar ranges (91·3–97·0% for in-hospital mortality prediction, 91·5–96·0% for the prediction of mechanical ventilation, and 81·0–88·3% for the prediction of prolonged hospital stay). For survival prediction, CovRNN achieved a concordance index of 86·0% (95% CI 85·1–86·9) for in-hospital mortality and 92·6% (92·2–93·0) for mechanical ventilation.
               
                  Interpretation
                  Trained on a large, heterogeneous, real-world dataset, our CovRNN models showed high prediction accuracy and transferability through consistently good performances on multiple external datasets. Our results show the feasibility of a COVID-19 predictive model that delivers high accuracy without the need for complex feature engineering.
               
                  Funding
                  Cancer Prevention and Research Institute of Texas.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2022.102069,Journal,Computerized Medical Imaging and Graphics,scopus,2022-06-01,sciencedirect,Deep learning-based framework for motion-compensated image fusion in catheterization procedures,https://api.elsevier.com/content/abstract/scopus_id/85130396710,"Objective
                  Augmenting X-ray (XR) fluoroscopy with 3D anatomic overlays is an essential technique to improve the guidance of the catheterization procedures. Unfortunately, cardiac and respiratory motion compromises the augmented fluoroscopy. Motion compensation methods can be applied to update the overlay of a static model with regard to respiratory and cardiac motion. We investigate the feasibility of motion detection between two fluoroscopic frames by applying a convolutional neural network (CNN). Its integration in the existing open-source software framework 3D-XGuide is demonstrated, such extending its functionality to automatic motion detection and compensation.
               
                  Methods
                  The CNN is trained on reference data generated from tracking of the rapid pacing catheter tip by applying template matching with normalized cross-correlation (CC). The developed CNN motion compensation model is packaged in a standalone web service, allowing for independent use via a REST API. For testing and demonstration purposes, we have extended the functionality of 3D-XGuide navigation framework by an additional motion compensation module, which uses the displacement predictions of the standalone CNN model service for motion compensation of the static 3D model overlay. We provide the source code on GitHub under BSD license.
               
                  Results
                  The performance of the CNN motion compensation model was evaluated on a total of 1690 fluoroscopic image pairs from ten clinical datasets. The CNN model-based motion compensation method clearly overperformed the tracking of the rapid pacing catheter tip with CC with prediction frame rates suitable for live application in the clinical setting.
               
                  Conclusion
                  A novel CNN model-based method for automatic motion compensation during fusion of 3D anatomic models with XR fluoroscopy is introduced and its integration with a real software application demonstrated. Automatic motion extraction from 2D XR images using a CNN model appears as a substantial improvement for reliable augmentation during catheter interventions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gim.2022.02.007,Journal,Genetics in Medicine,scopus,2022-06-01,sciencedirect,Genomic answers for children: Dynamic analyses of &gt;1000 pediatric rare disease genomes,https://api.elsevier.com/content/abstract/scopus_id/85129740694,"Purpose
                  This study aimed to provide comprehensive diagnostic and candidate analyses in a pediatric rare disease cohort through the Genomic Answers for Kids program.
               
                  Methods
                  Extensive analyses of 960 families with suspected genetic disorders included short-read exome sequencing and short-read genome sequencing (srGS); PacBio HiFi long-read genome sequencing (HiFi-GS); variant calling for single nucleotide variants (SNV), structural variant (SV), and repeat variants; and machine-learning variant prioritization. Structured phenotypes, prioritized variants, and pedigrees were stored in PhenoTips database, with data sharing through controlled access the database of Genotypes and Phenotypes.
               
                  Results
                  Diagnostic rates ranged from 11% in patients with prior negative genetic testing to 34.5% in naive patients. Incorporating SVs from genome sequencing added up to 13% of new diagnoses in previously unsolved cases. HiFi-GS yielded increased discovery rate with >4-fold more rare coding SVs compared with srGS. Variants and genes of unknown significance remain the most common finding (58% of nondiagnostic cases).
               
                  Conclusion
                  Computational prioritization is efficient for diagnostic SNVs. Thorough identification of non-SNVs remains challenging and is partly mitigated using HiFi-GS sequencing. Importantly, community research is supported by sharing real-time data to accelerate gene validation and by providing HiFi variant (SNV/SV) resources from >1000 human alleles to facilitate implementation of new sequencing platforms for rare disease diagnoses.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cca.2022.04.997,Journal,Clinica Chimica Acta,scopus,2022-06-01,sciencedirect,Semi-nested RT-PCR enables sensitive and high-throughput detection of SARS-CoV-2 based on melting analysis,https://api.elsevier.com/content/abstract/scopus_id/85129253904,"Background
                  Asymptomatic transmission was found to be the Achilles’ heel of the symptom-based screening strategy, necessitating the implementation of mass testing to efficiently contain the transmission of COVID-19 pandemic. However, the global shortage of molecular reagents and the low throughput of available realtime PCR facilities were major limiting factors.
               
                  Methods
                  A novel semi-nested and heptaplex (7-plex) RT-PCR assay with melting analysis for detection of SARS-CoV-2 RNA has been established for either individual testing or 96-sample pooled testing. The complex melting spectrum collected from the heptaplex RT-PCR amplicons was interpreted with the support of an artificial intelligence algorithm for the detection of SARS-CoV-2 RNA. The analytical and clinical performance of the semi-nested RT-PCR assay was evaluated using RNAs synthesized in-vitro and those isolated from nasopharyngeal samples.
               
                  Results
                  The LOD of the assay for individual testing was estimated to be 7.2 copies/reaction. Clinical performance evaluation indicated a sensitivity of 100% (95% CI: 97.83–100) and a specificity of 99.87% (95% CI: 99.55–99.98). More importantly, the assay supports a breakthrough sample pooling method, which makes possible parallel screening of up to 96 samples in one real-time PCR well without loss of sensitivity. As a result, up to 8,820 individual pre-amplified samples could be screened for SARS-CoV-2 within each 96-well plate of realtime PCR using the pooled testing procedure.
               
                  Conclusion
                  The novel semi-nested RT-PCR assay provides a solution for highly multiplex (7-plex) detection of SARS-CoV-2 and enables 96-sample pooled detection for increase of testing capacity.
                  .",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cobme.2022.100382,Journal,Current Opinion in Biomedical Engineering,scopus,2022-06-01,sciencedirect,Emerging and future use of intra-surgical volumetric X-ray imaging and adjuvant tools for decision support in breast-conserving surgery,https://api.elsevier.com/content/abstract/scopus_id/85128643388,"Breast-conserving surgery requires that resection margins be cancer-free, but re-excision rates due to positive margins have remained near 20% for much of the last decade with high variability between surgical centers. Recent studies have demonstrated that volumetric X-ray imaging improves margin assessment over standard techniques, given the speed of image reconstruction and full three-dimensional sensing of all margins. Deep learning approaches for automated analysis of volumetric medical image data are gaining traction and could play an important role streamlining the clinical workflow for intra-surgical specimen imaging. X-ray imaging systems currently deployed in clinical studies suffer from poor tumor-to-fibroglandular tissue contrast, motivating the development of adjuvant tools that could potentially complement volumetric X-ray scanning and further improve the future of intra-surgical margin assessment by real-time augmented guidance for the surgeon.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isprsjprs.2022.04.002,Journal,ISPRS Journal of Photogrammetry and Remote Sensing,scopus,2022-06-01,sciencedirect,Vision based crown loss estimation for individual trees with remote aerial robots,https://api.elsevier.com/content/abstract/scopus_id/85128243118,"With the capability of capturing high-resolution imagery data and the ease of accessing remote areas, aerial robots are becoming increasingly popular for forest health monitoring applications. For example, forestry tasks such as field surveys and foliar sampling which are generally manual and labour intensive can be automated with remotely controlled aerial robots. In this study, we propose two new online frameworks to quantify and rank the severity of individual tree crown loss. The real-time crown loss estimation (RTCLE) model localises and classifies individual trees into their respective crown loss percentage bins. Experiments are conducted to investigate if synthetically generated tree images can be used to train the RTCLE model as real images with diverse viewpoints are generally expensive to collect. Results have shown that synthetic data training helps to achieve a satisfactory baseline mean average precision (mAP) which can be further improved with just some additional real imagery data. We showed that the mAP can be increased approximately from 60% to 78% by mixing the real dataset with the generated synthetic data. For individual tree crown loss ranking, a two-step crown loss ranking (TSCLR) framework is developed to handle the inconsistently labelled crown loss data. The TSCLR framework detects individual trees before ranking them based on some relative crown loss severity measures. The tree detection model is trained with the combined dataset used in the RTCLE model training where we achieved an mAP of approximately 95% suggesting that the model generalises well to unseen datasets. The relative crown loss severity of each tree is estimated, with deep representation learning, by a probabilistic encoder from a fully trained variational autoencoder (VAE) model. The VAE is trained end-to-end to reconstruct tree images in a background agnostic way. Based on a conservative evaluation, the estimated crown loss severity from the probabilistic encoder generally showed moderate agreement with the expert’s estimation across all species of trees present in the dataset. All the software pipelines, the dataset, and the synthetic dataset generation can be found in the GitHub link.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2022.104758,Journal,International Journal of Medical Informatics,scopus,2022-06-01,sciencedirect,Machine learning models for diabetes management in acute care using electronic medical records: A systematic review,https://api.elsevier.com/content/abstract/scopus_id/85127677478,"Background
                  Machine learning (ML) is a subset of Artificial Intelligence (AI) that is used to predict and potentially prevent adverse patient outcomes. There is increasing interest in the application of these models in digital hospitals to improve clinical decision-making and chronic disease management, particularly for patients with diabetes. The potential of ML models using electronic medical records (EMR) to improve the clinical care of hospitalised patients with diabetes is currently unknown.
               
                  Objective
                  The aim was to systematically identify and critically review the published literature examining the development and validation of ML models using EMR data for improving the care of hospitalised adult patients with diabetes.
               
                  Methods
                  The Preferred Reporting Items for Systematic Reviews and Meta Analyses (PRISMA) guidelines were followed. Four databases were searched (Embase, PubMed, IEEE and Web of Science) for studies published between January 2010 to January 2022. The reference lists of the eligible articles were manually searched. Articles that examined adults and both developed and validated ML models using EMR data were included. Studies conducted in primary care and community care settings were excluded. Studies were independently screened and data was extracted using Covidence® systematic review software. For data extraction and critical appraisal, the Checklist for Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies (CHARMS) was followed. Risk of bias was assessed using the Prediction model Risk Of Bias Assessment Tool (PROBAST). Quality of reporting was assessed by adherence to the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) guideline. The IJMEDI checklist was followed to assess quality of ML models and the reproducibility of their outcomes. The external validation methodology of the studies was appraised.
               
                  Results
                  Of the 1317 studies screened, twelve met inclusion criteria. Eight studies developed ML models to predict disglycaemic episodes for hospitalized patients with diabetes, one study developed a ML model to predict total insulin dosage, two studies predicted risk of readmission, and one study improved the prediction of hospital readmission for inpatients with diabetes. All included studies were heterogeneous with regard to ML types, cohort, input predictors, sample size, performance and validation metrics and clinical outcomes. Two studies adhered to the TRIPOD guideline. The methodological reporting of all the studies was evaluated to be at high risk of bias. The quality of ML models in all studies was assessed as poor. Robust external validation was not performed on any of the studies. No models were implemented or evaluated in routine clinical care.
               
                  Conclusions
                  This review identified a limited number of ML models which were developed to improve inpatient management of diabetes. No ML models were implemented in real hospital settings. Future research needs to enhance the development, reporting and validation steps to enable ML models for integration into routine clinical care.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2022.105430,Journal,Computers in Biology and Medicine,scopus,2022-06-01,sciencedirect,Deep convolutional neural network-based signal quality assessment for photoplethysmogram,https://api.elsevier.com/content/abstract/scopus_id/85126968131,"Quality assessment of bio-signals is important to prevent clinical misdiagnosis. With the introduction of mobile and wearable health care, it is becoming increasingly important to distinguish available signals from noise. The goal of this study was to develop a signal quality assessment technology for photoplethysmogram (PPG) widely used in wearable healthcare. In this study, we developed and verified a deep neural network (DNN)-based signal quality assessment model using about 1.6 million 5-s segment length PPG big data of about 29 GB from the MIMIC III PPG waveform database. The DNN model was implemented through a 1D convolutional neural network (CNN). The number of CNN layers, number of fully connected nodes, dropout rate, batch size, and learning rate of the model were optimized through Bayesian optimization. As a result, 6 CNN layers, 1,546 fully connected layer nodes, 825 batch size, 0.2 dropout rate, and 0.002 learning rate were needed for an optimal model. Performance metrics of the result of classifying waveform quality into ‘Good’ and ‘Bad’, the accuracy, specificity, sensitivity, area under the receiver operating curve, and area under the precision–recall curve were 0.978, 0.948, 0.993, 0.985, 0.980, and 0.969, respectively. Additionally, in the case of simulated real-time application, it was confirmed that the proposed signal quality score tracked the decrease in pulse quality well.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.phymed.2022.154059,Journal,Phytomedicine,scopus,2022-06-01,sciencedirect,Discovery of the directionally detoxification effect and chemical mechanism of Ginseng-Fuzi co-decoction based on real-time online filtration electrospray ionization mass spectrometry,https://api.elsevier.com/content/abstract/scopus_id/85126880073,"Background
                  The synergic action of compound prescriptions is an important feature and core advantage of traditional medicine. Ginseng-Fuzi decoction is a classic compatible phytomedicine in China, of which Ginseng can effectively reduce the toxicity of Fuzi in clinical, but the detoxification chemical mechanism is still unclear.
               
                  Purpose
                  Develop a novel method for real-time tracking and monitoring of complex substances in the decoction system of traditional Chinese medicine to uncover the detoxification effect Ginseng on Fuzi and explore the possible chemical reaction mechanism of Ginseng-Fuzi co-decoction.
               
                  Methods
                  A novel real-time monitoring system, online filtration electrospray ionization mass spectrometry, was developed for extremely complex substances analysis in the decoction of traditional medicine compounds to uncover the directionally detoxification effect and the mechanism of compatibility interaction.
               
                  Results
                  Nine key alkaloids and 7 ginsenosides in Ginseng-Fuzi decoction were simultaneously in-situ monitoring in positive ion mode or negative ion mode respectively. Both types of targeted analytes had satisfactory MS signal response for real-time qualitative and quantitative analysis with high precision (RSD < 14.04%) and low LLODs (0.002 ng/ml-10 ng/ml). Through long-term tracking analysis, the exact detoxification and synergistic effect of Ginseng-Fuzi decoction were confirmed as the concentration of main toxic alkaloids decreased (e.g. the content of mesaconitine has been reduced by about 38%) and the main active monoester alkaloids increased obviously. More importantly, the possible molecular mechanism of the detoxification effect of Ginseng compatibility was revealed for the first time, which was the nucleophilic substitution reaction of diester alkaloids catalyzed by fatty acids.
               
                  Conclusion
                  This study revealed the exact effect of co-decoction of Ginseng and Fuzi at the molecular level and the chemical reaction mechanism of fatty acid-catalyzed degradation of toxic diester-type alkaloids. The comprehensive multi-component real-time monitoring strategy for complex traditional medicine compounds developed and implemented here has important demonstration significance for revealing the scientific connotation of the compatibility of compound traditional medicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2022.104736,Journal,International Journal of Medical Informatics,scopus,2022-06-01,sciencedirect,A hybrid model to identify fall occurrence from electronic health records,https://api.elsevier.com/content/abstract/scopus_id/85126622773,"Introduction
                  Falls are a leading cause of unintentional injury in the elderly. Electronic health records (EHRs) offer the unique opportunity to develop models that can identify fall events. However, identifying fall events in clinical notes requires advanced natural language processing (NLP) to simultaneously address multiple issues because the word “fall” is a typical homonym.
               
                  Methods
                  We implemented a context-aware language model, Bidirectional Encoder Representations from Transformers (BERT) to identify falls from the EHR text and further fused the BERT model into a hybrid architecture coupled with post-hoc heuristic rules to enhance the performance. The models were evaluated on real world EHR data and were compared to conventional rule-based and deep learning models (CNN and Bi-LSTM). To better understand the ability of each approach to identify falls, we further categorize fall-related concepts (i.e., risk of fall, prevention of fall, homonym) and performed a detailed error analysis.
               
                  Results
                  The hybrid model achieved the highest f1-score on sentence (0.971), document (0.985), and patient (0.954) level. At the sentence level (basic data unit in the model), the hybrid model had 0.954, 1.000, 0.988, and 0.999 in sensitivity, specificity, positive predictive value, and negative predictive value, respectively. The error analysis showed that that machine learning-based approaches demonstrated higher performance than a rule-based approach in challenging cases that required contextual understanding. The context-aware language model (BERT) slightly outperformed the word embedding approach trained on Bi-LSTM. No single model yielded the best performance for all fall-related semantic categories.
               
                  Conclusion
                  A context-aware language model (BERT) was able to identify challenging fall events that requires context understanding in EHR free text. The hybrid model combined with post-hoc rules allowed a custom fix on the BERT outcomes and further improved the performance of fall detection.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2022.106727,Journal,Computer Methods and Programs in Biomedicine,scopus,2022-06-01,sciencedirect,Cardi-Net: A deep neural network for classification of cardiac disease using phonocardiogram signal,https://api.elsevier.com/content/abstract/scopus_id/85126586158,"Background and objectives
                  The lack of medical facilities in isolated areas makes many patients remain aloof from quick and timely diagnosis of cardiovascular diseases, leading to high mortality rates. A deep learning based method for automatic diagnosis of multiple cardiac diseases from Phonocardiogram (PCG) signals is proposed in this paper.
               
                  Methods
                  The proposed system is a combination of deep learning based convolutional neural network (CNN) and power spectrogram Cardi-Net, which can extract deep discriminating features of PCG signals from the power spectrogram to identify the diseases. The choice of Power Spectral Density (PSD) makes the model extract highly discriminatory features significant for the multi-classification of four common cardiac disorders.
               
                  Results
                  Data augmentation techniques are applied to make the model robust, and the model undergoes 10-fold cross-validation to yield an overall accuracy of 98.879% on the test dataset to diagnose multi heart diseases from PCG signals.
               
                  Conclusion
                  The proposed model is completely automatic, where signal pre-processing and feature engineering are not required. The conversion time of power spectrogram from PCG signals is very low range from 0.10 s to 0.11 s. This reduces the complexity of the model, making it highly reliable and robust for real-time applications. The proposed architecture can be deployed on cloud and a low cost processor, desktop, android app leading to proper access to the dispensaries in remote areas.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2022.105413,Journal,Computers in Biology and Medicine,scopus,2022-06-01,sciencedirect,Overcoming limitation of dissociation between MD and MI classifications of breast cancer histopathological images through a novel decomposed feature-based knowledge distillation method,https://api.elsevier.com/content/abstract/scopus_id/85126566015,"Magnification-independent (MI) classification is considered a promising method for detecting the histopathological images of breast cancer. However, it has too many parameters for real implementation due to dependence on input images in different magnification factors. In addition, magnification-dependent (MD) classification usually performs poorly on unseen samples, although it has lower input image sizes and fewer parameters. This paper proposes a novel method based on knowledge distillation (KD) to overcome the limitation of dissociation between MI classification and MD classification of breast cancer in histopathological images. The proposed KD method includes a pre-trained MI teacher model that is responsible for training an unprepared MD student model developed through only one magnification factor. In the proposed method, the decomposed feature maps of a teacher's intermediate layers are transferred as dark knowledge to a student. According to the experimental results, the student model developed through 40X images yielded accuracy rates of 99.41%, 99.26%, 99.14%, and 99.09% in response to unseen samples of 40X, 100X, 200X, and 400X images, respectively. Moreover, comparison results indicated the competitive performance of the proposed student model as opposed to the state-of-the-art method based on deep learning on BreakHis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.amc.2022.126967,Journal,Applied Mathematics and Computation,scopus,2022-06-01,sciencedirect,Plug-and-Play gradient-based denoisers applied to CT image enhancement,https://api.elsevier.com/content/abstract/scopus_id/85124034114,"Blur and noise corrupting Computed Tomography (CT) images can hide or distort small but important details, negatively affecting the consequent diagnosis. In this paper, we present a novel gradient-based Plug-and-Play (PnP) algorithm and we apply it to restore CT images. The plugged denoiser is implemented as a deep Convolutional Neural Network (CNN) trained on the gradient domain (and not on the image one, as in state-of-the-art works) and it induces an external prior onto the restoration model. We further consider a hybrid scheme which combines the gradient-based external denoiser with an internal one, obtained from the Total Variation functional. The proposed frameworks rely on the Half-Quadratic Splitting scheme and we prove a general fixed-point convergence theorem, under weak assumptions on both the denoisers. The experiments confirm the effectiveness of the proposed gradient-based approach in restoring blurred noisy CT images, both in simulated and real medical settings. The obtained performances outperform the achievements of many state-of-the-art methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asej.2021.101660,Journal,Ain Shams Engineering Journal,scopus,2022-06-01,sciencedirect,A review of enabling technologies for Internet of Medical Things (IoMT) Ecosystem,https://api.elsevier.com/content/abstract/scopus_id/85122471097,"The goal of Internet of Medical Things (IoMT) and digital healthcare systems is to provide people with the ease of receiving quality healthcare at the comfort of their homes. Hence, the aim of IoMT is the ubiquitous deployment of home-based healthcare systems. Making such systems intelligent and efficient for timely prediction of critical diseases can save millions of lives while simultaneously reducing the burden on the traditional healthcare systems e.g., hospitals. The advancement in IoT has enabled both patients and doctors to access real time data. This advancement has reduced the cost and energy consumption of digital healthcare systems by using efficient sensors and communication technologies. This paper provides a comprehensive review of various studies conducted for the development and improvement of IoMT. It analyses different sensors used for measurement of various parameters ranging from physiological to emotional signals. It also provides a detailed investigation of different communication technologies being used, their advantages, and limitations. Moreover, digital healthcare systems are now deploying machine learning technology for the prediction of health status of patients. These techniques and algorithms are also discussed. Data security and prediction accuracy are the main concerns in the development of this area. In conclusion, this paper reviews the various digital system designs in the context of healthcare, their methodology, limitations, and the present challenges faced by the e-health sector.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pec.2021.09.027,Journal,Patient Education and Counseling,scopus,2022-06-01,sciencedirect,"Ask Rosa – The making of a digital genetic conversation tool, a chatbot, about hereditary breast and ovarian cancer",https://api.elsevier.com/content/abstract/scopus_id/85116873604,"Objective
                  We aimed at developing a pilot version of an app (Rosa) that can perform digital conversations with breast or ovarian cancer patients about genetic BRCA testing, using chatbot technology, to identify best practices for future patient-focused chatbots.
               
                  Methods
                  We chose a commercial chatbot platform and participatory methodology with a team of patient representatives, IT engineers, genetic counselors and clinical geneticists, within a nationwide collaboration. An iterative approach ensured extensive user and formal usability testing during the development process.
               
                  Results
                  The development phase lasted for two years until the pilot version was completed in December 2019. The iteration steps disclosed major challenges in the artificial intelligence (AI)-based matching of user provided questions with predefined information in the database, leading initially to high level of fallback answers. We therefore developed strategies to reduce potential language ambiguities (e.g. BRCA1 vs BRCA2) and overcome dialogue confusion. The first prototype contained a database with 500 predefined questions and 67 corresponding predefined answers, while the final version included 2257 predefined questions and 144 predefined answers. Despite the limited AI functionality of the chatbot, the testing revealed that the users liked the layout and found the chatbot trustworthy and reader friendly.
               
                  Conclusions
                  Building a health chatbot is challenging, expensive and time consuming with today’s technology. The users had a positive attitude to the chatbot, and would use it in a real life setting, if given to them by health care personnel.
               
                  Practice implications
                  We here present a framework for future health chatbot initiatives. The participatory methodology in combination with an iterative approach ensured that the patient perspective was incorporated at every level of the development process. We strongly recommend this approach in patient-centered health innovations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2022.02.032,Journal,Neurocomputing,scopus,2022-05-28,sciencedirect,A hierarchical scheme for remaining useful life prediction with long short-term memory networks,https://api.elsevier.com/content/abstract/scopus_id/85125541259,"Remaining useful life (RUL) prediction is essential in prognostics and health management (PHM) applications, where data-driven approaches employ the tendency of the degradation process using operating data of complex systems, and have attracted more and more attention. With the idea that forecasting the time period before the equipment reaches the critical degradation stage (e.g., failure, fault, etc.), RUL prediction is usually formed as an optimization problem (in particular, a regression problem between the inputs–real-time measurements and the outputs–the RUL predictions). This work formulates the RUL prediction as a bi-level optimization problem, (i) the lower level is intended to forecast the time-series in the near future, and (ii) the upper level is to predict the RULs by integrating the available measurements up-to-date and the predicted ones by the lower-level prediction. To tackle the hierarchical optimization problem, a bi-level deep learning scheme is proposed for the machine RUL prediction, where long short-term memory (LSTM) networks are applied as of the unique characteristics in processing time-series and extracting recursive and non-recursive features among them. Case studies using PHM08 data challenge data set, 4 data sets in C-MAPSS package and 1 data set in the new CMAPSS dataset are implemented, to validate the proposed framework. The results show that the presented method outperforms the state-of-the-art approaches.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2022.111054,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2022-05-15,sciencedirect,Integrating bio medical sensors in detecting hidden signatures of COVID-19 with Artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85127210536,"Today COVID-19 pandemic articulates high stress on clinical resources around the world. At present, physical and viral tests are slowly emerging, and there is a need for robust pandemic detection that biomedical sensors can aid. The utility of biomedical sensors is correlated with the medical instruments with physiological metrics. These Biomedical sensors are integrated with the systematic device to track the target analytes with a biomedical component. The COVID-19 patients' samples are collected, and biomarkers are detected using four sensors: blood pressure sensor, G-FET based biosensor, electrochemical sensor, and potentiometric sensor with different quantifiable measures. The imputed data is then profiled with chest X-ray images from the Covid-19 patients.Multi-Layer Perceptron (MLP), an AI model, is deployed to identify the hidden signatures with biomarkers. The performance of the biosensor is measured with three parameters such as sensitivity, specificity and detection limit by generating the calibration plots that accurately fits the model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(22)00021-8,Journal,The Lancet Digital Health,scopus,2022-05-01,sciencedirect,Validation of artificial intelligence prediction models for skin cancer diagnosis using dermoscopy images: the 2019 International Skin Imaging Collaboration Grand Challenge,https://api.elsevier.com/content/abstract/scopus_id/85128465006,"Background
                  Previous studies of artificial intelligence (AI) applied to dermatology have shown AI to have higher diagnostic classification accuracy than expert dermatologists; however, these studies did not adequately assess clinically realistic scenarios, such as how AI systems behave when presented with images of disease categories that are not included in the training dataset or images drawn from statistical distributions with significant shifts from training distributions. We aimed to simulate these real-world scenarios and evaluate the effects of image source institution, diagnoses outside of the training set, and other image artifacts on classification accuracy, with the goal of informing clinicians and regulatory agencies about safety and real-world accuracy.
               
                  Methods
                  We designed a large dermoscopic image classification challenge to quantify the performance of machine learning algorithms for the task of skin cancer classification from dermoscopic images, and how this performance is affected by shifts in statistical distributions of data, disease categories not represented in training datasets, and imaging or lesion artifacts. Factors that might be beneficial to performance, such as clinical metadata and external training data collected by challenge participants, were also evaluated. 25 331 training images collected from two datasets (in Vienna [HAM10000] and Barcelona [BCN20000]) between Jan 1, 2000, and Dec 31, 2018, across eight skin diseases, were provided to challenge participants to design appropriate algorithms. The trained algorithms were then tested for balanced accuracy against the HAM10000 and BCN20000 test datasets and data from countries not included in the training dataset (Turkey, New Zealand, Sweden, and Argentina). Test datasets contained images of all diagnostic categories available in training plus other diagnoses not included in training data (not trained category). We compared the performance of the algorithms against that of 18 dermatologists in a simulated setting that reflected intended clinical use.
               
                  Findings
                  64 teams submitted 129 state-of-the-art algorithm predictions on a test set of 8238 images. The best performing algorithm achieved 58·8% balanced accuracy on the BCN20000 data, which was designed to better reflect realistic clinical scenarios, compared with 82·0% balanced accuracy on HAM10000, which was used in a previously published benchmark. Shifted statistical distributions and disease categories not included in training data contributed to decreases in accuracy. Image artifacts, including hair, pen markings, ulceration, and imaging source institution, decreased accuracy in a complex manner that varied based on the underlying diagnosis. When comparing algorithms to expert dermatologists (2460 ratings on 1269 images), algorithms performed better than experts in most categories, except for actinic keratoses (similar accuracy on average) and images from categories not included in training data (26% correct for experts vs 6% correct for algorithms, p<0·0001). For the top 25 submitted algorithms, 47·1% of the images from categories not included in training data were misclassified as malignant diagnoses, which would lead to a substantial number of unnecessary biopsies if current state-of-the-art AI technologies were clinically deployed.
               
                  Interpretation
                  We have identified specific deficiencies and safety issues in AI diagnostic systems for skin cancer that should be addressed in future diagnostic evaluation protocols to improve safety and reliability in clinical practice.
               
                  Funding
                  Melanoma Research Alliance and La Marató de TV3.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ebiom.2022.103989,Journal,eBioMedicine,scopus,2022-05-01,sciencedirect,Mind your Ps: A probabilistic model to aid the interpretation of molecular epidemiology data,https://api.elsevier.com/content/abstract/scopus_id/85127726316,"Background
                  Assessing relatedness of pathogen sequences in clinical samples is a core goal in molecular epidemiology. Tools for Bayesian analysis of phylogeny, such as the BEAST software package, have been typically used in the analysis of sequence/time data in public health. However, they are computationally-, time-, and knowledge-intensive, demanding resources that many laboratories do not have available or cannot allocate frequently.
               
                  Methods
                  To evaluate a faster and simpler alternative method to support the routine interpretation of sequence data for epidemiology, we obtained sequences for two regions in the measles virus genome, N-450 and MF-NCR, from patient samples of genotypes B3, D4 and D8 taken between 2011 and 2017 in the UK and Romania. A mathematical model incorporating time, possible shared ancestry and the Poisson distribution describing the number of expected substitutions at a given time point was developed to exclude epidemiological relatedness between pairs of sequences. The model was validated against the commonly used Bayesian phylogenetic method using an independent dataset collected in 2017–19.
               
                  Findings
                  We demonstrate that our model, using time and sequence information to predict whether two samples may be related within a given time frame, minimises the risk of erroneous exclusion of relatedness. An easy-to-use implementation in the form of a guide and spreadsheet is provided for convenient application.
               
                  Interpretation
                  The proposed model only requires a previously calculated substitution rate for the locus and pathogen of interest. It allows for an informed but quick decision on the likelihood of relatedness between two samples within a time frame, without the need for phylogenetic reconstruction, thus facilitating rapid epidemiological interpretation of sequence data.
               
                  Funding
                  This work was funded by the United Kingdom Health Security Agency (UKHSA). The World Health Organization European Regional Office funded Aurora Fernández-García and Mihaela Lazar training visits to UKHSA.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.fsi.2022.03.030,Journal,Fish and Shellfish Immunology,scopus,2022-05-01,sciencedirect,Acute septicemia and immune response of spotted sea bass (Lateolabrax maculatus) to Aeromonas veronii infection,https://api.elsevier.com/content/abstract/scopus_id/85127596055,"A previous study confirmed that spotted sea bass (Lateolabrax maculatus), an economically important cultured species in East Asia, is a new host of Aeromonas veronii, which can cause acute death in these fish, but there is little in-depth understanding of this disease. In the present study, the virulence of 10 isolates of A. veronii derived from spotted sea bass was determined. It was found that the 18BJ181 isolate was a virulent strain and led to the fastest death of spotted sea bass. Death was determined to be within in 2–12 h, and resulted in abdominal effusion and varying degrees of hemorrhage in internal organs. Bacterial colonization analysis showed that the bacterial load in the spleen was highest, and was up to 3.1 × 105 cfu g−1. In addition, the bacteria proliferated massively in the blood and reached 2.4 × 107 cfu mL−1 at 12 h after 18BJ181 strain infection, which was also a typical feature of acute septicemia. Histopathology of the spleen revealed edema in interstitial tissue, degeneration, and necrosis in lymphoid tissue, and hemorrhage in the capillary network. Transcriptome analysis of the spleen showed that the expression level of HSP70, CCL19, and IL-1β was extremely significantly up-regulated at 8 h after infection (P < 0.01), and the expression of these genes was normal at 24 h. These results revealed that A. veronii infection could rapidly activate the chemokine signal pathway and stimulate the acute inflammatory response in the host. The bacterial colonization, pathological features, and gene expression patterns in immune pathways will help us to better understand acute septicemia in spotted sea bass caused by A. veronii.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2022.107965,Journal,Computers and Electrical Engineering,scopus,2022-05-01,sciencedirect,Real-Time intelligent Elevator Monitoring and Diagnosis: Case Studies and Solutions with applications using Artificial Intelligence,https://api.elsevier.com/content/abstract/scopus_id/85127311531,"Under ""Industry 4.0"", the implementation and application of big data and Artificial Intelligence (AI) technology in the elevator industry has become more and more common. With the surge of the elevator operation data and higher requirements for its real-time performance, the traditional elevator fault monitoring is inaccurate, which needs to be solved urgently. In this paper, a fault monitoring and diagnosis method of elevator based on AI and big data is proposed. Firstly, the elevator system and its fault types and causes are analyzed. Then in order to select the best big data processing tools, the performance of Flink and Spark Streaming is compared. The results show that Flink features faster computing speed and is more suitable for handling big data. Thirdly, a pattern recognition algorithm based on finite state machine (FSM) is proposed to monitor the running state for whole elevator control system. Finally, simulation experiment has been made.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jics.2022.100429,Journal,Journal of the Indian Chemical Society,scopus,2022-05-01,sciencedirect,Evaluation of nanomaterials-grafted enzymes for application in contaminants degradation: Need of the hour with proposed IoT synchronized nanosensor fit sustainable clean water technology in en masse,https://api.elsevier.com/content/abstract/scopus_id/85126918775,"Increased water pollution and challenges in ultrafast recognition of water pollutants poses considerable burden to the public health. The issue of providing clean water to rural people is always a daunting yet challenging task wherein building a centralized water treatment system along with proper pipeline to connect dispersed population is not at all feasible. Amongst different water treatment technologies, sustainable nanozyme based materials have made an exceptional contribution towards providing contaminants free potable water to mankind due to its strong activity and sensitivity towards chemical substances thus facilitating use in advanced point-of-use (POU) system. In this article, we have briefly highlighted the way by which silica, carbon and MOF based nano support stabilizes the enzyme with its improved selectivity and sensitivity towards water decontamination. The strength of nanozymes and its potential use in POU devices has also been discussed for future research endeavor. Additionally, development of various nano-chemo-sensors with advanced machine learning approach is an added advantage towards detecting various contaminants from real samples with its implementation in POU devices. We have also proposed the implementing strategies of these nanozyme based water technologies so that early adopters can be given an informed decision about its way of implementation in coming days in India.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2022.102262,Journal,Artificial Intelligence in Medicine,scopus,2022-05-01,sciencedirect,A method for the early prediction of chronic diseases based on short sequential medical data,https://api.elsevier.com/content/abstract/scopus_id/85126362520,"Noncommunicable diseases (NCDs) have become the leading cause of death worldwide. NCDs' chronicity, hiddenness, and irreversibility make patients' disease self-awareness extremely important in disease control but hard to achieve. With an accumulation of electronic health record (EHR) data, it has become possible to predict NCDs early through machine learning approaches. However, EHR data from latent NCD patients are often irregularly sampled temporally, and the data sequences are short and imbalanced, which prevents researchers from fully and effectively using such data. Here, we outline the characteristics of typical short sequential data for NCD early prediction and emphasize the importance of using such data in machine learning schemes. We then propose a novel NCD early prediction method: the short sequential medical data-based early prediction method (SSEPM). The SSEPM network contains two stacked subnetworks for multilabel enhancement. In each subnetwork, long short-term memory (LSTM) and attention layers are implemented to extract both temporal and nontemporal embedded features. During training, with prior clinical knowledge of the NCD characteristics, a random connection (RC) process is proposed for data augmentation. Comparative experiments involving ten-fold cross-validation are performed with real-world medical data to predict 5 NCDs. The result shows that the SSEPM outperforms the state-of-the-art NCD early prediction algorithms and works well in dealing with short sequential data. The results also suggest that the direct use of short sequential data could be more effective than formatting datasets with temporal exclusion limitations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2022.104724,Journal,International Journal of Medical Informatics,scopus,2022-05-01,sciencedirect,Deep Learning-based detection of psychiatric attributes from German mental health records,https://api.elsevier.com/content/abstract/scopus_id/85126045365,"Background
                  Health care records provide large amounts of data with real-world and longitudinal aspects, which is advantageous for predictive analyses and improvements in personalized medicine. Text-based records are a main source of information in mental health. Therefore, application of text mining to the electronic health records – especially mental state examination – is a key approach for detection of psychiatric disease phenotypes that relate to treatment outcomes.
               
                  Methods
                  We focused on the mental state examination (MSE) in the patients’ discharge summaries as the key part of the psychiatric records. We prepared a sample of 150 text documents that we manually annotated for psychiatric attributes and symptoms. These documents were further divided into training and test sets. We designed and implemented a system to detect the psychiatric attributes automatically and linked the pathologically assessed attributes to AMDP terminology. This workflow uses a pre-trained neural network model, which is fine-tuned on the training set, and validated on the independent test set. Furthermore, a traditional NLP and rule-based component linked the recognized mentions to AMDP terminology. In a further step, we applied the system on a larger clinical dataset of 510 patients to extract their symptoms.
               
                  Results
                  The system identified the psychiatric attributes as well as their assessment (normal and pathological) and linked these entities to the AMDP terminology with an F1-score of 86% and 91% on an independent test set, respectively.
               
                  Conclusion
                  The development of the current text mining system and the results highlight the feasibility of text mining methods applied to MSE in electronic mental health care reports. Our findings pave the way for the secondary use of routine data in the field of mental health, facilitating further clinical data analyses.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2022.100511,Journal,Internet of Things (Netherlands),scopus,2022-05-01,sciencedirect,Smart mask – Wearable IoT solution for improved protection and personal health,https://api.elsevier.com/content/abstract/scopus_id/85125502352,"The use of face masks is an important way to fight the COVID-19 pandemic. In this paper, we envision the Smart Mask, an IoT supported platform and ecosystem aiming to prevent and control the spreading of COVID-19 and other respiratory viruses. The integration of sensing, materials, AI, wireless, IoT, and software will help the gathering of health data and health-related event detection in real time from the user as well as from their environment. In the larger scale, with the help of AI-based analysis for health data it is possible to predict and decrease medical costs with accurate diagnoses and treatment plans, where the comparison of personal data to large-scale public data enables drawing up a personal health trajectory, for example. Key research problems for smart respiratory protective equipment are identified in addition to future research directions. A Smart Mask prototype was developed with accompanying user application, backend and heath AI to study the concept.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ultrasmedbio.2022.01.015,Journal,Ultrasound in Medicine and Biology,scopus,2022-05-01,sciencedirect,Using Immersive Virtual Reality Simulation to Ensure Competence in Contrast-Enhanced Ultrasound,https://api.elsevier.com/content/abstract/scopus_id/85125498254,"Contrast-enhanced ultrasound (CEUS) is used in various medical specialties as a diagnostic imaging tool and for procedural guidance. Experience in the procedure is currently attained via supervised clinical practice that is challenged by patient availability and risks. Prior simulation-based training and subsequent assessment could improve and ensure competence before performance on patients, but no simulator currently exists. Immersive virtual reality (IVR) is a new promising simulation tool that can replicate complex interactions and environments that are unfeasible to achieve by traditional simulators. This study was aimed at developing an IVR simulation-based test for core CEUS competencies and gathering validity evidence for the test in accordance with Messick's framework. The test was developed by IVR software specialists and clinical experts in CEUS and medical education and imitated a CEUS examination of a patient with a focal liver lesion with emphasis on the pre-contrast preparations. Twenty-five medical doctors with varying CEUS experience were recruited as test participants, and their results were used to analyze test quality and to establish a pass/fail standard. The final test of 23 test items had good internal reliability (Cronbach's α = 0.85) and discriminatory abilities. The risks of false positives and negatives (9.1% and 23.6%, respectively) were acceptable for the test to be used as a certification tool prior to supervised clinical training in CEUS.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.phymed.2022.153962,Journal,Phytomedicine,scopus,2022-05-01,sciencedirect,Trillin inhibits myoblast differentiation via increasing autophagy,https://api.elsevier.com/content/abstract/scopus_id/85124483715,"Background
                  Trillin, an active ingredient in traditional Chinese medicine Trillium tschonoskii, is a potential small molecule compound candidate that affecting myoblast differentiation, which predicting by AI technology in our previous study. Autophagy modulating myoblast differentiation has also been studied. In addition, Trillin was shown to regulate mTOR signaling pathway, a highly conserved kinase important for autophagy regulation.
               
                  Purpose
                  In this research, we aim to clarify the effect and underlying mechanism of Trillin on myoblast differentiation.
               
                  Study design and methods
                  Using mice C2C12 cell line to establish a myoblast differentiation model in vitro, treated with different concentration and time of Trillin, to explore the effect and latent mechanism of Trillin on myoblast differentiation by qRT-PCR, Western Blot and other molecular biological technique.
               
                  Results
                  Results showed that C2C12 differentiation was significantly inhibited by Trillin in a dose-dependent manner. The expression of MyHC, MyOG and MyoD was decreased extremely significant after 10 μM Trillin treatment. Meanwhile, autophagy level was significantly elevated with the supplement of Trillin. And C2C12 differentiation was recovered after ATG7 knockdown. Mechanically, we found that the activity of AKT/mTOR declined during the inhibition of differentiation by Trillin.
               
                  Conclusion
                  Our findings suggested that Trillin attenuated C2C12 differentiation via increasing autophagy through AKT/mTOR signaling pathway. Taken together, we introduce a novel physiological function of Trillin in inhibiting skeletal muscle differentiation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apm.2022.01.008,Journal,Applied Mathematical Modelling,scopus,2022-05-01,sciencedirect,Deep learning for gas sensing using MOFs coated weakly-coupled microbeams,https://api.elsevier.com/content/abstract/scopus_id/85123830545,"Gas sensors have been increasingly employed in a wide range of applications such as air quality monitoring, disease diagnosis, potential leakage of exhaust gases in industrial facilities, and food quality control. We propose a novel MEMS gas sensor made of two mechanically-coupled microbeams coated with metal organic frameworks and subject to electric actuation. The objective is to exploit the dynamic features of the microstructure to simultaneously detect the presence of two gases, namely carbon dioxide (CO
                        
                           
                           2
                        
                     ) and methane (CH
                        
                           
                           4
                        
                     ), and estimate their concentrations. A nonlinear mathematical model of the gas sensor is developed and verified in the nonlinear operating regime against experiments reported in the literature. Deep learning methods are integrated with the sensor’s model to predict the gases’ characteristics from the dynamic features of the coupled microbeams. To do so, we generate a large set of dynamic responses of the sensor for varying operating conditions and use it to train deep neural networks to capture the nonlinear dependencies in the data. The results show evidence of high prediction accuracy in terms of gas type and concentration estimation. The optimal accuracy is achieved when all dynamic features of the two coupled beams are used as inputs. These include the first six natural frequencies, the RMS, minimum, and maximum values of the dynamic response of the coupled microbeams when actuated by a combination of DC and AC voltages near the veering point. Yet, the use of the dynamic features of one of the two microbeams is found to still predict the concentrations of both gases with a good accuracy level. As such, one can deploy one beam for actuation and the other beam for sensing both gases thanks to their mechanical coupling. We also compare our results to those obtained from classical statistical approaches, namely linear regression and support vector regression. The neural network based approach outperforms these two classical methods, especially when a limited number of data features is used as input.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.snb.2022.131476,Journal,Sensors and Actuators B: Chemical,scopus,2022-05-01,sciencedirect,"A hand-held, real-time, AI-assisted capillary convection PCR system for point-of-care diagnosis of African swine fever virus",https://api.elsevier.com/content/abstract/scopus_id/85123634788,"A hand-held, low-cost and real-time convection polymerase chain reaction (CPCR) system is developed for point-of-care diagnosis of African swine fever (ASF) virus. In CPCR amplification, the reagent is transferred to denaturation, annealing and extension stages of the reaction repeatedly due to thermal convection. Two different modes of fiber-based optical detection are compared, and it shows that the detection sensitivity, repeatability, and consistency can be significantly improved with bottom collection comparing to sidewall collection. Each capillary tube is illuminated by its own LED from the top through a common optical filter, and meanwhile, a camera equipped with another optical filter is adopted to detect the fluorescence signal from optical fibers. To handle the untypical real-time fluorescence curves of negative tests due to non-specific amplification, AI-based classification methods, for example, artificial neural network (ANN) is adopted to improve the detection specificity up to 97.50% comparing to 47.5% or 75.0% which is achieved with Ct-based method. A smartphone is adopted to run the AI algorithm and custom software, as well as to report an ASF event with the geographical information. Experimental results show that with the hand-held CPCR system, within 30 min, ASF viruses can be successfully detected with acceptable sensitivity and specificity.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2021.12.006,Journal,Future Generation Computer Systems,scopus,2022-05-01,sciencedirect,Identifying fraud in medical insurance based on blockchain and deep learning,https://api.elsevier.com/content/abstract/scopus_id/85122297088,"With the rapid growth of medical costs, the control of medical expenses has been becoming an important task of Health Insurance Department. Traditional medical insurance settlement is paid on a per-service basis, which leads to lots of unreasonable expenses. To cope with this problem, the single-disease payment mechanism has been widely used in recent years. However, the single-disease payment also has a risk of fraud. In this work, we propose a framework to identify fraud of medical insurance based on consortium blockchain and deep learning, which can recognize suspicious medical records automatically to ensure valid implementation on single-disease payment and lighten the work of medical insurance auditors. An explainable model BERT-LE is designed to evaluate the reasonability of ICD disease code for Medicare reimbursement by predicting the probability of a disease according to the chief complaint of a patient. We also put forward a storage and management process of medical records based on consortium blockchain to ensure the security, immutability, traceability, and auditability of the data. The experiments on two real datasets from two 3A hospitals demonstrate that the proposed solution can identify fraud effectively and greatly improve the efficiency in medical insurance reviews.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijpharm.2022.121604,Journal,International Journal of Pharmaceutics,scopus,2022-04-25,sciencedirect,Reliable stability prediction to manage research or marketed vaccines and pharmaceutical products. “Avoid any doubt for the end-user of vaccine compliance at time of administration”,https://api.elsevier.com/content/abstract/scopus_id/85126311953,"A major challenge for the pharmaceutical/vaccine industry is to anticipate and test/control product stability, regardless of the time/temperature profile of the product, from release to administration. Current empirical stability protocols performed to ensure product stability remain limited to the prediction of product stability in a thermal excursion (cold chain break) during their long-term storage. As recently recommended by the World Health Organization, mathematical models can be used for shelf-life and stability predictions. Therefore, various approaches have been published with good performance for simple chemical reactions. However, for biomolecules/vaccines, more complex reaction profiles require more complex models to predict their stability with a good level of confidence. This complexity constitutes a real scientific challenge because the number of model parameters increases with model complexity and need to be balanced with the limited number and quality of the available experimental data.
                  We have developed a dedicated method/software based on different vaccines/pharmaceutical case studies. This predictive method considers phenomenological models, five levels of model confidence assessment, predictive quality value and simulated designs of experiment to improve and define the limits within which the prediction models can be used, and to increase model/prediction confidence to the required regulatory and scientific levels. This artificial intelligence system should help to avoid any doubt of stability at time of vaccine injection.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.snb.2022.131415,Journal,Sensors and Actuators B: Chemical,scopus,2022-04-15,sciencedirect,Saliva-based COVID-19 detection: A rapid antigen test of SARS-CoV-2 nucleocapsid protein using an electrical-double-layer gated field-effect transistor-based biosensing system,https://api.elsevier.com/content/abstract/scopus_id/85123088695,"Facing the unstopped surges of COVID-19, an insufficient capacity of diagnostic testing jeopardizes the control of disease spread. Due to a centralized setting and a long turnaround, real-time reverse transcription polymerase chain reaction (real-time RT-PCR), the gold standard of viral detection, has fallen short in timely reflecting the epidemic status quo during an urgent outbreak. As such, a rapid screening tool is necessitated to help contain the spread of COVID-19 amid the countries where the vaccine implementations have not been widely deployed. In this work, we propose a saliva-based COVID-19 antigen test using the electrical double layer (EDL)-gated field-effect transistor-based biosensor (BioFET). The detection of SARS-CoV-2 nucleocapsid (N) protein is validated with limits of detection (LoDs) of 0.34 ng/mL (7.44 pM) and 0.14 ng/mL (2.96 pM) in 1× PBS and artificial saliva, respectively. The specificity is inspected with types of antigens, exhibiting low cross-reactivity among MERS-CoV, Influenza A virus, and Influenza B virus. This portable system is embedded with Bluetooth communication and user-friendly interfaces that are fully compatible with digital health, feasibly leading to an on-site turnaround, an effective management, and a proactive response taken by medical providers and frontline health workers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2022.100441,Journal,Patterns,scopus,2022-04-08,sciencedirect,Chemical-induced gene expression ranking and its application to pancreatic cancer drug repurposing,https://api.elsevier.com/content/abstract/scopus_id/85124879639,"Chemical-induced gene expression profiles provide critical information of chemicals in a biological system, thus offering new opportunities for drug discovery. Despite their success, large-scale analysis leveraging gene expressions is limited by time and cost. Although several methods for predicting gene expressions were proposed, they only focused on imputation and classification settings, which have limited applications to real-world scenarios of drug discovery. Therefore, a chemical-induced gene expression ranking (CIGER) framework is proposed to target a more realistic but more challenging setting in which overall rankings in gene expression profiles induced by de novo chemicals are predicted. The experimental results show that CIGER significantly outperforms existing methods in both ranking and classification metrics. Furthermore, a drug screening pipeline based on CIGER is proposed to identify potential treatments of drug-resistant pancreatic cancer. Our predictions have been validated by experiments, thereby showing the effectiveness of CIGER for phenotypic compound screening of precision medicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jadr.2022.100337,Journal,Journal of Affective Disorders Reports,scopus,2022-04-01,sciencedirect,"Investigation of physical activity, sleep, and mental health recovery in treatment resistant depression (TRD) patients receiving repetitive transcranial magnetic stimulation (rTMS) treatment",https://api.elsevier.com/content/abstract/scopus_id/85127011623,"Background
                  Repetitive transcranial magnetic stimulation (rTMS) is effective in treating depression; however, the effect on physical activity, sleep and recovery is unclear. This study investigated rTMS effect on physical activity and sleep through providing patients with a Fitbit and software apps; and reports the impact of rTMS on depression, anxiety and mental health recovery.
               
                  Methods
                  Study design was a pre and post data collection without a control, with twenty-four participants with treatment-resistant depression (TRD). Measures used were Fitbit activity and sleep data, and patient-rated Recovering Quality of Life (ReQoL-20), Patient Health Questionnaire (PHQ-9) and Generalised Anxiety Disorder (GAD-7).
               
                  Results
                  Response and remission rates were, respectively: 34.8% and 39% for PHQ-9; 34.8% and 47.8% for GAD-7. ReQoL-20 response and reliable improvement were 29.4% and 53%. PHQ-9, GAD-7 and ReQol-20 scores significantly improved, with large effect sizes. Analysis of Fitbit activity and sleep data yielded non-significant results. The Fitbit data machine learning model classified two levels of depression to 82% accuracy.
               
                  Limitations
                  rTMS treatment was open-label and adjunct to existing antidepressant medication. No control group. Female patients were overrepresented.
               
                  Conclusions
                  Improvements on the ReQoL-20 and aspects of sleep and activity indicate the positive impact of rTMS on the individual's real world functioning and quality of life. A wearable activity tracker can provide feedback to patients and clinicians on sleep, physical activity and depression levels. Further research could be undertaken through a sufficiently powered RCT comparing rTMS versus rTMS with use of a Fitbit, its software applications, and sleep and physical activity advice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00272-7,Journal,The Lancet Digital Health,scopus,2022-04-01,sciencedirect,Real-world evaluation of rapid and laboratory-free COVID-19 triage for emergency care: external validation and pilot deployment of artificial intelligence driven screening,https://api.elsevier.com/content/abstract/scopus_id/85126685401,"Background
                  Uncertainty in patients' COVID-19 status contributes to treatment delays, nosocomial transmission, and operational pressures in hospitals. However, the typical turnaround time for laboratory PCR remains 12–24 h and lateral flow devices (LFDs) have limited sensitivity. Previously, we have shown that artificial intelligence-driven triage (CURIAL-1.0) can provide rapid COVID-19 screening using clinical data routinely available within 1 h of arrival to hospital. Here, we aimed to improve the time from arrival to the emergency department to the availability of a result, do external and prospective validation, and deploy a novel laboratory-free screening tool in a UK emergency department.
               
                  Methods
                  We optimised our previous model, removing less informative predictors to improve generalisability and speed, developing the CURIAL-Lab model with vital signs and readily available blood tests (full blood count [FBC]; urea, creatinine, and electrolytes; liver function tests; and C-reactive protein) and the CURIAL-Rapide model with vital signs and FBC alone. Models were validated externally for emergency admissions to University Hospitals Birmingham, Bedfordshire Hospitals, and Portsmouth Hospitals University National Health Service (NHS) trusts, and prospectively at Oxford University Hospitals, by comparison with PCR testing. Next, we compared model performance directly against LFDs and evaluated a combined pathway that triaged patients who had either a positive CURIAL model result or a positive LFD to a COVID-19-suspected clinical area. Lastly, we deployed CURIAL-Rapide alongside an approved point-of-care FBC analyser to provide laboratory-free COVID-19 screening at the John Radcliffe Hospital (Oxford, UK). Our primary improvement outcome was time-to-result, and our performance measures were sensitivity, specificity, positive and negative predictive values, and area under receiver operating characteristic curve (AUROC).
               
                  Findings
                  72 223 patients met eligibility criteria across the four validating hospital groups, in a total validation period spanning Dec 1, 2019, to March 31, 2021. CURIAL-Lab and CURIAL-Rapide performed consistently across trusts (AUROC range 0·858–0·881, 95% CI 0·838–0·912, for CURIAL-Lab and 0·836–0·854, 0·814–0·889, for CURIAL-Rapide), achieving highest sensitivity at Portsmouth Hospitals (84·1%, Wilson's 95% CI 82·5–85·7, for CURIAL-Lab and 83·5%, 81·8–85·1, for CURIAL-Rapide) at specificities of 71·3% (70·9–71·8) for CURIAL-Lab and 63·6% (63·1–64·1) for CURIAL-Rapide. When combined with LFDs, model predictions improved triage sensitivity from 56·9% (51·7–62·0) for LFDs alone to 85·6% with CURIAL-Lab (81·6–88·9; AUROC 0·925) and 88·2% with CURIAL-Rapide (84·4–91·1; AUROC 0·919), thereby reducing missed COVID-19 cases by 65% with CURIAL-Lab and 72% with CURIAL-Rapide. For the prospective deployment of CURIAL-Rapide, 520 patients were enrolled for point-of-care FBC analysis between Feb 18 and May 10, 2021, of whom 436 received confirmatory PCR testing and ten (2·3%) tested positive. Median time from arrival to a CURIAL-Rapide result was 45 min (IQR 32–64), 16 min (26·3%) sooner than with LFDs (61 min, 37–99; log-rank p<0·0001), and 6 h 52 min (90·2%) sooner than with PCR (7 h 37 min, 6 h 5 min to 15 h 39 min; p<0·0001). Classification performance was high, with sensitivity of 87·5% (95% CI 52·9–97·8), specificity of 85·4% (81·3–88·7), and negative predictive value of 99·7% (98·2–99·9). CURIAL-Rapide correctly excluded infection for 31 (58·5%) of 53 patients who were triaged by a physician to a COVID-19-suspected area but went on to test negative by PCR.
               
                  Interpretation
                  Our findings show the generalisability, performance, and real-world operational benefits of artificial intelligence-driven screening for COVID-19 over standard-of-care in emergency departments. CURIAL-Rapide provided rapid, laboratory-free screening when used with near-patient FBC analysis, and was able to reduce the number of patients who tested negative for COVID-19 but were triaged to COVID-19-suspected areas.
               
                  Funding
                  The Wellcome Trust, University of Oxford Medical and Life Sciences Translational Fund.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jksus.2022.101898,Journal,Journal of King Saud University - Science,scopus,2022-04-01,sciencedirect,Efficient multimodal deep-learning-based COVID-19 diagnostic system for noisy and corrupted images,https://api.elsevier.com/content/abstract/scopus_id/85125392835,"Introduction
                  In humanity’s ongoing fight against its common enemy of COVID-19, researchers have been relentless in finding efficient technologies to support mitigation, diagnosis, management, contact tracing, and ultimately vaccination.
               
                  Objectives
                  Engineers and computer scientists have deployed the potent properties of deep learning models (DLMs) in COVID-19 detection and diagnosis. However, publicly available datasets are often adulterated during collation, transmission, or storage. Meanwhile, inadequate, and corrupted data are known to impact the learnability and efficiency of DLMs.
               
                  Methods
                  This study focuses on enhancing previous efforts via two multimodal diagnostic systems to extract required features for COVID-19 detection using adulterated chest X-ray images. Our proposed DLM consists of a hierarchy of convolutional and pooling layers that are combined to support efficient COVID-19 detection using chest X-ray images. Additionally, a batch normalization layer is used to curtail overfitting that usually arises from the convolution and pooling (CP) layers.
               
                  Results
                  In addition to matching the performance of standard techniques reported in the literature, our proposed diagnostic systems attain an average accuracy of 98% in the detection of normal, COVID-19, and viral pneumonia cases using corrupted and noisy images.
               
                  Conclusions
                  Such robustness is crucial for real-world applications where data is usually unavailable, corrupted, or adulterated.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2022.104743,Journal,Engineering Applications of Artificial Intelligence,scopus,2022-04-01,sciencedirect,"A comprehensive survey of clustering algorithms: State-of-the-art machine learning applications, taxonomy, challenges, and future research prospects",https://api.elsevier.com/content/abstract/scopus_id/85125128146,"Clustering is an essential tool in data mining research and applications. It is the subject of active research in many fields of study, such as computer science, data science, statistics, pattern recognition, artificial intelligence, and machine learning. Several clustering techniques have been proposed and implemented, and most of them successfully find excellent quality or optimal clustering results in the domains mentioned earlier. However, there has been a gradual shift in the choice of clustering methods among domain experts and practitioners alike, which is precipitated by the fact that most traditional clustering algorithms still depend on the number of clusters provided a priori. These conventional clustering algorithms cannot effectively handle real-world data clustering analysis problems where the number of clusters in data objects cannot be easily identified. Also, they cannot effectively manage problems where the optimal number of clusters for a high-dimensional dataset cannot be easily determined. Therefore, there is a need for improved, flexible, and efficient clustering techniques. Recently, a variety of efficient clustering algorithms have been proposed in the literature, and these algorithms produced good results when evaluated on real-world clustering problems. This study presents an up-to-date systematic and comprehensive review of traditional and state-of-the-art clustering techniques for different domains. This survey considers clustering from a more practical perspective. It shows the outstanding role of clustering in various disciplines, such as education, marketing, medicine, biology, and bioinformatics. It also discusses the application of clustering to different fields attracting intensive efforts among the scientific community, such as big data, artificial intelligence, and robotics. This survey paper will be beneficial for both practitioners and researchers. It will serve as a good reference point for researchers and practitioners to design improved and efficient state-of-the-art clustering algorithms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pnucene.2022.104143,Journal,Progress in Nuclear Energy,scopus,2022-04-01,sciencedirect,Predictions of component Remaining Useful Lifetime Using Bayesian Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85124881509,"The Machine Prognostics and Health Management (PHM) are concerned with the prediction of the Remaining Useful Lifetime (RUL) of assets. Accurate real-time RUL predictions are necessary when developing an efficient predictive maintenance (PdM) framework for equipment health assessment. If correctly implemented, a PdM framework can maximize the interval between maintenance operations, minimize the cost and number of unscheduled maintenance operations, and improve overall availability of the large facilities like nuclear power plants (NPPs). This is especially important for nuclear power facilities to maximize capacity factor and reliability. In this work, we propose a data-driven approach to make predictions of both the RUL and its uncertainty using a Bayesian Neural Network (BNN). The BNN utilizes the Bayes by backprop algorithm with variational inference to estimate the posterior distribution for each trainable parameter so that the model output is also a PDF from which one can draw the mean prediction and the associated uncertainty. To learn the correlations between various time-series sensor data measurements, a time window approach is implemented with a two-stage noise filtering process for incoming sensor measurements to enhance the feature extraction and overall model performance. As a proof of concept, the NASA Commercial Modular Aero Propulsion System Simulation (C-MAPPS) datasets are utilized to assess the performance of the BNN model. The modeled system can be treated as a surrogate for turbine generators used in NPPs due to the similar mode of operation, degradation, and measurable variables. Comparisons against other state-of-the-art algorithms on the same datasets indicate that the BNN model can not only make predictions with comparable level of accuracy, but also offer the benefit of estimating uncertainty associated with the prediction. This additional uncertainty, which can be continuously updated as more measurement data are collected, can facilitate the decision-making process with a quantifiable confidence level within a PdM framework. Additional advantages of the BNN are showcased, such as providing component maintenance ranges and model executing frequency, with an example of how the BNN estimated uncertainty can be used to support the continuous predictive maintenance. A PdM framework based on a BNN will allow for utilities to make more informed decisions on the optimal time for maintenance so that the loss of revenue can be minimized from planned and unplanned maintenance outages.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.acap.2021.12.013,Journal,Academic Pediatrics,scopus,2022-04-01,sciencedirect,Implementation and Evaluation of an Artificial Intelligence Driven Simulation to Improve Resident Communication With Primary Care Providers,https://api.elsevier.com/content/abstract/scopus_id/85124645011,"Our artificial intelligence platform facilitated, evaluated, and provided real-time feedback on a standardized, simulated conversation. Learners evaluated the experience as equally effective to traditional education modalities and reported that it reinforced key communication elements, which would impact their future communication.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2022.106682,Journal,Computer Methods and Programs in Biomedicine,scopus,2022-04-01,sciencedirect,Physiological responses to pain in cancer patients: A systematic review,https://api.elsevier.com/content/abstract/scopus_id/85124477290,"Background and objective
                  Pain is one of the most debilitating symptoms in persons with cancer. Still, its assessment is often neglected both by patients and healthcare professionals. There is increasing interest in conducting pain assessment and monitoring via physiological signals that promise to overcome the limitations of state-of-the-art pain assessment tools. This systematic review aims to evaluate existing experimental studies to identify the most promising methods and results for objectively quantifying cancer patients’ pain experience.
               
                  Methods
                  Four electronic databases (Pubmed, Compendex, Scopus, Web of Science) were systematically searched for articles published up to October 2020.
               
                  Results
                  Fourteen studies (528 participants) were included in the review. The selected studies analyzed seven physiological signals. Blood pressure and ECG were the most used signals. Sixteen physiological parameters showed significant changes in association with pain. The studies were fairly consistent in stating that heart rate, the low-frequency to high-frequency component ratio (LF/HF), and systolic blood pressure positively correlate with the pain.
               
                  Conclusions
                  Current evidence supports the hypothesis that physiological signals can help objectively quantify, at least in part, cancer patients’ pain experience. While there is much more to be done to obtain a reliable pain assessment method, this review takes an essential first step by highlighting issues that should be taken into account in future research: use of a wearable device for pervasive recording in a real-world context, implementation of a big-data approach possibly supported by AI, including multiple stratification factors (e.g., cancer site and stage, source of pain, demographic and psychosocial data), and better-defined recording procedures. Improved methods and algorithms could then become valuable add-ons in taking charge of cancer patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2022.106655,Journal,Computer Methods and Programs in Biomedicine,scopus,2022-04-01,sciencedirect,A real-time integrated framework to support clinical decision making for covid-19 patients,https://api.elsevier.com/content/abstract/scopus_id/85124421101,"Background
                  The COVID-19 pandemic affected healthcare systems worldwide. Predictive models developed by Artificial Intelligence (AI) and based on timely, centralized and standardized real world patient data could improve management of COVID-19 to achieve better clinical outcomes. The objectives of this manuscript are to describe the structure and technologies used to construct a COVID-19 Data Mart architecture and to present how a large hospital has tackled the challenge of supporting daily management of COVID-19 pandemic emergency, by creating a strong retrospective knowledge base, a real time environment and integrated information dashboard for daily practice and early identification of critical condition at patient level. This framework is also used as an informative, continuously enriched data lake, which is a base for several on-going predictive studies.
               
                  Methods
                  The information technology framework for clinical practice and research was described. It was developed using SAS Institute software analytics tool and SAS® Vyia® environment and Open-Source environment R ® and Python ® for fast prototyping and modeling. The included variables and the source extraction procedures were presented.
               
                  Results
                  The Data Mart covers a retrospective cohort of 5528 patients with SARS-CoV-2 infection. People who died were older, had more comorbidities, reported more frequently dyspnea at onset, had higher d-dimer, C-reactive protein and urea nitrogen. The dashboard was developed to support the management of COVID-19 patients at three levels: hospital, single ward and individual care level.
               
                  Interpretation
                  The COVID-19 Data Mart based on integration of a large collection of clinical data and an AI-based integrated framework has been developed, based on a set of automated procedures for data mining and retrieval, transformation and integration, and has been embedded in the clinical practice to help managing daily care. Benefits from the availability of a Data Mart include the opportunity to build predictive models with a machine learning approach to identify undescribed clinical phenotypes and to foster hospital networks. A real-time updated dashboard built from the Data Mart may represent a valid tool for a better knowledge of epidemiological and clinical features of COVID-19, especially when multiple waves are observed, as well as for epidemic and pandemic events of the same nature (e. g. with critical clinical conditions leading to severe pulmonary inflammation). Therefore, we believe the approach presented in this paper may find several applications in comparable situations even at region or state levels. Finally, models predicting the course of future waves or new pandemics could largely benefit from network of DataMarts.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2022.104708,Journal,International Journal of Medical Informatics,scopus,2022-04-01,sciencedirect,Pharmaceutical algorithms set in a real time clinical decision support targeting high-alert medications applied to pharmaceutical analysis,https://api.elsevier.com/content/abstract/scopus_id/85124384917,"Background
                  Pharmaceutical analysis of the prescription has to prop up the quality of patients' medication management in a context of medication’s risk acculturation. But this activity remains highly variable. Medication-related clinical decision support may succeed in reducing adverse drug events and healthcare costs.
               
                  Purpose
                  This study aims to present AVICENNE as a real time medication-related clinical decision support (rt-CDS) applied to pharmaceutical analysis and its ability to detect Drug related problems (DRP) consecutively resolved by pharmacists.
                  Basic procedures
                  A Medication-related rt-CDS is created by integrating the software PharmaClass® (Keenturtle), 5 health data streams on the patient and Pharmaceutical algorithms (PA). PA are created by modeling the pharmaceutical experiment about DRP and the thread of their criticality. They are partially encoded as computerized rules in Pharmaclass® allowing alerts’ issue.
                  An observational prospective study is conducted during 9-months among 1000 beds in 2 health facilities. The first step is to identify alerts as DRP; their resolution follows with clear guidelines worked out for the pharmaceutical analysis. A basis on predictive positive values (PPV) of the PA is being built today helping to know the performance of DRP detection and resolution.
                  Main findings
                  71 PA are encoded as rules into Pharmaclass®: 40 targeted serious adverse drug events. 1508 alerts are analyzed by pharmacists. Among them 921 DRPs were characterized and 540 pharmaceutical interventions transmitted of which 219 were accepted by prescribers. Three PPV are defined depending on software, pharmacist and patient.
                  Principal conclusion
                  Clinical pharmacy societies should host, share and update a national corpus of PA and exploit its educational interest.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103663,Journal,Sustainable Cities and Society,scopus,2022-04-01,sciencedirect,"Federated learning enabled digital twins for smart cities: Concepts, recent advances, and future directions",https://api.elsevier.com/content/abstract/scopus_id/85123031989,"Recent advances in Artificial Intelligence (AI) and the Internet of Things (IoT) have facilitated continuous improvement in smart city based applications such as smart healthcare, transportation, and environmental management. Digital Twin (DT) is an AI-based virtual replica of the real-world physical entity. DTs have been successfully adopted in manufacturing and industrial sectors, they are however still at the early stage in smart city based applications. The major reason for this lag is the lack of trust and privacy issues in sharing sensitive data. Federated Learning (FL) is a technology that could be integrated along with DT to ensure privacy preservation and trustworthiness. This paper focuses on the integration of these two promising technologies for adoption in real-time and life-critical scenarios, as well as for ease of governance in smart city based applications. We present an extensive survey on the various smart city based applications of FL models in DTs. Based on the study, some prominent challenges and future directions are presented for better FL–DT integration in future applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mee.2022.111750,Journal,Microelectronic Engineering,scopus,2022-03-15,sciencedirect,Flexible pressure sensor with a wide pressure measurement range and an agile response based on multiscale carbon fibers/carbon nanotubes composite,https://api.elsevier.com/content/abstract/scopus_id/85125486815,"As an important branch of wearable electronics, flexible pressure sensors have aroused extensive concern owing to their wide range of applications, such as human health monitoring, human–machine interfaces, and artificial intelligence. Therefore, higher requirements are put forward for the dominating performances of sensitivity, pressure measurement range and response time about flexible pressure sensors. Here, we present a flexible piezoresistive pressure sensor (FPPS) based on carbon fibers (CFs)/carbon nanotubes (CNTs)-polydimethylsiloxane (PDMS) composite and interdigital electrode, which displays a wide measurement range of stress and an agile response at loading and unloading forces. Due to the cooperating advantages of the multiscale carbon fillers, the microstructures on the surface of the piezoresistive film and the interdigital electrode, the FPPS reveals a wide measurement range (from 0 kPa to 185.9 kPa) and a high sensitivity (2.02 kPa‐1 at pressures between 36 Pa and 50.2 kPa). Meanwhile, owing to the carefully designed trilateral double-sided adhesive structure, the FPPS exhibits an agile response (response time of 43 ms) and a stable output (test time of 9000 s). Moreover, the FPPS is capable of identifying clapping and trampling motions, demonstrating its effectiveness as a flexible sensing unit. The novel pressure sensor was integrated with additional software and hardware to realize a real-time pressure acquisition and display system, providing a potential use of the device in an intelligent industry application.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ces.2021.117373,Journal,Chemical Engineering Science,scopus,2022-03-15,sciencedirect,An explainable artificial intelligence based approach for interpretation of fault classification results from deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85122261466,"Process monitoring is crucial to ensure operational reliability and to prevent industrial accidents. Data-driven methods have become the preferred approach for fault detection and diagnosis. Specifically, deep learning algorithms such as Deep Neural Networks (DNNs) show good potential even in complex processes. A key shortcoming of DNNs is the difficulty in interpreting their classification result. Emerging approaches from explainable Artificial Intelligence (XAI) seek to address this shortcoming. This paper proposes a method based on the Shapley value framework and its implementation using integrated gradients to identify those variables which lead a DNN to classify an input as a fault. The method estimates the marginal contribution of each variable to the DNN, averaged over the path from the baseline (in this case, the process’ normal state) to the current sample. We illustrate the resulting variable attribution using a numerical example and the benchmark Tennessee Eastman process. Our results show that the proposed methodology provides accurate, sample-specific explanations of the DNN’s prediction. These can be used by the offline model developer to improve the DNN if necessary. It can also be used by the plant operator in real-time to understand the black-box DNN’s predictions and decide on operational strategies.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2021.113902,Journal,Biosensors and Bioelectronics,scopus,2022-03-15,sciencedirect,"A sandwich-based evanescent wave fluorescent biosensor for simple, real-time exosome detection<sup>†</sup>",https://api.elsevier.com/content/abstract/scopus_id/85121694226,"Exosomes are regarded as a promising biomarker for the noninvasive diagnosis and treatment of diseases. The value of exosomes for medical research has promoted the search for a fast, efficient, and sensitive detection method. This study reported a sandwich-based evanescent wave fluorescent biosensor (S-EWFB) for exosome detection. A two-step strategy was implemented to take advantages of the simple binding of fluorescent probes with exosomes via the hydrophobic interaction between the cholesteryl and phospholipid bilayer membrane, as well as real-time detection on an evanescent wave liquid-solid interface based on CD63 aptamer-specific capture to form an exosome@fluorescence probe/aptamer sandwich structure. The one-to-many connection between exosomes and signal molecules and the aptamer-modified evanescent wave optical fiber detection platform reduced the detection limit of exosomes to 7.66 particles/mL, with a linear range of 47.5–4.75 × 106 particles/mL. The entire detection process was simple, rapid, and real-time and lasted about 1 h while requiring no separation and purification. Additionally, this platform showed excellent surface regeneration capability and exhibited good performance during the analysis of tumor and non-tumor-derived exosomes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2022.100440,Journal,Patterns,scopus,2022-03-11,sciencedirect,DAISM-DNN<sup>XMBD</sup>: Highly accurate cell type proportion estimation with in silico data augmentation and deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85124889392,"Understanding the immune cell abundance of cancer and other disease-related tissues has an important role in guiding disease treatments. Computational cell type proportion estimation methods have been previously developed to derive such information from bulk RNA sequencing data. Unfortunately, our results show that the performance of these methods can be seriously plagued by the mismatch between training data and real-world data. To tackle this issue, we propose the DAISM-DNNXMBD (XMBD: Xiamen Big Data, a biomedical open software initiative in the National Institute for Data Science in Health and Medicine, Xiamen University, China.) (denoted as DAISM-DNN) pipeline that trains a deep neural network (DNN) with dataset-specific training data populated from a certain amount of calibrated samples using DAISM, a novel data augmentation method with an in silico mixing strategy. The evaluation results demonstrate that the DAISM-DNN pipeline outperforms other existing methods consistently and substantially for all the cell types under evaluation in real-world datasets.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijhydene.2022.01.145,Journal,International Journal of Hydrogen Energy,scopus,2022-03-05,sciencedirect,Real-time data-driven fault diagnosis of proton exchange membrane fuel cell system based on binary encoding convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85124312531,"The performance of proton exchange Membrane fuel cell (PEMFC) fault diagnosis system plays an important role in normal operation of PEMFC. Therefore, a new fault diagnosis algorithm based on binary matrix encoding neural network called BinE-CNN is proposed. In BinE-CNN, high-dimensional features are extracted through binary encoding, and the feature maps are transferred to a convolutional neural network (CNN) to realize seven-category fault classification. For development of BinE-CNN, a PEMFC model is modeled to generate simulative datasets. Simulative test precision and Frames per second (FPS) of BinE-CNN have reached respectively 0.973 and 999.8 (better than support vector machines (SVM), long short-term memory neural network (LSTM), etc.). In experimental verification section, fault datasets are collected during bench test. After that, BinE-CNN is deployed on vehicle control unit (VCU) to verify its engineering value (real-time and precision). The result meet both requirements, with time cost of 96.15 ms and precision of 0.931.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eclinm.2022.101320,Journal,eClinicalMedicine,scopus,2022-03-01,sciencedirect,Economic costs of childhood stunting to the private sector in low- and middle-income countries,https://api.elsevier.com/content/abstract/scopus_id/85126568488,"Background
                  Stunting during childhood has long-term consequences on human capital, including decreased physical growth, and lower educational attainment, cognition, workforce productivity and wages. Previous research has quantified the costs of stunting to national economies, however, beyond a few single-country datasets there has been a limited number of which have used diverse datasets and have had a dedicated focus on the private sector, which employs nearly 90% of the workforce in many low- and middle-income countries (LMICs). We aimed to examine (i) the impact of childhood stunting on income loss of private sector workforce in LMICs; (ii) to quantify losses in sales to private firms in LMICs due to childhood stunting; and (iii) to estimate potential gains (benefit-cost ratios) if stunting levels are reduced in select high prevalence countries.
               
                  Methods
                  This multiple-methods study engaged multi-disciplinary technical advisers, executed several literature reviews, used innovative statistical methods, and implemented health and labor economic models. We analyzed data from seven longitudinal datasets (up to 30+ years of follow-up; 1982–2016; Peru, Ethiopia, India, Vietnam, Philippines, Tanzania, Brazil), 108 private firm datasets (spanning 2008–2020), and many global datasets including Joint Malnutrition Estimates, and World Development Indicators to produce estimates for 120+ LMICs (with estimates up to 2021). We studied the impact of childhood stunting on adult cognition, education, and height as pathways to wages/productivity in adulthood. We employed cloud-based artificial intelligence (AI) platforms, and conducted comparative analyses using three analytic approaches: traditional frequentist statistics, Bayesian inferential statistics and machine learning. We employed labour and health economic models to estimate wage losses to the private sector worker and firm revenue losses due to stunting. We also estimated benefit-cost ratios for countries investing in nutrition-specific interventions to prevent stunting.
               
                  Findings
                  Across 95 LMICs, childhood stunting costs the private sector at least US$135.4 billion in sales annually. Firms from countries in Latin America and the Caribbean and East Asia and Pacific regions had the greatest losses. Total sales losses to the private sector accumulated to 0.01% to 1.2% of national GDP across countries. Sectors most affected by childhood stunting were manufacturing (non-metallic mineral, fabricated metal, other), garments and food sectors. Sales losses were highest for larger sized private firms. Across regions (representing 123 LMICs), US$700 million (Middle East and North Africa) to US$16.5 billion (East Asia and Pacific) monthly income was lost among private sector workers. Investing in stunting reduction interventions yields gains from US$2 to US$81 per $1 invested annually (or 100% to 8000% across countries). Across sectors, the highest returns were in elementary occupations (US$46) and the lowest were among agricultural workers (US$8). By gender, women incurred a higher income penalty from childhood stunting and earned less than men; due to their relatively higher earnings, the returns for investing in stunting reduction were consistently higher for men across most countries studied.
               
                  Interpretation
                  Childhood stunting costs the private sector in LMICs billions of dollars in sales and earnings for the workforce annually. Returns to nutrition interventions show that there is an economic case to be made for investing in childhood nutrition, alongside a moral one for both the public and private sector. This research could be used to motivate strong public-private sector partnerships to invest in childhood undernutrition for benefits in the short and long-term.
               
                  Funding
                  The Power of Nutrition (UK); Patrick J McGovern Foundation (USA).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2022.104009,Journal,Journal of Biomedical Informatics,scopus,2022-03-01,sciencedirect,Real-time data analysis in health monitoring systems: A comprehensive systematic literature review,https://api.elsevier.com/content/abstract/scopus_id/85125883978,"Health monitoring systems (HMSs) capture physiological measurements through biosensors (sensing), obtain significant properties and measures from the output signal (perceiving), use algorithms for data analysis (reasoning), and trigger warnings or alarms (acting) when an emergency occurs. These systems have the potential to enhance health care delivery in different application domains, showing promising benefits for health diagnosis, early symptom detection, disease prediction, among others. However, the implementation of HMS presents challenges for sensing, perceiving, reasoning, and acting based on monitored data, mainly when data processing should be performed in real time. Thus, the quality of these diagnoses relies heavily on the data and data analysis methods applied. Data mining techniques have been broadly investigated in health systems; however, it is not clear what real-time data analysis techniques are best suited for each context. This work carries out a search in five scientific electronic databases to identify recent studies that investigated HMS using real-time data analysis techniques. Thirty-six research studies were selected after screening 2,822 works. Applied data analysis methods, application domains, utilized sensors, physiological parameters, extracted features, claimed benefits, limitations, datasets used, and published results were described, compared and analyzed. The findings indicate that machine learning methods are trending in such studies. There is no universal solution for all health domains; however, support vector machines are a predominant method. Among the application domains, cardiovascular disease is the most investigated. Most reviewed studies reported improvements in performing data mining tasks or operational modes of solutions. Although studies tested algorithms and presented promising results, those are particular for each experiment. This review gives a comprehensive overview of HMS real-time data analysis and points to directions for future research.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chaos.2022.111886,Journal,"Chaos, Solitons and Fractals",scopus,2022-03-01,sciencedirect,Automated identification of inter-ictal discharges using residual deep learning neural network amidst of various artefacts,https://api.elsevier.com/content/abstract/scopus_id/85125865137,"Background
                  Visual analysis to identify inter-ictal activity in scalp EEG to support the diagnosis of epilepsy is a challenging task, which is embarked on by an experienced neurologist. Inter-Ictal state is a phase between convolutions (seizures) that are a feature of epilepsy disorder. The objective of this work is to automate the process of identification of inter-ictal activity and to distinguish it from the activity of a controlled patient with and without presence of artifacts
               
                  Methods
                  In this work, we have used two-second scalp EEG data. The novel data is collected from Max Super Speciality Hospital, Saket, New Delhi. Expert neurologists mark the data according to the exclusion and inclusion criterion presented and approved by the scientific and ethical committee. Under our architecture, we have first divided the EEG data collected from the patients into two-second segments. The two-second EEG signal is converted to scalograms used as input to fourteen layer novel Residual neural network architecture. For comparison we have created fourteen layer convolution neural network and sixteen layer model where CNN and LSTM models are stacked. For this work we have worked on two cases, the first group is a comparison between intect-ictal and controlled, while the second group is a classification between inte-ictal vs (different artifacts and controlled).
               
                  Results
                  We have evaluated our model based on six parameters Accuracy, Sensitivity, Specificity, Precision, Recall, and AUC. Under this architecture, we have divided the complete data set into two parts 80% of data is training data on which k- fold validation is being applied. The value of k is set to 10. The rest, 20%, is used as testing data on which the performance of the model is evaluated. The developed model (RNN) has provided outstanding results in identifying the inter-ictal activity, detecting test dataset with 97.98% accuracy, and has achieved an AUC value of .9974 without the presence of artifacts accuracy of 91.42% and AUC value of 0.9698, has been acheived.
               
                  Conclusion
                  Residual neural network in its two-dimensional implementation with fourteen layers has outperformed the two other models developed on similar lines. This research suggests that the proposed architecture has the potential to be utilized in the real-time clinical setup.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2022.103996,Journal,Journal of Biomedical Informatics,scopus,2022-03-01,sciencedirect,Evaluating pointwise reliability of machine learning prediction,https://api.elsevier.com/content/abstract/scopus_id/85123373748,"Interest in Machine Learning applications to tackle clinical and biological problems is increasing. This is driven by promising results reported in many research papers, the increasing number of AI-based software products, and by the general interest in Artificial Intelligence to solve complex problems. It is therefore of importance to improve the quality of machine learning output and add safeguards to support their adoption. In addition to regulatory and logistical strategies, a crucial aspect is to detect when a Machine Learning model is not able to generalize to new unseen instances, which may originate from a population distant to that of the training population or from an under-represented subpopulation. As a result, the prediction of the machine learning model for these instances may be often wrong, given that the model is applied outside its “reliable” space of work, leading to a decreasing trust of the final users, such as clinicians. For this reason, when a model is deployed in practice, it would be important to advise users when the model’s predictions may be unreliable, especially in high-stakes applications, including those in healthcare. Yet, reliability assessment of each machine learning prediction is still poorly addressed.
                  Here, we review approaches that can support the identification of unreliable predictions, we harmonize the notation and terminology of relevant concepts, and we highlight and extend possible interrelationships and overlap among concepts. We then demonstrate, on simulated and real data for ICU in-hospital death prediction, a possible integrative framework for the identification of reliable and unreliable predictions. To do so, our proposed approach implements two complementary principles, namely the density principle and the local fit principle. The density principle verifies that the instance we want to evaluate is similar to the training set. The local fit principle verifies that the trained model performs well on training subsets that are more similar to the instance under evaluation. Our work can contribute to consolidating work in machine learning especially in medicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.105179,Journal,Computers in Biology and Medicine,scopus,2022-03-01,sciencedirect,An efficient multilevel thresholding image segmentation method based on the slime mould algorithm with bee foraging mechanism: A real case with lupus nephritis images,https://api.elsevier.com/content/abstract/scopus_id/85123196699,"To improve the diagnosis of Lupus Nephritis (LN), a multilevel LN image segmentation method is developed in this paper based on an improved slime mould algorithm. The search of the optimal threshold set is key to multilevel thresholding image segmentation (MLTIS). It is well known that swarm-based methods are more efficient than the traditional methods because of the high complexity in finding the optimal threshold, especially when performing image partitioning at high threshold levels. However, swarm-based methods tend to obtain the poor quality of the found segmentation thresholds and fall into local optima during the process of segmentation. Therefore, this paper proposes an ASMA-based MLTIS approach by combining an improved slime mould algorithm (ASMA),  where ASMA is mainly implemented by introducing the position update mechanism of the artificial bee colony (ABC) into the SMA. To prove the superiority of the ASMA-based MLTIS method, we first conducted a comparison experiment between ASMA and 11 peers using 30 test functions. The experimental results fully demonstrate that ASMA can obtain high-quality solutions and almost does not suffer from premature convergence. Moreover, using standard images and LN images, we compared the ASMA-based MLTIS method with other peers and evaluated the segmentation results using three evaluation indicators called PSNR, SSIM, and FSIM. The proposed ASMA can be an excellent swarm intelligence optimization method that can maintain a delicate balance during the segmentation process of LN images, and thus the ASMA-based MLTIS method has great potential to be used as an image segmentation method for LN images. The lastest updates for the SMA algorithm are available in https://aliasgharheidari.com/SMA.html.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.smhl.2021.100249,Journal,Smart Health,scopus,2022-03-01,sciencedirect,A pilot study towards a smart-health framework to collect and analyze biomarkers with low-cost and flexible wearables,https://api.elsevier.com/content/abstract/scopus_id/85120868737,"Artificial intelligence-enabled applications on edge devices have the potential to revolutionize disease detection and monitoring with smart health (sHealth) applications. The major challenges are user-friendly and flexible sensors for seamless collection of physiological data for long hours, online and on-device processing of sensitive medical data to facilitate privacy protection, reliable extraction of disease-related biomarkers, and implementation of lightweight artificially intelligent algorithms for inference at the edge without degrading the system performance. In this pilot project, we conducted a yearlong field study with 9 participants conducting 480 data collection sessions in the “living lab” environment. We used smartphones as the edge computing device and implemented pre-trained machine learning algorithms in the smartphone app for computing disease-related Events-of-Interest (EoI). We considered real-time data processing on the smartphone itself without sharing raw data with the cloud or any other computing facility to minimize privacy concerns, and network bandwidth requirements. We used a commercial smart band and a custom-designed zero-power inkjet-printed sensor for physiological sensing and capturing health biomarkers such as heart rate variability (HRV) and core body temperature. The extracted HRV feature values are within the 95% confidence interval of normative values. On top of that, the extracted HRV shows some informative trends i.e. hammock pattern for healthy subjects which may be helpful in subsequent research studies. Moreover, we used core body temperature with user-reported outcomes for estimating flu-related symptoms severity and visualizing the spatiotemporal trend in a cloud-server to facilitate personalized as well as community-wide health monitoring. Inference at the edge provided a data reduction of 3 order while the runtime latency, power consumption, memory requirement, and storage size of the smartphone app were 500 ms, 51.90 mAH, 9.4 MB, and 2.4 MB, respectively. Our developed framework of sHealth enables automated community-wide monitoring of symptoms severity in addition to personalized monitoring which paves the way for early monitoring of a disease outbreak for a smart and connected community.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2021.103436,Journal,Biomedical Signal Processing and Control,scopus,2022-03-01,sciencedirect,A physiological signal compression approach using optimized Spindle Convolutional Auto-encoder in mHealth applications,https://api.elsevier.com/content/abstract/scopus_id/85120708188,"Background and Objectives
                  The COVID-19 pandemic manifested the need of developing robust digital platforms for facilitating healthcare services such as consultancy, clinical therapies, real time remote monitoring, early diagnosis and future predictions. Innovations made using technologies such as Internet of Things (IoT), edge computing, cloud computing and artificial intelligence are helping address this crisis. The urge for remote monitoring, symptom analysis and early detection of diseases lead to tremendous increase in the deployment of wearable sensor devices. They facilitate seamless gathering of physiological data such as electrocardiogram (ECG) signals, respiration traces (RESP), galvanic skin response (GSR), pulse rate, body temperature, photoplethysmograms (PPG), oxygen saturation (SpO2) etc. For diagnosis and analysis purpose, the gathered data needs to be stored. Wearable devices operate on batteries and have a memory constraint. In mHealth application architectures, this gathered data is hence stored on cloud based servers. While transmitting data from wearable devices to cloud servers via edge devices, a lot of energy is consumed. This paper proposes a deep learning based compression model SCAElite that reduces the data volume, enabling energy efficient transmission.
               
                  Results
                  Stress Recognition in Automobile Drivers dataset and MIT-BIH dataset from PhysioNet are used for validation of algorithm performance. The model achieves a compression ratio of up to 300 fold with reconstruction errors within 8% over the stress recognition dataset and 106.34-fold with reconstruction errors within 8% over the MIT-BIH dataset. The computational complexity of SCAElite is 51.65% less compared to state-of-the-art deep compressive model.
               
                  Conclusion
                  It is experimentally validated that SCAElite guarantees a high compression ratio with good quality restoration capabilities for physiological signal compression in mHealth applications. It has a compact architecture and is computationally more efficient compared to state-of-the-art deep compressive model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physc.2021.1354007,Journal,Physica C: Superconductivity and its Applications,scopus,2022-02-15,sciencedirect,Optical fibre based quench detection in HTS applications using machine learning classifiers,https://api.elsevier.com/content/abstract/scopus_id/85122309535,"A Mach-Zehnder Interferometer (MZI) based optical fibre sensing technique, developed and patented by EPFL, is an efficient and economical way to detect hotspots in High Temperature Superconductor (HTS) applications. Due to the MZI sensitivity being a composite of strain sensitive and temperature sensitive contributions, the MZI gives an instantaneous response to a quench (within 10 ms), because of the quick strain transfer to the optical fibre. However, the MZI output signal can also manifest the environmental noise caused by mechanical vibrations, bubbling in the cryostat and temperature variations, along with the response to the quench. This presents the problems of false alarms and indiscernible response to a quench. Discrete wavelet transform (DWT) has been proven to be a useful tool for feature extraction in different fields requiring signal categorization and hence holds the potential to enable quench recognition in the MZI output. This paper proposes an effective approach of performing DWT based feature extraction on experimental data and subsequently using the extracted features for the MZI response classification using two machine learning based classification techniques: k-nearest neighbours (KNN) and Artificial Neural Network (ANN). For this manuscript, experiments were performed using MZI for quench detection in an HTS tape. Feature extraction was then implemented on these experimental measurements using discrete wavelet coefficients extracted at different decomposition levels from the MZI output; these features were then used to train the KNN and ANN models for identifying quench in the MZI signal. This method could be a valuable supplement to the MZI technique by enabling the development of a real time application that can process the MZI output data as well as eliminate the occurrences of false alarms; thereby facilitating reliable quench detection. With this development, the MZI technique would become an even more attractive solution for the health monitoring of HTS applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2021.108661,Journal,Computer Networks,scopus,2022-02-11,sciencedirect,Evaluating Federated Learning for intrusion detection in Internet of Things: Review and challenges,https://api.elsevier.com/content/abstract/scopus_id/85121903251,"The application of Machine Learning (ML) techniques to the well-known intrusion detection systems (IDS) is key to cope with increasingly sophisticated cybersecurity attacks through an effective and efficient detection process. In the context of the Internet of Things (IoT), most ML-enabled IDS approaches use centralized approaches where IoT devices share their data with data centers for further analysis. To mitigate privacy concerns associated with centralized approaches, in recent years the use of Federated Learning (FL) has attracted a significant interest in different sectors, including healthcare and transport systems. However, the development of FL-enabled IDS for IoT is in its infancy, and still requires research efforts from various areas, in order to identify the main challenges for the deployment in real-world scenarios. In this direction, our work evaluates a FL-enabled IDS approach based on a multiclass classifier considering different data distributions for the detection of different attacks in an IoT scenario. In particular, we use three different settings that are obtained by partitioning the recent ToN_IoT dataset according to IoT devices’ IP address and types of attack. Furthermore, we evaluate the impact of different aggregation functions according to such setting by using the recent IBMFL framework as FL implementation. Additionally, we identify a set of challenges and future directions based on the existing literature and the analysis of our evaluation results.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ajhg.2021.12.008,Journal,American Journal of Human Genetics,scopus,2022-02-03,sciencedirect,PhenoApt leverages clinical expertise to prioritize candidate genes via machine learning,https://api.elsevier.com/content/abstract/scopus_id/85123821072,"In recent years, exome sequencing (ES) has shown great utility in the diagnoses of Mendelian disorders. However, after rigorous filtering, a typical ES analysis still involves the interpretation of hundreds of variants, which greatly hinders the rapid identification of causative genes. Since the interpretations of ES data require comprehensive clinical analyses, taking clinical expertise into consideration can speed the molecular diagnoses of Mendelian disorders. To leverage clinical expertise to prioritize candidate genes, we developed PhenoApt, a phenotype-driven gene prioritization tool that allows users to assign a customized weight to each phenotype, via a machine-learning algorithm. Using the ability to rank causative genes in top-10 lists as an evaluation metric, baseline analysis demonstrated that PhenoApt outperformed previous phenotype-driven gene prioritization tools by a relative increase of 22.7%–140.0% in three independent, real-world, multi-center cohorts (cohort 1, n = 185; cohort 2, n = 784; and cohort 3, n = 208). Additional trials showed that, by adding weights to clinical indications, which should be explained by the causative gene, PhenoApt performance was improved by a relative increase of 37.3% in cohort 2 (n = 471) and 21.4% in cohort 3 (n = 208). Moreover, PhenoApt could assign an intrinsic weight to each phenotype based on the likelihood of its being a Mendelian trait using term frequency-inverse document frequency techniques. When clinical indications were assigned with intrinsic weights, PhenoApt performance was improved by a relative increase of 23.7% in cohort 2 and 15.5% in cohort 3. For the integration of PhenoApt into clinical practice, we developed a user-friendly website and a command-line tool.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ces.2021.117205,Journal,Chemical Engineering Science,scopus,2022-02-02,sciencedirect,"Developments of leak detection, diagnostics, and prediction algorithms in multiphase flows",https://api.elsevier.com/content/abstract/scopus_id/85118896502,"Leak detection, diagnostics, and prediction constitute a crucial phase of the flow assurance risk management process for onshore and offshore pipelines. There are a variety of techniques and algorithms that can be deployed to address each aspect. To date, most review papers have concentrated on steady-state and single-phase flow conditions. The goal of the current review is therefore to carry out a thorough analysis of the available leak detection and diagnosis methods by focusing on (i) multiphase flow and transient flow conditions, (ii) model-based and data-driven techniques, (iii) prediction tools, and (iv) performance measures. Detailed assessment of leak detection methods based on accuracy, complexity, data requirement, and cost of installation are discussed. Data-driven techniques are utterly dependent on qualitative and quantitative data available from pipeline systems. Contrastingly data-driven techniques, model-based techniques require less data to achieve leak detection, provided that a nearly accurate base model is available. Different methodologies and technologies can be combined in order to produce the best detection and diagnosis outputs. In many cases, statistical analysis was combined with the Real Time Transient Method (RTTM), which helped to minimize false alarms. The material in this review can be used as a robust guide for the design of diagnostic systems and further research.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cjca.2021.11.009,Journal,Canadian Journal of Cardiology,scopus,2022-02-01,sciencedirect,A Primer on the Present State and Future Prospects for Machine Learning and Artificial Intelligence Applications in Cardiology,https://api.elsevier.com/content/abstract/scopus_id/85122266625,"The artificial intelligence (AI) revolution is well underway, including in the medical field, and has dramatically transformed our lives. An understanding of the basics of AI applications, their development, and challenges to their clinical implementation is important for clinicians to fully appreciate the possibilities of AI. Such a foundation would ensure that clinicians have a good grasp and realistic expectations for AI in medicine and prevent discrepancies between the promised and real-world impact. When quantifying the track record for AI applications in cardiology, we found that a substantial number of AI systems are never deployed in clinical practice, although there certainly are many success stories. Successful implementations shared the following: they came from clinical areas where large amount of training data was available; were deployable into a single diagnostic modality; prediction models generally had high performance in external validation; and most were developed as part of collaborations with medical device manufacturers who had substantial experience with implementation of new clinical technology. When looking into the current processes used for developing AI-based systems, we suggest that expanding the analytic framework to address potential deployment and implementation issues at project outset will improve the rate of successful implementation, and will be a necessary next step for AI to achieve its full potential in cardiovascular medicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.105144,Journal,Computers in Biology and Medicine,scopus,2022-02-01,sciencedirect,Domain generalization on medical imaging classification using episodic training with task augmentation,https://api.elsevier.com/content/abstract/scopus_id/85121969937,"Medical imaging datasets usually exhibit domain shift due to the variations of scanner vendors, imaging protocols, etc. This raises the concern about the generalization capacity of machine learning models. Domain generalization (DG), which aims to learn a model from multiple source domains such that it can be directly generalized to unseen test domains, seems particularly promising to medical imaging community. To address DG, recent model-agnostic meta-learning (MAML) has been introduced, which transfers the knowledge from previous training tasks to facilitate the learning of novel testing tasks. However, in clinical practice, there are usually only a few annotated source domains available, which decreases the capacity of training task generation and thus increases the risk of overfitting to training tasks in the paradigm. In this paper, we propose a novel DG scheme of episodic training with task augmentation on medical imaging classification. Based on meta-learning, we develop the paradigm of episodic training to construct the knowledge transfer from episodic training-task simulation to the real testing task of DG. Motivated by the limited number of source domains in real-world medical deployment, we consider the unique task-level overfitting and we propose task augmentation to enhance the variety during training task generation to alleviate it. With the established learning framework, we further exploit a novel meta-objective to regularize the deep embedding of training domains. To validate the effectiveness of the proposed method, we perform experiments on histopathological images and abdominal CT images.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103559,Journal,Sustainable Cities and Society,scopus,2022-02-01,sciencedirect,Assessment of sustainable development objectives in Smart Labs: technology and sustainability at the service of society,https://api.elsevier.com/content/abstract/scopus_id/85120052266,"Sustainable development is the working basis of engineering research and cities are becoming increasingly flexible, inclusive and intelligent. In this context, there is a need for environments that emulate real-life spaces in which cutting-edge technologies can be implemented for subsequent deployment in society. Smart Labs or Living Labs are spaces for innovation, research and experimentation that integrate systems, devices and methodologies focused on people and their environments. The technologies studied and developed in such labs can then be deployed in human spaces to provide intelligence, comfort, health and sustainability. Health and wellness, energy and environment, artificial intelligence, big data and digital rights are some of the disciplines being studied. At the same time, the UN 2030 Agenda provides a comprehensive framework to promote human well-being through the Sustainable Development Goals. In this work, an evaluation model of its indicators in smart environments is performed through a mixed review methodology. The objective of this work is the analysis and implementation of the SDGs in Smart Labs through a literature review and a case study of UJAmI, the smart laboratory of the University of Jaén. The results provide quantitative and qualitative data on the present and future of the smart devices implemented in the UJAmI lab, providing a roadmap for future developments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2021.103269,Journal,Biomedical Signal Processing and Control,scopus,2022-02-01,sciencedirect,Identification of spatiotemporal dispersion electrograms in atrial fibrillation ablation using machine learning: A comparative study,https://api.elsevier.com/content/abstract/scopus_id/85119414961,"Atrial Fibrillation (AF) is the most widespread sustained arrhythmia in clinical practice. A recent personalized AF therapy consists in ablating areas displaying spatiotemporal dispersion (STD) electrograms (EGM) with the use of catheters. Interventional cardiologists use a multipolar mapping catheter called PentaRay to identify visually atrial sites with STD pattern by visual inspection. In this contribution, we propose to automatize the identification of STD EGMs using machine learning while comparing several features. The aim is to design a data representation and an adapted classification algorithm for accurate STD detection with affordable computational resources and low prediction time. Four data formats are considered: 1) EGM matrices; 2) EGM plots; 3) three-dimensional EGM plots; 4) maximal voltage absolute values. Convolutional neural networks and transfer learning based on the VGG16 architecture are benchmarked. Classification results on the test set show that extracting features automatically with VGG16 is possible and yields comparable results to classifying raw EGM recordings with values of accuracy and AUC of 90%. However, the overall precision and F1 score are low (50%), which can be explained by the high class imbalance ratio. This issue is addressed with data augmentation. Due to its low computational cost, our solution can also be deployed in real time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jiac.2021.10.027,Journal,Journal of Infection and Chemotherapy,scopus,2022-02-01,sciencedirect,A study of quality assessment in SARS-CoV-2 pathogen nucleic acid amplification tests performance; from the results of external quality assessment survey of clinical laboratories in the Tokyo Metropolitan Government external quality assessment program in 2020,https://api.elsevier.com/content/abstract/scopus_id/85119258737,"Introduction
                  The Tokyo Metropolitan Government (TMG) conducted an external quality assessment (EQA) survey of pathogen nucleic acid amplification tests (NAATs) as a TMG EQA program for SARS-CoV-2 for clinical laboratories in Tokyo.
               
                  Methods
                  We diluted and prepared a standard product manufactured by Company A to about 2,500 copies/mL to make a positive control and distribute it with a negative control. The participants reported the use of the NAATs methods for SARS-CoV-2, the name of the real-time RT-PCR kit, the name of the detection device, the target gene(s), nucleic acid extraction kit, Threshold Cycle value in the case of RT-PCR and the Threshold time value and Differential calculation value in the case of Loop-Mediated Isothermal Amplification (LAMP) method.
               
                  Results
                  As a result, 17 laboratories using fully automated equipment and 34 laboratories using the RT-PCR method reported generally appropriate results in this EQA survey. On the other hand, among the laboratories that adopted the LAMP method, there were a plurality of laboratories that judged positive samples to be negative.
               
                  Conclusion
                  The false negative result is considered to be due to the fact that the amount of virus genome contained in the quality control reagent used this time was below the detection limit of the LAMP method combined with the rapid extraction reagent for influenza virus. On the other hand, false positive results are considered to be due to the non-specific reaction of the NAATs. The EQA program must be continued for the proper implementation of the pathogen NAATs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ress.2021.108119,Journal,Reliability Engineering and System Safety,scopus,2022-02-01,sciencedirect,Prognostics and Health Management (PHM): Where are we and where do we (need to) go in theory and practice,https://api.elsevier.com/content/abstract/scopus_id/85117331443,"We are performing the digital transition of industry, living the 4th industrial revolution, building a new World in which the digital, physical and human dimensions are interrelated in complex socio-cyber-physical systems. For the sustainability of these transformations, knowledge, information and data must be integrated within model-based and data-driven approaches of Prognostics and Health Management (PHM) for the assessment and prediction of structures, systems and components (SSCs) evolutions and process behaviors, so as to allow anticipating failures and avoiding accidents, thus, aiming at improved safe and reliable design, operation and maintenance.
                  There is already a plethora of methods available for many potential applications and more are being developed: yet, there are still a number of critical problems which impede full deployment of PHM and its benefits in practice. In this respect, this paper does not aim at providing a survey of existing works for an introduction to PHM nor at providing new tools or methods for its further development; rather, it aims at pointing out main challenges and directions of advancements, for full deployment of condition-based and predictive maintenance in practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2021.08.030,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,A wearable-based posture recognition system with AI-assisted approach for healthcare IoT,https://api.elsevier.com/content/abstract/scopus_id/85115908462,"Human posture recognition is a challenging task in the medical healthcare industry, when pursuing intelligence, accuracy, security, privacy, and efficiency, etc. Currently, the main posture recognition methods are captured-behaviors-based visual image analysis and wearable devices-based signal analysis. However, these methods suffer from issues such as high misjudgment rate, high-cost and low-efficiency. To address these issues, we propose a collaborative AI-IoT-based solution (namely, WMHPR) that embeds with advanced AI-assisted approach. In WMHPR, we propose the multi-posture recognition (MPR), an offline algorithm is implemented on wearable hardware, to identify posture based on multi-dimensions data. Meanwhile, an AI-based algorithm running on the cloud server (online), named Cascade-AdaBoosting-CART (CACT), is proposed to further enhance the reliability and accuracy of MPR. We recruit 20 volunteers for real-life experiments to evaluate the effectiveness, and the results show our solution is significantly outstanding in terms of accuracy and reliability while comparing with other typical algorithms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2021.09.010,Journal,Future Generation Computer Systems,scopus,2022-02-01,sciencedirect,XSRU-IoMT: Explainable simple recurrent units for threat detection in Internet of Medical Things networks,https://api.elsevier.com/content/abstract/scopus_id/85115376405,"The Internet of Medical Things (IoMT) is increasingly replacing the traditional healthcare systems. However, less focus has been paid to their security against cyber-threats in the implementation of the IoMT and its networks. One of the key reasons can be the challenging task of optimizing typical security solutions to the IoMT networks. And despite the rising admiration of machine learning and deep learning methods in the cyber-security domain (e.g., a threat detection system), most of these methods are acknowledged as a black-box model. The explainable AI (XAI) has become progressively vital to understand the employed learning models to improve trust level and empower security experts to interpret the prediction decisions. The authors propose a highly efficient model named XSRU-IoMT, for effective and timely detection of sophisticated attack vectors in IoMT networks. The proposed model is developed using novel bidirectional simple recurrent units (SRU) using the phenomenon of skip connections to eradicate the vanishing gradient problem and achieve a fast training process in recurrent networks. We also explore the concepts of XAI to improve trust level by providing explanations of the predictive decisions and enabling humans and security experts to understand the causal reasoning and underlying data evidence. The evaluation results on the ToN_IoT dataset demonstrate the effectiveness and superiority of the proposed XSRU-IoMT model as compared to the state-of-the-art compelling detection models, suggesting its usefulness as a viable deployment model in real-IoMT networks.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aej.2021.06.024,Journal,Alexandria Engineering Journal,scopus,2022-02-01,sciencedirect,"Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath",https://api.elsevier.com/content/abstract/scopus_id/85109458695,"The problem of respiratory sound classification has received good attention from the clinical scientists and medical researcher’s community in the last year to the diagnosis of COVID-19 disease. The Artificial Intelligence (AI) based models deployed into the real-world to identify the COVID-19 disease from human-generated sounds such as voice/speech, dry cough, and breath. The CNN (Convolutional Neural Network) is used to solve many real-world problems with Artificial Intelligence (AI) based machines. We have proposed and implemented a multi-channeled Deep Convolutional Neural Network (DCNN) for automatic diagnosis of COVID-19 disease from human respiratory sounds like a voice, dry cough, and breath, and it will give better accuracy and performance than previous models. We have applied multi-feature channels such as the data De-noising Auto Encoder (DAE) technique, GFCC (Gamma-tone Frequency Cepstral Coefficients), and IMFCC (Improved Multi-frequency Cepstral Coefficients) methods on augmented data to extract the deep features for the input of the CNN. The proposed approach improves system performance to the diagnosis of COVID-19 disease and provides better results on the COVID-19 respiratory sound dataset.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2021.149834,Journal,Science of the Total Environment,scopus,2022-01-10,sciencedirect,"Viral outbreaks detection and surveillance using wastewater-based epidemiology, viral air sampling, and machine learning techniques: A comprehensive review and outlook",https://api.elsevier.com/content/abstract/scopus_id/85114771539,"A viral outbreak is a global challenge that affects public health and safety. The coronavirus disease 2019 (COVID-19) has been spreading globally, affecting millions of people worldwide, and led to significant loss of lives and deterioration of the global economy. The current adverse effects caused by the COVID-19 pandemic demands finding new detection methods for future viral outbreaks. The environment's transmission pathways include and are not limited to air, surface water, and wastewater environments. The wastewater surveillance, known as wastewater-based epidemiology (WBE), can potentially monitor viral outbreaks and provide a complementary clinical testing method. Another investigated outbreak surveillance technique that has not been yet implemented in a sufficient number of studies is the surveillance of Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2) in the air. Artificial intelligence (AI) and its related machine learning (ML) and deep learning (DL) technologies are currently emerging techniques for detecting viral outbreaks using global data. To date, there are no reports that illustrate the potential of using WBE with AI to detect viral outbreaks. This study investigates the transmission pathways of SARS-CoV-2 in the environment and provides current updates on the surveillance of viral outbreaks using WBE, viral air sampling, and AI. It also proposes a novel framework based on an ensemble of ML and DL algorithms to provide a beneficial supportive tool for decision-makers. The framework exploits available data from reliable sources to discover meaningful insights and knowledge that allows researchers and practitioners to build efficient methods and protocols that accurately monitor and detect viral outbreaks. The proposed framework could provide early detection of viruses, forecast risk maps and vulnerable areas, and estimate the number of infected citizens.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.3168/jds.2021-21171,Journal,Journal of Dairy Science,scopus,2022-01-01,sciencedirect,Detection of nonpregnant cows and potential embryo losses by color Doppler ultrasound and interferon-stimulated gene expression in grazing dairy cows,https://api.elsevier.com/content/abstract/scopus_id/85133380921,"Many studies have been conducted to estimate pregnancy losses between 19 and 34 d after artificial insemination (AI) in dairy cows managed under confinement-based systems, but few studies have examined embryo mortality during this interval in dairy cows managed under gazing systems. The objectives of this prospective cohort study were (1) to assess the diagnostic value of the corpus luteum (CL) blood perfusion (BP) evaluation by Doppler ultrasound (US) to detect nonpregnant cows at 19 to 20 d post-AI, and (2) to assess the rate of potential embryo mortality between 19 to 34 d post-AI. The CL-BP of all cows included in the study (n = 131) was examined on farm by power and color mode of Doppler US and later using an image processing software by a second evaluator. The endometrium thickness and echotexture were evaluated by B-mode US at the same visit to assess if the nonpregnancy diagnosis could be improved at 19 to 20 d post-AI by this additional diagnostic tool. Blood samples were obtained at 19 to 20 d post-AI for progesterone (P4) measurement by chemiluminescence and to determine the mRNA expression of ISG by real-time PCR. Pregnancy diagnosis based on embryo visualization was performed at 33 to 34 d post-AI by US B-mode. In parallel interpretation, ISG15 and MX2 mRNA expression in leukocytes [sensitivity (Se), 100%] were regarded as suitable biomarkers for early pregnancy and were selected for molecular characterization of pregnancy at 19 to 20 d post-AI. At 19 to 20 d post-AI, 61.1% of the cows had positive CL-BP by Doppler US (Se, 98.0%), 62.7% had ISG mRNA expression in leukocytes over the cutoff point (Se, 95.7%), and 50.8% were positive, based on the combination of ISG mRNA expression, CL-BP by Doppler US, and P4 concentration (Se, 100%), and were considered as possible pregnant. At 33 to 34 d, the pregnancy rate was 37.4% diagnosed by the B-mode US. Based on the expression of the selected biomarkers in cows with active CL, we found that 28.1% of the cows could have potentially lost their pregnancy between 19 and 34 d post-AI. The Doppler US color mode showed similar accuracy and a higher negative predictive value than the genes selected as biomarkers. The additional B-mode ultrasound evaluation of the uterine stratum vasculare and the endometrium thickness improved the diagnostic accuracy. Therefore, assessing the CL-BP by Doppler US allowed early detection of nonpregnant cows at 19 to 20 d post-AI. The combination of early CL-BP by Doppler US (d 19 to 20) with early embryo detection by B-mode US (d 33–34) could be used to facilitate earlier rebreeding of dairy cows.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2022.04.388,Journal,Materials Today: Proceedings,scopus,2022-01-01,sciencedirect,"Evaluation of strain measurements using ZnS: Mn, Cu as mechanoluminescent material and strain gauge sensor",https://api.elsevier.com/content/abstract/scopus_id/85132601395,"Structural health monitoring (SHM) is emerging as a significant aspect in structural engineering. Predominantly, civil engineering structures have become more reliant on SHM. Advanced sensors and smart materials are the prominent technologies for applying Structural Health Monitoring. Numerous techniques for damage detection of the structures in the field of civil engineering. In this paper, we have introduced innovative smart material, Mechanoluminescent material that enables real-time continuous monitoring and damage detection of the structures. The most prominent ML (Mechanoluminescent material) Mn (Manganese) or Cu (Copper) doped ZnS (Zinc sulphide) crystal is studied because they exhibit the brightest luminescent emission. The present investigation aims to evaluate the strain measurements using ML material and compare the readings with the strain gauge sensor obtained in the Arduino Integrated Development Environment Software (IDE). An experimental approach has been done to produce ML material and to understand the fundamental ML phenomenon. At present, many researchers have developed ML material for the implementation to real-social infrastructure. If success leads the ML material will be a new step for development of modified sensor channel that could monitor a structure for actual impacts with the existence of stress levels acting on it.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2022.03.068,Conference Proceeding,Procedia Computer Science,scopus,2022-01-01,sciencedirect,The Security Concerns on Cyber-Physical Systems and Potential Risks Analysis Using Machine Learning,https://api.elsevier.com/content/abstract/scopus_id/85132207250,"The use of engineering to drive down costs and improve productivity has been an ongoing business exercise since the first Industrial Revolution. The term Cyber-Physical System is a wide range of different computing technologies embedded with the next-generation engineered systems into the physical world. Connected Cyber-Physical Systems (CPS) improve the lives of people and increase industry and manufacturing efficiency. It is affecting many branches of life such as transportation, healthcare and medicine, the environment, and energy. Industry 4.0 integrates humans, machines, and data to provide a holistic and interlinked approach to manufacturing, hence, increasing privacy concerns. For example, Autonomous Vehicles (AV) can be driven without a pilot and those systems can be hacked if there is a breach in the system. Nowadays, most of the systems are interconnected to the internet and nothing can be considered fully safe. Therefore, with this increase of security threats and privacy concerns, there is a need to assess and evaluate the trade-off between enhancements and improvements in manufacturing and the possible threats and security risks in the context of Cyber-Physical Systems. We need to bridge the gaps and overcome some of these limitations. In this work, we studied the security concerns emerging from interconnected Cyber-Physical systems, devices, and services in Industry 4.0. To identify security vulnerabilities, we have chosen the energy dataset because energy is the key point of every Cyber-Physical system so aimed to show the importance of energy, and the K-Means algorithm implemented which is an advanced Machine Learning and potential risks detected.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-821661-3.00007-0,Book,"Wearable Physical, Chemical and Biological Sensors: Fundamentals, Materials and Applications",scopus,2022-01-01,sciencedirect,Healthcare data analytics for wearable sensors,https://api.elsevier.com/content/abstract/scopus_id/85131501337,"In a growing number of machine learning applications—such as autonomous monitoring of hospital rooms, remote patient monitoring, and node or link prediction in evolving networks—one must make online, real-time decisions and continuously improve performance with the sequential arrival of data. This chapter discusses different aspect of healthcare data analytics for wearable sensors highlighting big data and Edge artificial intelligence which intersects between hardware and software analytics. This chapter underlines the challenging issues about the healthcare data analytics such as network scalability, data accuracy, power consumptions of wearable sensing devices, data privacy and security.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacr.2022.03.016,Journal,Journal of the American College of Radiology,scopus,2022-01-01,sciencedirect,"Federated Learning in Medical Imaging: Part II: Methods, Challenges, and Considerations",https://api.elsevier.com/content/abstract/scopus_id/85130886520,"Federated learning is a machine learning method that allows decentralized training of deep neural networks among multiple clients while preserving the privacy of each client’s data. Federated learning is instrumental in medical imaging because of the privacy considerations of medical data. Setting up federated networks in hospitals comes with unique challenges, primarily because medical imaging data and federated learning algorithms each have their own set of distinct characteristics. This article introduces federated learning algorithms in medical imaging and discusses technical challenges and considerations of real-world implementation of them.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.entcom.2022.100496,Journal,Entertainment Computing,scopus,2022-01-01,sciencedirect,Particle swarm optimization for procedural content generation in an endless platform game,https://api.elsevier.com/content/abstract/scopus_id/85130317786,"Given the ever-increasing competition in the digital gaming industry, induced by a market of an exponentially growing gamer population, the production of creative, coherent, and appealing games has become inherently more complex. Creating game content by hand is both costly and time-consuming. By automating or assisting programmers and designers in their tasks, the techniques of procedural content generation (PCG) for games may address these challenges. PCG is not new, being active for several decades. However, the more traditional (and popular) form of PCG is somehow limited. It relies on some basic techniques ranging from simple pseudo-random number generators, generative grammars, image filtering, and spatial algorithms. The most advanced forms of PCG may utilize the modeling and simulation of complex systems and techniques from Artificial Intelligence (AI). In this context, this paper proposes a novel PCG approach, which is based on an optimization algorithm, known as Particle Swarm Optimization (PSO). Our approach is tested on a 2D endless platform runner game. The game structure (based on the Godot Game Engine) and a previous solution using Genetic Algorithms (GA) were first proposed and evaluated in an earlier work. In this paper, besides proposing the novel solution using PSO, we performed a comparative evaluation between the novel and previous solutions. The fitness function, utilized by both algorithms, takes into account the game’s environment aesthetics, physics, and some rules associated with gameplay, so that the generated environments are both enjoyable and playable. Our experiments evaluated time viability for in-game real-time generation and convergence to high/stable fitness values. We discovered hyper parameter ranges that yielded viable solutions. In the end, PSO has proven to be better suited to the investigated PCG task than the GA, since it presented faster convergence time and higher fitness function values.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-823978-0.00003-4,Book,Applications of Computational Intelligence in Multi-Disciplinary Research,scopus,2022-01-01,sciencedirect,IoT in healthcare ecosystem,https://api.elsevier.com/content/abstract/scopus_id/85130106885,"In recent years, IoT has been revolutionizing the technology landscape, leading to explosive growth in fields like automated manufacturing, asset management, and wearable consumer healthcare products. IoT’s presence can be seen in all domains. Ever since IoT gained its entry into the medical field, there has been a magnificent transformation in the healthcare domain. Personal healthcare is now made a reality with IoT offering solutions in several dimensions like remote healthcare; smart clothing such as smartwatches, smart bands, and smart pants; and telemedicine like smart pills and personal care robots. This chapter gives a comprehensive walkthrough of IoT in the healthcare ecosystem, addressing the different applications of IoT in healthcare, the architecture models, challenges faced by IoT in healthcare, security practices and issues, and the future of IoT in the domain. In the first section, IoT applications in healthcare are discussed, which include patient-centric applications like remote health monitoring and critical care monitoring; and hospital-centric IoT applications such as the deployment of the staff, reducing charting times, and real-time location of medical equipment, subsequently followed by a discussion on how the data collected from the patient-centric and hospital-centric applications contribute to the ease of other domains like health insurance; and then, IoT’s support toward the pharmaceutical industry to restrict counterfeit medicine is discussed. Secondly, the implementation designs of healthcare IoT are discussed. Apart from the traditional cloud services, new offerings like fog and edge computing have seen a spike in recent years. Fog and edge computing are considered intelligent and flexible architectures. The subsequent section deals with architecture designs and the advantages and challenges of the two computing models. The next section demonstrates the actual implementation methodologies of the two applications in the following domains in detail: (1) Heart disease prediction and (2) healthcare IoT-based affective state mining using deep convolutional neural networks. The following section discusses the challenges faced by IoT in the healthcare domain. In general, the challenges can be categorized into technological challenges; people-oriented challenges like the acceptance of IoT in the healthcare domain; and finally, security bottlenecks. The data generated and maintained by the IoT platforms serves as a gold mine for different healthcare professionals for future research and development in the medical field and the health insurance providers and pharmaceutical industries for their benefits. Hence, more emphasis is given to the security and privacy aspects of how the domain handles sensitive data of the patients. The next section provides insights into the security issues along with the cyber threats and attacks faced by healthcare IoT and the defensive mechanisms. Furthermore, this chapter deals with the IoT’s role in combatting the novel coronavirus that has caused an unprecedented global pandemic. Finally, the future of IoT is talked about. With the advent of 5G and an upsurge in artificial intelligence, the different dimensions of the IoT that are expected to see an outburst of growth are discussed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.fmre.2022.03.025,Journal,Fundamental Research,scopus,2022-01-01,sciencedirect,Artificial Intelligence Reinforced Upconversion Nanoparticle-based Lateral Flow Assay via Transfer Learning,https://api.elsevier.com/content/abstract/scopus_id/85129516599,"The combination of upconverting nanoparticles (UCNPs) and immunochromatography has become a widely used and promising new detection technique for point-of-care testing (POCT). However, their low luminescence efficiency, non-specific adsorption, and image noise have always limited their progress toward practical applications. Recently, artificial intelligence (AI) has demonstrated powerful representational learning and generalization capabilities in computer vision. We report for the first time a combination of AI and upconversion nanoparticle-based lateral flow assays (UCNP-LFAs) for the quantitative detection of commercial internet of things (IoT) devices. This universal UCNPs quantitative detection strategy combines high accuracy, sensitivity, and applicability in the field detection environment. By using transfer learning to train AI models in a small self-built database, we not only significantly improved the accuracy and robustness of quantitative detection, but also efficiently solved the actual problems of data scarcity and low computing power of POCT equipment. Then, the trained AI model was deployed in IoT devices, whereby the detection process does not require detailed data preprocessing to achieve real-time inference of quantitative results. We validated the quantitative detection of two detectors using eight transfer learning models on a small dataset. The AI quickly provided ultra-high accuracy prediction results (some models could reach 100% accuracy) even when strong noise was added. Simultaneously, the high flexibility of this strategy promises to be a general quantitative detection method for optical biosensors. We believe that this strategy and device have a scientific significance in revolutionizing the existing POCT technology landscape and providing excellent commercial value in the in vitro diagnostics (IVD) industry.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-821750-4.00002-5,Book,"Endorobotics: Design, R and D and Future Trends",scopus,2022-01-01,sciencedirect,Artificial intelligence for medical robotics,https://api.elsevier.com/content/abstract/scopus_id/85128569934,"The shift in surgery toward minimally invasive approaches requires transitioning from an analog world to a digitally transformed system and presents a huge opportunity in this emerging field. Artificial intelligence (AI) in healthcare has the potential to transform the role of doctors and revolutionize the practice of medicine. The convergence between AI and medical robotic technologies creates an interesting area for research and development activities for the medical technology industry.
               Despite rapid improvements in robotic-assisted surgery over the past decade, the level of adoption remains low due to high costs, which is cited as a major challenge. This chapter outlines the current trends and perspectives of AI in medical robotics, with a rapid review of AI-supported robotics in allied health, radiology, rehabilitation medicine, with a specific focus on surgical applications.
               The chapter looks at how AI is being used in medical robotics for teaching and training, through to surgical planning and robotic-assisted surgery, using case studies.
               Some challenges with the use of AI in medicine include the issue of legal liability and attribution of negligence when errors occur. The chapter provides insights on ethical and legal issues of AI in medical robotics, with a discussion around implementation and adoption of this new technology.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2021.07.016,Journal,Information Fusion,scopus,2022-01-01,sciencedirect,"Unbox the black-box for the medical explainable AI via multi-modal and multi-centre data fusion: A mini-review, two showcases and beyond",https://api.elsevier.com/content/abstract/scopus_id/85127068702,"Explainable Artificial Intelligence (XAI) is an emerging research topic of machine learning aimed at unboxing how AI systems’ black-box choices are made. This research field inspects the measures and models involved in decision-making and seeks solutions to explain them explicitly. Many of the machine learning algorithms cannot manifest how and why a decision has been cast. This is particularly true of the most popular deep neural network approaches currently in use. Consequently, our confidence in AI systems can be hindered by the lack of explainability in these black-box models. The XAI becomes more and more crucial for deep learning powered applications, especially for medical and healthcare studies, although in general these deep neural networks can return an arresting dividend in performance. The insufficient explainability and transparency in most existing AI systems can be one of the major reasons that successful implementation and integration of AI tools into routine clinical practice are uncommon. In this study, we first surveyed the current progress of XAI and in particular its advances in healthcare applications. We then introduced our solutions for XAI leveraging multi-modal and multi-centre data fusion, and subsequently validated in two showcases following real clinical scenarios. Comprehensive quantitative and qualitative analyses can prove the efficacy of our proposed XAI solutions, from which we can envisage successful applications in a broader range of clinical questions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.japh.2022.02.018,Journal,Journal of the American Pharmacists Association,scopus,2022-01-01,sciencedirect,Framework to enable pharmacist access to health care data using Blockchain technology and artificial intelligence,https://api.elsevier.com/content/abstract/scopus_id/85126528487,"Background
                  Decentralization and authentication are embedded in blockchain technology, which utilizes artificial intelligence (AI) to ensure seamless sharing of data among different health care providers while safeguarding data privacy. Although community pharmacists are highly accessible to patients and possess robust clinical knowledge, they are limited in the clinical services they can provide owing to their lack of access to patient health records. We proposed a blockchain- and AI-based conceptual framework by performing a scoping review of successful blockchain integration in health systems.
               
                  Objective
                  To formulate a conceptual framework based on a scoping review to improve access to health care data in the community pharmacy setting through the adoption of blockchain technology and AI.
               
                  Methods
                  We performed a scoping review of literature based on Preferred Reporting Items for Systematic reviews and Meta-Analyses review criteria to identify the specific areas where blockchain can be implemented in health systems. We utilized the Pharmacists’ Patient Care Process (PPCP) to identify 2 critical areas for blockchain integration that can support community pharmacists to access patient electronic health records and implement patient-specific information in clinical decision-making.
               
                  Results
                  We included 7 articles out of 70 articles in our final review. The 2 areas in the PPCP identified for the use of blockchain on the basis of the literature review were “Assess” and “Implement.” Our proposed model involves pharmacists using AI and blockchain technology to comprehensively assess any concerns with the prescribed medication through access to laboratory results for patients and then implement a plan based on a comprehensive assessment of the patient’s health record.
               
                  Conclusions
                  Utilizing blockchain to securely share health data with community pharmacies has the potential to improve patient outcomes, optimize medication safety, and amplify pharmacists’ roles in patient care. Future research should focus on implementing the model in the real-world settings.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.survophthal.2022.02.001,Journal,Survey of Ophthalmology,scopus,2022-01-01,sciencedirect,Virtual reality and augmented reality— emerging screening and diagnostic techniques in ophthalmology: A systematic review,https://api.elsevier.com/content/abstract/scopus_id/85126113695,"In health care, virtual reality (VR) and augmented reality (AR) have been applied extensively for many purposes. Similar to other technologies such as telemedicine and artificial intelligence, VR and AR may improve clinical diagnosis and screening services in ophthalmology by alleviating current problems, including workforce shortage, diagnostic error, and underdiagnosis. In the past decade a number of studies and products have used VR and AR concepts to build clinical tests for ophthalmology, but comprehensive reviews on these studies are limited. Therefore, we conducted a systematic review on the use of VR and AR as a diagnostic and screening tool in ophthalmology. We identified 26 studies that implemented a variety of VR and AR tests on different conditions, including VR cover tests for binocular vision disorder, VR perimetry for glaucoma, and AR slit lamp biomicroscopy for retinal diseases. In general, while VR and AR tools can become standardized, automated, and cost-effective tests with good user experience, several weaknesses, including unsatisfactory accuracy, weak validation, and hardware limitations, have prevented these VR and AR tools from having wider clinical application. Also, a comparison between VR and AR is made to explain why studies have predominantly used VR rather than AR.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.medin.2021.12.005,Journal,Medicina Intensiva,scopus,2022-01-01,sciencedirect,Impact of Aspergillus spp. isolation in the first 24 hours of admission in critically ill patients with severe influenza virus pneumonia,https://api.elsevier.com/content/abstract/scopus_id/85124136387,"Objective
                  To determine the incidence and impact of Aspergillus spp. isolation (AI) on ICU mortality in critically ill patients with severe influenza pneumonia during the first 24h of admission.
               
                  Design
                  Secondary analysis of an observational and prospective cohort study.
               
                  Setting
                  ICUs voluntary participating in the Spanish severe Influenza pneumonia registry, between June 2009 and June 2019.
               
                  Patients
                  Consecutive patients admitted to the ICU with diagnosis of severe influenza pneumonia, confirmed by real-time polymerase chain reaction.
               
                  Interventions
                  None.
               
                  Main variables of interest
                  Incidence of AI in respiratory samples. Demographic variables, comorbidities, need for mechanical ventilation and the presence of shock according at admission. Acute Physiology and Chronic Health Evaluation II (APACHE II) scale calculated on ICU admission.
               
                  Results
                  3702 patients were analyzed in this study. AI incidence was 1.13% (n
                     =42). Hematological malignancies (OR 4.39, 95% CI 1.92–10.04); HIV (OR 3.83, 95% CI 1.08–13.63), and other immunosuppression situations (OR 4.87, 95% CI 1.99–11.87) were factors independently associated with the presence of Aspergillus spp. The automatic CHAID decision tree showed that hematologic disease with an incidence of 3.3% was the most closely AI related variable. Hematological disease (OR 2.62 95% CI 1.95–3.51), immunosuppression (OR 2.05 95% CI 1.46–2.88) and AI (OR 3.24, 95% CI 1.60–6.53) were variables independently associated with ICU mortality.
               
                  Conclusions
                  Empirical antifungal treatment in our population may only be justified in immunocompromised patients. In moderate-high risk cases, active search for Aspergillus spp. should be implemented.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.fmre.2021.12.005,Journal,Fundamental Research,scopus,2022-01-01,sciencedirect,AI-aided on-chip nucleic acid assay for smart diagnosis of infectious disease,https://api.elsevier.com/content/abstract/scopus_id/85122505591,"Global pandemics such as COVID-19 have resulted in significant global social and economic disruption. Although polymerase chain reaction (PCR) is recommended as the standard test for identifying the SARS-CoV-2, conventional assays are time-consuming. In parallel, although artificial intelligence (AI) has been employed to contain the disease, the implementation of AI in PCR analytics, which may enhance the cognition of diagnostics, is quite rare. The information that the amplification curve reveals can reflect the dynamics of reactions. Here, we present a novel AI-aided on-chip approach by integrating deep learning with microfluidic paper-based analytical devices (µPADs) to detect synthetic RNA templates of the SARS-CoV-2 ORF1ab gene. The µPADs feature a multilayer structure by which the devices are compatible with conventional PCR instruments. During analysis, real-time PCR data were synchronously fed to three unsupervised learning models with deep neural networks, including RNN, LSTM, and GRU. Of these, the GRU is found to be most effective and accurate. Based on the experimentally obtained datasets, qualitative forecasting can be made as early as 13 cycles, which significantly enhances the efficiency of the PCR tests by 67.5% (∼40 min). Also, an accurate prediction of the end-point value of PCR curves can be obtained by GRU around 20 cycles. To further improve PCR testing efficiency, we also propose AI-aided dynamic evaluation criteria for determining critical cycle numbers, which enables real-time quantitative analysis of PCR tests. The presented approach is the first to integrate AI for on-chip PCR data analysis. It is capable of forecasting the final output and the trend of qPCR in addition to the conventional end-point Cq calculation. It is also capable of fully exploring the dynamics and intrinsic features of each reaction. This work leverages methodologies from diverse disciplines to provide perspectives and insights beyond the scope of a single scientific field. It is universally applicable and can be extended to multiple areas of fundamental research.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.animal.2021.100432,Journal,Animal,scopus,2022-01-01,sciencedirect,A machine vision system to predict individual cow feed intake of different feeds in a cowshed,https://api.elsevier.com/content/abstract/scopus_id/85122307007,"Data on individual feed intake of dairy cows, an important variable for farm management, are currently unavailable in commercial dairies. A real-time machine vision system including models that are able to adapt to multiple types of feed was developed to predict individual feed intake of dairy cows. Using a Red-Green-Blue-Depth (RGBD) camera, images of feed piles of two different feed types (lactating cows' feed and heifers' feed) were acquired in a research dairy farm, for a range of feed weights under varied configurations and illuminations. Several models were developed to predict individual feed intake: two Transfer Learning (TL) models based on Convolutional Neural Networks (CNNs), one CNN model trained on both feed types, and one Multilayer Perceptron and Convolutional Neural Network model trained on both feed types, along with categorical data. We also implemented a statistical method to compare these four models using a Linear Mixed Model and a Generalised Linear Mixed Model, showing that all models are significantly different. The TL models performed best and were trained on both feeds with TL methods. These models achieved Mean Absolute Errors (MAEs) of 0.12 and 0.13 kg per meal with RMSE of 0.18 and 0.17 kg per meal for the two different feeds, when tested on varied data collected manually in a cowshed. Testing the model with actual cows’ meals data automatically collected by the system in the cowshed resulted in a MAE of 0.14 kg per meal and RMSE of 0.19 kg per meal. These results suggest the potential of measuring individual feed intake of dairy cows in a cowshed using RGBD cameras and Deep Learning models that can be applied and tuned to different types of feed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ebiom.2021.103774,Journal,eBioMedicine,scopus,2022-01-01,sciencedirect,Accuracy and ease-of-use of seven point-of-care SARS-CoV-2 antigen-detecting tests: A multi-centre clinical evaluation,https://api.elsevier.com/content/abstract/scopus_id/85121647709,"Background
                  Antigen-detecting rapid diagnostic tests (Ag-RDTs) for SARS-CoV-2 are important diagnostic tools. We assessed clinical performance and ease-of-use of seven Ag-RDTs in a prospective, manufacturer-independent, multi-centre cross-sectional diagnostic accuracy study to inform global decision makers.
               
                  Methods
                  Unvaccinated participants suspected of a first SARS-CoV-2 infection were recruited at six sites (Germany, Brazil). Ag-RDTs were evaluated sequentially, with collection of paired swabs for routine reverse transcription polymerase chain reaction (RT-PCR) testing and Ag-RDT testing. Performance was compared to RT-PCR overall and in sub-group analyses (viral load, symptoms, symptoms duration). To understandusability a System Usability Scale (SUS) questionnaire and ease-of-use (EoU) assessment were performed.
               
                  Findings
                  7471 participants were included in the analysis. Sensitivities across Ag-RDTs ranged from 70·4%-90·1%, specificities were above 97·2% for all Ag-RDTs but one (93·1%).Ag-RDTs, Mologic, Bionote, Standard Q, showed diagnostic accuracy in line with WHO targets (> 80% sensitivity, > 97% specificity). All tests showed high sensitivity in the first three days after symptom onset (≥87·1%) and in individuals with viral loads≥ 6 log10SARS-CoV2 RNA copies/mL (≥ 88·7%). Usability varied, with Rapigen, Bionote and Standard Q reaching very good scores; 90, 88 and 84/100, respectively.
               
                  Interpretation
                  Variability in test performance is partially explained by variable viral loads in population evaluated over the course of the pandemic. All Ag-RDTs reach high sensitivity early in the disease and in individuals with high viral loads, supporting their role in identifying transmission relevant infections. For easy-to-use tests, performance shown will likely be maintained in routine implementation.
               
                  Funding
                  Ministry of Science, Research and Arts, State of Baden-Wuerttemberg, Germany, internal funds from Heidelberg University Hospital, University Hospital Charité − Universitätsmedizin Berlin, UK Department of International Development, WHO, Unitaid.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00211-9,Journal,The Lancet Digital Health,scopus,2022-01-01,sciencedirect,"Deep learning-based classification of kidney transplant pathology: a retrospective, multicentre, proof-of-concept study",https://api.elsevier.com/content/abstract/scopus_id/85120858490,"Background
                  Histopathological assessment of transplant biopsies is currently the standard method to diagnose allograft rejection and can help guide patient management, but it is one of the most challenging areas of pathology, requiring considerable expertise, time, and effort. We aimed to analyse the utility of deep learning to preclassify histology of kidney allograft biopsies into three main broad categories (ie, normal, rejection, and other diseases) as a potential biopsy triage system focusing on transplant rejection.
               
                  Methods
                  We performed a retrospective, multicentre, proof-of-concept study using 5844 digital whole slide images of kidney allograft biopsies from 1948 patients. Kidney allograft biopsy samples were identified by a database search in the Departments of Pathology of the Amsterdam UMC, Amsterdam, Netherlands (1130 patients) and the University Medical Center Utrecht, Utrecht, Netherlands (717 patients). 101 consecutive kidney transplant biopsies were identified in the archive of the Institute of Pathology, RWTH Aachen University Hospital, Aachen, Germany. Convolutional neural networks (CNNs) were trained to classify allograft biopsies as normal, rejection, or other diseases. Three times cross-validation (1847 patients) and deployment on an external real-world cohort (101 patients) were used for validation. Area under the receiver operating characteristic curve (AUROC) was used as the main performance metric (the primary endpoint to assess CNN performance).
               
                  Findings
                  Serial CNNs, first classifying kidney allograft biopsies as normal (AUROC 0·87 [ten times bootstrapped CI 0·85–0·88]) and disease (0·87 [0·86–0·88]), followed by a second CNN classifying biopsies classified as disease into rejection (0·75 [0·73–0·76]) and other diseases (0·75 [0·72–0·77]), showed similar AUROC in cross-validation and deployment on independent real-world data (first CNN normal AUROC 0·83 [0·80–0·85], disease 0·83 [0·73–0·91]; second CNN rejection 0·61 [0·51–0·70], other diseases 0·61 [0·50–0·74]). A single CNN classifying biopsies as normal, rejection, or other diseases showed similar performance in cross-validation (normal AUROC 0·80 [0·73–0·84], rejection 0·76 [0·66–0·80], other diseases 0·50 [0·36–0·57]) and generalised well for normal and rejection classes in the real-world data. Visualisation techniques highlighted rejection-relevant areas of biopsies in the tubulointerstitium.
               
                  Interpretation
                  This study showed that deep learning-based classification of transplant biopsies could support pathological diagnostics of kidney allograft rejection.
               
                  Funding
                  European Research Council; German Research Foundation; German Federal Ministries of Education and Research, Health, and Economic Affairs and Energy; Dutch Kidney Foundation; Human(e) AI Research Priority Area of the University of Amsterdam; and Max-Eder Programme of German Cancer Aid.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ergon.2021.103234,Journal,International Journal of Industrial Ergonomics,scopus,2022-01-01,sciencedirect,Industrial intelligence in the care of workers’ mental health: A review of status and challenges,https://api.elsevier.com/content/abstract/scopus_id/85120173556,"Mental health is a current concern because people worldwide have been committed to disorders that impair lives as a whole, affecting emotional states, behaviors, and body responses. These disorders decrease worker's productivity, impact industries economically, and cause serious psycho-physical conditions. However, technological advances have leveraged the industry to a novel phase where digitalization and automation provide a new reality. Hence, this industrial transformation may contribute to assists human beings in the workplace with a focus on mental health. This article presents a systematic literature review to investigate studies regarding technologies employed in the care of worker's mental health and the industrial role in this scenario. Three general, three focused, and three descriptive questions highlight the academic progress of industrial concern on mental health, implemented systems and cases, and research challenges. As a result, the review discussed 31 studies, extracted from an initial corpus of 25269, ranging from January 2010 to November 2020. The studies approached stress as the most frequent mental issue in the industry and Support Vector Machine (SVM) as the most used machine learning algorithm, where biomarkers presented the primary data extractors to deal with this theme. Moreover, information fusion methods improved the accuracy of specific cases. However, a growing interest in mental health care has emerged only in recent years, and several challenges require efforts before applying systems in real industrial environments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.suscom.2021.100622,Journal,Sustainable Computing: Informatics and Systems,scopus,2022-01-01,sciencedirect,Internet of Things for sustaining a smart and secure healthcare system,https://api.elsevier.com/content/abstract/scopus_id/85119703892,"The thyroid is a key endocrine gland in the human body that regulates several bodily processes, including protein synthesis, energy consumption, and the body’s reaction to other hormones. Segmentation and volume regeneration of the thyroid is particularly important for identifying thyroid-related diseases since the majority of these problems result in a change in the thyroid’s shape and scale over time. There is an urgent need for research on the disease’s origins and spread. The Internet of Things, cloud computing, and artificial intelligence all provide real-time processing for a variety of applications in the healthcare sector. In healthcare and biomedicine applications, machine learning algorithms are increasingly being utilized to make critical choices. Thyroid patients urgently need a robust and latency-sensitive Quality of Service framework. This paper aims to integrate fog computing and artificial intelligence with smart health to provide a dependable platform for thyroid infection early detection. To identify thyroid patients, a novel ensemble-based classifier is proposed. The thyroid dataset is obtained from the UCI library and the simulation is carried out utilizing Python programming. To increase the framework’s security, encryption and decryption methods are suggested. The suggested framework’s performance is assessed in terms of latency, network use, RAM utilization, and energy consumption. On the other side, the suggested classifier’s accuracy, precision, specificity, sensitivity and F1 score are all assessed. The result demonstrates that the suggested framework and classifier perform consistently better than conventional frameworks and classifiers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2021.103123,Journal,Biomedical Signal Processing and Control,scopus,2022-01-01,sciencedirect,Real-time application based CNN architecture for automatic USCT bone image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85114454344,"Artificial Intelligence (AI) in medical image analysis has achieved excellent success in automatic diagnosis in the same way as clinician, especially in the ultrasound field. In this work, we develop a new segmentation application based on various Convolutional Neural Network (CNN) models for Ultrasonic Computed Tomographic (USCT) images. To evaluate the proposed segmentation system, we use different state-of-the-art models for better segmentation performances to train and test the suggested system. We ensure in this work a USCT data augmentation technique based on the Haar wavelet transform and the improved k-means algorithms. Thus, we offer a free dataset for USCT researchers. Moreover, the proposed CNN system is trained and tested using the networks of Adadelta and Adam optimizers. The whole system is implemented on a CPU and a GPU for complexity analysis. High segmentation accuracy has been achieved using the Adadelta optimizer, reaching 99.24%, 99.19%, 99.13% and 99.10% for VGG-Segnet, VGG-Unet, Fully CNN (FCN)-8 and FCN-32 models, respectively. To obtain better results, we use the Adam optimizer to train and test different architectures, and we obtain more competitive results attaining 99.55%, 99.31%, 99.35% and 99.45% for VGG-Segnet, VGG-Unet, FCN-8 and FCN-32, respectively. The achieved results outperform the state of the art in terms of accuracy and time speed up. Moreover, our proposed CNN segmentation confirms the low computational complexity of the system. In addition, our system proves to be a good candidate for medical real-time applications thanks to its implementation on the GPU.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.115863,Journal,Expert Systems with Applications,scopus,2021-12-30,sciencedirect,Auto-detection of acoustic emission signals from cracking of concrete structures using convolutional neural networks: Upscaling from specimen,https://api.elsevier.com/content/abstract/scopus_id/85114837702,"Acoustic emission (AE) monitoring has gained significant interest as a promising method for monitoring of changes in structural integrity and durability. Long-term AE monitoring needs to detect and distinguish crack signals from ambient noise (or dummy) signals; however, it is still a daunting task which currently limits field implementation of the AE method. Herein, we explore the feasibility of using convolutional neural network (CNN) models to detect AE crack signals from ambient signals. The trained models are validated both with noise-embedded synthesized signals and with upscaled physical model experiments simulating earthquake loading to a scaled model foundation by using a large-scale shaking table. The 2D CNN model trained the laboratory-synthesized signal sets effectively captured the crack and crack-free signals in all cases including the upscaled physical model experiments. This study presents a simple but robust CNN model for pre-filtering of crack signals and a novel training method for enhanced accuracy, which can be applied for real-time structural health monitoring of concrete-based structures.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2021.109371,Journal,Journal of Neuroscience Methods,scopus,2021-12-01,sciencedirect,Development of deep learning models for microglia analyses in brain tissue using DeePathology™ STUDIO,https://api.elsevier.com/content/abstract/scopus_id/85116054792,"Background
                  Interest in artificial intelligence-driven analysis of medical images has seen a steep increase in recent years. Thus, our paper aims to promote and facilitate the use of this state-of-the-art technology to fellow researchers and clinicians.
               
                  New method
                  We present custom deep learning models generated in DeePathology™ STUDIO without the need for background knowledge in deep learning and computer science underlined by practical suggestions.
               
                  Results
                  We describe the general workflow in this commercially available software and present three real-world examples how to detect microglia on IBA1-stained mouse brain sections including their differences, validation results and analysis of a sample slide.
               
                  Comparison with existing methods
                  Deep-learning assisted analysis of histological images is faster than classical analysis methods, and offers a wide variety of detection possibilities that are not available using methods based on staining intensity.
               
                  Conclusions
                  Reduced researcher bias, increased speed and extended possibilities make deep-learning assisted analysis of histological images superior to traditional analysis methods for histological images.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.irbm.2021.06.010,Journal,IRBM,scopus,2021-12-01,sciencedirect,Backpropagation Neural Network for Processing of Missing Data in Breast Cancer Detection,https://api.elsevier.com/content/abstract/scopus_id/85110572168,"Background
                  A complete dataset is essential for biomedical implementation. Due to the limitation of objective or subjective factors, missing data often occurs, which exerts uncertainty in the subsequent data processing. Commonly used methods of interpolation are interpolating substitute values that keep minimum error. Some applications of statistics are usually used for handling this problem.
               
                  Methods
                  We are trying to find a higher performance interpolation method compared with the usual statistic methods, by using artificial intelligence which is in full swing today. The prediction and classification of backpropagation neural network are used in this paper, describes a missing data interpolation method to propose the interpolation model that mines association rules in the data. In the experiment, depending on a multi-layer network structure, the model is trained and tested by sample data, constantly revises network weights and thresholds. The error function decreases along the negative gradient direction and approaches the expected real output. The model is validated on the breast cancer dataset, and we select real samples from the data set for validation, moreover, add four traditional methods as a control group.
               
                  Results
                  The proposed method has great performance improvement in the interpolation of missing data. Experimental results show that the interpolation accuracy of our proposed method (84%) is higher than four traditional methods (1.33%, 74.67%, 73.33%, 77.33%) as mentioned in this paper, BPNN stays low in MSE evaluation. Finally, we analyze the performance of various methods in processing missing data.
               
                  Conclusions
                  The study in this paper has estimated missing data with high accuracy as much as possible to reduce the negative impact in the diagnosis of real life. At the same time, it can also assist in missing data processing in the biomedical field.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2021.107955,Journal,Mechanical Systems and Signal Processing,scopus,2021-12-01,sciencedirect,A novel percussion-based method for multi-bolt looseness detection using one-dimensional memory augmented convolutional long short-term memory networks,https://api.elsevier.com/content/abstract/scopus_id/85104439984,"In the past decade, bolt looseness detection has attracted much attention. Compared to common approaches that require the implementation of constant-contact sensors, several percussion-based methods have demonstrated their superiorities, including low-cost and easy-to-operate, in detecting bolt looseness. However, some drawbacks may impede the further real-world application of percussion-based methods in detecting bolt looseness. First, current percussion-based methods depend on hand-crafted features, which require the extensive experience of operators. In addition, the ability of current percussion-based methods in anti-noising and adaptability is unknown, since no related investigation has been conducted. Moreover, only single-bolt looseness is considered in the current percussion-based investigation. With these deficiencies in mind, in this paper, we propose a novel percussion-based method that uses a newly developed one-dimensional memory augmented convolutional long short-term memory (1D-MACLSTM) networks. Via the convolutional operation in the 1D-MACLSTM, we can avoid manual feature extraction, and the long short-term memory (LSTM) controller backed by external memory can enhance the ability of anti-noising and adaptability. Finally, three case studies are conducted on a pair of typical multi-bolt connections to verify the effectiveness of the proposed method, which has better performance than current percussion-based methods, particularly in a noisy environment and new scenarios.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enconman.2021.114667,Journal,Energy Conversion and Management,scopus,2021-11-15,sciencedirect,Photovoltaic mono and bifacial module/string electrical model parameters identification and validation based on a new differential evolution bee colony optimizer,https://api.elsevier.com/content/abstract/scopus_id/85116895926,"Well estimating the electrical model parameters of the photovoltaic (PV) module/string serves to develop an accurate simulator and a fault diagnosis tool. Several based evolutionary techniques were proposed to identify the unknown circuit equivalent PV generator (PVG) parameters. Whereas most of them have not been examined to various real operating conditions of solar irradiance and PV cells temperature. That requires larger search range than the adopted one in the literature. Enlarging the search range imposes more computational time and high exploration and exploitation features. Hence, a novel hybrid differential evolution and artificial bee colony intelligence (nDEBCO) approach is proposed. In terms of convergence quality, CPU execution time, number of function evaluations (NFE), and error standard deviation (StD). The newly developed approach permits to accurately identify the PV module/string unknown parameters with suitable implementation complexity. Mono-facial CLS 220P PV string has been utilized employing an adequate experimental setup with online implementation. 1080 I-V curves have been measured and estimated, where the overall RMSE ± StD is below 0.02 ± 1e−16. The nDEBCO outperforms the present-day published works, for common case studies in the literature with two based root mean square error (RMSE) objective functions namely Lambert W function (LWF) and classic. It yields 7.73006268e− 4 of RMSE, 7.8785e− 18 of StD, and 2150 NFE under ODM with LWF for RTC France PV cell. Bifacial PV module has been evaluated and the electrical parameters have been extracted within less than 1.36 s of CPU run time and not>8.0299631e− 3 ± 6.9096e− 16 of RMSE ± StD for front and rear faces. Additionally, the parameter identification procedure has been well validated to simulate the real partial shading scenarios of the studied PV string with a RMSE less than 0.045 and 0.397% of power maximum point absolute error.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2021.113486,Journal,Biosensors and Bioelectronics,scopus,2021-11-15,sciencedirect,A mask-based diagnostic platform for point-of-care screening of Covid-19,https://api.elsevier.com/content/abstract/scopus_id/85109504460,"Diagnostics of SARS-CoV-2 infection using real-time reverse-transcription polymerase chain reaction (RT-PCR) on nasopharyngeal swabs is now well-established, with saliva-based testing being lately more widely implemented for being more adapted for self-testing approaches. In this study, we introduce a different concept based on exhaled breath condensate (EBC), readily collected by a mask-based sampling device, and detection with an electrochemical biosensor with a modular architecture that enables fast and specific detection and quantification of COVID-19. The face mask forms an exhaled breath vapor containment volume to hold the exhaled breath vapor in proximity to the EBC collector to enable a condensate-forming surface, cooled by a thermal mass, to coalesce the exhaled breath into a 200–500 μL fluid sample in 2 min. EBC RT-PCR for SARS-CoV-2 genes (E, ORF1ab) on samples collected from 7 SARS-CoV-2 positive and 7 SARS-CoV-2 negative patients were performed. The presence of SARS-CoV-2 could be detected in 5 out of 7 SARS-CoV-2 positive patients. Furthermore, the EBC samples were screened on an electrochemical aptamer biosensor, which detects SARS-CoV-2 viral particles down to 10 pfu mL−1 in cultured SARS-CoV-2 suspensions. Using a “turn off” assay via ferrocenemethanol redox mediator, results about the infectivity state of the patient are obtained in 10 min.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106460,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,Multi-Modality guidance based surgical navigation for percutaneous endoscopic transforaminal discectomy,https://api.elsevier.com/content/abstract/scopus_id/85118353932,"Objective
                  Fluoroscopic guidance is a critical step for the puncture procedure in percutaneous endoscopic transforaminal discectomy (PETD). However, two-dimensional observations of the three-dimensional anatomic structure suffer from the effects of projective simplification. To accurately assess the spatial relations between the patient vertebra tissues and puncture needle, a considerable number of fluoroscopic images from different orientations need to be acquired by the surgeons. This process significantly increases the radiation risk for both the patient and surgeons.
               
                  Methods
                  In this paper, we propose an augmented reality (AR) surgical navigation system for PETD based on multi-modality information, which contains fluoroscopy, optical tracking, and depth camera. To register the fluoroscopic image with the intraoperative video, we design a lightweight non-invasive fiducial with markers and detect the markers based on the deep learning method. It can display the intraoperative video fused with the registered fluoroscopic images. We also present a self-adaptive calibration and transformation method between a 6-DOF optical tracking device and a depth camera, which are in different coordinate systems.
               
                  Results
                  With the substantially reduced frequency of fluoroscopy imaging, the system can accurately track and superimpose the virtual puncture needle on fluoroscopy images in real-time. From operating theatre in vivo animal experiments, the results illustrate that the system average positioning accuracy can reach 1.98mm and the orientation accuracy can reach 1.19
                        
                           
                           ∘
                        
                     . From the clinical validation results, the system significantly lower the frequency of fluoroscopy imaging (42.7%) and reduce the radiation risk for both the patient and surgeons.
               
                  Conclusion
                  Coupled with the user study, both the quantitative and qualitative results indicate that our navigation system has the potential to be highly useful in clinical practice. Compared with the existing navigation systems, which are usually equipped with a variety of large and high-cost medical equipments, such as O-arm, cone-beam CT, and robots, our navigation system does not need special equipment and can be implemented with common equipment in the operating room, such as C-arm, desktop, etc., even in small hospitals.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106464,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-11-01,sciencedirect,Deep embeddings and logistic regression for rapid active learning in histopathological images,https://api.elsevier.com/content/abstract/scopus_id/85118333751,"Background and Objective
                  Recognizing different tissue components is one of the most fundamental and essential works in digital pathology. Current methods are often based on convolutional neural networks (CNNs), which need numerous annotated samples for training. Creating large-scale histopathological datasets is labor-intensive, where interactive data annotation is a potential solution.
               
                  Methods
                  We propose DELR (Deep Embedding-based Logistic Regression) to enable rapid model training and inference for histopathological image analysis. DELR utilizes a pretrained CNN to encode images as compact embeddings with low computational cost. The embeddings are then used to train a Logistic Regression model efficiently. We implemented DELR in an active learning framework, and validated it on three histopathological problems (binary, 4-category, and 8-category classification challenge for lung, breast, and colorectal cancer, respectively). We also investigated the influence of active learning strategy and type of the encoder.
               
                  Results
                  On all the three datasets, DELR can achieve an area under curve (AUC) metric higher than 0.95 with only 100 image patches per class. Although its AUC is slightly lower than a fine-tuned CNN counterpart, DELR can be 536, 316, and 1481 times faster after pre-encoding. Moreover, DELR is proved to be compatible with a variety of active learning strategies and encoders.
               
                  Conclusions
                  DELR can achieve comparable accuracy to CNN with rapid running speed. These advantages make it a potential solution for real-time interactive data annotation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jprocont.2021.10.006,Journal,Journal of Process Control,scopus,2021-11-01,sciencedirect,OASIS-P: Operable Adaptive Sparse Identification of Systems for fault Prognosis of chemical processes,https://api.elsevier.com/content/abstract/scopus_id/85118170677,"With the increasing process complexities, data-driven fault prognosis has emerged as a promising fault management tool that predicts and manages abnormal events well in advance. In this paper, we develop a fault prognosis framework named ‘OASIS-P’ by integrating operable adaptive sparse identification of systems (OASIS), which is a data-driven adaptive modeling technique, with a risk-based process monitoring approach and contribution plots. Firstly, OASIS is employed with the risk assessment procedure for the prediction of impending faults. As the OASIS model is adaptive, it copes with the initial fault symptoms and forecasts the future behavior of the process under faulty conditions reasonably well, thereby providing an early fault prediction. Next, the fault isolation step is immediately initiated using contribution plots to identify the faulty variables. Unlike in fault diagnosis, the problem of ambiguity in interpreting contribution results due to fault propagation is not an issue in fault prognosis, if the fault isolation step is implemented at an early stage of the fault before it affects the other variables. Hence, the contribution plots together with OASIS can proactively monitor the process in real-time. As a case study, we demonstrate OASIS-P for fault prognosis of a reactor–separator system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.104914,Journal,Computers in Biology and Medicine,scopus,2021-11-01,sciencedirect,Integrating multi-domain deep features of electrocardiogram and phonocardiogram for coronary artery disease detection,https://api.elsevier.com/content/abstract/scopus_id/85116650381,"Electrocardiogram (ECG) and phonocardiogram (PCG) are both noninvasive and convenient tools that can capture abnormal heart states caused by coronary artery disease (CAD). However, it is very challenging to detect CAD relying on ECG or PCG alone due to low diagnostic sensitivity. Recently, several studies have attempted to combine ECG and PCG signals for diagnosing heart abnormalities, but only conventional manual features have been used. Considering the strong feature extraction capabilities of deep learning, this paper develops a multi-input convolutional neural network (CNN) framework that integrates time, frequency, and time-frequency domain deep features of ECG and PCG for CAD detection. Simultaneously recorded ECG and PCG signals from 195 subjects are used. The proposed framework consists of 1-D and 2-D CNN models and uses signals, spectrum images, and time-frequency images of ECG and PCG as inputs. The framework combining multi-domain deep features of two-modal signals is very effective in classifying non-CAD and CAD subjects, achieving an accuracy, sensitivity, and specificity of 96.51%, 99.37%, and 90.08%, respectively. The comparison with existing studies demonstrates that our method is very competitive in CAD detection. The proposed approach is very promising in assisting the real-world CAD diagnosis, especially under general medical conditions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103922,Journal,Journal of Biomedical Informatics,scopus,2021-11-01,sciencedirect,Predicting potential palliative care beneficiaries for health plans: A generalized machine learning pipeline,https://api.elsevier.com/content/abstract/scopus_id/85116551006,"Recognizing that palliative care improves the care quality and reduces the healthcare costs for individuals in their end of life, health plan providers strive to better enroll the appropriate target population for palliative care. Current research has not adequately addressed challenges related to proactively select potential palliative care beneficiaries from a population health perspective. This study presents a Generalized Machine Learning Pipeline (GMLP) to predict palliative needs in patients using administrative claims data. The GMLP has five steps: data cohort creation, feature engineering, predictive modeling, scoring beneficiaries, and model maintenance. It encapsulates principles of population health management, business domain knowledge, and machine learning (ML) process knowledge with an innovative data pull strategy. The GMLP was applied in a regional health plan using a data cohort of 17,197 patients. Multiple ML models were turned and evaluated against a custom performance metric based on the business requirement. The best model was an AdaBoost model with a precision of 71.43% and a recall of 67.98%. The post-implementation evaluation of the GMLP showed that it increased the recall of high mortality risk patients, improved their quality of life, and reduced the overall cost. The GMLP is a novel approach that can be applied agnostically to the data and specific ML algorithms. To the best of our knowledge, it is the first attempt to continuously score palliative care beneficiaries using administrative data. The GMLP and its use case example presented in the paper can serve as a methodological guide for different health plans and healthcare policymakers to apply ML in solving real-world clinical challenges, such as palliative care management and other similar risk-stratified care management workflows.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.psep.2021.09.008,Journal,Process Safety and Environmental Protection,scopus,2021-11-01,sciencedirect,Graph convolutional networks based contamination source identification across water distribution networks,https://api.elsevier.com/content/abstract/scopus_id/85115991403,"Water distribution Networks (WDNs) are one of the most important infrastructures for modern society. Due to accidental or malicious reasons, water contamination incidents have been repeatedly reported all over the world, which not only disrupt the water supply but also endanger public health. To ensure the safety of WDNs, water quality sensors are deployed across the WDNs for real-time contamination detection and source identification. In the literature, various methods have been employed to improve the performance of contamination source identification (CSI) and recent studies show that there is a great potential to tackle the CSI problem by deep learning models. The success of deep learning based CSI methods often requires a large size of training samples being collected. In real-world situations, the number of contamination events occurring in a single WDN is rather small, especially for a newly built WDN. However, the existing CSI methods in the literature mostly focus on the study of training and applying models on the same WDNs and the knowledge of CSI gained from one WDN cannot be reused by a different WDN. To these ends, based on the application of graph convolutional networks, this paper provides a solution for cross-network CSI that can transfer the CSI knowledge learned from one WDN to a different WDN. Empirically, based on a benchmark WDN in the task of contamination source identification, we show that the proposed cross-network CSI method can achieve comparable accuracy even trained on a different WDN.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.psj.2021.101437,Journal,Poultry Science,scopus,2021-11-01,sciencedirect,Pharmacokinetic/pharmacodynamic profiles of baicalin against Mycoplasma gallisepticum in an in vivo infection model,https://api.elsevier.com/content/abstract/scopus_id/85115144118,"Mycoplasma gallisepticum (
                        M. gallisepticum
                     ), a devastating avian pathogen that commonly causes chronic respiratory disease in chicken, is responsible for tremendous economic losses to the poultry industry. Baicalin is the main constituent of Scutellaria baicalensis that shows potential therapeutic effects against M. gallisepticum. However, the pharmacokinetic/pharmacodynamics (PK/PD) profiles of baicalin against M. gallisepticum are not well understood. The main objective of the present study was to determine the relationship between the PK/PD index and efficacy of baicalin in the M. gallisepticum infection model in chickens. The experiments were carried out on 10-day-old chickens that were challenged with M. gallisepticum in the bilateral air sacs. While, baicalin was orally administrated once in a day for 3 consecutive days, started from d 3 postinfection. Ultra-performance liquid chromatography (UPLC) was used to evaluate the PK parameters of baicalin at doses of 200, 400, and 600 mg/kg in M. gallisepticum-infected chickens. Real-time PCR (RT-PCR) was used for the quantitative detection of M. gallisepticum in lungs. The PK and PD data were fitted to WinNonlin software to evaluate the PK/PD profiles of baicalin against M. gallisepticum. The minimum inhibitory concentration (MIC) of baicalin against M. gallisepticum strain Rlow was 31.25 µg/mL. The in vivo data suggested that baicalin concentration in the lung tissues was higher than plasma (1.21–1.73 times higher). The ratios of AUC24h/MIC of baicalin against bacteriostatic, bactericidal, and eradication were 0.62, 1.33, and 1.49 h, respectively. In conclusion, these results provided potential reference for future clinical dose selection of baicalin and evaluation of susceptibility breakpoints.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2021.114272,Journal,Journal of Virological Methods,scopus,2021-11-01,sciencedirect,A rapid and simple protocol for concentration of SARS-CoV-2 from sewage,https://api.elsevier.com/content/abstract/scopus_id/85113952280,"The aim of this study was to set up a simple protocol to concentrate SARS-CoV-2 from sewage, which can be implemented in laboratories with minimal equipment resources. The method avoids the need for extensive purification steps and reduces the concentration of potential inhibitors of RT-qPCR contained in sewage. The concentration method consists of a single step, in which a small volume (40 mL) of sewage sample is incubated with polyaluminum chloride (PAC)(0.00045 N Al3+ final concentration). Virus particles adsorbed to the precipitate are collected by low-speed centrifugation, after which the recovered pellet is resuspended with a saline buffer. PAC-concentrated samples are stable for at least one week at 4 °C. Therefore, they may be sent refrigerated to a diagnosis center for RNA extraction and RT-qPCR for SARS-CoV-2 RNA detection if the lab does not have such capabilities. The PAC concentration method produced an average shift of 4.5-units in quantification cycle (Cq) values compared to non-concentrated samples, indicating a 25-fold increase in detection sensitivity. The lower detection limit corresponded approximately to 100 viral copies per ml. Kappa index indicated substantial agreement between PAC and polyethylene glycol (PEG) precipitation protocols (k = 0.688, CI 0.457−0.919). This low-cost concentration protocol could be useful to aid in the monitoring of community circulation of SARS-CoV-2, especially in low- and middle-income countries, which do not have massive access to support from specialized labs for sewage surveillance.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103215,Journal,Sustainable Cities and Society,scopus,2021-11-01,sciencedirect,IoHT-enabled gliomas disease management using fog Computing computing for sustainable societies,https://api.elsevier.com/content/abstract/scopus_id/85111854275,"The proliferation of sensor-based applications in healthcare has given rise to Internet of Health Things (IoHT) that improves patient safety, staff morale, and operational efficiency. Edge-fog computing has seen significant development in recent years and supports the association of various intelligent things with sensors for establishing smooth data transfer. However, it becomes challenging for edge-fog computing to tackle diverse IoHT settings such as efficient disease management, emergency response management, etc. The key limitation of existing architectures is the restricted scalability and inability to meet the demands of hierarchical computing environments for IoHT. This is because latency-sensitive applications often require large quantities of data to be measured and transferred to the data centers, which causes delay and reduced output. This research proposes a novel edge-fog computing framework for the convergence of machine learning ensemble with edge-fog computing. The proposed architecture delivers healthcare as a fog system that handles data from different sources to manage the diseases effectively. The proposed framework is used for the real-life implementation and automatic detection of gliomas diseases. Glioma is a kind of tumor, which ensues in the spinal cord and a portion of the brain. Glioma instigates in the glial cells that surround the nerve cells. The proposed edge-fog framework efficiently manages the real-time data related to gliomas. This framework is configured for specific operating modes including diverse edge-fog scenarios, different user requirements, quality of service, precision, and predictive accuracy. The proposed framework is evaluated using real-time datasets from various sources and experimentally tested with reliable datasets that disclose the effectiveness of the proposed architecture. The performance of the proposed model is evaluated in terms of power consumption, latency, accuracy, and execution time, respectively.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jelectrocard.2021.07.012,Journal,Journal of Electrocardiology,scopus,2021-11-01,sciencedirect,Novel ECG features and machine learning to optimize culprit lesion detection in patients with suspected acute coronary syndrome,https://api.elsevier.com/content/abstract/scopus_id/85111533630,"Background
                  Novel temporal-spatial features of the 12‑lead ECG can conceptually optimize culprit lesions' detection beyond that of classical ST amplitude measurements. We sought to develop a data-driven approach for ECG feature selection to build a clinically relevant algorithm for real-time detection of culprit lesion.
               
                  Methods
                  This was a prospective observational cohort study of chest pain patients transported by emergency medical services to three tertiary care hospitals in the US. We obtained raw 10-s, 12‑lead ECGs (500 s/s, HeartStart MRx, Philips Healthcare) during prehospital transport and followed patients 30 days after the encounter to adjudicate clinical outcomes. A total of 557 global and lead-specific features of P-QRS-T waveform were harvested from the representative average beats. We used Recursive Feature Elimination and LASSO to identify 35/557, 29/557, and 51/557 most recurrent and important features for LAD, LCX, and RCA culprits, respectively. Using the union of these features, we built a random forest classifier with 10-fold cross-validation to predict the presence or absence of culprit lesions. We compared this model to the performance of a rule-based commercial proprietary software (Philips DXL ECG Algorithm).
               
                  Results
                  Our sample included 2400 patients (age 59 ± 16, 47% female, 41% Black, 10.7% culprit lesions). The area under the ROC curves of our random forest classifier was 0.85 ± 0.03 with sensitivity, specificity, and negative predictive value of 71.1%, 84.7%, and 96.1%. This outperformed the accuracy of the automated interpretation software of 37.2%, 95.6%, and 92.7%, respectively, and corresponded to a net reclassification improvement index of 23.6%. Metrics of ST80; Tpeak-Tend; spatial angle between QRS and T vectors; PCA ratio of STT waveform; T axis; and QRS waveform characteristics played a significant role in this incremental gain in performance.
               
                  Conclusions
                  Novel computational features of the 12‑lead ECG can be used to build clinically relevant machine learning-based classifiers to detect culprit lesions, which has important clinical implications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2021.105407,Journal,Safety Science,scopus,2021-11-01,sciencedirect,Highway 4.0: Digitalization of highways for vulnerable road safety development with intelligent IoT sensors and machine learning,https://api.elsevier.com/content/abstract/scopus_id/85111074950,"According to United Nations (UN) 2030 agenda, the transportation system needs to be enhanced for the establishment of access to safe, affordable, accessible, and sustainable transport systems along with enhanced road safety. The highway road transport system is one of the transport systems that enables to transits goods and humans from one location to another location. The agenda of UN 2030 for the transport system will be accomplished with the assistance of digital technologies like the internet of things (IoT) and artificial intelligence (AI). The implementation of these digital technologies on highways empowers to provide reliable, smarter, intelligent, and renewable energy sources experience to the users travelling along the highways. This study discusses the significance of the digitalization of highways that supporting and realizing a sustainable environment on the highways. To discuss the significance of digitalization, the study has categorized digitalization into five subcomponents namely smart highway lighting system, smart traffic and emergency management system, renewable energy sources on highways, smart display and AI in highways. An architecture-for smart highway lighting, smart traffic, and emergency management are proposed and discussed in the study. The significance of implementing smart display boards and renewable sources with real-time applications is also addressed in this study. Moreover, the integration of AI in highways is addressed with the perspective of enhancing road safety. The integration of deep learning (DL) in the edge-based vision node for predicting the patterns of traffic flow, highway road safety, and maintenance of quality roads have been addressed in the discussion section. Embedding the deep learning techniques in the vison node at the traffic junction and the highway lighting controller is able to deliver an intelligent system that provides sustained experience and management of the highways. Smart reflectors, adoption of renewable energy, developing vehicle-to-vehicle communication in vehicles, and smart lamppost are the few recommendations for the implementation of digitalizing highways.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.actaastro.2021.07.012,Journal,Acta Astronautica,scopus,2021-11-01,sciencedirect,"A review of space surgery - What have we achieved, current challenges, and future prospects",https://api.elsevier.com/content/abstract/scopus_id/85110745640,"Major surgical events/incidents onboard are rare but can be catastrophic to any mission. National Aeronautics and Space Administration (NASA) uses the Integrated Medical Model (IMM) to develop an integrated, quantified, evidence-based decision support tool useful for crew health and mission planners to assess risk and design medical systems. In 2017, the IMM of the NASA Human Research Program included a list of 100 medical conditions that could be anticipated during space flight. Of those conditions, 27 are expected to need surgical treatment. Consequently, there has been a continuing interest in surgical capabilities for exploration space flight. The surgical system capabilities aboard all space stations and analogue flights have been designed and implemented with an emphasis on stabilisation, medical evacuation, and ATLS capabilities. However, with future missions to the Moon and Mars, evacuation is not a possibility and astronauts will need to troubleshoot, adapt, and self-administer complex surgical care autonomously.
                  This narrative review aims to examine the published work on surgical care in space, discuss the inherent challenges, and identify scope for future studies. The review evaluates and analyses results from several landmark experiments covering important technical aspects such as basic surgical skills, laparoscopic surgery, robotic surgery, and tele surgery. Relevant studies for the review were identified from the MEDLINE, PubMed, and EMBASE databases. Eligible studies were published between 1960 and June 2021 and were identified using the terms “space surgery”, “microgravity”, “zero gravity”, “weightlessness”, “parabolic flight”, “neutral buoyancy”, and “spaceflight”. Only articles in English were selected and references cited in the selected publications were followed up and included where appropriate. Documents available in the public domain and/or archives of National Space agencies were also included. The search yielded a total of 86 hits including review articles, commentaries, studies, meeting summaries and technical reports submitted to National Space agencies. Results were then filtered for eligible papers relevant to this narrative review. Challenges on a long-duration mission will be unique, unlike anything we have faced so far in the last 60 years of space travel. Despite the progress in space surgery in the last 40 years, there are several challenges to achieving a fully functional surgical care system on any mission outside Low Earth Orbit. The microgravity environment presents unique challenges related to altered physiology as well as mechanics and techniques pertinent to surgical care. Some of the challenges include but are not limited to crew selection, role of prophylactic surgery, adaptation to zero gravity, lack of ground support, training and maintenance of surgical skills and limitation of weight and volume for hardware. Ultrasound imaging, 3D printing and AI-based surgical assistance coupled with robotic surgery have shown promise, but their real efficacy and functionality remains to be tested.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.virusres.2021.198505,Journal,Virus Research,scopus,2021-10-02,sciencedirect,A point-of-care rapid HIV-1 test using an isothermal recombinase-aided amplification and CRISPR Cas12a-mediated detection,https://api.elsevier.com/content/abstract/scopus_id/85110743698,"Human immunodeficiency virus type one (HIV-1) infection is one of the major public health problems worldwide. Effective control of HIV-1 epidemic relies on early diagnosis of HIV-1 infection by using simple, rapid point-of-care test (POCT). An integrated assay was developed and evaluated in this study to combine a real-time isothermal reverse-transcription recombinase-aided amplification (rRT-RAA) and CRISPR Cas12a-mediated detection for HIV-1. The testing results could be directly observed with naked eye using a blue light imager, making it a suitable on-site testing assay. Our preliminary data indicated that the assay was capable of detecting 20 copies of purified HIV-1 DNA or RNA per reaction or as low as 123 copies/ml of HIV-1 viral load in clinical samples. When screening 155 clinical samples with or without HIV-1 infection, the sensitivity and specificity of the rRT-RAA assay were 98.95% (94/95) and 100% (60/60), respectively. The coefficient value was 0.986 when compared with the Chinese FDA approved HIV-1 RT-qPCR assay. Furthermore, the newly developed HIV-1 rRT-RAA assay could detect the major HIV-1 genotypes CRF01_AE, CRF07_BC, CRF08_BC, CRF08_BC and subtype B in China. Our preliminary results indicated that the rRT-RAA assay or its combination with CRISPR Cas12a-mediated detection could serve as a rapid, convenient, and robust assay for HIV-1 detection.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2021.102151,Journal,Artificial Intelligence in Medicine,scopus,2021-10-01,sciencedirect,Optimizing the setting of medical interactive rehabilitation assistant platform to improve the performance of the patients: A case study,https://api.elsevier.com/content/abstract/scopus_id/85114984743,"Tele-rehabilitation is an alternative to the conventional rehabilitation service that helps patients in remote areas to access a service that is practical in terms of logistics and cost, in a controlled environment. It includes the usage of mobile phones or other wireless devices that are applied to rehabilitation exercises. Such applications or software include exercises in the form of virtual games, treatment monitoring based on the rehabilitation progress and data analysis. However, nowadays, physiotherapists use a default profiling setting for patients carrying out rehabilitation, due to lack of information. Medical Interactive Rehabilitation Assistant (MIRA) is a computer-based (virtual reality) rehabilitation platform. The profile setting includes: a level of difficulty, percentage of tolerance and maximum range. To the best of our knowledge, there is a lack of optimization in the parameter values setting of MIRA exergames that could enhance patients' performance. Generally, non-optimal profile setting leads to reduced effectiveness. Therefore, this study aims to develop a method that optimizes the profile setting of each patient according to the estimated (desired) optimal results. The proposed method is developed using unsupervised and supervised machine learning techniques. We use Self-Organizing Map (SOM) to cluster patient records into several distinct clusters. K-fold cross validation is applied to construct the prediction models. Classification And Regression Tree (CART) is utilized to predict the patient's optimal input setting for playing the MIRA games. The combination of these techniques seems to improve the efficiency of the standard (default) way in predicting the optimal settings for exergames. To evaluate the proposed method, we conduct an experiment with data collected from a rehabilitation center. We use three metrics to quantify the quality of the results: R-squared (R2), Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). The results of experimental analysis demonstrate that the proposed method is effective in predicting the adequate parameter setting in MIRA platform. The method has potential to be implemented as an intelligent system for MIRA prediction in healthcare. Moreover, the method could be extended to similar platforms for which data is available to train our method on.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejon.2021.102023,Journal,European Journal of Oncology Nursing,scopus,2021-10-01,sciencedirect,Developing and validating a prediction model for lymphedema detection in breast cancer survivors,https://api.elsevier.com/content/abstract/scopus_id/85114224581,"Purpose
                  Early detection and intervention of lymphedema is essential for improving the quality of life of breast cancer survivors. Previous studies have shown that patients have symptoms such as arm tightness and arm heaviness before experiencing obvious limb swelling. Thus, this study aimed to develop a symptom-warning model for the early detection of breast cancer-related lymphedema.
               
                  Methods
                  A cross-sectional study was conducted at a tertiary hospital in Beijing between April 2017 and December 2018. A total of 24 lymphedema-associated symptoms were identified as candidate predictors. Circumferential measurements were used to diagnose lymphedema. The data were randomly split into training and validation sets with a 7:3 ratio to derive and evaluate six machine learning models. Both the discrimination and calibration of each model were assessed on the validation set.
               
                  Results
                  A total of 533 patients were included in the study. The logistic regression model showed the best performance for early detection of lymphedema, with AUC = 0.889 (0.840–0.938), sensitivity = 0.771, specificity = 0.883, accuracy = 0.825, and Brier scores = 0.141. Calibration was also acceptable. It has been deployed as an open-access web application, allowing users to estimate the probability of lymphedema individually in real time. The application can be found at https://apredictiontoolforlymphedema.shinyapps.io/dynnomapp/.
               
                  Conclusion
                  The symptom-warning model developed by logistic regression performed well in the early detection of lymphedema. Integrating this model into an open-access web application is beneficial to patients and healthcare providers to monitor lymphedema status in real-time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2021.107702,Journal,Applied Soft Computing,scopus,2021-10-01,sciencedirect,OrbitNet: A new CNN model for automatic fault diagnostics of turbomachines,https://api.elsevier.com/content/abstract/scopus_id/85111487515,"Unplanned outage due to faults in a high-fidelity turbomachine such as steam turbine and centrifugal compressor often results in the reduced reliability and productivity of a factory while increasing its maintenance costs. Shaft orbit images generated from turbomachine vibration signals have been used to diagnose component faults. However, the existing methods were developed mostly by either using features extracted from orbits or utilizing simulation data which may produce inaccurate results in practical applications due to system complexity and data uncertainties. This paper presents a novel deep learning convolution neural network methodology for accurately automatic diagnostics of multiple faults in general rotating machines by adeptly integrating advanced signal processing with orbit images augmentation, considering the high non-linearity and uncertainty of sensed vibration signals. Environmental noise in vibration signals are filtered through the integration of multiresolution discrete wavelet packet transform and Bayesian hypothesis testing-based automatic thresholding. Shaft orbit images generated from the cleansed vibration data are augmented to increase their representativity and generalization. A novel multi-layer convolutional neural network model, OrbitNet, is specially designed to improve its generality and robustness while avoid possible overfitting in fault identification of various turbomachines. The proposed model retains the pattern information in the axis trajectory to the greatest extent, with the ability of accurately capturing features of various faults in different turbomachines. A generic implementation procedure is proposed for automatic fault diagnosis of rotating machinery based on the presented methodology. A comparison study is conducted to demonstrate the effectiveness and feasibility of the proposed methodology by using the sensed vibration signals collected from three real-world centrifugal compressors, two steam turbines and one generator with four different fault modes including imbalance, friction, misalignment and oil whirl.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envsci.2021.06.011,Journal,Environmental Science and Policy,scopus,2021-10-01,sciencedirect,A Big Data and Artificial Intelligence Framework for Smart and Personalized Air Pollution Monitoring and Health Management in Hong Kong,https://api.elsevier.com/content/abstract/scopus_id/85111282536,"All people in the world are entitled to enjoy a clean environment and a good quality of life. With big data and artificial intelligence technologies, it is possible to estimate personalized air pollution exposure and synchronize it with activity, health, quality of life and behavioural data, and provide real-time, personalized and interactive alert and advice to improve the health and well-being of individual citizens. In this paper, we propose an overarching framework outlining five major challenges to personalized air pollution monitoring and health management, and respective methodologies in an integrated interdisciplinary manner. First, urban air quality data is sparse, rendering it difficult to provide timely personalized alert and advice. Second, collected data, especially those involving human inputs such as health perception, are often missing and erroneous. Third, the data collected are heterogeneous, and highly complex, not easily comprehensible to facilitate individual and collective decision-making. Fourth, the causal relationships between personal air pollutants exposure (specifically, PM2.5 and PM1.0 and NO2) and personal health conditions, and health-related quality of life perception, of young asthmatics and young healthy citizens in Hong Kong (HK), are yet to be established. Fifth, whether personalized and smart information and advice provided can induce behavioural change and improve health and quality of life are yet to be determined. To overcome these challenges, our first novelty is to develop an AI and big data framework to estimate and forecast air quality in high temporal-spatial resolution and real-time. Our second novelty includes the deployment of mobile pollution sensor platforms to substantially improve the accuracy of estimated and forecasted air quality data, and the collection of activity, health condition and perception data. Our third novelty is the development of visualization tools and comprehensible indexes, by correlating personal exposure with four types of personal data, to provide timely, personalized pollution, health and travel alerts and advice. Our fourth novelty is determining causal relationship, if any, between personal pollutants, PM1.0 and PM2.5, NO2 exposure and personal health condition, and personal health perception, based on a clinical experiment of 150 young asthmatics and 150 young healthy citizens in HK. Our fifth novelty is an intervention study to determine if smart information, presented via our proposed visualized platform, will induce personal behavioural change. Our novel big data AI-driven approach, when integrated with other analytical approaches, provides an integrated interdisciplinary framework for personalized air pollution monitoring and health management, easily transferrable to and applicable in other domains and countries.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2021.114241,Journal,Journal of Virological Methods,scopus,2021-10-01,sciencedirect,SARS-CoV-2 saliva testing is a useful tool for Covid-19 diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85111012231,"SARS-CoV-2 is the etiologic agent of coronavirus disease 2019 (COVID-19) and is mainly detected by RT-PCR methods from upper respiratory specimens, as recommended by the World Health Organization. Oro/nasopharyngeal swabbing can be discomfortable to the patients, requires trained healthcare personnel and may generate aerosol, increasing the risk of nosocomial infections. In this study, we describe two SARS-CoV-2 RNA extraction-free single RT-PCR protocols on saliva samples and compared the results with the paired oro/nasopharyngeal swab specimens from 400 patients. The two saliva protocols demonstrated a substantial agreement when compared to the oro/nasopharyngeal swab protocol. Moreover, the positivity rate of saliva protocols increased according to the disease period. The 95 % limit of detection of one of the therefore implemented saliva protocol was determined as 9441 copies/mL. Our results support the conclusion that RNA extraction-free RT-PCR using self-collected saliva specimens is an alternative to nasopharyngeal swabs, especially in the early phase of symptom onset.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcot.2021.06.036,Journal,Revue de Chirurgie Orthopedique et Traumatologique,scopus,2021-10-01,sciencedirect,Virtual preoperative planning of acetabular fractures using patient-specific biomechanical simulation: A case-control study,https://api.elsevier.com/content/abstract/scopus_id/85110536437,"Introduction
                  Le premier modèle biomécanique patient-spécifique pour la planification de la réduction chirurgicale des fractures de l’acétabulum a été developpé dans notre institution. Aucune étude antérieure n’a encore démontré son efficacité en terme de réduction chirurgicale, de durée opératoire et de saignement opératoire. L’objectif principal de cette étude cas-témoin était : 1) d’évaluer l’effet de la simulation préopératoire par simulateur biomécanique patient-spécifique sur la durée opératoire et le saignement peropératoire ; 2) d’évaluer l’effet de la simulation préopératoire par simulateur biomécanique patient-spécifique sur la qualité de la réduction.
               
                  Methode
                  Tous les patients opérés entre janvier 2019 et juin 2019 après planification par simulation biomécanique étaient inclus dans cette étude cas-témoin. Chaque patient inclus était apparié à 2 patients issus de notre base de données (2015–2018) selon des critères d’âge et de variété fracturaire. Les données DICOM étaient extraites des scanners haute-résolutions préopératoires pour construire un modèle tridimensionnel de la fracture par segmentation semi-automatique. Un modèle biomécanique était construit pour simuler virtuellement les différentes étapes de la réduction chirurgicale. La chirurgie était ensuite réalisée conformément aux données de la simulation. La durée opératoire, les pertes sanguines, les résultats radiologiques et les complications peropératoires étaient enregistrés, analysés et comparés.
               
                  Resultats
                  Trente patients étaient inclus, 10 dans le groupe simulation et 20 dans le groupe témoin. Les deux groupes étaient comparables en termes d’âge, de délai accident-chirugie, de variétés fracturaires et d’approche chirurgicale. La durée opératoire moyenne était significativement réduite dans le groupe simulation : 113min±33 (60–180) versus 196±32 (60–260) (p
                     =0,01). La perte sanguine moyenne était significativement réduite dans le groupe simulation : 505mL±189 (100–750) versus 745mL±130 (200–850) (p
                     <0,01). En revanche, aucune différence significative n’était retrouvée concernant les résultats radiologiques, selon les critères de Matta, bien qu’une réduction anatomique était obtenue pour 9 patients du groupe simulation (90 %) versus 12 patients du groupe témoin (60 %) (p
                     =0,26). Une complication neurologique postopératoire était enregistrée dans le groupe témoin (déficit sensitif du nerf cutané latéral de cuisse).
               
                  Conclusion
                  Cette étude confirme les résultats prometteurs de la planification préopératoire en chirurgie traumatologique de l’acétabulum à partir d’une simulation biomécanique patient-spécifique ainsi que sa faisabilité en routine clinique. En permettant une meilleure compréhension de la fracture et de son comportement, elle permet une réduction de la durée et du saignement peropératoires.
               
                  Niveau de preuve
                  III ; étude cas-témoin.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2021.107766,Journal,Mechanical Systems and Signal Processing,scopus,2021-10-01,sciencedirect,An artificial neural network methodology for damage detection: Demonstration on an operating wind turbine blade,https://api.elsevier.com/content/abstract/scopus_id/85102975974,"This study presents a novel artificial neural network (ANN) based methodology within a vibration-based structural health monitoring framework for robust damage detection. The ANN-based methodology establishes the nonlinear relationships between selected damage sensitive features (DSF) influenced by environmental and operational variabilities (EOVs) and their corresponding novelty indices computed by the Mahalanobis distance (MD). The ANN regression model is trained and validated based on a reference state (i.e., a healthy structure). The trained model is used to predict the corresponding MD of new observations. The prediction error between the calculated and predicted MD is used as a new novelty index for damage detection. Firstly, an artificial 2D feature set is generated to illustrate how the limitations of solely using the MD-based novelty index can be overcome by the proposed ANN-based methodology. Secondly, the methodology is implemented in data obtained from an in-operation wind turbine with different artificially induced damage scenarios in one of its blades. Finally, the performance of the proposed methodology is evaluated by the metrics of accuracy, F1-score and Matthews correlation coefficient. The results demonstrate the advantages of the proposed methodology by improving damage detectability in all the different damage scenarios despite the influence of EOVs in both the simulated and real data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.xpro.2021.100639,Journal,STAR Protocols,scopus,2021-09-17,sciencedirect,Timesias: A machine learning pipeline for predicting outcomes from time-series clinical records,https://api.elsevier.com/content/abstract/scopus_id/85108953840,"The prediction of outcomes is a critical part of the clinical surveillance for hospitalized patients. Here, we present Timesias, a machine learning pipeline which predicts outcomes from real-time sequential clinical data. The strategy implemented in Timesias is the first-place solution in the crowd-sourcing DII (discover, innovate, impact) National Data Science Challenge involving more than 100,000 patients, achieving 0.85 as evaluated by AUROC (area under receiver operator characteristic curve) in predicting the early onset of sepsis status. Timesias is freely available via PyPI and GitHub.
                  For complete details on the use and execution of this protocol, please refer to Guan et al. (2021).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2666-5247(21)00143-9,Journal,The Lancet Microbe,scopus,2021-09-01,sciencedirect,Comparative performance of SARS-CoV-2 lateral flow antigen tests and association with detection of infectious virus in clinical specimens: a single-centre laboratory evaluation study,https://api.elsevier.com/content/abstract/scopus_id/85128475543,"Background
                  Lateral flow devices (LFDs) for rapid antigen testing are set to become a cornerstone of SARS-CoV-2 mass community testing, although their reduced sensitivity compared with PCR has raised questions of how well they identify infectious cases. Understanding their capabilities and limitations is, therefore, essential for successful implementation. We evaluated six commercial LFDs and assessed their correlation with infectious virus culture and PCR cycle threshold (Ct) values.
               
                  Methods
                  In a single-centre, laboratory evaluation study, we did a head-to-head comparison of six LFDs commercially available in the UK: Innova Rapid SARS-CoV-2 Antigen Test, Spring Healthcare SARS-CoV-2 Antigen Rapid Test Cassette, E25Bio Rapid Diagnostic Test, Encode SARS-CoV-2 Antigen Rapid Test Device, SureScreen COVID-19 Rapid Antigen Test Cassette, and SureScreen COVID-19 Rapid Fluorescence Antigen Test. We estimated the specificities and sensitivities of the LFDs using stored naso-oropharyngeal swabs collected at St Thomas' Hospital (London, UK) for routine diagnostic SARS-CoV-2 testing by real-time RT-PCR (RT-rtPCR). Swabs were from inpatients and outpatients from all departments of St Thomas' Hospital, and from health-care staff (all departments) and their household contacts. SARS-CoV-2-negative swabs from the same population (confirmed by RT-rtPCR) were used for comparative specificity determinations. All samples were collected between March 23 and Oct 27, 2020. We determined the limit of detection (LOD) for each test using viral plaque-forming units (PFUs) and viral RNA copy numbers of laboratory-grown SARS-CoV-2. Additionally, LFDs were selected to assess the correlation of antigen test result with RT-rtPCR Ct values and positive viral culture in Vero E6 cells. This analysis included longitudinal swabs from five infected inpatients with varying disease severities. Furthermore, the sensitivities of available LFDs were assessed in swabs (n=23; collected from Dec 4, 2020, to Jan 12, 2021) confirmed to be positive (RT-rtPCR and whole-genome sequencing) for the B.1.1.7 variant, which was the dominant genotype in the UK at the time of study completion.
               
                  Findings
                  All LFDs showed high specificity (≥98·0%), except for the E25Bio test (86·0% [95% CI 77·9–99·9]), and most tests reliably detected 50 PFU/test (equivalent SARS-CoV-2 N gene Ct value of 23·7, or RNA copy number of 3 × 106/mL). Sensitivities of the LFDs on clinical samples ranged from 65·0% (55·2–73·6) to 89·0% (81·4–93·8). These sensitivities increased to greater than 90% for samples with Ct values of lower than 25 for all tests except the SureScreen fluorescence (SureScreen-F) test. Positive virus culture was identified in 57 (40·4%) of 141 samples; 54 (94·7%) of the positive cultures were from swabs with Ct values lower than 25. Among the three LFDs selected for detailed comparisons (the tests with highest sensitivity [Innova], highest specificity [Encode], and alternative technology [SureScreen-F]), sensitivity of the LFDs increased to at least 94·7% when only including samples with detected viral growth. Longitudinal studies of RT-rtPCR-positive samples (tested with Innova, Encode, and both SureScreen-F and the SureScreen visual [SureScreen-V] test) showed that most of the tests identified all infectious samples as positive. Test performance (assessed for Innova and SureScreen-V) was not affected when reassessed on swabs positive for the UK variant B.1.1.7.
               
                  Interpretation
                  In this comprehensive comparison of antigen LFDs and virus infectivity, we found a clear relationship between Ct values, quantitative culture of infectious virus, and antigen LFD positivity in clinical samples. Our data support regular testing of target groups with LFDs to supplement the current PCR testing capacity, which would help to rapidly identify infected individuals in situations in which they would otherwise go undetected.
               
                  Funding
                  King's Together Rapid COVID-19, Medical Research Council, Wellcome Trust, Huo Family Foundation, UK Department of Health, National Institute for Health Research Comprehensive Biomedical Research Centre.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.visinf.2021.07.002,Journal,Visual Informatics,scopus,2021-09-01,sciencedirect,Algorithms for rapid digitalization of prescriptions,https://api.elsevier.com/content/abstract/scopus_id/85122825878,"Prescription data are invaluable for healthcare research and intelligence, yet, extraction of these data is challenging as this information is intertwined in the unstructured and non-grammatical text in prescription images. Moreover, text extraction from images in itself is hard, particularly for handwritten text. While piecemeal solutions exist, they are either limited to a small set of entities of interest or have very low accuracy and are not scalable. In this paper, we present two algorithms: the C-Cube algorithm for digitization of computer-printed prescriptions and the 3-Step Filtering algorithm for handwritten prescriptions. While a brute-force approach would match every word that is received from an optical character reader (OCR) with all possible entries in the database, this approach is inefficient and imprecise. The premise of our algorithms is an application of pattern intelligence to select a much smaller set of words (from the words returned by the OCR) as potential entities of interest. We rigorously tested the two algorithms on a corpus of more than 10,000 prescriptions’ images, taking the brute-force technique as the baseline methodology. Regarding latencies, we found that the C-Cube and the 3-Step Filtering algorithms were 588 and 231 times faster than the brute-force approach. In terms of accuracies, we found that the F-score of the C-cube algorithm was 90% higher than the F-score of the brute-force approach whereas the F-score for the 3-Step filtering algorithm was found to be 8,600% higher. The algorithms are decidedly faster and more accurate than the brute-force approach. These attributes make them suitable for implementation in real-time environments as well as for use in batch-mode for various applications. We expect the algorithms to play a significant role in the digitalization of healthcare information and briefly discuss a few applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2021.100422,Journal,Internet of Things (Netherlands),scopus,2021-09-01,sciencedirect,Identification and Authentication in Healthcare Internet-of-Things Using Integrated Fog Computing Based Blockchain Model,https://api.elsevier.com/content/abstract/scopus_id/85115027489,"The healthcare Internet-of-Things (IoT) offers many benefits including data transmission in real-time mode, the ability to monitor the physiological state of the patient in a different interval of time. Devices such as blood-pressure monitors, glucose meters, heart monitoring implants, Electroencephalography (EEG), Electrocardiogram (ECG), and Electromyography (EMG) wearable devices allow health providers to collect the patient health information locally and make a real-time decision based on the Patient Health Data (PHD). Hospitals have been adopting the IoT for many years and now they have healthcare IoT devices in patients’ rooms and their bodies. However, the medical agencies, hospitals, and companies do not consider the security risk of healthcare IoT devices connected to a Local Area Network (LAN) or Wide Area Network (WAN). The IoT devices can be easily hacked and may lead to several potentially life-threatening risks due to poor authentication and encryption practices. Existing machine learning algorithms and blockchain approach working in the cloud computing environment are unable to meet the Quality of Service (QoS) like reliability, authentication, identification, and security requirements of healthcare IoT devices. Most of the traditional machine learning algorithms and techniques for healthcare IoT lacks the real-world implementation for secure data transmission. Therefore, blockchain is introduced for secure and reliable transaction in healthcare IoT. Whereas Fog Computing (FC) is introduced to extend the services of the cloud at the edge of networks. Integration of FC with blockchain can overcome the issue of healthcare IoT device identification, authentication, and verification for scalable frequent data transmission in a decentralized environment. Hence, a novel solution for the abovementioned problem is proposed using FC and blockchain. It includes an FC-based three-tier architecture, an analytical model, a mathematical framework, and an Advanced Signature-Based Encryption (ASE) algorithm for healthcare IoT device identification, verification, and Patient Health Data (PHD) authentication. The aim is to extend secure data transmission for healthcare IoT and end-users availing the real-time services. The proposed model and algorithm will be able to provide services for transaction and transmission near the edge in a secure manner. By analyzing the generated results from the proposed novel ASE algorithm for throughput, packet error, reliability, and malicious node detection accuracy; it is observed that the ASE algorithm in the FC environment easily outperforms the cloud and the other existing state of the art techniques such as FogBus, Femto cloud, Blockchain Fog-based Architecture Network (BFAN), and BeeKeeper. The malicious node detection accuracy of the ASE algorithm in the FC environment is 91% and in the cloud is 83%. Whereas the reliability percentage of the ASE algorithm in FC is 95% and in the cloud is 87%. The proposed approach is tested on simulators iFogSim (Net-Beans) and SimBlock.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.amsu.2021.102489,Journal,Annals of Medicine and Surgery,scopus,2021-09-01,sciencedirect,Covid-19 imaging: A narrative review,https://api.elsevier.com/content/abstract/scopus_id/85112793878,"Background
                  The 2019 novel coronavirus disease (COVID-19) imaging data is dispersed in numerous publications. A cohesive literature review is to be assembled.
               
                  Objective
                  To summarize the existing literature on Covid-19 pneumonia imaging including precautionary measures for radiology departments, Chest CT's role in diagnosis and management, imaging findings of Covid-19 patients including children and pregnant women, artificial intelligence applications and practical recommendations.
               
                  Methods
                  A systematic literature search of PubMed/med line electronic databases.
               
                  Results
                  The radiology department's staff is on the front line of the novel coronavirus outbreak. Strict adherence to precautionary measures is the main defense against infection's spread. Although nucleic acid testing is Covid-19's pneumonia diagnosis gold standard; kits shortage and low sensitivity led to the implementation of the highly sensitive chest computed tomography amidst initial diagnostic tools. Initial Covid-19 CT features comprise bilateral, peripheral or posterior, multilobar ground-glass opacities, predominantly in the lower lobes. Consolidations superimposed on ground-glass opacifications are found in few cases, preponderantly in the elderly. In later disease stages, GGO transformation into multifocal consolidations, thickened interlobular and intralobular lines, crazy paving, traction bronchiectasis, pleural thickening, and subpleural bands are reported. Standardized CT reporting is recommended to guide radiologists. While lung ultrasound, pulmonary MRI, and PET CT are not Covid-19 pneumonia's first-line investigative diagnostic modalities, their characteristic findings and clinical value are outlined. Artificial intelligence's role in strengthening available imaging tools is discussed.
               
                  Conclusion
                  This review offers an exhaustive analysis of the current literature on imaging role and findings in COVID-19 pneumonia.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2021.104384,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-09-01,sciencedirect,A study on the use of Edge TPUs for eye fundus image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85111215307,"Medical image segmentation can be implemented using Deep Learning methods with fast and efficient segmentation networks. Single-board computers (SBCs) are difficult to use to train deep networks due to their memory and processing limitations. Specific hardware such as Google’s Edge TPU makes them suitable for real time predictions using complex pre-trained networks. In this work, we study the performance of two SBCs, with and without hardware acceleration for fundus image segmentation, though the conclusions of this study can be applied to the segmentation by deep neural networks of other types of medical images. To test the benefits of hardware acceleration, we use networks and datasets from a previous published work and generalize them by testing with a dataset with ultrasound thyroid images. We measure prediction times in both SBCs and compare them with a cloud based TPU system. The results show the feasibility of Machine Learning accelerated SBCs for optic disc and cup segmentation obtaining times below 25 ms per image using Edge TPUs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2021.101956,Journal,Computerized Medical Imaging and Graphics,scopus,2021-09-01,sciencedirect,Automated three-dimensional vessel reconstruction based on deep segmentation and bi-plane angiographic projections,https://api.elsevier.com/content/abstract/scopus_id/85111016853,"Automated three-dimensional (3D) blood vessel reconstruction to improve vascular diagnosis and therapeutics is a challenging task in which the real-time implementation of automatic segmentation and specific vessel tracking for matching artery sequences is essential. Recently, a deep learning-based segmentation technique has been proposed; however, existing state-of-the-art deep architectures exhibit reduced performance when they are employed using real in-vivo imaging because of serious issues such as low contrast and noise contamination of the X-ray images. To overcome these limitations, we propose a novel methodology composed of the de-haze image enhancement technique as pre-processing and multi-level thresholding as post-processing to be applied to the lightweight multi-resolution U-shaped architecture. Specifically, (1) bi-plane two-dimensional (2D) vessel images were extracted simultaneously using the deep architecture, (2) skeletons of the vessels were computed via a morphology operation, (3) the corresponding skeleton structure between image sequences was matched using the shape-context technique, and (4) the 3D centerline was reconstructed using stereo geometry. The method was validated using both in-vivo and in-vitro models. The results show that the proposed technique could improve the segmentation quality, reduce computation time, and reconstruct the 3D skeleton automatically. The algorithm accurately reconstructed the phantom model and the real mouse vessel in 3D in 2 s. Our proposed technique has the potential to allow therapeutic micro-agent navigation in clinical practice, thereby providing the 3D position and orientation of the vessel.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.urology.2021.06.008,Journal,Urology,scopus,2021-09-01,sciencedirect,Robot-assisted Magnetic Resonance Imaging-ultrasound Fusion Transperineal Targeted Biopsy,https://api.elsevier.com/content/abstract/scopus_id/85110653934,"Objective
                  To demonstrate the key steps to perform robot-assisted magnetic resonance imaging-ultrasound fusion transperineal prostate biopsy.
               
                  Materials and methods
                  Men with suspicion of prostate cancer underwent 3-Tesla multi-parametric MRI and were assigned a Prostate Imaging Reporting and Data System v2 score (PI-RADS). The prostate outline and suspicious lesions were marked by our radiologist using our software to produce a 3-dimensional prostate MRI model. All biopsies were performed under general anaesthesia and the real-time transrectal ultrasound model is created and subsequently fused with the MRI model using non-rigid software fusion. Transperineal targeted and systematic biopsy were then performed under stereotactic guidance using our robot-assisted prostate biopsy platform. Our clinically significant prostate cancer (Grade group ≥2) detection rates were previously described.
                        1
                     
                  
               
                  Results
                  Out of the 433 patients who underwent targeted and systematic biopsy, clinically-significant cancer detection rate was 46% (85% for PI- RADS 5 vs 38% for PI-RADS 4 vs 16% for PI-RADS 3; P < .001). Our overall complication rate was 13%, out of which the majority were Clavien-Dindo I (99%). The most common complications encountered were urinary retention (10%) and significant gross hematuria requiring bladder irrigation (2%). A higher prostate volume was associated with greater odds of urinary retention (OR 1.4, 95% CI: 1.21-1.65, P < .001 for every 10 mL increase in prostate volume). There was only 1 reported case of mild urinary tract infection.
               
                  Conclusion
                  Robot-assisted transperineal prostate biopsy has established itself as a reliable and accurate method of prostate cancer detection with minimal morbidity.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2021.105962,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-09-01,sciencedirect,StrokeWatch: An Instrument for Objective Standardized Real-Time Measurement of Door-to-Needle Times in Acute Ischemic Stroke Treatment,https://api.elsevier.com/content/abstract/scopus_id/85109982805,"Objectives
                  Monitoring critical time intervals in acute ischemic stroke treatment delivers metrics for quality of performance – the door-to-needle time being well-established. To resolve the conflict of self-reporting bias a “StrokeWatch” was designed – an instrument for objective standardized real-time measurement of procedural times.
               
                  Materials and methods
                  An observational, monocentric analysis of patients receiving intravenous thrombolysis for acute ischemic stroke between January 2018 and September 2019 was performed based on an ongoing investigator-initiated, prospective, and blinded endpoint registry. Patient data and treatment intervals before and after introduction of ""StrokeWatch"" were compared.
               
                  Results
                  “StrokeWatch” was designed as a mobile board equipped with three digital stopwatches tracking door-to-needle, door-to-groin, and door-to-recanalization intervals as well as a form for standardized documentation. 118 patients before introduction of “StrokeWatch” (subgroup A) and 53 patients after introduction of “StrokeWatch” (subgroup B) were compared. There were no significant differences in baseline characteristics, procedural times, or clinical outcome. A non-significant increase in patients with door-to-needle intervals of 60 min or faster (93.2 vs 98.1%, p = 0.243) and good functional outcome (mRS d90 ≤ 2, 47.5 vs 58.5%, p = 0.218) as well as a significant increase in reports of delayed arrival of intra-hospital patient transport service (0.8 vs 13.2%, p = 0.001) were observed in subgroup B.
               
                  Conclusions
                  The implementation of StrokeWatch for objective standardized real-time measurement of door-to-needle times is feasible in a real-life setting without negative impact on procedural times or outcome. It helped to reassure a high-quality treatment standard and reveal factors associated with procedural delays.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2021.104316,Journal,Engineering Applications of Artificial Intelligence,scopus,2021-09-01,sciencedirect,Deep replacement: Reinforcement learning based constellation management and autonomous replacement,https://api.elsevier.com/content/abstract/scopus_id/85108677220,"The Deep Reinforcement Learning (DRL) algorithm, Proximal Policy Optimization (PPO2), is deployed on a custom spacecraft (S/C) build and loss model to determine if an Artificial Intelligence (AI) can learn to monitor satellite constellation health and determine an optimal replacement strategy. A custom environment is created to simulate how S/C are built, launched, generate revenue, and finally decay. The reinforcement learning agent successfully learned an optimal policy for two models: a Simplified Model where the financial cost of actions is ignored; and an Advanced Model where the financial cost of actions is a major element. In both models the AI monitors the constellations and takes multiple strategic and tactical actions to replace satellites to maintain constellation performance. The Simplified Model showed that the PPO2 algorithm was able to converge on an optimal solution after 
                        ∼
                     200,000 simulations. The Advanced Model was much more difficult for the AI to learn, and thus, the performance drops during the early episodes, but eventually converges to an optimal policy at 
                        ∼
                     25,000,000 simulations. With the Advanced Model, the AI is taking actions that are successfully providing strategies for constellation management and satellite replacements which include these actions’ financial implications. Thus, the methods in this paper provide initial research developments towards a real-world tool and an AI application that can aid various Aerospace businesses in managing Low Earth Orbit (LEO) constellations. This type of AI application may become imperative for deploying and maintaining small satellite mega-constellations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.adhoc.2021.102562,Journal,Ad Hoc Networks,scopus,2021-09-01,sciencedirect,Developing novel low complexity models using received in-phase and quadrature-phase samples for interference detection and classification in Wireless Sensor Network and GPS edge devices,https://api.elsevier.com/content/abstract/scopus_id/85107952090,"Despite Wireless Sensor Networks (WSNs) significantly developing over the past decade, these networks, like most wireless networks, remain susceptible to malicious interference and spectrum coexistence. Other vulnerabilities arise as WSN applications adopt open standards and typically resource and energy-constrained commercial-off-the-shelf equipment. Deployments include safety-critical applications such as the internet of things, medical, aerospace and space and deep-sea exploration. To manage safety and privacy requirements across such a diverse wireless landscape, security on wireless edge devices needs improvement while maintaining low complexity. This paper improves wireless edge device security by developing a novel intelligent interference diagnostic framework. Received in-phase (I) and quadrature-phase (Q) samples are exclusively utilized to detect modern, subtle and traditional crude jamming attacks. This I/Q sample utilization inherently enables decentralized decision-making, where the low-order features were extracted in a previous study focused on classifying typical 2.4–2.5 GHz wireless signals. The associated optimal intelligent models are leveraged as the foundation for this paper’s work. Initially, Matlab Monte Carlo simulations investigate the ideal case, which incorporates no hardware limitations, identifies the required data type of signal interactions and motivates a hardware investigation. Software-defined radios (SDRs) collect the required live over-the-air I/Q data and transmit matched signal (ZigBee) and continuous-wave interference in developed ZigBee wireless testbeds. Low complexity supervised machine learning models are developed based exclusively on the low-order features and achieve an average accuracy among the developed models above 98%. The designed methodology involves examining ZigBee over-the-air data for artificial jamming and SDR jamming of ZigBee signals transmitted from SDR and commercial (XBee) sources. This approach expands to a legitimate node classification technique and an overall algorithm for wireless edge device interference diagnostic tools. The investigation includes developing Support Vector Machine, XGBoost and Deep Neural Network (DNN) models, where XGBoost is optimal. Adapting the optimized models to global positioning system signals establishes the transferability of the designed methodology. Implementing the designed approaches on a Raspberry Pi embedded device examines a relatively resource-constrained deployment. The primary contribution is the real experimentally validated interference diagnostic framework that enables independent device operation, as no channel assumptions, network-level information or spectral images are required. Developed models exclusively use I/Q data low-order features and achieve high accuracy and generalization to unseen data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103050,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Optimization of AI-driven communication systems for green hospitals in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85107113682,"The green hospital is an important part for constructing Sustainable Cities. In this paper, system optimization algorithms based on artificial intelligence technologies are proposed by studying the communication system of the green hospital in the smart sustainable city, and the overall architecture design and detailed functional module design were carried out. The functions in the system can be divided into basic information management function, patient monitoring function, and remote self-test, etc. The medical equipment management system is characterized by the combination of Internet of Things technology, so that equipment managers can control the operating status of the equipment at any time, and can remotely upgrade and control the equipment through the system, and medical staff can view the measurement data of the equipment at the system interface and grasp the real-time information of treating patients to improve work efficiency. The accuracy of the improved particle swarm optimization (PSO) algorithm was compared with that of a single BP neural network algorithm. According to the requirement analysis of the health monitoring software and the overall design scheme of the system, each functional module of the health monitoring software is designed and the specific implementation of each functional module is carried out.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.103009,Journal,Sustainable Cities and Society,scopus,2021-09-01,sciencedirect,Applying machine learning in intelligent sewage treatment: A case study of chemical plant in sustainable cities,https://api.elsevier.com/content/abstract/scopus_id/85106305327,"Nowadays, sewage treatment in sustainable cities attracts more researchers both from academic and industrial communities. Especially, since industrial sewage is normally highly toxic, which could cause serious pollution in a city and lead to health problems of residents, it is critical to monitor and predictably maintain sewage treatment facilities in cities. This paper presents an intelligent sewage treatment system based on machine learning and Internet of Things sensors to assist to manage the sewage treatment in a fine chemical plant. The implemented system has operated for twenty months, acquired multi-dimension data such as temperatures in different treatment processes, operation parameters of devices, and real-time Chemical Oxygen Demand (COD). Since the change trend of outflow COD is highly related to operation status, this paper innovatively uses different types of temperature and water inflow data as model inputs and applies three algorithms to make prediction, which are Support Vector Regression (SVR), Long Short-Term Memory (LSTM) neural network, and Gated Recurrent Unit (GRU) neural network. The experimental results show that GRU model performs better (MAPE = 10.18%, RMSE = 35.67, MAE = 31.16) than LSTM and SVR. This study can be extended to various sewage treatment scenarios in sustainable cities.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.114951,Journal,Expert Systems with Applications,scopus,2021-09-01,sciencedirect,Providing music service in Ambient Intelligence: experiments with gym users,https://api.elsevier.com/content/abstract/scopus_id/85104365062,"Ambient Intelligence (AmI) is an interdisciplinary research area of ICT which has evolved since the 90s, taking great advantage from the advent of the Internet of Things (IoT). AmI creates, by using Artificial Intelligence (AI), an intelligent ecosystem in which computers, sensors, lighting, music, personal devices, and distributed services, work together to improve the user experience through the support of natural and intuitive user interfaces. Nowadays, AmI is used in various contexts, e.g., for building smart homes and smart cities, providing healthcare, and creating an adequate atmosphere in retail and public environments.
                  In this paper, we propose a novel AmI system for gym environments, named Gym Intelligence, able to provide adequate music atmosphere, according to the users’ physical effort during the training. The music is taken from Spotify and is classified according to some music features, as provided by Spotify itself. The system is based on a multi-agent computational intelligence model built on two main components: 
                        
                           (
                           i
                           )
                        
                      machine learning methods that forecast appropriate values for the Spotify music features, and 
                        
                           (
                           ii
                           )
                        
                      a multi-objective dynamic genetic algorithm that selects a specific Spotify music track, according to such values. Gym Intelligence is built by sensing the ambient with a minimal, low-cost, and non-intrusive set of sensors, and it has been designed considering the outcome of a preliminary analysis in real gyms, involving real users. We have considered well-known regression methods and we have validated them using a collected data 
                        
                           (
                           i
                           )
                        
                      about the users’ physical effort, through the sensors, and 
                        
                           (
                           ii
                           )
                        
                      about the users’ music preferences, through an Android app that the users have used during the training. Among the regression methods considered, the one that provided the best results is the Random Forest, which predicted Spotify music features with a mean absolute error of 0.02 and a root mean squared error of 0.05. We have implemented Gym Intelligence and deployed it in five real gyms. We have evaluated it conducting several experiments. The experiments show how, with the help of Gym Intelligence, the users’ satisfaction about the provided background music, rose from 3.05 to 4.91 (on a scale from 1 to 5, where 5 is the maximum score).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jes.2021.01.029,Journal,Journal of Environmental Sciences (China),scopus,2021-09-01,sciencedirect,Comparison of approaches to quantify SARS-CoV-2 in wastewater using RT-qPCR: Results and implications from a collaborative inter-laboratory study in Canada,https://api.elsevier.com/content/abstract/scopus_id/85101937522,"Detection of SARS-CoV-2 RNA in wastewater is a promising tool for informing public health decisions during the COVID-19 pandemic. However, approaches for its analysis by use of reverse transcription quantitative polymerase chain reaction (RT-qPCR) are still far from standardized globally. To characterize inter- and intra-laboratory variability among results when using various methods deployed across Canada, aliquots from a real wastewater sample were spiked with surrogates of SARS-CoV-2 (gamma-radiation inactivated SARS-CoV-2 and human coronavirus strain 229E [HCoV-229E]) at low and high levels then provided “blind” to eight laboratories. Concentration estimates reported by individual laboratories were consistently within a 1.0-log10 range for aliquots of the same spiked condition. All laboratories distinguished between low- and high-spikes for both surrogates. As expected, greater variability was observed in the results amongst laboratories than within individual laboratories, but SARS-CoV-2 RNA concentration estimates for each spiked condition remained mostly within 1.0-log10 ranges. The no-spike wastewater aliquots provided yielded non-detects or trace levels (<20 gene copies/mL) of SARS-CoV-2 RNA. Detections appear linked to methods that included or focused on the solids fraction of the wastewater matrix and might represent in-situ SARS-CoV-2 to the wastewater sample. HCoV-229E RNA was not detected in the no-spike aliquots. Overall, all methods yielded comparable results at the conditions tested. Partitioning behavior of SARS-CoV-2 and spiked surrogates in wastewater should be considered to evaluate method effectiveness. A consistent method and laboratory to explore wastewater SARS-CoV-2 temporal trends for a given system, with appropriate quality control protocols and documented in adequate detail should succeed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2021.03.109,Journal,Neurocomputing,scopus,2021-08-18,sciencedirect,Real-time detection of bursts in neuronal cultures using a neuromorphic auditory sensor and spiking neural networks,https://api.elsevier.com/content/abstract/scopus_id/85104794271,"The correct identification of burst events is crucial in many scenarios, ranging from basic neuroscience to biomedical applications. However, none of the burst detection methods that can be found in the literature have been widely adopted for this task. As an alternative to conventional techniques, a novel neuromorphic approach for real-time burst detection is proposed and tested on acquisitions from in vitro cultures. The system consists of a Neuromorphic Auditory Sensor, which converts the input signal obtained from electrophysiological recordings into spikes and decomposes them into different frequency bands. The output of the sensor is sent to a trained Spiking Neural Network implemented on a SpiNNaker board that discerns between bursting and non-bursting activity. This data-driven approach was compared with different conventional spike-based and raw-based burst detection methods, addressing some of their drawbacks, such as being able to detect both high and low frequency events and working in an online manner. Similar results in terms of number of detected events, mean burst duration and correlation as current state-of-the-art approaches were obtained with the proposed system, also benefiting from its lower power consumption and computational latency. Therefore, our neuromorphic-based burst detection paves the road to future implementations for real-time neuroprosthetic applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neuroimage.2021.118206,Journal,NeuroImage,scopus,2021-08-15,sciencedirect,"Joint super-resolution and synthesis of 1 mm isotropic MP-RAGE volumes from clinical MRI exams with scans of different orientation, resolution and contrast",https://api.elsevier.com/content/abstract/scopus_id/85106551066,"Most existing algorithms for automatic 3D morphometry of human brain MRI scans are designed for data with near-isotropic voxels at approximately 1 mm resolution, and frequently have contrast constraints as well-typically requiring T1-weighted images (e.g., MP-RAGE scans). This limitation prevents the analysis of millions of MRI scans acquired with large inter-slice spacing in clinical settings every year. In turn, the inability to quantitatively analyze these scans hinders the adoption of quantitative neuro imaging in healthcare, and also precludes research studies that could attain huge sample sizes and hence greatly improve our understanding of the human brain. Recent advances in convolutional neural networks (CNNs) are producing outstanding results in super-resolution and contrast synthesis of MRI. However, these approaches are very sensitive to the specific combination of contrast, resolution and orientation of the input images, and thus do not generalize to diverse clinical acquisition protocols – even within sites. In this article, we present SynthSR, a method to train a CNN that receives one or more scans with spaced slices, acquired with different contrast, resolution and orientation, and produces an isotropic scan of canonical contrast (typically a 1 mm MP-RAGE). The presented method does not require any preprocessing, beyond rigid coregistration of the input scans. Crucially, SynthSR trains on synthetic input images generated from 3D segmentations, and can thus be used to train CNNs for any combination of contrasts, resolutions and orientations without high-resolution real images of the input contrasts. We test the images generated with SynthSR in an array of common downstream analyses, and show that they can be reliably used for subcortical segmentation and volumetry, image registration (e.g., for tensor-based morphometry), and, if some image quality requirements are met, even cortical thickness morphometry. The source code is publicly available at https://github.com/BBillot/SynthSR.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.114848,Journal,Expert Systems with Applications,scopus,2021-08-15,sciencedirect,Domain adaptation based self-correction model for COVID-19 infection segmentation in CT images,https://api.elsevier.com/content/abstract/scopus_id/85103118631,"The capability of generalization to unseen domains is crucial for deep learning models when considering real-world scenarios. However, current available medical image datasets, such as those for COVID-19 CT images, have large variations of infections and domain shift problems. To address this issue, we propose a prior knowledge driven domain adaptation and a dual-domain enhanced self-correction learning scheme. Based on the novel learning scheme, a domain adaptation based self-correction model (DASC-Net) is proposed for COVID-19 infection segmentation on CT images. DASC-Net consists of a novel attention and feature domain enhanced domain adaptation model (AFD-DA) to solve the domain shifts and a self-correction learning process to refine segmentation results. The innovations in AFD-DA include an image-level activation feature extractor with attention to lung abnormalities and a multi-level discrimination module for hierarchical feature domain alignment. The proposed self-correction learning process adaptively aggregates the learned model and corresponding pseudo labels for the propagation of aligned source and target domain information to alleviate the overfitting to noises caused by pseudo labels. Extensive experiments over three publicly available COVID-19 CT datasets demonstrate that DASC-Net consistently outperforms state-of-the-art segmentation, domain shift, and coronavirus infection segmentation methods. Ablation analysis further shows the effectiveness of the major components in our model. The DASC-Net enriches the theory of domain adaptation and self-correction learning in medical imaging and can be generalized to multi-site COVID-19 infection segmentation on CT images for clinical deployment.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.medj.2021.06.006,Journal,Med,scopus,2021-08-13,sciencedirect,Real-time analysis of a mass vaccination effort confirms the safety of FDA-authorized mRNA COVID-19 vaccines,https://api.elsevier.com/content/abstract/scopus_id/85110410124,"Background
                  As the coronavirus disease 2019 (COVID-19) vaccination campaign unfolds, it is important to continuously assess the real-world safety of Food and Drug Administration (FDA)-authorized vaccines. Curation of large-scale electronic health records (EHRs) enables near-real-time safety evaluations that were not previously possible.
               
                  Methods
                  In this retrospective study, we deployed deep neural networks over a large EHR system to automatically curate the adverse effects mentioned by physicians in over 1.2 million clinical notes between December 1, 2020 and April 20, 2021. We compared notes from 68,266 individuals who received at least one dose of BNT162b2 (n = 51,795) or mRNA-1273 (n = 16,471) to notes from 68,266 unvaccinated individuals who were matched by demographic, geographic, and clinical features.
               
                  Findings
                  Individuals vaccinated with BNT162b2 or mRNA-1273 had a higher rate of return to the clinic, but not the emergency department, after both doses compared to unvaccinated controls. The most frequently documented adverse effects within 7 days of each vaccine dose included myalgia, headache, and fatigue, but the rates of EHR documentation for each side effect were remarkably low compared to those derived from active solicitation during clinical trials. Severe events, including anaphylaxis, facial paralysis, and cerebral venous sinus thrombosis, were rare and occurred at similar frequencies in vaccinated and unvaccinated individuals.
               
                  Conclusions
                  This analysis of vaccine-related adverse effects from over 1.2 million EHR notes of more than 130,000 individuals reaffirms the safety and tolerability of the FDA-authorized mRNA COVID-19 vaccines in practice.
               
                  Funding
                  This study was funded by nference.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chbr.2021.100146,Journal,Computers in Human Behavior Reports,scopus,2021-08-01,sciencedirect,Intelligent autonomous agents and trust in virtual reality,https://api.elsevier.com/content/abstract/scopus_id/85125679082,"Intelligent autonomous agents (IAA) are proliferating and rapidly evolving due to the exponential growth in computational power and recent advances, for instance, in artificial intelligence research. Ranging from chatbots, over personal virtual assistants and medical decision-aiding systems, to self-driving or self-piloting systems, whether unbeknownst to the users or not, IAA are increasingly integrated into many aspects of daily life. Despite this technological development, many people remain skeptical of such agents. Conversely, others might have excessive confidence in them. Therefore, establishing an appropriate level of trust is crucial to the successful deployment of IAA in everyday contexts. Virtual Reality (VR) is another domain where IAA play a significant role, yet its experiential and immersive character particularly allows for new ways of interaction and tackling trust-related issues. In this article, we provide an overview of the numerous factors involved in establishing trust between users and IAA, spanning scientific disciplines as diverse as psychology, philosophy, sociology, computer science, and economics. Focusing on VR, we discuss the different types and definitions of trust and identify foundational factors classified into three interrelated dimensions: Human-Technology, Human-System, and Interpersonal. Based on this taxonomy, we identify open issues and a research agenda towards facilitating the study of trustful interaction and collaboration between users and IAA in VR settings.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00086-8,Journal,The Lancet Digital Health,scopus,2021-08-01,sciencedirect,Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study,https://api.elsevier.com/content/abstract/scopus_id/85111153013,"Background
                  Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted.
               
                  Methods
                  In this national real-world evidence study, we trained a DLS, the Comprehensive AI Retinal Expert (CARE) system, to identify the 14 most common retinal abnormalities using 207 228 colour fundus photographs derived from 16 clinical settings with different disease distributions. CARE was internally validated using 21 867 photographs and externally tested using 18 136 photographs prospectively collected from 35 real-world settings across China where CARE might be adopted, including eight tertiary hospitals, six community hospitals, and 21 physical examination centres. The performance of CARE was further compared with that of 16 ophthalmologists and tested using datasets with non-Chinese ethnicities and previously unused camera types. This study was registered with ClinicalTrials.gov, NCT04213430, and is currently closed.
               
                  Findings
                  The area under the receiver operating characteristic curve (AUC) in the internal validation set was 0·955 (SD 0·046). AUC values in the external test set were 0·965 (0·035) in tertiary hospitals, 0·983 (0·031) in community hospitals, and 0·953 (0·042) in physical examination centres. The performance of CARE was similar to that of ophthalmologists. Large variations in sensitivity were observed among the ophthalmologists in different regions and with varying experience. The system retained strong identification performance when tested using the non-Chinese dataset (AUC 0·960, 95% CI 0·957–0·964 in referable diabetic retinopathy).
               
                  Interpretation
                  Our DLS (CARE) showed satisfactory performance for screening multiple retinal abnormalities in real-world settings using prospectively collected fundus photographs, and so could allow the system to be implemented and adopted for clinical care.
               
                  Funding
                  This study was funded by the National Key R&D Programme of China, the Science and Technology Planning Projects of Guangdong Province, the National Natural Science Foundation of China, the Natural Science Foundation of Guangdong Province, and the Fundamental Research Funds for the Central Universities.
               
                  Translation
                  For the Chinese translation of the abstract see Supplementary Materials section.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103854,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,"A generalized kernel machine approach to identify higher-order composite effects in multi-view datasets, with application to adolescent brain development and osteoporosis",https://api.elsevier.com/content/abstract/scopus_id/85110205594,"In recent years, a comprehensive study of complex disease with multi-view datasets (e.g., multi-omics and imaging scans) has been a focus and forefront in biomedical research. State-of-the-art biomedical technologies are enabling us to collect multi-view biomedical datasets for the study of complex diseases. While all the views of data tend to explore complementary information of disease, analysis of multi-view data with complex interactions is challenging for a deeper and holistic understanding of biological systems. In this paper, we propose a novel generalized kernel machine approach to identify higher-order composite effects in multi-view biomedical datasets (GKMAHCE). This generalized semi-parametric (a mixed-effect linear model) approach includes the marginal and joint Hadamard product of features from different views of data. The proposed kernel machine approach considers multi-view data as predictor variables to allow a more thorough and comprehensive modeling of a complex trait. We applied GKMAHCE approach to both synthesized datasets and real multi-view datasets from adolescent brain development and osteoporosis study. Our experiments demonstrate that the proposed method can effectively identify higher-order composite effects and suggest that corresponding features (genes, region of interests, and chemical taxonomies) function in a concerted effort. We show that the proposed method is more generalizable than existing ones. To promote reproducible research, the source code of the proposed method is available at.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103848,Journal,Journal of Biomedical Informatics,scopus,2021-08-01,sciencedirect,Face mask detection using deep learning: An approach to reduce risk of Coronavirus spread,https://api.elsevier.com/content/abstract/scopus_id/85109043381,"Effective strategies to restrain COVID-19 pandemic need high attention to mitigate negatively impacted communal health and global economy, with the brim-full horizon yet to unfold. In the absence of effective antiviral and limited medical resources, many measures are recommended by WHO to control the infection rate and avoid exhausting the limited medical resources. Wearing a mask is among the non-pharmaceutical intervention measures that can be used to cut the primary source of SARS-CoV2 droplets expelled by an infected individual. Regardless of discourse on medical resources and diversities in masks, all countries are mandating coverings over the nose and mouth in public. To contribute towards communal health, this paper aims to devise a highly accurate and real-time technique that can efficiently detect non-mask faces in public and thus, enforcing to wear mask. The proposed technique is ensemble of one-stage and two-stage detectors to achieve low inference time and high accuracy. We start with ResNet50 as a baseline and applied the concept of transfer learning to fuse high-level semantic information in multiple feature maps. In addition, we also propose a bounding box transformation to improve localization performance during mask detection. The experiment is conducted with three popular baseline models viz. ResNet50, AlexNet and MobileNet. We explored the possibility of these models to plug-in with the proposed model so that highly accurate results can be achieved in less inference time. It is observed that the proposed technique achieves high accuracy (98.2%) when implemented with ResNet50. Besides, the proposed model generates 11.07% and 6.44% higher precision and recall in mask detection when compared to the recent public baseline model published as RetinaFaceMask detector. The outstanding performance of the proposed model is highly suitable for video surveillance devices.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2021.102145,Journal,Medical Image Analysis,scopus,2021-08-01,sciencedirect,APPLAUSE: Automatic Prediction of PLAcental health via U-net Segmentation and statistical Evaluation,https://api.elsevier.com/content/abstract/scopus_id/85109028622,"Purpose:Artificial-intelligence population-based automated quantification of placental maturation and health from a rapid functional Magnetic Resonance scan. The placenta plays a crucial role for any successful human pregnancy. Deviations from the normal dynamic maturation throughout gestation are closely linked to major pregnancy complications. Antenatal assessment in-vivo using T2* relaxometry has shown great promise to inform management and possible interventions but clinical translation is hampered by time consuming manual segmentation and analysis techniques based on comparison against normative curves over gestation.
                  
                     Methods:This study proposes a fully automatic pipeline to predict the biological age and health of the placenta based on a free-breathing rapid (sub-30 second) T2* scan in two steps: Automatic segmentation using a U-Net and a Gaussian process regression model to characterize placental maturation and health. These are trained and evaluated on 108 3T MRI placental data sets, the evaluation included 20 high-risk pregnancies diagnosed with pre-eclampsia and/or fetal growth restriction. An independent cohort imaged at 1.5 T is used to assess the generalization of the training and evaluation pipeline.
                  
                     Results: Across low- and high-risk groups, automatic segmentation performs worse than inter-rater performance (mean Dice coefficients of 0.58 and 0.68, respectively) but is sufficient for estimating placental mean T2* (0.986 Pearson Correlation Coefficient). The placental health prediction achieves an excellent ability to differentiate cases of placental insufficiency between 27 and 33 weeks. High abnormality scores correlate with low birth weight, premature birth and histopathological findings. Retrospective application on a different cohort imaged at 1.5 T illustrates the ability for direct clinical translation.
                  
                     Conclusion:The presented automatic pipeline facilitates a fast, robust and reliable prediction of placental maturation. It yields human-interpretable and verifiable intermediate results and quantifies uncertainties on the cohort-level and for individual predictions. The proposed machine-learning pipeline runs in close to real-time and, deployed in clinical settings, has the potential to become a cornerstone of diagnosis and intervention of placental insufficiency. APPLAUSE generalizes to an independent cohort imaged at 1.5 T, demonstrating robustness to different operational and clinical environments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2021.101437,Journal,Pervasive and Mobile Computing,scopus,2021-08-01,sciencedirect,Porting deep neural networks on the edge via dynamic K-means compression: A case study of plant disease detection,https://api.elsevier.com/content/abstract/scopus_id/85108633572,"Cyber Physical Systems (CPS) totally revolutionized the way we interact with the world providing useful services that can support the human being in many aspects of his life. Artificial Intelligence (AI) is another important player for bringing intelligence to CPS and allows the realization of Intelligent Cyber Physical Systems where smart applications can run. However, the constrained hardware of these devices in terms of memory and computing power makes challenging the deployment and execution of powerful algorithms (e.g., deep neural networks). To address this problem, modern solutions involve the use of compression techniques to reduce the memory footprint of deep learning models while saving the accuracy performance. The proposed work focuses on plant disease detection which represents one of the biggest challenges in smart agriculture; in such a context, the possibility to perform a timely diagnosis on crops suspected to be infected can avoid the spread of diseases, thus saving a lot of time and money during the plantation works. In this paper, we realized an intelligent CPS on top of which we implemented an AI application, called Deep Leaf that exploits Convolutional Neural Networks to detect the main biotic stresses affecting crops. To meet the hardware requirements of the Edge device running our application, we propose a novel dynamic compression algorithm based on K-Means for the reduction of models footprint. Experimental results show that our detector is able to correctly classify the plant health condition with an accuracy of 95% and demonstrate the effectiveness of the proposed compression algorithm which is able to maintain the same accuracy of the original 32 bit float model, with an overall memory size reduction of about 85.2%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2021.105825,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-08-01,sciencedirect,Machine Learning Analysis of MicroRNA Expression Data Reveals Novel Diagnostic Biomarker for Ischemic Stroke,https://api.elsevier.com/content/abstract/scopus_id/85108095605,"Objectives
                  Ischemic stroke (IS) is one of the leading causes of morbidity and mortality worldwide. Circulating microRNAs have a potential as minimally invasive biomarkers for disease prediction, diagnosis, and prognosis. In this study, we sought to use different machine learning algorithms to identify an optimal model of microRNA by integrating the expression data of pre-selected microRNAs for discriminating patients with IS from controls.
               
                  Methods
                  The expression level of microRNAs in the peripheral blood of 50 patients with IS and 50 matched controls were assessed through real-time polymerase chain reaction (qRT-PCR). Machine learning algorithms, including artificial neural network, random forest, extreme gradient boosting, and support vector machine (SVM) were employed via R 3.6.3 software to establish diagnostic models for IS.
               
                  Results
                  The IS group had significantly increased expression levels of miR-19a (P < 0.001), miR-148a (P < 0.001), miR-320d (P = 0.003), and miR-342-3p (P < 0.001) compared with the control group. MiR-148a, miR-342-3p, miR-19a, and miR-320d yielded areas under the receiver operating characteristic curve (AUC) of 0.872, 0.844, 0.721, and 0.673, respectively, with 0.740, 0.940, 0.740, and 0.840 sensitivity and 0.920, 0.640, 0.600, and 0.440 specificity, respectively. Model miR-148a + miR-342-3p + miR-19a had the best predictive value when analyzed via SVM algorithm with AUC, sensitivity, and specificity values of 0.958, 0.937, and 0.889, respectively.
               
                  Conclusion
                  The diagnostic value of the combination of miR-148a, miR-342-3p, and miR-19a through SVM algorithm has the potential to serve as a feasible approach to promote the diagnosis of IS.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jocn.2021.05.015,Journal,Journal of Clinical Neuroscience,scopus,2021-08-01,sciencedirect,Potential and limitations of radiomics in neuro-oncology,https://api.elsevier.com/content/abstract/scopus_id/85107849829,"Radiomics seeks to apply classical methods of image processing to obtain quantitative parameters from imaging. Derived features are subsequently fed into algorithmic models to aid clinical decision making. The application of radiomics and machine learning techniques to clinical medicine remains in its infancy. The great potential of radiomics lies in its objective, granular approach to investigating clinical imaging. In neuro-oncology, advanced machine learning techniques, particularly deep learning, are at the forefront of new discoveries in the field. However, despite the great promise of machine learning aided radiomic approaches, the current use remains confined to scholarly research, without real-world deployment in neuro-oncology. The paucity of data, inconsistencies in preprocessing, radiomic feature instability, and the rarity of the events of interest are critical barriers to clinical translation. In this article, we will outline the major steps in the process of radiomics, as well as review advances and challenges in the field as they pertain to neuro-oncology.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gsd.2021.100612,Journal,Groundwater for Sustainable Development,scopus,2021-08-01,sciencedirect,"Assessing drinking water quality based on physical, chemical and microbial parameters in the Red Sea State, Sudan using a combination of water quality index and artificial neural network model",https://api.elsevier.com/content/abstract/scopus_id/85107352300,"This study aimed to assess the quality of water resources, and its suitability for the drinking uses in Red Sea State, Sudan. Particularly, with regard to international standards from the World Health Organization (WHO/2017), and the national standards from Sudanese Standard and Meteorology Organization for drinking water (SDS-044/2007). Twenty locations site were investigated to represent this important area, where its analysed for compliance with the national and international standards, furthermore, the suitability for drinking purpose was assessed by using water quality index (WQI) method. Artificial Neural Network (ANN) was applied to predict the QWI by using the algorithm of feed forward back propagation artificial neural networks (BP ANN) for optimization. Physio-chemical assessments indicated that, water resources did not conform to the safe limits, especially heavy metals likes cadmium, which has the highest concentrations-hazard in almost all samples. High lead levels were observed at nineteen sites, while a high concentrations of nickel, and Total dissolved solids were observed at seven locations. The microbial assessment indicated most of locations did not conform to the safe limits, a high bacteria –hazard for Total coliform and Escherichia coli were observed in fourteen, and seven locations, respectively. Computed WQI values ranged from 35.61 to 337.52. ANN model showed much high prediction accuracy of WQI modeling with R2 values greater than 0.95 during training, testing and validation. WQI spatial distribution shown that, Red Sea State has unsuitable water quality in most of study sites (70%). The effects of heavy pollutants dominated on the water quality, and spread in these regions. This study conducted the first full-scale survey of the drinking water sources (ground and surface) in the Red Sea State of Sudan. Based on these results, we recommended that, an urgent measures such as a chemical treatments to treat the pollution, with/or filters installation should be implemented as soon as possible to manage and protect the water resources.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ghir.2021.101408,Journal,Growth Hormone and IGF Research,scopus,2021-08-01,sciencedirect,Digital technologies to improve the precision of paediatric growth disorder diagnosis and management,https://api.elsevier.com/content/abstract/scopus_id/85107315211,"Paediatric disorders of impaired linear growth are challenging to manage, in part because of delays in the identification of pathological short stature and subsequent referral and diagnosis, the requirement for long-term therapy, and frequent poor adherence to treatment, notably with human growth hormone (hGH). Digital health technologies hold promise for improving outcomes in paediatric growth disorders by supporting personalisation of care, from diagnosis to treatment and follow up. The value of automated systems in monitoring linear growth in children has been demonstrated in Finland, with findings that such a system is more effective than a traditional manual system for early diagnosis of abnormal growth. Artificial intelligence has potential to resolve problems of variability that may occur during analysis of growth information, and augmented reality systems have been developed that aim to educate patients and caregivers about growth disorders and their treatment (such as injection techniques for hGH administration). Adherence to hGH treatment is often suboptimal, which negatively impacts the achievement of physical and psychological benefits of the treatment. Personalisation of adherence support necessitates capturing individual patient adherence data; the use of technology to assist with this is exemplified by the use of an electronic injection device, which shares real-time recordings of the timing, date and dose of hGH delivered to the patient with the clinician, via web-based software. The use of an electronic device is associated with high levels of adherence to hGH treatment and improved growth outcomes. It can be anticipated that future technological advances, coupled with continued ‘human interventions’ from healthcare providers, will further improve management of paediatric growth disorders.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106168,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-08-01,sciencedirect,Semi-AI and Full-AI digitizer: The ways to digitalize visual field big data,https://api.elsevier.com/content/abstract/scopus_id/85106865896,"Background and objective
                  Glaucoma is one of the major diseases that cause blindness, which is incurable and irreversible, and it is essential to detect glaucoma vision deficits in treatment and check the progression of vision disorders in advance. In order to minimize the risk of glaucoma, it is necessary not only to diagnose and observe glaucoma but also to predict prognosis via indicators from Visual Field (VF) tests. However, information from the VF test cannot be directly used in clinical studies because most medical institutions store VF test sheets in Portable Document Format (PDF) or image files in different standards.
               
                  Methods
                  We developed AI-based real-time VF big data digitizing systems that digitalize VF test images in real-time in two ways; Semi-AI and Full-AI digitizer. The Semi-AI digitizer detects the VF text area with actual coordinates derived from mouse handler system. Full-AI digitizer detects the VF text area with Faster Region Based Convolutional Neural Networks (RCNN). After detecting the text area, both systems extract texts with Recurrent Neural Network based Optical Character Recognition. Semi-AI and Full-AI digitizer post-processes the extracted text results with in-system algorithm and out-of-system algorithm, respectively.
               
                  Results
                  Both systems used 325,310 VF test sheets from a tertiary hospital and extracted a total of 5,530,270 texts. From the 100 randomly selected VF sheets, 3,400 texts were used for the validation. Semi-AI and Full-AI digitizer showed 0.993 and 0.983 of accuracy, respectively.
               
                  Conclusion
                  This study demonstrates the effectiveness of AI applications in detecting text areas and the different implementation methodologies of the post-processing process. In detecting text area, Semi-AI may be better than Full-AI digitizer in terms of system speed and human labor labeling if the number of types to be classified is small. However, Full-AI digitizer is recommended because it allows detecting text area regardless of resolution and size of the VF sheets, as the types of real-world VF test sheets cannot be predicted, and the types become more unpredictable when extended to multi-hospital studies. For Post-preprocessing, Semi-AI methodology is recommended because Semi-AI produced higher results with less effort and considered the convenience of researchers by implementing them as in-system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.renene.2021.04.040,Journal,Renewable Energy,scopus,2021-08-01,sciencedirect,Damage identification of wind turbine blades with deep convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85105896900,"Online early detection of surface damages on blades is critical for the safety of wind turbines, which could avoid catastrophic failures, minimize downtime, and enhance the reliability of the system. Monitoring the health status of blades is attracting more and more attention including on-site cameras and mobile cameras by drones and crawling robots. To deploy fast and efficient damage detection methods from image data, this work presents a hierarchical identification framework for wind turbine blades, which consists of a Haar-AdaBoost step for region proposal and a convolutional neural network (CNN) classifier for damage detection and fault diagnosis. Case studies are carried out on real data set collected from an eastern China wind farm. Results show that (i) the proposed framework can detect and identify the blade damages and outperforms other schemes include SVM and VGG16 models, (ii) sensitive analysis is conducted to validate the robustness of proposed method under limited data conditions, (iii) the proposed scheme is faster than one-step CNN method that directly classifying raw data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.annemergmed.2021.02.029,Journal,Annals of Emergency Medicine,scopus,2021-08-01,sciencedirect,Development and Validation of Machine Learning Models to Predict Admission From Emergency Department to Inpatient and Intensive Care Units,https://api.elsevier.com/content/abstract/scopus_id/85105468712,"Study objective
                  This study aimed to develop and validate 2 machine learning models that use historical and current-visit patient data from electronic health records to predict the probability of patient admission to either an inpatient unit or ICU at each hour (up to 24 hours) of an emergency department (ED) encounter. The secondary goal was to provide a framework for the operational implementation of these machine learning models.
               
                  Methods
                  Data were curated from 468,167 adult patient encounters in 3 EDs (1 academic and 2 community-based EDs) of a large academic health system from August 1, 2015, to October 31, 2018. The models were validated using encounter data from January 1, 2019, to December 31, 2019. An operational user dashboard was developed, and the models were run on real-time encounter data.
               
                  Results
                  For the intermediate admission model, the area under the receiver operating characteristic curve was 0.873 and the area under the precision-recall curve was 0.636. For the ICU admission model, the area under the receiver operating characteristic curve was 0.951 and the area under the precision-recall curve was 0.461. The models had similar performance in both the academic- and community-based settings as well as across the 2019 and real-time encounter data.
               
                  Conclusion
                  Machine learning models were developed to accurately make predictions regarding the probability of inpatient or ICU admission throughout the entire duration of a patient’s encounter in ED and not just at the time of triage. These models remained accurate for a patient cohort beyond the time period of the initial training data and were integrated to run on live electronic health record data, with similar performance.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scs.2021.102945,Journal,Sustainable Cities and Society,scopus,2021-08-01,sciencedirect,Effective task scheduling algorithm with deep learning for Internet of Health Things (IoHT) in sustainable smart cities,https://api.elsevier.com/content/abstract/scopus_id/85105291613,"In the recent years, important key factor for urban planning is to analyze the sustainability and its functionality towards smart cities. Presently, many researchers employ the conservative machine learning based analysis but those are not appropriate for IoT based health data analysis because of their physical feature extraction and low accuracy. In this paper, we propose remote health monitoring and data analysis by integrating IoT and deep learning concepts. We proposed novel IoT based FoG assisted cloud network architecture that accumulates real-time health care data from patients via several medical IoT sensor networks, these data are analyzed using a deep learning algorithm deployed at Fog based Healthcare Platform. Furthermore, the proposed methodology is applied to the sustainable smart cities to evaluate the process for real-time. The proposed framework not only analyses the healthcare data but also provides immediate relief measures to the patient facing critical conditions and needs immediate consultancy of doctor. Performance is measure in terms of accuracy, precision and sensitivity of the proposed DHNN with task scheduling algorithm and it is obtained 97.6%, 97.9%, and 94.9%. While accuracy, precision and sensitivity for deep CNN is 96.5%, 97.5% and 94% and for Deep auto-encoder is 92%, 91%, and 82.5%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dss.2021.113539,Journal,Decision Support Systems,scopus,2021-08-01,sciencedirect,Predicting employee absenteeism for cost effective interventions,https://api.elsevier.com/content/abstract/scopus_id/85105018797,"This paper describes a decision support system designed for a Belgian Human Resource (HR) and Well-Being Service Provider. Their goal is to improve health and well-being in the workplace, and to this end, the task is to identify groups of employees at risk of sickness absence who can then be targeted with interventions aiming to reduce or prevent absences. To facilitate deployment, we apply a range of existing machine-learning methods to obtain predictions at monthly intervals using real HR and payroll data that contains no health-related predictors. We model employee absence as a binary classification problem with loss asymmetry and conceptualise a misclassification cost matrix of employee sickness absence. Model performance is evaluated using cost-based metrics, which have intuitive interpretation. We also demonstrate how this problem can be approached when costs are unknown. The proposed flexible evaluation procedure is not restricted to a specific model or domain and can be applied to address other HR analytics questions when deployed. Our approach of considering a wider range of methods and cost-based performance evaluation is novel in the domain of absenteeism prediction.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bbrc.2020.10.077,Journal,Biochemical and Biophysical Research Communications,scopus,2021-07-30,sciencedirect,"Life, death, and self: Fundamental questions of primitive cognition viewed through the lens of body plasticity and synthetic organisms",https://api.elsevier.com/content/abstract/scopus_id/85095615733,"Central to the study of cognition is being able to specify the Subject that is making decisions and owning memories and preferences. However, all real cognitive agents are made of parts (such as brains made of cells). The integration of many active subunits into a coherent Self appearing at a larger scale of organization is one of the fundamental questions of evolutionary cognitive science. Typical biological model systems, whether basal or advanced, have a static anatomical structure which obscures important aspects of the mind-body relationship. Recent advances in bioengineering now make it possible to assemble, disassemble, and recombine biological structures at the cell, organ, and whole organism levels. Regenerative biology and controlled chimerism reveal that studies of cognition in intact, “standard”, evolved animal bodies are just a narrow slice of a much bigger and as-yet largely unexplored reality: the incredible plasticity of dynamic morphogenesis of biological forms that house and support diverse types of cognition. The ability to produce living organisms in novel configurations makes clear that traditional concepts, such as body, organism, genetic lineage, death, and memory are not as well-defined as commonly thought, and need considerable revision to account for the possible spectrum of living entities. Here, I review fascinating examples of experimental biology illustrating that the boundaries demarcating somatic and cognitive Selves are fluid, providing an opportunity to sharpen inquiries about how evolution exploits physical forces for multi-scale cognition. Developmental (pre-neural) bioelectricity contributes a novel perspective on how the dynamic control of growth and form of the body evolved into sophisticated cognitive capabilities. Most importantly, the development of functional biobots – synthetic living machines with behavioral capacity – provides a roadmap for greatly expanding our understanding of the origin and capacities of cognition in all of its possible material implementations, especially those that emerge de novo, with no lengthy evolutionary history of matching behavioral programs to bodyplan. Viewing fundamental questions through the lens of new, constructed living forms will have diverse impacts, not only in basic evolutionary biology and cognitive science, but also in regenerative medicine of the brain and in artificial intelligence.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2021.110967,Journal,Energy and Buildings,scopus,2021-07-15,sciencedirect,"A non-intrusive approach for fault detection and diagnosis of water distribution systems based on image sensors, audio sensors and an inspection robot",https://api.elsevier.com/content/abstract/scopus_id/85104453372,"Fault diagnosis is important to maintain the normal operation of air-conditioning systems, reduce the energy consumption in buildings, and increase the service life of air-conditioning system equipment. We present a novel approach for fault detection and diagnosis system that relies on image and audio sensors and relevant algorithms.
                  This paper proposes a fault diagnosis algorithm based on a robot that can automatically capture audio and image signals from microphone arrays and cameras during inspection in a chiller room. It includes audio- and image-based fault diagnosis algorithms. The validity of the algorithm combined with sensors is verified using data from actual equipment in a chiller room.
                  The audio-based algorithm, which can monitor the abnormal sound of pumps to detect faults, utilizes Fourier transform, a finite impulse response digital filter, and an autoregressive integrated moving average model. We analyze the frequency domain of the pump signal and set the appropriate threshold to monitor abnormal signals based on the fitted model. Meanwhile, the image-based algorithms are divided into three sections to achieve three functions: 1) an AlexNet convolutional neural network is modified to classify the images of the chiller room equipment obtained by the visible light camera; 2) image morphology methods and trigonometric functions are used to read the dials’ indicators acquired by the visible light camera; and 3) optical character recognition is used to obtain the highest temperature value in the infrared image of the pump captured by the infrared camera, which helps maintenance staff verify the operation of the pump and detect faults as soon as possible.
                  These diagnostic algorithms are non-intrusive, low cost, and easy to deploy. Combined with real-time data collection from the sensors on the robot, the algorithms can effectively improve the intelligence of the equipment room and allocate human resources more reasonably.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ebiom.2021.103465,Journal,EBioMedicine,scopus,2021-07-01,sciencedirect,A mass spectrometry-based targeted assay for detection of SARS-CoV-2 antigen from clinical specimens,https://api.elsevier.com/content/abstract/scopus_id/85109005451,"Background
                  The COVID-19 pandemic caused by severe acute respiratory syndrome-coronavirus 2 (SARS-CoV-2) has overwhelmed health systems worldwide and highlighted limitations of diagnostic testing. Several types of diagnostic tests including RT-PCR-based assays and antigen detection by lateral flow assays, each with their own strengths and weaknesses, have been developed and deployed in a short time.
               
                  Methods
                  Here, we describe an immunoaffinity purification approach followed a by high resolution mass spectrometry-based targeted qualitative assay capable of detecting SARS-CoV-2 viral antigen from nasopharyngeal swab samples. Based on our discovery experiments using purified virus, recombinant viral protein and nasopharyngeal swab samples from COVID-19 positive patients, nucleocapsid protein was selected as a target antigen. We then developed an automated antibody capture-based workflow coupled to targeted high-field asymmetric waveform ion mobility spectrometry (FAIMS) - parallel reaction monitoring (PRM) assay on an Orbitrap Exploris 480 mass spectrometer. An ensemble machine learning-based model for determining COVID-19 positive samples was developed using fragment ion intensities from the PRM data.
               
                  Findings
                  The optimized targeted assay, which was used to analyze 88 positive and 88 negative nasopharyngeal swab samples for validation, resulted in 98% (95% CI = 0.922–0.997) (86/88) sensitivity and 100% (95% CI = 0.958–1.000) (88/88) specificity using RT-PCR-based molecular testing as the reference method.
               
                  Interpretation
                  Our results demonstrate that direct detection of infectious agents from clinical samples by tandem mass spectrometry-based assays have potential to be deployed as diagnostic assays in clinical laboratories, which has hitherto been limited to analysis of pure microbial cultures.
               
                  Funding
                  This study was supported by DBT/Wellcome Trust India Alliance Margdarshi Fellowship grant IA/M/15/1/502023 awarded to AP and the generosity of Eric and Wendy Schmidt.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2021.105826,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2021-07-01,sciencedirect,Automatic Acute Stroke Symptom Detection and Emergency Medical Systems Alerting by Mobile Health Technologies: A Review,https://api.elsevier.com/content/abstract/scopus_id/85107711467,"Objectives
                  To survey recent advances in acute stroke symptom automatic detection and Emergency Medical Systems (EMS) alerting by mobile health technologies.
               
                  Materials and methods
                  Narrative review
               
                  Results
                  Delayed activation of EMS for stroke symptoms by patients and witnesses deprives patients of rapid access to brain-saving therapies and occurs due to public unawareness of stroke features, cognitive and motor deficits produced by the stroke itself, and sleep onset. A promising emerging approach to overcoming the inherent biologic constraints of patient capacity to self-detect and respond to stroke symptoms is continuous monitoring by mobile health technologies with wireless sensors and artificial intelligence recognition systems. This review surveys 11 sensing technologies - accelerometers, gyroscopes, magnetometers, pressure sensors, touch screen and keyboard input detectors, artificial vision, and artificial hearing; and 10 consumer device form factors in which they are increasingly implemented: smartphones, smart speakers, smart watches and fitness bands, smart speakers/voice assistants, home health robots, smart clothing, smart beds, closed circuit television, smart rings, and desktop/laptop/tablet computers.
               
                  Conclusions
                  The increase in computing power, wearable sensors, and mobile connectivity have ushered in an array of mobile health technologies that can transform stroke detection and EMS activation. By continuously monitoring a diverse range of biometric parameters, commercially available devices provide the technologic capability to detect cardinal language, motor, gait, and sensory signs of stroke onset. Intensified translational research to convert the promise of these technologies to validated, accurate real-world deployments are an important next priority for stroke investigation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106130,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-07-01,sciencedirect,"Chest x-ray automated triage: A semiologic approach designed for clinical implementation, exploiting different types of labels through a combination of four Deep Learning architectures",https://api.elsevier.com/content/abstract/scopus_id/85107617149,"Background and objectives
                  The multiple chest x-ray datasets released in the last years have ground-truth labels intended for different computer vision tasks, suggesting that performance in automated chest x-ray interpretation might improve by using a method that can exploit diverse types of annotations. This work presents a Deep Learning method based on the late fusion of different convolutional architectures, that allows training with heterogeneous data with a simple implementation, and evaluates its performance on independent test data. We focused on obtaining a clinically useful tool that could be successfully integrated into a hospital workflow.
               
                  Materials and methods
                  Based on expert opinion, we selected four target chest x-ray findings, namely lung opacities, fractures, pneumothorax and pleural effusion. For each finding we defined the most suitable type of ground-truth label, and built four training datasets combining images from public chest x-ray datasets and our institutional archive. We trained four different Deep Learning architectures and combined their outputs with a late fusion strategy, obtaining a unified tool. The performance was measured on two test datasets: an external openly-available dataset, and a retrospective institutional dataset, to estimate performance on the local population.
               
                  Results
                  The external and local test sets had 4376 and 1064 images, respectively, for which the model showed an area under the Receiver Operating Characteristics curve of 0.75 (95%CI: 0.74–0.76) and 0.87 (95%CI: 0.86–0.89) in the detection of abnormal chest x-rays. For the local population, a sensitivity of 86% (95%CI: 84–90), and a specificity of 88% (95%CI: 86–90) were obtained, with no significant differences between demographic subgroups. We present examples of heatmaps to show the accomplished level of interpretability, examining true and false positives.
               
                  Conclusion
                  This study presents a new approach for exploiting heterogeneous labels from different chest x-ray datasets, by choosing Deep Learning architectures according to the radiological characteristics of each pathological finding. We estimated the tool's performance on the local population, obtaining results comparable to state-of-the-art metrics. We believe this approach is closer to the actual reading process of chest x-rays by professionals, and therefore more likely to be successful in a real clinical setting.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.smhl.2021.100205,Journal,Smart Health,scopus,2021-07-01,sciencedirect,Wearable motion sensor-based chewing side detection,https://api.elsevier.com/content/abstract/scopus_id/85107281216,"Chewing side preference means a tendency to use one side to chew food more frequently than the other. Medical studies show that chewing side preference can result in lateral facial asymmetry, teeth abrasion, temporomandibular disorders, malocclusion, and stomach illness. To continuously detect chewing side preference and quantify its severity in daily life, several wearable sensor-based methods have been proposed in recent years. However, these methods are either intrusive or not fine-grained enough. In this paper, we propose a wearable motion sensor-based chewing side detection method. We observe that chewing activity generates mastication muscle bulge and skull vibration, which can be sensed by motion sensors worn on the mastication muscles. In addition, the muscle bulge and skull vibration of the chewing side are different from those of the non-chewing side. These observations motivate us to deploy motion sensors on the left and right temporalis muscles to detect chewing sides. We propose a heuristic-rules based method to exclude non-chewing data and segment each chew accurately. The relative difference series of the left and right sensors are then calculated to characterize the difference of muscle bulge and skull vibration between the chewing side and the non-chewing side. A two-class classifier is trained using long short-term memory (LSTM), an artificial recurrent neural network, to model the data samples and classify chewing sides. A real-world evaluation dataset of eight food types is collected from eight human subjects. The average detection accuracy reaches 84.8%. The highest detection accuracy for a single subject is up to 97.4%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2021.102083,Journal,Artificial Intelligence in Medicine,scopus,2021-07-01,sciencedirect,Multi-domain clinical natural language processing with MedCAT: The Medical Concept Annotation Toolkit,https://api.elsevier.com/content/abstract/scopus_id/85106551455,"Electronic health records (EHR) contain large volumes of unstructured text, requiring the application of information extraction (IE) technologies to enable clinical analysis. We present the open source Medical Concept Annotation Toolkit (MedCAT) that provides: (a) a novel self-supervised machine learning algorithm for extracting concepts using any concept vocabulary including UMLS/SNOMED-CT; (b) a feature-rich annotation interface for customizing and training IE models; and (c) integrations to the broader CogStack ecosystem for vendor-agnostic health system deployment. We show improved performance in extracting UMLS concepts from open datasets (F1:0.448–0.738 vs 0.429–0.650). Further real-world validation demonstrates SNOMED-CT extraction at 3 large London hospitals with self-supervised training over 
                        ∼
                     8.8B words from 
                        ∼
                     17M clinical records and further fine-tuning with 
                        ∼
                     6K clinician annotated examples. We show strong transferability (F1 > 0.94) between hospitals, datasets and concept types indicating cross-domain EHR-agnostic utility for accelerated clinical and research use cases.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jaip.2021.03.039,Journal,Journal of Allergy and Clinical Immunology: In Practice,scopus,2021-07-01,sciencedirect,Predicting Severe Asthma Exacerbations in Children: Blueprint for Today and Tomorrow,https://api.elsevier.com/content/abstract/scopus_id/85106217297,"Severe asthma exacerbations are the primary cause of morbidity and mortality in children with asthma. Accurate prediction of children at risk for severe exacerbations, defined as those requiring systemic corticosteroids, emergency department visit, and/or hospitalization, would considerably reduce health care utilization and improve symptoms and quality of life. Substantial progress has been made in identifying high-risk exacerbation-prone children. Known risk factors for exacerbations include demographic characteristics (ie, low income, minority race/ethnicity), poor asthma control, environmental exposures (ie, aeroallergen exposure/sensitization, concomitant viral infection), inflammatory biomarkers, genetic polymorphisms, and markers from other “omic” technologies. The strongest risk factor for a future severe exacerbation remains having had one in the previous year. Combining risk factors into composite scores and use of advanced predictive analytic techniques such as machine learning are recent methods used to achieve stronger prediction of severe exacerbations. However, these methods are limited in prediction efficiency and are currently unable to predict children at risk for impending (within days) severe exacerbations. Thus, we provide a commentary on strategies that have potential to allow for accurate and reliable prediction of children at risk for impending exacerbations. These approaches include implementation of passive, real-time monitoring of impending exacerbation predictors, use of population health strategies, prediction of severe exacerbation responders versus nonresponders to conventional exacerbation management, and considerations for preschool-age children who can be especially high risk. Rigorous prediction and prevention of severe asthma exacerbations is needed to advance asthma management and improve the associated morbidity and mortality.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2021.104450,Journal,Computers in Biology and Medicine,scopus,2021-07-01,sciencedirect,A comprehensive review and analysis of supervised-learning and soft computing techniques for stress diagnosis in humans,https://api.elsevier.com/content/abstract/scopus_id/85105598718,"Stress is the most prevailing and global psychological condition that inevitably disrupts the mood and behavior of individuals. Chronic stress may gravely affect the physical, mental, and social behavior of victims and consequently induce myriad critical human disorders. Herein, a review has been presented where supervised learning (SL) and soft computing (SC) techniques used in stress diagnosis have been meticulously investigated to highlight the contributions, strengths, and challenges faced in the implementation of these methods in stress diagnostic models. A three-tier review strategy comprising of manuscript selection, data synthesis, and data analysis was adopted. The issues in SL strategies and the potential possibility of using hybrid techniques in stress diagnosis have been intensively investigated. The strengths and weaknesses of different SL (Bayesian classifier, random forest, support vector machine, and nearest neighbours) and SC (fuzzy logic, nature-inspired, and deep learning) techniques have been presented to obtain clear insights into these optimization strategies. The effects of social, behavioral, and biological stresses have been highlighted. The psychological, biological, and behavioral responses to stress have also been briefly elucidated. The findings of the study confirmed that different types of data/signals (related to skin temperature, electro-dermal activity, blood circulation, heart rate, facial expressions, etc.) have been used in stress diagnosis. Moreover, there is a potential scope for using distinct nature-inspired computing techniques (Genetic Algorithm, Particle Swarm Optimization, Ant Colony Optimization, Whale Optimization Algorithm, Butterfly Optimization, Harris Hawks Optimizer, and Crow Search Algorithm) and deep learning techniques (Deep-Belief Network, Convolutional-Neural Network, and Recurrent-Neural Network) on multimodal data compiled using behavioral testing, electroencephalogram signals, finger temperature, respiration rate, pupil diameter, galvanic-skin-response, and blood pressure. Likewise, there is a wider scope to investigate the use of SL and SC techniques in stress diagnosis using distinct dimensions such as sentiment analysis, speech recognition, handwriting recognition, and facial expressions. Finally, a hybrid model based on distinct computational methods influenced by both SL and SC techniques, adaption, parameter tuning, and the use of chaos, levy, and Gaussian distribution may address exploration and exploitation issues. However, factors such as real-time data collection, bias, integrity, multi-dimensional data, and data privacy make it challenging to design precise and innovative stress diagnostic systems based on artificial intelligence.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2021.116977,Journal,Applied Energy,scopus,2021-07-01,sciencedirect,Cloud-based health-conscious energy management of hybrid battery systems in electric vehicles with deep reinforcement learning,https://api.elsevier.com/content/abstract/scopus_id/85104708241,"In order to fulfill the energy and power demand of battery electric vehicles, a hybrid battery system with a high-energy and a high-power battery pack can be implemented as the energy source. This paper explores a cloud-based multi-objective energy management strategy for the hybrid architecture with a deep deterministic policy gradient, which increases the electrical and thermal safety, and meanwhile minimizes the system’s energy loss and aging cost. In order to simulate the electro-thermal dynamics and aging behaviors of the batteries, models are built for both high-energy and high-power cells based on the characterization and aging tests. A cloud-based training approach is proposed for energy management with real-world vehicle data collected from various road conditions. Results show the improvement of electrical and thermal safety, as well as the reduction of energy loss and aging cost of the whole system with the proposed strategy based on the collected real-world driving data. Furthermore, processor-in-the-loop tests verify that the proposed strategy can achieve a much higher convergence rate and a better performance in terms of the minimization of both energy loss and aging cost compared with state-of-the-art learning-based strategies.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jiac.2021.03.021,Journal,Journal of Infection and Chemotherapy,scopus,2021-07-01,sciencedirect,Efficacy and validity of automated quantitative chemiluminescent enzyme immunoassay for SARS-CoV-2 antigen test from saliva specimen in the diagnosis of COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85103977814,"Introduction
                  The pandemic of a novel coronavirus disease 2019 (COVID-19) caused by a severe acute respiratory coronavirus 2 (SARS-CoV-2) infection has been problematic worldwide. A new SARS-CoV-2 antigen test (LUMIPULSEⓇ) was licensed and widely used in Japan since May 2020. We conducted this study intending to whether the automated quantitative CLEIA antigen test using a saliva sample is effective and valid for the diagnosis of COVID-19.
               
                  Patients and methods
                  We analyzed and compared the diagnostic accuracy of both the automated quantitative CLEIA antigen test and real-time RT-PCR (rRT-PCR) using a saliva sample from individuals suspected as having COVID-19.
               
                  Results
                  A total of 305 samples were collected and tested in Aichi Medical University Hospital and affiliated facilities from December 2020 until January 2021 at our institute. Using reverse-transcription PCR as a reference, the AUROC of the automated quantitative CLEIA antigen test was 0.903 (95% confidential interval 0.845–0.962, p < 0.001). The appropriate cut-off antigen level was 4.0 pg/mL and had a sensitivity of 77.8%, a specificity of 99.6%, a positive predictive value of 98%, and a negative predictive value of 94.5%. On the other hand, the diagnostic accuracy of the antigen test decreased among patients among patients with COVID-19 with threshold cycle (Ct-value)≥27, which shows the AUROC was 0.795 (95%CI 0.687–0.907, p < 0.001).
               
                  Conclusion
                  While the automated quantitative CLEIA antigen test from saliva specimen could be one of the most useful diagnostic tests for the diagnosis of COVID-19 in general practice, clinicians should know the limitations of the antigen test.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.semcancer.2020.06.002,Journal,Seminars in Cancer Biology,scopus,2021-07-01,sciencedirect,Artificial intelligence for breast cancer detection in mammography and digital breast tomosynthesis: State of the art,https://api.elsevier.com/content/abstract/scopus_id/85086474184,"Screening for breast cancer with mammography has been introduced in various countries over the last 30 years, initially using analog screen-film-based systems and, over the last 20 years, transitioning to the use of fully digital systems. With the introduction of digitization, the computer interpretation of images has been a subject of intense interest, resulting in the introduction of computer-aided detection (CADe) and diagnosis (CADx) algorithms in the early 2000′s. Although they were introduced with high expectations, the potential improvement in the clinical realm failed to materialize, mostly due to the high number of false positive marks per analyzed image.
                  In the last five years, the artificial intelligence (AI) revolution in computing, driven mostly by deep learning and convolutional neural networks, has also pervaded the field of automated breast cancer detection in digital mammography and digital breast tomosynthesis. Research in this area first involved comparison of its capabilities to that of conventional CADe/CADx methods, which quickly demonstrated the potential of this new technology. In the last couple of years, more mature and some commercial products have been developed, and studies of their performance compared to that of experienced breast radiologists are showing that these algorithms are on par with human-performance levels in retrospective data sets. Although additional studies, especially prospective evaluations performed in the real screening environment, are needed, it is becoming clear that AI will have an important role in the future breast cancer screening realm. Exactly how this new player will shape this field remains to be determined, but recent studies are already evaluating different options for implementation of this technology.
                  The aim of this review is to provide an overview of the basic concepts and developments in the field AI for breast cancer detection in digital mammography and digital breast tomosynthesis. The pitfalls of conventional methods, and how these are, for the most part, avoided by this new technology, will be discussed. Importantly, studies that have evaluated the current capabilities of AI and proposals for how these capabilities should be leveraged in the clinical realm will be reviewed, while the questions that need to be answered before this vision becomes a reality are posed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacc.2021.04.072,Journal,Journal of the American College of Cardiology,scopus,2021-06-29,sciencedirect,Automated Prediction of Cardiorespiratory Deterioration in Patients With Single Ventricle,https://api.elsevier.com/content/abstract/scopus_id/85107757877,"Background
                  Patients with single-ventricle physiology have a significant risk of cardiorespiratory deterioration between their first and second stage palliation surgeries.
               
                  Objectives
                  The objective of this study is to develop and validate a real-time computer algorithm that can automatically recognize physiological precursors of cardiorespiratory deterioration in children with single-ventricle physiology during their interstage hospitalization.
               
                  Methods
                  A retrospective study was conducted from prospectively collected physiological data of subjects with single-ventricle physiology. Deterioration events were defined as a cardiac arrest requiring cardiopulmonary resuscitation or an unplanned intubation. Physiological metrics were derived from the electrocardiogram (heart rate, heart rate variability, ST-segment elevation, and ST-segment variability) and the photoplethysmogram (peripheral oxygen saturation and pleth variability index). A logistic regression model was trained to separate the physiological dynamics of the pre-deterioration phase from all other data generated by study subjects. Data were split 50/50 into model training and validation sets to enable independent model validation.
               
                  Results
                  Our cohort consisted of 238 subjects admitted to the cardiac intensive care unit and stepdown units of Texas Children’s Hospital over a period of 6 years. Approximately 300,000 h of high-resolution physiological waveform and vital sign data were collected using the Sickbay software platform (Medical Informatics Corp., Houston, Texas). A total of 112 cardiorespiratory deterioration events were observed. Seventy-two of the subjects experienced at least 1 deterioration event. The risk index metric generated by our optimized algorithm was found to be both sensitive and specific for detecting impending events 1 to 2 h in advance of overt extremis (receiver-operating characteristic curve area: 0.958; 95% confidence interval: 0.950 to 0.965).
               
                  Conclusions
                  Our algorithm can provide 1 to 2 h of advanced warning for 62% of all cardiorespiratory deterioration events in children with single-ventricle physiology during their interstage period, with only 1 alarm being generated at the bedside per patient per day.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.physrep.2021.03.002,Journal,Physics Reports,scopus,2021-06-25,sciencedirect,"Physical principles of brain–computer interfaces and their applications for rehabilitation, robotics and control of human brain states",https://api.elsevier.com/content/abstract/scopus_id/85103968577,"Brain–computer interfaces (BCIs) development is closely related to physics. In this paper, we review the physical principles of BCIs, and underlying novel approaches for registration, analysis, and control of brain activity. We analyze recent advances in BCI studies focusing on their applications for (i) controlling the movement of robots and exoskeletons, (ii) revealing and preventing brain pathologies, (iii) assessing and controlling psychophysiological states, and (iv) monitoring and controlling normal and pathological cognitive activity.
                  We consider the BCI as a hardware/software communication system that allows interaction of humans or animals with their surroundings without the involvement of peripheral nerves and muscles, using control signals generated from brain cerebral activity. Classifying BCIs into three main types (active, reactive and passive), we describe their functional models and neuroimaging methods, as well as novel techniques for signal enhancement and artifact recognition and avoidance, to improve BCI performance in real time. We also review different BCI applications, including communications, external device control, movement control, neuroprostheses, and assessment of human psychophysiological states.
                  Then, we describe the most common techniques for the analysis and classification of electroencephalographic (EEG) and magnetoencephalographic (MEG) data. Special attention is paid to modern technology based on machine learning and reservoir computing. We discuss main results on the creation and application of BCIs based on invasive and noninvasive EEG recordings. First, we consider neurointerfaces for controlling the movement of robots and exoskeletons. Second, we describe BCIs for diagnosis and control of pathological brain activity, in particular, epilepsy. We also discuss the results on the development of invasive BCIs for predicting and mitigating absence epileptic seizures. After that, we focus on passive neurointerfaces for assessing and controlling a person’s psychophysiological states and cognitive activity. Special attention is given to optogenetic brain interfaces using photostimulation to deliver intervention to specific cell types. We outline the basic principles of optogenetic neurocontrol and extracellular electrophysiology recording. We also describe the state-of-the-art of miniaturized closed-loop optogenetic devices to control normal and pathological brain activities.
                  Further, we discuss the new emerging technological trend in the BCI development which consists in using neurointerfaces to improve the interaction between people, so-called brain-to-brain interfaces (BBIs). Such interfaces can increase the efficiency of collaborative processes when working in a group. We propose a BBI which distributes a cognitive load among all team members working on a common task. This BBI allows sharing the workload among the participants according to their current cognitive performance, estimated from their electrical brain activity. The novel results of the brain-to-brain interaction are promising for the development of a new generation of communication systems based on the neurophysiological brain activity of interacting persons, where the BBI estimates physical conditions of each partner and adapts the assigned task accordingly.
                  Finally, we trace the main historical epochs in BCI development and applications and highlight possible future directions for this research area, including hybrid BCIs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2021.108057,Journal,Computer Networks,scopus,2021-06-19,sciencedirect,A deep reinforcement learning-based multi-optimality routing scheme for dynamic IoT networks,https://api.elsevier.com/content/abstract/scopus_id/85104075448,"With the development of Internet of Things (IoT) and 5G technologies, more and more applications, such as autonomous vehicles and tele-medicine, become more sensitive to network latency and accuracy, which require routing schemes to be more flexible and efficient. In order to meet such urgent need, learning-based routing strategies are emerging as strong candidate solutions, with the advantages of high flexibility and accuracy. These strategies can be divided into two categories, centralized and distributed, enjoying the advantages of high precision and high efficiency, respectively. However, routing becomes more complex in dynamic IoT network, where the link connections and access states are time-varying, hence these learning-based routing mechanisms are required to have the capability to adapt to network changes in real time. In this paper, we designed and implemented both centralized and distributed Reinforcement Learning-based Routing schemes combined with Multi-optimality routing criteria (RLR-M). By conducting a series of experiments, we performed a comprehensive analysis of the results and arrived at the conclusion that the centralized is better suited to cope with dynamic networks due to its faster reconvergence (2.2 
                        ×
                      over distributed), while the distributed is better positioned to handle with large-scale networks through its high scalability (1.6 
                        ×
                      over centralized). Moreover, the multi-optimality routing scheme is implemented through model fusion, which is more flexible than traditional strategies and as such is better placed to meet the needs of IoT.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2020.107510,Journal,Mechanical Systems and Signal Processing,scopus,2021-06-16,sciencedirect,Metric-based meta-learning model for few-shot fault diagnosis under multiple limited data conditions,https://api.elsevier.com/content/abstract/scopus_id/85100211264,"The real-world large industry has gradually become a data-rich environment with the development of information and sensor technology, making the technology of data-driven fault diagnosis acquire a thriving development and application. The success of these advanced methods depends on the assumption that enough labeled samples for each fault type are available. However, in some practical situations, it is extremely difficult to collect enough data, e.g., when the sudden catastrophic failure happens, only a few samples can be acquired before the system shuts down. This phenomenon leads to the few-shot fault diagnosis aiming at distinguishing the failure attribution accurately under very limited data conditions. In this paper, we propose a new approach, called Feature Space Metric-based Meta-learning Model (FSM3), to overcome the challenge of the few-shot fault diagnosis under multiple limited data conditions. Our method is a mixture of general supervised learning and episodic metric meta-learning, which will exploit both the attribute information from individual samples and the similarity information from sample groups. The experiment results demonstrate that our method outperforms a series of baseline methods on the 1-shot and 5-shot learning tasks of bearing and gearbox fault diagnosis across various limited data conditions. The time complexity and implementation difficulty have been analyzed to show that our method has relatively high feasibility. The feature embedding is visualized by t-SNE to investigate the effectiveness of our proposed model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.energy.2021.120152,Journal,Energy,scopus,2021-06-15,sciencedirect,Fuzzy logic and Elman neural network tuned energy management strategies for a power-split HEVs,https://api.elsevier.com/content/abstract/scopus_id/85102149995,"This paper focuses on optimal energy sharing between the two sources i.e., the internal combustion engine and the battery-powered electric motor in a hybrid electric vehicle (HEV). It is necessary that these sources operate in their efficient operating region while fulfilling the energy demanded by the vehicle to obtain the maximum fuel economy. As both of these sources have different operating characteristic and vehicle running conditions, the situation requires a smart controller to address this problem appropriately. In this work, fuzzy logic and Elman neural network-based adaptive energy management strategies (EMS) in an HEV are designed and implemented. The input parameters to these EMS are torque demand, battery state of charge, and regenerative braking. The proposed strategy aims to maximise the fuel economy while maintaining the battery health. A power-split HEV along with EMS is designed, modelled and simulated in MATLAB/Simulink first and then the whole system is validated in real-time using controller hardware in the loop testing platform (CHIL). The FPGA based MicroLabBox CHIL has been employed to test the system behaviour in real-time. The proposed EMS have been compared with conventional strategies and the comparison reveals that the Elman neural network-based method results in higher fuel economy, faster response, and minimal mismatch between desired and attained vehicle speeds.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.01.124,Journal,Neurocomputing,scopus,2021-06-07,sciencedirect,"Predicting energy cost of public buildings by artificial neural networks, CART, and random forest",https://api.elsevier.com/content/abstract/scopus_id/85101355528,"The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.24920/003821,Journal,Chinese Medical Sciences Journal,scopus,2021-06-01,sciencedirect,"Epidemiologic Features, Radiological Findings and Clinical Outcomes of 19 Patients with COVID-19 in a Single Center in Beijing, China",https://api.elsevier.com/content/abstract/scopus_id/85109461384,"Objective
                  To describe the epidemiologic, clinical, laboratory, and radiological characteristics and prognoses of COVID-19 confirmed patients in a single center in Beijing, China.
               
                  Methods
                  The study retrospectively included 19 patients with nucleic acid-confirmed SARS-CoV-2 infection at our hospital from January 20 to March 5, 2020. The final follow-up date was March 14, 2020. The epidemiologic and clinical information was obtained through direct communication with the patients or their family members. Laboratory results retrieved from medical records and radiological images were analyzed both qualitatively by two senior chest radiologists as well as quantitatively via an artificial intelligence software.
               
                  Results
                  We identified 5 family clusters (13/19, 68.4%) from the study cohort. All cases had good clinical prognoses and were either mild (3/19) or moderate (16/19) clinical types. Fever (15/19, 78.9%) and dry cough (11/19, 57.9%) were common symptoms. Two patients received negative results for more than three consecutive viral nucleic acid tests. The longest interval between an initial CT abnormal finding and a confirmed diagnosis was 30 days. One patient's nucleic acid test turned positive on the follow-up examination after discharge. The presence of radiological abnormalities was non-specific for the diagnosis of COVID-19.
               
                  Conclusions
                  COVID-19 patients with mild or no clinical symptoms are common in Beijing, China. Radiological abnormalities are mostly non-specific and massive CT examinations for COVID-19 screening should be avoided. Analyses of the contact histories of diagnosed cases in combination with clinical, radiological and laboratory findings are crucial for the early detection of COVID-19. Close monitoring after discharge is also recommended.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2589-7500(21)00005-4,Journal,The Lancet Digital Health,scopus,2021-06-01,sciencedirect,Health information technology and digital innovation for national learning health and care systems,https://api.elsevier.com/content/abstract/scopus_id/85106359380,"Health information technology can support the development of national learning health and care systems, which can be defined as health and care systems that continuously use data-enabled infrastructure to support policy and planning, public health, and personalisation of care. The COVID-19 pandemic has offered an opportunity to assess how well equipped the UK is to leverage health information technology and apply the principles of a national learning health and care system in response to a major public health shock. With the experience acquired during the pandemic, each country within the UK should now re-evaluate their digital health and care strategies. After leaving the EU, UK countries now need to decide to what extent they wish to engage with European efforts to promote interoperability between electronic health records. Major priorities for strengthening health information technology in the UK include achieving the optimal balance between top-down and bottom-up implementation, improving usability and interoperability, developing capacity for handling, processing, and analysing data, addressing privacy and security concerns, and encouraging digital inclusivity. Current and future opportunities include integrating electronic health records across health and care providers, investing in health data science research, generating real-world data, developing artificial intelligence and robotics, and facilitating public–private partnerships. Many ethical challenges and unintended consequences of implementation of health information technology exist. To address these, there is a need to develop regulatory frameworks for the development, management, and procurement of artificial intelligence and health information technology systems, create public–private partnerships, and ethically and safely apply artificial intelligence in the National Health Service.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2021.106156,Journal,Computers and Electronics in Agriculture,scopus,2021-06-01,sciencedirect,A system for automatic rice disease detection from rice paddy images serviced via a Chatbot,https://api.elsevier.com/content/abstract/scopus_id/85104652334,"A LINE Bot System to diagnose rice diseases from actual paddy field images was developed and presented in this paper. It was easy-to-use and automatic system designed to help rice farmers improve the rice yield and quality. The targeted images were taken from the actual paddy environment without special sample preparation. We used a deep learning neural networks technique to detect rice diseases from the images. We developed an object detection model training and refinement process to improve the performance of our previous research on rice leave diseases detection. The process was based on analyzing the model’s predictive results and could be repeatedly used to improve the quality of the database in the next training of the model. The deployment model for our LINE Bot system was created from the selected best performance technique in our previous paper, YOLOv3, trained by refined training data set. The performance of the deployment model was measured on 5 target classes and found that the Average True Positive Point improved from 91.1% in the previous paper to 95.6% in this study. Therefore, we used this deployment model for Rice Disease LINE Bot system. Our system worked automatically real-time to suggest primary diagnosis results to the users in the LINE group, which included rice farmers and rice disease specialists. They could communicate freely via chat. In the real LINE Bot deployment, the model’s performance was measured by our own defined measurement Average True Positive Point and was found to be an average of 78.86%. The system was fast and took only 2–3 s for detection process in our system server.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106071,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-06-01,sciencedirect,Computer-aided diagnosis system for the classification of multi-class kidney abnormalities in the noisy ultrasound images,https://api.elsevier.com/content/abstract/scopus_id/85104342062,"Background and Objective: The primary causes of kidney failure are chronic and polycystic kidney diseases. Cyst, stone, and tumor development lead to chronic kidney diseases that commonly impair kidney functions. The kidney diseases are asymptomatic and do not show any significant symptoms at its initial stage. Therefore, diagnosing the kidney diseases at their earlier stage is required to prevent the loss of kidney function and kidney failure.
                  
                     Methods: This paper proposes a computer-aided diagnosis (CAD) system for detecting multi-class kidney abnormalities from ultrasound images. The presented CAD system uses a pre-trained ResNet-101 model for extracting the features and support vector machine (SVM) classifier for the classification purpose. Ultrasound images usually gets affected by speckle noise that degrades the image quality and performance of the CAD system. Hence, it is necessary to remove speckle noise from the ultrasound images. Therefore, a CAD based system is proposed with the despeckling module using a deep residual learning network (RLN) to reduce speckle noise. Pre-processing of ultrasound images using deep RLN helps to drastically improve the classification performance of the CAD system. The proposed CAD system achieved better prediction results when compared to the existing state-of-the-art methods.
                  
                     Results: To validate the proposed CAD system performance, the experiments have been carried out in the noisy kidney ultrasound images. The designed system framework achieved the maximum classification accuracy when compared to the existing approaches. The SVM classifier is selected for the CAD system based on performance comparison with various classifiers like K-nearest neighbour, tree, discriminant, Naive Bayes, and linear.
                  
                     Conclusions: The proposed CAD system outperforms in classifying the noisy kidney ultrasound images precisely as compared to the existing state-of-the-art methods. Further, the CAD system is evaluated in terms of selectivity and sensitivity scores. The presented CAD system with the pre-processing module would serve as a real-time supporting tool for diagnosing multi-class kidney abnormalities from the ultrasound images.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijpe.2021.108114,Journal,International Journal of Production Economics,scopus,2021-06-01,sciencedirect,Machine learning-based predictive maintenance: A cost-oriented model for implementation,https://api.elsevier.com/content/abstract/scopus_id/85104317955,"Predictive Maintenance (PdM) is a condition-based maintenance strategy (CBM) that carries out maintenance action when needed, avoiding unnecessary preventive actions or failures. Machine learning (ML), in the form of advanced monitoring and diagnosis technologies, has become increasingly attractive. Implementing ML-based PdM is a difficult and expensive process, especially for those companies which often lack the necessary skills and financial and labour resources. Thus, a cost-oriented analysis is required to define when ML-based PdM is the most suitable maintenance strategy. The implementation of this strategy involves investment costs in IT technologies, in addition to costs incurred from traditional maintenance activities depending of the performance of the ML model classifier; however, no previous research consider both costs in the economic evaluation of PdM.This paper aims to provide a mathematical model where investment costs are included and the ML performance is evaluated in terms of the probability to correctly intercept faults. A error matrix is used to quantify costs due to maintenance actions. Moreover, the mathematical model provides a cost-based quantitative method, based on the Receiver Operating Characteristics (ROC) curve. This optimizes the decision threshold of the ML model classifier, which allows the maintenance costs to be minimized in comparison to traditional decision threshold optimisation methods. Based on the mathematical model, a useful Decision Support System (DSS) that guides PdM implementation is introduced. Finally, the DSS is applied to a real case study to illustrate its applicability.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scp.2021.100415,Journal,Sustainable Chemistry and Pharmacy,scopus,2021-06-01,sciencedirect,Green chemistry and coronavirus,https://api.elsevier.com/content/abstract/scopus_id/85104072773,"The novel coronavirus pandemic has rapidly spread around the world since December 2019. Various techniques have been applied in identification of SARS-CoV-2 or COVID-19 infection including computed tomography imaging, whole genome sequencing, and molecular methods such as reverse transcription polymerase chain reaction (RT-PCR). This review article discusses the diagnostic methods currently being deployed for the SARS-CoV-2 identification including optical biosensors and point-of-care diagnostics that are on the horizon. These innovative technologies may provide a more accurate, sensitive and rapid diagnosis of SARS-CoV-2 to manage the present novel coronavirus outbreak, and could be beneficial in preventing any future epidemics. Furthermore, the use of green synthesized nanomaterials in the optical biosensor devices could leads to sustainable and environmentally-friendly approaches for addressing this crisis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2214-109X(21)00059-0,Journal,The Lancet Global Health,scopus,2021-06-01,sciencedirect,The injustice of unfit clinical practice guidelines in low-resource realities,https://api.elsevier.com/content/abstract/scopus_id/85103953372,"To end the international crisis of preventable deaths in low-income and middle-income countries, evidence-informed and cost-efficient health care is urgently needed, and contextualised clinical practice guidelines are pivotal. However, as exposed by indirect consequences of poorly adapted COVID-19 guidelines, fundamental gaps continue to be reported between international recommendations and realistic best practice. To address this long-standing injustice of leaving health providers without useful guidance, we draw on examples from maternal health and the COVID-19 pandemic. We propose a framework for how global guideline developers can more effectively stratify recommendations for low-resource settings and account for predictable contextual barriers of implementation (eg, human resources) as well as gains and losses (eg, cost-efficiency). Such development of more realistic clinical practice guidelines at the global level will pave the way for simpler and achievable adaptation at local levels. We also urge the development and adaptation of high-quality clinical practice guidelines at national and subnational levels in low-income and middle-income countries through co-creation with end-users, and we encourage global sharing of these experiences.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106037,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-06-01,sciencedirect,CBRA: Cardiac biomarkers release analyzer,https://api.elsevier.com/content/abstract/scopus_id/85103660432,"Background and objectives
                  The most advanced technologies and continuous innovations in the medical field require a necessary interaction between the clinical and the engineering world. In this context, software applications are proposed as a bridge between the two scientific fields and, therefore, as powerful tools, easy to use, and with great analytical skills. In this work, we propose CBRA as an innovative software platform, moving towards personalized medicine, which aims to simplify and speed up the triage of patients and support doctors in the diagnostic and prognostic phase.
               
                  Methods
                  The computational core of the devised software application consists of a model-based identification algorithm, which enables the reconstruction of the cardiac biomarkers release curves in patients with ST-Elevation Acute Myocardial Infarction (STEMI). Identification and parametric optimization techniques allow the application of the proposed approach to each singular patient: based on a few experimental acquisitions, CBRA can extrapolate several quantitative features of high clinical relevance, thus facilitating and rendering more objective the clinical evaluation and therapeutic choices. A dedicated database to collect and manage patients clinical and personal data, as well as a graphical user interface, provides clinicians and researchers with an intuitive and user-friendly environment.
               
                  Results
                  In the following work, we present some examples of the possible applications of CBRA, ranging from the management of the cardiac biomarkers time-series, up to the real analysis of the clinical features that CBRA can extract from the reconstructed curve, such as, e.g., maximum concentration values of biomarkers in the plasma and relative times, in the distinct phases of the acute myocardial infarction, or identification of the time to onset of symptoms.
               
                  Conclusions
                  CBRA makes it easy for clinicians to use modeling and parametric identification tools to reconstruct release curves. Furthermore, CBRA provides support to the clinical decision, thanks to its capability to extract information of high clinical relevance, not easily obtainable from the mere visual analysis of experimental samples. Having information about the previously listed clinical parameters could allow, e.g., identify in which stage of AMI the patient is, when She/He goes to the emergency room, with significant benefits in the therapy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rser.2021.110889,Journal,Renewable and Sustainable Energy Reviews,scopus,2021-06-01,sciencedirect,"Artificial intelligence and internet of things to improve efficacy of diagnosis and remote sensing of solar photovoltaic systems: Challenges, recommendations and future directions",https://api.elsevier.com/content/abstract/scopus_id/85101928488,"Currently, a huge number of photovoltaic plants have been installed worldwide and these plants should be carefully protected and supervised continually in order to be safe and reliable during their working lifetime. Photovoltaic plants are subject to different types of faults and failures, while available fault detection equipment are mainly used to protect and isolate the photovoltaic plants from some faults (such as arc fault, line-to-line, line-to-ground and ground faults). Although a good number of international standards (IEC, NEC, and UL) exists, undetectable faults continue to create serious problems in photovoltaic plants. Thus, designing smart equipment, including artificial intelligence and internet of things for remote sensing and fault detection and diagnosis of photovoltaic plants, will considerably solve the shortcomings of existing methods and commercialized equipment. This paper presents an overview of artificial intelligence and internet of things applications in photovoltaic plants. This research presents also the most advanced algorithms such as machine and deep learning, in terms of cost implementation, complexity, accuracy, software suitability, and feasibility of real-time applications. The embedding of artificial intelligence and internet of things techniques for fault detection and diagnosis into simple hardware, such as low-cost chips, may be economical and technically feasible for photovoltaic plants located in remote areas, with costly and challenging accessibility for maintenance. Challenging issues, recommendations, and trends of these techniques will also be presented in this paper.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.vph.2021.106838,Journal,Vascular Pharmacology,scopus,2021-06-01,sciencedirect,Interleukin-10 does not contribute to the anti-contractile nature of PVAT in health,https://api.elsevier.com/content/abstract/scopus_id/85100685883,"Perivascular adipose tissue (PVAT) is protective and reduces contraction of blood vessels in health. PVAT is composed of adipocytes, multiple types of immune cells and stromal cells. Interleukin (IL)-10, an anti-inflammatory cytokine usually produced by T cells, B cells and macrophages, was identified as one of the highly expressed (mRNA) cytokines in the mesenteric PVAT of healthy rats. One report suggested that exogenous IL-10 causes relaxation of mouse mesenteric arteries, also suggesting that IL-10 maybe a potential anti-contractile factor. Hence, we hypothesized that PVAT-derived IL-10 causes vasorelaxation and/or reduces vasoconstriction, thus contributing to the anti-contractile nature of PVAT in health. Mesenteric arteries from rats and mice expressed the receptor for IL-10 (in tunica intima and media) as determined by immunohistochemistry. Mesenteric resistance arteries for rats and superior mesenteric artery for mice were used for isometric contractility studies. Increasing concentrations [0.4–100 ng/mL] of recombinant rat/mouse (rr/mr) IL-10 or vehicle was directly added to half-maximally constricted (phenylephrine, PE) vessels (without PVAT, with endothelium). IL-10 did not cause a direct vasorelaxation. Further, the ability of rrIL-10 to cause a rightward or downward shift of a vasoconstriction-response curve was tested in the rat. The vessels were incubated with rrIL-10 [100 ng/mL or 10 ng/mL] or vehicle for 1.5 h in the tissue bath followed by a cumulative PE [10−8–10−4 M] or U46619 [10−10–10−5 M] response curve. The maximal contractions and EC50 values were similar in IL-10 incubated vessels vs vehicle. Thus, acute exposure of exogenous IL-10 did not reduce local vasoconstriction. To further test if endogenous IL-10 from PVAT was anti-contractile, superior mesenteric arteries from IL-10 WT and KO mice, with and without PVAT, were subjected to increasing concentrations of PE. The anti-contractile nature of PVAT was preserved with both short-term and prolonged depletion (using younger and older mice, respectively) of endogenous IL-10 in males and females. Contrary to our hypothesis, PVAT-derived IL-10 neither caused vasorelaxation nor reduced local vasoconstriction directly/indirectly. Therefore, IL-10 does not contribute to the anti-contractile nature of PVAT in healthy rodents.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2021.114568,Journal,Expert Systems with Applications,scopus,2021-06-01,sciencedirect,An expert system for EMI data classification based on complex Bispectrum representation and deep learning methods,https://api.elsevier.com/content/abstract/scopus_id/85100040048,"This paper presents expert system framework based on Machine Learning (ML) for High-Voltage (HV) asset condition monitoring. The work investigates the classification of insulation faults in HV environment, based on real-world time series signals labelled by condition monitoring experts. Extending on our previous work, the proposed approach exploits the Bispectrum analysis and deep learning for feature extraction and classification. The calculated Bispectrum on time series signals can be deployed as the complex-valued Bispectrum, which contains phase information, or as its real-valued magnitude. This can be approached as an image classification problem which can be implemented in various deep networks including Convolutional Neural Network (CNN), Residual Neural Network (ResNet) and their complex-valued version. The employed deep networks performance is compared in terms of their classification accuracy. High classification performance is obtained which produces comparable performance with expert diagnosis. Thus, it can be interpreted as transfer of expert system to an intelligent system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bpg.2020.101722,Journal,Best Practice and Research: Clinical Gastroenterology,scopus,2021-06-01,sciencedirect,Striving for quality improvement: can artificial intelligence help?,https://api.elsevier.com/content/abstract/scopus_id/85099293210,"Artificial intelligence (AI) is of keen interest for global health development as potential support for current human shortcomings. Gastrointestinal (GI) endoscopy is an excellent substrate for AI, since it holds the genuine potential to improve quality in GI endoscopy and overall patient care by improving detection and diagnosis guiding the endoscopists in performing endoscopy to the highest quality standards. The possibility of large data acquisitioning to refine algorithms makes implementation of AI into daily practice a potential reality. With the start of a new era adopting deep learning, large amounts of data can easily be processed, resulting in better diagnostic performances. In the upper gastrointestinal tract, research currently focusses on the detection and characterization of neoplasia, including Barrett’s, squamous cell and gastric carcinoma, with an increasing amount of AI studies demonstrating the potential and benefit of AI–augmented endoscopy. Deep learning applied to small bowel video capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. In the colon, multiple prospective trials including five randomized trials, showed a consistent improvement in polyp and adenoma detection rates, one of the main quality indicators in endoscopy. There are however potential additional roles for AI to assist in quality improvement of endoscopic procedures, training and therapeutic decision making. Further large-scale, multicenter validation trials are required before AI–augmented diagnostic gastrointestinal endoscopy can be integrated into our routine clinical practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bpg.2020.101721,Journal,Best Practice and Research: Clinical Gastroenterology,scopus,2021-06-01,sciencedirect,Colorectal polyp characterization with endocytoscopy: Ready for widespread implementation with artificial intelligence?,https://api.elsevier.com/content/abstract/scopus_id/85098512500,"Endocytoscopy provides an in-vivo visualization of nuclei and micro-vessels at the cellular level in real-time, facilitating so-called “optical biopsy” or “virtual histology” of colorectal polyps/neoplasms. This functionality is enabled by 520-fold magnification power with endocytoscopy and recent breakthroughs in artificial intelligence (AI) allowing a great advance in endocytoscopic imaging; interpretation of images is now fully supported by AI tool which outputs predictions of polyp histopathology during colonoscopy. The advantage of the use of AI during optical biopsy can be appreciated especially by non-expert endoscopists who to increase performance.
                  This paper provides an overview of the latest evidence on colorectal polyp characterization with endocytoscopy combined with AI and identify the barriers to its widespread implementation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jclepro.2021.126493,Journal,Journal of Cleaner Production,scopus,2021-05-15,sciencedirect,High-resolution prediction of the spatial distribution of PM<inf>2.5</inf> concentrations in China using a long short-term memory model,https://api.elsevier.com/content/abstract/scopus_id/85102349520,"The concentration of fine particulate matter (PM2.5) has a significant impact on the environment and human health. However, strong spatial heterogeneity and spatiotemporal dependence increases the difficulty of prediction. Moreover, due to the lag of the update of auxiliary variables at national scale in the prediction application, it is still difficult to achieve the timely nationwide PM2.5 prediction at present. To better model and predict real time concentrations and spatial distributions of PM2.5, this study developed a workflow of future PM2.5 concentrations prediction based on long short-term memory (LSTM) model. Using ground-based station PM2.5 data in 2014–2018, the 1 km Multi-Angle Implementation of Atmospheric Correction (MAIAC) aerosol optical depth (AOD) product and other auxiliary data to predict PM2.5 concentrations in the next year and generate a high-resolution national PM2.5 concentration spatial distribution map. The LSTM model outperformed random forest (RF) and Cubist approaches for prediction PM2.5 because of its recurrent neural network structure that can capture time dependence and nonlinear relationships among PM2.5 concentrations and other independent variables, and exhibited a stable accuracy with an R2 of 0.83, by applying the annual time series, with an improvement of 0.04–0.09, compared to daily and monthly data. The results indicated that PM2.5 pollution had gradually decreased in 2019 after application of pollution controls, with annual mean PM2.5 concentrations of 27.33 ± 15.56 μg m−3, although there were still some areas with severe pollution, including the North China Plain, parts of the Loess Plateau, and the Taklimakan Desert. The LSTM model makes it possible to predict fine-scale PM2.5 spatial distributions nationwide in the future and may thus be useful for sustainable management and control of air pollution at a national scale.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engstruct.2021.112084,Journal,Engineering Structures,scopus,2021-05-15,sciencedirect,Human-machine collaboration framework for structural health monitoring and resiliency,https://api.elsevier.com/content/abstract/scopus_id/85102047246,"Post-earthquake damage assessment can be significantly expedited when machine learning (ML) algorithms supported by sensing technologies are used. ML has some limitations when it comes to seismic damage assessment. ML tools require data from each class while training but in the case of seismic structural health monitoring, vibration data are usually available from the undamaged structures. In this paper, a framework called the human-machine collaboration (H-MC) is proposed. The H-MC framework combines the ML tools and human (domain) expertise for damage assessment of real instrumented buildings with only data from undamaged cases. It uses novelty detection as the ML tool and structure-specific analytical model to enable rapid damage detection. Subsequently, the framework is applied to detect damage in real instrumented buildings. The results showed that the H-MC algorithm correctly detected the damaged cases. It also labeled all the undamaged events accurately eliminating false positive detection. Furthermore, it is revealed that the resiliency of a building can be improved when the H-MC method is implemented over traditional field inspection. The proposed framework can be a viable tool for rapid post-earthquake damage assessment which is essential for improving community resiliency.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijcard.2021.01.035,Journal,International Journal of Cardiology,scopus,2021-05-15,sciencedirect,Application of cardiac computed tomographic imaging and fluoroscopy fusion for guiding left atrial appendage occlusion,https://api.elsevier.com/content/abstract/scopus_id/85101317960,"Objective
                  Evaluate the value of 3D computed tomography (CT) and CT-integrating fluoroscopy for procedural guidance during WATCHMAN implantation.
               
                  Methods
                  This observational study compared the clinical and procedural parameters for LAAO with and without fusion imaging. Forty-one pairs of patients—matched by procedure month and with or without the use of the image fusion system—were enrolled. Using the image fusion Advanced Workstation 4.6 software (GE Healthcare), we identified the 3D cardiac anatomy and safe zones for septal punch. The LAA orifice anatomy outlines were then projected onto the real-time fluoroscopy image during the procedure to guide all the steps of LAAO.
               
                  Results
                  The use of image fusion significantly reduced the procedural time, compared to the time required for the control group (44.73 ± 20.03 min vs. 63.73 ± 26.10 min, respectively; P < 0.001). When compared to the standard procedure, the use of image fusion significantly reduced both the total radiation dose (448.80 ± 556.35 mGy vs. 798.42 ± 616.34 mGy; P = 0.004) and dose area product (DAP) (38.03 ± 47.15 Gy∙cm2 vs. 67.66 ± 52.23 Gy∙cm2, P = 0.004). Corresponding to the radiation dose, the contrast volume was also reduced (67.32 ± 18.65 vs. 90.98 ± 25.03 ml; P = 0.0004). During short-term follow-up at 6 months, there was only one femoral hematoma and incomplete LAA sealing (>3 mm) in either group.
               
                  Conclusions
                  Automated real-time integration of cardiac CT and fluoroscopy is feasible, safe, and applicable in LAAO. It may significantly reduce the radiation exposure, procedure duration, and volume of contrast media. Following these results, the potential of merging reconstructed 3D CT scans with real-time coronary angiography should be fully exploited in LAAO.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114538,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Parallel versus cascaded logistic regression trained single-hidden feedforward neural network for medical data,https://api.elsevier.com/content/abstract/scopus_id/85098990261,"Objective
                  An important step towards a better healthcare system is fast and accurate diagnosis. In the last decade, the application of intelligent systems in healthcare has led to impressive results. The goal of this paper is to extend the LogSLFN (single-hidden layer feedforward neural network trained using logistic regression) algorithm, which has been deployed successfully in the past for the case of a two-class decision problem, to the case of multiple classes. We have considered and statistically analyzed two approaches: a parallel LogSLFN, and a cascaded LogSLFN.
               
                  Materials and methods
                  According to the universal approximation theorem, a single-hidden layer feedforward neural network has the ability to approximate arbitrarily closely continuous functions of several real variables under certain reasonable assumptions. Essentially, a single hidden layer containing a finite fixed number of neurons is sufficient to provide an arbitrarily well approximation to a given training set of inputs and a desired target output represented by a continuous function. Parallel LogSLFN and cascaded LogSLFN are two novel approaches that can be applied to multiple-class decision problems. Both methods are extensions of the LogSLFN, which uses logistic regression to compute the weights between the input and hidden layer of a single-hidden layer feedforward network. No error correction is needed, the weights between the hidden and the output layer being computed using the Moore-Penrose pseudoinverse matrix. The proposed models have been tested on two medical datasets regarding cancer diagnosis and liver fibrosis staging. Experimental results and the subsequent statistical analysis have proved the robustness of the proposed models with other machine learning techniques reported in literature.
               
                  Main findings
                  The experimental results showed that the Parallel approach surpasses the Cascaded one. Still, both models are competitive to the other state-of-the-art techniques.
               
                  Conclusions
                  The LogSFLN algorithm can be successfully extended to multiple-class decision problems. By embedding knowledge extracted from the data into the architecture, we obtained a raise by 20% in accuracy when applied on the liver fibrosis dataset.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114533,Journal,Expert Systems with Applications,scopus,2021-05-15,sciencedirect,Dynamic learning framework for epileptic seizure prediction using sparsity based EEG Reconstruction with Optimized CNN classifier,https://api.elsevier.com/content/abstract/scopus_id/85098953605,"The World Health Organization (WHO) recently stated that epilepsy affects nearly 65 million people of the world population. Early forecast of the oncoming seizures is of paramount importance in saving the life of epileptic patients. This paper demonstrates a phase transition-based seizure prediction approach from multi-channel scalp electroencephalogram (EEG) recordings. The primary focus of this work is to discriminate the seizure and seizure-free EEG signals by learning the dynamics of preictal, interictal and ictal period. We propose an adaptive optimization approach using non-linear conjugate gradient technique in conjunction with Sparsity based EEG Reconstruction (SER) and three-dimensional Optimized Convolutional Neural Network (3D OCNN) classifier, based on Fletcher Reeves (FR) algorithm. Sparsity based artifact removal approach along with a 3D OCNN classifier, classifies the various states of seizures. FR algorithm is deployed with the deep neural network architecture to accelerate the convergence rate and to reduce the complexity of the proposed non-linear model. The Principle Component Analysis (PCA) algorithm replacing the Singular Value Decomposition (SVD) in the K-SVD algorithm, further reduces the time and complexity of the pre-processing stage. We further propose a Phase Transition based Kullback-Leibler divergence (PTB-KL) predictor for obtaining the Optimal Seizure Prediction Horizon (OSPH). The proposed model is evaluated using three diverse databases such as CHB-MIT, NINC and SRM respectively. Empirical results on the three EEG databases of 300 recordings outperforms the state-of-art approaches with an accuracy score of 0.98, sensitivity score of 0.99 and False Prediction Rate (FPR) of 0.07 FP/h. Statistical assessment of the proposed predictor gains an OSPH of about 1.1 h prior to the seizure onset. Experimental results prove that the phase transition-based seizure prediction approach is a promising one for accurate real-time prediction of epilepsy using scalp EEG data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tru.2021.100043,Journal,Thrombosis Update,scopus,2021-05-01,sciencedirect,Real-world data of thrombotic microangiopathy management: The key role of ADAMTS13 activity and complement testing,https://api.elsevier.com/content/abstract/scopus_id/85126108689,"ADAMTS13 (A Disintegrin and Metalloprotease with ThromboSpondin type 1 motifs) activity is a key tool in differential diagnosis of thrombotic microangiopathies (TMAs). Due to the lack of availability of ADAMTS13 testing, PLASMIC/PLASIC scores have been suggested to predict ADAMTS13 deficiency. The importance of differentiating TTP from other complement-mediated TMAs is highlighted by the need to urgently start plasma exchange and utility of treatments such as caplacizumab or eculuzimab. Therefore, we aimed to evaluate ADAMTS13 activity, PLASMIC/PLASIC scores, and complement testing in guiding management of a real-world TMA cohort. We enrolled consecutive TMA patients with samples referred to our Center (01/2018–2020). If ADAMTS13 ​> ​10%, soluble C5b-9 was measured. Among 80 TMA patients, ADAMTS13 activity was ≤10% in 50 patients, while 28 had a relapsing disease. PLASMIC/PLASIC were excellent predictors of ADAMTS13 deficiency, especially in patients without secondary causes. Soluble C5b-9 levels were elevated (median 525 ​ng/ml, range 313–913 ​ng/ml) in 7 patients without secondary causes and ADAMTS13 ​> ​10% (hemolytic uremic syndrome/HUS). Two were shiga-toxin associated; while 5 atypical HUS. Only 1/5 patients received eculizumab and achieved TMA resolution implemented by guidance based on soluble C5b-9 levels. In transplant-associated TMA, 8/16 patients not responding to first-line treatment received eculizumab due to elevated C5b-9 levels (median 353 ​ng/ml, range 281–1252 ​ng/ml) and achieved TMA resolution. In conclusion, our real-world data confirm that ADAMTS13, complement testing, and PLASMIC/PLASIC are valuable tools in diagnosis and management of TMAs, but also highlight the unmet need of using available markers and treatments in clinical practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2021.103787,Journal,Journal of Biomedical Informatics,scopus,2021-05-01,sciencedirect,Can technological advancements help to alleviate COVID-19 pandemic? a review,https://api.elsevier.com/content/abstract/scopus_id/85104674391,"The COVID-19 pandemic is continuing, and the innovative and efficient contributions of the emerging modern technologies to the pandemic responses are too early and cannot be completely quantified at this moment. Digital technologies are not a final solution but are the tools that facilitate a quick and effective pandemic response. In accordance, mobile applications, robots and drones, social media platforms (such as search engines, Twitter, and Facebook), television, and associated technologies deployed in tackling the COVID-19 (SARS-CoV-2) outbreak are discussed adequately, emphasizing the current-state-of-art. A collective discussion on reported literature, press releases, and organizational claims are reviewed. This review addresses and highlights how these effective modern technological solutions can aid in healthcare (involving contact tracing, real-time isolation monitoring/screening, disinfection, quarantine enforcement, syndromic surveillance, and mental health), communication (involving remote assistance, information sharing, and communication support), logistics, tourism, and hospitality. The study discusses the benefits of these digital technologies in curtailing the pandemic and ‘how’ the different sectors adapted to these in a shorter period. Social media and television’s role in ensuring global connectivity and serving as a common platform to share authentic information among the general public were summarized. The World Health Organization and Governments’ role globally in-line with the prevention of propagation of false news, spreading awareness, and diminishing the severity of the COVID-19 was discussed. Furthermore, this collective review is helpful to investigators, health departments, Government organizations, and policymakers alike to facilitate a quick and effective pandemic response.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gsd.2021.100580,Journal,Groundwater for Sustainable Development,scopus,2021-05-01,sciencedirect,Superposition learning-based model for prediction of E.coli in groundwater using physico-chemical water quality parameters,https://api.elsevier.com/content/abstract/scopus_id/85104633758,"The prediction of waterborne bacteria is crucial to prevent health risks. Therefore, there is a need to study the quality of groundwater by predicting the presence of E.coli. The experimental data for prediction is obtained from BITS-UVA (University of Virginia) groundwater contamination project, having 1301 experimental laboratory results that will be synthesized to test the physical, chemical, and microbiological parameters of water. In this study, a superposition-based learning algorithm (SLA) is proposed to observe the patterns of ANN-based sensitivity analysis to determine the importance of each water quality parameter resulting in the prediction of E.coli in groundwater. Mean Square Error (MSE) and the Coefficient of determination (R2) are calculated using MATLAB (R2019b, Mathworks, Natik, MA, USA) software for model performance evaluation. The highest correlation is observed between E.coli and the pH values, whereas the lowest correlation is observed with Dissolved Oxygen. In order to find out the uncertainty in the output of our mathematical model, a sensitivity analysis for the seven models is carried out. The results show that the model having Turbidity, pH, Total Dissolved Salts (TDS), and Electrical Conductivity as inputs displayed the best performance. The model architecture constitutes three hidden layers, twenty neurons in each layer, which is optimized using the Bayesian Regularization training algorithm (BR) with the overall highest R2 values of 0.90 and lowest MSE values of 0.0892. Patterns of the trained neural network are presented in superposition. After training, it can be concluded that the superposition models based on Grover's algorithm is more efficient in predicting all patterns in the counts of E.coli in groundwater. The algorithm is superimposed on multiple neural network architectures and returns a trained neural network. In addition to accurate results, there is also a need to automate the process of real-time bacterial monitoring for minimizing the error.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jsps.2021.03.002,Journal,Saudi Pharmaceutical Journal,scopus,2021-05-01,sciencedirect,"Commiphora myrrha (Nees) Engl. resin extracts induce phase-I cytochrome P450 2C8, 2C9, 2C19, and 3A4 isoenzyme expressions in human hepatocellular carcinoma (HepG2) cells",https://api.elsevier.com/content/abstract/scopus_id/85104367846,"Commiphora myrrha (Nees) Engl. (C. myrrha) resin is the most Middle Eastern herbal medicine used against numerous diseases. After being decocted or macerated, this resin is widely consumed among Saudi Arabian patients who are already under prescribed medication. Despite its popularity, no studies have been reported on potential modulation effects of these resin extracts on drug metabolism. Therefore, we studied C. myrrha resin extracts on the expression of cytochrome P450 (CYP) drug-metabolizing isoenzyme in human hepatocellular carcinoma cell line HepG2. The C. myrrha extracts were prepared by sonication and boiling, resembling the most popular traditional preparations of maceration and decoction, respectively. Both boiled and sonicated aqueous extracts were fingerprinted using high-performance liquid chromatography equipped with ultra-violet detector (HPLC-UVD). The viability of HepG2 cells treated with these aqueous extracts was determined using CellTiter-Glo® assay in order to select the efficient and non-toxic resin extract concentrations for phase-I metabolic CYP isoenzyme expression analysis. The isoenzyme gene and protein expression levels of CYP 2C8, 2C9, 2C19, and 3A4 were assessed using reverse transcription-quantitative polymerase chain reaction and Western blot technologies. The HPLC-UVD fingerprinting revealed different chromatograms for C. myrrha boiled and sonicated aqueous extracts. Both aqueous extracts were toxic to HepG2 cells when tested at concentrations exceeding 150 µg/ml of the dry crude extract. The CYP 2C8, 2C9, and 2C19 mRNA expression levels increased up to 4.0-fold in HepG2 cells treated with either boiled or sonicated C. myrrha aqueous extracts tested between 1 and 30 µg/ml, as compared with the untreated cells. However, CYP3A4 mRNA expression level exceeded the 2.0-fold cutoff when the cells were exposed to 30 µg/ml of C. myrrha extracts. The up-regulation of CYP mRNA expression levels induced by both boiled and sonicated C. myrrha aqueous extracts was confirmed at the CYP protein expression levels. In conclusion, both sonicated and boiled C. myrrha aqueous extracts modulate CYP 2C8, 2C9, 2C19, and 3A4 gene expression at clinically-relevant concentrations regardless of preparation methods. Further in vitro and in vivo experiments are required for CYP isoenzyme activity assessment and the establishment of herb-drug interaction profile for these traditional medicinal resin extracts.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cjca.2020.12.009,Journal,Canadian Journal of Cardiology,scopus,2021-05-01,sciencedirect,Digital Health Approaches for the Assessment and Optimisation of Hypertension Care Provision,https://api.elsevier.com/content/abstract/scopus_id/85104335482,"Although many aspects of our lives have been transformed by digital innovation, widespread adoption of digital health advancements within the health care sector in general, and for hypertension care specifically, has been limited. However, it is likely that, over the next decade, material increases in the uptake of digital health innovations for hypertension care delivery will be seen. In this narrative review, we summarise those innovations thought to have the greatest chance for impact in the next decade. These include provision of virtual care combined with home blood pressure (BP) telemonitoring, use of digital registries and protocolised care, leveraging continuous BP measurement to collect vast amounts of individual and population-based BP data, and adoption of digital therapeutics to provide low-cost scalable interventions for patients with or at risk for hypertension. Of these, home BP telemonitoring is likely the most ready for implementation, but it needs to be done in a way that enables efficient guideline-concordant care in a cost-effective manner. In addition, efforts must be focused on implementing digital health solutions in a manner that addresses the major challenges to digital adoption. This entails ensuring that innovations are accessible, usable, secure, validated, evidence based, cost-effective, and integrated into the electronic systems that are already used by patients or providers. Increasing the use of broader digital innovations such as artificial/augmented intelligence, data analytics, and interactive voice response is also critically important. The digital revolution holds substantial promise, but success will depend on the ability of collaborative stakeholders to adopt and implement innovative, usable solutions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.evopsy.2021.03.006,Journal,Evolution Psychiatrique,scopus,2021-05-01,sciencedirect,"From Digital Identity to Connected Personality, From Augmented Diagnostician to Virtual Caregiver: What Are the Challenges for the Psychology and the Psychiatry of the Future?",https://api.elsevier.com/content/abstract/scopus_id/85104125089,"Objectifs
                  Qui sommes-nous devenus, citoyens, patients, praticiens ? En quoi les moyens de communications et l’informatisation de notre société modifient-ils, intègrent-ils nos identités ? L’intelligence artificielle comprendrait-elle bientôt plus justement l’être humain dont elle s’émanciperait ?
               
                  Matériel et méthodes
                  Cheminons à partir de la lexicologie pour tenter de saisir, via le point de vue de la philosophie, l’identité contemporaine vers la notion d’« identité numérique » dont les incidents psychologiques normaux ou pathologiques entraînent ce que nous définissons « la personnalité numérique ». Puis, posant les bases d’une psychologie de l’identité contemporaine, nous envisageons comment « la psychologie » et « la psychiatrie » actuelles considèrent « la personnalité » du patient et, en retour, comment elles se définissent du point du vue du « praticien en ligne » ou du « chercheur connecté ».
               
                  Résultats
                  En échange de son utilisation « gratuite », l’action de l’internaute sur le Web 2.0 produit du contenu et alimente des bases de données, déclaratives ou non. En perte d’intimité au fur et à mesure que « ses » données ne lui appartiennent plus, l’identité du citoyen se décompose en fonctions des supports digitaux : site de rencontre amical, plateforme de liens amoureux, blog concernant un loisir ou un voyage, etc. Par le même mouvement, l’identité numérique se compose en autre-soi possédant une part d’intelligence artificielle pourvoyeuse de capacité d’existence propre. Plutôt que deux entités parallèlement différentiables, réelle ou augmentée, naît une identité hybride « réalistiquo-virtuelle ». Quelles conséquences normales ou pathologiques chez l’être humain ? Les tendances sociétales post-modernes issues du digital ou y trouvant expression peuvent entraîner, chez un individu donné, une exacerbation des traits de personnalité préalablement existants, voire des symptômes. Parallèlement, il arrive que les moyens de communication moderne deviennent une aide pour expérimenter le monde, majorer l’estime de soi, rêver favorablement ses phantasmes, se confier plus facilement à des « inconnu(e)s », etc. Mais dans tous les cas, chez le sujet souffrant, ou ne souffrant pas, préalablement à sa surexposition, de maladie neuropsychiatrique ou de trouble psychopathologique, il s’avère aujourd’hui scientifiquement documenté que la confrontation numérique accrue induit des atteintes neuropsychiques massives (affaiblissement de la mémoire de travail, des capacités d’attention et de concentration, des aptitudes à construire des opérations cognitives élaborées, etc.). Sur le plan psychopathologique, plutôt que la terminologie de « trouble de l’identité » ou une notion de « co-identités », le terme d’« identité trouble » nous paraît le mieux rendre compte de cette mutation du « moi » où la frontière entre réalité et virtualités s’amenuise : la dissociation prévaut. L’homme post-moderne et ses objets connectés ne font plus qu’un, mais cet « uniforme » apparaît constitué d’un patchwork de confettis identificatoires plus ou moins accolés, sans réelle harmonisation d’ensemble. La personnalité commune se marque d’hyperexpressivité et d’hyperémotivité, au détriment de la possibilité de contrôle des affects et du développement des capacités d’introspection. Contre le risque du vide, tend à se développer une contra-phobie par l’ordiphone, par l’objet lui-même, par la possibilité de contacter en permanence ses proches si nécessaire, et en retour rester toujours « disponible », ce qui alimente une forme d’égocentrisme addictogène. Résulte de ses évolutions, globalement dans la société, un affaiblissement des capacités langagières, et ainsi de réflexion, y compris pour l’espace clinique et scientifique.
               
                  Discussion
                  Pour les domaines de la psychologie et de la psychiatrie, s’associent actuellement deux évolutions : une velléité d’« objectivité-scientificité » et une numérisation de la relation patient–soignant. Du côté de la « science », la médecine objective « factuelle » s’intéresse de plus en plus à la pathologie aux dépens du sujet en souffrance, confondant signe et symptôme, glissant jusqu’à un niveau moléculaire, très en-deçà du patient, vers une psychiatrie ou une psychologie « post-clinique ». Qu’on veuille la promouvoir ou l’anéantir, du côté du clinicien ou du chercheur, la « subjectivité » est devenue un signifiant à la mode pour le domaine de la santé psychique. Ce retour actuel du « subjectif » prospère sur une sorte de peur de la subjectivité depuis la fin de la seconde guerre mondiale qui avait entraîné la nosographie américaine vers les « objectifs » des DSM (Manuel Diagnostique et Statistique des Troubles Psychiques publié par l’American Psychiatric Association depuis 1952). Mais plutôt qu’une connaissance validable, et/ou invariable concernant tel ou tel trouble psychique, le changement, la relativité des entités nosographiques d’une version à l’autre du manuel traduit, en miroir, la subjectivité d’une époque, ce que nous appelons « subjectivité sociétale ». Autant qu’elle témoigne de notre temps, la révolution bio-numérique s’imposera probablement dans une future édition de la nosographie : la validité diagnostique devrait se majorer par la définition précise de marqueurs biologiques et/ou neuroradiologiques, si ceux-ci participent à construire une théorie étiopathogénique des phénomènes psychiques observés. Cette orientation reste toutefois balbutiante : outre l’infime nombre de biomarqueurs identifiés, et surtout utilisables en pratique quotidienne, leurs liens de causalité ou de conséquentialité avec les symptômes ou le processus morbide restent le plus souvent incertains autant qu’ils sont fort divers et interreliés. Le chercheur en neurosciences vise à mesurer et analyser une multitude de données, intégrant en particulier les mimiques et les émotions authentifiables par caméra thermique, les mouvements des segments des corps et dynamiques des regards enregistrables par des capteurs, la standardisation des voix et des discours pour analyse par logiciel informatique de la prosodie, des signifiants employés, de la syntaxe… le tout s’intégrant dans un phénotypage digital de la souffrance. Pourra-t-on bientôt parler, en remplacement du psychologue ou du psychiatre, de « diagnosticien augmenté » ?
               
                  Conclusion
                  Apparaît-il actuellement hasardeux de faire confiance à un thérapeute entièrement virtuel… expérience déjà lancée il y a plus de 50 ans ! L’être humain est un « être de sens », or, selon le modèle de la clinique traumatique, le surgissement du tout-numérique peut entraîner un « effondrement du sens » générateur d’une tendance à la dissociation de la personnalité. Accordant le rétablissement des liens entre émotions, affects, comportements et cognitions, le langage parlé atténue puis fait disparaître la dissociation. Guidée par le praticien, cette parole thérapeutique est parfois qualifiée de « maïeutique », du nom de la science de l’accouchement : elle construit synchroniquement à son essence la pensée, et une prise de conscience de celle-ci, plutôt qu’elle n’en rendrait compte secondairement. Il s’agit d’une réinterprétation causale d’un sens compris ou plutôt « attribué » singulièrement par le sujet, après-coup, le passé revisité dans l’instant noue une synthèse, le hasard est transformé en destin. Le sujet qui parle réélabore son histoire vers une reconstruction sémantique, une densification de ses réseaux de signification. Reconquérant son être par la création d’un discours, de méandres véridiques comme fictionnels, la narration, voire la poétisation, offre l’illusion ponctuelle d’une meilleure cohérence, toujours relative, illusoire La parole thérapeutique et le discours sur celle-ci restent en devenir, inachevés, incertains autant que vivants, caractérisant une « post-psychothérapie », c’est-à-dire une psychothérapie et non pas une technique rééducative qui se trouverait figée dans des objectifs connus à l’avance. Les notions de faits et de réalité sont ici secondaires, non pas au sens de l’objectif, ni même du subjectif, mais du second degré, puis d’autres degrés successifs ou imbriqués portant l’effort intellectuel. Vers l’apaisement, si nous voulions amener la réflexion à son paroxysme, nous pourrions avancer qu’il suffirait de donner « n’importe quel sens », d’en choisir un quel qu’il soit, du côté du patient ou du praticien, sans qu’il ne soit nécessairement le même, témoignage d’une construction intersubjective formellement invalide.
               
                  Objectives
                  Who have we become, as citizens, patients, practitioners? How do the means of communication and the computerization of our society, its digitization, modify and integrate our identities? Can we assume that artificial intelligence will soon have a more accurate understanding of the human being from whom it will have emancipated itself?
               
                  Materials and methods
                  We move from lexicology to try to grasp, from the point of view of philosophy, a contemporary identity that is moving towards the notion of a “digital identity” whose normal or pathological psychological incidents lead to what we define as “the digital personality.” Then, laying the foundations for a contemporary psychology of identity, we consider how current “psychology” and “psychiatry” view the patient's “personality” and, in turn, how they define themselves from the point of view of “the patient,” or, inversely, from the point of view of the “online practitioner” or “connected researcher.”
               
                  Results
                  In exchange for its “free” use, the Internet user's action on Web 2.0 produces content and feeds databases, whether this is declared or not. Users’ privacy is lost, as “their” data no longer belongs to them; and citizens’ identity is broken down into digital media functions: a site for meeting friends, a dating platform, a blog about hobbies or travel, etc. At the same time, digital identity is made up of an other-self, including a part of artificial intelligence that provides capacity for its own existence. Rather than two parallel, differentiable entities, real or augmented, a “realistic-virtual” hybrid identity is born. What are the normal or pathological consequences for humans? Postmodern societal trends emerging from or finding expression in the digital can lead to an exacerbation of previously existing personality traits, or even symptoms, in a given individual. At the same time, it happens that the modern means of communication become an aid to experience the world, to increase self-esteem, to dream favorably about one's fantasies, to confide more easily in “strangers,” etc. But in all cases, in the subject suffering, or not suffering, prior to his overexposure, from a neuropsychiatric disease or a psychopathological disorder, it now turns out to be scientifically documented that the increased numerical confrontation induces massive neuropsychic damage (weakening working memory, attention and concentration skills, skills in constructing sophisticated cognitive operations, etc.). On the psychopathological level, rather than the terminology of “identity disorder” or a notion of “co-identities,” the term “identity elusive"" seems to us to best account for this mutation of the “me” where the border between reality and virtualities is shrinking: dissociation prevails. The postmodern human and its connected objects become one, but this “uniformity” appears to be made up of a patchwork of identifying confetti more or less joined together, without a real overall harmonization. The common personality is marked by hyperexpressiveness and hyperemotivity, to the detriment of the possibility of controlling affects and the development of introspective capacities. Against the risk of a vacuum, a contra-phobia tends to develop through the smartphone, by the object itself, by the possibility of constantly contacting relatives if necessary, and in return always remaining “available,” which fuels a form of addicting self-centeredness. The result of these developments, for society in general, is a weakening of language skills, and thus of reflection, including in the clinical and scientific space.
               
                  Discussion
                  For the areas of psychology and psychiatry, two developments are currently associated: a desire for “objectivity-scientificity” and a digitization of the patient–caregiver relationship. On the side of “science,” objective “factual” medicine is increasingly interested in pathology at the expense of the suffering subject, confusing sign and symptom, sliding down to a molecular level, far below the patient, towards psychiatry or postclinical psychology. Whether we want to promote it or destroy it, on the side of the clinician or the researcher, “subjectivity” has become a fashionable signifier in the field of mental health. This current return of the “subjective” thrives on a kind of fear of subjectivity present since the end of World War II, which had led American nosography towards the “objectives” of the DSM (Diagnostic and Statistical Manual of Mental Disorders, published by the American Psychiatric Association since 1952). But rather than a verifiable and/or invariable knowledge concerning a particular psychic disorder, the changes and the relativity of nosographic entities from one version of the manual to another provides us with a mirror image of the subjectivity of an era, which we propose to call “societal subjectivity.” As much as it is a product of our time, the bio-digital revolution will probably impose itself in a future edition of nosography: the diagnostic validity should be increased by the precise definition of biological and/or neuroradiological markers, if these participate in building an etiopathogenic theory of observed psychic phenomena. This orientation remains in its infancy, however: in addition to the tiny number of identified biomarkers, and above all, those that are usable in daily practice, their causal or consequential links with symptoms or with the morbid process remain most often uncertain, inasmuch as they are diverse and interrelated. The neuroscience researcher aims to measure and analyze a multitude of data, integrating, in particular, mimicry and emotions authenticated by thermal camera; movements of body segments and gaze dynamics recorded by sensors; the standardization of voices and speeches for computer software analysis of prosody, used signifiers, syntax… all of which is integrated into a digital phenotyping of suffering. Will we soon be able to speak, replacing the psychologist or the psychiatrist, of an “augmented diagnostician?”.
               
                  Conclusion
                  Does it currently appear risky to trust an entirely virtual therapist… an experiment already launched more than 50 years ago! The human being is a “being of meaning,” yet, according to the model of trauma, the emergence of the all-digital can lead to a “collapse of meaning,” generating a tendency to personality dissociation. Granting the reestablishment of the links between emotions, affects, behaviors, and cognitions, spoken language attenuates dissociation, then makes it disappear. Guided by the practitioner, this therapeutic word is sometimes qualified as “maieutics,” from the name of the science of childbirth: it builds thought synchronously to its essence, and an awareness of it, rather than nondisclosure, would account for it secondarily. It is a causal reinterpretation of a meaning understood or rather “attributed” singularly by the subject, after the fact: the past revisited in the present moment creates a synthesis, and chance is transformed into fate. The speaking subject re-elaborates her/his story towards a semantic reconstruction, a densification of her/his networks of signification. Reclaiming one's being by the creation of a discourse, of veridical as well as fictional meanders, narration, even poetization, offers the punctual illusion of a better coherence, always relative, illusory… Therapeutic speech and discourse about such speech–these are still being made, unfinished, uncertain, and alive. These are the characteristics of what we could a “post-psychotherapy,” that is, a psychotherapy and not a re-educational technique whose objectives would be fixed and known in advance. The notions of facts and reality are secondary here, not in the sense of the objective, nor even of the subjective, but of the second degree, then of other successive or overlapping degrees that require intellectual effort. Moving towards appeasement, if we wanted to bring the reflection to its paroxysm, we could advance that it would be enough to give “any meaning,” whatever it may be. This would apply both to the patient and to the practitioner, without each party's meaning necessarily being the same: a testimony to a formally invalid intersubjective construction.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jcv.2021.104817,Journal,Journal of Clinical Virology,scopus,2021-05-01,sciencedirect,Performance of the RT-LAMP-based eazyplex® SARS-CoV-2 as a novel rapid diagnostic test,https://api.elsevier.com/content/abstract/scopus_id/85103724608,"Background
                  Diagnostic assays for severe acute respiratory syndrome Coronavirus-2 (SARS-CoV-2) that are easy to perform and produce fast results are essential for timely decision making regarding the isolation of contagious individuals.
               
                  Objective
                  We evaluated the CE-approved eazyplex® SARS-CoV-2, a ready-to-use real time RT-LAMP assay for identification of the SARS-CoV-2 N and ORF8 genes from swabs in less than 30 min without RNA extraction.
               
                  Study design
                  Oropharyngeal and nasal swabs from 100 positive and 50 negative patients were inoculated into 0.9 % saline and tested by NeuMoDx™ RT-PCR. An aliquot was diluted fivefold in Copan sputum liquefying (SL) solution and directly analyzed by eazyplex® SARS-CoV-2. In addition, 130 patient swabs were prospectively tested with both methods in parallel. Analytical sensitivity of the assay was determined using virus stock dilutions.
               
                  Results
                  Positive percent agreement (PPA) between the eazyplex® SARS-CoV-2 and RT-PCR was 74 % for samples with Ct values < 35. When using a Ct cut-off ≤ 28 the PPA increased to 97.4 %. In the prospective part of the study overall PPA of the eazyplex® kit was 66.7 % but increased to 100 % when only Ct values ≤ 28 were considered. There were no false positive results. The median time to positivity was 12.5 min for the N gene and 16.75 min for ORF8. Analytical sensitivity was 3.75 TCID50/mL. 105 virus copies/mL were reproducibly detected.
               
                  Conclusion
                  The eazyplex® SARS-CoV-2 is a rapid assay that accurately identifies samples with high viral loads. It may be useful for near-patient testing outside of a molecular diagnostic laboratory.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mimet.2021.106186,Journal,Journal of Microbiological Methods,scopus,2021-05-01,sciencedirect,"Large-scale comparison of E. coli levels determined by culture and a qPCR method (EPA Draft Method C) in Michigan towards the implementation of rapid, multi-site beach testing",https://api.elsevier.com/content/abstract/scopus_id/85103706448,"Fecal pollution remains a challenge for water quality managers at Great Lakes and inland recreational beaches. The fecal indicator of choice at these beaches is typically Escherichia coli (E. coli), determined by culture-based methods that require over 18 h to obtain results. Researchers at the United States Environmental Protection Agency (EPA) have developed a rapid E. coli qPCR methodology (EPA Draft Method C) that can provide same-day results for improving public health protection with demonstrated sensitivity, specificity, and data acceptance criteria. However, limited information is currently available to compare the occurrence of E. coli determined by cultivation and by EPA Draft Method C (Method C). This study provides a large-scale data collection effort to compare the occurrence of E. coli determined by these alternative methods at more than 100 Michigan recreational beach and other sites using the complete set of quantitative data pairings and selected subsets of the data and sites meeting various eligibility requirements. Simple linear regression analyses of composite (pooled) data indicated a correlation between results of the E. coli monitoring approaches for each of the multi-site datasets as evidenced by Pearson R-squared values ranging from 0.452 to 0.641. Theoretical Method C threshold values, expressed as mean log10 target gene copies per reaction, that corresponded to an established E. coli culture method water quality standard of 300 MPN or CFU /100 mL varied only from 1.817 to 1.908 for the different datasets using this model. Different modeling and derivation approaches that incorporated within and between-site variability in the estimates also gave Method C threshold values in this range but only when relatively well-correlated datasets were used to minimize the error. A hypothetical exercise to evaluate the frequency of water impairments based on theoretical qPCR thresholds corresponding to the E. coli water quality standard for culture methods suggested that the methods may provide the same beach notification outcomes over 90% of the time with Method C results differing from culture method results that indicated acceptable and unacceptable water quality at overall rates of 1.9% and 6.6%, respectively. Results from this study provide useful information about the relationships between E. coli determined by culture and qPCR methods across many diverse freshwater sites and should facilitate efforts to implement qPCR-based E. coli detection for rapid recreational water quality monitoring on a large scale in the State of Michigan.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2021.106035,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-05-01,sciencedirect,Convolutional neural network based automatic screening tool for cardiovascular diseases using different intervals of ECG signals,https://api.elsevier.com/content/abstract/scopus_id/85102972408,"Background and Objective: Automatic screening tools can be applied to detect cardiovascular diseases (CVDs), which are the leading cause of death worldwide. As an effective and non-invasive method, electrocardiogram (ECG) based approaches are widely used to identify CVDs. Hence, this paper proposes a deep convolutional neural network (CNN) to classify five CVDs using standard 12-lead ECG signals.
                  
                     Methods: The Physiobank (PTB) ECG database is used in this study. Firstly, ECG signals are segmented into different intervals (one-second, two-seconds and three-seconds), without any wave detection, and three datasets are obtained. Secondly, as an alternative to any complex preprocessing, durations of raw ECG signals have been considered as input with simple min-max normalization. Lastly, a ten-fold cross-validation method is employed for one-second ECG signals and also tested on other two datasets (two-seconds and three-seconds).
                  
                     Results: Comparing to the competing approaches, the proposed CNN acquires the highest performance, having an accuracy, sensitivity, and specificity of 99.59%, 99.04%, and 99.87%, respectively, with one-second ECG signals. The overall accuracy, sensitivity, and specificity obtained are 99.80%, 99.48%, and 99.93%, respectively, using two-seconds of signals with pre-trained proposed models. The accuracy, sensitivity, and specificity of segmented ECG tested by three-seconds signals are 99.84%, 99.52%, and 99.95%, respectively.
                  
                     Conclusion: The results of this study indicate that the proposed system accomplishes high performance and keeps the characterizations in brief with flexibility at the same time, which means that it has the potential for implementation in a practical, real-time medical environment.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2021.102538,Journal,Biomedical Signal Processing and Control,scopus,2021-05-01,sciencedirect,A novel multiscale convolutional neural network based age-related macular degeneration detection using OCT images,https://api.elsevier.com/content/abstract/scopus_id/85102353470,"Age-related macular degeneration (AMD) is an ocular disorder that affects the elderly. The prevalence of AMD is growing due to the aging population in society; hence early diagnosis is necessary to prevent vision loss in the elderly. Arranging a detailed eye screening system for detecting AMD is a very challenging process. This paper proposes a novel multiscale convolutional neural network (CNN) architecture for accurate diagnosis of AMD. The architecture proposed is a multiscale CNN with seven convolutional layers for classifying AMD or normal images. The multiscale convolution layer enables a large number of local structures to be generated with various filter sizes. In this proposed network, the sigmoid function is used as the classifier. The proposed CNN network is trained on the Mendeley dataset and tested on four datasets, namely Mendeley, OCTID, Duke, SD-OCT Noor dataset and achieved an accuracy of 99.73%, 98.08%, 96.66%, and 97.95% respectively. Comparison with alternative methods yielded results that exhibit the efficiency of the proposed algorithm in AMD detection. Even if the proposed model is trained only on the Mendeley dataset, it achieved good detection accuracy when tested with other datasets. This indicates the proposed model's ability to classify AMD/Normal images from other datasets. Comparison with other approaches produced results that exhibit the efficiency of the proposed algorithm in detecting AMD. The proposed architecture can be applied in rapid screening of the eye for the early detection of AMD. Due to less complexity and fewer learnable parameters, the proposed CNN can be implemented in real-time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2021.101990,Journal,Medical Image Analysis,scopus,2021-05-01,sciencedirect,VR-Caps: A Virtual Environment for Capsule Endoscopy,https://api.elsevier.com/content/abstract/scopus_id/85101407908,"Current capsule endoscopes and next-generation robotic capsules for diagnosis and treatment of gastrointestinal diseases are complex cyber-physical platforms that must orchestrate complex software and hardware functions. The desired tasks for these systems include visual localization, depth estimation, 3D mapping, disease detection and segmentation, automated navigation, active control, path realization and optional therapeutic modules such as targeted drug delivery and biopsy sampling. Data-driven algorithms promise to enable many advanced functionalities for capsule endoscopes, but real-world data is challenging to obtain. Physically-realistic simulations providing synthetic data have emerged as a solution to the development of data-driven algorithms. In this work, we present a comprehensive simulation platform for capsule endoscopy operations and introduce VR-Caps, a virtual active capsule environment that simulates a range of normal and abnormal tissue conditions (e.g., inflated, dry, wet etc.) and varied organ types, capsule endoscope designs (e.g., mono, stereo, dual and 360
                        
                           
                           ∘
                        
                      camera), and the type, number, strength, and placement of internal and external magnetic sources that enable active locomotion. VR-Caps makes it possible to both independently or jointly develop, optimize, and test medical imaging and analysis software for the current and next-generation endoscopic capsule systems. To validate this approach, we train state-of-the-art deep neural networks to accomplish various medical image analysis tasks using simulated data from VR-Caps and evaluate the performance of these models on real medical data. Results demonstrate the usefulness and effectiveness of the proposed virtual platform in developing algorithms that quantify fractional coverage, camera trajectory, 3D map reconstruction, and disease classification. All of the code, pre-trained weights and created 3D organ models of the virtual environment with detailed instructions how to setup and use the environment are made publicly available at https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy and a video demonstration can be seen in the supplementary videos (Video-I).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2021.107036,Journal,Computers and Electrical Engineering,scopus,2021-05-01,sciencedirect,Screening of Glaucoma disease from retinal vessel images using semantic segmentation,https://api.elsevier.com/content/abstract/scopus_id/85101383196,"A timely diagnosis of Glaucoma has crucial importance in preventing blindness. As this disease exists in the immediate vicinity of the optical disk (OD), its precise localization and segmentation are critical in its accurate diagnosis. OD consists of two parts, namely: neuroretinal and optic cup (OC). In the proposed work, the problem of OD and OC segmentation is modeled as a semantic pixel-wise labeling problem, thus bridging the gap between medical image segmentation and semantic segmentation. The proposed method eliminates the need for pre- and post-processing steps. The proposed method is evaluated for the segmentation of OD and OC on Drishti and Rim-one datasets. The offered low computational and resource requirements along with the observed state-of-the-art accuracy of the proposed method support its implementation in the real-time automatic screening of the Glaucoma disease.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2021.105190,Journal,Safety Science,scopus,2021-05-01,sciencedirect,Beirut explosion 2020: A case study for a large-scale urban blast simulation,https://api.elsevier.com/content/abstract/scopus_id/85100545374,"In the face of continued global urbanization, cities are challenged to satisfy increasing standards in terms of quality of life, environmental conditions, safety, security, health, economic growth and mobility. The concept of “smart cities” aims at utilising advanced technologies, artificial intelligence and high computational capacity to increase their resilience and improve the services provided to the citizens. Computation-based numerical simulations have been essentially used to estimate the effects of explosion events in urban environments in terms of both structural damage and human casualties. These provide urban planners and decision makers with valuable information for vulnerability assessment and aid developing prevention or mitigation solutions. In this article, we present a framework to generate a 3D large-scale urbanistic finite element model, where the desired geospatial data are extracted from the open-source world map OpenStreetMap. The model is used to simulate blast wave propagation effects in a wide urban area taking into account the reflections at building surfaces via a sophisticated Fluid-Structure interaction technique integrated in the EUROPLEXUS explicit finite element method software. The explosion in the Port of Beirut in Lebanon, which took place on the 4th of August 2020, was remarkable for the large amount of explosive material causing considerable damage to surrounding structures and a high number of deaths and injured. Such characteristics make the event suitable for assessing the performance of the proposed computational approach in a widely exposed (by the blast wave) urban zone.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jisa.2021.102748,Journal,Journal of Information Security and Applications,scopus,2021-05-01,sciencedirect,Agent architecture of an intelligent medical system based on federated learning and blockchain technology,https://api.elsevier.com/content/abstract/scopus_id/85100236256,"Multi-agent systems enable the division of complicated tasks into individual objects that can cooperate. Such architecture can be useful in building solutions in the Internet of Medical Things (IoMT). In this paper, we propose an architecture of such a system that ensures the security of private data, as well as allows the addition and/or modification of the used classification methods. The main advantages of the proposed system are based on the implementation of blockchain technology elements and threaded federated learning. The individual elements are located on the agents who exchange information. Additionally, we propose building an agent with a consortium mechanism for classification results from many machine learning solutions. This proposal offers a new model of agents that can be implemented as a system for processing medical data in real-time. Our proposition was described and tested to present advantages over other, existing state-of-the-art methods. We show, that this proposition can improve the Internet of Medical Thing solutions by presenting a new idea of a multi-agent system that can separate different tasks like security, or classification and as a result minimize operation time and increase accuracy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.preteyeres.2020.100900,Journal,Progress in Retinal and Eye Research,scopus,2021-05-01,sciencedirect,"Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective",https://api.elsevier.com/content/abstract/scopus_id/85093916279,"The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a “new normal”, the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jclepro.2021.125814,Journal,Journal of Cleaner Production,scopus,2021-04-20,sciencedirect,Online accurate state of health estimation for battery systems on real-world electric vehicles with variable driving conditions considered,https://api.elsevier.com/content/abstract/scopus_id/85101808443,"The environmental sustainability stimulates the development of electric vehicles with great energy-saving and emission reduction effects. State of health of the battery system in an electric vehicle is crucial to the safety of vehicle operation, charging station, and the environment. The existing techniques implemented in well-controlled experimental environments fail to learn unpredictable drivers’ driving behaviors and complex road/weather conditions during actual vehicular operation. This paper investigates a novel deep-learning-enabled method to perform accurate state of health estimation for battery systems on real-world electric vehicles. Eight potential evaluation schemes depending on the stable charging stages are recapped and discussed. By fitting the correlation between battery degeneration factors and various vehicle operation parameters such as ambient temperature and mileage, an approximate battery degeneration model oriented for the real application scenarios is obtained. The variable-length-input long short-term memory network is used to learn the variable battery degeneration factors acquired from different driving stages of a yearlong dataset. The test results show that the proposed method has a better performance than other estimation methods. More significantly, based on the acquisition advantages of big-data platforms, it can be used to full-state and full-climate vehicle applications unrestricted by complex actual environments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114237,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,Monitoring linear profiles using Artificial Neural Networks with run rules,https://api.elsevier.com/content/abstract/scopus_id/85098181038,"In some applications, a relation between a response variable and one or more explanatory variables (referred as a “profile”) characterizes the quality of a process. Profile monitoring is commonly performed through statistical methods, while machine learning schemes have not received much attention in this regard. In this paper, a control chart based on Artificial Neural Networks (ANN) is proposed to monitor linear profiles in phase II. In the proposed control chart, some novel run rules as the major contribution of this paper are also used to enhance the efficiency of the control chart and for faster detection of shifts. Simulation results revealed a good performance of the proposed control chart based on average run length (ARL) criterion. Further, a systematic ANN-based diagnostic procedure was proposed to identify which parameter has changed in the process. Finally, the implementation of the proposed scheme was illustrated through a real calibration example from the field of chemical engineering.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.114218,Journal,Expert Systems with Applications,scopus,2021-04-15,sciencedirect,Breast calcification detection based on multichannel radiofrequency signals via a unified deep learning framework,https://api.elsevier.com/content/abstract/scopus_id/85096864735,"Breast calcifications in radiographic images suggest a high likelihood of breast lesion malignancy. However, it is difficult to detect calcifications in traditional B-mode ultrasound images due to resolution limits and speckle noise. In this paper, we propose a unified deep learning framework for automatic calcification detection based on multichannel ultrasound radio frequency (RF) signals. First, beamforming is used during preprocessing to merge and blend multichannel signals into one-channel RF signals. Each scan line is converted into a spectrogram by the short-time Fourier transform (STFT) to utilize the frequency domain characteristics. Then, an improved fully convolutional neural network called the RF signal Spectrogram-Calcification-Detection-Net (SCD-Net) is proposed to detect calcifications from spectrograms. This method employs a deep learning architecture based on YOLOv3 and combines features via convolutional long short-term memory (ConvLSTM). Next, a Kalman filter for tracking calcifications between consecutive spectrograms based on SCD-Net detection results is applied since the spatial coherence of calcifications in neighboring frames can be taken into account. Finally, the detected calcification is mapped from the time domain of spectrograms to B-mode images for clinical diagnosis. Experiments were conducted on a database of 337 experienced doctor-marked breast tumors with calcifications. Compared to the state-of-the-art methods for detecting calcifications, the proposed method achieved an average precision (AP) of 88.25%, an accuracy of 84% and an F1 score of 91%. The experimental results demonstrate that the unified framework has great performance for tumor calcification detection. The system can be effectively applied in a portable ultrasound instrument to accurately help radiologists and provide guidance for breast tumor diagnosis. This implies that the proposed approach can be implemented in real practice for analyzing breast RF signals, which have many useful medical applications in clinical breast tumor diagnosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.smhl.2021.100191,Journal,Smart Health,scopus,2021-04-01,sciencedirect,Inferring food types through sensing and characterizing mastication dynamics,https://api.elsevier.com/content/abstract/scopus_id/85107633513,"Unhealthy dietary structure leads to the prevalence of some chronic diseases, such as obesity, diabetes, and heart disease. Automatic food type recognition helps nutritionists and medical professionals understand patients’ nutritional contents, provide accurate and personalized treatments, and evaluate therapeutic effects. Existing wearable sensor-based methods take advantage of microphone, electromyography (EMG), and piezoelectric sensors embedded in the wearable devices. However, these sensors are either easily impacted by ambient acoustic noise or intrusive and uncomfortable to wear. We observe that each type of food has its own intrinsic properties, such as hardness, elasticity, fracturability, adhesiveness, and size. Different food properties result in different mastication dynamics. In this paper, we present the first effort in using wearable motion sensors to sense mastication dynamics and infer food types accordingly. We specifically define six mastication dynamics parameters to represent these food properties. They are chewing speed, the number of chews, chewing time, chewing force, chewing cycle duration and skull vibration. We embed motion sensors in a headband and deploy the sensors on the temporalis muscles to sense mastication dynamics accurately and less intrusively. In addition, we extract 65 hand-crafted features from each chewing sequence to explicitly characterize the mastication dynamics using motion sensor data. A real-world evaluation dataset of 11 food categories (20 types of food in total) is collected from 15 human subjects. The average recognition accuracy of these 15 human subjects is 82.3%. The accuracy of a single human subject is up to 93.3%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmsy.2021.02.012,Journal,Journal of Manufacturing Systems,scopus,2021-04-01,sciencedirect,Robust diagnosis with high protection to gas turbine failures identification based on a fuzzy neuro inference monitoring approach,https://api.elsevier.com/content/abstract/scopus_id/85101807612,"Modern industry requires the development of new monitoring and diagnostic procedures, which enable the detection, localization, and isolation of faults. For sustainable solutions in terms of operational safety and availability, while bringing out zero accidents, zero downtime, and zero faults, for a trend acting on environmental issues. Towards this development, this work proposes solutions for the monitoring of gas turbines and their real-time implementation, in order to approximate and predict the degradation of the components of this system, by an approach of faults detection and isolation, based on an adaptive neural-fuzzy inference system. This will develop a reliable approach to maintain and monitor gas turbines, in case of failure or accident to prevent in real-time and makes it possible to achieve high power with efficiency and small footprint with High performance by operating this rotating machine. However, the application of the Adaptive Neuro-Fuzzy Inference System Observer-Based Approach, makes it possible to increase the life of the examined turbine and keep better reliability for their monitoring system and satisfy the techno-economic and environmental performance impacts. For the purpose of controlling failures and the occurrence of turbine system malfunctions, and avoiding their consequences on the safety and productivity of the installation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bja.2020.12.035,Journal,British Journal of Anaesthesia,scopus,2021-04-01,sciencedirect,Deep learning models for the prediction of intraoperative hypotension,https://api.elsevier.com/content/abstract/scopus_id/85100623913,"Background
                  Intraoperative hypotension is associated with a risk of postoperative organ dysfunction. In this study, we aimed to present deep learning algorithms for real-time predictions 5, 10, and 15 min before a hypotensive event.
               
                  Methods
                  In this retrospective observational study, deep learning algorithms were developed and validated using biosignal waveforms acquired from patient monitoring of noncardiac surgery. The classification model was a binary classifier of a hypotensive event (MAP <65 mm Hg) or a non-hypotensive event by analysing biosignal waveforms. The regression model was developed to directly estimate the MAP. The primary outcome was area under the receiver operating characteristic (AUROC) curve and the mean absolute error (MAE).
               
                  Results
                  In total, 3301 patients were included. For invasive models, the multichannel model with an arterial pressure waveform, electrocardiography, photoplethysmography, and capnography showed greater AUROC than the arterial-pressure-only models (AUROC15-min, 0.897 [95% confidence interval {CI}: 0.894–0.900] vs 0.891 [95% CI: 0.888–0.894]) and lesser MAE (MAE15-min, 7.76 mm Hg [95% CI: 7.64–7.87 mm Hg] vs 8.12 mm Hg [95% CI: 8.02–8.21 mm Hg]). For the noninvasive models, the multichannel model showed greater AUROCs than that of the photoplethysmography-only models (AUROC15-min, 0.762 [95% CI: 0.756–0.767] vs 0.694 [95% CI: 0.686–0.702]) and lesser MAEs (MAE15-min, 11.68 mm Hg [95% CI: 11.57–11.80 mm Hg] vs 12.67 [95% CI: 12.56–12.79 mm Hg]).
               
                  Conclusions
                  Deep learning models can predict hypotensive events based on biosignals acquired using invasive and noninvasive patient monitoring. In addition, the model shows better performance when using combined rather than single signals.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jnca.2021.102995,Journal,Journal of Network and Computer Applications,scopus,2021-04-01,sciencedirect,Dew computing-inspired health-meteorological factor analysis for early prediction of bronchial asthma,https://api.elsevier.com/content/abstract/scopus_id/85100605135,"Bronchial asthma is one of the most common chronic diseases of childhood and considered as a major health problem globally. The irregularity in meteorological factors has become a primary cause of health severity for the individuals suffering from asthma. In the presented research, a dew-cloud assisted cyber-physical system (CPS) is proposed to analyze the correlation between the meteorological and health parameters of the individuals. The work is primarily focused on determining the health adversity caused by the irregular scale of meteorological factors in real-time. IoT-assisted smart sensors are utilized to capture ubiquitous information from indoor environment that make a vital impact on the health of the individual directly or indirectly. The data is analyzed over the cyber-space to quantify the probable irregular health events by utilizing the data classification efficiency of Weighted-Naïve Bayes modeling technique. Moreover, the relationship between meteorological and health parameters is estimated by utilizing the Adaptive Neuro-Fuzzy Inference System (ANFIS) and calculate a unifying factor over the temporal scale. To validate the monitoring performance, the proposed model is implemented in the four schools of Jalandhar, India. The experimental evaluation of the proposed model acknowledges the performance efficiency through several statistical approaches. Furthermore, the comparative analysis is evaluated with state-of-the-art decision-making algorithms that demonstrate the effectiveness of the proposed solution for the targeted application.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aca.2021.338254,Journal,Analytica Chimica Acta,scopus,2021-04-01,sciencedirect,Detection of Plasmodium falciparum malaria in 1 h using a simplified enzyme-linked immunosorbent assay,https://api.elsevier.com/content/abstract/scopus_id/85100400846,"Malaria is a parasitic disease caused by protists of the genus Plasmodium, which are transmitted to humans through the bite of infected female Anopheles mosquitoes. Analytical methodologies and efficient drugs exist for the early detection and treatment of malaria, and yet this disease continues infecting millions of people and claiming several hundred thousand lives each year. One of the reasons behind this failure to control the disease is that the standard method for malaria diagnosis, microscopy, is time-consuming and requires trained personnel. Alternatively, rapid diagnostic tests, which have become common for point-of-care testing thanks to their simplicity of use, tend to be insufficiently sensitive and reliable, and PCR, which is sensitive, is too complex and expensive for massive population screening.
                  In this work, we report a sensitive simplified ELISA for the quantitation of Plasmodium falciparum lactate dehydrogenase (Pf-LDH), which is capable of detecting malaria in 45–60 min. Assay development was founded in the selection of high-performance antibodies, implementation of a poly-horseradish peroxidase (polyHRP) signal amplifier, and optimization of whole-blood sample pre-treatment. The simplified ELISA achieved limits of detection (LOD) and quantification (LOQ) of 0.11 ng mL−1 and 0.37 ng mL−1, respectively, in lysed whole blood, and an LOD comparable to that of PCR in Plasmodium in vitro cultures (0.67 and 1.33 parasites μL−1 for ELISA and PCR, respectively). Accordingly, the developed immunoassay represents a simple and effective diagnostic tool for P. falciparum malaria, with a time-to-result of <60 min and sensitivity similar to the reference PCR, but easier to implement in low-resource settings.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.autcon.2021.103603,Journal,Automation in Construction,scopus,2021-04-01,sciencedirect,A field parameters-based method for real-time wear estimation of disc cutter on TBM cutterhead,https://api.elsevier.com/content/abstract/scopus_id/85100241917,"In hard rock TBM tunneling, the loss caused by disc cutter wear accounts for a large proportion of time and cost for the entire project. However, existing disc cutter wear prediction models mainly focus on predicting cutter consumption before construction and cannot predict the wear of each disc cutter. Moreover, the accurate rock parameters required in these models are challenging to obtain. Hence, these models are not capable of determining which cutter on cutterhead should be replaced during construction. To solve the problems mentioned above, this paper presents a novel field parameters-based method for estimating the wear of each disc cutter in real-time. The proposed method is implemented through the following steps. To begin with, a new health index is constructed and defined as the ratio of the rolling distance of a cutter in a small excavated section to its maximum rolling distance. Then, specific field parameters related to the new health index are analyzed and selected. Thereafter, the mapping model between the new health index and the specific field parameters is established based on a one-dimensional convolutional neural network. Finally, on the basis of the established model, the estimated health indices corresponding to all excavated sections of a disc cutter are accumulated to obtain its health status. The field data obtained from Mumbai metro tunnel was utilized to verify the effectiveness of the proposed method, which demonstrates that the proposed method can estimate the wear of each disc cutter in real-time with average accuracy as high as 87.8% on the test set. Therefore, the proposed method is capable of significantly reducing the time and cost of cutter inspection, replacement, and repair for TBM, thereby improve tunneling efficiency and reduce construction cost.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.petrol.2020.108329,Journal,Journal of Petroleum Science and Engineering,scopus,2021-04-01,sciencedirect,Using the motor power and XGBoost to diagnose working states of a sucker rod pump,https://api.elsevier.com/content/abstract/scopus_id/85099215424,"In oilfiled production, the dynamometer cards are usually used to diagnose the downhole conditions of the pumping well. They record changes in the rod load versus rod displacement. However, the measurement has deficiencies such as poor real-time performance and high maintenance costs. Aiming at the problems, a novel method based on motor power for fault detection of the sucker rod pump is proposed in this paper. In this method, the motor power curves of seven working states are obtained by transforming the dynamometer cards into motor power curves. The characteristics of the motor power curves under different working states are analyzed combining with the theoretical motor power curve. Furthermore, the novel sixteen features are extracted in time and frequency domains with the analysis of the working mechanism of the sucker rod pump. Subsequently, the Extreme Gradient Boosting (XGBoost) algorithm, machine learning algorithm, is employed to classify and identify working states of the sucker rod pumps. At last, this paper uses the dataset collected from the oil field to corroborate the proposed method. The experimental results showing the proposed method gives 98% correct diagnosis, proves a higher accuracy to SVM and KNN. Moreover, the final engineering practice also proves the effectiveness of the method proposed in this paper.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2020.101942,Journal,Medical Image Analysis,scopus,2021-04-01,sciencedirect,Automated interpretation of congenital heart disease from multi-view echocardiograms,https://api.elsevier.com/content/abstract/scopus_id/85098981556,"Congenital heart disease (CHD) is the most common birth defect and the leading cause of neonate death in China. Clinical diagnosis can be based on the selected 2D key-frames from five views. Limited by the availability of multi-view data, most methods have to rely on the insufficient single view analysis. This study proposes to automatically analyze the multi-view echocardiograms with a practical end-to-end framework. We collect the five-view echocardiograms video records of 1308 subjects (including normal controls, ventricular septal defect (VSD) patients and atrial septal defect (ASD) patients) with both disease labels and standard-view key-frame labels. Depthwise separable convolution-based multi-channel networks are adopted to largely reduce the network parameters. We also approach the imbalanced class problem by augmenting the positive training samples. Our 2D key-frame model can diagnose CHD or negative samples with an accuracy of 95.4%, and in negative, VSD or ASD classification with an accuracy of 92.3%. To further alleviate the work of key-frame selection in real-world implementation, we propose an adaptive soft attention scheme to directly explore the raw video data. Four kinds of neural aggregation methods are systematically investigated to fuse the information of an arbitrary number of frames in a video. Moreover, with a view detection module, the system can work without the view records. Our video-based model can diagnose with an accuracy of 93.9% (binary classification), and 92.1% (3-class classification) in a collected 2D video testing set, which does not need key-frame selection and view annotation in testing. The detailed ablation study and the interpretability analysis are provided.
                  The presented model has high diagnostic rates for VSD and ASD that can be potentially applied to the clinical practice in the future. The short-term automated machine learning process can partially replace and promote the long-term professional training of primary doctors, improving the primary diagnosis rate of CHD in China, and laying the foundation for early diagnosis and timely treatment of children with CHD.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cpc.2020.107779,Journal,Computer Physics Communications,scopus,2021-04-01,sciencedirect,Mammography and breast tomosynthesis simulator for virtual clinical trials,https://api.elsevier.com/content/abstract/scopus_id/85098176202,"Computer modeling and simulations are increasingly being used to predict the clinical performance of x-ray imaging devices in silico, and to generate synthetic patient images for training and testing of machine learning algorithms. We present a detailed description of the computational models implemented in the open source GPU-accelerated Monte Carlo x-ray imaging simulation code MC-GPU. This code, originally developed to simulate radiography and computed tomography, has been extended to replicate a commercial full-field digital mammography and digital breast tomosynthesis (DBT) device. The code was recently used to image 3000 virtual breast models with the aim of reproducing in silico a clinical trial used in support of the regulatory approval of DBT as a replacement of mammography for breast cancer screening. The updated code implements a more realistic x-ray source model (extended 3D focal spot, tomosynthesis acquisition trajectory, tube motion blurring) and an improved detector model (direct-conversion Selenium detector with depth-of-interaction effects, fluorescence tracking, electronic noise and anti-scatter grid). The software uses a high resolution voxelized geometry model to represent the breast anatomy. To reduce the GPU memory requirements, the code stores the voxels in memory within a binary tree structure. The binary tree is an efficient compression mechanism because many voxels with the same composition are combined in common tree branches while preserving random access to the phantom composition at any location. A delta scattering ray-tracing algorithm which does not require computing ray-voxel interfaces is used to minimize memory access. Multiple software verification and validation steps intended to establish the credibility of the implemented computational models are reported. The software verification was done using a digital quality control phantom and an ideal pinhole camera. The validation was performed reproducing standard bench testing experiments used in clinical practice and comparing with experimental measurements. A sensitivity study intended to assess the robustness of the simulated results to variations in some of the input parameters was performed using an in silico clinical trial pipeline with simulated lesions and mathematical observers. We show that MC-GPU is able to simulate x-ray projections that incorporate many of the sources of variability found in clinical images, and that the simulated results are robust to some uncertainty in the input parameters. Limitations of the implemented computational models are discussed.
               
                  Program summary
                  
                     Program title: MCGPU_VICTRE
                  
                     CPC Library link to program files: 
                     https://doi.org/10.17632/k5x2bsf27m.1
                  
                  
                     Licensing provisions: CC0 1.0
                  
                     Programming language: C (with NVIDIA CUDA extensions)
                  
                     Nature of problem: The health risks associated with ionizing radiation impose a limit to the amount of clinical testing that can be done with x-ray imaging devices. In addition, radiation dose cannot be directly measured inside the body. For these reasons, a computational replica of an x-ray imaging device that simulates radiographic images of synthetic anatomical phantoms is of great value for device evaluation. The simulated radiographs and dosimetric estimates can be used for system design and optimization, task-based evaluation of image quality, machine learning software training, and in silico imaging trials.
                  
                     Solution method: Computational models of a mammography x-ray source and detector have been implemented. X-ray transport through matter is simulated using Monte Carlo methods customized for parallel execution in multiple Graphics Processing Units. The input patient anatomy is represented by voxels, which are efficiently stored in the video memory using a new binary tree structure compression mechanism.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2020.107398,Journal,Mechanical Systems and Signal Processing,scopus,2021-04-01,sciencedirect,1D convolutional neural networks and applications: A survey,https://api.elsevier.com/content/abstract/scopus_id/85095978325,"During the last decade, Convolutional Neural Networks (CNNs) have become the de facto standard for various Computer Vision and Machine Learning operations. CNNs are feed-forward Artificial Neural Networks (ANNs) with alternating convolutional and subsampling layers. Deep 2D CNNs with many hidden layers and millions of parameters have the ability to learn complex objects and patterns providing that they can be trained on a massive size visual database with ground-truth labels. With a proper training, this unique ability makes them the primary tool for various engineering applications for 2D signals such as images and video frames. Yet, this may not be a viable option in numerous applications over 1D signals especially when the training data is scarce or application specific. To address this issue, 1D CNNs have recently been proposed and immediately achieved the state-of-the-art performance levels in several applications such as personalized biomedical data classification and early diagnosis, structural health monitoring, anomaly detection and identification in power electronics and electrical motor fault detection. Another major advantage is that a real-time and low-cost hardware implementation is feasible due to the simple and compact configuration of 1D CNNs that perform only 1D convolutions (scalar multiplications and additions). This paper presents a comprehensive review of the general architecture and principals of 1D CNNs along with their major engineering applications, especially focused on the recent progress in this field. Their state-of-the-art performance is highlighted concluding with their unique properties. The benchmark datasets and the principal 1D CNN software used in those applications are also publicly shared in a dedicated website. While there has not been a paper on the review of 1D CNNs and its applications in the literature, this paper fulfills this gap.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gie.2020.07.052,Journal,Gastrointestinal Endoscopy,scopus,2021-04-01,sciencedirect,Prospective development and validation of a volumetric laser endomicroscopy computer algorithm for detection of Barrett's neoplasia,https://api.elsevier.com/content/abstract/scopus_id/85095854894,"Background and Aims
                  Volumetric laser endomicroscopy (VLE) is an advanced imaging modality used to detect Barrett’s esophagus (BE) dysplasia. However, real-time interpretation of VLE scans is complex and time-consuming. Computer-aided detection (CAD) may help in the process of VLE image interpretation. Our aim was to train and validate a CAD algorithm for VLE-based detection of BE neoplasia.
               
                  Methods
                  The multicenter, VLE PREDICT study, prospectively enrolled 47 patients with BE. In total, 229 nondysplastic BE and 89 neoplastic (high-grade dysplasia/esophageal adenocarcinoma) targets were laser marked under VLE guidance and subsequently underwent a biopsy for histologic diagnosis. Deep convolutional neural networks were used to construct a CAD algorithm for differentiation between nondysplastic and neoplastic BE tissue. The CAD algorithm was trained on a set consisting of the first 22 patients (134 nondysplastic BE and 38 neoplastic targets) and validated on a separate test set from patients 23 to 47 (95 nondysplastic BE and 51 neoplastic targets). The performance of the algorithm was benchmarked against the performance of 10 VLE experts.
               
                  Results
                  Using the training set to construct the algorithm resulted in an accuracy of 92%, sensitivity of 95%, and specificity of 92%. When performance was assessed on the test set, accuracy, sensitivity, and specificity were 85%, 91%, and 82%, respectively. The algorithm outperformed all 10 VLE experts, who demonstrated an overall accuracy of 77%, sensitivity of 70%, and specificity of 81%.
               
                  Conclusions
                  We developed, validated, and benchmarked a VLE CAD algorithm for detection of BE neoplasia using prospectively collected and biopsy-correlated VLE targets. The algorithm detected neoplasia with high accuracy and outperformed 10 VLE experts. (The Netherlands National Trials Registry (NTR) number: NTR 6728.)",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2020.100347,Journal,Internet of Things (Netherlands),scopus,2021-03-01,sciencedirect,RL-PMAgg: Robust aggregation for PM2.5 using deep RL-based trust management system,https://api.elsevier.com/content/abstract/scopus_id/85114812625,"Air pollution has become a major environmental issue in large cities. Air pollutants, especially fine particulate matter (PM2.5) has raised various concerns on human health. As a result, several low-cost PM2.5 monitoring systems have been deployed worldwide. However, an accurate air pollution monitoring system profoundly relies on data quality. In this paper, we propose RL-PMAgg for robustly computing PM2.5 pollution rates in existence of faulty sensors. Our method consists of three modules. The outlier detector gives quality assessments to the measurements. We use an RL-based trust management system to create a profile for each sensor and track its behavior in the long run. Then, an aggregated PM2.5 rate is computed by using a set of honest sensors along with their trust levels and measurements. We evaluate RL-PMAgg on both simulated and real-world datasets. We compare the proposed method with relevant works. Experimental results show that RL-PMAgg resists the majority of attacks as compared with other works.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jcv.2021.104757,Journal,Journal of Clinical Virology,scopus,2021-03-01,sciencedirect,"Evaluation of a measles virus multiplex, triple-target real-time RT-PCR in three specimen matrices at a U.S. academic medical center",https://api.elsevier.com/content/abstract/scopus_id/85101360201,"Background
                  Measles virus (MeV) is an important cause of acute febrile illness and pediatric mortality globally, with recent U.S. outbreaks associated with under-vaccination. MeV is highly contagious and timely diagnosis is critical to limit spread. RNA detection is the most sensitive method for acute measles diagnosis; however, MeV nucleic acid amplification assays are not widely available.
               
                  Methods
                  We performed a diagnostic accuracy study of a triple-target, real-time RT-PCR (rRT-PCR) assay for simultaneous detection of MeV N, H, and L genes.
               
                  Results
                  The MeV triple-target rRT-PCR was tested against serial dilutions (7.0−2.0 log10 copies/mL) of five MeV isolates representing circulating genotypes, and detected 98.7% (74/75) of nasopharyngeal (NP) swab dilutions, 100% (75/75) of plasma dilutions, and 85.3% (64/75) of urine dilutions. MeV RNA detection in urine was markedly improved with the addition of a nucleic acid stabilizing agent. A 95% lower limit of detection (LLOD) of < 3.0 log10 copies/mL was established in each specimen matrix. No cross-reactivity with relevant viruses or interfering substances were identified in specificity studies. The MeV triple-target rRT-PCR detected all three gene targets in a clinical NP swab from an individual with confirmed measles infection. Furthermore, pooled testing from 798 influenza A/B/RSV-negative pediatric NP swabs identified two specimens positive for MeV RNA, confirmed by N gene sequencing to represent shedding of the vaccine-type measles virus.
               
                  Conclusions
                  The MeV triple-target rRT-PCR assay showed high analytic sensitivity across circulating MeV genotypes in three clinically-relevant matrices. Implementation of this assay in the clinical laboratory may facilitate timely diagnosis of acute measles infection and implementation of appropriate infection control interventions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.clineuro.2021.106524,Journal,Clinical Neurology and Neurosurgery,scopus,2021-03-01,sciencedirect,Clinical application of Myelopathy-hand Functional Evaluation System in evaluating the postoperative hand motor function for myelopathy patients,https://api.elsevier.com/content/abstract/scopus_id/85100619463,"Objective
                  Recovery of hand motor function after surgical treatment in myelopathy patients is commonly observed. Accurate evaluation of postoperative hand function contributes to assessing the efficacy of surgical treatment. However, no objective and effective evaluation method has been widely accepted in clinical practice. Therefore, the study aimed to explore the value of Myelopathy-hand Functional Evaluation System (MFES) in assessing the postoperative hand function for myelopathy patients.
               
                  Material and method
                  MFES mainly consist of a pair of wise-gloves and a computer with software. One hundred and thirty myelopathy patients were included and all of them received optimal surgery treatment. The Japanese Orthopaedic Association (JOA) scores were marked at preoperative and at 6 months after surgery. All patients were asked to perform the 10-s grip and release test, and the hand movements were simulated and converted into waveforms by MFES. The waveform parameters were measured and analyzed.
               
                  Results
                  The JOA scores and the number of grip-and-release (G–R) cycles significantly increased after surgery. Correspondingly, the waveforms of ulnar three fingers were significantly higher and narrower, along with the significantly declined average time per cycle in postoperative. The a/b ratio (Wave height/wave width) of five fingers were significantly higher in postoperative than that in preoperative. Based on the improvement rate of a/b, the excellent and good rate of surgical outcomes was 62.30 %, which was significantly higher than that (47.69 %) based on the improvement rate of JOA scores (P = 0.019).
               
                  Conclusion
                  MFES is an effective assessment tool in evaluating the postoperative hand function for myelopathy patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.berh.2021.101662,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2021-03-01,sciencedirect,Managing patients using telerheumatology: Lessons from a pandemic,https://api.elsevier.com/content/abstract/scopus_id/85100105533,"The coronavirus disease 2019 (COVID-19) pandemic has presented unique challenges to rheumatology provision. Measures to control the pandemic have limited face-to-face contact with rheumatology healthcare professionals. One innovation has been the widespread adoption of telerheumatology to assist in the care of patients with rheumatic and musculoskeletal diseases, building on an existing evidence base in rheumatology. Widespread adoption has only occurred following the COVID-19 pandemic. We discuss the evidence supporting telerheumatology adoption prior to the pandemic, and outline several innovative approaches used to assist in the care of rheumatology patients that have been introduced. Alongside the advantages of these interventions, we discuss the limitations and regulatory challenges. Advances must be balanced, considering wider issues of equity of access, implementation, adoption, and sustainability of telerheumatology post-pandemic. We propose it is not ‘if’, but ‘how’ rheumatologists embrace newer telerheumatology technology, outlining practice points and future research agenda.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.104189,Journal,Computers in Biology and Medicine,scopus,2021-03-01,sciencedirect,A novel algorithm for minute ventilation estimation in remote health monitoring with magnetometer plethysmography,https://api.elsevier.com/content/abstract/scopus_id/85099685697,"Purpose
                  The purpose of this study was to evaluate the accuracy of minute ventilation (
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                     ) estimation using a novel method based on a non-linear algorithm coupled with cycle-based features. The experiment protocol was well adapted for remote health monitoring applications by exploiting data streams from respiratory magnetometer plethysmography (RMP) during different physical activity (PA) types. Methods Thirteen subjects with an age distribution of 
                        
                           24.1
                           ±
                           3.4
                        
                      years performed thirteen PA ranging from sedentary to moderate intensity (walking at 4 and 6 km/h, running at 9 and 12 km/h, biking at 90 W and 110 W). In total, 3359 temporal segments of 10s were acquired using the Nomics RMP device while the iWorx spirometer was used for reference 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      measurements. An artificial neural network (ANN) model based on respiration features was used to estimate 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      and compared to the multiple linear regression (MLR) model. We also compared the subject-specific approach with the subject-independent approach. Results The ANN model using subject-specific approach achieved better accuracy for the 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      estimation. The bias was between 
                        
                           0.20
                           ±
                           0.87
                        
                      and 
                        
                           0.78
                           ±
                           3
                        
                      l/min with the ANN model as compared to 
                        
                           0.73
                           ±
                           3.19
                        
                      and 
                        
                           4.17
                           ±
                           2.61
                        
                      l/min with the MLR model. Conclusion Our results demonstrated the pertinence of processing data streams from wearable RMP device to estimate the 
                        
                           
                              
                                 V
                                 ˙
                              
                              E
                           
                        
                      with sufficient accuracy for various PA types. Due to its low-complexity and real-time algorithm design, the current approach can be easily integrated into most remote health monitoring applications coupled with wearable sensors.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103737,Journal,Microprocessors and Microsystems,scopus,2021-03-01,sciencedirect,HPAC-sbox- a novel implementation of predictive learning classifier and adaptive chaotic s-box for counterfeiting sidechannel attacks in an IOT networks,https://api.elsevier.com/content/abstract/scopus_id/85099437035,"Today, embedded systems are augmented with the Internet of things and more with the artificial intelligence to make world even connected with aliens. With an IoT networks are getting its insight since it deals with large number of data information, security has considered to be more important and needs to be a diagnosis for every minute. To enhance the security in the network, a mathematically secure algorithms were formulated and runs on the cryptographic embedded chips to counterfeit the risks which are caused by the different attacks such as side channel attacks (SCA) on the networks. Even though many cryptographic encryption algorithms such as AES, DES, RC4 algorithms were gaining its importance, fixed encryption keys, non-intelligent detection of attacks, cognitive countermeasures are some of the real-time challenges in an existing system of encryption. Following the limitations of existing systems, this research article focuses on design of new AES with HPAC-SBOX (Hybrid Prediction and Adaptive Chaos) which integrates powerful predictive learning algorithms and adaptive chaotic logistic S-Box. The following contributions of this research articles are: a) Preparation of Data Sets from the Power consumption traces captured from Multi Core Embedded boards while running the Advanced Encryption Systems(AES) on it b) Implementation of High Speed and High Accurate Prediction learning machines for the prediction of side-channel attacks c) Design of Adaptive Chaotic S-Box using 3-Dlogistic Hyperbolic maps for attacked bits. To evaluate the proposed architecture, experimentation in carried out in an IoT networks and various performance parameters were calculated and analyzed. The results show that the proposed architecture outperforms the other existing algorithms in terms of prediction and performance.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmi.2020.11.009,Journal,Clinical Microbiology and Infection,scopus,2021-03-01,sciencedirect,Antibody response using six different serological assays in a completely PCR-tested community after a coronavirus disease 2019 outbreak—the CoNAN study,https://api.elsevier.com/content/abstract/scopus_id/85098155473,"Objectives
                  Due to a substantial proportion of asymptomatic and mild courses, many severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infections remain unreported. Therefore, assessment of seroprevalence may detect the real burden of disease. We aimed to determine and characterize the rate of SARS-CoV-2 infections and the resulting seroprevalence in a defined population. The primary objective of the study was to assess SARS-CoV-2 antibody seroprevalence using six different IgG-detecting immunoassays. Secondary objectives of the study were: (a) to determine potential risk factors for symptomatic versus asymptomatic coronavirus disease 2019 courses, and (b) to investigate the rate of virus RNA-persistence.
               
                  Methods
                  CoNAN is a population-based cohort study performed in the community Neustadt am Rennsteig, Germany, which was quarantined from 22 March to 5 April after six SARS-CoV-2 cases were detected in the village's population. The SARS-CoV-2 outbreak comprised 51 cases and 3 deaths. The CoNAN study was performed from 13 May to 22 May 2020, 6 weeks after a SARS-CoV-2 outbreak.
               
                  Results
                  We enrolled a total of 626 participants (71% of the community population) for PCR and antibody testing in the study. All actual SARS-CoV-2 PCR tests were negative. Fifty-two out of 620 (8.4%) participants had antibodies against SARS-CoV-2 in at least two different assays. There were 38 participants with previously PCR-confirmed SARS-CoV-2 infection. Of those, only 19 (50%) displayed anti-SARS-CoV-2 antibodies. We also show that antibody-positive participants with symptoms compatible with a respiratory tract infection had significantly higher antibody levels then asymptomatic participants (EU-assay: median 2.9 versus 7.2 IgG-index, p 0.002; DS-assay: median 45.2 versus 143 AU/mL, p 0.002). Persisting viral replication was not detected.
               
                  Conclusions
                  Our data question the relevance and reliability of IgG antibody testing to detect past SARS-CoV-2 infections 6 weeks after an outbreak. We conclude that assessing immunity for SARS-CoV-2 infection should not rely on antibody tests alone.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2020.112903,Journal,Biosensors and Bioelectronics,scopus,2021-03-01,sciencedirect,Induced bioresistance via BNP detection for machine learning-based risk assessment,https://api.elsevier.com/content/abstract/scopus_id/85098146521,"Machine Learning (ML) is a powerful tool for big data analysis that shows substantial potential in the field of healthcare. Individual patient data can be inundative, but its value can be extracted by ML's predictive power and ability to find trends. A great area of interest is early diagnosis and disease management strategies for cardiovascular disease (CVD), the leading cause of death in the world. Treatment is often inhibited by analysis delays, but rapid testing and determination can help improve frequency for real time monitoring. In this research, an ML algorithm was developed in conjunction with a flexible BNP sensor to create a quick diagnostic tool. The sensor was fabricated as an ion-selective field effect transistor (ISFET) in order to be able to quickly gather large amounts of electrical data from a sample. Artifical samples were tested to characterize the sensors using linear sweep voltammetry, and the resulting data was utilized as the initial training set for the ML algorithm, an implementation of quadratic discriminant analysis (QDA) written in MATLAB. Human blood serum samples from 30 University of Pittsburgh Medical Center (UPMC) patients were tested to evaluate the effective sorting power of the algorithm, yielding 95% power in addition to ultra fast data collection and determination.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rvsc.2020.11.017,Journal,Research in Veterinary Science,scopus,2021-03-01,sciencedirect,Efficacy of a Salmonella enterica serovar Abortusovis (S. Abortusovis) inactivated vaccine in experimentally infected gestating ewes,https://api.elsevier.com/content/abstract/scopus_id/85096997250,"Salmonella enterica serovar Abortusovis (S. Abortusovis) infection is one of the most important causes of infectious late-term abortion as well as birth of weak lambs in sheep in many countries throughout the world. Implementation of protocols based on the application of effective vaccines is one of the most effective approaches for controlling this disease, but variable efficacy has been reported, possibly related to factors associated with the host, the vaccine, the parameters used for determining efficacy and the challenge protocols. In this context, a new commercial inactivated vaccine (INMEVA; Laboratorios Hipra S.A., Spain) was evaluated in 20 control and 17 vaccinated gestating ewes, subcutaneously challenged at 90 days of gestation with 5 × 106 colony-forming units (cfu) of a wild strain of S. Abortusovis. Incidence of reproductive failures, bacterial vaginal excretion (by real time PCR), and lamb survival were evaluated as indicators of the vaccine's level of protection. Moreover, humoral response (by ELISA test in serum samples) was studied. Vaccination was showed to be safe under the study conditions. Vaccine efficacy was demonstrated in two different ways: i) it significantly decreased the percentage of abortions [29.4% (5/17) in the vaccinated group compared to the control group (65%; 13/20)] and ii) there was a significant reduction of the overall vaginal excretion in the sampling period (3.05 log cfu/mL ± 0.84 in the vaccinated group vs. 5.68 ± 0.67 in the control group).
                  Given these results, the vaccine evaluated can be considered as an effective alternative for controlling S. Abortusovis infection in ovine flocks.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jep.2020.113541,Journal,Journal of Ethnopharmacology,scopus,2021-03-01,sciencedirect,Identification and characterization of new potent inhibitors of dengue virus NS5 proteinase from Andrographis paniculata supercritical extracts on in animal cell culture and in silico approaches,https://api.elsevier.com/content/abstract/scopus_id/85095777426,"Ethnopharmacological relevance
                  About 2.5 billion peoples are at risk of dengue virus and the majority of people, use traditional plant-based medicines to combat dengue. The whole plant of Andrographis paniculata used traditionally over past decades for health promotion. Andrographolide isolated from Andrographis paniculata is used as natural remedy for the treatment of various diseases in different parts of the world. Andrographolide has been reported to have antiviral activity against hepatitis B virus, hepatitis C virus, herpes simplex virus, influenza virus, chikungunya virus, dengue virus 2 and 4.
               
                  Aim of the study
                  The aim of the present study to isolate the andrographolide from the A. paniculata by supercritical fluid extraction technique and to characterize the isolated compound along with it anti-dengue activity against DENV-2 in vitro and in silico methods.
               
                  Materials and methods
                  Supercritical extraction condition for A. paniculata was standardised to isolate andrographolide compound at definite temperature and pressure on the basis of previous study. The andrographolide was identified by using Ultraviolet–Visible Spectroscopy (UV-VIS), Fourier-Transform Infrared Spectroscopy (FT-IR) and High Performance Thin Layer Chromatography (HPTLC) and Proton Nuclear Magnetic Resonance (1HNMR). The maximum non-toxic dose of isolated andrographolide was detected by MTT assay using a micro plate reader at 595 nm. One hundred (100) copies/ml of the DENV-2 virus was used for antiviral assay in C6/36 cells lines and inhibition of virus due to andrographolide was determined by real-time PCR assay. The purity of isolated andrographolide was determined by Differential Scanning Calorimetry (DSC). The dengue NS5 receptor protein was docked with andrographolide and evaluated on the basis of the total energy and binding affinity score by Auto Dock (V4.2.6) software.
               
                  Results
                  Andrographolide, a diterpene lactone was isolated from the A. paniculata supercritical extract at 40 °C temperature and 15 Mpa pressure. UV spectrophotometer analysis revealed that the curve of andrographolide plant extract was overlapped with reference compound at 228 nm and the similar bands were detected from FT-IR spectroscopy analysis at 3315, 2917, 2849, 1673, 1462 and 1454 cm−
                     1 in isolated and standard andrographolide. HPTLC analysis shows the retention factor (Rf) of A. paniculata extract at 0.74 ± 0.06 as similar to standard andrographolide Rf values. The purity of isolated andrographolide was 99.76%. The maximum non-toxic dose of isolated andrographolide was found as 15.62 μg/ml on the C6/36 cell line calculated by using MTT assay. The andrographolide showed the 97.23% anti-dengue activity against the dengue-2 virus in C6/36 cell lines. Results of molecular docking showed that the interaction between andrographolide and NS5 of dengue protein with the maximum binding energy as −7.35 kcal/mol.
               
                  Conclusions
                  It is concluded that isolated andrographolide from the A. paniculata possess anti-dengue activity against dengue-2 virus as revealed from in vitro and in silico method. Due to lack of the vaccine and anti-viral agents, andrographolide extracted from A. paniculata play a major role to inhibit the dengue replication. Hence, it could be a source for drug design and help to reduce the dengue infection.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2020.10.030,Journal,Future Generation Computer Systems,scopus,2021-03-01,sciencedirect,HealthXAI: Collaborative and explainable AI for supporting early diagnosis of cognitive decline,https://api.elsevier.com/content/abstract/scopus_id/85095701881,"Our aging society claims for innovative tools to early detect symptoms of cognitive decline. Several research efforts are being made to exploit sensorized smart-homes and artificial intelligence (AI) methods to detect a decline of the cognitive functions of the elderly in order to promptly alert practitioners. Even though those tools may provide accurate predictions, they currently provide limited support to clinicians in making a diagnosis. Indeed, most AI systems do not provide any explanation of the reason why a given prediction was computed. Other systems are based on a set of rules that are easy to interpret by a human. However, those rule-based systems can cope with a limited number of abnormal situations, and are not flexible enough to adapt to different users and contextual situations. In this paper, we tackle this challenging problem by proposing a flexible AI system to recognize early symptoms of cognitive decline in smart-homes, which is able to explain the reason of predictions at a fine-grained level. Our method relies on well known clinical indicators that consider subtle and overt behavioral anomalies, as well as spatial disorientation and wandering behaviors. In order to adapt to different individuals and situations, anomalies are recognized using a collaborative approach. We experimented our approach with a large set of real world subjects, including people with MCI and people with dementia. We also implemented a dashboard to allow clinicians to inspect anomalies together with the explanations of predictions. Results show that our system’s predictions are significantly correlated to the person’s actual diagnosis. Moreover, a preliminary user study with clinicians suggests that the explanation capabilities of our system are useful to improve the task performance and to increase trust. To the best of our knowledge, this is the first work that explores data-driven explainable AI for supporting the diagnosis of cognitive decline.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.113920,Journal,Expert Systems with Applications,scopus,2021-03-01,sciencedirect,BIDI: A classification algorithm with instance difficulty invariance,https://api.elsevier.com/content/abstract/scopus_id/85090363699,"In artificial intelligence, an expert/intelligent systems can emulate the decision-making ability of human experts. A good classification algorithm can provide significant assistance to expert/intelligent systems in solving a variety of practical problems. In classification, the “hard” instances may be outliers or noisy instances that are difficult to learn, which may confuse the classifier and induce the overfitting problem in the case of placing much emphasis on them. In fact, the difficulty of instances is crucial for improving the generalization and credibility of classification. Unfortunately, nearly all the existing classifiers ignore this important information. In this paper, the classification difficulty of each instance is introduced from a statistical perspective, which is an inherent characteristic of the instance itself. Then, a new classification algorithm named “boosting with instance difficulty invariance (BIDI)” is proposed by incorporating the classification difficulty of instances. The BIDI conforms to the human cognition that easy instances are misclassified with a lower probability than difficult ones, and performs better with respect to generalization. The key insight of BIDI can provide relevant guidance for researchers to improve the generalization and credibility of classifiers in the expert systems of decision support systems. Experimental results demonstrate the effectiveness of BIDI in real-world data sets, indicating that it has great potential for solving many classification tasks of expert systems such as disease diagnosis and credit card fraud detection. Although the classification difficulty has strong statistical significance, its implementation remains computationally expensive. A fast method demonstrating rationality and feasibility is also proposed to approximate instances’ classification difficulty.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.10.039,Journal,Neurocomputing,scopus,2021-02-28,sciencedirect,A new method for intelligent fault diagnosis of machines based on unsupervised domain adaptation,https://api.elsevier.com/content/abstract/scopus_id/85097714683,"Data driven fault diagnosis has attracted a lot of attention in recent years owing to its intelligent and accurate detection of fault categories. However, it is a challenge for its applications in real world. The abundant labeled data is extremely necessary for data driven fault diagnosis to train a favorable model. Even though enough labeled data is prepared for training a model, we still cannot ensure the data used for training and testing draw from identical distribution. In other words, the labeled source domain has different distribution compared with the unlabeled target domain. In this paper, we introduce the domain adaptation strategy into deep neural networks to propose a deep domain adaptation architecture, which realizes to learn knowledge from the labeled source domain to facilitate the target classification. In the proposed model, the conditional and marginal distribution are adapted together in multiple layers of neural network, which uses MMD to measure the distribution discrepancy. Besides, the relative importance between marginal and conditional distributions is explored, and an adaptively weighted strategy is further introduced to learn the relative importance of the two distributions. To evaluate the proposed method, we conduct the simulations on different workloads, sensor deployment locations, and even different platforms. The results show the superiority of the proposed model to other intelligent fault diagnosis methods, meanwhile verify the necessity of marginal and conditional distribution adaptation and adaptive weighted strategy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.applthermaleng.2020.116343,Journal,Applied Thermal Engineering,scopus,2021-02-25,sciencedirect,Comparative performance and emissions assessments of a single-cylinder diesel engine using artificial neural network and thermodynamic simulation,https://api.elsevier.com/content/abstract/scopus_id/85097099640,"Diesel engine parameter prediction became a topic of interest in recent years, along with the development of condition-based maintenance, and is now considered a key instrument for engine diagnosis research. This contribution compares two different approaches for diesel engine performance prediction: thermodynamic modelling and artificial neural networks (ANNs). The thermodynamic modelling was developed using AVL Boost™ software simulating a single-cylinder diesel engine with different engine loads and operating conditions. The ANN modelling was conducted by comparing two efficient training algorithms to achieve the best prediction performance, with the ANN structure parameters determined by network error analysis. Both models’ prediction accuracy was verified by a single-cylinder engine test bench operating under real conditions. The adaptability and robustness of the two approaches was studied for the whole engine load spectrum, comparing predicted values to experimental measurements. Both prediction tools, ANN and thermodynamic modelling, proved to be reliable for engine performance and emissions prediction. In both models brake-specific fuel consumption (BSFC), exhaust gas temperature (Texh), carbon monoxide (CO) and nitrogen oxides (NO
                        x
                     ) were predicted using brake mean effective pressure (BMEP) and engine speed as inputs. ANN show higher accuracy for BSFC prediction in all engine loads, and Texh prediction accuracy is better for ANN when dealing with medium to high loads, while the thermodynamic model shows better results when dealing with medium to low loads. CO is better predicted by the thermodynamic model except for the highest engine loads, and NO
                        x
                      predictions present high accuracy in both models, except for the lowest loads. Calculation time is lower for ANN, but the thermodynamic model provides additional performance results (i.e. combustion pressure tracing and associated values).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106679,Journal,Knowledge-Based Systems,scopus,2021-02-15,sciencedirect,Federated learning for machinery fault diagnosis with dynamic validation and self-supervision,https://api.elsevier.com/content/abstract/scopus_id/85098734354,"Intelligent data-driven machinery fault diagnosis methods have been successfully and popularly developed in the past years. While promising diagnostic performance has been achieved, the existing methods generally require large amounts of high-quality supervised data for training, which are mostly difficult and expensive to collect in real industries. Therefore, it is motivated that the distributed data of multiple clients can be integrated and exploited to build a powerful data-driven model. However, that basically requires data sharing among different users, and is not preferred in most industrial cases due to potential conflict of interests. In order to address the data island problem, a federated learning method for machinery fault diagnosis is proposed in this paper. Model training is locally implemented within each participated client, and a self-supervised learning scheme is proposed to enhance the learning performance. The server aggregates the locally updated models in each training round under the dynamic validation scheme, and a global fault diagnosis model can be established. Only the models are mutually communicated rather than the data, which ensures data privacy among different clients. The experiments on two datasets suggest the proposed method offers a promising approach on confidential decentralized learning.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2020.112830,Journal,Biosensors and Bioelectronics,scopus,2021-02-15,sciencedirect,Diagnosis of COVID-19 for controlling the pandemic: A review of the state-of-the-art,https://api.elsevier.com/content/abstract/scopus_id/85098139782,"To date, health organizations and countries around the world are struggling to completely control the spread of the coronavirus disease 2019 (COVID-19). Scientists and researchers are developing tests for the rapid detection of individuals who may carry the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), while striving to find a suitable vaccine to immunize healthy individuals. As there are clinically reported cases of asymptomatic carriers of SARS-CoV-2, fast and accurate diagnosis plays an important role in the control and further prevention of this disease. Herein, we present recent technologies and techniques that have been implemented for the diagnosis of COVID-19. We summarize the methods created by different research institutes as well as the commercial devices and kits developed by companies for the detection of SARS-CoV-2. The description of the existing methods is followed by highlighting their advantages and challenges. Finally, we propose some promising techniques that could potentially be applied to the detection of SARS-CoV-2, and tracing the asymptomatic carriers of COVID-19 rapidly and accurately in the early stages of infection, based on reviewing the research studies on the detection of similar infectious viruses, especially severe acute respiratory syndrome (SARS) coronavirus, and Middle East respiratory syndrome (MERS) coronavirus.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100195,Journal,Patterns,scopus,2021-02-12,sciencedirect,Topic classification of electric vehicle consumer experiences with transformer-based deep learning,https://api.elsevier.com/content/abstract/scopus_id/85100638713,"The transportation sector is a major contributor to greenhouse gas (GHG) emissions and is a driver of adverse health effects globally. Increasingly, government policies have promoted the adoption of electric vehicles (EVs) as a solution to mitigate GHG emissions. However, government analysts have failed to fully utilize consumer data in decisions related to charging infrastructure. This is because a large share of EV data is unstructured text, which presents challenges for data discovery. In this article, we deploy advances in transformer-based deep learning to discover topics of attention in a nationally representative sample of user reviews. We report classification accuracies greater than 91% (F1 scores of 0.83), outperforming previously leading algorithms in this domain. We describe applications of these deep learning models for public policy analysis and large-scale implementation. This capability can boost intelligence for the EV charging market, which is expected to grow to US$27.6 billion by 2027.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.wneu.2020.10.171,Journal,World Neurosurgery,scopus,2021-02-01,sciencedirect,Attitudes of the Surgical Team Toward Artificial Intelligence in Neurosurgery: International 2-Stage Cross-Sectional Survey,https://api.elsevier.com/content/abstract/scopus_id/85097780896,"Background
                  Artificial intelligence (AI) has the potential to disrupt how we diagnose and treat patients. Previous work by our group has demonstrated that the majority of patients and their relatives feel comfortable with the application of AI to augment surgical care. The aim of this study was to similarly evaluate the attitudes of surgeons and the wider surgical team toward the role of AI in neurosurgery.
               
                  Methods
                  In a 2-stage cross sectional survey, an initial open-question qualitative survey was created to determine the perspective of the surgical team on AI in neurosurgery including surgeons, anesthetists, nurses, and operating room practitioners. Thematic analysis was performed to develop a second-stage quantitative survey that was distributed via social media. We assessed the extent to which they agreed and were comfortable with real-world AI implementation using a 5-point Likert scale.
               
                  Results
                  In the first-stage survey, 33 participants responded. Six main themes were identified: imaging interpretation and preoperative diagnosis, coordination of the surgical team, operative planning, real-time alert of hazards and complications, autonomous surgery, and postoperative management and follow-up. In the second stage, 100 participants responded. Responders somewhat agreed or strongly agreed about AI being used for imaging interpretation (62%), operative planning (82%), coordination of the surgical team (70%), real-time alert of hazards and complications (85%), and autonomous surgery (66%). The role of AI within postoperative management and follow-up was less agreeable (49%).
               
                  Conclusions
                  This survey highlights that the majority of surgeons and the wider surgical team both agree and are comfortable with the application of AI within neurosurgery.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2020.116049,Journal,Applied Energy,scopus,2021-02-01,sciencedirect,Adaptive prognostics in a controlled energy conversion process based on long- and short-term predictors,https://api.elsevier.com/content/abstract/scopus_id/85097470918,"The pulp and paper industry is a fundamental sector of the economy of many countries. However, this sector requires real collaboration and initiatives from stakeholders to reduce its significant consumption of energy and emission of greenhouse gases. Heat exchangers are examples of equipment in pulp mills that are subjected to undesirable and complex phenomena such as evolution of fouling over time, which leads to inefficiency in terms of energy consumption and unplanned shutdowns, resulting in ineffective maintenance strategies and production costs. Therefore, there is a clear need to develop an accurate predictive maintenance tool that helps mill operators avoid such situations. It is necessary for that tool to effectively track the fouling evolution level and, based on it, deploy a reliable prognostics approach to estimate more accurately the time-to-clean of this equipment. This study presents a new hybrid prognostics approach for fouling prediction in heat exchangers. The proposed approach relies on the fusion of information of different prediction horizons to estimate the time-to-clean. Employing long short-term memory, it allows adaptation of long-term predictions by accurate short-term predictions using multiple non-linear auto-regressive exogenous models. This fusion not only captures the changes in degradation trend over time, but also ensures a good accuracy of prognostics results in both the short- and long-term horizons for planning maintenance actions. The effectiveness of the proposed approach was successfully proven on real industrial data collected from a pulp mill heat exchanger located in Canada.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apenergy.2020.116297,Journal,Applied Energy,scopus,2021-02-01,sciencedirect,An Echo State Network for fuel cell lifetime prediction under a dynamic micro-cogeneration load profile,https://api.elsevier.com/content/abstract/scopus_id/85097452614,"Improving Proton Exchange Membrane Fuel Cell durability is a key that paves the way to its large scale industrial deployment. During the last five years, the prognostics discipline emerged as an interesting field for Proton Exchange Membrane Fuel Cell state of health prediction and lifetime estimation. The information provided by the prognostic module is crucial for optimizing the control strategy to extend the fuel cell lifetime. In this paper, an approach based on Echo State Network for fuel cell prognostics under a variable load is developed. The novelty of this paper is to perform prognostics under a variable load profile without prior knowledge of this latter. Two solutions are developed in this work. The first one consists of evaluating the remaining useful lifetime under a repeated load cycle. The second one is based on using Markov chains to generate estimations of the future load profile, allowing thus to overcome the need of real future load profile prior knowledge. Both proposed solutions give accurate prediction results of proton exchange membrane fuel cell remaining useful lifetime, with low uncertainties.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2020.104348,Journal,International Journal of Medical Informatics,scopus,2021-02-01,sciencedirect,Towards effective machine learning in medical imaging analysis: A novel approach and expert evaluation of high-grade glioma ‘ground truth’ simulation on MRI,https://api.elsevier.com/content/abstract/scopus_id/85097334964,"Purpose/objective(s)
                  Gliomas are uniformly fatal brain tumours with significant neurological and quality of life detriment to patients. Improvement in outcomes has remained largely unchanged in nearly 20 years. MRI (magnetic resonance imaging) is often used in diagnosis and management. Machine learning analyses of large-scale MRI data are pivotal in advancing the diagnosis, management and improve outcomes in neuro-oncology. A common challenge to robust machine learning approaches is the lack of large ‘ground truth’ datasets in supervised learning for building classification and prediction models. The creation of these datasets relies on human-expert input and is time-consuming and subjective error-prone, limiting effective machine learning applications. Simulation of mechanistic aspects such as geometry, location and physical properties of brain tumours can generate large-scale ground-truth datasets allowing for comparison of analysis techniques in clinical applications. We aimed to develop a transparent and convenient method for building ‘ground truth’ presentations of simulated glioma lesions on anatomical MRI.
               
                  Materials/methods
                  The simulation workflow was created using the Feature Manipulation Engine (FME®), a data integration platform specializing in the spatial data processing. By compiling and integrating FME’s functions to read, integrate, transform, validate, save, and display MRI data, and experimenting with ways to manipulate the parameters concerning location, size, shape, and signal intensity with the presentations of glioma, we were able to generate simulated appearances of high-grade gliomas on gadolinium-based high-resolution 3D T1-weighted MRI (1 mm3). Data of patients with canonical high-grade tumours were used as real-world tumours for validating the accuracy of the simulation. Twenty raters who are experienced with brain tumour interpretation on MRI independently completed a survey, designed to distinguish simulated and real-world brain tumours. Sensitivity and specificity were calculated for assessing the performance of the approach with the binary classification of simulated vs real-world tumours. Correlation and regression were used in run time analysis, assessing the software toolset’s efficiency in producing different numbers of simulated lesions. Differences in the group means were examined using the non-parametric Kruskal-Wallis test.
               
                  Results
                  The simulation method was developed as an interpretable and useful workflow for the easy creation of tumour simulations and incorporation into 3D MRI. A linear increase in the running time and memory usage was observed with an increasing number of generated lesions. The respondents' accuracy rate ranged between 33.3 and 83.3 %. The sensitivity and specificity were low for a human expert to differentiate simulated lesions from real gliomas (0.43 and 0.58) or vice versa (0.65 and 0.62). The mean scores ranking the real-world gliomas did not differ between the simulated and real tumours.
               
                  Conclusion
                  The reliable and user-friendly software method can allow for robust simulation of high-grade glioma on MRI. Ongoing research efforts include optimizing the workflow for generating glioma datasets as well as adapting it to simulating additional MRI brain changes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103301,Journal,Microprocessors and Microsystems,scopus,2021-02-01,sciencedirect,IoT enabled cancer prediction system to enhance the authentication and security using cloud computing,https://api.elsevier.com/content/abstract/scopus_id/85094168107,"In recent days, Internet of Things, Cloud Computing, Deep learning, Machine learning and Artificial Intelligence are considered to be an emerging technologies to solve variety of real world problems. These techniques are importantly applied in various fields such as healthcare systems, transportation systems, agriculture and smart cities to produce fruitful results for number of issues in today's environment. This research work focuses on one such application in the field of IoT together with cloud computing. More number of sensors that are deployed in human body is used to collect patient related data such as deviation in body temperature and others which leads to variation in blood cells that turned to be cancerous cells. Main intention of this work is design a cancer prediction system using Internet of Things upon extracting the details of blood results to test whether it is normal or abnormal. In addition to this, encryption is done on the blood results of cancer affected patient and store it in cloud for quick reference through Internet for the doctor or healthcare nurse to handle the patient data secretly. This research work concentrates on enhancing the health care computations and processing. It provides a framework to enhance the performance of the existing health care industry across the globe. As the entire medical data has to be saved in cloud, the traditional medical treatment limitations can be overcome. Encryption and decryption is done using AES algorithm in order to provide authentication and security in handling cancer patients. The main focus is to handle healthcare data effectively for the patient when they are away from the home town since the needed cancer treatment details are stored in cloud. The task completion time is greatly reduce from 400 to 160  by using VMs. CloudSim gives an adaptable simulation structure that empowers displaying and reproduced results.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2020.08.046,Journal,Future Generation Computer Systems,scopus,2021-02-01,sciencedirect,A drone-based networked system and methods for combating coronavirus disease (COVID-19) pandemic,https://api.elsevier.com/content/abstract/scopus_id/85090189689,"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus. It is similar to influenza viruses and raises concerns through alarming levels of spread and severity resulting in an ongoing pandemic worldwide. Within eight months (by August 2020), it infected 24.0 million persons worldwide and over 824 thousand have died. Drones or Unmanned Aerial Vehicles (UAVs) are very helpful in handling the COVID-19 pandemic. This work investigates the drone-based systems, COVID-19 pandemic situations, and proposes an architecture for handling pandemic situations in different scenarios using real-time and simulation-based scenarios. The proposed architecture uses wearable sensors to record the observations in Body Area Networks (BANs) in a push–pull data fetching mechanism. The proposed architecture is found to be useful in remote and highly congested pandemic areas where either the wireless or Internet connectivity is a major issue or chances of COVID-19 spreading are high. It collects and stores the substantial amount of data in a stipulated period and helps to take appropriate action as and when required. In real-time drone-based healthcare system implementation for COVID-19 operations, it is observed that a large area can be covered for sanitization, thermal image collection, and patient identification within a short period (2 KMs within 10 min approx.) through aerial route. In the simulation, the same statistics are observed with an addition of collision-resistant strategies working successfully for indoor and outdoor healthcare operations. Further, open challenges are identified and promising research directions are highlighted.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.rcim.2020.102029,Journal,Robotics and Computer-Integrated Manufacturing,scopus,2021-02-01,sciencedirect,Towards manufacturing robotics accuracy degradation assessment: A vision-based data-driven implementation,https://api.elsevier.com/content/abstract/scopus_id/85088120602,"In this manuscript we report on a vision-based data-driven methodology for industrial robot health assessment. We provide an experimental evidence of the usefulness of our methodology on a system comprised of a 6-axis industrial robot, two monocular cameras and five binary squared fiducial markers. The fiducial marker system permits to accurately track the deviation of the end-effector along a fixed non-trivial trajectory. Moreover, we monitor the trajectory deflection using three gradually increasing weights attached to the end-effector. When the robot is loaded with the maximum allowed payload, a deviation of 0.77mm is identified in the Z-coordinate of the end-effector. Tracing trajectory information, we train five supervised learning regression models. Such models are afterwards used to predict the deviation of the end-effector, using the pose estimation provided by the visual tracking system. As a result of this study, we show that this procedure is a stable, robust, rigorous and reliable tool for robot trajectory deviation estimation and it even allows to identify the mechanical element producing non-kinematic errors.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejso.2020.04.010,Journal,European Journal of Surgical Oncology,scopus,2021-02-01,sciencedirect,Peroperative personalised decision support and analytics for colon cancer surgery- Short report,https://api.elsevier.com/content/abstract/scopus_id/85083856433,"Advanced instrumentation whether robotic or non-robotic- hasn't itself made for better surgery as all critical measures of operative success depend still on intraoperative surgeon judgement and decision-making. Computer assisted surgery, or digital surgery, refers to the combination of technology with real-time data during an operation and is often assumed to need new hardware platforms to become a reality. However, methods to support personalised surgical endeavour exist now and can be deployed today within standard laparoscopic paradigms. Here we describe in detail the rationale for the deployment of such assistance for surgical step-advancement in our current practice evolution from traditional proximal colon cancer resection to complete mesocolic excision focussing on personalised 3d anatomical display, intraoperative, quantificative fluorescence assessment of intracorporeal anastomoses and postoperative digital feedback to enable reflection and identify areas of technical improvement.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijpharm.2020.120028,Journal,International Journal of Pharmaceutics,scopus,2021-01-05,sciencedirect,Optimization and evaluation of propolis liposomes as a promising therapeutic approach for COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85095979631,"The present work aimed to develop an optimized liposomal formulation for enhancing the anti-viral activity of propolis against COVID-19. Docking studies were performed for certain components of Egyptian Propolis using Avigan, Hydroxychloroquine and Remdesivir as standard antivirals against both COVID-19 3CL-protease and S1 spike protein. Response surface methodology and modified injection method were implemented to maximize the entrapment efficiency and release of the liposomal formulation. The optimized formulation parameters were as follow: LMC of 60 mM, CH% of 20% and DL of 5 mg/ml. At those values the E.E% and released % were 70.112% and 81.801%, respectively with nanosized particles (117 ± 11 nm). Docking studies revealed that Rutin and Caffeic acid phenethyl ester showed the highest affinity to both targets. Results showed a significant inhibitory effect of the optimized liposomal formula of Propolis against COVID-3CL protease (IC50 = 1.183 ± 0.06) compared with the Egyptian propolis extract (IC50 = 2.452 ± 0.11), P < 0.001. Interestingly, the inhibition of viral replication of COVID-19 determined by RT_PCR has been significantly enhanced via encapsulation of propolis extract within the liposomal formulation (P < 0.0001) and was comparable to the viral inhibitory effect of the potent antiviral (remdesivir). These findings identified the potential of propolis liposomes as a promising treatment approach against COVID-19.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-90769-9.00004-9,Book,Data Science for COVID-19: Volume 2: Societal and Medical Perspectives,scopus,2021-01-01,sciencedirect,Artificial intelligence-based solutions for COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85130158172,"Witness the coronavirus disease 2019 (COVID-19) virus becoming more deadly. Artificial intelligence (AI) scientists are using social media, the web, and other knowledge machine learning techniques to look for subtle signs that the disease may spread elsewhere. AI is a weapon in the battle against the infectious pandemic that has had impacts on the whole planet since early 2020. It echoes the high hopes of data science to confront the coronavirus in the press and the scientific community. The AI approach is used in the battle for cure, prediction, and pandemic predictors. Improving AI is a good step toward growing such uncertainties, one of the essential data analytics tools built over the past decade or so. Data scientists have approached the task of motivation. The index is growing exponentially as work information surface, beyond the potential of humans to do it alone. AI describes large data models, and this chapter should clarify how this challenge has become one of the ace cards of humanity. Advances in AI software, such as natural language processing, expression understanding, data mining, etc., are used for diagnosis as well as traceability and production of vaccines. AI has supported and contributed to the control of the COVID-19 pandemic. We include an initial overview of the real and potential contribution of AI to the fight against COVID-19 and the existing constraints on these contributions. In this chapter, different technologic solutions using AI for COVID-19 have been discussed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85117-6.00007-8,Book,Cognitive Big Data Intelligence with a Metaheuristic Approach,scopus,2021-01-01,sciencedirect,Livestock health monitoring using a smart IoT-enabled neural network recognition system,https://api.elsevier.com/content/abstract/scopus_id/85129907981,"A poultry farm monitoring system along with a livestock monitoring system is a principal system for investigating the status of bird health by collecting biological traits such as their uttered sounds. This theme combines the Internet of Things (IoT) with nonintrusive and reliable wearable sensing technology. In recent developments, machine learning (ML) or artificial neural networks (ANNs) have been well applied and recognized as an effective tool for a range of complicated scenario analyses in real time, including healthcare sector applications. This will help to alleviate problems typically suffered and faced by medical researchers in these fields by saving time for practitioners by providing unbiased results. In this chapter we discuss the utilization of analytics learning and neural network usage toward clinical concerns in health care using the IoT. ANN is a prime research domain with recent deployment of computational sophistication in hardware and software in several application domains with highly complicated computing scenarios. The healthcare sector is one area which is capable of automation to save time and that is subjective by nature. Therefore, ML- and ANN-based simulations generate unbiased outcomes. This chapter describes an IoT-structured wearable sensing platform with the inclusion of an audio feature and temperature of the livestock. In particular, the secure audio-wellbeing features are incorporated into the platform to spontaneously examine and conclude using voice information from the livestock for recognition of diseased birds. One month of long-term recognition experimentation analysis was performed where the recognition accuracy of the onset of disease bird was about 91% using a spiking neural network (SNN).The recognition accuracy of SNN in this regard is better than the performance of an ANN. A sequence of steps was taken in connection with a specific event that occurred and involved in examining the interrelationship across the central monitoring unit and the local monitoring unit using the IoT by utilizing the bird voice features, bird temperature, and room temperature and humidity.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85854-0.00033-2,Book,Wearable Telemedicine Technology for the Healthcare Industry: Product Design and Development,scopus,2021-01-01,sciencedirect,Wearable Telemedicine Technology for the Healthcare Industry: Product Design and Development,https://api.elsevier.com/content/abstract/scopus_id/85129829828,Unknown,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85193-0.00012-7,Book,"Microbial Management of Plant Stresses: Current Trends, Application and Challenges",scopus,2021-01-01,sciencedirect,Advances in sensing plant diseases by imaging and machine learning methods for precision crop protection,https://api.elsevier.com/content/abstract/scopus_id/85128582282,"Plant diseases are one of the primary causes of major economic losses in the agriculture industry worldwide. The continuous monitoring of plant health and early detection of pathogens are crucial to reduce the disease spread and help effective disease management. The traditional methods of plant disease management generally rely on the spraying of chemical pesticides in the entire field, irrespective of its real requirement or not. Such blind application of these chemicals leads to undesirable effects on soil chemistry and microbiota. Following the second green revolution utilizing genomic advancements, smart or precision farming is changing the agricultural landscape at a very fast pace across the world. Precision agriculture relies on the implementation of modern-day advanced imaging and information technologies in disease identification. These intelligent and noninvasive methods use near real-time observations to protect crop damages caused by plant diseases. From a huge landscape of precision agriculture, the present chapter concentrates on the imaging-based approaches for biotic stress detection in plants. In this chapter, the machine learning methods including support vector machines, neural networks, and deep learning are also highlighted for the detection of plant diseases. These algorithms help in making smart decisions for the actual requirement and the adequate application of crop protection resources. Both imaging and machine learning methods are powerful and unparalleled tools for sustainable agriculture. They effectively detect biotic stress in plants and can provide data directly from different geographical scales.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-822884-5.00017-9,Book,Big Data in Psychiatry and Neurology,scopus,2021-01-01,sciencedirect,Big data in personalized healthcare,https://api.elsevier.com/content/abstract/scopus_id/85128096859,"Big data technologies enable correlation of multiple data sources into a coherent view. Big data and Big Data analytics have been used in public health, electronic consultation (e-consultation), real-time telediagnosis, precision healthcare, and personalized healthcare. e-Consultation is one aspect of telemedicine related to remote communication between medical specialists and clinicians, or clinicians and patients. It is generally implemented via the Internet or mobile communication devices (e.g., smartphone) and often generates big data. The concepts, characteristics, methods, emerging technologies, and software platforms or tools of big data and Big Data analytics are introduced in this chapter. Big data and applications in general healthcare are presented. Specifically, big data in precision healthcare and personalized healthcare are introduced. Challenges of big data and Big Data analytics in personalized healthcare are also outlined.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-822884-5.00020-9,Book,Big Data in Psychiatry and Neurology,scopus,2021-01-01,sciencedirect,A scalable medication intake monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85128012085,"Poor medication adherence is a global issue, causing adverse health-care problems and economic consequences. Many recent studies have designed and developed medication intake monitoring systems for both directly and indirectly monitoring patients using various sensors and advanced signal processing and machine learning algorithms. However, many studies have failed to deliver a system architecture that can be easily adapted to real-life scenarios with respect to cost, size, wearability, and social acceptance. A modern system architecture for medication intake monitoring must overcome these concerns, providing a practical design that combines hardware and software to accurately identify medication intake. Furthermore, for storing and processing high-frequency sensor data streams from multiple users simultaneously, it is essential to utilize scalable data storage and computing frameworks. In this chapter, we introduce a recently developed smartwatch application and a cloud-based data pipeline. The smartwatch application collects activity sensor data and sound data using embedded inertial sensors and microphones. The cloud-based data pipeline includes distributed data storage, Apache Spark-based distributed computing, and H2O-based distributed machine learning frameworks in order to build a machine learning model that identifies instances of medication intake.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-821229-5.00008-2,Book,Machine Learning and the Internet of Medical Things in Healthcare,scopus,2021-01-01,sciencedirect,Artificial itelligence in medicine,https://api.elsevier.com/content/abstract/scopus_id/85127629358,"Modern lifestyle and the polluted environment are the main causes of different types of diseases. Some diseases are curable through primary medication but some are more severe and require proper medication. In clinical treatment, different categories of medicines such as allopathic, homeopathy, herbal, art therapy, homemade medicine, etc. are applied to cure the diseases. The prediction of an appropriate medicine as per the symptoms of the disease is a challenging task for the clinicians. In this context, intelligent systems could be very helpful to predict the right medicine to the right people. Artificial Intelligence (AI) is a kind of intelligent system that applies different techniques to work with a huge amount of data for real-time analysis and better prediction to attain the required outcome. Also in the medicine industry, the process of discovering new medicines needs several clinical trials and requires approval by the concerned authority to deploy in the market. AI can improve decision-making and assist in the search for better medicines. Machine Learning is another revolution from AI that learns from the preexisting data sets and improves its accuracy in decision-making. This chapter presents a detailed literature survey on different AI techniques, followed by recent developments and applications in the medical industry.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-819742-4.00009-3,Book,"Machine Learning and Data Science in the Power Generation Industry: Best Practices, Tools, and Case Studies",scopus,2021-01-01,sciencedirect,Electrical consumption forecasting in hospital facilities,https://api.elsevier.com/content/abstract/scopus_id/85126794555,"The topic of energy efficiency applied to buildings represents one of the key aspects in today's international energy policies. Emissions reduction and the achievement of the targets set by the Kyoto Protocol are becoming a fundamental concern in the work of engineers and technicians operating in the energy management field. Optimal energy management practices need to deal with uncertainties in generation and demand. Hence the development of reliable forecasting methods is an important priority and area of research in electric energy systems. This chapter presents a load forecasting model and the way it was applied to a real case study in forecasting the electrical consumption of the Cellini medical clinic of Turin, Italy. The model can be easily integrated into a Building Management System or into a real-time monitoring system. The load forecasting is performed through the implementation of an artificial neural network (ANN). The proposed multilayer perceptron ANN, based on a backpropagation training algorithm, is able to take as inputs: loads, type of day (e.g., weekday/holiday), time of the day, and weather data. This work focuses on providing a detailed analysis and an innovative formal procedure for the selection of all ANN parameters.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.10.060,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Arrhythmia detection using multi-lead ECG spectra and Complex Support Vector Machine Classifiers,https://api.elsevier.com/content/abstract/scopus_id/85121789364,"Electrocardiograms (ECG) are extensively used for the diagnosis of cardiac arrhythmias. This work investigates the use of machine learning classification algorithms for ECG analysis and arrhythmia detection. Four beat types, Normal (N), Premature Ventricular Contraction (PVC), Atrial Premature Contraction (APC) and Right Bundle Branch Block Beat (RBBB) are simultaneously presented to a Complex Support Vector Machine (CSVM) classifier. The ECG signals are obtained from the St Petersburg INCART 12-lead Arrhythmia Database (INCARTDB). The detection of ECG Wave (P, QRS, T) is performed with the Wave Form Database (WFDB) Software Package which is used to read the annotation files and find the R (peak) location. For feature extraction, the Discrete Fourier Transform (DFT) is used. Fifty Fourier coefficients were selected for reconstructing individual ECG beats. This ensures moderate dimensionality reduction and de-noising of the input vector to the classifier. ECG beats classification is performed using CSVM with several training and test datasets. Sequential Minimal Optimization (SMO) is used to train the CSVM and compute the hyperplane parameters associated with both the real and complex hyperplanes. Cross validation is used for finding the best parameter values of the SVM and the two Gaussian RBK kernel functions. The aim of the study is to establish the advantage of CSVM over standard SVM in simultaneously detecting different types of arrhythmias on the basis of multi-lead recordings following signal compression in the Fourier domain. Implementation of the algorithms was performed in MATLAB. The CSVM classification algorithm provided better performance than the standard SVM classifier. The classification accuracy of the proposed scheme is 98.25% using CSVM. Future work will concentrate on the further development of ECG signal pre-processing using adaptive wavelet algorithms as well as classification with Clifford SVMs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aiia.2021.11.004,Journal,Artificial Intelligence in Agriculture,scopus,2021-01-01,sciencedirect,Automation and digitization of agriculture using artificial intelligence and internet of things,https://api.elsevier.com/content/abstract/scopus_id/85120995341,"The growing population and effect of climate change have put a huge responsibility on the agriculture sector to increase food-grain production and productivity. In most of the countries where the expansion of cropland is merely impossible, agriculture automation has become the only option and is the need of the hour. Internet of things and Artificial intelligence have already started capitalizing across all the industries including agriculture. Advancement in these digital technologies has made revolutionary changes in agriculture by providing smart systems that can monitor, control, and visualize various farm operations in real-time and with comparable intelligence of human experts. The potential applications of IoT and AI in the development of smart farm machinery, irrigation systems, weed and pest control, fertilizer application, greenhouse cultivation, storage structures, drones for plant protection, crop health monitoring, etc. are discussed in the paper. The main objective of the paper is to provide an overview of recent research in the area of digital technology-driven agriculture and identification of the most prominent applications in the field of agriculture engineering using artificial intelligence and internet of things. The research work done in the areas during the last 10 years has been reviewed from the scientific databases including PubMed, Web of Science, and Scopus. It has been observed that the digitization of agriculture using AI and IoT has matured from their nascent conceptual stage and reached the execution phase. The technical details of artificial intelligence, IoT, and challenges related to the adoption of these digital technologies are also discussed. This will help in understanding how digital technologies can be integrated into agriculture practices and pave the way for the implementation of AI and IoT-based solutions in the farms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2021.08.144,Conference Proceeding,IFAC-PapersOnLine,scopus,2021-01-01,sciencedirect,Fingerprint analysis for machine tool health condition monitoring,https://api.elsevier.com/content/abstract/scopus_id/85120666283,"One of the pillars of the smart factory concept within the Industry 4.0 paradigm is the capability to monitor the health conditions of production systems and their critical components in a continuous and effective way. This could be enabled through the implementation of innovative diagnosis, prognosis and predictive maintenance actions. A wide literature has been devoted to methodologies to monitor the manufacturing process and the tool wear. A parallel research field is dedicated to isolate the health condition of the machine tool from the production process and external source of noise. This study presents a novel solution for machine health condition monitoring based on the so-called “fingerprint” cycle approach. A fingerprint cycle is a pre-defined test cycle in no-load conditions, where the axes and the spindle are activated in a sequential order. Several signals are extracted from the machine controller to characterize the current health state of the machine. The method is suitable to separate drifts, trends and shifts in CNC signals caused by a change in machine tool health condition from any variation related to the cutting process and external factors. A machine learning method that combines Principal Component Analysis and statistical process monitoring allows one to quickly detect degraded conditions affecting one or multiple critical components. A real case study is presented to highlight the potentials and benefits provided by the proposed approach.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-323-85172-5.00018-6,Book,"Electronic Devices, Circuits, and Systems for Biomedical Applications: Challenges and Intelligent Approach",scopus,2021-01-01,sciencedirect,Health monitoring system,https://api.elsevier.com/content/abstract/scopus_id/85120586080,"Electronics have become an essential part of biomedicine. The urge for real-time health monitoring and disease detection at an early stage has created a rapid growth of the market for smart sensors. Biosensors have investigated the prospects of point of care (POC) applications for better management of healthcare, and efforts are being made to make these more efficient. Integrating with micro-electro-mechanical systems (MEMS) and nano-electro-mechanical systems (NEMS) technology has enabled biosensors to be automated and more precise, with higher accuracy data sensing systems. The application of biosensors with POC has increased research related to nanotechnology, advanced functional sensing materials, miniaturized sensing system development, AI, and the internet of things (IoT). Breath analysis is one such form for which biosensors have been used. Diabetes, Parkinson disease, urinary tract infections, lung cancer, kidney disease, pancreas infection, etc., can be detected through breath analysis. This chapter deals with a smart sensor system for diagnosis of diseases, precisely chronologic at an early stage. The sensor system is developing for detecting volatile organic compounds. Sensor arrays are deployed to collect and process electromagnetic or acoustic signals. Health monitoring systems provides a better perception of the patient’s condition, allowing doctors to make the correct diagnosis in real time and enhance curative procedure. IoT integrated with machine learning and artificial intelligence plays a vital role here.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.10.018,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Implementation of Indoor Positioning Methods: Virtual Hospital Case,https://api.elsevier.com/content/abstract/scopus_id/85120573245,"Indoor positioning systems (IPS) have great potential to define the location of objects with no GPS or other radionavigation data. Such systems include location estimation algorithms based on time series data from Wi-Fi, BLE, and other devices. Algorithms use to tracking location in real-time and obtain a trajectory close to the actual path. This, in turn, opens up opportunities for finding typical pathways, queues, and bottlenecks in various indoor places. IPS are often used in healthcare, and they are an essential part of the organization of internal processes in the case of a virtual hospital. In this research, we use iBeacons equipment because of its low cost and ease of use. However, the signals received at the objects have high noise, and the location estimation algorithms have an error that accumulates over time. This paper considered two ways to solve high noise: a probabilistic-based method and a neural network method. These algorithms have closer errors (2.11 - 0.96 m), but using the neural network method makes it possible to increase the performance of the indoor positioning algorithms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejor.2021.10.062,Journal,European Journal of Operational Research,scopus,2021-01-01,sciencedirect,An optimization model for planning testing and control strategies to limit the spread of a pandemic – The case of COVID-19,https://api.elsevier.com/content/abstract/scopus_id/85120159246,"The global health crisis caused by the coronavirus SARS-CoV-2 has highlighted the importance of efficient disease detection and control strategies for minimizing the number of infections and deaths in the population and halting the spread of the pandemic. Countries have shown different preparedness levels for promptly implementing disease detection strategies, via mass testing and isolation of identified cases, which led to a largely varying impact of the outbreak on the populations and health-care systems. In this paper, we propose a new pandemic resource allocation model for allocating limited disease detection and control resources, in particular testing capacities, in order to limit the spread of a pandemic. The proposed model is a novel epidemiological compartmental model formulated as a non-linear programming model that is suitable to address the inherent non-linearity of an infectious disease progression within the population. A number of novel features are implemented in the model to take into account important disease characteristics, such as asymptomatic infection and the distinct risk levels of infection within different segments of the population. Moreover, a method is proposed to estimate the vulnerability level of the different communities impacted by the pandemic and to explicitly consider equity in the resource allocation problem. The model is validated against real data for a case study of COVID-19 outbreak in France and our results provide various insights on the optimal testing intervention time and level, and the impact of the optimal allocation of testing resources on the spread of the disease among regions. The results confirm the significance of the proposed modeling framework for informing policymakers on the best preparedness strategies against future infectious disease outbreaks.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.09.145,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,"Architecture and organization of a Platform for diagnostics, therapy and post-covid complications using AI and mobile monitoring",https://api.elsevier.com/content/abstract/scopus_id/85116935586,"Infectious diseases accompanied mankind throughout its existence. However, in the 20th century, with the implementation od mass vaccination, this problem was partially forgotten. It reappeared at the end of the 2019 with the COVID-19 pandemic. The diseases are associated with high mortality, the main causes of which are: respiratory failure, acute respiratory distress syndrome, thrombotic complications, etc. As many centuries ago, the key to fighting a pandemic is to diagnose patients with infections as quickly as possible, isolate them, and implement treatment procedures. In this paper we propose a Platform supporting medics in the fight against epidemic. Unlike alternative systems, the proposed IT Platform will ultimately cover all areas of fighting against COVID-19, from the diagnosis of infection, through treatment, to rehabilitation of post-disease complications. Like most clinical information systems, the Platform is based on Artificial Intelligence, in particular Federated Learning. Also, unlike known solutions, it uses all available historical data of the patient’s health and information from real-time mobile diagnostics, using cellular communication and Internet of Things solutions. Such solutions could be helpful in fighting against any future mass infections.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.4103/jpi.jpi_100_20,Journal,Journal of Pathology Informatics,scopus,2021-01-01,sciencedirect,"Browser-based data annotation, active learning, and real-time distribution of artificial intelligence models: From tumor tissue microarrays to COVID-19 radiology",https://api.elsevier.com/content/abstract/scopus_id/85116859715,"Background: Artificial intelligence (AI) is fast becoming the tool of choice for scalable and reliable analysis of medical images. However, constraints in sharing medical data outside the institutional or geographical space, as well as difficulties in getting AI models and modeling platforms to work across different environments, have led to a “reproducibility crisis” in digital medicine. Methods: This study details the implementation of a web platform that can be used to mitigate these challenges by orchestrating a digital pathology AI pipeline, from raw data to model inference, entirely on the local machine. We discuss how this federated platform provides governed access to data by consuming the Application Program Interfaces exposed by cloud storage services, allows the addition of user-defined annotations, facilitates active learning for training models iteratively, and provides model inference computed directly in the web browser at practically zero cost. The latter is of particular relevance to clinical workflows because the code, including the AI model, travels to the user's data, which stays private to the governance domain where it was acquired. Results: We demonstrate that the web browser can be a means of democratizing AI and advancing data socialization in medical imaging backed by consumer-facing cloud infrastructure such as Box.com. As a case study, we test the accompanying platform end-to-end on a large dataset of digital breast cancer tissue microarray core images. We also showcase how it can be applied in contexts separate from digital pathology by applying it to a radiology dataset containing COVID-19 computed tomography images. Conclusions: The platform described in this report resolves the challenges to the findable, accessible, interoperable, reusable stewardship of data and AI models by integrating with cloud storage to maintain user-centric governance over the data. It also enables distributed, federated computation for AI inference over those data and proves the viability of client-side AI in medical imaging.
                  
                     Availability: The open-source application is publicly available at https://episphere.github.io/path, with a short video demonstration at https://youtu.be/z59jToy2TxE.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.csbj.2021.08.048,Journal,Computational and Structural Biotechnology Journal,scopus,2021-01-01,sciencedirect,Automated metabolic assignment: Semi-supervised learning in metabolic analysis employing two dimensional Nuclear Magnetic Resonance (NMR),https://api.elsevier.com/content/abstract/scopus_id/85115236580,"Metabolomics is an expanding field of medical diagnostics since many diseases cause metabolic reprogramming alteration. Additionally, the metabolic point of view offers an insight into the molecular mechanisms of diseases. Due to the complexity of metabolic assignment dependent on the 1D NMR spectral analysis, 2D NMR techniques are preferred because of spectral resolution issues. Thus, in this work, we introduce an automated metabolite identification and assignment from 1H-1H TOCSY (total correlation spectroscopy) using real breast cancer tissue. The new approach is based on customized and extended semi-supervised classifiers: KNFST, SVM, third (PC3) and fourth (PC4) degree polynomial. In our approach, metabolic assignment is based only on the vertical and horizontal frequencies of the metabolites in the 1H–1H TOCSY. KNFST and SVM show high performance (high accuracy and low mislabeling rate) in relatively low size of initially labeled training data. PC3 and PC4 classifiers showed lower accuracy and high mislabeling rates, and both classifiers fail to provide an acceptable accuracy at extremely low size (≤9% of the entire dataset) of initial training data. Additionally, semi-supervised classifiers were implemented to obtain a fully automatic procedure for signal assignment and deconvolution of TOCSY, which is a big step forward in NMR metabolic profiling. A set of 27 metabolites were deduced from the TOCSY, and their assignments agreed with the metabolites deduced from a 1D NMR spectrum of the same sample analyzed by conventional human-based methodology.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.07.059,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,PlantifyAI: A Novel Convolutional Neural Network Based Mobile Application for Efficient Crop Disease Detection and Treatment,https://api.elsevier.com/content/abstract/scopus_id/85115224350,"Crop diseases are a major threat to human food security. Around the world, more than 80% of agricultural production is generated by farmers, and over 50% of their yield is lost due to pests and pathogens, leading to mass disruption in food supply and a large number of hungry people. Identifying a disease correctly is a crucial first step for efficient treatment but remains difficult in many parts of the world due to limited access to agricultural experts and professional infrastructure. The purpose of this research was to create a free, easy-to-use, and widely accessible mobile application that efficiently and accurately, diagnoses 26 diseases of 14 crop species. Furthermore, this application provides treatment steps, common symptoms, and access to recommended curing products for each disease. The real-time crop disease diagnosis is based on a convolutional neural network (CNN) that was trained, validated, and tested on a dataset of 87,860 leaf images split into 38 classes. To design an optimal CNN, 16 different CNNs were designed and tested. MobileNetV2 using the Canny Edge Detection filter was chosen as it had the highest classification accuracy of 95.7% and an F1 score of 96.1. Multi-level testing and data analysis was conducted for this application, it has been verified to be functional in the real world through field testing at local garden centers. This application is a novel and accessible tool for crop disease management and can be deployed as a free service to farmers for ecologically sustainable production, overall increasing food security.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2021.03.109,Conference Proceeding,Materials Today: Proceedings,scopus,2021-01-01,sciencedirect,Real-time applications and novel manufacturing strategies of incremental forming: An industrial perspective,https://api.elsevier.com/content/abstract/scopus_id/85114180763,"Incremental Sheet-Metal Forming (ISMF) is a flexible and evolving metal forming technology for rapid free-form prototyping and small-batch metal components manufacturing. The end product has evolved by means of localized deformation in addition bi-axial stretching during that deforming tool squeezed on blank with predefined process variables. Owing to a unique process advantages and low manufacturing cost, its market requirement continuous enlargement and the process gradually transforms from prototyping to real-time manufacturing perspective. Over the preceding decades, ISMF technology has been adequately established in research and development, although it is less explored in the real-time industrial environment. The main intention of this exploration is to bring-forth insight into potential applications such as aviation, automotive, bio-medical, research and concept development through implementation of ISMF. Further, component evaluation performed to establish a convenient and feasible solution from deep-drawing and hydro-forming. For customized part forming, conventional forming process seems to be insufficient. Due to industrial transformation, dependent on cost-effectiveness, even prototyping and low-volume manufactured components relying on superior quality. Although, understanding the effect and influence of process variable, which needs the data analysis with implementing the optimization models and Artificial neural-network (ANN) model. These types of analysis majorly focus on monitoring and predict target values at each cycle and also reconfigure to optimistic or organize the iterative method for describing the appropriate process guidelines. Further, recent advances in ISMF process variants are explored, while looking at the benefits of ISMF for real-time part production. ISMF continues to mature into technology for production applications, while exploring the potential field to transform the way sheet components are fabricated in the new-era of digital manufacturing. This study will, in turn, enhance the capabilities of ISMF technology, which has grown significantly over the preceding decades, allowing technology adopters to innovate new design principle and achieve greater production flexibility.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2021.05.031,Conference Proceeding,Procedia CIRP,scopus,2021-01-01,sciencedirect,Artificial intelligence enhanced interaction in digital twin shop-floor,https://api.elsevier.com/content/abstract/scopus_id/85107885361,"As an enabling technology for smart manufacturing, digital twin has been widely applied in manufacturing shop-floor. A great deal of research focuses on the key issues in implementing digital twin shop-floor (DTS), including scheduling, production planning, fault diagnosis and prognostics. However, DTS puts forward higher requirements in terms of real-time interaction. Artificial intelligence (AI), as an effective approach to improve the intelligence of the physical shop-floor, provides a new method to meet the above requirements. In this paper, a framework of AI-enhanced DTS in interaction is proposed. AI-enhanced DTS improves the real-time interaction through predictive control. The implementation mechanism of AI-enhanced interaction in DTS is also presented in detail. Enabling technologies for interaction in DTS are introduced at last.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.nicl.2021.102707,Journal,NeuroImage: Clinical,scopus,2021-01-01,sciencedirect,icobrain ms 5.1: Combining unsupervised and supervised approaches for improving the detection of multiple sclerosis lesions,https://api.elsevier.com/content/abstract/scopus_id/85107640291,"Multiple sclerosis (MS) is a chronic autoimmune, inflammatory neurological disease of the central nervous system. Its diagnosis nowadays commonly includes performing an MRI scan, as it is the most sensitive imaging test for MS. MS plaques are commonly identified from fluid-attenuated inversion recovery (FLAIR) images as hyperintense regions that are highly varying in terms of their shapes, sizes and locations, and are routinely classified in accordance to the McDonald criteria. Recent years have seen an increase in works that aimed at development of various semi-automatic and automatic methods for detection, segmentation and classification of MS plaques. In this paper, we present an automatic combined method, based on two pipelines: a traditional unsupervised machine learning technique and a deep-learning attention-gate 3D U-net network. The deep-learning network is specifically trained to address the weaker points of the traditional approach, namely difficulties in segmenting infratentorial and juxtacortical plaques in real-world clinical MRIs. It was trained and validated on a multi-center multi-scanner dataset that contains 159 cases, each with T1 weighted (T1w) and FLAIR images, as well as manual delineations of the MS plaques, segmented and validated by a panel of raters. The detection rate was quantified using lesion-wise Dice score. A simple label fusion is implemented to combine the output segmentations of the two pipelines. This combined method improves the detection of infratentorial and juxtacortical lesions by 14% and 31% respectively, in comparison to the unsupervised machine learning pipeline that was used as a performance assessment baseline.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.03.025,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Lightweight photoplethysmography quality assessment for real-time IoT-based health monitoring using unsupervised anomaly detection,https://api.elsevier.com/content/abstract/scopus_id/85106733954,"Real-time remote health monitoring is dramatically growing, revolutionizing healthcare delivery and outcome in everyday settings. Such remote services enable monitoring individuals anywhere and anytime, allowing diseases early detection and prevention. Photoplethysmography (PPG) is a non-invasive and convenient technique that enables tracking vital signs such as heart rate, heart rate variability, respiration rate, and blood oxygen saturation. PPG is broadly used in various clinical and commercial wearable devices, as it is easy-to-implement and low-cost. However, the technique is highly susceptible to motion artifacts and environmental noises, which distort the collected signals. Therefore, the signal quality needs to be investigated, and unreliable signals should be discarded. In the literature, rule-based and machine learning-based PPG quality assessment methods have been investigated in several studies. However, the rule-based methods are mostly inaccurate in remote health monitoring, where users engage in different physical activities. The supervised machine learning-based methods –including deep learning–are also infeasible for real-time monitoring applications since they are slow and are dependent on a massive pool of annotated data to train the model. In this paper, we introduce a PPG quality assessment method, enabled by an elliptical envelope, which requires low computational resources. The method clusters the PPG signals into two groups as “reliable” and “unreliable.” We also investigate various features extracted from the PPG signals. Five features with the highest scoring values are selected to be fed to the elliptical envelope model. Moreover, we assess the performance of the proposed method in terms of accuracy and execution time, using data collected in free-living conditions via an Internet-of-Things-based health monitoring system enabled by smart wristbands. The method is evaluated in comparison to a state-of-the-art PPG quality assessment method. We also provide the model implemented in Python for the community to be used in their solutions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.03.070,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Using deep learning model for adapting and managing covid-19 pandemic crisis,https://api.elsevier.com/content/abstract/scopus_id/85106702825,"The purpose of current paper is to create a smart and effective tool for telemedicine to early detect and diagnose COVID-19 disease and therefore help to manage Pandemic Crisis (MCPC) in Sultanate of Oman, as a tool for future pandemic containment. In this paper, we used tools to create robust models in real-time to support Telemedicine, it is Machine Learning (ML), Deep Learning (DL), Convolutional Neural Networks using Tensorflow (CNN-TF), and CNN Deployment. These models will assist telemedicine, 1) developing Automated Medical Immediate Diagnosis service (AMID). 2) Analysis of Chest X-rays image (CXRs). 3) Simplifying Classification of confirmed cases according to its severity. 4) Overcoming the lack of experience, by improving the performance of medical diagnostics and providing recommendations to the medical staff. The results show that the best Regression among the five Regression models is Random Forest Regression. while the best classification among the eight classification models and Recurrent Neural Network using Tensorflow (RNNTF) is Random Forest classification, and the best Clustering model among two Clustering models is K-Means++. Furthermore, CNN-TF model was able to discriminate between those with positive cases Covid-19 and those with negative cases.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2021.100591,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,The diagnostic accuracy of Artificial Intelligence-Assisted CT imaging in COVID-19 disease: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85105522693,"Artificial intelligence (AI) systems have become critical in support of decision-making. This systematic review summarizes all the data currently available on the AI-assisted CT-Scan prediction accuracy for COVID-19. The ISI Web of Science, Cochrane Library, PubMed, Scopus, CINAHL, Science Direct, PROSPERO, and EMBASE were systematically searched. We used the revised Quality Assessment of Diagnostic Accuracy Studies (QUADAS-2) tool to assess all included studies' quality and potential bias. A hierarchical receiver-operating characteristic summary (HSROC) curve and a summary receiver operating characteristic (SROC) curve have been implemented. The area under the curve (AUC) was computed to determine the diagnostic accuracy. Finally, 36 studies (a total of 39,246 image data) were selected for inclusion into the final meta-analysis. The pooled sensitivity for AI was 0.90 (95% CI, 0.90–0.91), specificity was 0.91 (95% CI, 0.90–0.92) and the AUC was 0.96 (95% CI, 0.91–0.98). For deep learning (DL) method, the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.88 (95% CI, 0.87–0.88) and the AUC was 0.96 (95% CI, 0.93–0.97). In case of machine learning (ML), the pooled sensitivity was 0.90 (95% CI, 0.90–0.91), specificity was 0.95 (95% CI, 0.94–0.95) and the AUC was 0.97 (95% CI, 0.96–0.99). AI in COVID-19 patients is useful in identifying symptoms of lung involvement. More prospective real-time trials are required to confirm AI's role for high and quick COVID-19 diagnosis due to the possible selection bias and retrospective existence of currently available studies.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.02.012,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,The impact of the soft errors in convolutional neural network on GPUS: Alexnet as case study,https://api.elsevier.com/content/abstract/scopus_id/85105461752,"Convolutional Neural Networks (CNNs) have been increasingly deployed in many applications, including safety critical system such as healthcare and autonomous vehicles. Meanwhile, the vulnerability of CNN model to soft errors (e.g., caused by radiation induced) rapidly increases, thus reliability is crucial especially in real-time system. There are many traditional techniques for improve the reliability of the system, e.g., Triple Modular Redundancy, but these techniques incur high overheads, which makes them hard to deploy. In this paper, we experimentally evaluate the vulnerable parts of Alexnet mode (e.g., fault injector). Results show that FADD and LD are the top vulnerable instructions against soft errors for Alexnet model, both instructions generate at least 84% of injected faults as SDC errors. Thus, these the only parts of the Alexnet model that need to be hardened instead of using fully duplication solutions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2021.03.075,Conference Proceeding,Procedia Computer Science,scopus,2021-01-01,sciencedirect,Input doubling method based on SVR with RBF kernel in clinical practice: Focus on small data,https://api.elsevier.com/content/abstract/scopus_id/85104314419,"In recent years, machine-learning-based approaches have become of considerable interest to the efficient processing of short or limited data samples. Its so-called small data approach. This is due to the significant growth of new intellectual analysis tasks in various industries, which are characterized by limited historical data. These include Materials Science, Economics, Medicine, and so on. An effective processing of short datasets is especially acute in medicine. Insufficient number of vectors, significant gaps in the data collected during the supervision of patient’s treatment or rehabilitation, reduces the effectiveness or prevents effective intellectual analysis based on them. This paper presents a new approach to processing short medical data samples. The basis of the developed method is SVR with RBF kernel. The algorithmic implementation of the method in both operation modes is described. Experimental modeling on a real short data set (Trabecular bone data) is conducted. It contained only 35 observations. A comparison of the method with a number of existing machine learning methods is conducted. It is experimental established the highest accuracy of the method among those considered. The developed method has potential opportunities for wide application in various fields of medicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2021.100566,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,COVID-19 prediction using LSTM algorithm: GCC case study,https://api.elsevier.com/content/abstract/scopus_id/85104093246,"Coronavirus-19 (COVID-19) is the black swan of 2020. Still, the human response to restrain the virus is also creating massive ripples through different systems, such as health, economy, education, and tourism. This paper focuses on research and applying Artificial Intelligence (AI) algorithms to predict COVID-19 propagation using the available time-series data and study the effect of the quality of life, the number of tests performed, and the awareness of citizens on the virus in the Gulf Cooperation Council (GCC) countries at the Gulf area. So we focused on cases in the Kingdom of Saudi Arabia (KSA), United Arab of Emirates (UAE), Kuwait, Bahrain, Oman, and Qatar. For this aim, we accessed the time-series real-datasets collected from Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE). The timeline of our data is from January 22, 2020 to January 25, 2021. We have implemented the proposed model based on Long Short-Term Memory (LSTM) with ten hidden units (neurons) to predict COVID-19 confirmed and death cases. From the experimental results, we confirmed that KSA and Qatar would take the most extended period to recover from the COVID-19 virus, and the situation will be controllable in the second half of March 2021 in UAE, Kuwait, Oman, and Bahrain. Also, we calculated the root mean square error (RMSE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and death cases are 320.79 and 1.84, respectively, and both are related to Bahrain. While the worst values are 1768.35 and 21.78, respectively, and both are related to KSA. On the other hand, we also calculated the mean absolute relative errors (MARE) between the actual and predicted values of each country for confirmed and death cases, and we found that the best values for both confirmed and deaths cases are 37.76 and 0.30, and these are related to Kuwait and Qatar respectively. While the worst values are 71.45 and 1.33, respectively, and both are related to KSA.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2021.100564,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,"Machine learning approaches in COVID-19 diagnosis, mortality, and severity risk prediction: A review",https://api.elsevier.com/content/abstract/scopus_id/85104050206,"The existence of widespread COVID-19 infections has prompted worldwide efforts to control and manage the virus, and hopefully curb it completely. One important line of research is the use of machine learning (ML) to understand and fight COVID-19. This is currently an active research field. Although there are already many surveys in the literature, there is a need to keep up with the rapidly growing number of publications on COVID-19-related applications of ML. This paper presents a review of recent reports on ML algorithms used in relation to COVID-19. We focus on the potential of ML for two main applications: diagnosis of COVID-19 and prediction of mortality risk and severity, using readily available clinical and laboratory data. Aspects related to algorithm types, training data sets, and feature selection are discussed. As we cover work published between January 2020 and January 2021, a few key points have come to light. The bulk of the machine learning algorithms used in these two applications are supervised learning algorithms. The established models are yet to be used in real-world implementations, and much of the associated research is experimental. The diagnostic and prognostic features discovered by ML models are consistent with results presented in the medical literature. A limitation of the existing applications is the use of imbalanced data sets that are prone to selection bias.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2021.100540,Journal,Informatics in Medicine Unlocked,scopus,2021-01-01,sciencedirect,COVIDC: An expert system to diagnose COVID-19 and predict its severity using chest CT scans: Application in radiology,https://api.elsevier.com/content/abstract/scopus_id/85101761883,"Early diagnosis of Coronavirus disease 2019 (COVID-19) is significantly important, especially in the absence or inadequate provision of a specific vaccine, to stop the surge of this lethal infection by advising quarantine. This diagnosis is challenging as most of the patients having COVID-19 infection stay asymptomatic while others showing symptoms are hard to distinguish from patients having different respiratory infections such as severe flu and Pneumonia. Due to cost and time-consuming wet-lab diagnostic tests for COVID-19, there is an utmost requirement for some alternate, non-invasive, rapid, and discounted automatic screening system. A chest CT scan can effectively be used as an alternative modality to detect and diagnose the COVID-19 infection. In this study, we present an automatic COVID-19 diagnostic and severity prediction system called COVIDC (COVID-19 detection using CT scans) that uses deep feature maps from the chest CT scans for this purpose. Our newly proposed system not only detects COVID-19 but also predicts its severity by using a two-phase classification approach (COVID vs non-COVID, and COVID-19 severity) with deep feature maps and different shallow supervised classification algorithms such as SVMs and random forest to handle data scarcity. We performed a stringent COVIDC performance evaluation not only through 10-fold cross-validation and an external validation dataset but also in a real setting under the supervision of an experienced radiologist. In all the evaluation settings, COVIDC outperformed all the existing state-of-the-art methods designed to detect COVID-19 with an F1 score of 0.94 on the validation dataset and justified its use to diagnose COVID-19 effectively in the real setting by classifying correctly 9 out of 10 COVID-19 CT scans. We made COVIDC openly accessible through a cloud-based webserver and python code available at https://sites.google.com/view/wajidarshad/software and https://github.com/wajidarshad/covidc.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tige.2020.09.001,Journal,Techniques and Innovations in Gastrointestinal Endoscopy,scopus,2021-01-01,sciencedirect,Training for Advanced Endoscopic Imaging in Gastrointestinal Diseases,https://api.elsevier.com/content/abstract/scopus_id/85100680745,"Advanced endoscopic imaging is an emerging field in endoscopy practice, especially in optical diagnosis. Current technologies like virtual chromoendoscopy and small-field technologies allow visualization of subtle changes in mucosal and vascular patterns that are predictive of histology. The limiting factor in broadly utilizing these techniques is training and the need for reliable detection of these subtleties. This review provides the current evidence and limitations of training in advanced endoscopic imaging, and future directions of learning. A literature search was performed on PubMed and Medline through March 2020 with relevant keywords as advanced endoscopic imaging, training, and learning. References of relevant articles were screened for additional literature. Several didactic and web-based education programs are developed for training in virtual chromoendoscopy, autofluorescence imaging, confocal laser endomicroscopy, and volumetric laser endomicroscopy. Studies and post-hoc analysis on learning curves showed relatively steep learning curves after training, and web-based education seems to be as valuable as in-person didactic training for most techniques. However, consistent performance on expert level after training has not yet been demonstrated. Most advanced endoscopic imaging techniques are learned within a reasonable timeframe. Future efforts to enhance training and implementation of these techniques should focus on developing standardized and broadly incorporated training programs. The future role of artificial intelligence-assistance in advanced endoscopy and training has to be elucidated.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aei.2021.101246,Journal,Advanced Engineering Informatics,scopus,2021-01-01,sciencedirect,"A systematic literature review on intelligent automation: Aligning concepts from theory, practice, and future perspectives",https://api.elsevier.com/content/abstract/scopus_id/85099458674,"With the recent developments in robotic process automation (RPA) and artificial intelligence (AI), academics and industrial practitioners are now pursuing robust and adaptive decision making (DM) in real-life engineering applications and automated business workflows and processes to accommodate context awareness, adaptation to environment and customisation. The emerging research via RPA, AI and soft computing offers sophisticated decision analysis methods, data-driven DM and scenario analysis with regard to the consideration of decision choices and provides benefits in numerous engineering applications. The emerging intelligent automation (IA) – the combination of RPA, AI and soft computing – can further transcend traditional DM to achieve unprecedented levels of operational efficiency, decision quality and system reliability. RPA allows an intelligent agent to eliminate operational errors and mimic manual routine decisions, including rule-based, well-structured and repetitive decisions involving enormous data, in a digital system, while AI has the cognitive capabilities to emulate the actions of human behaviour and process unstructured data via machine learning, natural language processing and image processing. Insights from IA drive new opportunities in providing automated DM processes, fault diagnosis, knowledge elicitation and solutions under complex decision environments with the presence of context-aware data, uncertainty and customer preferences. This sophisticated review attempts to deliver the relevant research directions and applications from the selected literature to the readers and address the key contributions of the selected literature, IA’s benefits, implementation considerations, challenges and potential IA applications to foster the relevant research development in the domain.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tej.2020.106885,Journal,Electricity Journal,scopus,2021-01-01,sciencedirect,Machine learning methods for power line outage identification,https://api.elsevier.com/content/abstract/scopus_id/85098190289,"As Phasor Measurement Units (PMUs) become widely deployed, power systems can take advantage of the large amount of data provided by PMUs and leverage the advances in big data analytics to improve real-time monitoring and diagnosis. In this paper, we develop practical analytics that are not tightly coupled with the power flow analysis and state estimation, as these tasks require detailed and accurate information about the power system. We focus on power line outage identification, and use a machine learning framework to locate line outages. The same framework is used for the prediction of both single line and multiple line outages. We investigate a range of machine learning algorithms and feature extraction methods. The algorithms are designed to capture the essential dynamic characteristics of the power system when the topology change occurs abruptly. The proposed methods use only voltage phasor angles obtained by continuously monitoring the buses. We tested the proposed methods on their prediction performance under different levels of noise and missingness. It is shown that the proposed methods have better tolerance for noisy data and incomplete data when compared to the previous work that involves solving power flow equations or state estimation equations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cct.2020.106219,Journal,Contemporary Clinical Trials,scopus,2021-01-01,sciencedirect,Using digital technologies in clinical trials: Current and future applications,https://api.elsevier.com/content/abstract/scopus_id/85097798472,"In 2015, we provided an overview of the use of digital technologies in clinical trials, both as a methodological tool and as a mechanism to deliver interventions. At that time, there was limited guidance and limited use of digital technologies in clinical research. However, since then smartphones have become ubiquitous and digital health technologies have exploded. This paper provides an update to our earlier publication and an overview of how technology has been used in the past five years in clinical trials, providing examples with varying levels of technological integration and across different health conditions. Digital technology integration ranges from the incorporation of artificial intelligence in diagnostic devices to the use of real-world data (e.g., electronic health records) for study recruitment. Clinical trials can now be conducted entirely virtually, eliminating the need for in-person interaction. Much of the published research demonstrates how digital approaches can improve the design and implementation of clinical trials. While challenges remain, progress over the last five years is encouraging, and barriers can be overcome with careful planning.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.psychres.2020.113585,Journal,Psychiatry Research,scopus,2021-01-01,sciencedirect,"Digital Gaming Interventions in Psychiatry: Evidence, Applications and Challenges",https://api.elsevier.com/content/abstract/scopus_id/85097734134,"Human evolution has regularly intersected with technology. Digitalization of various services has brought a paradigm shift in consumerism. Treading this path, mental health practice has gradually moved to Digital Mental Health Interventions (DMHI), to improve service access and delivery. Applied games are one such innovation that has gained recent popularity in psychiatry. Based on the principles of gamification, they target psychosocial and cognitive domains, according to the deficits in various psychiatric disorders. They have been used to deliver cognitive behaviour therapy, cognitive training and rehabilitation, behavioural modification, social motivation, attention enhancement, and biofeedback. Research shows their utility in ADHD, autistic spectrum disorders, eating disorders, post-traumatic stress, impulse control disorders, depression, schizophrenia, dementia, and even healthy aging. Virtual reality and artificial intelligence have been used in conjunction with gaming interventions to improvise their scope. Even though these interventions hold promise in engagement, ease of use, reduction of stigma, and bridging the mental-health gap, there are pragmatic challenges, especially in developing countries. These include network quality, infrastructure, feasibility, socio-cultural adaptability, and potential for abuse. Keeping this in the background, this review summarizes the scope, promise, and evidence of digital gaming in psychiatric practice, and highlights the potential caveats in their implementation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2020.101883,Journal,Medical Image Analysis,scopus,2021-01-01,sciencedirect,Rigid and non-rigid motion artifact reduction in X-ray CT using attention module,https://api.elsevier.com/content/abstract/scopus_id/85095417175,"Motion artifacts are a major factor that can degrade the diagnostic performance of computed tomography (CT) images. In particular, the motion artifacts become considerably more severe when an imaging system requires a long scan time such as in dental CT or cone-beam CT (CBCT) applications, where patients generate rigid and non-rigid motions. To address this problem, we proposed a new real-time technique for motion artifacts reduction that utilizes a deep residual network with an attention module. Our attention module was designed to increase the model capacity by amplifying or attenuating the residual features according to their importance. We trained and evaluated the network by creating four benchmark datasets with rigid motions or with both rigid and non-rigid motions under a step-and-shoot fan-beam CT (FBCT) or a CBCT. Each dataset provided a set of motion-corrupted CT images and their ground-truth CT image pairs.
                  The strong modeling power of the proposed network model allowed us to successfully handle motion artifacts from the two CT systems under various motion scenarios in real-time. As a result, the proposed model demonstrated clear performance benefits. In addition, we compared our model with Wasserstein generative adversarial network (WGAN)-based models and a deep residual network (DRN)-based model, which are one of the most powerful techniques for CT denoising and natural RGB image deblurring, respectively. Based on the extensive analysis and comparisons using four benchmark datasets, we confirmed that our model outperformed the aforementioned competitors. Our benchmark datasets and implementation code are available at https://github.com/youngjun-ko/ct_mar_attention.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105779,Journal,Computer Methods and Programs in Biomedicine,scopus,2021-01-01,sciencedirect,A modular and scalable computational framework for interactive immersion into imaging data with a holographic augmented reality interface,https://api.elsevier.com/content/abstract/scopus_id/85092219783,"Background and objective
                  Modern imaging scanners produce an ever-growing body of 3D/4D multimodal data requiring image analytics and visualization of fused images, segmentations, and information. For the latter, augmented reality (AR) with head-mounted displays (HMDs) has shown potential. This work describes a framework (FI3D) for interactive immersion with data, integration of image processing and analytics, and rendering and fusion with an AR interface.
               
                  Methods
                  The FI3D was designed and endowed with modules to communicate with peripherals, including imaging scanners and HMDs, and to provide computational power for data acquisition and processing. The core of FI3D is deployed to a dedicated computational unit that performs the computationally demanding processes in real-time, and the HMD is used as a display output peripheral and an input peripheral through gestures and voice commands. FI3D offers user-made processing and analysis dedicated modules. Users can customize and optimize these for a particular workflow while incorporating current or future libraries.
               
                  Results
                  The FI3D framework was used to develop a workflow for processing, rendering, and visualization of CINE MRI cardiac sets. In this version, the data were loaded from a remote database, and the endocardium and epicardium of the left ventricle (LV) were segmented using a machine learning model and transmitted to a HoloLens HMD to be visualized in 4D. Performance results show that the system is capable of maintaining an image stream of one image per second with a resolution of 512 × 512. Also, it can modify visual properties of the holograms at 1 update per 16 milliseconds (62.5 Hz) while providing enough resources for the segmentation and surface reconstruction tasks without hindering the HMD.
               
                  Conclusions
                  We provide a system design and framework to be used as a foundation for medical applications that benefit from AR visualization, removing several technical challenges from the developmental pipeline.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.envres.2020.110141,Journal,Environmental Research,scopus,2021-01-01,sciencedirect,Assessing personal exposure using Agent Based Modelling informed by sensors technology,https://api.elsevier.com/content/abstract/scopus_id/85092078286,"Technology innovations create possibilities to capture exposure-related data at a great depth and breadth. Considering, though, the substantial hurdles involved in collecting individual data for whole populations, this study introduces a first approach of simulating human movement and interaction behaviour, using Agent Based Modelling (ABM).
                  A city scale ABM was developed for urban Thessaloniki, Greece that feeds into population-based exposure assessment without imposing prior bias, basing its estimations onto emerging properties of the behaviour of the computerised autonomous decision makers (agents) that compose the city-system. Population statistics, road and buildings networks data were transformed into human, road and building agents, respectively. Survey outputs with time-use patterns were associated with human agent rules, aiming to model representative to real-world behaviours. Moreover, time-geography of exposure data, derived from a local sensors campaign, was used to inform and enhance the model. As a prevalence of an agent-specific decision-making, virtual individuals of different sociodemographic backgrounds express different spatiotemporal behaviours and their trajectories are coupled with spatially resolved pollution levels.
                  Personal exposure was evaluated by assigning PM concentrations to human agents based on coordinates, type of location and intensity of encountered activities. Study results indicated that PM2.5 inhalation adjusted exposure between housemates can differ by 56.5% whereas exposure between two neighbours can vary by as much as 87%, due to the prevalence of different behaviours.
                  This study provides details of a new methodology that permits the cost-effective construction of refined time-activity diaries and daily exposure profiles, taking into account different microenvironments and sociodemographic characteristics. The proposed method leads to a refined exposure assessment model, addressing effectively vulnerable subgroups of population. It can be used for evaluating the probable impacts of different public health policies prior to implementation reducing, therefore, the time and expense required to identify efficient measures.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2020.107061,Journal,Mechanical Systems and Signal Processing,scopus,2021-01-01,sciencedirect,Recovering compressed images for automatic crack segmentation using generative models,https://api.elsevier.com/content/abstract/scopus_id/85086994715,"In a structural health monitoring (SHM) system that uses digital cameras to monitor cracks of structural surfaces, techniques for reliable and effective data compression are essential to ensure a stable and energy-efficient crack images transmission in wireless devices, e.g., drones and robots with high definition cameras installed. Compressive sensing (CS) is a signal processing technique that allows accurate recovery of a signal from a sampling rate much smaller than the limitation of the Nyquist sampling theorem. Different from the popular approach of simultaneously training encoder and decoder using neural network models, the CS theory ensures a high probability of accurate signal reconstruction based on random measurements that is shorter than the length of the original signal under a sparsity constraint. Such method is particularly useful when measurements are expensive, such as wireless sensing of civil structures, because its hardware implementation allows down sampling of signals during the sensing process. Hence, CS methods can achieve significant energy saving for the sensing devices. However, the strong assumption of the signals being highly sparse in an invertible space is relatively hard to guarantee for many real images, such as image of cracks. In this paper, we present a new approach of CS that replaces the sparsity regularization with a generative model that is able to effectively capture a low dimension representation of targeted images. We develop a recovery framework for automatic crack segmentation of compressed crack images based on this new CS method. We demonstrate the remarkable performance of our method that takes advantage of the strong capability of generative models to capture the necessary features required in the crack segmentation task even the backgrounds of the generated images are not well reconstructed. The superior performance of our recovery framework is illustrated by comparisons to three existing CS algorithms. Furthermore, we show that our framework is potentially extensible to other common problems in automatic crack segmentation, such as defect recovery from motion blurring and occlusion.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aprim.2020.04.014,Journal,Atencion Primaria,scopus,2021-01-01,sciencedirect,Artificial intelligence and its applications in medicine II: Current importance and practical applications,https://api.elsevier.com/content/abstract/scopus_id/85086736700,"La tecnología y la medicina siguen un camino paralelo durante las últimas décadas. Los avances tecnológicos van modificando el concepto de salud y las necesidades sanitarias están influyendo en el desarrollo de la tecnología.
                  La inteligencia artificial (IA) está formada por una serie de algoritmos lógicos suficientemente entrenados a partir de los cuales las máquinas son capaces de tomar decisiones para casos concretos a partir de normas generales.
                  Esta tecnología tiene aplicaciones en el diagnóstico y seguimiento de pacientes con una evaluación pronóstica individualizada de los mismos.
                  Además,si combinamos esta tecnología con la robótica, podemos crear máquinas inteligentes que hagan propuestas diagnósticas o que sean mucho más eficientes en su trabajo.
                  Por lo tanto la IA va a ser una tecnología presente en nuestro trabajo cotidiano a través de máquinas o programas informáticos, que de manera más o menos transparente para el usuario, van a ir siendo una realidad cotidiana en los procesos sanitarios. Los profesionales sanitarios tenemos que conocer esta tecnología, sus ventajas y sus inconvenientes, porque va a ser una parte integral de nuestro trabajo.
                  En estos dos artículos pretendemos dar una visión básica de esta tecnología adaptada a los médicos con un repaso de su historia y evolución, de sus aplicaciones reales en el momento actual y una visión de un futuro en el que la IA y el Big Data van a conformar la medicina personalizada que caracterizará al siglo XXI.
               
                  Technology and medicine follow a parallel path during the last decades. Technological advances are changing the concept of health and health needs are influencing the development of technology.
                  Artificial intelligence (AI) is made up of a series of sufficiently trained logical algorithms from which machines are capable of making decisions for specific cases based on general rules.
                  This technology has applications in the diagnosis and follow-up of patients with an individualized prognostic evaluation of them.
                  Furthermore, if we combine this technology with robotics, we can create intelligent machines that make more efficient diagnostic proposals in their work.
                  Therefore, AI is going to be a technology present in our daily work through machines or computer programs, which in a more or less transparent way for the user, will become a daily reality in health processes. Health professionals have to know this technology, its advantages and disadvantages, because it will be an integral part of our work.
                  In these two articles we intend to give a basic vision of this technology adapted to doctors with a review of its history and evolution, its real applications at the present time and a vision of a future in which AI and Big Data will shape the personalized medicine that will characterize the 21st century.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jclepro.2020.123365,Journal,Journal of Cleaner Production,scopus,2020-12-20,sciencedirect,An active preventive maintenance approach of complex equipment based on a novel product-service system operation mode,https://api.elsevier.com/content/abstract/scopus_id/85089891280,"The product-service system (PSS) business model has received increasing attention in equipment maintenance studies, as it has the potential to provide high value-added services for equipment users and construct ethical principles for equipment providers to support the implementation of circular economy. However, the PSS providers in equipment industry are facing many challenges when implementing Industry 4.0 technologies. One important challenge is how to fully collect and analyse the operational data of different equipment and diverse users in widely varied conditions to make the PSS providers create innovative equipment management services for their customers. To address this challenge, an active preventive maintenance approach for complex equipment is proposed. Firstly, a novel PSS operation mode was developed, where complex equipment is offered as a part of PSS and under exclusive control by the providers. Then, a solution of equipment preventive maintenance based on the operation mode was designed. A deep neural network was trained to predict the remaining effective life of the key components and thereby, it can pre-emptively assess the health status of equipment. Finally, a real-world industrial case of a leading CNC machine provider was developed to illustrate the feasibility and effectiveness of the proposed approach. Higher accuracy for predicting the remaining effective life was achieved, which resulted in predictive identification of the fault features, proactive implementation of the preventive maintenance, and reduction of the PSS providers’ maintenance costs and resource consumption. Consequently, the result shows that it can help PSS providers move towards more ethical and sustainable directions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpowsour.2020.229069,Journal,Journal of Power Sources,scopus,2020-12-15,sciencedirect,Cloud computing-based real-time global optimization of battery aging and energy consumption for plug-in hybrid electric vehicles,https://api.elsevier.com/content/abstract/scopus_id/85095795552,"This paper addresses two conflicts in the energy management strategy (EMS) for plug-in hybrid electric vehicles (PHEVs). One is the conflict between fuel economy optimization and battery state of health preservation, and the other is the conflict between global optimality and real-time capability. Inspired by the hierarchy structure of a computer, a two-layer internet-distributed EMS (ID-EMS) is developed using cloud computing and the internet of vehicles. The top layer in the cloud, which possesses powerful calculating capability, focuses on global optimality by utilizing machine learning technology and stochastic dynamic programming. The bottom layer on board, with limited computing power, employs a fuzzy controller to respond to real-time conditions while trying not to deviate too far from the global solution. Thus, a real-time global optimal EMS can be achieved. The ID-EMS is implemented on an internet-distributed vehicle-in-the-loop simulation platform whose in-loop vehicle makes it possible to test the ID-EMS in an on-road driving experiment. The ID-EMS outperforms a rule-based EMS in terms of overall cost by 6.8%, but it is surpassed by an acausal EMS with dynamic programming by 7%. These results suggest directions for the future development of EMS for PHEVs using cloud computing.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100145,Journal,Patterns,scopus,2020-12-11,sciencedirect,A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread,https://api.elsevier.com/content/abstract/scopus_id/85097386310,"We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100137,Journal,Patterns,scopus,2020-12-11,sciencedirect,Parallel Factor Analysis Enables Quantification and Identification of Highly Convolved Data-Independent-Acquired Protein Spectra,https://api.elsevier.com/content/abstract/scopus_id/85096522758,"High-throughput data-independent acquisition (DIA) is the method of choice for quantitative proteomics, combining the best practices of targeted and shotgun approaches. The resultant DIA spectra are, however, highly convolved and with no direct precursor-fragment correspondence, complicating biological sample analysis. Here, we present CANDIA (canonical decomposition of data-independent-acquired spectra), a GPU-powered unsupervised multiway factor analysis framework that deconvolves multispectral scans to individual analyte spectra, chromatographic profiles, and sample abundances, using parallel factor analysis. The deconvolved spectra can be annotated with traditional database search engines or used as high-quality input for de novo sequencing methods. We demonstrate that spectral libraries generated with CANDIA substantially reduce the false discovery rate underlying the validation of spectral quantification. CANDIA covers up to 33 times more total ion current than library-based approaches, which typically use less than 5% of total recorded ions, thus allowing quantification and identification of signals from unexplored DIA spectra.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jtbi.2020.110380,Journal,Journal of Theoretical Biology,scopus,2020-12-07,sciencedirect,Anticipating future learning affects current control decisions: A comparison between passive and active adaptive management in an epidemiological setting,https://api.elsevier.com/content/abstract/scopus_id/85089137762,"Infectious disease epidemics present a difficult task for policymakers, requiring the implementation of control strategies under significant time constraints and uncertainty. Mathematical models can be used to predict the outcome of control interventions, providing useful information to policymakers in the event of such an epidemic. However, these models suffer in the early stages of an outbreak from a lack of accurate, relevant information regarding the dynamics and spread of the disease and the efficacy of control. As such, recommendations provided by these models are often incorporated in an ad hoc fashion, as and when more reliable information becomes available. In this work, we show that such trial-and-error-type approaches to management, which do not formally take into account the resolution of uncertainty and how control actions affect this, can lead to sub-optimal management outcomes. We compare three approaches to managing a theoretical epidemic: a non-adaptive management (AM) approach that does not use real-time outbreak information to adapt control, a passive AM approach that incorporates real-time information if and when it becomes available, and an active AM approach that explicitly incorporates the future resolution of uncertainty through gathering real-time information into its initial recommendations. The structured framework of active AM encourages the specification of quantifiable objectives, models of system behaviour and possible control and monitoring actions, followed by an iterative learning and control phase that is able to employ complex control optimisations and resolve system uncertainty. The result is a management framework that is able to provide dynamic, long-term projections to help policymakers meet the objectives of management. We investigate in detail the effect of different methods of incorporating up-to-date outbreak information. We find that, even in a highly simplified system, the method of incorporating new data can lead to different results that may influence initial policy decisions, with an active AM approach to management providing better information that can lead to more desirable outcomes from an epidemic.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.prevetmed.2020.105199,Journal,Preventive Veterinary Medicine,scopus,2020-12-01,sciencedirect,Estimation of the sensitivity and specificity of four serum ELISA and one fecal PCR for diagnosis of paratuberculosis in adult dairy cattle in New Zealand using Bayesian latent class analysis,https://api.elsevier.com/content/abstract/scopus_id/85097155218,"In New Zealand, a new diagnostic approach for the control of paratuberculosis in mixed aged milking cows has been developed using a combination of ELISA and quantitative fecal PCR (f-qPCR). Our analysis was designed to evaluate performance of these individual tests in infected or infectious mixed aged cows across the prevalence of infection typically encountered on NZ dairy farms and calculate test accuracy when used as a screening test of serological ELISAs for four separate antigens read in parallel followed by a confirmatory quantitative f-qPCR test.
                  Data from a cross-sectional study of 20 moderate prevalence herds was combined with existing data from 2 low and 20 high prevalence herds forming a dataset of 3845 paired serum and fecal samples. Incidence of clinical Johne’s disease (JD) was used to classify herds into three prevalence categories. High (≥ 3% annual clinical JD for the last three years), moderate (<3 – 1%) and low (<1% incidence for at least the last five years). Positive tests were declared if> 50 ELISA units and f-qPCR at two cut-points (≥1 × 104 genomes/mL or >1 × 103 genomes/mL).
                  Fixed Bayesian latent class models at both f-qPCR cut-points, accounted for conditional independence and paired conditional dependence. Mixed models at both f-qPCR cut-points, using a different mechanism to account for conditional dependencies between tests were also implemented. Models (24 in number) were constructed using OpenBUGS. The aim was to identify Mycobacterium avium subsp. paratuberculosis (MAP) infected cows that met at least one of two criteria: shedding sufficient MAP in feces to be detected by f-qPCR or mounting a detectable MAP antibody response.
                  The best fit to the data was obtained by modelling pairwise dependencies between tests in a fixed model or by accounting for dependencies in a mixed model at a fecal cut-off of ≥1 × 104 genomes/mL. Test performance differed with prevalence, but models were robust to prior assumptions. For the fixed model, at a prevalence of 0.29 (95 % probability interval (PI) = 0.25−0.33), as a screening plus confirmatory f-qPCR, post-test probability for disease in a positive animal was 0.84 (95 %PI = 0.80−0.88) and 0.16 (95 %PI = 0.15−0.18) for disease in a test negative animal. In low prevalence herds (0.01(95 %PI = 0.00−0.04)) the equivalent figures were 0.84 (95 %PI = 0.08−0.92) and 0.00 (95 %PI = 0.00−0.02).
                  These results suggest this is a useful tool to control JD on dairy farms, particularly in herds with higher levels of infection, where the sampling and testing cost per animal is defrayed across more detected animals.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.psychres.2020.113558,Journal,Psychiatry Research,scopus,2020-12-01,sciencedirect,Accuracy of machine learning-based prediction of medication adherence in clinical research,https://api.elsevier.com/content/abstract/scopus_id/85096703550,"Medication non-adherence represents a significant barrier to treatment efficacy. Remote, real-time measurement of medication dosing can facilitate dynamic prediction of risk for medication non-adherence, which in-turn allows for proactive clinical intervention to optimize health outcomes. We examine the accuracy of dynamic prediction of non-adherence using data from remote real-time measurements of medication dosing. Participants across a large set of clinical trials (n = 4,182) were observed via a smartphone application that video records patients taking their prescribed medication. The patients’ primary diagnosis, demographics, and prior indication of observed adherence/non-adherence were utilized to predict (1) adherence rates ≥ 80% across the clinical trial, (2) adherence ≥ 80% for the subsequent week, and (3) adherence the subsequent day using machine learning-based classification models. Empirically observed adherence was demonstrated to be the strongest predictor of future adherence/non-adherence. Collectively, the classification models accurately predicted adherence across the trial (AUC = 0.83), the subsequent week (AUC = 0.87) and the subsequent day (AUC = 0.87). Real-time measurement of dosing can be utilized to dynamically predict medication adherence with high accuracy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmoldx.2020.09.004,Journal,Journal of Molecular Diagnostics,scopus,2020-12-01,sciencedirect,Development of a New Multiplex Real-Time RT-PCR Assay for Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) Detection,https://api.elsevier.com/content/abstract/scopus_id/85096229747,"This research describes the development of a new multiplex real-time RT-PCR test for detection of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), with primers designed to amplify a 108 bp target on the spike surface glycoprotein (S gene) and a hydrolysis TaqMan probe designed to specifically detect SARS-CoV-2. The limit of detection (LOD) and clinical performance of this new assay were evaluated. A LOD study with inactivated virus exhibited performance equal to the modified CDC assay, with a final LOD of 1301 ± 13 genome equivalents/mL for the Northwell Health Laboratories laboratory-developed test (NWHL LDT) versus 1249 ± 14 genome equivalents/mL for the modified CDC assay. In addition, a clinical evaluation with 270 nasopharyngeal swab specimens exhibited 98.5% positive percent agreement and 99.3% negative percent agreement compared with the modified CDC assay. The NWHL LDT multiplex design allows testing of 91 patients per plate, versus a maximum of 29 patients per plate on the modified CDC assay, providing the benefit of testing significantly more patients per run and saving reagents, during a time when both of these parameters are critical. The results show that the NWHL LDT multiplex assay performs as well as the modified CDC assay but is more efficient and cost-effective and can be used as a diagnostic assay and for epidemiologic surveillance and clinical management of SARS-CoV-2.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jngse.2020.103671,Journal,Journal of Natural Gas Science and Engineering,scopus,2020-12-01,sciencedirect,System-level prognosis and health monitoring modeling framework and software implementation for gas pipeline system integrity management,https://api.elsevier.com/content/abstract/scopus_id/85094628312,"Over the past few decades, recurrent pipeline failures have caused a major impact on human lives and property damage. Studies have shown the lack of a comprehensive, integrated, and accessible set of risk-informed integrity management models and tools for pipeline operators are the main reason behind those damages. To address this gap, this paper presents a system-level Prognosis and Health Monitoring (PHM) modeling framework for gas pipeline system integrity management to prevent or reduce the likelihood of failures. PHM modeling is a comprehensive approach that takes into consideration all possible failure modes of the pipeline under study. It leverages the advancement of sensor technology to stream field data in real-time to perform a dynamic system-level failure analysis based on Hybrid Causal Logic (HCL) and Dynamic Bayesian Networks (DBNs) predictive models to provide cost-effective and optimal mitigation actions such as sensor placement and maintenance schedule optimizations. The developed models are implemented into a software platform where the pipeline operators can observe the real-time and projected health state of the pipeline and the set of suggested actions to enhance the structural integrity of the pipeline system. The platform includes three main modules: Real-Time Monitoring, System-Level Reliability, and Optimal Mitigation Actions. From a safety perspective, the proposed comprehensive and dynamic pipeline health assessment framework either prevents the pipeline failures or reduces their likelihood by supporting pipeline operators in optimal decision-making and planning activities. To verify the performance of the proposed framework and its software implementation, it is applied to a case study of a corroded gas transmission pipeline and the results are discussed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cct.2020.106191,Journal,Contemporary Clinical Trials,scopus,2020-12-01,sciencedirect,Identification of undiagnosed atrial fibrillation patients using a machine learning risk prediction algorithm and diagnostic testing (PULsE-AI): Study protocol for a randomised controlled trial,https://api.elsevier.com/content/abstract/scopus_id/85093084431,"Atrial fibrillation (AF) is associated with an increased risk of stroke, enhanced stroke severity, and other comorbidities. However, AF is often asymptomatic, and frequently remains undiagnosed until complications occur. Current screening approaches for AF lack either cost-effectiveness or diagnostic sensitivity; thus, there is interest in tools that could be used for population screening. An AF risk prediction algorithm, developed using machine learning from a UK dataset of 2,994,837 patients, was found to be more effective than existing models at identifying patients at risk of AF. Therefore, the aim of the trial is to assess the effectiveness of this risk prediction algorithm combined with diagnostic testing for the identification of AF in a real-world primary care setting. Eligible participants (aged ≥30 years and without an existing AF diagnosis) registered at participating UK general practices will be randomised into intervention and control arms. Intervention arm participants identified at highest risk of developing AF (algorithm risk score ≥ 7.4%) will be invited for a 12‑lead electrocardiogram (ECG) followed by two-weeks of home-based ECG monitoring with a KardiaMobile device. Control arm participants will be used for comparison and will be managed routinely. The primary outcome is the number of AF diagnoses in the intervention arm compared with the control arm during the research window. If the trial is successful, there is potential for the risk prediction algorithm to be implemented throughout primary care for narrowing the population considered at highest risk for AF who could benefit from more intensive screening for AF.
                  Trial Registration: NCT04045639",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2020.113991,Journal,Journal of Virological Methods,scopus,2020-12-01,sciencedirect,A combined approach of MALDI-TOF mass spectrometry and multivariate analysis as a potential tool for the detection of SARS-CoV-2 virus in nasopharyngeal swabs,https://api.elsevier.com/content/abstract/scopus_id/85092484384,"Coronavirus disease 2019, known as COVID-19, is caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The early, sensitive and specific detection of SARS-CoV-2 virus is widely recognized as the critical point in responding to the ongoing outbreak. Currently, the diagnosis is based on molecular real time RT-PCR techniques, although their implementation is being threatened due to the extraordinary demand for supplies worldwide. That is why the development of alternative and / or complementary tests becomes so relevant. Here, we exploit the potential of mass spectrometry technology combined with machine learning algorithms, for the detection of COVID-19 positive and negative protein profiles directly from nasopharyngeal swabs samples. According to the preliminary results obtained, accuracy = 67.66 %, sensitivity = 61.76 %, specificity = 71.72 %, and although these parameters still need to be improved to be used as a screening technique, mass spectrometry-based methods coupled with multivariate analysis showed that it is an interesting tool that deserves to be explored as a complementary diagnostic approach due to the low cost and fast performance. However, further steps, such as the analysis of a large number of samples, should be taken in consideration to determine the applicability of the method developed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2020.106754,Journal,Applied Soft Computing Journal,scopus,2020-12-01,sciencedirect,Sentiment Analysis of COVID-19 tweets by Deep Learning Classifiers—A study to show how popularity is affecting accuracy in social media,https://api.elsevier.com/content/abstract/scopus_id/85092457474,"COVID-19 originally known as Corona VIrus Disease of 2019, has been declared as a pandemic by World Health Organization (WHO) on 11th March 2020. Unprecedented pressures have mounted on each country to make compelling requisites for controlling the population by assessing the cases and properly utilizing available resources. The rapid number of exponential cases globally has become the apprehension of panic, fear and anxiety among people. The mental and physical health of the global population is found to be directly proportional to this pandemic disease. The current situation has reported more than twenty four million people being tested positive worldwide as of 27th August, 2020. Therefore, it is the need of the hour to implement different measures to safeguard the countries by demystifying the pertinent facts and information. This paper aims to bring out the fact that tweets containing all handles related to COVID-19 and WHO have been unsuccessful in guiding people around this pandemic outbreak appositely. This study analyzes two types of tweets gathered during the pandemic times. In one case, around twenty three thousand most re-tweeted tweets within the time span from 1st Jan 2019 to 23rd March 2020 have been analyzed and observation says that the maximum number of the tweets portrays neutral or negative sentiments. On the other hand, a dataset containing 226,668 tweets collected within the time span between December 2019 and May 2020 have been analyzed which contrastingly show that there were a maximum number of positive and neutral tweets tweeted by netizens. The research demonstrates that though people have tweeted mostly positive regarding COVID-19, yet netizens were busy engrossed in re-tweeting the negative tweets and that no useful words could be found in WordCloud or computations using word frequency in tweets. The claims have been validated through a proposed model using deep learning classifiers with admissible accuracy up to 81%. Apart from these the authors have proposed the implementation of a Gaussian membership function based fuzzy rule base to correctly identify sentiments from tweets. The accuracy for the said model yields up to a permissible rate of 79%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.exppara.2020.108014,Journal,Experimental Parasitology,scopus,2020-12-01,sciencedirect,Analytical sensitivity of loopamp and quantitative real-time PCR on dried blood spots and their potential role in monitoring human African trypanosomiasis elimination,https://api.elsevier.com/content/abstract/scopus_id/85092023989,"The objective set by WHO to reach elimination of human African trypanosomiasis (HAT) as a public health problem by 2020 is being achieved. The next target is the interruption of gambiense-HAT transmission in humans by 2030. To monitor progress towards this target, in areas where specialized local HAT control capacities will disappear, is a major challenge. Test specimens should be easily collectable and safely transportable such as dried blood spots (DBS). Monitoring tests performed in regional reference centres should be reliable, cheap and allow analysis of large numbers of specimens in a high-throughput format. The aim of this study was to assess the analytical sensitivity of Loopamp, M18S quantitative real-time PCR (M18S qPCR) and TgsGP qPCR as molecular diagnostic tests for the presence of Trypanosoma brucei gambiense in DBS. The sensitivity of the Loopamp test, with a detection limit of 100 trypanosomes/mL, was in the range of parasitaemias commonly observed in HAT patients, while detection limits for M18S and TgsGP qPCR were respectively 1000 and 10,000 trypanosomes/mL. None of the tests was entirely suitable for high-throughput use and further development and implementation of sensitive high-throughput molecular tools for monitoring HAT elimination are needed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.arr.2020.101174,Journal,Ageing Research Reviews,scopus,2020-12-01,sciencedirect,"A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",https://api.elsevier.com/content/abstract/scopus_id/85091870837,"One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the ‘one child policy’ and the ‘empty-nest elderly’ phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of ‘exercising more, eating less’, while other anti-ageing molecules from molecular gerontologists could help to improve ‘healthspan’ in the elderly. Machine learning, ‘Big Data’, and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2020.113971,Journal,Journal of Virological Methods,scopus,2020-12-01,sciencedirect,"Development of a differential multiplex real-time PCR assay for porcine circovirus type 2 (PCV2) genotypes PCV2a, PCV2b and PCV2d",https://api.elsevier.com/content/abstract/scopus_id/85091116124,"A multiplex quantitative real-time polymerase chain reaction (mqPCR) assay was developed and validated for detection and differentiation of porcine circovirus type 2 (PCV2) genotypes, PCV2a, PCV2b and PCV2d. Single nucleotide polymorphism in primers or probes was deployed for different genotype detections, while conserved sequence in the 3' end of a primer and in the middle of a probe was used for the targeted genotype. In silico analysis of 2601 PCV2 ORF2 sequences showed that the predicted strain coverage of the assay was 93.4 % (409/438) for PCV2a, 95.1 % (1161/1221) for PCV2b and 93.6 % (882/942) for PCV2d strains. The PCR amplification efficiencies were 94.5 %, 100.2 %, and 99.2 % for PCV2a, PCV2b and PCV2d, respectively, with correlation coefficients >0.995 for all genotypes. The limits of detection (LOD) were 1.58 × 10−4 TCID50/mL for PCV2a, 5.62 × 10−4 TCID50/mL for PCV2b, and 3.16 × 10−3 TCID50/mL for PCV2d. Sanger sequencing of 74 randomly selected PCV2 positive clinical samples confirmed the genotypes of strains identified by the mqPCR. Validation with clinical samples co-positive for target and non-target pathogens demonstrated that the mqPCR assay specifically detected targeted viruses without cross reacting to each other or to other common porcine viruses.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.est.2020.101836,Journal,Journal of Energy Storage,scopus,2020-12-01,sciencedirect,Intelligent state of health estimation for lithium-ion battery pack based on big data analysis,https://api.elsevier.com/content/abstract/scopus_id/85090922628,"State of health (SOH) of in-vehicle lithium-ion batteries not only directly determines the acceleration performance and driving range of electric vehicles (EVs), but also reflects the residual value of the batteries. Especially, with the development of data acquisition and analysis technologies, using big data to realize on-line evaluation of battery SOH shows vital significance. In this paper, we propose an intelligent SOH estimation framework based on the real-world data of EVs collected by the big data platform. Defined by the more accessible detection, the health features are extracted from historical operating data. Then, the deep learning process is implemented in feedforward neural network driven by the degradation index. The estimation method is validated by the one-year monitoring dataset from 700 vehicles with different driving mode. The result shows that the proposed framework can effectively estimate SOH with the maximum relative error of 4.5% and describe the aging trend of battery pack based on big data platform.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.renene.2020.06.154,Journal,Renewable Energy,scopus,2020-12-01,sciencedirect,Spatio-temporal fusion neural network for multi-class fault diagnosis of wind turbines based on SCADA data,https://api.elsevier.com/content/abstract/scopus_id/85089269994,"Numerous sensors have been deployed in different locations in components of wind turbines to continuously monitor the health status of the turbine system and accordingly, generate a large volume of operation data by the supervisory control and data acquisition (SCADA) system. Naturally, these sensory data are multivariate time series with high spatio-temporal correlations. It is still challenging to effectively model such correlations and then enable an accurate fault diagnosis. To this end, we proposed a new spatio-temporal fusion neural network (STFNN) for wind turbine fault diagnosis. Specifically, a multi-kernel fusion convolution neural network (MKFCNN) with multiple convolution kernels of different sizes is first designed to extract multi-scale spatial correlations among different variables. Then, we adopt the long short-term memory (LSTM) to further learn the temporal dependence of the learned spatial features. The proposed STFNN model provides an end-to-end fault diagnosis way, which can directly learn spatio-temporal dependency from the raw SCADA data and give the fault diagnosis result. The effectiveness and superiority of the proposed method are evaluated on a generic wind turbine benchmark simulation dataset and a SCADA dataset from a real wind farm. Both experimental results have indicated that the proposed method outperformed several compared methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.06.072,Journal,Information Sciences,scopus,2020-12-01,sciencedirect,Self-learning based medical image representation for rigid real-time and multimodal slice-to-volume registration,https://api.elsevier.com/content/abstract/scopus_id/85088921051,"Recently, the convolutional neural network (CNN) based real-time slice-to-volume registration methods show great potential in related clinical applications. Generally, these methods are mostly employed in monomodal scenarios because they essentially rely on image intensities. To extend this strategy in more general computer-aided surgery scenarios, we present a self-learning based multimodal image representation model for real-time and multimodal slice-to-volume registration. Different from usual approaches, which utilize structural descriptors or translate the image from one modality to another, the proposed method exploits the highly similar information embedded in multimodal images through the two-channel self-learning strategy based on the CNN. In this way, a universal image representation network for any modality can be achieved. Specifically, different multimodal image pairs can be simultaneously fed into two shared-weight channels in the training phase. The self-learning strategy is concretely implemented by making the paired outputs similar and retaining the edge information of the originals. Subsequently, the image representation of any modality can be realized through one channel. Experiments on different datasets have been conducted to evaluate the proposed method, demonstrating its significant advantage in providing multimodal representation for real-time and multimodal slice-to-volume registration; moreover, it is observed to be superior to the state-of-the-art representation methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aprim.2020.04.013,Journal,Atencion Primaria,scopus,2020-12-01,sciencedirect,Artificial intelligence and its applications in medicine I: introductory background to AI and robotics,https://api.elsevier.com/content/abstract/scopus_id/85087789087,"La tecnología y la medicina siguen un camino paralelo durante las últimas décadas. Los avances tecnológicos van modificando el concepto de salud y las necesidades sanitarias están influyendo en el desarrollo de la tecnología.
                  La inteligencia artificial (IA) está formada por una serie de algoritmos lógicos suficientemente entrenados a partir de los cuales las máquinas son capaces de tomar decisiones para casos concretos a partir de normas generales.
                  Esta tecnología tiene aplicaciones en el diagnóstico y seguimiento de pacientes con una evaluación pronóstica individualizada de los mismos.
                  Además,si combinamos esta tecnología con la robótica, podemos crear máquinas inteligentes que hagan propuestas diagnósticas o que sean mucho más eficientes en su trabajo.
                  Por lo tanto la IA va a ser una tecnología presente en nuestro trabajo cotidiano a través de máquinas o programas informáticos, que de manera más o menos transparente para el usuario, van a ir siendo una realidad cotidiana en los procesos sanitarios. Los profesionales sanitarios tenemos que conocer esta tecnología, sus ventajas y sus inconvenientes, porque va a ser una parte integral de nuestro trabajo.
                  En estos dos artículos pretendemos dar una visión básica de esta tecnología adaptada a los médicos con un repaso de su historia y evolución, de sus aplicaciones reales en el momento actual y una visión de un futuro en el que la IA y el Big Data van a conformar la medicina personalizada que caracterizará al siglo XXI.
               
                  Technology and medicine follow a parallel path during the last decades. Technological advances are changing the concept of health and health needs are influencing the development of technology.
                  Artificial intelligence (AI) is made up of a series of sufficiently trained logical algorithms from which machines are capable of making decisions for specific cases based on general rules.
                  This technology has applications in the diagnosis and follow-up of patients with an individualized prognostic evaluation of them.
                  Furthermore, if we combine this technology with robotics, we can create intelligent machines that make more efficient diagnostic proposals in their work.
                  Therefore, AI is going to be a technology present in our daily work through machines or computer programs, which in a more or less transparent way for the user, will become a daily reality in health processes. Health professionals have to know this technology, its advantages and disadvantages, because it will be an integral part of our work.
                  In these two articles we intend to give a basic vision of this technology adapted to doctors with a review of its history and evolution, its real applications at the present time and a vision of a future in which AI and Big Data will shape the personalized medicine that will characterize the 21st century.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105616,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-12-01,sciencedirect,CLIN-IK-LINKS: A platform for the design and execution of clinical data transformation and reasoning workflows,https://api.elsevier.com/content/abstract/scopus_id/85087430673,"Background and Objective
                  Effective sharing and reuse of Electronic Health Records (EHR) requires technological solutions which deal with different representations and different models of data. This includes information models, domain models and, ideally, inference models, which enable clinical decision support based on a knowledge base and facts. Our goal is to develop a framework to support EHR interoperability based on transformation and reasoning services intended for clinical data and knowledge.
               
                  Methods
                  Our framework is based on workflows whose primary components are reusable mappings. Key features are an integrated representation, storage, and exploitation of different types of mappings for clinical data transformation purposes, as well as the support for the discovery of new workflows. The current framework supports mappings which take advantage of the best features of EHR standards and ontologies. Our proposal is based on our previous results and experience working with both technological infrastructures.
               
                  Results
                  We have implemented CLIN-IK-LINKS, a web-based platform that enables users to create, modify and delete mappings as well as to define and execute workflows. The platform has been applied in two use cases: semantic publishing of clinical laboratory test results; and implementation of two colorectal cancer screening protocols. Real data have been used in both use cases.
               
                  Conclusions
                  The CLIN-IK-LINKS platform allows the composition and execution of clinical data transformation workflows to convert EHR data into EHR and/or semantic web standards. Having proved its usefulness to implement clinical data transformation applications of interest, CLIN-IK-LINKS can be regarded as a valuable contribution to improve the semantic interoperability of EHR systems.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.joes.2020.03.003,Journal,Journal of Ocean Engineering and Science,scopus,2020-12-01,sciencedirect,Developing a predictive maintenance model for vessel machinery,https://api.elsevier.com/content/abstract/scopus_id/85086839612,"The aim of maintenance is to reduce the number of failures in equipment and to avoid breakdowns that may lead to disruptions during operations. The objective of this study is to initiate the development of a predictive maintenance solution in the shipping industry based on a computational artificial intelligence model using real-time monitoring data. The data analysed originates from the historical values from sensors measuring the vessel´s engines and compressors health and the software used to analyse these data was R. The results demonstrated key parameters held a stronger influence in the overall state of the components and proved in most cases strong correlations amongst sensor data from the same equipment. The results also showed a great potential to serve as inputs for developing a predictive model, yet further elements including failure modes identification, detection of potential failures and asset criticality are some of the issues required to define prior designing the algorithms and a solution based on artificial intelligence. A systematic approach using big data and machine learning as techniques to create predictive maintenance strategies is already creating disruption within the shipping industry, and maritime organizations need to consider how to implement these new technologies into their business operations and to improve the speed and accuracy in their maintenance decision making.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pcd.2020.05.005,Journal,Primary Care Diabetes,scopus,2020-12-01,sciencedirect,The prevalence of chronic kidney disease and screening of renal function in type 2 diabetic patients in Finnish primary healthcare,https://api.elsevier.com/content/abstract/scopus_id/85086126998,"Aims
                  To estimate the prevalence of chronic kidney disease (CKD) in patients with type 2 diabetes (T2D) in Finnish primary healthcare, and to evaluate the screening for CKD and the proportions of patients receiving antihyperglycemic and cardiovascular preventive medication.
               
                  Material and methods
                  T2D patients treated at the Rovaniemi Health Center, Finland during the years 2015–2019. Data included patient characteristics, blood pressure, HbA1c, lipid levels, kidney function and albuminuria, and medications prescribed. CKD was defined as estimated glomerular filtration rate (eGFR) <60 ml/min/1.72 m2 and/or albuminuria.
               
                  Results
                  The study population comprised of 5112 T2D patients with a mean (SD) age of 66.7 (13.0) years. Of these, 60.2% were screened for CKD with both eGFR and albuminuria, and 30.1% of these patients had CKD. The prevalence of moderately increased and severely increased albuminuria was 19.6% and 3.2%, respectively. A total of 57.0% of the study population received angiotensin-converting enzyme (ACE) inhibitors or angiotensin receptor blockers (ARB).
               
                  Conclusions
                  Screening for CKD with both recommended measures (eGFR and albuminuria) was insufficiently performed among this T2D population. Additionally, just over half of the study population had been prescribed ACE inhibitors or ARB. These results suggest an incongruity between the gold standard of diabetes care and real-world clinical practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1177/2472555220923332,Journal,SLAS Discovery,scopus,2020-12-01,sciencedirect,"Recommended Guidelines for Developing, Qualifying, and Implementing Complex In Vitro Models (CIVMs) for Drug Discovery",https://api.elsevier.com/content/abstract/scopus_id/85085937026,"The pharmaceutical industry is continuing to face high research and development (R&D) costs and low overall success rates of clinical compounds during drug development. There is an increasing demand for development and validation of healthy or disease-relevant and physiological human cellular models that can be implemented in early-stage discovery, thereby shifting attrition of future therapeutics to a point in discovery at which the costs are significantly lower. There needs to be a paradigm shift in the early drug discovery phase (which is lengthy and costly), away from simplistic cellular models that show an inability to effectively and efficiently reproduce healthy or human disease-relevant states to steer target and compound selection for safety, pharmacology, and efficacy questions. This perspective article covers the various stages of early drug discovery from target identification (ID) and validation to the hit/lead discovery phase, lead optimization, and preclinical safety. We outline key aspects that should be considered when developing, qualifying, and implementing complex in vitro models (CIVMs) during these phases, because criteria such as cell types (e.g., cell lines, primary cells, stem cells, and tissue), platform (e.g., spheroids, scaffolds or hydrogels, organoids, microphysiological systems, and bioprinting), throughput, automation, and single and multiplexing endpoints will vary. The article emphasizes the need to adequately qualify these CIVMs such that they are suitable for various applications (e.g., context of use) of drug discovery and translational research. The article ends looking to the future, in which there is an increase in combining computational modeling, artificial intelligence and machine learning (AI/ML), and CIVMs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jns.2020.117081,Journal,Journal of the Neurological Sciences,scopus,2020-11-15,sciencedirect,New technologies and Amyotrophic Lateral Sclerosis – Which step forward rushed by the COVID-19 pandemic?,https://api.elsevier.com/content/abstract/scopus_id/85090005531,"Amyotrophic Lateral Sclerosis (ALS) is a fast-progressive neurodegenerative disease leading to progressive physical immobility with usually normal or mild cognitive and/or behavioural involvement. Many patients are relatively young, instructed, sensitive to new technologies, and professionally active when developing the first symptoms. Older patients usually require more time, encouragement, reinforcement and a closer support but, nevertheless, selecting user-friendly devices, provided earlier in the course of the disease, and engaging motivated carers may overcome many technological barriers. ALS may be considered a model for neurodegenerative diseases to further develop and test new technologies. From multidisciplinary teleconsults to telemonitoring of the respiratory function, telemedicine has the potentiality to embrace other fields, including nutrition, physical mobility, and the interaction with the environment. Brain-computer interfaces and eye tracking expanded the field of augmentative and alternative communication in ALS but their potentialities go beyond communication, to cognition and robotics. Virtual reality and different forms of artificial intelligence present further interesting possibilities that deserve to be investigated. COVID-19 pandemic is an unprecedented opportunity to speed up the development and implementation of new technologies in clinical practice, improving the daily living of both ALS patients and carers.
                  The present work reviews the current technologies for ALS patients already in place or being under evaluation with published publications, prompted by the COVID-19 pandemic.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2020.103590,Journal,Journal of Biomedical Informatics,scopus,2020-11-01,sciencedirect,A virtual reality methodology for cardiopulmonary resuscitation training with and without a physical mannequin,https://api.elsevier.com/content/abstract/scopus_id/85092735575,"Background
                  Cardiopulmonary resuscitation (CPR) is an emergency procedure that can increase survival after a cardiac arrest. Performing CPR effectively requires both procedural knowledge and manual skills. Traditional CPR training methodology includes lessons led by instructors and supervised practice on mannequins, thus requiring considerable resources.
               
                  Objective
                  This paper proposes a new methodology for low-cost CPR training based on virtual reality (VR) with and without the addition of a physical mannequin. Moreover, it describes an experimental evaluation of the methodology that assessed gain in manual skills during training, transfer of procedural knowledge and manual skills in a final assessment, and changes in self-efficacy with three measurements over time (pre-training, post-training, and post-assessment).
               
                  Methods
                  We implemented a VR application that supports the proposed methodology, and can thus be used with or without a mannequin. The experimental evaluation involved 30 participants who tried CPR in VR twice, performing two repetitions of 30 chest compressions per trial. Half participants tried the VR application with the mannequin and half without it. Final assessment required all participants to perform CPR on the mannequin without the assistance of VR. To assess self-efficacy, participants filled in a questionnaire at the three times of measurement.
               
                  Results
                  Mixed-design ANOVAs showed effects of repetition, effects of group, or interaction between the two variables on manual skills assessed during training. In the final assessment, participants in both groups correctly remembered most of the steps of the procedure. ANOVAs revealed differences between the two groups only in pressure-related skills (better with mannequin) and in the number of wrong steps added to the procedure (better without mannequin). Mixed-design ANOVA showed a self-efficacy increase in both groups after training, which was maintained after final assessment.
               
                  Conclusions
                  The proposed VR methodology for CPR training has a positive effect on procedural knowledge, manual skills, and self-efficacy, with as well as without the physical mannequin. Trials on a mannequin are required to understand the correct pressure for chest compression. This supports the adoption of the proposed VR methodology to reduce instructor and mannequin time required to teach CPR to trainees.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.104038,Journal,Computers in Biology and Medicine,scopus,2020-11-01,sciencedirect,Generating wall shear stress for coronary artery in real-time using neural networks: Feasibility and initial results based on idealized models,https://api.elsevier.com/content/abstract/scopus_id/85092058026,"Computational fluid dynamics (CFD) and medical imaging can be integrated to derive some important hemodynamic parameters such as wall shear stress (WSS). However, CFD suffers from a relatively long computational time that usually varies from dozens of minutes to hours. Machine learning is a popular tool that has been applied to many fields, and it can predict outcomes fast and even instantaneously in most applications. This study aims to use machine learning as an alternative to CFD for generating hemodynamic parameters in real-time diagnosis during medical examinations. To perform the feasibility study, we used CFD to model the blood flow in 2000 idealized coronary arteries, and the calculated WSS values in these models were used as the dataset for training and testing. The preparation of the dataset was automated by scripts programmed in Python, and OpenFOAM was used as the CFD solver. We have explored multivariate linear regression, multi-layer perceptron, and convolutional neural network architectures to generate WSS values from coronary artery geometry directly without CFD. These architectures were implemented in TensorFlow 2.0. Our results showed that these algorithms were able to generate results in less than 1 s, proving its capability in real-time applications, in terms of computational time. Based on the accuracy, convolutional neural network outperformed the other architectures with a normalized mean absolute error of 2.5%. Although this study is based on idealized models, to the best of our knowledge, it is the first attempt to predict WSS in a stenosed coronary artery using machine learning approaches.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.nedt.2020.104592,Journal,Nurse Education Today,scopus,2020-11-01,sciencedirect,Communication skills training using virtual reality: A descriptive qualitative study,https://api.elsevier.com/content/abstract/scopus_id/85090743102,"Background
                  Modern medical pedagogical strategies are shifting toward the use of virtual patient simulations.
               
                  Objective
                  This study aims to examine students' users' attitudes and experiences and clinical facilitators' perspectives on student performances in the clinical setting post-virtual patient training.
               
                  Design
                  A descriptive qualitative study design was used.
               
                  Setting
                  Nursing faculty at a local university in Singapore.
               
                  Participants
                  24 nursing undergraduates and six clinical facilitators.
               
                  Methods
                  This study is a follow-up of an experimental study on the Virtual Counseling Application Using Artificial Intelligence (VCAAI). The study took place from the academic year 2017/2018 ended in November 2019. Focus group discussions and individual interviews were conducted. All interviews and focus group discussions were audiotaped, transcribed verbatim, and analyzed using thematic analysis.
               
                  Results
                  Two overarching themes (students' virtual patient user experience and clinical facilitators' evaluations of students' clinical communication skills) comprising six themes were generated. Themes under students' user experience included: 1) attitudes toward virtual patient training, 2) virtual patient's role in student development, and 3) enhanced features and implementation suggestions. Themes under clinical facilitators' evaluations included: 1) insights on students' communication skills and 2) approaches to improve communication skills. An overlapping theme titled ‘value of technology in teaching communication’ comprised of mutual feedback from both students and clinical facilitators. Early implementation, continued accessibility, enhancing realism and technological improvements to the VCAAI were listed as key areas for program improvement, while increased situational sensitivity and language training are recommended to further enhance students' communication skills.
               
                  Conclusion
                  The mixed attitudes toward virtual patient interactions and recognitions of the benefits of virtual patient simulations suggest the potential effectiveness of the use of virtual patients in teaching effective nursing communication skills. However, the lack of authenticity and other limitations need to be addressed before official implementations of such trainings with virtual patients to undergraduate nursing curricula.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mpdhp.2020.08.004,Journal,Diagnostic Histopathology,scopus,2020-11-01,sciencedirect,Artificial intelligence in pathology: an overview,https://api.elsevier.com/content/abstract/scopus_id/85090478810,"Artificial intelligence (AI) is at the forefront of modern technology and emerging uses within the healthcare sector are now being realised. Pathology will be a key area where the impact of AI will be felt. With more and more laboratories making the transition to digital pathology this will provide the key infrastructure in which to deploy these tools and their use will start to become a reality in diagnostic practice. The potential of AI in pathology is to create image analysis tools which could either be used for diagnostic support or to derive novel insights into disease biology, in addition to those achievable with a human observer. Some examples providing diagnostic support currently exist for a limited, but expanding number of applications, such as tumour detection, automated tumour grading, immunohistochemistry scoring, and predicting mutation status. There are a number of challenges to consider, not least the validation and regulatory framework for these tools. In this article, we set out an overview of AI in histopathology, discuss its potential workflow applications, and give key examples of the potential for AI in clinical practice. Considerations for the implementation of AI in practice are also explored.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ipm.2020.102340,Journal,Information Processing and Management,scopus,2020-11-01,sciencedirect,A topic modeling framework for spatio-temporal information management,https://api.elsevier.com/content/abstract/scopus_id/85087504158,"Real-time processing and learning of conflicting data, especially messages coming from different ideas, locations, and time, in a dynamic environment such as Twitter is a challenging task that recently gained lots of attention. This paper introduces a framework for managing, processing, analyzing, detecting, and tracking topics in streaming data. We propose a model selector procedure with a hybrid indicator to tackle the challenge of online topic detection. In this framework, we built an automatic data processing pipeline with two levels of cleaning. Regular and deep cleaning are applied using multiple sources of meta knowledge to enhance data quality. Deep learning and transfer learning techniques are used to classify health-related tweets, with high accuracy and improved F1-Score. In this system, we used visualization to have a better understanding of trending topics. To demonstrate the validity of this framework, we implemented and applied it to health-related twitter data from users originating in the USA over nine months. The results of this implementation show that this framework was able to detect and track the topics at a level comparable to manual annotation. To better explain the emerging and changing topics in various locations over time the result is graphically displayed on top of the United States map.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2020.107847,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Under the background of healthy China: Regulating the analysis of hybrid machine learning in sports activities to control chronic diseases,https://api.elsevier.com/content/abstract/scopus_id/85086573801,"One of the most important concerns in human life is concentrating on health. Major threats to human life are chronic diseases such as cancer and diabetes. China government mainly focusing on understanding the progression and spreading of chronic diseases over the population for allocating medical resources and designing a strategy in healthcare. Various conventional methods have been used for fetching chronic disease indicators in large scale based on the population health. But they are costly, not time effective and less accuracy in prediction. But this paper used Hybrid Predicting Model designed by incorporating the main features of the Gaussian Mixture Method and Collaborating Topic Modelling to increase the prediction accuracy. The proposed HPM method experimented on human mobility pattern dataset collected from the various metropolitan area of China. From the dataset, HPM predicts the rate of chronic disease presence and relative activity. GMM obtain the health condition whereas CTM obtains the data sparsity. The proposed hybrid prediction method is implemented in MATLAB software and experimented. Form the obtained results and comparing with the other existing methods, it is identified that the HPM outperforms in terms of prediction accuracy. HPM is evaluated using real-time check-in and chronic disease dataset in China cities. The proposed HPM method obtained 0.09% of the value which is high than the other baseline methods. From the obtained MSE and value, it is well clear the proposed HPM outperforms than the baseline methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2020.108052,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-11-01,sciencedirect,Deep learning-based prognostic approach for lithium-ion batteries with adaptive time-series prediction and on-line validation,https://api.elsevier.com/content/abstract/scopus_id/85086367941,"Prognostics for lithium-ion batteries is very critical in many industrial applications, and accurate prediction of battery state of health (SOH) is of great importance for health management. This paper proposes a novel deep learning-based prognostic method for lithium-ion batteries with on-line validation. An effective variant of recurrent neural network, i.e. long short-term memory structure, is used with variable input dimension, that facilitates network training with additional labeled samples. Adaptive time-series predictions are carried out for prognostics. An on-line validation method is further proposed for parameter optimization in real time based on the available system information, which allows for continuous model improvement. Experiments on a popular lithium-ion battery dataset are implemented to validate the effectiveness and superiority of the proposed method. The experimental results show the prognostic performances are promising both for the multi-steps-ahead predictions and long-horizon SOH estimations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jclepro.2020.121941,Journal,Journal of Cleaner Production,scopus,2020-10-20,sciencedirect,Artificial intelligence-enabled context-aware air quality prediction for smart cities,https://api.elsevier.com/content/abstract/scopus_id/85088373071,"Metropolitan areas around the world are experiencing a surge in air pollution levels due to different anthropogenic causes, making accurate air quality prediction a critical task for public health. Although many prediction systems have been researched and modelled, many of them have neglected the different effects that air pollution has on each individual citizen. Hence, we present a novel context prediction model that includes context-aware computing concepts to merge an accurate air pollution prediction algorithm (using Long Short-Term Memory Deep Neural Network) with information from both surrounding pollution sources (e.g., bushfire incidents, traffic volumes) and user’s health profile. This model is then integrated into a tool called My Air Quality Index (MyAQI), which is further implemented and evaluated in a real-life use case set up in Melbourne Urban Area (Victoria, Australia). Results obtained with MyAQI show both that (i) high precision levels are reached (90–96%) when forecasting air quality situations in four air quality monitoring stations, and (ii) the proposed model is highly adaptable to users’ individual health condition effects under the same airborne pollutant levels.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100108,Journal,Patterns,scopus,2020-10-09,sciencedirect,Using Machine Learning to Identify Adverse Drug Effects Posing Increased Risk to Women,https://api.elsevier.com/content/abstract/scopus_id/85102228908,"Adverse drug reactions are the fourth leading cause of death in the US. Although women take longer to metabolize medications and experience twice the risk of developing adverse reactions compared with men, these sex differences are not comprehensively understood. Real-world clinical data provide an opportunity to estimate safety effects in otherwise understudied populations, i.e., women. These data, however, are subject to confounding biases and correlated covariates. We present AwareDX, a pharmacovigilance algorithm that leverages advances in machine learning to predict sex risks. Our algorithm mitigates these biases and quantifies the differential risk of a drug causing an adverse event in either men or women. AwareDX demonstrates high precision during validation against clinical literature and pharmacogenetic mechanisms. We present a resource of 20,817 adverse drug effects posing sex-specific risks. AwareDX, and this resource, present an opportunity to minimize adverse events by tailoring drug prescription and dosage to sex.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.104004,Journal,Computers in Biology and Medicine,scopus,2020-10-01,sciencedirect,Scalable and energy efficient seizure detection based on direct use of compressively-sensed EEG data on an ultra low power multi-core architecture,https://api.elsevier.com/content/abstract/scopus_id/85091921119,"Extracting information from dense multi-channel neural sensors for accurate diagnosis of brain disorders necessitates computationally expensive and advanced signal processing approaches to analyze the massive volume of recorded data. Compressive Sensing (CS) is an efficient method for reducing the computational complexity and power consumption in the resource-constrained multi-site neural systems. However, reconstructing the signal from compressed measurements is computationally intensive, making it unsuitable for real-time applications such as seizure detection. In this paper, a seizure detection algorithm is proposed to overcome these limitations by circumventing the reconstruction phase and directly processing the compressively sampled EEG signals. The Lomb-Scargle Periodogram (LSP) is used to extract the spectral energy features of the compressed data. Performance of the seizure detector using non-linear support vector machine (SVM) classifier, tested on 24 patients of the CHB-MIT data-set for compression ratios (CR) of 1–64x, is 96–93%, 92-87%, 0.95–0.91, and <1 s for sensitivity, accuracy, the area under the curve, and latency, respectively. A power-efficient classification method based on the utilization of dual linear SVM classifiers is proposed. The proposed classification method based on the dual linear SVM classification achieved better classification performance compared to commonly used classifiers, such as K-nearest neighbor, random forest, artificial neural network, and linear SVM, while consuming low power in comparison to non-linear SVM kernels. The hardware-optimized implementation of this algorithm is proposed on a low-power multi-core SoC for near-sensor data analytics: Mr. Wolf. Optimized implementation of this algorithm on Mr. Wolf platform leads to detecting a seizure with an energy budget of 18.4 μJ and 3.9 μJ for a compression ratio of 24x using non-linear SVM classifier and the dual linear SVM based classification method, respectively.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103227,Journal,Microprocessors and Microsystems,scopus,2020-10-01,sciencedirect,Fog Computing-inspired Smart Home Framework for Predictive Veterinary Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85089574391,"Domestic Pet Care has been an important domain in the healthcare industry. In the presented study, a comprehensive framework of the Smart VetCare system for the health monitoring of domestic pets has been presented. The work is focused on the remote surveillance of domestic animals’ health conditions inside the home environment using IoMT Technology. Specifically, pet health is analyzed for vulnerability in the ambient home environment and ubiquitous activities over a fog computing platform of FogBus. Furthermore, a temporal data granule is formulated and the Probability of Health Vulnerability (PoHV) is defined for determining the health severity of the animal. Additionally, the Temporal Sensitivity Measure (TSM) is defined for real-time pet healthcare analysis, which is visualized using the Self Organized Mapping (SOM) Technique. For validation purposes, the framework is deployed in the smart home environment using 12 IoMT WiSense Nodes and Health Sensor belt for monitoring a domestic dog of American Bully breed over the dynamic resource management platform of FogBus and iFogSim simulator. Based on the comparison with numerous state-of-the-art techniques, the proposed framework can register a better precision value (94.78%), accuracy value (95.38%), sensitivity value (93.71%), and f-measure value (94.41%).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ohx.2020.e00131,Journal,HardwareX,scopus,2020-10-01,sciencedirect,Partially RepRapable automated open source bag valve mask-based ventilator,https://api.elsevier.com/content/abstract/scopus_id/85089470505,"This study describes the development of a simple and easy-to-build portable automated bag valve mask (BVM) compression system, which, during acute shortages and supply chain disruptions can serve as a temporary emergency ventilator. The resuscitation system is based on the Arduino controller with a real-time operating system installed on a largely RepRap 3-D printable parametric component-based structure. The cost of the materials for the system is under $170, which makes it affordable for replication by makers around the world. The device provides a controlled breathing mode with tidal volumes from 100 to 800 mL, breathing rates from 5 to 40 breaths/minute, and inspiratory-to-expiratory ratio from 1:1 to 1:4. The system is designed for reliability and scalability of measurement circuits through the use of the serial peripheral interface and has the ability to connect additional hardware due to the object-oriented algorithmic approach. Experimental results after testing on an artificial lung for peak inspiratory pressure (PIP), respiratory rate (RR), positive end-expiratory pressure (PEEP), tidal volume, proximal pressure, and lung pressure demonstrate repeatability and accuracy exceeding human capabilities in BVM-based manual ventilation. Future work is necessary to further develop and test the system to make it acceptable for deployment outside of emergencies such as with COVID-19 pandemic in clinical environments, however, the nature of the design is such that desired features are relatively easy to add using protocols and parametric design files provided.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.berh.2020.101559,Journal,Best Practice and Research: Clinical Rheumatology,scopus,2020-10-01,sciencedirect,Innovations to improve access to musculoskeletal care,https://api.elsevier.com/content/abstract/scopus_id/85088788188,"Innovation is a form of realising a new way of doing something, often ignoring traditional wisdom, in order to meet new challenges. Globally, particularly in emerging economies, the high burden of musculoskeletal conditions and their contribution to multimorbidity continue to rise, as does the gap for services to deliver essential care. There is a growing need to find solutions to this challenge and deliver person-centred and integrated care, wherein empowering patients with the capacity for self-management is critical. Whilst there is an abundance of information available online to support consumer education, the number of sources for credible medical information is diluted by uninformed anecdotal social media solutions. Even with the provision of high-quality information, behavioural change does not necessarily follow, and more robust educational approaches are required.
                  In this chapter, we examine innovation, its management and the strategic directions required to improve musculoskeletal healthcare at macro (policy), meso (service delivery) and micro (clinical practice) levels. We discuss the critical role of consumer agency (patients and their families/carers) in driving innovation and the need to leverage this through empowerment by education.
                  We provide a snapshot of real-world examples of innovative practices including capacity building in consumer and interprofessional musculoskeletal education and practice; recommendations to transform the access and delivery of integrated, person-centred care; and initiatives in musculoskeletal care and implementation of models of care, enabled by digital health solutions including telehealth, remote monitoring, artificial intelligence, blockchain technology and big data. We provide emerging evidence for how innovation can support systems' strengthening and build capacity to support improved access to ‘right’ musculoskeletal care, and explore some of the ways to best manage innovations.
                  We conclude with recommended systematic steps to establish required leadership, collaboration, research, networking, dissemination, implementation and evaluation of future innovations in musculoskeletal health and care.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jobcr.2020.07.015,Journal,Journal of Oral Biology and Craniofacial Research,scopus,2020-10-01,sciencedirect,Present and future of artificial intelligence in dentistry,https://api.elsevier.com/content/abstract/scopus_id/85088647471,"The last decennary has marked as the breakthrough in the advancement of technology with evolution of artificial intelligence, which is rapidly gaining the attention of researchers across the globe. Every field opted artificial intelligence with huge enthusiasm and so the field of dental science is no exception. With huge increases in patient documented information and data this is the need of the hour to use intelligent software to compile and save this data. From the basic step of taking a patient's history to data processing and then to extract the information from the data for diagnosis, artificial intelligence has many applications in dental and medical science. While in no case artificial intelligence can replace the role of a dental surgeon but it is important to be acquainted with the scope to amalgamate this advancement of technology in future for betterment of dental practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.revmed.2020.04.012,Journal,Revue de Medecine Interne,scopus,2020-10-01,sciencedirect,Evaluation of the use of a simulation software in the learning of cardiopulmonary auscultation in undergraduate medical students,https://api.elsevier.com/content/abstract/scopus_id/85087753992,"Introduction
                  Medsounds™ software allows to create an auscultation learning platform, by providing real pre-recorded cardiopulmonary sounds on virtual chests. The study aimed at comparing the skills in cardiopulmonary auscultation between students who benefited from this platform and students who did not have access to it.
               
                  Methods
                  A controlled trial was conducted with 2nd year medical students randomised into three groups. Groups A, B and C received 10 h of cardiopulmonary clinical training. In addition, group B benefited from an online access to the educative platform, and group C had a demonstration of the platform during their clinical training, then an online access. The main outcome was a 3-point multiple-choice questionnaire based on 2 original case vignettes about the description of cardiopulmonary sounds. The secondary outcome was the faculty exam on high-fidelity cardiopulmonary simulator.
               
                  Results
                  Groups A and B included 127 students, and group C 117. Students in group C had a significantly higher score than those in group A (1.72/3 versus 1.48/3; p = 0.02), without difference between the groups B and C. Students who actually had a demonstration of the platform and used it at home had a higher score than those who did not use it (1.87 versus 1.51; p = 0.01). Students who had a demonstration of the platform before using it performed a better pulmonary examination on high-fidelity simulators.
               
                  Conclusion
                  The supervised use of an online auscultation simulation software in addition to the traditional clinical training seems to improve the auscultation performances of undergraduated medical students.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105635,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,Data preprocessing for heart disease classification: A systematic literature review.,https://api.elsevier.com/content/abstract/scopus_id/85087500300,"Context
                  Early detection of heart disease is an important challenge since 17.3 million people yearly lose their lives due to heart diseases. Besides, any error in diagnosis of cardiac disease can be dangerous and risks an individual's life. Accurate diagnosis is therefore critical in cardiology. Data Mining (DM) classification techniques have been used to diagnosis heart diseases but still limited by some challenges of data quality such as inconsistencies, noise, missing data, outliers, high dimensionality and imbalanced data. Data preprocessing (DP) techniques were therefore used to prepare data with the goal of improving the performance of heart disease DM based prediction systems.
               
                  Objective
                  The purpose of this study is to review and summarize the current evidence on the use of preprocessing techniques in heart disease classification as regards: (1) the DP tasks and techniques most frequently used, (2) the impact of DP tasks and techniques on the performance of classification in cardiology, (3) the overall performance of classifiers when using DP techniques, and (4) comparisons of different combinations classifier-preprocessing in terms of accuracy rate.
               
                  Method
                  A systematic literature review is carried out, by identifying and analyzing empirical studies on the application of data preprocessing in heart disease classification published in the period between January 2000 and June 2019. A total of 49 studies were therefore selected and analyzed according to the aforementioned criteria.
               
                  Results
                  The review results show that data reduction is the most used preprocessing task in cardiology, followed by data cleaning. In general, preprocessing either maintained or improved the performance of heart disease classifiers. Some combinations such as (ANN + PCA), (ANN + CHI) and (SVM + PCA) are promising terms of accuracy. However the deployment of these models in real-world diagnosis decision support systems is subject to several risks and limitations due to the lack of interpretation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105643,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,High accurate lightweight deep learning method for gesture recognition based on surface electromyography,https://api.elsevier.com/content/abstract/scopus_id/85087496227,"Background and objectives
                  Surface Electromyography (sEMG) is used mostly for neuromuscular diagnosis, assistive technology, physical rehabilitation, and human-computer interactions. Achieving a precise and lightweight method along with low latency for gesture recognition is still a real-life challenge, especially for rehabilitation and assistive robots. This work aims to introduce a highly accurate and lightweight deep learning method for gesture recognition.
               
                  Methods
                  High-density sEMG, unlike sparse sEMG, does not require accurate electrode placement and provides more physiological information. Then we apply high-density sEMG, which, according to previous studies, leads to sEMG images. In this study, we introduce the Sensor-Wise method, which has a higher capability to extract features compared to the sEMG image method due to its high compatibility with the nature of sEMG signals and the structure of convolutional networks.
               
                  Results
                  The proposed method, because of its optimal structure with only two hidden layers and its high compatibility, has shown no sign of overfitting and was able to reach an accuracy of almost 100% (99.99%) when it was evaluated by CapgMyo DB-a database through 96 electrodes. Using this method, even with 16 electrodes, we were able to reach an accuracy of 99.8%, which was higher than the accuracies reported in the previous studies. Additionally, the method was evaluated by the CSL-HDEMG database, where the accuracy reached 99.55%. Previous studies either introduced expensive computational methods with overfitting or reported lower accuracies compared to this study.
               
                  Conclusions
                  The Sensor- Wise method has high compatibility with the nature of sEMG signals and the structure of convolutional networks. The high accuracy and lightweight structure of this method with only two hidden layers make it a proper option for hardware implementation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2020.101757,Journal,Medical Image Analysis,scopus,2020-10-01,sciencedirect,Yottixel – An Image Search Engine for Large Archives of Histopathology Whole Slide Images,https://api.elsevier.com/content/abstract/scopus_id/85087273852,"With the emergence of digital pathology, searching for similar images in large archives has gained considerable attention. Image retrieval can provide pathologists with unprecedented access to the evidence embodied in already diagnosed and treated cases from the past. This paper proposes a search engine specialized for digital pathology, called Yottixel, a portmanteau for “one yotta pixel,” alluding to the big-data nature of histopathology images. The most impressive characteristic of Yottixel is its ability to represent whole slide images (WSIs) in a compact manner. Yottixel can perform millions of searches in real-time with a high search accuracy and low storage profile. Yottixel uses an intelligent indexing algorithm capable of representing WSIs with a mosaic of patches which are then converted into barcodes, called “Bunch of Barcodes” (BoB), the most prominent performance enabler of Yottixel. The performance of the prototype platform is qualitatively tested using 300 WSIs from the University of Pittsburgh Medical Center (UPMC) and 2,020 WSIs from The Cancer Genome Atlas Program (TCGA) provided by the National Cancer Institute. Both datasets amount to more than 4,000,000 patches of 1000 × 1000 pixels. We report three sets of experiments that show that Yottixel can accurately retrieve organs and malignancies, and its semantic ordering shows good agreement with the subjective evaluation of human observers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chaos.2020.110059,Journal,"Chaos, Solitons and Fractals",scopus,2020-10-01,sciencedirect,Applications of machine learning and artificial intelligence for Covid-19 (SARS-CoV-2) pandemic: A review,https://api.elsevier.com/content/abstract/scopus_id/85086902632,"Background and objective
                  During the recent global urgency, scientists, clinicians, and healthcare experts around the globe keep on searching for a new technology to support in tackling the Covid-19 pandemic. The evidence of Machine Learning (ML) and Artificial Intelligence (AI) application on the previous epidemic encourage researchers by giving a new angle to fight against the novel Coronavirus outbreak. This paper aims to comprehensively review the role of AI and ML as one significant method in the arena of screening, predicting, forecasting, contact tracing, and drug development for SARS-CoV-2 and its related epidemic.
               
                  Method
                  A selective assessment of information on the research article was executed on the databases related to the application of ML and AI technology on Covid-19. Rapid and critical analysis of the three crucial parameters, i.e., abstract, methodology, and the conclusion was done to relate to the model's possibilities for tackling the SARS-CoV-2 epidemic.
               
                  Result
                  This paper addresses on recent studies that apply ML and AI technology towards augmenting the researchers on multiple angles. It also addresses a few errors and challenges while using such algorithms in real-world problems. The paper also discusses suggestions conveying researchers on model design, medical experts, and policymakers in the current situation while tackling the Covid-19 pandemic and ahead.
               
                  Conclusion
                  The ongoing development in AI and ML has significantly improved treatment, medication, screening, prediction, forecasting, contact tracing, and drug/vaccine development process for the Covid-19 pandemic and reduce the human intervention in medical practice. However, most of the models are not deployed enough to show their real-world operation, but they are still up to the mark to tackle the SARS-CoV-2 epidemic.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105532,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-10-01,sciencedirect,COVID-19 identification in chest X-ray images on flat and hierarchical classification scenarios,https://api.elsevier.com/content/abstract/scopus_id/85085953358,"Background and Objective:The COVID-19 can cause severe pneumonia and is estimated to have a high impact on the healthcare system. Early diagnosis is crucial for correct treatment in order to possibly reduce the stress in the healthcare system. The standard image diagnosis tests for pneumonia are chest X-ray (CXR) and computed tomography (CT) scan. Although CT scan is the gold standard, CXR are still useful because it is cheaper, faster and more widespread. This study aims to identify pneumonia caused by COVID-19 from other types and also healthy lungs using only CXR images.
                  
                     Methods:In order to achieve the objectives, we have proposed a classification schema considering the following perspectives: i) a multi-class classification; ii) hierarchical classification, since pneumonia can be structured as a hierarchy. Given the natural data imbalance in this domain, we also proposed the use of resampling algorithms in the schema in order to re-balance the classes distribution. We observed that, texture is one of the main visual attributes of CXR images, our classification schema extract features using some well-known texture descriptors and also using a pre-trained CNN model. We also explored early and late fusion techniques in the schema in order to leverage the strength of multiple texture descriptors and base classifiers at once.
                  To evaluate the approach, we composed a database, named RYDLS-20, containing CXR images of pneumonia caused by different pathogens as well as CXR images of healthy lungs. The classes distribution follows a real-world scenario in which some pathogens are more common than others.
                  
                     Results:The proposed approach tested in RYDLS-20 achieved a macro-avg F1-Score of 0.65 using a multi-class approach and a F1-Score of 0.89 for the COVID-19 identification in the hierarchical classification scenario.
                  
                     Conclusions:As far as we know, the top identification rate obtained in this paper is the best nominal rate obtained for COVID-19 identification in an unbalanced environment with more than three classes. We must also highlight the novel proposed hierarchical classification approach for this task, which considers the types of pneumonia caused by the different pathogens and lead us to the best COVID-19 recognition rate obtained here.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmi.2020.02.006,Journal,Clinical Microbiology and Infection,scopus,2020-10-01,sciencedirect,Machine learning in the clinical microbiology laboratory: has the time come for routine practice?,https://api.elsevier.com/content/abstract/scopus_id/85081582683,"Background
                  Machine learning (ML) allows the analysis of complex and large data sets and has the potential to improve health care. The clinical microbiology laboratory, at the interface of clinical practice and diagnostics, is of special interest for the development of ML systems.
               
                  Aims
                  This narrative review aims to explore the current use of ML In clinical microbiology.
               
                  Sources
                  References for this review were identified through searches of MEDLINE/PubMed, EMBASE, Google Scholar, biorXiv, arXiV, ACM Digital Library and IEEE Xplore Digital Library up to November 2019.
               
                  Content
                  We found 97 ML systems aiming to assist clinical microbiologists. Overall, 82 ML systems (85%) targeted bacterial infections, 11 (11%) parasitic infections, nine (9%) viral infections and three (3%) fungal infections. Forty ML systems (41%) focused on microorganism detection, identification and quantification, 36 (37%) evaluated antimicrobial susceptibility, and 21 (22%) targeted the diagnosis, disease classification and prediction of clinical outcomes. The ML systems used very diverse data sources: 21 (22%) used genomic data of microorganisms, 19 (20%) microbiota data obtained by metagenomic sequencing, 19 (20%) analysed microscopic images, 17 (18%) spectroscopy data, eight (8%) targeted gene sequencing, six (6%) volatile organic compounds, four (4%) photographs of bacterial colonies, four (4%) transcriptome data, three (3%) protein structure, and three (3%) clinical data. Most systems used data from high-income countries (n = 71, 73%) but a significant number used data from low- and middle-income countries (n = 36, 37%). Performance measures were reported for the 97 ML systems, but no article described their use in clinical practice or reported impact on processes or clinical outcomes.
               
                  Implications
                  In clinical microbiology, ML has been used with various data sources and diverse practical applications. The evaluation and implementation processes represent the main gap in existing ML systems, requiring a focus on their interpretability and potential integration into real-world settings.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jaim.2018.02.140,Journal,Journal of Ayurveda and Integrative Medicine,scopus,2020-10-01,sciencedirect,Effect of seeds of Entada phaseoloides on chronic restrain stress in mice,https://api.elsevier.com/content/abstract/scopus_id/85059584549,"Background
                  
                     Entada phaseoloides is a well-known medicinal plant traditionally used in Ayurvedic medicine for centuries.
               
                  Objective
                  To evaluate the anti-stress activity of seeds of E. phaseoloides in endoplasmic reticulum stress during chronic restrain stress in mice, based on our preliminary screening.
               
                  Materials and Methods
                  Mice (n = 6/group) were restrained daily for 6 h in 50 ml polystyrene tubes for 28 days. Methanolic extract of E. phaseoloides (MEEP) (100 and 200 mg/kg, p.o.) and standard drug, imipramine (10 mg/kg i.p.) were administered daily 45 min prior to restrain from day 22–28. Then, forced swim test (FST) was performed to assess despair behavior. Lipid peroxidation (LPO) and antioxidant enzymes Reduced glutathione (GSH), Superoxide dismutase (SOD) were measured in the hippocampus of mice. 78 kDa Glucose-regulated Protein, 94 kDa Glucose-regulated Protein, C/EBP homologous protein, Caspase-12 expression were quantified by Real Time PCR.
               
                  Results
                  MEEP significantly reduced the immobility time in FST (P < 0.001). Significant reduction of LPO (P < 0.05) level and restored antioxidant enzymes viz. GSH (P < 0.001) and SOD towards vehicle control group were observed. Down-regulation of genes GRP 78, GRP 94 (P < 0.001), CHOP and Caspase-12 (P < 0.001) as compared to the chronic restrain stress group was evident, which were upregulated following treatment. Isolation of the active components of the seeds revealed the presence of Oleic acid (1), Entadamide A (2), Entadamide A-beta-d-glucopyranoside (3) and 1-O-protocatechuoyl-β-d-glucose.
               
                  Conclusion
                  MEEP altered endoplasmic reticulum stress in chronic restrain stressed mice; however, as an antidepressant it showed a weaker response.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2020.106178,Journal,Knowledge-Based Systems,scopus,2020-09-27,sciencedirect,Deep learning-based unsupervised representation clustering methodology for automatic nuclear reactor operating transient identification,https://api.elsevier.com/content/abstract/scopus_id/85087409980,"Transient identification of condition monitoring data in nuclear reactor is important for system health assessment. Conventionally, the operating transients are correlated with the pre-designed ones by human operators during operations. However, due to necessary conservatism and significant differences between the operating and pre-designed transients, it has been less effective to manually identify transients, that usually contribute to different system degradation modes. This paper proposes a deep learning-based unsupervised representation clustering method for automatic transient pattern recognition based on the on-site condition monitoring data. Sample entropy is used as indicator for transient extraction, and a pre-training stage is implemented using an auto-encoder architecture for learning high-level features. An iterative representation clustering algorithm is further proposed to enhance the clustering effects, where a novel distance metric learning strategy is integrated. Experiments on a real-world nuclear reactor condition monitoring dataset validate the effectiveness and superiority of the proposed method, which provides a promising tool for transient identification in the real industrial scenarios. This study offers a new perspective in exploring unlabeled data with deep learning, and the end-to-end implementation scheme facilitates applications in the real nuclear industry.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100083,Journal,Patterns,scopus,2020-09-11,sciencedirect,"The Veterans Affairs Precision Oncology Data Repository, a Clinical, Genomic, and Imaging Research Database",https://api.elsevier.com/content/abstract/scopus_id/85102968026,"The Veterans Affairs Precision Oncology Data Repository (VA-PODR) is a large, nationwide repository of de-identified data on patients diagnosed with cancer at the Department of Veterans Affairs (VA). Data include longitudinal clinical data from the VA's nationwide electronic health record system and the VA Central Cancer Registry, targeted tumor sequencing data, and medical imaging data including computed tomography (CT) scans and pathology slides. A subset of the repository is available at the Genomic Data Commons (GDC) and The Cancer Imaging Archive (TCIA), and the full repository is available through the Veterans Precision Oncology Data Commons (VPODC). By releasing this de-identified dataset, we aim to advance Veterans' health care through enabling translational research on the Veteran population by a wide variety of researchers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cjche.2020.06.015,Journal,Chinese Journal of Chemical Engineering,scopus,2020-09-01,sciencedirect,Deep learning technique for process fault detection and diagnosis in the presence of incomplete data,https://api.elsevier.com/content/abstract/scopus_id/85089986909,"In modern industrial processes, timely detection and diagnosis of process abnormalities are critical for monitoring process operations. Various fault detection and diagnosis (FDD) methods have been proposed and implemented, the performance of which, however, could be drastically influenced by the common presence of incomplete or missing data in real industrial scenarios. This paper presents a new FDD approach based on an incomplete data imputation technique for process fault recognition. It employs the modified stacked autoencoder, a deep learning structure, in the phase of incomplete data treatment, and classifies data representations rather than the imputed complete data in the phase of fault identification. A benchmark process, the Tennessee Eastman process, is employed to illustrate the effectiveness and applicability of the proposed method.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.103940,Journal,Computers in Biology and Medicine,scopus,2020-09-01,sciencedirect,Computer-Aided Diagnosis system for diagnosis of pulmonary emphysema using bio-inspired algorithms,https://api.elsevier.com/content/abstract/scopus_id/85089819166,"Pulmonary emphysema is a condition characterized by the destruction and permanent enlargement of the alveoli of the lungs. The destruction of gas-exchanging alveoli causes shortness of breath followed by a chronic cough and sputum production. A Computer-Aided Diagnosis (CAD) framework for diagnosing pulmonary emphysema from chest Computed Tomography (CT) slices has been designed and implemented in this study. The process of implementing the CAD framework includes segmenting the lung tissues and extracting the regions of interest (ROIs) using the Spatial Intuitionistic Fuzzy C-Means clustering algorithm. The ROIs that were considered in this work were emphysematous lesions — namely, centrilobular, paraseptal, and bullae that were labelled by an expert radiologist. The shape, texture, and run-length features were extracted from each ROI. A wrapper approach that employed four bio-inspired algorithms — namely, Moth–Flame Optimization (MFO), Firefly Optimization (FFO), Artificial Bee Colony Optimization, and Ant Colony Optimization — with the accuracy of the support vector machine classifier as the fitness function was used to select the optimal feature subset. The selected features of each bio-inspired algorithm were trained independently using the Extreme Learning Machine classifier based on the tenfold cross-validation technique. The framework was tested on real-time and public emphysema datasets to perform binary classification of lung CT slices of patients with and without the presence of emphysema. The framework that used MFO and FFO for feature selection produced superior results regarding accuracy, precision, recall, and specificity for the real-time dataset and the public dataset, respectively, when compared to the other bio-inspired algorithms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.prevetmed.2020.105101,Journal,Preventive Veterinary Medicine,scopus,2020-09-01,sciencedirect,Potential role of MicroRNA as a diagnostic tool in the detection of bovine mastitis,https://api.elsevier.com/content/abstract/scopus_id/85089492197,"Bovine mastitis is a major health problem that affects dairy cows and has a negative impact on milk production. The presence of microRNAs in biofluids, such as blood and milk, could play a pivotal role in the detection of bovine mastitis. The purpose of the current study was to determine the levels of microRNA gene expression in milk, in combination with other reported mastitis indicators, as a biomarker of bovine mastitis. Milk samples (n = 171) were obtained from 113 dairy cows with known disease status (i.e., healthy; n = 23 cows, subclinical mastitis; n = 45 cows, or clinical mastitis; n = 45 cows) and analyzed for the presence of MIR24-2, MIR29B-2, MIR146A, MIR148A, MIR155, MIR181A1, MIR184, and MIR223 expression using the real-time PCR (qPCR) method. The expression data were then utilized in the creation of receiver operator characteristic curves (ROC) and further analyzed by the machine learning (ML) methods. MIR29B-2, MIR146A, MIR148A, and MIR155 expression levels differed significantly among the three groups. These potential microRNA biomarkers of mastitis exhibited high sensitivity and specificity. Next, we applied ML algorithm, specifically, a decision tree (DT) model to predict the status of milk based on MIR29B-2 and MIR146A expression levels. The results suggested that MIR29B-2, when used in combination with the California mastitis test (CMT) and days in milk (DIM) data, was applicable for screening and classification of milk samples from cows as healthy, subclinical mastitis, or mastitis. MIR29B-2 appears to have sufficient discriminatory power to enable it to be utilized as a biomarker in cases where the status of a milk sample cannot be determined based on CMT results.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2020.107861,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-09-01,sciencedirect,Internet of things sensor assisted security and quality analysis for health care data sets using artificial intelligent based heuristic health management system,https://api.elsevier.com/content/abstract/scopus_id/85089438452,"The developments in the medical systems, especially in health care management systems, play a vital role in patients. The effective management of health records leads to an increase in the importance of the healthcare management system all over the world. A real-time health monitoring system is a key zone for the Internet of Things (IoT) sensor technology in human services using Big Data Analytics. The major challenge that has to do with the health care data sets is security and privacy. In this paper, an artificial intelligence-based heuristic health management system has been designed and developed. This system is exceptionally close to improve the security and privacy of the live datasets of patients and the association of medicinal services over its different viewpoints. These services include the capacity for specialists, experts, attendants, and staff to settle on better decisions faster. Moreover, security and quality of data by configuration should be a part of any IoT use case, task or arrangement. Utilizing IoT assisted artificial intelligent based heuristic health management system intends to improve and minimize the security risk on health care data sets with assisted IoT sensors. The experimental results show promising outcomes in terms of various performance factors. The system attains precision as 99.75%, error rate as 0.0646 and predicted positive condition rate as 98.46%, Informedness as 98.6% and accuracy as 99.66%. The system is implemented using the MATLAB program.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jocn.2020.04.125,Journal,Journal of Clinical Neuroscience,scopus,2020-09-01,sciencedirect,Tele-robotics and artificial-intelligence in stroke care,https://api.elsevier.com/content/abstract/scopus_id/85088965193,"In the last forty years, the field of medicine has experienced dramatic shifts in technology-enhanced surgical procedures – from its initial use in 1985 for neurosurgical biopsies to current implementation of systems such as magnetic-guided catheters for endovascular procedures. Systems such as the Niobe Magnetic Navigation system and CorPath GRX have allowed for utilization of a fully integrated surgical robotic systems for perioperative manipulation, as well as tele-controlled manipulation systems for telemedicine. These robotic systems hold tremendous potential for future implementation in cerebrovascular procedures, but lack of relevant clinical experience and uncharted ethical and legal territory for real-life tele-robotics have stalled their adoption for neurovascular surgery, and might present significant challenges for future development and widespread implementation. Yet, the promise that these technologies hold for dramatically improving the quality and accessibility of cerebrovascular procedures such as thrombectomy for acute stroke, drives the research and development of surgical robotics. These technologies, coupled with artificial intelligence (AI) capabilities such as machine learning, deep-learning, and outcome-based analyses and modifications, have the capability to uncover new dimensions within the realm of cerebrovascular surgery.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2020.102106,Journal,Biomedical Signal Processing and Control,scopus,2020-09-01,sciencedirect,FPGA-based real-time epileptic seizure classification using Artificial Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85088878293,"Epilepsy is a neurological disorder characterised by unusual brain activity widely known as seizure affecting 4-7% of the world's population. The diagnosis of this disorder is currently based on analysis of the electroencephalography (EEG) signals in the time-frequency domain. The analysis is performed applying various algorithms that yield high performance, however the challenge of effective real-time epilepsy diagnosis persists.
                  To address this, we have developed a Field Programmable Gate Array (FPGA) based solution for the classification of generalized and focal epileptic seizure types using a feed-forward multi-layer neural network architecture (MLP ANN).
                  The neural network algorithm is trained, validated and tested on 822 captured signals from Temple University Hospital Seizure Detection Corpus (TUH EEG Corpus) database. Inputs into the system were five main features obtained from EEG signals by time-frequency analysis followed by Continuous Wavelet Transform (CWT) and subsequent statistical analysis. Out of the total number of samples, 583 (70 %) of them were utilised during the system development in MATLAB and TensorFlow and 239 (30 %) samples were further used for subsequent testing of the model performance on the FPGA. Subsequently, the adequate parameters of the ANN model were determined by using k-Fold Cross-Validation. Finally, the best performing ANN model in terms of average validation data accuracy achieved during cross-validation was implemented on the FPGA for real-time seizure classification. The digital ANN solution was coded in Very High-Speed Integrated Circuit Hardware Description Language (VHDL) and tested on the FPGA using 30 % reaming data.
                  The results of this research demonstrate that epilepsy diagnosis with quite high accuracy (95.14 %) can be achieved with (5-12-3) MLP ANN implemented on FPGA. Also, the results show the steps towards appropriate implementation of ANN on the FPGA. These results can be utilised as the basis for the design of an application-specific integrated circuit (ASIC) allowing large serial production.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2020.101175,Journal,Pervasive and Mobile Computing,scopus,2020-09-01,sciencedirect,IoT-enabled Low Power Environment Monitoring System for prediction of PM2.5,https://api.elsevier.com/content/abstract/scopus_id/85086801095,"Air pollution is a major concern worldwide due to its significant impacts on the global environment and human health. The conventional instruments used by the air quality monitoring stations are costly, bulkier, time-consuming, and power-hungry. Furthermore, due to limited data availability and non-scalability, these stations cannot provide high spatial and temporal resolution in real-time. Although energy-efficient, wireless sensor network with the high spatio-temporal resolution is one of the potential solutions, real-time remote monitoring of all significant air quality parameters with low power consumption is challenging. To address this challenge, we propose internet of things-enabled low power environment monitoring system for real-time monitoring of ten significant air quality parameters. Moreover, the proposed system enables remote monitoring and storage of data for future analysis. Unlike earlier research work, further expansion of the proposed system is easily possible, as the proposed Wireless Sensor Node (WSN) can interface a higher number of sensors with the same number of interfacing pins. We did an in-depth analysis through calibration, experiments, and deployment which confirms the power efficiency, flexibility, reliability and accuracy of the proposed system. Results illustrate the low power consumption of 25.67mW, data transmission reliability of 97.4%, and battery life of approximately 31 months for a sampling time of 60 min. The study of the correlation between Particulate Matter 2.5 (PM2.5) and other pollutants is performed using Central Pollution Control Board data of 41 months. The initial study related to correlation is performed for the future work of developing a prediction model of PM2.5 using highly correlated pollutants. The future approach for developing a prediction model in the form of analytical equations with the help of artificial neural network is demonstrated. This approach can be implemented using the proposed WSN or low-cost processing tool for evaluating PM2.5 from precursor gases. Therefore, this approach can be one of the promising approaches in the future for monitoring PM2.5 without power-hungry gas sensors and bulkier analyzers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2020.100185,Journal,Internet of Things (Netherlands),scopus,2020-09-01,sciencedirect,Highly-efficient fog-based deep learning AAL fall detection system,https://api.elsevier.com/content/abstract/scopus_id/85086362688,"Falls is one of most concerning accidents in aged population due to its high frequency and serious repercussion; thus, quick assistance is critical to avoid serious health consequences. There are several Ambient Assisted Living (AAL) solutions that rely on the technologies of the Internet of Things (IoT), Cloud Computing and Machine Learning (ML). Recently, Deep Learning (DL) have been included for its high potential to improve accuracy on fall detection. Also, the use of fog devices for the ML inference (detecting falls) spares cloud drawback of high network latency, non-appropriate for delay-sensitive applications such as fall detectors. Though, current fall detection systems lack DL inference on the fog, and there is no evidence of it in real environments, nor documentation regarding the complex challenge of the deployment. Since DL requires considerable resources and fog nodes are resource-limited, a very efficient deployment and resource usage is critical. We present an innovative highly-efficient intelligent system based on a fog-cloud computing architecture to timely detect falls using DL technics deployed on resource-constrained devices (fog nodes). We employ a wearable tri-axial accelerometer to collect patient monitoring data. In the fog, we propose a smart-IoT-Gateway architecture to support the remote deployment and management of DL models. We deploy two DL models (LSTM/GRU) employing virtualization to optimize resources and evaluate their performance and inference time. The results prove the effectiveness of our fall system, that provides a more timely and accurate response than traditional fall detector systems, higher efficiency, 98.75% accuracy, lower delay, and service improvement.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2020.104176,Journal,International Journal of Medical Informatics,scopus,2020-09-01,sciencedirect,The development an artificial intelligence algorithm for early sepsis diagnosis in the intensive care unit,https://api.elsevier.com/content/abstract/scopus_id/85085579350,"Background
                  Severe sepsis and septic shock are still the leading causes of death in Intensive Care Units (ICUs), and timely diagnosis is crucial for treatment outcomes. The progression of electronic medical records (EMR) offers the possibility of storing a large quantity of clinical data that can facilitate the development of artificial intelligence (AI) in medicine. However, several difficulties, such as poor structure and heterogenicity of the raw EMR data, are encountered when introducing AI with ICU data. Labor-intensive work, including manual data entry, personal medical records sorting, and laboratory results interpretation may hinder the progress of AI. In this article, we introduce the developing of an AI algorithm designed for sepsis diagnosis using pre-selected features; and compare the performance of the AI algorithm with SOFA score based diagnostic method.
               
                  Materials and methods
                  This is a prospective open-label cohort study. A specialized EMR, named TED_ICU, was implemented for continuous data recording. One hundred six clinical features relevant to sepsis diagnosis were selected prospectively. A labeling work to allocate SEPSIS or NON_SEPSIS status for each ICU patient was performed by the in-charge intensivist according to SEPSIS-3 criteria, along with the automatic recording of selected features every day by TED_ICU. Afterward, we use de-identified data to develop the AI algorithm. Several machine learning methods were evaluated using 5-fold cross-validation, and XGBoost, a decision-tree based algorithm was adopted for our AI algorithm development due to best performance.
               
                  Results
                  The study was conducted between August 2018 and December 2018 for the first stage of analysis. We collected 1588 instances, including 444 SEPSIS and 1144 NON-SEPSIS, from 434 patients. The 434 patients included 259 (59.6%) male patients and 175 female patients. The mean age was 67.6-year-old, and the mean APACHE II score was 13.8. The SEPSIS cohort had a higher SOFA score and increased use of organ support treatment. The AI algorithm was developed with a shuffle method using 80% of the instances for training and 20% for testing. The established AI algorithm achieved the following: accuracy = 82% ± 1%; sensitivity = 65% ± 5%; specificity = 88% ± 2%; precision = 67% ± 3%; and F1 = 0.66 ± 0.02. The area under the receiver operating characteristic curve (AUROC) was approximately 0.89. The SOFA score was used on the same 1588 instances for sepsis diagnosis, and the result was inferior to our AI algorithm (AUROC = 0.596).
               
                  Conclusion
                  Using real-time data, collected by EMR, from the ICU daily practice, our AI algorithm established with pre-selected features and XGBoost can provide a timely diagnosis of sepsis with an accuracy greater than 80%. AI algorithm also outperforms the SOFA score in sepsis diagnosis and exhibits practicality as clinicians can deploy appropriate treatment earlier. The early and precise response of this AI algorithm will result in cost reduction, outcome improvement, and benefit for healthcare systems, medical staff, and patients as well.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.microc.2020.105038,Journal,Microchemical Journal,scopus,2020-09-01,sciencedirect,A smartphone-based rapid quantitative detection platform for lateral flow strip of human chorionic gonadotropin with optimized image algorithm,https://api.elsevier.com/content/abstract/scopus_id/85085341749,"Colloidal gold immunochromatographic test strip has been widely used as a rapid, simple and low-cost correct detection technology. However, its detection is often qualitative or semi-quantitative, which limits its clinical application to some extent. Herein, a portable test strip quantitative detection device based on smartphone to detect human chorionic gonadotropin (HCG) is developed. In experiment, a colloidal gold HCG detection strip based on antigen antibody immune response is constructed, and the quantitative results of three different image processing methods on the same strip detection are compared, including the threshold processing algorithm based on location information, the RGB color component extraction algorithm and the grayscale projection value processing algorithm, the results show that the last algorithm can realize the best recognition of the region of interest of strip. The mobile phone application software (App) based on this design shows that the detection limit of constructed colloidal gold HCG strip is 3 ng/mL with a linear range of 6–300 ng/mL. The detection result of real urine sample is consistent with the spiked concentration (R2 = 0.988), indicating that the concentration of HCG can be accurately measured in urine with this method, presenting the potential for instant diagnosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.appet.2020.104698,Journal,Appetite,scopus,2020-09-01,sciencedirect,Momentary changes in heart rate variability can detect risk for emotional eating episodes,https://api.elsevier.com/content/abstract/scopus_id/85083899611,"Emotion dysregulation is a known risk factor for a variety of maladaptive eating behaviors, including emotional eating (Crockett, Myhre, & Rokke, 2015; Lavender et al., 2015). New passive sensing technologies offer the prospect of detecting emotion dysregulation in real-time through measurement of heart rate variability (HRV), a transdiagnostic bio-signal of emotion regulation, which may in turn signal risk of engaging in a maladaptive eating behavior. In the current study, our primary aim was to test the hypothesis that momentary changes in HRV can be used to detect risk of experiencing an emotional eating episode in an ecologically valid setting using a wrist worn sensor with acceptable classification accuracy. Participants were 21 adults with clinically significant emotional eating behaviors. Participants wore the Empatica E4 wrist-sensor and tracked all emotional eating episodes using ecological momentary assessment for four weeks. Time and frequency domain features of HRV were extracted in the 30-min period preceding emotional eating episodes and control cases (defined as the 30 min prior to an EMA survey that did not contain an emotional eating episode). Support vector machine (SVM) learning models were implemented using time domain and frequency domain features. SVM models using frequency domain features achieved the highest classification accuracy (77.99%), sensitivity (78.75%), and specificity (75.00%), consistent with standards deemed acceptable for the prediction of event-level health behavior. SVM models using time domain features still performed above chance, though were less accurate at classifying episodes (accuracy 63.48%, sensitivity 62.68%, and specificity 70.00%) and did not meet acceptable classification accuracy. Wearable sensors that assess HRV show promise as a tool for capturing risk of engaging in emotional eating episodes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2019.11.001,Journal,Future Generation Computer Systems,scopus,2020-09-01,sciencedirect,Wireless high-frequency NLOS monitoring system for heart disease combined with hospital and home,https://api.elsevier.com/content/abstract/scopus_id/85075418039,"Heart disease is one of the serious public health problems in the world at present. According to the research, the mortality and disability rates of cardiovascular diseases are the highest in the world. In this paper, we introduce wireless radio-frequency technique for health monitoring and use non-line-of-sight (NLOS) biological device to perceive physiological signal of patients. Therefore, we put forward a NLOS monitoring system for heart disease. Firstly, It is used to collect the physiological data of heart disease patients in real time. It is portable and non-line-of-sight, which provides really contact-less and interference-free monitoring environment for patients. Besides, edge computing is introduced to the heart disease monitoring system to support the short-delay and high-reliability response to urgent disease condition. Specifically, we deploy based on deep learning disease prediction model at edge nodes. Meanwhile, combining hospital and home healthcare, we propose rescue strategies for heart attack. To verify the feasibility of wireless NLOS monitoring system for heart disease combined hospital and home, we conduct case analysis for the key technologies and methods in the monitoring system, and built an experimental platform to test the proposed system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.04.123,Journal,Neurocomputing,scopus,2020-08-25,sciencedirect,Automated diagnosis of multi-plane breast ultrasonography images using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85085094427,"Breast ultrasonography is currently considered the first-line examination in the diagnosis of breast lesions or other abnormalities. Many automated breast cancer diagnosis methods have been developed for ultrasonography images; however, most previous automated methods used only a single breast ultrasonography image. This is inconsistent with the real-world situation, as breast cancer is heterogeneous, and it can lead to high false negative rates. Generally, sonographers diagnose a lesion by reviewing multiple planes. In this paper, we formulate the diagnosis of breast cancer on ultrasonography images as a Multiple Instance Learning (MIL) problem, diagnosing a breast nodule by jointly analyzing the nodule on multiple planes. An attention-augmented deep neural network is then developed to solve this problem. To the best of our knowledge, this is the first implementation of a MIL framework on such data. A large breast ultrasonography image dataset was constructed to train and evaluate the model; this contained 10,464 images from 3700 lesions labeled as benign or malignant, which originated from 2568 patients. The high classification accuracy achieved demonstrates the effectiveness of the proposed architecture for the diagnosis of breast cancer. The MIL based method obtained superior performance to single instance methods in this breast cancer diagnosis task. Notably, the proposed attention-augmented network allowed us to find key instances, which can be provided the region of interest (ROI) in the final diagnosis given to a doctor. Furthermore, we empirically demonstrate that our approach achieves better performance than other state-of-the-art MIL methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.05.014,Journal,Neurocomputing,scopus,2020-08-25,sciencedirect,Domain generalization in rotating machinery fault diagnostics using deep neural networks,https://api.elsevier.com/content/abstract/scopus_id/85084766952,"The past years have witnessed the successful development of intelligent machinery fault diagnostic methods. Besides the basic data-driven fault diagnosis tasks where the training and testing data are collected from the same distribution, the more practical cross-domain problems have also attracted much attention considering variations of machine operating conditions. In the literature, most existing studies generally assume the availability of testing data during model training, thus facilitating explicit domain adaptations. However, this assumption poses obstacles in the application on real-time cross-domain fault diagnosis, where the testing data can not be obtained in advance. This paper proposes a deep learning-based domain generalization method for machinery fault diagnosis. A domain augmentation method is adopted to expand the available dataset. Domain adversarial training is implemented, and generalized features can be learned from different domains, which hold in new working scenarios without assuming the availability of testing data. Distance metric learning is also used to further enhance model robustness in fault classifications. Through experiments on two rotating machinery datasets, the effectiveness of the proposed method is validated, which is promising in on-line cross-domain fault diagnosis tasks.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100074,Journal,Patterns,scopus,2020-08-14,sciencedirect,Machine-Learning Approaches in COVID-19 Survival Analysis and Discharge-Time Likelihood Prediction Using Clinical Data,https://api.elsevier.com/content/abstract/scopus_id/85092796371,"As a highly contagious respiratory disease, COVID-19 has yielded high mortality rates since its emergence in December 2019. As the number of COVID-19 cases soars in epicenters, health officials are warning about the possibility of the designated treatment centers being overwhelmed by coronavirus patients. In this study, several computational techniques are implemented to analyze the survival characteristics of 1,182 patients. The computational results agree with the outcome reported in early clinical reports released for a group of patients from China that confirmed a higher mortality rate in men compared with women and in older age groups. The discharge-time prediction of COVID-19 patients was also evaluated using different machine-learning and statistical analysis methods. The results indicate that the Gradient Boosting survival model outperforms other models for patient survival prediction in this study. This research study is aimed to help health officials make more educated decisions during the outbreak.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2352-3018(20)30190-9,Journal,The Lancet HIV,scopus,2020-08-01,sciencedirect,Modern diagnostic technologies for HIV,https://api.elsevier.com/content/abstract/scopus_id/85088944280,"Novel diagnostic technologies, including nanotechnology, microfluidics, -omics science, next-generation sequencing, genomics big data, and machine learning, could contribute to meeting the UNAIDS 95-95-95 targets to end the HIV epidemic by 2030. Novel technologies include multiplexed technologies (including biomarker-based point-of-care tests and molecular platform technologies), biomarker-based combination antibody and antigen technologies, dried-blood-spot testing, and self-testing. Although biomarker-based rapid tests, in particular antibody-based tests, have dominated HIV diagnostics since the development of the first HIV test in the mid-1980s, targets such as nucleic acids and genes are now used in nanomedicine, biosensors, microfluidics, and -omics to enable early diagnosis of HIV. These novel technologies show promise as they are associated with ease of use, high diagnostic accuracy, rapid detection, and the ability to detect HIV-specific markers. Additional clinical and implementation research is needed to generate evidence for use of novel technologies and a public health approach will be required to address clinical and operational challenges to optimise their global deployment.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2020.103490,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,A visual framework to create photorealistic retinal vessels for diagnosis purposes,https://api.elsevier.com/content/abstract/scopus_id/85087492636,"The methods developed in recent years for synthesising an ocular fundus can be been divided into two main categories. The first category of methods involves the development of an anatomical model of the eye, where artificial images are generated using appropriate parameters for modelling the vascular networks and fundus. The second type of method has been made possible by the development of deep learning techniques and improvements in the performance of hardware (especially graphics cards equipped with a large number of cores). The methodology proposed here to produce high-resolution synthetic fundus images is intended to be an alternative to the increasingly widespread use of generative adversarial networks to overcome the problems that arise in producing slightly modified versions of the same real images. This will allow the simulation of pathologies and the prediction of eye-related diseases. The proposed approach is based on the principle of least action and correctly places the vessels on the simulated eye fundus without using real morphometric information. An a posteriori analysis of the average characteristics such as the size, length, bifurcations, and endpoint positioning confirmed the substantial accuracy of the proposed approach compared to real data. A graphical user interface allows the user to make any changes in real time by controlling the positions of control points.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2020.103494,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Evolving dynamic self-adaptation policies of mHealth systems for long-term monitoring,https://api.elsevier.com/content/abstract/scopus_id/85087487414,"Tele-rehabilitation can complement traditional rehabilitation therapies by providing valuable information that can help in the evaluation, monitoring, and treatment of patients. Many patient tele-monitoring systems that integrate wearable technology are emerging as an effective tool for the long-term surveillance of rehabilitation progression, enabling continuous sampling of patient real-time movement in a non-invasive way, without affecting the normal daily activity of the outpatient, who, therefore, will not need to make frequent clinic visits. One of the main challenges of tele-rehabilitation systems is to pay special attention to the diversity of dysfunctions in patients by offering devices with customized behaviours adaptable to the physical conditions of each patient at the different stages of the rehabilitation therapy. Long-term monitoring systems need an adaptation policy to autonomously reconfigure their behaviour according to vital signs read during the physical activity of the patient, the remaining battery level, or the required accuracy of collected data. However, it would alsobe desirable to adjust such adaptation policies over time, according to the patient’s evolution. This work presents a wearable patient-monitoring system for tele-rehabilitation that is able to dynamically self-configure its internal behaviour to the current context of the outpatient according to a set of adaptation policies that optimize battery consumption, taking into account other QoS parameters at the same time. Our system is also able to self-adapt its internal adaptation policies as a patient’s condition improves, while maintaining the system’s efficiency. We illustrate our proposal with a real mHealth case study. The results of the experiments show that the system updates the adaptation policies, taking into account specific indicators of the disease. The validation results show that the evolution of the self-adaptation policies correlates with the progression of different patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2020.103483,Journal,Journal of Biomedical Informatics,scopus,2020-08-01,sciencedirect,Agents and robots for collaborating and supporting physicians in healthcare scenarios,https://api.elsevier.com/content/abstract/scopus_id/85087202709,"Monitoring patients through robotics telehealth systems is an interesting scenario where patients’ conditions, and their environment, are dynamic and unknown variables. We propose to improve telehealth systems’ features to include the ability to serve patients with their needs, operating as human caregivers. The objective is to support the independent living of patients at home without losing the opportunity to monitor their health status. Application scenarios are several, and they spread from simple clinical assisting scenarios to an emergency one. For instance, in the case of a nursing home, the system would support in continuously monitoring the elderly patients. In contrast, in the case of an epidemic diffusion, such as COVID-19 pandemic, the system may help in all the early triage phases, significantly reducing the risk of contagion. However, the system has to let medical assistants perform actions remotely such as changing therapies or interacting with patients that need support. The paper proposes and describes a multi-agent architecture for intelligent medical care. We propose to use the beliefs-desires-intentions agent architecture, part of it is devised to be deployed in a robot. The result is an intelligent system that may allow robots the ability to select the most useful plan for unhandled situations and to communicate the choice to the physician for his validation and permission.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jiph.2020.06.006,Journal,Journal of Infection and Public Health,scopus,2020-08-01,sciencedirect,Artificial intelligence-based tools to control healthcare associated infections: A systematic review of the literature,https://api.elsevier.com/content/abstract/scopus_id/85086591816,"Background
                  Healthcare-associated infections (HAIs) are the most frequent adverse events in healthcare and a global public health concern. Surveillance is the foundation for effective HAIs prevention and control. Manual surveillance is labor intensive, costly and lacks standardization. Artificial Intelligence (AI) and machine learning (ML) might support the development of HAI surveillance algorithms aimed at understanding HAIs risk factors, improve patient risk stratification, identification of transmission pathways, timely or real-time detection. Scant evidence is available on AI and ML implementation in the field of HAIs and no clear patterns emerges on its impact.
               
                  Methods
                  We conducted a systematic review following the PRISMA guidelines to systematically retrieve, quantitatively pool and critically appraise the available evidence on the development, implementation, performance and impact of ML-based HAIs detection models.
               
                  Results
                  Of 3445 identified citations, 27 studies were included in the review, the majority published in the US (n
                     =15, 55.6%) and on surgical site infections (SSI, n
                     =8, 29.6%). Only 1 randomized controlled trial was included. Within included studies, 17 (63%) ML approaches were classified as predictive and 10 (37%) as retrospective. Most of the studies compared ML algorithms’ performance with non-ML logistic regression statistical algorithms, 18.5% compared different ML models’ performance, 11.1% assessed ML algorithms’ performance in comparison with clinical diagnosis scores, 11.1% with standard or automated surveillance models. Overall, there is moderate evidence that ML-based models perform equal or better as compared to non-ML approaches and that they reach relatively high-performance standards. However, heterogeneity amongst the studies is very high and did not dissipate significantly in subgroup analyses, by type of infection or type of outcome.
               
                  Discussion
                  Available evidence mainly focuses on the development and testing of HAIs detection and prediction models, while their adoption and impact for research, healthcare quality improvement, or national surveillance purposes is still far from being explored.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jcv.2020.104474,Journal,Journal of Clinical Virology,scopus,2020-08-01,sciencedirect,Validation and verification of the Abbott RealTime SARS-CoV-2 assay analytical and clinical performance,https://api.elsevier.com/content/abstract/scopus_id/85085767646,"Background
                  High-throughput assays for the SARS-CoV-2 virus are critical to increasing test capacity and slowing the spread of COVID-19. Abbott Molecular developed and received emergency use authorization (EUA) to deploy the new RealTime SARS-CoV-2 assay, run on the automated m2000sp/rt system.
               
                  Objective
                  To evaluate analytical and clinical performance of the RealTime SARS-CoV-2 assay compared to the SARS-CoV-2 CDC-based laboratory developed test (LDT) in clinical use by the University of Washington Clinical Virology Laboratory (UW Virology).
               
                  Methods
                  RealTime SARS-CoV-2 assay limit of detection (LOD) was evaluated by testing two dilution panels of 60 replicates each. Cross-reactivity was evaluated by testing 24 clinical samples positive for various non‒SARS-CoV-2 respiratory viruses. Clinical performance was evaluated using 30 positive and 30 negative SARS-CoV-2 clinical samples previously tested using the UW Virology SARS-CoV-2 LDT.
               
                  Results
                  Exceeding the 100 copies/mL LOD reported in the RealTime SARS-CoV-2 assay EUA product insert, 19 of 20 replicates were detected at 50 copies/mL and 16 of 20 replicates were detected at 25 copies/mL. All clinical samples positive for 24 non‒SARS-CoV-2 respiratory viruses were SARS-CoV-2 negative on the RealTime SARS-CoV-2 assay. The assay had high sensitivity (93%) and specificity (100%) for detecting SARS-CoV-2 in clinical samples. Two positive samples that tested negative with the RealTime SARS-CoV-2 assay had cycle numbers of 35.94 or greater and required dilution prior to testing. One of these samples was also inconclusive on the SARS-CoV-2 LDT.
               
                  Conclusion
                  The RealTime SARS-CoV-2 assay is acceptable for clinical use. With the high-throughput, fully automated m2000 system, this assay will accelerate the pace of SARS-CoV-2 testing.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2020.101963,Journal,Biomedical Signal Processing and Control,scopus,2020-08-01,sciencedirect,Accuracy comparison of dimensionality reduction techniques to determine significant features from IMU sensor-based data to diagnose vestibular system disorders,https://api.elsevier.com/content/abstract/scopus_id/85085506158,"This study is a significant step gone to develop Machine Learning (ML) algorithm to apply to gait sensory information collected from people to identify Vestibular System (VS) disorders. Although ML is widely used as diagnostic tool in medical decision-making, there is not much research done on application of ML methods to identify VS imperfections. In this paper, we compared the accuracies of two dimensionality-reduction techniques to use with SVM with Gaussian Kernel: Feature Selection (FS) and Feature Transformation (FT) methods. T-test and Sequential Backward Selection (SBS) were used for FS and Principal Component Analysis (PCA) and Kernel Principal Component Analysis (KPCA) with polynomial and Gaussian kernels were used as FT method. Both methods were applied to the dataset formed by 22 features collected from 37 people, of whom 21 were healthy and 16 subjects had VS-disorders. The highest accuracy among FT methods was 89.2%, while it was 81.1% for FS method. SVM with Gaussian Kernel, trained with the dataset of reduced dimensionality, had computation time of few hundreds of milliseconds, which makes real-time data processing possible. The importance of this work will obviously increase with the increase in the number of initial features. As a next step, we aim to increase dataset and use additional features extracted from pressure sensors placed under the feet. We also aim to use time domain characteristics of the features to increase overall accuracy as a next step.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2020.105458,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-08-01,sciencedirect,Prediction model of the response to neoadjuvant chemotherapy in breast cancers by a Naive Bayes algorithm,https://api.elsevier.com/content/abstract/scopus_id/85083086614,"Background and Objective:
                  Chemotherapy is useful to many breast cancer patients, however, it is not therapeutic for some patients. Pathologic complete response (pCR) is an indicator to good response in Neoadjuvant chemotherapy (NAC). In this study, we aimed to develop a way to predict pCR before NAC.
               
                  Methods:
                  We retrospectively collected 287 stage II-III breast cancer cases either to a training set (N = 197) or to a test set (N = 90). Fourteen candidate genes were selected from four public microarray data sets. A prediction model was built, by using these fourteen candidate genes and three reference genes expression which were tested by TaqMan probe-based quantitative polymerase chain reaction, after selecting a better algorithm.
               
                  Results:
                  The Naive Bayes algorithm had a relatively higher predictive value, compared with random forest, support vector machine (SVM), and k-nearest neighbor (knn) algorithms (P < 0.05). This 17-gene prediction model showed a high positive correlation with pCR (odds ratio, 8.914, 95% confidence interval, 4.430–17.934, P < 0.001). By using this model, the enrolled patients were classified into sensitive (SE) and insensitive (INS) groups. The pCR rates between the SE and INS groups were highly different (42.3% vs.7.6%, P < 0.001). The sensitivity and specificity of this prediction model were 84.5% and 62.0%.
               
                  Conclusions:
                  Instead of whole transcriptome-based technologies, panel gene expression with tens of essential genes implemented in a machine learning model has predictive potential for chemosensitivity in breast cancers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2020.107768,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2020-07-15,sciencedirect,"Intelligent fault diagnosis of rotating machinery via wavelet transform, generative adversarial nets and convolutional neural network",https://api.elsevier.com/content/abstract/scopus_id/85082880587,"The fault detection of rotating machinery systems especially its typical components such as bearings and gears is of special importance for maintaining machine systems working normally and safely. However, due to the change of working conditions, the disturbance of environment noise, the weakness of early features and various unseen compound failure modes, it is quite hard to achieve high-accuracy intelligent failure monitoring task of rotating machinery using existing intelligent fault diagnosis approaches in real industrial applications. In the paper, a novel and high-accuracy fault detection approach named WT-GAN-CNN for rotating machinery is presented based on Wavelet Transform (WT), Generative Adversarial Nets (GANs) and convolutional neural network (CNN). The proposed WT-GAN-CNN approach includes three parts. To begin with, WT is employed for extracting time-frequency image features from one-dimension raw time domain signals. Secondly, GANs are used to generate more training image samples. Finally, the built CNN model is used to accomplish the fault detection of rotating machinery by the original training time-frequency images and the generated fake training time-frequency images. Two experiment studies are implemented to assess the effectiveness of our proposed approach and the results demonstrate it is higher in testing accuracy than other intelligent failure detection approaches in the literatures even in the interference of strong environment noise or when working conditions are changed. Furthermore, its result in the stability of testing accuracy is also quite excellent.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2020.101920,Journal,Artificial Intelligence in Medicine,scopus,2020-07-01,sciencedirect,Automated detection of dynamical change in EEG signals based on a new rhythm measure,https://api.elsevier.com/content/abstract/scopus_id/85087898088,"Automated detection of dynamical change in EEG signals has been a long-standing problem in a wide range of clinic applications. It is essential to extract an effective and accurate EEG rhythm indicator that can reflect the dynamical behavior of a given EEG signal. Time-frequency analysis is a promising method to achieve this end, but existing methods still have limitations in real implementation making this kind of methods still progressive until the present day. In this paper, along the line of ongoing research on time-frequency methods, we present a new method based on graph-based modeling. By virtue of this method, an effective and accurate EEG rhythm indicator can be extracted to characterize the dynamical EEG time series. Together with the extracted EEG rhythm indicator, an automatic analysis of continuous monitoring of EEG signal, is developed by means of a null hypothesis testing to inspect whether an EEG change occurs or not during a monitoring period. The proposed framework is applied to both simulated data and real signals respectively to validate its effectiveness. Experimental results, together with theoretical interpretation and discussions, suggest its promising potentials in practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comcom.2020.05.042,Journal,Computer Communications,scopus,2020-07-01,sciencedirect,Fastest adaptive estimation algorithms for topological structure errors in smart grid networks,https://api.elsevier.com/content/abstract/scopus_id/85086375513,"Compared with traditional wired networks, wireless sensor networks(WSN) have the characteristics of low cost and rapid deployment, and also guarantee the same level of fault tolerance as wired networks. The WSN can also monitor the operating status of the power grid in real time, collect physical information such as related parameters, and provide more comprehensive and complete power grid operation data as a reference basis for smart grid operation and related management personnel, and complete the diagnosis, monitoring and power statistics of smart grid equipment The rapid construction of the data communication network has become a key technology to effectively solve the problems of difficult optimization management and high cost and economic benefits in the smart grid. This paper discusses the application of WSNs in smart grids from two aspects. Firstly, construct a WSN topology that complies with the smart grid architecture, and establish a real-time routing mechanism that meets the requirements of smart distribution network communication reliability; secondly, propose a fastest adaptive algorithm for the fault of the WSN topology in the smart grid . The proposed adaptive routing mechanism has certain advantages in node energy consumption, which reduces energy consumption by nearly 4% compared to the directional diffusion method and the LEACH algorithm. Therefore, the algorithm is more suitable for the adaptation of WSN topology, and the method can Improve the life cycle of sensor nodes and networks.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.arth.2020.04.048,Journal,Journal of Arthroplasty,scopus,2020-07-01,sciencedirect,Digital Orthopaedics: A Glimpse Into the Future in the Midst of a Pandemic,https://api.elsevier.com/content/abstract/scopus_id/85084400483,"Background
                  The response to COVID-19 catalyzed the adoption and integration of digital health tools into the health care delivery model for musculoskeletal patients. The change, suspension, or relaxation of Medicare and federal guidelines enabled the rapid implementation of these technologies. The expansion of payment models for virtual care facilitated its rapid adoption. The authors aim to provide several examples of digital health solutions utilized to manage orthopedic patients during the pandemic and discuss what features of these technologies are likely to continue to provide value to patients and clinicians following its resolution.
               
                  Conclusion
                  The widespread adoption of new technologies enabling providers to care for patients remotely has the potential to permanently change the expectations of all stakeholders about the way care is provided in orthopedics. The new era of Digital Orthopaedics will see a gradual and nondisruptive integration of technologies that support the patient’s journey through the successful management of their musculoskeletal disease.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2020.113251,Journal,Expert Systems with Applications,scopus,2020-07-01,sciencedirect,Integrating complex event processing and machine learning: An intelligent architecture for detecting IoT security attacks,https://api.elsevier.com/content/abstract/scopus_id/85079340111,"The Internet of Things (IoT) is growing globally at a fast pace: people now find themselves surrounded by a variety of IoT devices such as smartphones and wearables in their everyday lives. Additionally, smart environments, such as smart healthcare systems, smart industries and smart cities, benefit from sensors and actuators interconnected through the IoT. However, the increase in IoT devices has brought with it the challenge of promptly detecting and combating the cybersecurity attacks and threats that target them, including malware, privacy breaches and denial of service attacks, among others. To tackle this challenge, this paper proposes an intelligent architecture that integrates Complex Event Processing (CEP) technology and the Machine Learning (ML) paradigm in order to detect different types of IoT security attacks in real time. In particular, such an architecture is capable of easily managing event patterns whose conditions depend on values obtained by ML algorithms. Additionally, a model-driven graphical tool for security attack pattern definition and automatic code generation is provided, hiding all the complexity derived from implementation details from domain experts. The proposed architecture has been applied in the case of a healthcare IoT network to validate its ability to detect attacks made by malicious devices. The results obtained demonstrate that this architecture satisfactorily fulfils its objectives.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2020.02.049,Journal,Neurocomputing,scopus,2020-06-14,sciencedirect,Sparse filtering based domain adaptation for mechanical fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85080057528,"Recently, machine learning has achieved considerable success in the field of mechanical fault diagnosis. Nevertheless, in many real-world applications, the original vibration data usually collected under different work conditions which lead to large distribution divergences. As a result, the performances of many machine learning methods may drop dramatically. To overcome this deficiency, domain adaptation is introduced by adapting the regression model or classifier trained in the source domain for use in the distinct but related target domain. Particularly, a novel sparse filtering based domain adaptation approach (SFDA) is proposed for the mechanical fault diagnosis. Comparing with the previous researches, two main contributions of SFDA are concluded as follows: (1) the domain adaptation is applied to the sparse filtering algorithm. (2) The ℓ1-norm and ℓ2-norm are employed to the maximum mean discrepancy (MMD). (3) SFDA is easy to be implemented, and high classification accuracy can be obtained. The bearing and gear dataset are utilized to testify the validity and reliability of SFDA.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patter.2020.100042,Journal,Patterns,scopus,2020-06-12,sciencedirect,Deep Learning Identifies Digital Biomarkers for Self-Reported Parkinson's Disease,https://api.elsevier.com/content/abstract/scopus_id/85095745471,"Large-scale population screening and in-home monitoring for patients with Parkinson's disease (PD) has so far been mainly carried out by traditional healthcare methods and systems. Development of mobile health may provide an independent, future method to detect PD. Current PD detection algorithms will benefit from better generalizability with data collected in real-world situations. In this paper, we report the top-performing smartphone-based method in the recent DREAM Parkinson's Disease Digital Biomarker Challenge for digital diagnosis of PD. Utilizing real-world accelerometer records, this approach differentiated PD from control subjects with an area under the receiver-operating characteristic curve of 0.87 by 3D augmentation of accelerometer records, a significant improvement over other state-of-the-art methods. This study paves the way for future at-home screening of PD and other neurodegenerative conditions affecting movement.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2020.101729,Journal,Computerized Medical Imaging and Graphics,scopus,2020-06-01,sciencedirect,Simplification of neural networks for skin lesion image segmentation using color channel pruning,https://api.elsevier.com/content/abstract/scopus_id/85084760154,"Automatic analysis of skin abnormality is an effective way for medical experts to facilitate diagnosis procedures and improve their capabilities. Efficient and accurate methods for analysis of the skin abnormalities such as convolutional neural networks (CNNs) are typically complex. Hence, the implementation of such complex structures in portable medical instruments is not feasible due to power and resource limitations. CNNs can extract features from the skin abnormality images automatically. To reduce the burden of the network for feature extraction, which can lead to the network simplicity, proper input color channels could be selected. In this paper, a pruning framework is proposed to simplify these complex structures through the selection of most informative color channels and simplification of the network. Moreover, hardware requirements of different network structures are identified to analyze the complexity of different networks. Experimental results are conducted for segmentation of images from two publicly available datasets of both dermoscopy and non-dermoscopy images. Simulation results show that using the proposed color channel selection method, simple and efficient neural network structures can be applied for segmentation of skin abnormalities.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.psj.2019.10.015,Journal,Poultry Science,scopus,2020-06-01,sciencedirect,Cleaning and disinfection of crates and trucks used for duck transport: field observations during the H5N8 avian influenza outbreaks in France in 2017,https://api.elsevier.com/content/abstract/scopus_id/85084461250,"Transport of infected birds is thought to play a key role in the spread of avian influenza (AI) on poultry farms during epizootic outbreaks. Ensuring efficient cleaning and disinfection (C&D) of equipment used for transport is needed to prevent the spread of AI. This study aimed to evaluate the efficacy against the AI virus of C&D protocols applied on trucks and crates used for the transport of ducks during the H5N8 AI outbreaks in France in 2017. In 3 abattoirs, 16 transport vehicles and their crates were sampled by swabbing to detect the influenza type A genome by real-time reverse-transcription polymerase chain reaction. Vehicles were tested before and after decontamination, which was carried out in accordance with the abattoirs' protocols. A total of 86 samples out of 299 collected before C&D were positive for AI (29%); 7 trucks out of 16 transported crates detected positive for AI. After C&D, the AI genome was detected in 56 samples out of 308 (18%). Ten trucks were loaded with a shipment of AI-positive crates. Eight vehicles were detected positive in the cabin, on the truck bed, and/or on the wheels. Despite reinforcement of C&D, the efficacy of decontamination was variable among slaughterhouses. The efficacy seemed to depend on the initial contamination load, C&D protocols, and how the protocol is implemented. Breaks in biosecurity measures led to frequent contamination of trucks after C&D. Observational studies during animal health crises are of interest to analyze practices in emergency conditions and to put forward measures aimed at increased preparedness.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2020.103792,Journal,Computers in Biology and Medicine,scopus,2020-06-01,sciencedirect,Automated detection of COVID-19 cases using deep neural networks with X-ray images,https://api.elsevier.com/content/abstract/scopus_id/85083900518,"The novel coronavirus 2019 (COVID-2019), which first appeared in Wuhan city of China in December 2019, spread rapidly around the world and became a pandemic. It has caused a devastating effect on both daily lives, public health, and the global economy. It is critical to detect the positive cases as early as possible so as to prevent the further spread of this epidemic and to quickly treat affected patients. The need for auxiliary diagnostic tools has increased as there are no accurate automated toolkits available. Recent findings obtained using radiology imaging techniques suggest that such images contain salient information about the COVID-19 virus. Application of advanced artificial intelligence (AI) techniques coupled with radiological imaging can be helpful for the accurate detection of this disease, and can also be assistive to overcome the problem of a lack of specialized physicians in remote villages. In this study, a new model for automatic COVID-19 detection using raw chest X-ray images is presented. The proposed model is developed to provide accurate diagnostics for binary classification (COVID vs. No-Findings) and multi-class classification (COVID vs. No-Findings vs. Pneumonia). Our model produced a classification accuracy of 98.08% for binary classes and 87.02% for multi-class cases. The DarkNet model was used in our study as a classifier for the you only look once (YOLO) real time object detection system. We implemented 17 convolutional layers and introduced different filtering on each layer. Our model (available at (https://github.com/muhammedtalo/COVID-19)) can be employed to assist radiologists in validating their initial screening, and can also be employed via cloud to immediately screen patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gie.2019.12.049,Journal,Gastrointestinal Endoscopy,scopus,2020-06-01,sciencedirect,Artificial intelligence using convolutional neural networks for real-time detection of early esophageal neoplasia in Barrett's esophagus (with video),https://api.elsevier.com/content/abstract/scopus_id/85082811592,"Background and Aims
                  The visual detection of early esophageal neoplasia (high-grade dysplasia and T1 cancer) in Barrett’s esophagus (BE) with white-light and virtual chromoendoscopy still remains challenging. The aim of this study was to assess whether a convolutional neural artificial intelligence network can aid in the recognition of early esophageal neoplasia in BE.
               
                  Methods
                  Nine hundred sixteen images from 65 patients of histology-proven early esophageal neoplasia in BE containing high-grade dysplasia or T1 cancer were collected. The area of neoplasia was masked using image annotation software. Nine hundred nineteen control images were collected of BE without high-grade dysplasia. A convolutional neural network (CNN) algorithm was pretrained on ImageNet and then fine-tuned with the goal of providing the correct binary classification of “dysplastic” or “nondysplastic.” We developed an object detection algorithm that drew localization boxes around regions classified as dysplasia.
               
                  Results
                  The CNN analyzed 458 test images (225 dysplasia and 233 nondysplasia) and correctly detected early neoplasia with sensitivity of 96.4%, specificity of 94.2%, and accuracy of 95.4%. With regard to the object detection algorithm for all images in the validation set, the system was able to achieve a mean average precision of .7533 at an intersection over union of .3
               
                  Conclusions
                  In this pilot study, our artificial intelligence model was able to detect early esophageal neoplasia in BE images with high accuracy. In addition, the object detection algorithm was able to draw a localization box around the areas of dysplasia with high precision and at a speed that allows for real-time implementation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2020.02.037,Journal,Information Sciences,scopus,2020-06-01,sciencedirect,A training-integrity privacy-preserving federated learning scheme with trusted execution environment,https://api.elsevier.com/content/abstract/scopus_id/85081023216,"Machine learning models trained on sensitive real-world data promise improvements to everything from medical screening to disease outbreak discovery. In many application domains, learning participants would benefit from pooling their private datasets, training precise machine learning models on the aggregate data, and sharing the profits of using these models. Considering privacy and security concerns often prevent participants from contributing sensitive data for training, researchers proposed several techniques to achieve data privacy in federated learning systems. However, such techniques are susceptible to causative attacks, whereby malicious participants can inject false training results with the aim of corrupting the well-learned model. To end this, in this paper, we propose a new privacy-preserving federated learning scheme that guarantees the integrity of deep learning processes. Based on the Trusted Execution Environment (TEE), we design a training-integrity protocol for this scheme, in which causative attacks can be detected. Thus, each participant is compelled to execute the privacy-preserving learning algorithm of the scheme correctly. We evaluate the performance of our scheme by prototype implementations. The experimental result shows that the scheme is training-integrity and practical.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.copbio.2019.12.021,Journal,Current Opinion in Biotechnology,scopus,2020-06-01,sciencedirect,Incorporating biological structure into machine learning models in biomedicine,https://api.elsevier.com/content/abstract/scopus_id/85077913249,"In biomedical applications of machine learning, relevant information often has a rich structure that is not easily encoded as real-valued predictors. Examples of such data include DNA or RNA sequences, gene sets or pathways, gene interaction or coexpression networks, ontologies, and phylogenetic trees. We highlight recent examples of machine learning models that use structure to constrain model architecture or incorporate structured data into model training. For machine learning in biomedicine, where sample size is limited and model interpretability is crucial, incorporating prior knowledge in the form of structured data can be particularly useful. The area of research would benefit from performant open source implementations and independent benchmarking efforts.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2020.103589,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-05-01,sciencedirect,Deep reinforcement one-shot learning for artificially intelligent classification in expert aided systems,https://api.elsevier.com/content/abstract/scopus_id/85081990367,"In recent years there has been a sharp rise in applications, in which significant events need to be classified but only a few training instances are available. These are known as cases of one-shot learning. To handle this challenging task, organizations often use human analysts to classify events under high uncertainty. Existing algorithms use a threshold-based mechanism to decide whether to classify an object automatically or send it to an analyst for deeper inspection. However, this approach leads to a significant waste of resources since it does not take the practical temporal constraints of system resources into account. By contrast, the focus in this paper is on rigorously optimizing the resource consumption in the system which applies to broad application domains, and is of a significant interest for academic research, industrial developments, as well as society and citizens benefit. The contribution of this paper is threefold. First, a novel Deep Reinforcement One-shot Learning (DeROL) framework is developed to address this challenge. The basic idea of the DeROL algorithm is to train a deep-Q network to obtain a policy which is oblivious to the unseen classes in the testing data. Then, in real-time, DeROL maps the current state of the one-shot learning process to operational actions based on the trained deep-Q network, to maximize the objective function. Second, the first open-source software for practical artificially intelligent one-shot classification systems with limited resources is developed for the benefit of researchers and developers in related fields. Third, an extensive experimental study is presented using the OMNIGLOT dataset for computer vision tasks, the UNSW-NB15 dataset for intrusion detection tasks, and the Cleveland Heart Disease Dataset for medical monitoring tasks that demonstrates the versatility and efficiency of the DeROL framework.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mednuc.2020.02.006,Journal,Medecine Nucleaire,scopus,2020-05-01,sciencedirect,Joint SFMN/ANOCEF focus on 18F-FDOPA PET imaging in glioma: Current applications and perspectives,https://api.elsevier.com/content/abstract/scopus_id/85081912823,"18F-FDOPA PET has demonstrated its additional value during the clinical course of glioma, at initial diagnosis, for treatment planning or follow-up. The aim of the current review was to summarize current applications of 18F-FDOPA PET in gliomas and constitute, as a perspective, a first step in harmonizing clinical practices in French centers. In France, the indication for 18F-FDOPA PET is restricted to the assessment of primary brain tumor recurrence. According to the literature, this indication could be expanded to primary diagnosis and, to a lesser extent, treatment monitoring. There is a real need to harmonize standard procedures among French centers. The objective is to increase the availability of data for this rare entity of glioma and to develop multi-parametric PET analyses (static, dynamic and textural), also known as radiomics, by using artificial intelligence algorithms. For this purpose, kinetics analysis with dynamic PET acquisition should be implemented in routine practice because it has demonstrated its additional value for initial diagnosis in gliomas. Therefore, this review proposes a workflow based on acquisition and reconstruction parameters that can be implemented in each center to increase the amount of standardized 18F-FDOPA PET data in neuro-oncology imaging in France. This would help in creating a national database and developing national multi-center studies that can respond to the challenge of using multi-parametric PET in glioma.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2019.11.010,Journal,Neurocomputing,scopus,2020-04-28,sciencedirect,Output based transfer learning with least squares support vector machine and its application in bladder cancer prognosis,https://api.elsevier.com/content/abstract/scopus_id/85078061159,"Two dilemmas frequently occur in many real-world clinical prognoses. First, the on-hand data cannot be put entirely into the existing prediction model, since the features from new data do not perfectly match those of the model. As a result, some unique features collected from the patients in the current domain of interest might be wasted. Second, the on-hand data is not sufficient enough to learn a new prediction model. To overcome these challenges, we propose an output-based transfer learning approach with least squares support vector machine (LS-SVM) to make the maximum use of the small dataset and guarantee an enhanced generalization capability. The proposed approach can learn a current domain of interest with limited samples effectively by leveraging the knowledge from the predicted outputs of the existing model in the source domain. Also, the extent of output knowledge transfer from the source domain to the current one can be automatically and rapidly determined using a proposed fast leave-one-out cross validation strategy. The proposed approach is applied to a real-world clinical dataset to predict 5-year overall and cancer-specific mortality of bladder cancer patients after radical cystectomy. The experimental results indicate that the proposed approach achieves better classification performances than the other comparative methods and has the potential to be implemented into the real-world context to deal with small data problems in cancer prediction and prognosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tgie.2019.150631,Journal,Techniques and Innovations in Gastrointestinal Endoscopy,scopus,2020-04-01,sciencedirect,Artificial intelligence for colon polyp detection: Why should we embrace this?,https://api.elsevier.com/content/abstract/scopus_id/85104673399,"Optimal success of colonoscopy for prevention of colorectal cancer is currently measured by adenoma detection rate (ADR), which reflects a colonoscopists ability to identify colorectal and remove precancerous polyps. Among colonoscopists in the same health care system and shared patient population, ADR varies from 7% to 53%. For every 1% increase in ADR, risk of interval colorectal cancer is reduced by 3%-6%. Beyond attaining excellent exposure of entire mucosal surface during colonoscopy, ADR can be improved with a second observer. Computer-aided detection (“facial recognition” for polyps) has potential to improve ADR as a second observer. Several groups are working to bring this technology into the endoscopy unit. Success will require real-time implementation of an affordable system with very high accuracy and proven benefit to improve ADR and reduce miss rate of precancerous lesions. In just the past year, computer-aided detection systems that run live during colonoscopy have been shown to improve ADR using affordable off-the-shelf computers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2020.101147,Journal,Pervasive and Mobile Computing,scopus,2020-04-01,sciencedirect,Unsupervised domain adaptation for activity recognition across heterogeneous datasets,https://api.elsevier.com/content/abstract/scopus_id/85083082262,"Sensor-based human activity recognition is to recognise human daily activities through a collection of ambient and wearable sensors. It is the key enabler for many healthcare applications, especially in ambient assisted living. The advance of sensing and communication technologies has driven the deployment of sensors in many residential and care home settings. However, the challenge still resides in the lack of sufficient, high-quality activity annotations on sensor data, which most of the existing activity recognition algorithms rely on. In this paper, we propose an Unsupervised Domain adaptation technique for Activity Recognition, called UDAR, which supports sharing and transferring activity models from one dataset to another heterogeneous dataset without the need of activity labels on the latter. This approach has combined knowledge- and data-driven techniques to achieve coarse- and fine-grained feature alignment. We have evaluated UDAR on five third-party, real-world datasets and have demonstrated high recognition accuracy and robustness against sensor noise, compared to the state-of-the-art domain adaptation techniques.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brainresbull.2020.01.009,Journal,Brain Research Bulletin,scopus,2020-04-01,sciencedirect,MicroRNAs expressed in neuronal differentiation and their associated pathways: Systematic review and bioinformatics analysis,https://api.elsevier.com/content/abstract/scopus_id/85079431489,"MicroRNAs (miRNAs) plays an important role in the human brain from the embryonic period to adulthood. In this sense, they influence the development of neural stem cells (NSCs), regulating cellular differentiation and survival. Therefore, due to the importance of better comprehending the regulation of miRNAs in NSCs differentiation and the lack of studies that show the panorama of miRNAs and their signaling pathways studied until now we aimed to systematically review the literature to identify which miRNAs are currently being associated with neuronal differentiation and using bioinformatics analysis to identify their related pathways. A search was carried out in the following databases: Scientific Electronic Library Online (Scielo), National Library of Medicine National Institutes of Health (PubMed), Scopus, Web of Science and Science Direct, using the descriptors “(microRNA [MeSH])” and “(neurogenesis [MeSH])”. From the articles found, two independent and previously calibrated reviewers, using the EndNote X7 (Thomson Reuters, New York, NY, US), selected those that concern miRNA in the development of NSCs, based on in vitro studies. After, bioinformatic analysis was performed using the software DIANA Tools, mirPath v.3. Subsequently, data was tabulated, analyzed and interpreted. Among the 106 miRNAs cited by included studies, 55 were up-regulated and 47 were down-regulated. The bioinformatics analysis revealed that among the up-regulated miRNAs there were 24 total and 6 union pathways, and 3 presented a statistically significant difference (p ≤ 0.05). Among the down-regulated miRNAs, 46 total and 13 union pathways were found, with 7 presenting a significant difference (p ≤ 0.05). The miR-125a-5p, miR-423-5p, miR-320 were the most frequently found miRNAs in the pathways determined by bioinformatics. In this study a panel of altered miRNAs in neuronal differentiation was created with their related pathways, which could be a step towards understanding the complex network of miRNAs in neuronal differentiation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neunet.2020.01.001,Journal,Neural Networks,scopus,2020-04-01,sciencedirect,Medi-Care AI: Predicting medications from billing codes via robust recurrent neural networks,https://api.elsevier.com/content/abstract/scopus_id/85078189366,"In this paper, we present an effective deep prediction framework based on robust recurrent neural networks (RNNs) to predict the likely therapeutic classes of medications a patient is taking, given a sequence of diagnostic billing codes in their record. Accurately capturing the list of medications currently taken by a given patient is extremely challenging due to undefined errors and omissions. We present a general robust framework that explicitly models the possible contamination through overtime decay mechanism on the input billing codes and noise injection into the recurrent hidden states, respectively. By doing this, billing codes are reformulated into its temporal patterns with decay rates on each medical variable, and the hidden states of RNNs are regularized by random noises which serve as dropout to improved RNNs robustness towards data variability in terms of missing values and multiple errors. The proposed method is extensively evaluated on real health care data to demonstrate its effectiveness in suggesting medication orders from contaminated values.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105088,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,An efficient architecture for medical high-resolution images transmission in mobile telemedicine systems,https://api.elsevier.com/content/abstract/scopus_id/85076233598,"Background and Objective
                  The medical high-resolution image is very important in image processing and computer vision applications, which plays a critical role in image-guided diagnosis, clinical trials, consultation, and case discussion. How to efficiently access medical high-resolution images in mobile telemedicine systems is becoming a big challenge. Therefore, this work proposes an efficient pyramid architecture for optimizing medical high-resolution images transmission and rendering.
               
                  Methods
                  The proposed architecture consists of three core schemes: (1) unbalance pyramid scheme based on geometric relationship, (2) indexing scheme based on hash table and lattice partitioning and (3) query scheme based on similar matching. Then, we design the responsive service components: generating service, indexing service, and query service. Finally, these services are combined into a prototype system that enables efficient transmission and rendering of medical high-resolution images.
               
                  Results
                  The result shows that the unbalance pyramid scheme can quickly generate the pyramid structure and the corresponding image files. The indexing scheme can create the index structure and the index file in real-time. The query scheme can not only match the best layer to which the image block belongs in real-time, but also can accurately capture the query image block.
               
                  Conclusions
                  The prototype system based on proposed architecture is fully compliant with the DICOM standard, which can be seamlessly integrated with other existing medical systems or mobile applications, and used in various scenarios such as diagnosis, research, and education.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105254,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic digital ECG signal extraction and normal QRS recognition from real scene ECG images,https://api.elsevier.com/content/abstract/scopus_id/85076186466,"Background and objective
                  Electrocardiogram (ECG) is one of the most important tools for assessing cardiac function and detecting potential heart problems. However, most of the current ECG report records remain on the paper, which makes it difficult to preserve and analyze the data. Moreover, paper records could result in the loss significant data, which brings inconvenience to the subsequent clinical diagnosis or artificial intelligence-assisted heart health diagnosis. Taking digital pictures is an intuitive way of preserving these files and can be done simply using smartphones or any other devices with cameras. However, these real scene ECG images often have some image noise that hinders signal extraction. How to eliminate image noise and extract ECG binary image automatically from the noisy and low-quality real scene images of ECG reports is the first problem to be solved in this paper. Next, QRS recognition is implemented on the extracted binary images to determine key points of ECG signals. 1D digital ECG signal is also extracted for accessing the exact values of the extracted points. In light of these tasks, an automatic digital ECG signal extraction and normal QRS recognition from real scene ECG images is proposed in this paper.
               
                  Methods
                  The normal QRS recognition approach for real scene ECG images in this paper consists of two steps: ECG binary image extraction from ECG images using a new two-layer hierarchical method, and the subsequent QRS recognition based on a novel feature-fusing method. ECG binary image extraction is implemented using sub-channel filters followed by an adaptive filtering algorithm. According to the ratio between pixel and real value of ECG binary image, 1D digital ECG signal is obtained. The normal QRS recognition includes three main steps: establishment of candidate point sets, feature fusion extraction, and QRS recognition. Two datasets are introduced for evaluation including a real scene ECG images dataset and the public Non-Invasive Fetal Electrocardiogram Database (FECG).
               
                  Results
                  Through the experiment on real scene ECG image, the F1 score for Q, R, S detection is 0.841, 0.992, and 0.891, respectively. The evaluation on the public FECG dataset also proves the robustness of our algorithm, where F1 score for R is 0.992 (0.996 for thoracic lead) and 0.988 for thoracic S wave.
               
                  Conclusions
                  The proposed method in this article is a promising tool for automatically extracting digital ECG signals and detecting QRS complex in real scene ECG images with normal QRS.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105019,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-04-01,sciencedirect,Automatic diagnosis of fungal keratitis using data augmentation and image fusion with deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85070552720,"Background and objectives
                  Fungal keratitis is caused by inflammation of the cornea that results from infection by fungal organisms. The lack of an early effective diagnosis often results in serious complications even blindness. Confocal microscopy is one of the most effective methods in the diagnosis of fungal keratitis, but the diagnosis depends on the subjective judgment of medical experts.
               
                  Methods
                  To address this problem, this paper proposes a novel convolutional neural network framework for the automatic diagnosis of fungal keratitis using data augmentation and image fusion. Firstly, a normal image is augmented by flipping to solve the problem of having a limited and imbalanced database. Secondly, a sub-area contrast stretching algorithm is proposed for image preprocessing to highlight the key structures in the images and to filter out irrelevant information. Thirdly, the histogram matching fusion algorithm is implemented, then the preprocessed image is fused with the original image to form a new algorithm framework and a new database. Finally, the traditional convolutional neural network is integrated into the novel algorithm framework to perform the experiments.
               
                  Results
                  Experiments show that the accuracy of traditional AlexNet and VGGNet is 99.35% and 99.14%, that of AlexNet and VGGNet based on MF fusion is 99.80% and 99.83%, and that of AlexNet and VGGNet based on histogram matching fusion (HMF) is 99.95% and 99.89%. The experimental results show that the AlexNet framework using data augmentation and image fusion achieves a perfect trade-off between the diagnostic performance and the computational complexity, with a diagnostic accuracy of 99.95%.
               
                  Conclusions
                  These experimental results demonstrate the novel convolutional neural network framework perfectly balances the diagnostic performance and computational complexity, and can improve the effect and real-time performance in the diagnosis of fungal keratitis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.watres.2019.115435,Journal,Water Research,scopus,2020-03-15,sciencedirect,"Microbial source tracking (MST) in Chattahoochee River National Recreation Area: Seasonal and precipitation trends in MST marker concentrations, and associations with E. coli levels, pathogenic marker presence, and land use",https://api.elsevier.com/content/abstract/scopus_id/85077660807,"Escherichia coli levels in recreational waters are often used to predict when fecal-associated pathogen levels are a human health risk. The reach of the Chattahoochee River that flows through the Chattahoochee River National Recreation Area (CRNRA), located in the Atlanta-metropolitan area, is a popular recreation area that frequently exceeds the U.S. Environmental Protection Agency beach action value (BAV) for E. coli. A BacteriALERT program has been implemented to provide real-time E. coli estimates in the reach and notify the public of potentially harmful levels of fecal-associated pathogens as indicated by surrogate models based on real-time turbidity measurements from continuous water quality monitoring stations. However, E. coli does not provide information about the sources of fecal contamination and its accuracy as a human health indicator is questionable when sources of contamination are non-human. The objectives of our study were to investigate, within the Park and surrounding watersheds, seasonal and precipitation-related patterns in microbial source tracking marker concentrations of possible sources (human, dog, and ruminant), assess correlations between source contamination levels and culturable E. coli levels, determine which sources best explained model-based E. coli estimates above the BAV and detection of esp2 (a marker for the esp gene associated with pathogenic strains of Enterococcus faecium and Enterococcus faecalis), and investigate associations between source contamination levels and land use features. Three BacteriALERT sites on the Chattahoochee River were sampled six times per season in the winter and summer from December 2015 through September 2017, and 11 additional stream sites (synoptic sites) from the CRNRA watershed were sampled once per season. Samples were screened with microbial source tracking (MST) quantitative PCR (qPCR) markers for humans (HF183 Taqman), dogs (DogBact), and ruminants (Rum2Bac), the esp2 qPCR marker, and culturable E. coli. At the BacteriALERT sites, HF183 Taqman concentrations were higher under wet conditions DogBact concentrations were greater in the winter and under wet conditions, and Rum2Bac concentrations were comparatively low throughout the study with no difference across seasons or precipitation conditions. Concentrations of HF183 Taqman, DogBact, and Rum2Bac were positively correlated with culturable E. coli concentrations; however, DogBact had the largest R2 value among the three markers, and the forward stepwise regression indicated it was the best predictor of culturable E. coli concentrations at the BacteriALERT sites. Recursive partitioning indicated that BAV exceedances of model-based E. coli estimates were best explained by DogBact concentrations ≥3 gene copies per mL (CN/mL). Detections of esp2 at BacteriALERT sites were best explained by DogBact concentrations ≥11 CN/mL, while detections of esp2 at synoptic sites were best explained by HF183 Taqman ≥29 CN/mL. At the synoptic sites, HF183 Taqman levels were associated with wastewater treatment plant density. However, this relationship was driven primarily by a single site, suggesting possible conveyance issues in that catchment. esp2 detections at synoptic sites were positively associated with development within a 2-km radius and negatively associated with development within the catchment, suggesting multiple sources of esp2 in the watershed. DogBact and Rum2Bac were not associated with the land use features included in our analyses. Implications for Park management include: 1) fecal contamination levels were highest during wet conditions and in the off season when fewer visitors are expected to be participating in water-based recreation, 2) dogs are likely contributors to fecal contamination in the CRNRA and may be sources of pathogenic bacteria indicating further investigation of the origins of this contamination may be warranted as would be research to understand the human health risks from exposure to dog fecal contamination, and 3) high levels of the human marker at one site in the CRNRA watershed suggests more extensive monitoring in that catchment may locate the origin of human fecal contamination detected during this study.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.prro.2019.11.011,Journal,Practical Radiation Oncology,scopus,2020-03-01,sciencedirect,"Computed Tomography to Cone Beam Computed Tomography Deformable Image Registration for Contour Propagation Using Head and Neck, Patient-Based Computational Phantoms: A Multicenter Study",https://api.elsevier.com/content/abstract/scopus_id/85078045320,"Purpose
                  To investigate the performance of various algorithms for deformable image registration (DIR) for propagating regions of interest (ROIs) using multiple commercial platforms, from computed tomography to cone beam computed tomography (CBCT) and megavoltage computed tomography.
               
                  Methods and Materials
                  Fourteen institutions participated in the study using 5 commercial platforms: RayStation (RaySearch Laboratories, Stockholm, Sweden), MIM (Cleveland, OH), VelocityAI and SmartAdapt (Varian Medical Systems, Palo Alto, CA), and ABAS (Elekta AB, Stockholm, Sweden). Algorithms were tested on synthetic images generated with the ImSimQA (Oncology Systems Limited, Shrewsbury, UK) package by applying 2 specific deformation vector fields (DVF) to real head and neck patient datasets. On-board images from 3 systems were used: megavoltage computed tomography from Tomotherapy and 2 kinds of CBCT from a clinical linear accelerator. Image quality of the system was evaluated. The algorithms’ accuracy was assessed by comparing the DIR-mapped ROIs returned by each center with those of the reference, using the Dice similarity coefficient and mean distance to conformity metrics. Statistical inference on the validation results was carried out to identify the prognostic factors of DIR performance.
               
                  Results
                  Analyzing 840 DIR-mapped ROIs returned by the centers, it was demonstrated that DVF intensity and image quality were significant prognostic factors of DIR performance. The accuracy of the propagated contours was generally high, and acceptable DIR performance can be obtained with lower-dose CBCT image protocols.
               
                  Conclusions
                  The performance of the systems proved to be image quality specific, depending on the DVF type and only partially on the platforms. All systems proved to be robust against image artifacts and noise, except the demon-based software.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.iot.2019.100130,Journal,Internet of Things (Netherlands),scopus,2020-03-01,sciencedirect,An IoT based device-type invariant fall detection system,https://api.elsevier.com/content/abstract/scopus_id/85077314197,"As the world elderly population is increasing rapidly, the use of technology for the development of accurate and fast automatic fall detection systems has become a necessity. Most of the fall detection systems are developed for specific devices which reduces the versatility of the fall detection system. This paper proposes a centralized unobtrusive IoT based device-type invariant fall detection and rescue system for monitoring of a large population in real-time. Any type of devices such as Smartphones, Raspberry Pi, Arduino, NodeMcu, and Custom Embedded Systems can be used to monitor a large population in the proposed system. The devices are placed into the users’ left or right pant pocket. The accelerometer data from the devices are continuously sent to a multithreaded server which hosts a pre-trained machine learning model that analyzes the data to determine whether a fall has occurred or not. The server sends the classification results back to the corresponding devices. If a fall is detected, the server notifies the mediator of the user's location via an SMS. As a failsafe, the corresponding device alerts nearby individuals by sounding the buzzer and contacts emergency medical services and mediators via SMS for immediate medical assistance, thus saving the user's life. The proposed system achieved 99.7% accuracy, 96.3% sensitivity, and 99.6% specificity. Finally, the proposed system can be implemented on a variety of devices and used to reliably monitor a large population with low false alarm rate, without obstructing the users’ daily living, as no external connections are required.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmir.2019.11.001,Journal,Journal of Medical Imaging and Radiation Sciences,scopus,2020-03-01,sciencedirect,Machine Learning Methods for Computer-Aided Breast Cancer Diagnosis Using Histopathology: A Narrative Review,https://api.elsevier.com/content/abstract/scopus_id/85077158769,"Histopathology is a method used for breast cancer diagnosis. Machine learning (ML) methods have achieved success for supervised learning tasks in the medical domain. In this article, we investigate the impact of ML for the diagnosis of breast cancer using histopathology images of conventional photomicroscopy. Cancer diagnosis is the identification of images as cancer or noncancer, and this involves image preprocessing, feature extraction, classification, and performance analysis. In this article, different approaches to perform these necessary steps are reviewed. We find that most ML research for breast cancer diagnosis has been focused on deep learning. Based on inferences from the recent research activities, we discuss how ML methods can benefit conventional microscopy-based breast cancer diagnosis. Finally, we discuss the research gaps of ML approaches for the implementation in a real pathology environment and propose future research guidelines.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2019.102960,Journal,Microprocessors and Microsystems,scopus,2020-03-01,sciencedirect,A novel hybrid optimized and adaptive reconfigurable framework for the implementation of hybrid bio-inspired classifiers for diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85077060597,"Due to recent advances in IoT (Internet of Things) technologies, availability of reliable data and emergence of machine learning, bio-inspired learning and artificial intelligence, has demonstrated its ability to solve the large complex problems which is not possible before. In particular, machine learning and bio-inspired learning algorithms provides the effective solutions in image processing techniques. However, the implementation of the above-mentioned algorithms in the general CPU requires the intensive usage of bandwidth, area and power which makes the CPU unhealthy of usage and implementation. To overcome this problem, ASIC (application specific integrated circuits), GPU (Graphics Processing Unit) &FPGA (Field Programmable gate arrays) have been employed to improve the performance of the hybrid machine learning (ML) classifiers and deep learning algorithms. FPGA has been recently employed for an effective implementation and to achieve the high performance of the learning algorithms. But integrating the complex learning algorithms in FPGA still remains to be real challenge among the researchers. The paper proposes new reconfigurable architectures for bio- inspired classifiers to diagnosis the medical casualties which can be suitable for the tele health care applications. This paper aim is as follows (i) Design and implementation of Parallel Fusion of FSM and Reconfigurable shared Distributed Arithmetic for Bio-Inspired Classifiers (ii) Development of Accelerator Environment to test the performance of proposed architecture (iii) Performance evaluation of proposed architecture in terms of accuracy of detection in compared with MATLAB simulation iv) Implementation of proposed architectures in different ARtix-7 architectures and determination of power, throughput and area . Moreover, the proposed architecture has been tested with the and compared with the other existing architectures.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.103427,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-03-01,sciencedirect,Stochastic parallel extreme artificial hydrocarbon networks: An implementation for fast and robust supervised machine learning in high-dimensional data,https://api.elsevier.com/content/abstract/scopus_id/85076620125,"Artificial hydrocarbon networks (AHN) – a supervised learning method inspired on organic chemical structures and mechanisms – have shown improvements in predictive power and interpretability in comparison with other well-known machine learning models. However, AHN are very time-consuming that are not able to deal with large data until now. In this paper, we introduce the stochastic parallel extreme artificial hydrocarbon networks (SPE-AHN), an algorithm for fast and robust training of supervised AHN models in high-dimensional data. This training method comprises a population-based meta-heuristic optimization with defined individual encoding and objective function related to the AHN-model, an implementation in parallel-computing, and a stochastic learning approach for consuming large data. We conducted three experiments with synthetic and real data sets to validate the training execution time and performance of the proposed algorithm. Experimental results demonstrated that the proposed SPE-AHN outperforms the original-AHN method, increasing the speed of training more than 
                        
                           10
                           ,
                           000
                           x
                        
                      times in the worst case scenario. Additionally, we present two case studies in real data sets for solar-panel deployment prediction (regression problem), and human falls and daily activities classification in healthcare monitoring systems (classification problem). These case studies showed that SPE-AHN improves the state-of-the-art machine learning models in both engineering problems. We anticipate our new training algorithm to be useful in many applications of AHN like robotics, finance, medical engineering, aerospace, and others, in which large amounts of data (e.g. big data) is essential.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2019.101787,Journal,Biomedical Signal Processing and Control,scopus,2020-03-01,sciencedirect,An efficient error-minimized random vector functional link network for epileptic seizure classification using VMD,https://api.elsevier.com/content/abstract/scopus_id/85076002241,"In this paper, variational mode decomposition (VMD), Hilbert transform (HT), and proposed error-minimized random vector functional link network (EMRVFLN) are integrated to detect and classify epileptic seizure from electroencephalogram (EEG) signals. VMD is applied to decompose the EEG signal into Band-limited intrinsic mode functions (BLIMFs). The five efficacious instantaneous features are computed using HT to construct the feature vector. Proposed EMRVFLN classifier is used to classify the epileptic seizure. The performances of the proposed EMRVFLN are compared with recently developed classifiers such as least-square support vector machine (LSSVM) and extreme learning machine (ELM). The combination of VMD and HT with proposed EMRVFLN classifier outperforms other state-of-the-art methods with classification accuracy of 100% for two class classification problem and 99.74% for three class classification problem. The remarkable classification accuracy facilitates the digital implementation of the proposed EMRVFLN classifier which may aid to design an embedded system for real-time disease diagnosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2019.10.043,Journal,Future Generation Computer Systems,scopus,2020-03-01,sciencedirect,HealthFog: An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments,https://api.elsevier.com/content/abstract/scopus_id/85074613864,"Cloud computing provides resources over the Internet and allows a plethora of applications to be deployed to provide services for different industries. The major bottleneck being faced currently in these cloud frameworks is their limited scalability and hence inability to cater to the requirements of centralized Internet of Things (IoT) based compute environments. The main reason for this is that latency-sensitive applications like health monitoring and surveillance systems now require computation over large amounts of data (Big Data) transferred to centralized database and from database to cloud data centers which leads to drop in performance of such systems. The new paradigms of fog and edge computing provide innovative solutions by bringing resources closer to the user and provide low latency and energy efficient solutions for data processing compared to cloud domains. Still, the current fog models have many limitations and focus from a limited perspective on either accuracy of results or reduced response time but not both. We proposed a novel framework called HealthFog for integrating ensemble deep learning in Edge computing devices and deployed it for a real-life application of automatic Heart Disease analysis. HealthFog delivers healthcare as a fog service using IoT devices and efficiently manages the data of heart patients, which comes as user requests. Fog-enabled cloud framework, FogBus is used to deploy and test the performance of the proposed model in terms of power consumption, network bandwidth, latency, jitter, accuracy and execution time. HealthFog is configurable to various operation modes which provide the best Quality of Service or prediction accuracy, as required, in diverse fog computation scenarios and for different user requirements.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105132,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-03-01,sciencedirect,Virtual reality-based measurement of ocular deviation in strabismus,https://api.elsevier.com/content/abstract/scopus_id/85073938186,"Background and objective
                  Strabismus is an eye movement disorder in which shows the abnormal ocular deviation. Cover tests have mainly been used in the clinical diagnosis of strabismus for treatment. However, the whole process depends on the doctor's level of experience, which could be subjected to several factors. In this study, an automated technique for measurement of ocular deviation using a virtual reality (VR) device is developed.
               
                  Methods
                  A VR display system in which the screens that have the fixation target are changed alternately between on and off stages is used to simulate the normal strabismus diagnosis steps. Patients watch special-designed 3D scenes, and their eye motions are recorded by two infrared (IR) cameras. An image-processing-based pupil tracking technique is then applied to track their eye movement. After recording eye motion, two strategies for strabismus angle estimation are implemented: direct measurement and stepwise approximation. The direct measurement converts the eye movement to a strabismus angle after considering the eyeball diameter, while the stepwise approximation measures the ocular deviation through the feedback calibration process.
               
                  Results
                  Experiments are carried out with various strabismus patients. The results are compared to those of their doctors’ measurement, which shows good agreement.
               
                  Conclusions
                  The results clearly indicate that these techniques could identify ocular deviation with high accuracy and efficiency. The proposed system can be applied in small space and has high tolerance for the unexpected head movements compared with other camera-based system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.105277,Journal,Computer Methods and Programs in Biomedicine,scopus,2020-02-01,sciencedirect,An extensible software platform for interdisciplinary cardiovascular imaging research,https://api.elsevier.com/content/abstract/scopus_id/85076945151,"Background and objective
                  Cardiovascular imaging is an exponentially growing field with aspects ranging from image acquisition and analysis to disease characterization, and evaluation of therapy approaches.The transfer of innovative new technological and algorithmic solutions into clinical practice is still slow. In addition to the verification of solutions, their integration in the clinical processing workflow must be enabled for the assessment of clinical impact and risks. The goal of our software platform for cardiac image processing – CAIPI – is to support researchers from different specialties such as imaging physics, computer science, and medicine by a common extensible platform to address typical challenges and hurdles in interdisciplinary cardiovascular imaging research. It provides an integrated solution for method comparison, integrated analysis, and validation in the clinical context. The interface concept enables a combination with existing frameworks that address specific aspects of the pipeline, such as modeling (e.g., OpenCMISS, CARP) or image reconstruction (Gadgetron).
               
                  Methods
                  In our platform, we developed a concept for import, integration, and management of cardiac image data. The integration approach considers the spatiotemporal properties of the beating heart through a specific data model. The solution is based on MeVisLab and provides functionalities for data retrieval and storage. Two types of plugins can be added. While ToolPlugins usually provide processing algorithms such as image correction and segmentation, AnalysisPlugins enable interactive data exploration and reporting. GUI integration concepts are presented for both plugin types. We developed domain-specific reporting and visualization tools (e.g., AHA segment model) to enable validation studies by clinical experts. The platform offers plugins for calculating and reporting quantitative parameters such as cardiac function, which can be used to, e.g., evaluate the effect of processing algorithms on clinical parameters. Export functionalities include quantitative measurements to Excel, image data to PACS, and STL models to modeling and simulation tools.
               
                  Results
                  To demonstrate the applicability of this concept both for method development and clinical application, we present use cases representing different problems along the innovation chain in cardiac MR imaging.
                  Validation of an image reconstruction method (MRI T1 mapping)
                  Validation of an image correction method for real-time 2D-PC MRI
                  Comparison of quantification methods for blood flow analysis
                  Training and integration of machine learning solutions with expert annotations
                  Clinical studies with new imaging techniques (flow measurements in the carotid arteries and peripheral veins as well as cerebral spinal fluid).
               
                  Conclusion
                  The presented platform can be used in interdisciplinary teams, in which engineers or data scientists perform the method validation, followed by clinical research studies in patient collectives. The demonstrated use cases show how it enables the transfer of innovations through validation in the cardiovascular application context.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2019.102929,Journal,Microprocessors and Microsystems,scopus,2020-02-01,sciencedirect,A Fog-Cloud based cyber physical system for Ulcerative Colitis diagnosis and stage classification and management,https://api.elsevier.com/content/abstract/scopus_id/85075315081,"Ulcerative Colitis is a fairly common, chronic or long-term disease that causes inflammation of the large intestine. It can be debilitating and can sometimes lead to life threatening complications. Therefore, its diagnosis in nascent stages is important. Healthcare services based on Fog-Cloud assisted Cyber-Physical Systems are emerging as a proactive and efficacious solution to provide remote monitoring of individuals for early detection and consequent management of several diseases. This paper presents a novel IoT-Fog-Cloud assisted Cyber Physical System for diagnosis and stage classification of Ulcerative Colitis using Naïve Bayes classifier and Deep Neural Network respectively. A vital point of this paper is real-time alert generation from Fog Layer in case the user need emergency treatment if he/she is already diagnosed with UC. Finally, analysis results and compiled medical information of each user is stored on cloud. Implementation results of the proposed framework proves its efficiency in diagnosis and subsequent stage classification of Ulcerative Colitis with real-time classification mechanism at fog layer. Furthermore, alert generation improves the efficacy of the proposed system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.103336,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-02-01,sciencedirect,Fault location estimation for series-compensated double-circuit transmission line using EWT and weighted RVFLN,https://api.elsevier.com/content/abstract/scopus_id/85075028838,"In this paper, empirical Wavelet transform (EWT), Hilbert transform (HT) and weighted random vector functional link network (WRVFLN) are integrated for fault detection, classification, and location estimation in a series capacitor compensated double circuit transmission line (SCCDCTL). The full cycle current signals from the point of fault inception are decomposed using EWT to extract three band-limited modes (BLMs). The four efficacious instantaneous features namely energy, Shannon entropy, the standard deviation of the magnitude, and crest factor are computed from the Hilbert transformed array of the BLMs to construct the feature vector. A diagonal matrix W is computed from the zero sequence current of original six current signals as a weighting factor to categorize the ground fault accurately. Numerous faults are generated with a wide variation of the system conditions such as fault resistance, fault inception angle, fault distance, percentage compensation level, source impedance, line parameters, load angle, and inter-circuit fault in MATLAB/Simulink environments. An efficient WRVFLN computational intelligence technique is proposed to recognize and estimate the location of the faults by taking the extracted suitable feature vector with weight factor as an input. The performances of WRVFLN are compared with the recently developed advanced classifiers such as least-square support vector machine (LSSVM) and extreme learning machine (ELM) in the MATLAB interface. The lesser computational complexity, faster learning speed, superior classification accuracy, accurate fault location estimation, and short event detection time prove that the proposed EWTHT–WRVFLN method can be implemented in the real power system for online fault diagnosis. Finally, the developed system architecture is implemented on the reconfigurable digital field programmable gate array (FPGA) in ISE design suite 14.5 environments to verify the cogency of the proposed method in real-time. The feasibility of the proposed method is tested and validated by using the fast FPGA digital circuitry in a loop.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.breast.2019.10.001,Journal,Breast,scopus,2020-02-01,sciencedirect,"The ethical, legal and social implications of using artificial intelligence systems in breast cancer care",https://api.elsevier.com/content/abstract/scopus_id/85074099299,"Breast cancer care is a leading area for development of artificial intelligence (AI), with applications including screening and diagnosis, risk calculation, prognostication and clinical decision-support, management planning, and precision medicine. We review the ethical, legal and social implications of these developments. We consider the values encoded in algorithms, the need to evaluate outcomes, and issues of bias and transferability, data ownership, confidentiality and consent, and legal, moral and professional responsibility. We consider potential effects for patients, including on trust in healthcare, and provide some social science explanations for the apparent rush to implement AI solutions. We conclude by anticipating future directions for AI in breast cancer care. Stakeholders in healthcare AI should acknowledge that their enterprise is an ethical, legal and social challenge, not just a technical challenge. Taking these challenges seriously will require broad engagement, imposition of conditions on implementation, and pre-emptive systems of oversight to ensure that development does not run ahead of evaluation and deliberation. Once artificial intelligence becomes institutionalised, it may be difficult to reverse: a proactive role for government, regulators and professional groups will help ensure introduction in robust research contexts, and the development of a sound evidence base regarding real-world effectiveness. Detailed public discussion is required to consider what kind of AI is acceptable rather than simply accepting what is offered, thus optimising outcomes for health systems, professionals, society and those receiving care.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2019.102906,Journal,Microprocessors and Microsystems,scopus,2020-02-01,sciencedirect,Area and power efficient pipelined hybrid merged adders for customized deep learning framework for FPGA implementation,https://api.elsevier.com/content/abstract/scopus_id/85073599282,"With the rapid growth of deep learning and neural network algorithms, various fields such as communication, Industrial automation, computer vision system and medical applications have seen the drastic improvements in recent years. However, deep learning and neural network models are increasing day by day, while model parameters are used for representing the models. Although the existing models use efficient GPU for accommodating these models, their implementation in the dedicated embedded devices needs more optimization which remains a real challenge for researchers. Thus paper, carries an investigation of deep learning frameworks, more particularly as review of adders implemented in the deep learning framework. A new pipelined hybrid merged adders (PHMAC) optimized for FPGA architecture which has more efficient in terms of area and power is presented. The proposed adders represent the integration of the principle of carry select and carry look ahead principle of adders in which LUT is re-used for the different inputs which consume less power and provide effective area utilization. The proposed adders were investigated on different FPGA architectures in which the power and area were analyzed. Comparison of the proposed adders with the other adders such as carry select adders (CSA), carry look ahead adder (CLA), Carry skip adders and Koggle Stone adders has been made and results have proved to be highly vital into a 50% reduction in the area, power and 45% when compared with above mentioned traditional adders.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2019.120446,Journal,Talanta,scopus,2020-02-01,sciencedirect,Paper-based colorimetric spot test utilizing smartphone sensing for detection of biomarkers,https://api.elsevier.com/content/abstract/scopus_id/85073026488,"The need for a continuous, real-time monitoring of specific diseases represents an unmet scientific need. Evidently, cancer is one of the most important diseases where it is crucial to increase the rates of patient survival and monitor disease prognosis. Herein, a novel type of immunoassay was developed for detection of cancer biomarkers, using alpha-fetoprotein (AFP) and mucin-16 (MUC16) as model analytes. Using gold nanoparticle (AuNP) bioconjugates as a signal production tool, relevant antibody (Ab)-conjugated AuNPs were prepared on the nitrocellulose (NC) membrane. To construct a spot-like point-of-care (POC) immunoassay, cysteamine conjugated AuNPs (AuNP-Cys) were immobilized on the NC membrane and antibodies were conjugated to the nanoparticle on the detection pad, following a treatment with the samples that contains AFP or MUC16 which are well-known protein biomarkers for liver and ovarian cancer. By using the change in the colorimetric properties of AuNPs, detection of tumor markers was achieved by using a smartphone image and color analysis software at the final stage. Image J application was used for the evaluation of color changes depending on the biomarker concentration in buffer or spiked synthetic serum samples. The linear range was found as 0.1 ng/mL-100 ng/mL for AFP and 0.1–10 ng/mL for MUC16. Limit-of-detection (LOD) was calculated as 1.054 ng/mL and 0.413 ng/mL for AFP and MUC16, respectively. Interferent molecules, Her2, Immunoglobulin G (IgG) and bovine serum albumin (BSA) were tested on the system. Furthermore, synthetic serum samples spiked with selected analyte molecule were applied on the system and measured successfully.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-818576-6.00004-6,Book,Artificial Intelligence to Solve Pervasive Internet of Things Issues,scopus,2020-01-01,sciencedirect,"AI and IoT Capabilities: Standards, Procedures, Applications, and Protocols",https://api.elsevier.com/content/abstract/scopus_id/85125968641,"With the growing technology of hardware components like sensors, actuators, networking devices, and networks media with efficient software for data gathering and analysis, the Internet of Things (IoT) became more effective in real-world applications like healthcare, item tracking in supply chain, military, and prediction of seismic activity in volcanoes. Artificial intelligence (AI) is a branch of engineering based on mathematical techniques, which has potential to enhance many real-world application domains like healthcare, industrial automation, service sector, and so on. Machine learning (ML) is a form of thin AI, and is used to help or automate decision-making. The process of automated decision-making and making predictions is based on gathered data. This data gathering may be performed through IoT. The AI and IoT are clearly intersecting each other as AI simulates intelligent behavior through different kind of machines whereas IoT interconnects these machines and help in collecting data. This chapter will discuss state-of-the-art methods, standards, protocols, and applications of IoT and making smart IoT with AI. The chapter also discusses AI approaches to make Intelligent IoT.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-823337-5.00010-X,Book,Intelligence-Based Medicine: Artificial Intelligence and Human Cognition in Clinical Medicine and Healthcare,scopus,2020-01-01,sciencedirect,Key Concepts of the Future of Artificial Intelligence,https://api.elsevier.com/content/abstract/scopus_id/85124924379,"The future of artificial intelligence (AI) and its application in medicine are concomitantly challenging and remarkable. While there is some hype around the portfolio of AI tools and their deployment in medicine, especially with medical image interpretation, the long-term dividend remains underestimated. The myriad of emerging tools that are relevant to AI in medicine are the next-generation 5G connectivity; augmented, virtual, and mixed reality (medical extended reality); blockchain and its implications for cybersecurity and data privacy; brain–computer interface as a dimension of increased human cognition in AI; capsule network and the next phase of deep learning; cloud computing imbued with AI technology; edge computing and embedded AI as part of the evolution toward Internet of Everything; fuzzy cognitive maps combined with neural networks to form fuzzy cognitive maps; generative query network and its capability to learn on its own; hypergraph database as a disruptive innovation in databases; low-shot learning as a novel way to learn from small data; neuromorphic computing; quantum computing as a futuristic approach to computing; recursive and spiking neural networks as neural network variants with cognitive elements; swarm intelligence as a mechanism to incorporate crowd wisdom; temporal convolutional nets as a superior tool to recurrent neural network; and finally, transfer learning as a way to render learning more efficient. As promising as these developments and advances are, innovation also needs to be part of health -care data and databases as this is the foundation of future AI applications in medicine and health care.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-819246-7.00012-7,Book,"Wearable Sensors: Fundamentals, Implementation and Applications",scopus,2020-01-01,sciencedirect,From wearables to THINKables: Artificial intelligence-enabled sensors for health monitoring,https://api.elsevier.com/content/abstract/scopus_id/85123587536,"Wearable sensors are being used in clinical settings to monitor the condition of patients as well as in recreational environments for routine health monitoring. Some of the most advanced clinical applications include monitoring patients with Parkinson's disease through wearable inertial measuring units (IMUs) and patients with diabetes by means of wearable glucose sensors. Prominent examples of wearable sensors in routine use are fitness trackers, step-and calorie counters. Recently, wearables have evolved to being capable of running artificial intelligence algorithms in real-time at the point of sensing which allows to gain analytical insights directly from measurement data. We call such intelligent wearables with AI-at-the-edge functionality THINKables. First use cases for THINKables have emerged in both clinical and nonclinical applications: real-time seizure prediction or detection systems for epilepsy patients, or digital coaches providing real-time feedback to athletes on performance and injury risks. Technological and regulatory challenges of developing and deploying THINKables are multifold: data privacy and security of monitoring data needs to be ensured at all times, analytical AI models need to be transparent, explainable and fair, and all these features need to be implemented taking the limited computing power of point-of-sensing processors into account. In order for THINKables to become integrated into clinical workflows, all stakeholders in the Health AI ecosystem (regulators, clinicians, biomedical device technologists, pharma and biotech sectors, data scientists, and patients) need to work together to create frameworks for responsible and meaningful use.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2020.12.751,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,Intelligent comprehensive Occupational health monitoring system for mine workers,https://api.elsevier.com/content/abstract/scopus_id/85119604308,The objective of this work is to present a comprehensive occupational health monitoring system which provides the current state of the occupational health for mine workers. The hearing threshold shift and dust exposure of each individual mine worker is monitored using this system. The data obtained from the system is transmitted via Internet of Things to storage which may be cloud or a server. The novelty of this model lies in its dual ability to monitor both Noise Induced Hearing Loss and Pneumoconiousis which is caused by inhalation of dust particles. The output of this dual system is further processed using Machine learning and artificial intelligence techniques. Recommendations are then provided to the mine worker with regards to their state of health. This system forms part of an early intervention system in the mines. The model was validated using real data from a Platinum mine in South Africa. Future improvement to this work would entail refinement of the current preliminary implementation plan and carrying out the first phase of the implementation.,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-823014-5.00001-6,Book,Handbook of Deep Learning in Biomedical Engineering: Techniques and Applications,scopus,2020-01-01,sciencedirect,Early detection and diagnosis using deep learning,https://api.elsevier.com/content/abstract/scopus_id/85113589982,"With the growth of technology in every sphere, an attempt of reducing the human effort and increasing the accuracy of the system is always focused, and with the introduction to artificial intelligence (AI), we have covered almost every single domain in real-world scenario. The applications of AI are endless, and its use has helped in transforming the daily life through different use cases; under it, some of the highlighted examples for which it is well known in every sphere are natural language processing, self-driving cars, image processing, and so on. As it covers different domains of each sector, it also plays a significant role in healthcare sector. Influencing the sector entirely, it focuses on the end number of things that are part of this sector. When it approaches our health, specifically in matter when life and death are involved, the potential of AI to advance the consequences is enthralling. According to a survey, it has found that AI, specifically deep learning (DL), has the power to replace the whole discipline of medicine and is able to generate new characters for doctors called as information specialists. DL compromises substantial potential for medical diagnostics. There were times when detecting diseases was a tough task, but now with DL at rescue, diseases can be not only cured but also predicted at earlier stages. Chronic diseases such as Alzhiemer's disease, cancer, tumor, and much more can only be predicted by the advanced DL methods of prediction. Medical image processing plays a major role in detection and pinpointing of the exact problem it is leading to. The systems developed are smart enough to learn through the real cases and train the model as per the requirement, leading to the better prediction, detection, or providing with the methods of curing. Not only early-stage diagnosis is focused, but AI-assisted surgeries have also started taking place and AI-assisted nurses are also deployed for each patient to reduce the chances of errors. Mostly every problem of the healthcare sector whether it is administrative or medical or technical is majorly solved or falls under the category of DL, and many more researches related to this are under process.
               This chapter will help in determining how DL helps in the early diagnosis of several diseases such as Alzheimer's disease, rheumatic diseases, autism spectrum disorder, and more. After expanding upon the basics of DL and biomedical engineering, this chapter explores more upon diagnostics using DL and discusses the early diagnosis of certain diseases.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2020.12.2856,Conference Proceeding,IFAC-PapersOnLine,scopus,2020-01-01,sciencedirect,A deep learning unsupervised approach for fault diagnosis of household appliances,https://api.elsevier.com/content/abstract/scopus_id/85107800132,Fault detection and fault diagnosis are crucial subsystems to be integrated within the control architecture of modern industrial processes to ensure high quality standards. In this paper we present a two-stage unsupervised approach for fault detection and diagnosis in household appliances. In particular a suitable testing procedure has been implemented on a real industrial production line in order to extract the most meaningful features that allow to efficiently classify different types of fault by consecutively exploiting deep autoencoder neural network and k-means or hierarchical clustering techniques.,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-821326-1.00007-3,Book,An Industrial IoT Approach for Pharmaceutical Industry Growth: Volume 2,scopus,2020-01-01,sciencedirect,Internet of Things: From hype to reality,https://api.elsevier.com/content/abstract/scopus_id/85105522320,"The era of the Internet of Things (IoT) is sweeping over and replacing the Internet creating a world where smart things exist connected to each other intelligently. This was predicted by Eric Emerson Schmidt, the former C.E.O. of Google over 20 years ago. The physical world is now connecting to the digital world so quickly with the emergence of the IoT that it seems the Internet will become invisible soon, meaning the physical world will be connecting to the digital world seamlessly. The world will enjoy smart connectivity in the same way that the city of Barcelona has emerged to be the smartest city in the world. We are moving toward system-to-system connection, with smart networking reaching its peak. The idea of software-defined autonomous machines is about to become hugely important, which will become ubiquitous. With the advent of the IoT, we explore how it is becoming a reality and whether it has any limits. Maciej Kranz in his book on the IoT explains the very essential detailed and inclusive idea of the IoT, with IoT expanding to businesses, and covering and impacting on a variety of technology areas. Artificial intelligence and machine learning have a huge scope because of the enormous data generated by sensors and devices connected through the IoT. We will explore in this chapter the hype around the IoT and the reality. We will also discover improved metrics in the IoT that is allowing it to be a leader in the technological world. We are witnessing the fourth revolution in the digitization world and discuss the reasons behind its exponential growth. The protocols that differentiate them from others have evolved for IOT in a new set of patterns. This also creates security concerns and data are described as the new oil, raising further challenges of data privacy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.matpr.2020.08.718,Conference Proceeding,Materials Today: Proceedings,scopus,2020-01-01,sciencedirect,Hybrid clustering algorithm for an efficient brain tumor segmentation,https://api.elsevier.com/content/abstract/scopus_id/85102451494,"This work describes the data mining methods, techniques and algorithms used for implementation. It is an emerging field of IT industry and research. There are many other fields such as Artificial Intelligence, Machine Learning, Deep Learning, Virtualization, Visualization, Parallel Computing and Image Processing. The human internal Brain can be seen or visualized by the Magnetic Resonance Imaging scan or Computerized Tomography scan. The MRI image is scanned and will be taken as input for processing. The MRI scan is more advantageous and more comfortable than CT scan for diagnosis. MRI scan provides detailed picture of organs. It does not affect the human health and body condition. It doesn't use any radiation. It is purely based on the magnetic field and radio waves. LIPC technique makes the training samples from the patients and arranges them into different group of classes used to construct different dictionaries. Image segmentation is a technique of dividing an image into different multiple portions, which is used to spot out objects and boundaries in images. There are many image segmentation techniques applicable for image processing. No acceptable method is available for solving all kinds of segmentation problem. Every method has merits and demerits. So, choosing good method is the challenging task. The hybrid clustering method is proposed in this work. The k-means algorithm and fuzzy c-means algorithm is proposed for brain tumor segmentation. The algorithm is implemented in synthetic and real time dataset. From the experimental results, this method provides better results in the form of accuracy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.05.140,Conference Proceeding,,scopus,2020-01-01,sciencedirect,Development of real-time diagnosis framework for angular misalignment of robot spot-welding system based on machine learning,https://api.elsevier.com/content/abstract/scopus_id/85095131276,"This paper focuses on the real-time online monitoring and diagnosis framework for the angular misalignment of the robot spot-welding system, which can result in significant quality degradation of a weld nugget such as porosity. The data-driven approach is applied by installing the voltage and current sensors, collecting the associated mass data and processing them under normal and abnormal (angular misalignment) conditions. Two categories of features are extracted from the dynamic resistance (DR) and the voltage and current ones that are decomposed by wavelet transform (WT). The DR features are extracted from the DR profile and some critical features are selected by a t-test methodology. In the case of the WT-based features, the critical ones are selected by a max-relevance and min-redundancy (mRMR) and a sequential backward selection (SBS) wrapper. Consequently, three types of critical feature sets, such as DR features, WT features, and hybrid features combining those, are prepared to train machine learning-based models. Support vector machine (SVM) and probabilistic neural network (PNN) are applied to establish the diagnosis models, and the diagnostic accuracy and robustness are evaluated. Finally, the software for the on-line monitoring and diagnosis for angular misalignment of robot spot-welding system is developed and demonstrates its real-time applicability in an industrial site.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2020.103344,Journal,Microprocessors and Microsystems,scopus,2020-01-01,sciencedirect,Medical information retrieval systems for e-Health care records using fuzzy based machine learning model,https://api.elsevier.com/content/abstract/scopus_id/85094859542,"As other sectors advance through the aid of cognitive computing, whereas the health care sector is still evolving, offering more advantages for all consumers. The growing complexities of healthcare are compounded by an aging population that contributes to underprivileged decision-making contributing to adverse impacts on the standard of treatment and raises the cost of treatment. Advances in this field, however, is hampered by numerous challenges that create a gap between the knowledge base and user queries, query inconsistencies, and user domain information set. In recent years, the rapid development with the use of machine learning and artificial intelligence for medical applications has already been shown, from diagnostic heart failure to 1-D cardiovascular beatings and automated finding using multi-dimensional clinical data. Consequently, smart decision support structures are required, which can enable clinicians to make more informed treatment decisions. An innovative solution is to harness increasing healthcare digitization that produces enormous volumes of clinical data contained in e-HCR and merge it with advanced ML software to improve clinical decision-making, thus extending the medication evidence base at the same time. Through this work, we are investigating new methodologies as well as digging at specific real-life technologies already being implemented in the medical sector and concentrating mainly on studying about accurate depictions of patients from e-HCR.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.07.028,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,A mobile clinical DSS based on augmented reality and deep learning for the home cares of patients afflicted by bedsores,https://api.elsevier.com/content/abstract/scopus_id/85094582861,"A bedsore, also known as pressure sore, pressure ulcer or decubitus ulcer, is the result of constant pressure on skin occurring in bedridden patients and paraplegics continuously sitting in chair. All patients who are immobile for a long time due to any cause are likely to get bedsores. Effective and efficient management of processes related to the treatment of bedsores is an important issue for healthcare organizations as it heavily affects the quality of life of patients and the costs for such organizations. Therefore organizations need and look for more and more to provide their field workforce with smart mobile tools able to support such processes. In such a context, this paper proposes a mobile app implementing a Clinical Decision Support System (CDSS) to help field operators to measure the bedsore, classify its status, trace its evolution along the timeline and making correct decisions about the course of actions to effectively treat it. The mobile app is mostly based on Augmented Reality supported by Deep Learning, thus it requires an adequate system architecture to be effectively deployed, adopted and used. From the conceptual viewpoint, the defined CDSS model lays on three important considerations: providing automatic support to classify the status of a bedsore does not do all the work but help operators to improve the quality of their decisions, augmented reality allows to build a situated environment for decision-making supporting the operators’ cognitive processes, operators should use only one tool to execute all their tasks in order to be more focused on the real problem which is to improve the quality of life of their patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.03.004,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Activity Recognition in Smart Homes using UWB Radars,https://api.elsevier.com/content/abstract/scopus_id/85085563629,"In the last decade, smart homes have transitioned from a potential solution for aging-in-place to a real set of technologies being deployed in the real-world. This technological transfer has been mostly supported by simple, commercially available sensors such as passive infrared and electromagnetic contacts. On the other hand, many teams of research claim that the sensing capabilities are still too low to offer accurate, robust health-related monitoring and services. In this paper, we investigate the possibility of using Ultra-wideband (UWB) Doppler radars for the purpose of recognizing the ongoing ADLs in smart homes. Our team found out that with simple configuration and classical features engineering, a small set of UWB radars could reasonably be used to recognize ADLs in a realistic home environment. A dataset was built from 10 persons performing 15 different ADLs in a 40 square meters apartment with movement on the other side of the wall. Random Forest was able to attain 80% accuracy with an F1-Score of 79%, and a Kappa of 77%. Those results indicate the use of Doppler radars can be a good research avenue for smart homes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.03.036,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Air Quality Forecasting using LSTM RNN and Wireless Sensor Networks,https://api.elsevier.com/content/abstract/scopus_id/85085553433,"In the past few decades, many urban areas around the world have suffered from severe air pollution and the health hazards that come with it, making gathering real-time air quality and air quality forecasting very important to take preventive and corrective measures. This paper proposes a scalable architecture to monitor and gather real-time air pollutant concentration data from various places and to use this data to forecast future air pollutant concentrations. Two sources are used to collect air quality data. The first being a wireless sensor network that gathers and sends pollutant concentrations to a server, with its sensor nodes deployed in various locations in Bengaluru city in South India. The second source is the real-time air quality data gathered and made available by the Government of India as a part of its Open Data initiative. Both sources provide average concentrations of various air pollutants on an hourly basis. Due to its proven track record of success with time-series data, a Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) model was chosen to perform the task of air quality forecasting. This paper critically analyses the performance of the model in two regions that exhibit a significant difference in temporal variations in air quality. As these variations increase, the model suffers performance degradation necessitating adaptive modelling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/bs.pmbts.2020.04.003,Book Series,Progress in Molecular Biology and Translational Science,scopus,2020-01-01,sciencedirect,Correlation and association analyses in microbiome study integrating multiomics in health and disease,https://api.elsevier.com/content/abstract/scopus_id/85085165614,"Correlation and association analyses are one of the most widely used statistical methods in research fields, including microbiome and integrative multiomics studies. Correlation and association have two implications: dependence and co-occurrence. Microbiome data are structured as phylogenetic tree and have several unique characteristics, including high dimensionality, compositionality, sparsity with excess zeros, and heterogeneity. These unique characteristics cause several statistical issues when analyzing microbiome data and integrating multiomics data, such as large p and small n, dependency, overdispersion, and zero-inflation. In microbiome research, on the one hand, classic correlation and association methods are still applied in real studies and used for the development of new methods; on the other hand, new methods have been developed to target statistical issues arising from unique characteristics of microbiome data. Here, we first provide a comprehensive view of classic and newly developed univariate correlation and association-based methods. We discuss the appropriateness and limitations of using classic methods and demonstrate how the newly developed methods mitigate the issues of microbiome data. Second, we emphasize that concepts of correlation and association analyses have been shifted by introducing network analysis, microbe-metabolite interactions, functional analysis, etc. Third, we introduce multivariate correlation and association-based methods, which are organized by the categories of exploratory, interpretive, and discriminatory analyses and classification methods. Fourth, we focus on the hypothesis testing of univariate and multivariate regression-based association methods, including alpha and beta diversities-based, count-based, and relative abundance (or compositional)-based association analyses. We demonstrate the characteristics and limitations of each approaches. Fifth, we introduce two specific microbiome-based methods: phylogenetic tree-based association analysis and testing for survival outcomes. Sixth, we provide an overall view of longitudinal methods in analysis of microbiome and omics data, which cover standard, static, regression-based time series methods, principal trend analysis, and newly developed univariate overdispersed and zero-inflated as well as multivariate distance/kernel-based longitudinal models. Finally, we comment on current association analysis and future direction of association analysis in microbiome and multiomics studies.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2020.03.236,Conference Proceeding,Procedia Computer Science,scopus,2020-01-01,sciencedirect,Deep Convolutional Neural Network based Detection System for Real-time Corn Plant Disease Recognition,https://api.elsevier.com/content/abstract/scopus_id/85084445610,"Corn is one of the most popular food grains in the India and crop loss due to diseases substantially affects the Indian economy and threatens the food availability. Recent access of smart devices can be utilized to provide automatic diagnosis of corn diseases and prevent severe crop losses. This paper presents a real time method based on deep convolutional neural network for corn leaf disease recognition. Deep neural network performance is improved by tuning the hyper-parameters and adjusting the pooling combinations on a system with GPU. Further, the number of parameters of the developed model is optimized to make it suitable for real time inference. The pre-trained deep CNN model was deployed onto raspberry pi 3 using Intel Movidius Neural Compute Stick consisting dedicated CNN hardware blocks. During the recognition of corn leaf diseases, the deep learning model achieves an accuracy of 88.46% demonstrating the feasibility of this method. The presented corn plant disease recognition model is capable of running on standalone smart devices like raspberry-pi or smart-phone and drones.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2020.100335,Journal,Informatics in Medicine Unlocked,scopus,2020-01-01,sciencedirect,Spark Architecture for deep learning-based dose optimization in medical imaging,https://api.elsevier.com/content/abstract/scopus_id/85084287220,"Background and objectives
                  Deep Learning (DL) and Machine Learning (ML) have brought several breakthroughs to biomedical image analysis by making available more consistent and robust tools for the identification, classification, reconstruction, denoising, quantification, and segmentation of patterns in biomedical images. Recently, some applications of DL and ML in Computed Tomography (CT) scans for low dose optimization were developed. Nowadays, DL algorithms are used in CT to perform replacement of missing data (processing technique) such as low dose to high dose, sparse view to full view, low resolution to high resolution, and limited angle to full angle. Thus, DL comes with a new vision to process biomedical data imagery from CT scan. It becomes important to develop architectures and/or methods based on DL algorithms for minimizing radiation during a CT scan exam thanks to reconstruction and processing techniques.
               
                  Methods
                  This paper describes DL for CT scan low dose optimization, shows examples described in the literature, briefly discusses new methods used in CT scan image processing, and offers conclusions. We based our study on the literature and proposed a pipeline for low dose CT scan image reconstruction. Our proposed pipeline relies on DL and the Spark Framework using MapReduce programming. We discuss our proposed pipeline with those proposed in the literature to conclude the efficiency and importance.
               
                  Results
                  An architecture for low dose optimization using CT imagery is suggested. We used the Spark Framework to design the architecture. The proposed architecture relies on DL, and permits us to develop efficient and appropriate methods to process dose optimization with CT scan imagery. The real implementation of our pipeline for image denoising shows that we can reduce the radiation dose, and use our proposed pipeline to improve the quality of the captured image.
               
                  Conclusion
                  The proposed architecture based on DL is complete and enables faster processing of biomedical CT imagery as compared with prior methods described in the literature.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2020.100324,Journal,Informatics in Medicine Unlocked,scopus,2020-01-01,sciencedirect,Sperm motility analysis system implemented on a hybrid architecture to produce an intelligent analyzer,https://api.elsevier.com/content/abstract/scopus_id/85082863547,"Much research and analysis in biomedicine involve image and video inspection using microscopes. Presently, scientists are dissatisfied with manual observations and assessments, when objective and enhanced data can be obtained by applying new technologies (such as image and video inspection) to biomedical fields, such as sperm analysis. Computer Assisted Sperm Analysis (CASA) systems, developed in the late 1980s, constitute third-generation methods of sperm analysis. This study aimed to develop a standalone medical image and video analysis system that is reconfigurable, flexible, reliable, deterministic, and robust. It proposed a new sperm motility analysis system running on a dual core Central Processing Unit (CPU) + field programmable gate arrays (FPGA) platform, under a real-time operating system (RTOS), which is a step ahead of the third-generation CASA systems.
                  The system hardware and related sperm detection and tracking algorithms were the novelty of this work. The image processing functions mainly run on FPGA, image acquisition, and calculations run on CPU, parallel with FPGA.
                  The result is a much faster, reliable, reconfigurable, and compact intelligent analyzer system.
                  Our prototype system was applied to sperm motility analysis; however, other image processing systems can be applied to this architecture. Additionally, the proposed tracking method for sperm track determination is simple, effective, and does not exert a load on the system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2019.104014,Journal,International Journal of Medical Informatics,scopus,2020-01-01,sciencedirect,Cost-effective survival prediction for patients with advanced prostate cancer using clinical trial and real-world hospital registry datasets,https://api.elsevier.com/content/abstract/scopus_id/85075365778,"Introduction
                  Predictive survival modeling offers systematic tools for clinical decision-making and individualized tailoring of treatment strategies to improve patient outcomes while reducing overall healthcare costs. In 2015, a number of machine learning and statistical models were benchmarked in the DREAM 9.5 Prostate Cancer Challenge, based on open clinical trial data for metastatic castration resistant prostate cancer (mCRPC). However, applying these models into clinical practice poses a practical challenge due to the inclusion of a large number of model variables, some of which are not routinely monitored or are expensive to measure.
               
                  Objectives
                  To develop cost-specified variable selection algorithms for constructing cost-effective prognostic models of overall survival that still preserve sufficient model performance for clinical decision making.
               
                  Methods
                  Penalized Cox regression models were used for the survival prediction. For the variable selection, we implemented two algorithms: (i) LASSO regularization approach; and (ii) a greedy cost-specified variable selection algorithm. The models were compared in three cohorts of mCRPC patients from randomized clinical trials (RCT), as well as in a real-world cohort (RWC) of advanced prostate cancer patients treated at the Turku University Hospital. Hospital laboratory expenses were utilized as a reference for computing the costs of introducing new variables into the models.
               
                  Results
                  Compared to measuring the full set of clinical variables, economic costs could be reduced by half without a significant loss of model performance. The greedy algorithm outperformed the LASSO-based variable selection with the lowest tested budgets. The overall top performance was higher with the LASSO algorithm.
               
                  Conclusion
                  The cost-specified variable selection offers significant budget optimization capability for the real-world survival prediction without compromising the predictive power of the model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ahj.2019.10.007,Journal,American Heart Journal,scopus,2020-01-01,sciencedirect,ECG AI-Guided Screening for Low Ejection Fraction (EAGLE): Rationale and design of a pragmatic cluster randomized trial,https://api.elsevier.com/content/abstract/scopus_id/85074666778,"Background
                  A deep learning algorithm to detect low ejection fraction (EF) using routine 12-lead electrocardiogram (ECG) has recently been developed and validated. The algorithm was incorporated into the electronic health record (EHR) to automatically screen for low EF, encouraging clinicians to obtain a confirmatory transthoracic echocardiogram (TTE) for previously undiagnosed patients, thereby facilitating early diagnosis and treatment.
               
                  Objectives
                  To prospectively evaluate a novel artificial intelligence (AI) screening tool for detecting low EF in primary care practices.
               
                  Design
                  The EAGLE trial is a pragmatic two-arm cluster randomized trial (NCT04000087) that will randomize >100 clinical teams (i.e., clusters) to either intervention (access to the new AI screening tool) or control (usual care) at 48 primary care practices across Minnesota and Wisconsin. The trial is expected to involve approximately 400 clinicians and 20,000 patients. The primary endpoint is newly discovered EF ≤50%. Eligible patients will include adults who undergo ECG for any reason and have not been previously diagnosed with low EF. Data will be pulled from the EHR, and no contact will be made with patients. A positive deviance qualitative study and a post-implementation survey will be conducted among select clinicians to identify facilitators and barriers to using the new screening report.
               
                  Summary
                  This trial will examine the effectiveness of the AI-enabled ECG for detection of asymptomatic low EF in routine primary care practices and will be among the first to prospectively evaluate the value of AI in real-world practice. Its findings will inform future implementation strategies for the translation of other AI-enabled algorithms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/bs.adcom.2019.09.005,Book Series,Advances in Computers,scopus,2020-01-01,sciencedirect,Impact of cloud security in digital twin,https://api.elsevier.com/content/abstract/scopus_id/85073737509,"Digital Twin is a way to virtually represent or model a physical object using the real time data. This innovation sets up a way to deal with industries and organizations to supervise their products, consequently bridging the gap between design and implementations. As the name suggests, “Digital Twin” infers that a reproduction of the product is made in order to have a nearby relationship with the live item. The procedure of computerized twin begins by gathering real time data, processed data, and operational data and performs distinctive investigation which helps in anticipating the future. This additionally enhances the customer experiences by giving a digital feel of their product. The objective behind all these is the job of gathering information and putting them in a place, i.e., the cloud which could store exorbitant data. The user experience gets enhanced by the intervention of digital twin technology which could help in the successful working of the products geographically distributed. The impact of Internet of Things and Cloud Computing lifts up the digital twin.
                  The information gathered from the sources can be arranged in terms of utilization and prospect to change on a timely basis. These data, as they are stored require proper coordination and a legitimate use.
                  Digital Twin innovation assumes incredible opportunities in the field of manufacturing, healthcare, smart cities, automobile and so on. The effect of having a digital twin for the product makes it simple for activities and recognize the blemishes, if any happened. This approach can help reduce the workload and furthermore can get trained on the virtual machine without the need of a specific training.
                  With the most prevailing technologies of today, like Artificial Intelligence, Machine Learning and Internet of Things more prominent approach to train and monitor products, taking care of its own execution, collaborating to different frameworks, performing self-repairs are made possible. Hence the future is getting unfolded with the emerging DIGITAL TWIN era. The massive data utilized in the field of digital twin is prone to severe security breaches. Thus digital twin technology should be handled with extreme care so as to protect the data. Hence, this chapter identifies the ways and means of collecting, organizing and storing the data in a secured cloud environment. The data is filtered according to the use and priority and pushed into the cloud. It is determined to implement an exclusive algorithm for a secured cloud which would greatly benefit the users and the providers to handle and process it effectively.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2019.103255,Journal,Engineering Applications of Artificial Intelligence,scopus,2020-01-01,sciencedirect,Therapy-driven Deep Glucose Forecasting,https://api.elsevier.com/content/abstract/scopus_id/85072863135,"The automatic regulation of blood glucose for Type 1 diabetes patients is the main goal of the artificial pancreas, a closed-loop system that exploits continue glucose monitoring data to define an optimal insulin therapy. One of the most successful approaches for developing the artificial pancreas is the model predictive control, which exhibits promising results on both virtual and real patients. The performance of such controller is highly dependent on the reliability of the glucose–insulin model used for prediction purpose, which is usually implemented with classic mathematical models. The main limitation of these models consists in the difficulties of modeling the physiological nonlinear dynamics typical of this system. The availability of big amount of in silico and in vivo data moved the attention to new data-driven methods which are able to easily overcome this problem. In this paper we propose Deep Glucose Forecasting, a deep learning approach for forecasting glucose levels, based on a novel, two-headed Long-Short Term Memory implementation. It takes in input the previous values obtained through continue glucose monitoring, the carbohydrate intake, the suggested insulin therapy and forecasts the interstitial glucose level of the patient. The proposed architecture has been trained on 100 virtual adult patients of the UVA/Padova simulator, and tested on both virtual and real patients. The proposed solution is able to generalize to new unseen data, outperforms classical population models and reaches performance comparable to classical personalized models when fine-tuning is exploited on real patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bjoms.2019.08.011,Journal,British Journal of Oral and Maxillofacial Surgery,scopus,2020-01-01,sciencedirect,Welcome the “new kid on the block” into the family: artificial intelligence in oral and maxillofacial surgery,https://api.elsevier.com/content/abstract/scopus_id/85072055163,"Recent decades have witnessed the genesis and progressive application of intelligent machines and computer programs that have the ability to process information and execute cognitive functions similar to those of human logic and reasoning such as problem solving and decision making. That is artificial intelligence (AI) in a nutshell as envisioned by John McCarthy, “the father of AI”. Healthcare has welcomed AI, giving rise to collaborations such as the Moorfields Eye Hospital and Google’s DeepMind division in the screening and predicting of retinal disease. The use of AI by the maxillofacial surgical fraternity is, however, limited. We wish to highlight the fact that surgeons are uniquely positioned to help drive these innovations rather than passively waiting for the technology to become useful.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2019.101638,Journal,Biomedical Signal Processing and Control,scopus,2020-01-01,sciencedirect,EEG mobility artifact removal for ambulatory epileptic seizure prediction applications,https://api.elsevier.com/content/abstract/scopus_id/85070796123,"Mobile monitoring of electroencephalogram (EEG) signals is prone to different sources of artifacts. Most importantly, motion-related artifacts present a major challenge hindering the clean acquisition of EEG data as they spread all over the scalp and across all frequency bands. This leads to additional complexity in the development of neurologically-oriented mobile health solutions. Among the top five most common neurological disorders, epilepsy has increasingly relied on EEG for diagnosis. Separate methods have been used to classify EEG segments in the context of epilepsy while reducing the existing mobility artifacts. This work specifically devises an approach to remove motion-related artifacts in the context of epilepsy. The proposed approach first includes the recording of EEG signals using a wearable EEG headset. The recorded signals are then colored by some motion artifacts generated in a lab-controlled experiment. This stage is followed by temporal and spectral characterization of the signals and artifact removal using independent component analysis (ICA). The proposed approach is tested using real clinical EEG data and results showed an average increase in accuracy of ∼9% in seizure detection and ∼24% in prediction.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.112843,Journal,Expert Systems with Applications,scopus,2020-01-01,sciencedirect,Intelligent image-based colourimetric tests using machine learning framework for lateral flow assays,https://api.elsevier.com/content/abstract/scopus_id/85070583607,"This paper aims to deliberately examine the scope of an intelligent colourimetric test that fulfils ASSURED criteria (Affordable, Sensitive, Specific, User-friendly, Rapid and robust, Equipment-free, and Deliverable) and demonstrate the claim as well. This paper presents an investigation into an intelligent image-based system to perform automatic paper-based colourimetric tests in real-time to provide a proof-of-concept for a dry-chemical based or microfluidic, stable and semi-quantitative assay using a larger dataset with diverse conditions. The universal pH indicator papers were utilised as a case study. Unlike the works done in the literature, this work performs multiclass colourimetric tests using histogram-based image processing and machine learning algorithm without any user intervention. The proposed image processing framework is based on colour channel separation, global thresholding, morphological operation and object detection. We have also deployed aserver-based convolutional neural network framework for image classification using inductive transfer learning on a mobile platform. The results obtained by both traditional machine learning and pre-trained model-based deep learning were critically analysed with the set evaluation criteria (ASSURED criteria). The features were optimised using univariate analysis and exploratory data analysis to improve the performance. The image processing algorithm showed >98% accuracy while the classification accuracy by Least Squares Support Vector Machine (LS-SVM) was 100%. On the other hand, the deep learning technique provided >86% accuracy, which could be further improved with a large amount of data. The k-fold cross-validated LS-SVM based final system, examined on different datasets, confirmed the robustness and reliability of the presented approach, which was further validated using statistical analysis. The understaffed and resource-limited healthcare system can benefit from such an easy-to-use technology to support remote aid workers, assist in elderly care and promote personalised healthcare by eliminating the subjectivity of interpretation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2019.06.019,Journal,Information Fusion,scopus,2020-01-01,sciencedirect,A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition,https://api.elsevier.com/content/abstract/scopus_id/85067959783,"With the rapid development of artificial intelligence and mobile Internet, the new requirements for human-computer interaction have been put forward. The personalized emotional interaction service is a new trend in the human-computer interaction field. As a basis of emotional interaction, emotion recognition has also introduced many new advances with the development of artificial intelligence. The current research on emotion recognition mostly focuses on single-modal recognition such as expression recognition, speech recognition, limb recognition, and physiological signal recognition. However, the lack of the single-modal emotional information and vulnerability to various external factors lead to lower accuracy of emotion recognition. Therefore, multimodal information fusion for data-driven emotion recognition has been attracting the attention of researchers in the affective computing filed. This paper reviews the development background and hot spots of the data-driven multimodal emotion information fusion. Considering the real-time mental health monitoring system, the current development of multimodal emotion data sets, the multimodal features extraction, including the EEG, speech, expression, text features, and multimodal fusion strategies and recognition methods are discussed and summarized in detail. The main objective of this work is to present a clear explanation of the scientific problems and future research directions in the multimodal information fusion for data-driven emotion recognition field.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1053/j.ajkd.2019.06.013,Journal,American Journal of Kidney Diseases,scopus,2019-12-01,sciencedirect,Continuous Renal Replacement Therapy Dosing in Critically Ill Patients: A Quality Improvement Initiative,https://api.elsevier.com/content/abstract/scopus_id/85072198500,"Rationale & Objective
                  Clinical practice guidelines recommend delivering a continuous renal replacement therapy (CRRT) dose of 20 to 25mL/kg/h. However, practice patterns nationwide are highly variable; this inconsistent prescribing may lead to errors in medication dosing and increase rates of electrolyte and acid-base abnormalities. We describe an initiative to standardize CRRT practice patterns and reduce dosing variability.
               
                  Study Design
                  Quality improvement study.
               
                  Setting & Participants
                  Adult patients treated with CRRT at the University of Colorado Hospital between January 2016 and October 2017.
               
                  Quality Improvement Activities
                  An assessment of the magnitude of the variability in CRRT dosing and the following specific interventions were implemented during the course of 1 year: (1) modification of the electronic medical record (EMR) to include calculated average 24-hour dose in real time, (2) modification of the CRRT procedure note to include comments on dosing, (3) modification of the CRRT order set to display calculations, and (4) yearly educational sessions for renal fellows outlining CRRT-specific dosing targets.
               
                  Outcomes
                  The primary outcome was weekly percentage of CRRT treatments with an average delivered daily dose of 20 to 25mL/kg/h. Process and balancing outcomes included CRRT flowsheet accuracy, documentation of rates of delivered dose, and nursing satisfaction.
               
                  Analytical Approach
                  Rates of weekly CRRT dosing in compliance with national guidelines were determined and used to create run charts showing compliance rates before and after the quality improvement interventions.
               
                  Results
                  Among 837 treatments before the intervention, 279 (33%) daily CRRT sessions achieved an average dose of 20 to 25mL/kg/h. Following implementation of interventions, 631 of 952 (66%) treatments achieved this goal. Week-to-week variation in dosing was significantly reduced.
               
                  Limitations
                  A single-center study generating data that may not be generalizable to institutions with different CRRT nursing models or different EMR systems.
               
                  Conclusions
                  Changes to the EMR and documentation templates and education of CRRT providers about dosing were associated with doubling of the rate of appropriate CRRT dosing and reduction in dosing variability.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2018.12.025,Journal,ISA Transactions,scopus,2019-12-01,sciencedirect,Deep residual learning-based fault diagnosis method for rotating machinery,https://api.elsevier.com/content/abstract/scopus_id/85059116434,"Effective fault diagnosis of rotating machinery has always been an important issue in real industries. In the recent years, data-driven fault diagnosis methods such as neural networks have been receiving increasing attention due to their great merits of high diagnosis accuracy and easy implementation. However, it is mostly difficult to fully train a deep neural network since gradients in optimization may vanish or explode during back-propagation, which results in deterioration and noticeable variance in model performance. In fault diagnosis researches, larger data sequence of machinery vibration signal containing sufficient information is usually preferred and consequently, deep models with large capacity are generally adopted. In order to improve network training, a residual learning algorithm is proposed in this paper. The proposed architecture significantly improves the information flow throughout the network, which is well suited for processing machinery vibration signal with variable sequential length. Little prior expertise on fault diagnosis and signal processing is required, that facilitates industrial applications of the proposed method. Experiments on a popular rolling bearing dataset are implemented to validate the proposed method. The results of this study suggest that the proposed intelligent fault diagnosis method for rotating machinery offers a new and promising approach.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2019.106870,Journal,Computer Networks,scopus,2019-11-09,sciencedirect,Game-based adaptive anomaly detection in wireless body area networks,https://api.elsevier.com/content/abstract/scopus_id/85070500273,"Wireless Body Area Network (WBAN) is a quite suitable communication tool for medical IoT devices that are deployed to collect physiological parameters and forecast real-time events in order to facilitate the diagnostic decision-making for the medical staff. However, sensor readings may be inaccurate due to resource-constrained devices, sensor misplacement, hardware faults, and other environmental factors. Therefore, anomaly detection is envisioned as a promising approach to deal with unreliable and malicious data injection to improve remote patient monitoring systems and reduce false medical diagnosis. In this context, several data analysis and machine learning tools have been proposed to detect abnormal deviations in WBAN. Nevertheless, no one considers the dynamic context changes of WBAN to provide adaptive and dynamic outlier detection. In addition, most of them ignore the co-existence of strong spatial and temporal correlations between monitored physiological attributes. To this end, we propose a two-level lightweight and adaptive anomaly detection approach to discard false alarms caused by faulty measurements and raise alarms only when a patient seems to be in emergency situations. In the first level, a game-theoretic technique is introduced wherein body-worn sensor nodes exploit the spatiotemporal correlation among readings to locally and adaptively detect anomalous events according to the dynamic context changes of WBAN. In the second level, we apply the Mahalanobis distance in the Local Processing Unit (LPU) which has a global view for multivariate analysis. Our main objective is to ensure a tradeoff between detection accuracy, false positive rates, and network performance while considering the WBAN environment constraints. The proposed approach is evaluated through numerical simulations on a real physiological data set. Simulation results prove the effectiveness of the proposed approach in terms of achieving high detection accuracy with low false alarm rate and energy consumption.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2019.109440,Journal,Energy and Buildings,scopus,2019-11-01,sciencedirect,A deep reinforcement learning-based autonomous ventilation control system for smart indoor air quality management in a subway station,https://api.elsevier.com/content/abstract/scopus_id/85072289855,"Mechanical ventilation has been widely implemented to alleviate poor indoor air quality (IAQ) in confined underground public facilities. However, due to time-varying IAQ properties that are influenced by unpredictable factors, including outdoor air quality, subway schedules, and passenger volumes, real-time control that incorporates a trade-off between energy saving and IAQ is limited in conventional rule-based and model-based approaches. We propose a data-driven and intelligent approach for a smart ventilation control system based on a deep reinforcement learning (DeepRL) algorithm. This study utilized a deep Q-network (DQN) algorithm of DeepRL to design the ventilation system. The DQN agent was trained in a virtual environment defined by a gray-box model to simulate an IAQ system in a subway station. Performance of the proposed method over three weeks was evaluated by a comprehensive indoor air-quality index (CIAI) and energy consumption under different outdoor air quality scenarios. The results show that the proposed DeepRL-based ventilation control system reduced energy consumption by up to 14.4% for the validation dataset time interval and improved IAQ from unhealthy to acceptable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2019.06.022,Journal,International Journal of Medical Informatics,scopus,2019-11-01,sciencedirect,Automatic classification of free-text medical causes from death certificates for reactive mortality surveillance in France,https://api.elsevier.com/content/abstract/scopus_id/85072199154,"Background
                  Mortality surveillance is of fundamental importance to public health surveillance. The real-time recording of death certificates, thanks to Electronic Death Registration System (EDRS), provides valuable data for reactive mortality surveillance based on medical causes of death in free-text format. Reactive mortality surveillance is based on the monitoring of mortality syndromic groups (MSGs). An MSG is a cluster of medical causes of death (pathologies, syndromes or symptoms) that meets the objectives of early detection and impact assessment of public health events. The aim of this study is to implement and measure the performance of a rule-based method and two supervised models for automatic free-text cause of death classification from death certificates in order to implement them for routine surveillance.
               
                  Method
                  A rule-based method was implemented using four processing steps: standardization rules, splitting causes of death using delimiters, spelling corrections and dictionary projection. A supervised machine learning method using a linear Support Vector Machine (SVM) classifier was also implemented. Two models were produced using different features (SVM1 based solely on surface features and SVM2 combining surface features and MSGs classified by the rule-based method as feature vectors). The evaluation was conducted using an annotated subset of electronic death certificates received between 2012 and 2016. Classification performance was evaluated on seven MSGs (Influenza, Low respiratory diseases, Asphyxia/abnormal respiration, Acute respiratory disease, Sepsis, Chronic digestive diseases, and Chronic endocrine diseases).
               
                  Results
                  The rule-based method and the SVM2 model displayed a high performance with F-measures over 0.94 for all MSGs. Precision and recall were slightly higher for the rule-based method and the SVM2 model. An error-analysis shows that errors were not specific to an MSG.
               
                  Conclusion
                  The high performance of the rule-based method and SVM2 model will allow us to set-up a reactive mortality surveillance system based on free-text death certificates. This surveillance will be an added-value for public health decision making.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cose.2019.101603,Journal,Computers and Security,scopus,2019-11-01,sciencedirect,Multivariate Big Data Analysis for intrusion detection: 5 steps from the haystack to the needle,https://api.elsevier.com/content/abstract/scopus_id/85071721514,"The research literature on cybersecurity incident detection & response is very rich in automatic detection methodologies, in particular those based on the anomaly detection paradigm. However, very little attention has been devoted to the diagnosis ability of the methods, aimed to provide useful information on the causes of a given detected anomaly. This information is of utmost importance for the security team to reduce the time from detection to response. In this paper, we present Multivariate Big Data Analysis (MBDA), a complete intrusion detection approach based on 5 steps to effectively handle massive amounts of disparate data sources. The approach has been designed to deal with the main characteristics of Big Data, that is, the high volume, velocity and variety. The core of the approach is the Multivariate Statistical Network Monitoring (MSNM) technique proposed in a recent paper. Unlike in state of the art machine learning methodologies applied to the intrusion detection problem, when an anomaly is identified in MBDA the output of the system includes the detail of the logs of raw information associated to this anomaly, so that the security team can use this information to elucidate its root causes. MBDA is based in two open software packages available in Github: the MEDA Toolbox and the FCParser. We illustrate our approach with two case studies. The first one demonstrates the application of MBDA to semistructured sources of information, using the data from the VAST 2012 mini challenge 2. This complete case study is supplied in a virtual machine available for download. In the second case study we show the Big Data capabilities of the approach in data collected from a real network with labeled attacks.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enconman.2019.111932,Journal,Energy Conversion and Management,scopus,2019-11-01,sciencedirect,Cultural coyote optimization algorithm applied to a heavy duty gas turbine operation,https://api.elsevier.com/content/abstract/scopus_id/85070893013,"In the past decades, the quantity of researches regarding industrial gas turbines (GT) has increased exponentially in terms of number of publications and diversity of applications. The GTs offer high power output along with a high combined cycle efficiency and high fuel flexibility. As consequence, the energy efficiency, the pressure oscillations, the pollutant emissions and the fault diagnosis have become some of the recent concerns related to this type of equipment. In order to solve these GTs related problems and many other real-world engineering and industry 4.0 issues, a set of new technological approaches have been tested, such as the combination of Artificial Neural Networks (ANN) and metaheuristics for global optimization. In this paper, the recently proposed metaheuristic denoted Coyote Optimization Algorithm (COA) is applied to the operation optimization of a heavy duty gas turbine placed in Brazil and used in power generation. The global goal is to find the best valves setup to reduce the fuel consumption while coping with environmental and physical constraints from its operation. In order to treat it as an optimization problem, an integrated simulation model is implemented from original data-driven models and others previously proposed in literature. Moreover, a new version of the COA that links some concepts from Cultural Algorithms (CA) is proposed, which is validated under a set of benchmarks functions from the Institute of Electrical and Electronics Engineers (IEEE) Congress on Evolutionary Computation (CEC) 2017 and tested to the GT problem. The results show that the proposed Cultural Coyote Optimization Algorithm (CCOA) outperforms its counterpart for benchmark functions. Further, non-parametric statistical significance tests prove that the CCOA’s performance is competitive when compared to other state-of-the-art metaheuristics after a set of experiments for five case studies. In addition, the convergence analysis shows that the cultural mechanism employed in the CCOA has improved the COA balance between exploration and exploitation. As a result, the CCOA can improve the current GT operation significantly, reducing the fuel consumption up to 
                        
                           3.6
                           %
                        
                      meanwhile all constraints are accomplished.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.snb.2019.126851,Journal,"Sensors and Actuators, B: Chemical",scopus,2019-11-01,sciencedirect,A digital quantification method for the detection of biomarkers on a microfluidic array chip,https://api.elsevier.com/content/abstract/scopus_id/85069665496,"In this study, a digital quantification method is proposed for the detection of biomarkers. The proposed method is applied to detect alpha-fetoprotein (AFP), which is a biomarker of hepatocellular carcinoma. This digital quantification method is implemented with modified magnetic microparticles (MMPs) and a microfluidic array chip. The MMPs are modified with 186 ± 6 β-galactosidases (β-gal) and 117 ± 8 anti-human AFP antibodies (capture Ab) with a high capture efficiency and catalytic ability. The microfluidic array chip is modified with an AFP monoclonal antibody (coating Ab). The AFP captured by the modified MMPs is distributed in microwells, obeying the Poisson distribution. The modified MMPs that captured the AFP are captured by a coating Ab and anchored in the microwells, while the modified MMPs that did not capture the AFP are removed by a washing process. Therefore, the AFP can be detected by this digital quantification method with high sensitivity, selectivity and anti-interference ability. There is a linear relationship between –ln (1 - proportion of positive microwell (PPM)) and the AFP concentrations from 1 to 100 fg/mL, and the lowest AFP concentration that can be quantified is 1 fg/mL. This digital quantification method can also be used for real serum sample analysis, which holds great potential for the early diagnosis of cancer and therapeutic management.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brainres.2019.146341,Journal,Brain Research,scopus,2019-10-15,sciencedirect,Automatic detection and sonification of nonmotor generalized onset epileptic seizures: Preliminary results,https://api.elsevier.com/content/abstract/scopus_id/85069698124,"Long-term video-EEG monitoring has improved diagnosis and treatment of epilepsy, especially in children. However, the amount of data neurophysiologists must analyze has grown remarkably.
                  The main purpose of this paper is to provide a diagnostic support to speed up and ease EEG interpretation for a specific application concerning absence seizures, a type of non-motor generalized epileptic seizures.
                  The proposed method consists of a pre-processing step where signals are filtered through the Stationary Wavelet Transform for the reduction of possible artefacts. Subsequently, a supervised automatic classification method is implemented for seizure detection, based on the Support Vector Machine Fine Gaussian method. Finally, a post-processing step is implemented in which spatial and temporal thresholds are defined for both online and offline application.
                  In addition, a method that applies sonification techniques is developed. Sonification techniques could speed up the process of interpreting information, allowing rapid clinical intervention and a continuous monitoring of the event.
                  The dataset consists of 30 EEG recordings performed in 24 children with absence seizures, clinically evaluated at the Meyer Children's Hospital in Firenze, Italy.
                  The method shows encouraging results both in terms of balanced accuracy (about 96%) and latency times (1.25 s on average), which might make it suitable for online clinical trials. In fact, it was implemented in the perspective of a possible real-time application in clinical practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2019.111549,Journal,Biosensors and Bioelectronics,scopus,2019-10-01,sciencedirect,Efficient electron-mediated electrochemical biosensor of gold wire for the rapid detection of C-reactive protein: A predictive strategy for heart failure,https://api.elsevier.com/content/abstract/scopus_id/85071785022,"C-reactive protein (CRP) is considered a promising biomarker for the rapid and high-throughput real-time monitoring of cardiovascular disease and inflammation in unprocessed clinical samples. Implementation of this monitoring would enable various transformative biomedical applications. We have fabricated a highly specific sensor chip to detect CRP with a detection limit of 2.25 fg/mL. The protein was immobilized on top of a gold (Au) wire/polycarbonate (PC) substrate using 1-ethyl-3-(3-dimethylamino-propyl) carbodiimide hydrochloride/N-hydroxy succinimide-activated 3-mercaptoproponic acid (MPA) as a self-assembled monolayer agent and bovine serum albumin (BSA) as a blocking agent. In contrast to the bare PC substrate, the CRP/BSA/anti-CRP/MPA/Au substrate exhibited a considerably high electrochemical signal toward CRP. The influence of the experimental parameters on CRP detection was assessed via various analysis methods, and these parameters were then optimized. The linear dynamic range of the CRP was 5–220 fg/mL for voltammetric and impedance analysis. Morever, the strategy exhibited high selectivity against various potential interfering species and was capable of directly probing trace amounts of the target CRP in human serum with excellent selectivity. The analytical assay based on the CRP/BSA/anti-CRP/MPA/Au substrate could be exploited as a potentially useful tool for detecting CRP in clinical samples.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacr.2019.06.009,Journal,Journal of the American College of Radiology,scopus,2019-10-01,sciencedirect,Bending the Artificial Intelligence Curve for Radiology: Informatics Tools From ACR and RSNA,https://api.elsevier.com/content/abstract/scopus_id/85071398084,"Artificial intelligence (AI) will reshape radiology over the coming years. The radiology community has a strong history of embracing new technology for positive change, and AI is no exception. As with any new technology, rapid, successful implementation faces several challenges that will require creation and adoption of new integration technology. Use cases important to real-world application of AI are described, including clinical registries, AI research, AI product validation, and computer assistance for radiology reporting. Furthermore, the informatics technologies required for successful implementation of the use cases are described, including open Computer-Assisted Radiologist Decision Support, ACR Assist, ACR Data Science Institute use cases, common data elements (radelement.org), RadLex (radlex.org), LOINC/RSNA RadLex Playbook (loinc.org), and Radiology Report Templates (radreport.org).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compag.2019.104948,Journal,Computers and Electronics in Agriculture,scopus,2019-10-01,sciencedirect,Depthwise separable convolution architectures for plant disease classification,https://api.elsevier.com/content/abstract/scopus_id/85071251967,"Convolutional neural network has a huge partake and is still a dominating tool in the field of computer vision. In this study, we introduce a model with depthwise separable convolution architecture for plant disease detection based on images of leaves. We present two versions of depthwise separable convolution comprising two varieties of building blocks. Training and testing of the models were performed on a subset of publicly available PlantVillage dataset of 82,161 images containing 55 distinct classes of healthy and diseased plants. These depthwise separable convolutions achieved less accuracy and high gain in convergence speed. Several models were trained and tested, of which Reduced MobileNet achieved a classification accuracy of 98.34% with 29 times fewer parameters compared to VGG and 6 times lesser than that of MobileNet. However, MobileNet outperformed existing models with 36.03% accuracy when testing the model on a set of images taken under conditions different from those of the images used for training. Thin models were also introduced, which showed effective trade-off between latency and accuracy. The satisfactory accuracy and small size of this model makes it suitable for real-time crop diagnosis in resource constrained mobile devices.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.104993,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-10-01,sciencedirect,TTTS-GPS: Patient-specific preoperative planning and simulation platform for twin-to-twin transfusion syndrome fetal surgery,https://api.elsevier.com/content/abstract/scopus_id/85069856373,"Twin-to-twin transfusion syndrome (TTTS) is a serious condition that may occur in pregnancies when two or more fetuses share the same placenta. It is characterized by abnormal vascular connections in the placenta that cause blood to flow unevenly between the babies. If left untreated, perinatal mortality occurs in 90% of cases, whilst neurological injuries are still present in TTTS survivors. Minimally invasive fetoscopic laser surgery is the standard and optimal treatment for this condition, but is technically challenging and can lead to complications. Acquiring and maintaining the required surgical skills need consistent practice, and a steep learning curve. An accurate preoperative planning is thus vital for complex TTTS cases. To this end, we propose the first TTTS fetal surgery planning and simulation platform. The soft tissue of the mother, the uterus, the umbilical cords, the placenta and its vascular tree are segmented and registered automatically from magnetic resonance imaging and 3D ultrasound using computer vision and deep learning techniques. The proposed state-of-the-art technology is integrated into a flexible C++ and MITK-based application to provide a full exploration of the intrauterine environment by simulating the fetoscope camera as well as the laser ablation, determining the correct entry point, training doctors’ movements and trajectory ahead of operation, which allows improving upon current practice. A comprehensive usability study is reported. Experienced surgeons rated highly our TTTS planner and simulator, thus being a potential tool to be implemented in real and complex TTTS surgeries.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijcard.2019.05.070,Journal,International Journal of Cardiology,scopus,2019-10-01,sciencedirect,Best practices in digital health literacy,https://api.elsevier.com/content/abstract/scopus_id/85067503480,"The connection between health literacy and health outcomes includes access and utilization of healthcare services, patient/provider interaction and self-care. Digital approaches can be designed to simplify or expand on a concept, test for understanding, and do not have a time constraint. New technologies, such as artificial intelligence and machine learning, virtual and augmented reality, and blockchain can move the role of technology beyond data collection to a more integrated system. Rather than being a passive participant, digital solutions provide the opportunity for the individual to be an active participant in their health. These solutions can be delivered in a way that builds or enhances the individual's belief that the plan will be successful and more confidence that they can stick with it. Digital solutions allow for the delivery of multi-media education, such as videos, voice, and print, at different reading levels, in multiple languages, using formal and informal teaching methods. By giving the patient a greater voice and empowering them to be active participants in their care, they can develop their decision making and shared decision making skills. The first step in our health literacy instructional model is to address the emotional state of the person. Once the emotional state has been addressed, and an engagement strategy has been deployed the final phase is the delivery of an educational solution. While a clear definition of health literacy and an instructional model are important, further research must be done to continually determine more effective ways to incorporate health technology in the process of improving health outcomes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.csi.2019.103361,Journal,Computer Standards and Interfaces,scopus,2019-10-01,sciencedirect,Using artificial intelligence for modeling of the realistic animal behaviors in a virtual island,https://api.elsevier.com/content/abstract/scopus_id/85067381625,"The remarkable development of the computer graphic techniques enables the creation and management of more realistic games and virtual environments. However, placing the Artificial Intelligence (AI) in a virtual world get making these environments both more interactive and more believable. One of the most ambitious goals of the AI is to create virtual worlds in which a big number of virtual characters or humans being interacted and behave in an autonomous way. For this purpose, placing embodied intelligence characters in a virtual world offers a unique opportunity to evaluate the AI concept.
                  This paper introduces a Virtual Island developed in an innovative way based on fuzzy rules at the user interaction mechanism. We have used fuzzy tactics to create AI-based animals having various behavior types from an eagles’ perspective which called ‘Flight Simulation’. The simulation utilizes an eagle flying over the airspace of the Island of Chios. The AI on the ground is triggered by other animals when they enter a radius area with a certain speed defined in the software. It then decides how to behave according to health, behavior type and confidence level. Also, there is non-AI sparrow herd placed over the island to make user understand how fast he is and give the user sense of speed what can be called as an in-project feature. Consequently, the used Fuzzy Tactics have been tested in realized Unity 3D simulation. The results of the study have proven that the virtual environment consisting AI-based animals has a good performance in terms of animal-user interactions and provided satisfactory results in run time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.tips.2019.07.005,Journal,Trends in Pharmacological Sciences,scopus,2019-09-01,sciencedirect,Artificial Intelligence for Drug Toxicity and Safety,https://api.elsevier.com/content/abstract/scopus_id/85071055144,"Interventional pharmacology is one of medicine’s most potent weapons against disease. These drugs, however, can result in damaging side effects and must be closely monitored. Pharmacovigilance is the field of science that monitors, detects, and prevents adverse drug reactions (ADRs). Safety efforts begin during the development process, using in vivo and in vitro studies, continue through clinical trials, and extend to postmarketing surveillance of ADRs in real-world populations. Future toxicity and safety challenges, including increased polypharmacy and patient diversity, stress the limits of these traditional tools. Massive amounts of newly available data present an opportunity for using artificial intelligence (AI) and machine learning to improve drug safety science. Here, we explore recent advances as applied to preclinical drug safety and postmarketing surveillance with a specific focus on machine and deep learning (DL) approaches.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacr.2019.04.005,Journal,Journal of the American College of Radiology,scopus,2019-09-01,sciencedirect,An Initiative to Reduce Unnecessary Gadolinium-Based Contrast in Multiple Sclerosis Patients,https://api.elsevier.com/content/abstract/scopus_id/85069944004,"Objective
                  Patients with multiple sclerosis (MS) routinely undergo serial contrast-enhanced MRIs. Given concerns regarding tissue deposition of gadolinium-based contrast agents (GBCAs) and evidence that enhancement of lesions is only seen in patients with new disease activity on noncontrast imaging, we set out to implement a prospective quality improvement project whereby intravenous contrast would be reserved only for patients with evidence of new disease activity on noncontrast images.
               
                  Methods
                  To prospectively implement such a protocol, we leveraged our in-house computer-assisted detection (CAD) software and 3-D laboratory radiology technologists to perform real-time preliminary assessments of the CAD-processed T2 fluid attenuated inversion recovery (FLAIR) noncontrast images as a basis for deciding whether to inject contrast. Before implementation, we held multidisciplinary meetings with neurology, neuroradiology, and MR technologists and distributed surveys to objectively assess opinions and obstacles to clinical implementation. We evaluated reduction in GBCA utilization and technologist performance relative to final neuroradiologist interpretations.
               
                  Results
                  During a 2-month trial period, 153 patients were imaged under the new protocol. Technologists using the CAD software were able to identify patients with new or enlarging lesions on FLAIR images with 95% accuracy and 97% negative predictive value relative to final neuroradiologist interpretations, which allowed us to avoid the use of contrast and additional imaging sequences in 87% of patients.
               
                  Discussion
                  A multidisciplinary effort to implement a quality improvement project to limit contrast in MS patients receiving follow-up MRIs allowed for improved safety and cost by targeting patients that would benefit from the use of intravenous contrast in real-time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacr.2019.05.047,Journal,Journal of the American College of Radiology,scopus,2019-09-01,sciencedirect,"Strengths, Weaknesses, Opportunities, and Threats Analysis of Artificial Intelligence and Machine Learning Applications in Radiology",https://api.elsevier.com/content/abstract/scopus_id/85069706449,"Currently, the use of artificial intelligence (AI) in radiology, particularly machine learning (ML), has become a reality in clinical practice. Since the end of the last century, several ML algorithms have been introduced for a wide range of common imaging tasks, not only for diagnostic purposes but also for image acquisition and postprocessing. AI is now recognized to be a driving initiative in every aspect of radiology. There is growing evidence of the advantages of AI in radiology creating seamless imaging workflows for radiologists or even replacing radiologists. Most of the current AI methods have some internal and external disadvantages that are impeding their ultimate implementation in the clinical arena. As such, AI can be considered a portion of a business trying to be introduced in the health care market. For this reason, this review analyzes the current status of AI, and specifically ML, applied to radiology from the scope of strengths, weaknesses, opportunities, and threats (SWOT) analysis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.clineuro.2019.105442,Journal,Clinical Neurology and Neurosurgery,scopus,2019-09-01,sciencedirect,Artificial intelligence for assisting diagnostics and assessment of Parkinson's disease—A review,https://api.elsevier.com/content/abstract/scopus_id/85069629950,"Artificial intelligence, specifically machine learning, has found numerous applications in computer-aided diagnostics, monitoring and management of neurodegenerative movement disorders of parkinsonian type. These tasks are not trivial due to high inter-subject variability and similarity of clinical presentations of different neurodegenerative disorders in the early stages. This paper aims to give a comprehensive, high-level overview of applications of artificial intelligence through machine learning algorithms in kinematic analysis of movement disorders, specifically Parkinson’s disease (PD). We surveyed papers published between January 2007 and January 2019, within online databases, including PubMed and Science Direct, with a focus on the most recently published studies. The search encompassed papers dealing with the implementation of machine learning algorithms for diagnosis and assessment of PD using data describing motion of upper and lower extremities. This systematic review presents an overview of 48 relevant studies published in the abovementioned period, which investigate the use of artificial intelligence for diagnostics, therapy assessment and progress prediction in PD based on body kinematics. Different machine learning algorithms showed promising results, particularly for early PD diagnostics. The investigated publications demonstrated the potentials of collecting data from affordable and globally available devices. However, to fully exploit artificial intelligence technologies in the future, more widespread collaboration is advised among medical institutions, clinicians and researchers, to facilitate aligning of data collection protocols, sharing and merging of data sets.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2019.06.001,Journal,Computerized Medical Imaging and Graphics,scopus,2019-09-01,sciencedirect,Motion estimation and correction in cardiac CT angiography images using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85068381768,"Cardiac motion artifacts frequently reduce the interpretability of coronary computed tomography angiography (CCTA) images and potentially lead to misinterpretations or preclude the diagnosis of coronary artery disease (CAD). In this paper, a novel motion compensation approach dealing with Coronary Motion estimation by Patch Analysis in CT data (CoMPACT) is presented. First, the required data for supervised learning is generated by the Coronary Motion Forward Artifact model for CT data (CoMoFACT) which introduces simulated motion to 19 artifact-free clinical CT cases with step-and-shoot acquisition protocol. Second, convolutional neural networks (CNNs) are trained to estimate underlying 2D motion vectors from 2.5D image patches based on the coronary artifact appearance. In a phantom study with computer-simulated vessels, CNNs predict the motion direction and the motion magnitude with average test accuracies of 13.37°±1.21° and 0.77 ± 0.09 mm, respectively. On clinical data with simulated motion, average test accuracies of 34.85°±2.09° and 1.86 ± 0.11 mm are achieved, whereby the precision of the motion direction prediction increases with the motion magnitude. The trained CNNs are integrated into an iterative motion compensation pipeline which includes distance-weighted motion vector extrapolation. Alternating motion estimation and compensation in twelve clinical cases with real cardiac motion artifacts leads to significantly reduced artifact levels, especially in image data with severe artifacts. In four observer studies, mean artifact levels of 3.08 ± 0.24 without MC and 2.28 ± 0.29 with CoMPACT MC are rated in a five point Likert scale.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2019.06.029,Journal,Computer Methods and Programs in Biomedicine,scopus,2019-09-01,sciencedirect,C-HMOSHSSA: Gene selection for cancer classification using multi-objective meta-heuristic and machine learning methods,https://api.elsevier.com/content/abstract/scopus_id/85068374888,"Background and objective: Over the last two decades, DNA microarray technology has emerged as a powerful tool for early cancer detection and prevention. It helps to provide a detailed overview of disease complex microenvironment. Moreover, online availability of thousands of gene expression assays made microarray data classification an active research area. A common goal is to find a minimum subset of genes and maximizing the classification accuracy.
                  
                     Methods: In pursuit of a similar objective, we have proposed framework (C-HMOSHSSA) for gene selection using multi-objective spotted hyena optimizer (MOSHO) and salp swarm algorithm (SSA). The real-life optimization problems with more than one objective usually face the challenge to maintain convergence and diversity. Salp Swarm Algorithm (SSA) maintains diversity but, suffers from the overhead of maintaining the necessary information. On the other hand, the calculation of MOSHO requires low computational efforts hence is used for maintaining the necessary information. Therefore, the proposed algorithm is a hybrid algorithm that utilizes the features of both SSA and MOSHO to facilitate its exploration and exploitation capability.
                  
                     Results:Four different classifiers are trained on seven high-dimensional datasets using a subset of features (genes), which are obtained after applying the proposed hybrid gene selection algorithm. The results show that the proposed technique significantly outperforms existing state-of-the-art techniques.
                  
                     Conclusion: It is also shown that the new sets of informative and biologically relevant genes are successfully identified by the proposed technique. The proposed approach can also be applied to other problem domains of interest which involve feature selection.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1038/s41436-019-0439-8,Journal,Genetics in Medicine,scopus,2019-09-01,sciencedirect,Xrare: a machine learning method jointly modeling phenotypes and genetic evidence for rare disease diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85060610025,"Purpose
                  Despite the successful progress next-generation sequencing technologies has achieved in diagnosing the genetic cause of rare Mendelian diseases, the current diagnostic rate is still far from satisfactory because of heterogeneity, imprecision, and noise in disease phenotype descriptions and insufficient utilization of expert knowledge in clinical genetics. To overcome these difficulties, we present a novel method called Xrare for the prioritization of causative gene variants in rare disease diagnosis.
               
                  Methods
                  We propose a new phenotype similarity scoring method called Emission-Reception Information Content (ERIC), which is highly tolerant of noise and imprecision in clinical phenotypes. We utilize medical genetic domain knowledge by designing genetic features implementing American College of Medical Genetics and Genomics (ACMG) guidelines.
               
                  Results
                  ERIC score ranked consistently higher for disease genes than other phenotypic similarity scores in the presence of imprecise and noisy phenotypes. Extensive simulations and real clinical data demonstrated that Xrare outperforms existing alternative methods by 10–40% at various genetic diagnosis scenarios.
               
                  Conclusion
                  The Xrare model is learned from a large database of clinical variants, and derives its strength from the tight integration of medical genetics features and phenotypic features similarity scores. Xrare provides the clinical community with a robust and powerful tool for variant prioritization.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dsx.2018.07.014,Journal,Diabetes and Metabolic Syndrome: Clinical Research and Reviews,scopus,2019-09-01,sciencedirect,Prevalence of metabolic syndrome in Iranian patients with schizophrenia: A systematic review and meta-analysis,https://api.elsevier.com/content/abstract/scopus_id/85050864479,"Industry 4.0 is an updated concept of smart production, which is identified with the fourth industrial revolution and the emergence of cyber-physical systems. Industry 4.0 is the next stage in the digitization of productions and industries, where such technologies and concepts as the Internet of things, big data, predictive analytics, cloud computing, machine learning, machine interaction, artificial intelligence, robotics, 3D printing, augmented reality.
                  As an area of therapy with the best market potential and one of the most expensive global diseases, diabetes attracts the best healthcare players, who use innovative technologies.
                  Current trends in digitalization of diabetes management are presented.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2019.04.022,Journal,Knowledge-Based Systems,scopus,2019-08-15,sciencedirect,Evolutionary manifold regularized stacked denoising autoencoders for gearbox fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85065582506,"Vibration signals are widely employed to fulfill gearbox fault diagnosis in real-world cases. However, it is quite challenging to extract effective fault features from noised vibration signals and then to construct an effective defect recognition model. Although deep neural networks (DNNs) have been used for feature extraction from vibration signals, the optimization of parameters and structure of DNNs simultaneously is still a difficult task in many applications. This paper proposes a new stacked denoising autoencoders (SDAE) algorithm, called manifold regularized SDAE (MRSDAE) based on particle swarm optimization (PSO), where manifold regularization and feature selection are embedded in the deep network smoothly. This study puts its emphasis on using PSO to simultaneously learn structure and parameters of MRSDAE based on a specific individual representation and learning scheme. MRSDAE aims to generate discriminant features from vibration signal data by using the integration of these effective techniques, i.e., structure and parameter optimization, manifold regularization and feature selection. MRSDAE-based fault diagnosis is implemented by an unsupervised representation learning followed by a supervised fine-tuning. The effectiveness of the MRSDAE-based fault diagnosis method has been verified by experimental results on vibration signal data from a gearbox defect test rig. The results illustrate that MRSDAE learns effective discriminative features and achieves the better diagnosis accuracy in comparison with that of the regular DNNs. Finding from this study can be used as the effective guidance in feature learning for machinery fault diagnosis based on evolutionary DNNs with manifold regularization and feature selection techniques.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2019.03.011,Journal,Expert Systems with Applications,scopus,2019-08-15,sciencedirect,Constraint learning based gradient boosting trees,https://api.elsevier.com/content/abstract/scopus_id/85063576343,"Predictive regression models aim to find the most accurate solution to a given problem, often without any constraints related to the model’s predicted values. Such constraints have been used in prior research where they have been applied to a subpopulation within the training dataset which is of greater interest and importance. In this research we introduce a new setting of regression problems, in which each instance can be assigned a different constraint, defined based on the value of the target (predicted) attribute. The new use of constraints is taken into account and incorporated into the learning process, and is also considered when evaluating the induced model. We propose two algorithms which are modifications to the regression boosting method. There are two advantages of the proposed algorithms: they are not dependent on the base learner used during the learning process, and they can be adopted by any boosting technique. We implemented the algorithms by modifying the gradient boosting trees (GBT) model, and we also introduced two measures for evaluating the models that were trained to solve the constraint problems. We compared the proposed algorithms to three baseline algorithms using four real-life datasets. Due to the algorithms’ focus on satisfying the constraints, in most cases the results showed significant improvement in the constraint-related measures, with just a minimal effect on the general prediction error. The main impact of the proposed approach is in its ability to derive a model with a higher level of assurance for specific cases of interest (i.e., the constrained cases). This is extremely important and has great significance in various use cases and expert and intelligent systems, particularly critical systems, such as critical healthcare systems (e.g., when predicting blood pressure or blood sugar level), safety systems (e.g., when aiming to estimate the distance of cars or airplanes from other objects), or critical industrial systems (e.g., require to estimate their usability along time). In each of these cases, there is a subpopulation of all instances that is of greater interest to the expert or system, and the sensitivity of the model’s error changes according to the real value of the predicted feature. For example, for a subpopulation of patients (e.g., patients under the age of eight, or patients known to be at risk), physicians often require a sensitive model that accurately predicts blood pressure values.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gie.2019.03.019,Journal,Gastrointestinal Endoscopy,scopus,2019-07-01,sciencedirect,Quality assurance of computer-aided detection and diagnosis in colonoscopy,https://api.elsevier.com/content/abstract/scopus_id/85065917454,"Recent breakthroughs in artificial intelligence (AI), specifically via its emerging sub-field “deep learning,” have direct implications for computer-aided detection and diagnosis (CADe and/or CADx) for colonoscopy. AI is expected to have at least 2 major roles in colonoscopy practice—polyp detection (CADe) and polyp characterization (CADx). CADe has the potential to decrease the polyp miss rate, contributing to improving adenoma detection, whereas CADx can improve the accuracy of colorectal polyp optical diagnosis, leading to reduction of unnecessary polypectomy of non-neoplastic lesions, potential implementation of a resect-and-discard paradigm, and proper application of advanced resection techniques. A growing number of medical-engineering researchers are developing both CADe and CADx systems, some of which allow real-time recognition of polyps or in vivo identification of adenomas, with over 90% accuracy. However, the quality of the developed AI systems as well as that of the study designs vary significantly, hence raising some concerns regarding the generalization of the proposed AI systems. Initial studies were conducted in an exploratory or retrospective fashion by using stored images and likely overestimating the results. These drawbacks potentially hinder smooth implementation of this novel technology into colonoscopy practice. The aim of this article is to review both contributions and limitations in recent machine-learning-based CADe and/or CADx colonoscopy studies and propose some principles that should underlie system development and clinical testing.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2019.05.001,Journal,Medical Image Analysis,scopus,2019-07-01,sciencedirect,Denoising of 3D magnetic resonance images using a residual encoder–decoder Wasserstein generative adversarial network,https://api.elsevier.com/content/abstract/scopus_id/85065426790,"Structure-preserved denoising of 3D magnetic resonance imaging (MRI) images is a critical step in medical image analysis. Over the past few years, many algorithms with impressive performances have been proposed. In this paper, inspired by the idea of deep learning, we introduce an MRI denoising method based on the residual encoder–decoder Wasserstein generative adversarial network (RED-WGAN). Specifically, to explore the structure similarity between neighboring slices, a 3D configuration is utilized as the basic processing unit. Residual autoencoders combined with deconvolution operations are introduced into the generator network. Furthermore, to alleviate the oversmoothing shortcoming of the traditional mean squared error (MSE) loss function, the perceptual similarity, which is implemented by calculating the distances in the feature space extracted by a pretrained VGG-19 network, is incorporated with the MSE and adversarial losses to form the new loss function. Extensive experiments are implemented to assess the performance of the proposed method. The experimental results show that the proposed RED-WGAN achieves performance superior to several state-of-the-art methods in both simulated and real clinical data. In particular, our method demonstrates powerful abilities in both noise suppression and structure preservation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jtos.2019.03.003,Journal,Ocular Surface,scopus,2019-07-01,sciencedirect,Novel automated non invasive detection of ocular surface squamous neoplasia using multispectral autofluorescence imaging,https://api.elsevier.com/content/abstract/scopus_id/85065047875,"Purpose
                  Diagnosing Ocular surface squamous neoplasia (OSSN) using newly designed multispectral imaging technique.
               
                  Methods
                  Eighteen patients with histopathological diagnosis of Ocular Surface Squamous Neoplasia (OSSN) were recruited. Their previously collected biopsy specimens of OSSN were reprocessed without staining to obtain auto fluorescence multispectral microscopy images. This technique involved a custom-built spectral imaging system with 38 spectral channels. Inter and intra-patient frameworks were deployed to automatically detect and delineate OSSN using machine learning methods. Different machine learning methods were evaluated, with K nearest neighbor and Support Vector Machine chosen as preferred classifiers for intra- and inter-patient frameworks, respectively. The performance of the technique was evaluated against a pathological assessment.
               
                  Results
                  Quantitative analysis of the spectral images provided a strong multispectral signature of a relative difference between neoplastic and normal tissue both within each patient (at p < 0.0005) and between patients (at p < 0.001). Our fully automated diagnostic method based on machine learning produces maps of the relatively well circumscribed neoplastic-non neoplastic interface. Such maps can be rapidly generated in quasi-real time and used for intraoperative assessment. Generally, OSSN could be detected using multispectral analysis in all patients investigated here. The cancer margins detected by multispectral analysis were in close and reasonable agreement with the margins observed in the H&E sections in intra- and inter-patient classification, respectively.
               
                  Conclusions
                  This study shows the feasibility of using multispectral auto-fluorescence imaging to detect and find the boundary of human OSSN. Fully automated analysis of multispectral images based on machine learning methods provides a promising diagnostic tool for OSSN which can be translated to future clinical applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2019.04.010,Journal,Journal of Virological Methods,scopus,2019-07-01,sciencedirect,Development of an RT-LAMP assay for the detection of Lassa viruses in southeast and south-central Nigeria,https://api.elsevier.com/content/abstract/scopus_id/85064184174,"Lassa virus (LASV) causes Lassa fever (LF), a viral hemorrhagic fever endemic in West Africa. LASV strains are clustered into six lineages according to their geographic location. To confirm a diagnosis of LF, a laboratory test is required. Here, a reverse transcription loop-mediated isothermal amplification (RT-LAMP) assay using a portable device for the detection of LASV in southeast and south-central Nigeria using three primer sets specific for strains clustered in lineage II was developed. The assay detected in vitro transcribed LASV RNAs within 23 min and was further evaluated for detection in 73 plasma collected from suspected LF patients admitted into two health settings in southern Nigeria. The clinical evaluation using the conventional RT-PCR as the reference test revealed a sensitivity of 50% in general with 100% for samples with a viral titer of 9500 genome equivalent copies (geq)/mL and higher. The detection limit was estimated to be 4214 geq/mL. The assay showed 98% specificity with no cross-reactivity to other viruses which cause similar symptoms. These results suggest that this RT-LAMP assay is a useful molecular diagnostic test for LF during the acute phase, contributing to early patient management, while using a convenient device for field deployment and in resource-poor settings.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2019.03.011,Journal,Biomedical Signal Processing and Control,scopus,2019-07-01,sciencedirect,Are you afraid of heights and suitable for working at height?,https://api.elsevier.com/content/abstract/scopus_id/85063350700,"Fear of highs is one of the most common phobias all around world. It could affect people’s life, work and health. Standing on high-altitude can lead to fear, anxiety or even panic to some people. In this paper, EEG method is creatively combined with VR technology to assess the severity of fear of heights. By doing time-frequency analysis, we found that alpha band (8–13 Hz) and high beta (20–30 Hz) are sensitive to fear of heights and frontal and parietotemporal areas are the regions of interests for fear of heights. Then using cross mutual information we built up a functional brain networks of every subject. And we extracted EEG features from the brain networks. Statistical analysis was performed to select the features based on significance of difference. Finally, we implemented classification. The performance of classifiers (the average accuracy could reach 94.44%) based on the proposed method was compared to the performance of classifiers based on the traditional physiological features. As a result, the proposed method was verified to be reliable and superior on estimating the severity of fear of heights. In addition, the system was tested on elderly people and came out with good performance. It turns out that the proposed system has good generalization capability and adaptability.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.buildenv.2019.04.029,Journal,Building and Environment,scopus,2019-06-15,sciencedirect,Deep-learning-based fault detection and diagnosis of air-handling units,https://api.elsevier.com/content/abstract/scopus_id/85064669424,"This study proposed a real-time fault diagnostic model for air-handling units (AHUs); the model used deep learning to improve the operational efficiency of AHUs and thereby reduce the energy consumption of HVAC—heating, ventilating, and air conditioning—systems in buildings. Additionally, EnergyPlus simulation software was employed to establish different types of fault operation behavior data to serve as references for deep learning, thus reducing the complexity of data preprocessing, retaining data completeness, and improving the reliability of the diagnostic model.
                  The proposed deep neural network fault diagnostic model can serve as a reference for this research field; the model features five hidden layers, each comprising 200 neurons. Additionally, this study tested abnormal faults commonly observed in AHUs, including failure to control two-way hydronic valves and variable air volume box dampers as well as supply air temperature sensors exhibiting measurement error. After performing diagnosis with data that had not been used in the training or verification process, the diagnostic results indicated that the diagnostic model exhibited 95.16% accuracy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mimet.2019.03.003,Journal,Journal of Microbiological Methods,scopus,2019-06-01,sciencedirect,A duplex quantitative real-time PCR assay for the detection and quantification of Xanthomonas phaseoli pv. dieffenbachiae from diseased and latently infected anthurium tissue,https://api.elsevier.com/content/abstract/scopus_id/85064711930,"Anthurium bacterial blight caused by Xanthomonas phaseoli pv. dieffenbachiae (formerly Xanthomonas axonopodis pv. dieffenbachiae) is the major phytosanitary threat in many anthurium growing areas worldwide. Reliable and sensitive diagnostic tools are required for surveillance and certification programs. A duplex real–time quantitative PCR assay was developed for the detection and quantification of X. phaseoli pv. dieffenbachiae from anthurium tissue. This PCR assay targeted a X. phaseoli pv. dieffenbachiae–specific gene encoding an ABC transporter and an internal control encoding for chalcone synthase in Anthurium andreanum. A cycle threshold (Ct), using a receiver-operating characteristic approach (ROC), was implemented to ensure that the declaration of a positive sample was reliable. The duplex real–time assay displayed very high performance with regards to analytical specificity (100% inclusivity, 98.9% exclusivity), analytical sensitivity (LOD95% = 894 bacteria/ml corresponding to 18 bacteria per reaction) and repeatability. We demonstrated the pertinence of this real–time quantitative PCR assay for detecting X. phaseoli pv. dieffenbachiae from diseased leaf tissue (collected from outbreaks on anthurium) and from asymptomatic, latently infected anthurium plants. This assay could be useful for surveillance, as well as for indexing propagative plant material for the presence of X. phaseoli pv. dieffenbachiae.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.02.065,Journal,Information Sciences,scopus,2019-06-01,sciencedirect,Computer Aided detection for fibrillations and flutters using deep convolutional neural network,https://api.elsevier.com/content/abstract/scopus_id/85062047707,"Fibrillations and flutters are serious diseases influence the normal functioning of the heart. Among the most frequently occurring heart disorders belong atrial fibrillation (A
                        fib
                     ), atrial flutter (A
                        fl
                     ), and ventricular fibrillation (V
                        fib
                     ). Nowadays, heart failures are mostly detected by electrocardiogram (ECG) device by examining the signal transferred from electrodes placed on the human body to the output display. The signal is examined by professional health personnel, who are looking for an obvious pattern representing the normal or abnormal rhythm of the heart. Nevertheless, information from ECG can be distorted by noise on data transmission. Moreover,problematic pattern does not have to be so much different from normal and it can be difficult to recognize them just by human eye even by an expert in the field. An automated computer-aided diagnosis (CAD) is an approach to make decision support for elimination of these lacks. For early diagnosis, CAD tool should work in like real-time system without big time consuming and dependency on data and measuring differences of each device. This paper proposes a novel approach of a CAD system to the detection of fibrillations and flutters by our 8-layer deep convolutional neural network. Proposed model requires only basic data normalization without pre-processing and feature extraction from raw ECG samples. We have achieved the accuracy, specificity, and sensitivity of 98.45%, 99.27%, and 99.87% respectively. Designed system can be directly implemented like decision support system in clinical environment.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2019.02.309,Journal,Science of the Total Environment,scopus,2019-05-20,sciencedirect,Integrated system for population dose calculation and decision making on protection measures in case of an accident with air emissions in a nuclear power plant,https://api.elsevier.com/content/abstract/scopus_id/85061901769,"The accidents in Chernobyl and Fukushima remind us that nuclear power plants should continuously invest resources in improving safety and in risk management.
                  This paper presents the methodology for developing a measuring and modelling system with a high degree of automation, which enables predicting the effects of the spreading of radionuclides from the nuclear power plant to the atmosphere. The end result is the calculated population doses in the event of an accidental release, which is an essential piece of information needed by first responders to take proper action.
                  The key challenge addressed by this methodology is how to build a system so that its operation is maximally automated, ongoing and in real time. Moreover, in a way that “fresh”, normalized results for the hypothetically most probable types of emissions are always available to operators. The principle that normalized, fresh results are always automatically available to operators is the only real assurance that they will almost surely be available in the event of an accident and panic. This way, we can avoid performing complex model calculations at the operator's request when the accident is already taking place.
                  The methodology divides the building of the system into key modules, which are substantiated and described.
                  The theoretical section is followed by a description of implementation on the example of the Measuring and Modelling System at the Krško Nuclear Power Plant (in Slovenia). The system has been tested in regular nuclear emergency exercises and rated excellent by IAEA inspections; it has been operating automatically, continuously and in real time for many years. The availability of automatic results is counted for the last two years. Measurements and diagnostic modelling results were available for more than 96% and forecasts were available in more than 91% of all half-hour intervals.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.amsu.2019.04.001,Journal,Annals of Medicine and Surgery,scopus,2019-05-01,sciencedirect,"Artificial intelligence, regenerative surgery, robotics? What is realistic for the future of surgery?",https://api.elsevier.com/content/abstract/scopus_id/85064430299,"The potential of surgery lies in the technological advances that would complement it. The landscape of the field will differ depending on the time period being looked at and would no doubt include conjecture. Initial breakthroughs will need to pave the way for future medical technology and apply to the surgical sciences. Within the next 10 years we would expect to see the emergence of big data analysis, cuttingedge image processing techniques for surgical planning and better implementation of virtual and augmented reality in operating theatres for both patient care and teaching purposes. Over the next 50 to 100 years, the use of quantum computing should lead to increased automation in our healthcare systems. The inception of novel biomaterial invention and advanced genetic engineering will usher in the new age of regenerative medicine in the clinical setting. The future of surgery includes many predictions and promises, but it is apparent that the development will lead to bettering outcome and focus on patient care.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijleo.2019.04.034,Journal,Optik,scopus,2019-05-01,sciencedirect,Concealed object segmentation in terahertz imaging via adversarial learning,https://api.elsevier.com/content/abstract/scopus_id/85064317470,"Terahertz imaging (frequency between 0.1 to 10 THz) is a modern technique for public security check. Due to poor imaging quality, traditional machine vision methods often fail to detect concealed weapons in Terahertz samples, while modern instance segmentation approaches have complex multiple-stage concatenation and often hunger for massive and accurate training data. In this work, we realize a novel Conditional Generative Adversarial Nets (CGANs), named as Mask-CGANs to segment weapons in such a challenging imaging quality. The Mask-Generator network employs a “selected-connection U-Net” to restrain false alarms and speed up training convergence. The loss function takes reconstruction errors and sparse priors into consideration to preserve precise segmentation. Such a learning architecture works well with a small training dataset. Experiments show that the proposed model outperforms CGANs (more than 16–32% in Recall, Precision and Accuracy) and Mask-RCNN (more than 3–6%). Moreover, its testing speed (69.7 FPS) is fast enough to be implemented in a real-time security check system, which is 44 times faster than Mask-RCNN. In the experiments for mammographic mass segmentation on INBreast dataset, the Dice index of the proposed method is 91.29, surpasses the-state-of-the-art medical issue segmentation methods. The full implementation (based on TensorFlow) is available at https://github.com/JXPanzz/THz).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.crad.2019.02.006,Journal,Clinical Radiology,scopus,2019-05-01,sciencedirect,Artificial intelligence in breast imaging,https://api.elsevier.com/content/abstract/scopus_id/85062980487,"This article reviews current limitations and future opportunities for the application of computer-aided detection (CAD) systems and artificial intelligence in breast imaging. Traditional CAD systems in mammography screening have followed a rules-based approach, incorporating domain knowledge into hand-crafted features before using classical machine learning techniques as a classifier. The first commercial CAD system, ImageChecker M1000, relies on computer vision techniques for pattern recognition. Unfortunately, CAD systems have been shown to adversely affect some radiologists' performance and increase recall rates. The Digital Mammography DREAM Challenge was a multidisciplinary collaboration that provided 640,000 mammography images for teams to help decrease false-positive rates in breast cancer screening. Winning solutions leveraged deep learning's (DL) automatic hierarchical feature learning capabilities and used convolutional neural networks. Start-ups Therapixel and Kheiron Medical Technologies are using DL for breast cancer screening. With increasing use of digital breast tomosynthesis, specific artificial intelligence (AI)-CAD systems are emerging to include iCAD's PowerLook Tomo Detection and ScreenPoint Medical's Transpara. Other AI-CAD systems are focusing on breast diagnostic techniques such as ultrasound and magnetic resonance imaging (MRI). There is a gap in the market for contrast-enhanced spectral mammography AI-CAD tools. Clinical implementation of AI-CAD tools requires testing in scenarios mimicking real life to prove its usefulness in the clinical environment. This requires a large and representative dataset for testing and assessment of the reader's interaction with the tools. A cost-effectiveness assessment should be undertaken, with a large feasibility study carried out to ensure there are no unintended consequences. AI-CAD systems should incorporate explainable AI in accordance with the European Union General Data Protection Regulation (GDPR).",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jad.2019.03.044,Journal,Journal of Affective Disorders,scopus,2019-05-01,sciencedirect,Short-term prediction of suicidal thoughts and behaviors in adolescents: Can recent developments in technology and computational science provide a breakthrough?,https://api.elsevier.com/content/abstract/scopus_id/85062497590,"Background
                  Suicide is one of the leading causes of death among adolescents, and developing effective methods to improve short-term prediction of suicidal thoughts and behaviors (STBs) is critical. Currently, the most robust predictors of STBs are demographic or clinical indicators that have relatively weak predictive value. However, there is an emerging literature on short-term prediction of suicide risk that has identified a number of promising candidates, including (but not limited to) rapid escalation of: (a) emotional distress, (b) social dysfunction (e.g., bullying, rejection), and (c) sleep disturbance. However, these prior studies are limited in two critical ways. First, they rely almost entirely on self-report. Second, most studies have not focused on assessment of these risk factors using intensive longitudinal assessment techniques that are able to capture the dynamics of changes in risk states at the individual level.
               
                  Method
                  In this paper we explore how to capitalize on recent developments in real-time monitoring methods and computational analysis in order to address these fundamental problems.
               
                  Results
                  We now have the capacity to use: (a) smartphone, wearable computing, and smart home technology to conduct intensive longitudinal assessments monitoring of putative risk factors with minimal participant burden and (b) modern computational techniques to develop predictive algorithms for STBs. Current research and theory on short-term risk processes for STBs, combined with the emergent capabilities of new technologies, suggest that this is an important research agenda for the future.
               
                  Limitations
                  Although these approaches have enormous potential to create new knowledge, the current empirical literature is limited. Moreover, passive monitoring of risk for STBs raises complex ethical issues that will need to be resolved before large scale clinical applications are feasible.
               
                  Conclusions
                  Smartphone, wearable, and smart home technology may provide one point of access that might facilitate both early identification and intervention implementation, and thus, represents a key area for future STB research.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.surg.2019.01.002,Journal,Surgery (United States),scopus,2019-05-01,sciencedirect,Comparing clinical judgment with the MySurgeryRisk algorithm for preoperative risk assessment: A pilot usability study,https://api.elsevier.com/content/abstract/scopus_id/85061644981,"Background
                  Major postoperative complications are associated with increased cost and mortality. The complexity of electronic health records overwhelms physicians’ abilities to use the information for optimal and timely preoperative risk assessment. We hypothesized that data-driven, predictive-risk algorithms implemented in an intelligent decision-support platform simplify and augment physicians’ risk assessments.
               
                  Methods
                  This prospective, nonrandomized pilot study of 20 physicians at a quaternary academic medical center compared the usability and accuracy of preoperative risk assessment between physicians and MySurgeryRisk, a validated, machine-learning algorithm, using a simulated workflow for the real-time, intelligent decision-support platform. We used area under the receiver operating characteristic curve to compare the accuracy of physicians’ risk assessment for six postoperative complications before and after interaction with the algorithm for 150 clinical cases.
               
                  Results
                  The area under the receiver operating characteristic curve of the MySurgeryRisk algorithm ranged between 0.73 and 0.85 and was significantly better than physicians' initial risk assessments (area under the receiver operating characteristic curve between 0.47 and 0.69) for all postoperative complications except cardiovascular. After interaction with the algorithm, the physicians significantly improved their risk assessment for acute kidney injury and for an intensive care unit admission greater than 48 hours, resulting in a net improvement of reclassification of 12% and 16%, respectively. Physicians rated the algorithm as easy to use and useful.
               
                  Conclusion
                  Implementation of a validated, MySurgeryRisk computational algorithm for real-time predictive analytics with data derived from the electronic health records to augment physicians’ decision-making is feasible and accepted by physicians. Early involvement of physicians as key stakeholders in both design and implementation of this technology will be crucial for its future success.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ins.2019.01.073,Journal,Information Sciences,scopus,2019-05-01,sciencedirect,A lightweight machine learning-based authentication framework for smart IoT devices,https://api.elsevier.com/content/abstract/scopus_id/85061004380,"The Internet of Things (IoT) is the next generation plethora of interconnected devices that includes sensors, actuators, etc. and that can provide personalized services such as healthcare, security, and surveillance. The quality of our daily lives is improved by the IoT through pervasive computation and communication. Innumerable devices are being connected each day to IoT applications. Although the quality of our lives is enhanced by the IoT, IoT applications also cause serious challenges in securing networks and data in transit. Existing security solutions, such as password-based two-factor authentication and traditional biometric template-based authentication, can be challenged because of several threats that affect the reliability and efficiency of the entire system. Hence, there is a need for a highly secure authentication mechanism such as the Cancelable Biometric System (CBS). In essence, the CBS is a biometric template protection scheme that operates based on repeated distortions/transformations at the feature/signal level. Therefore, in this paper, we propose a framework for a cloud-based lightweight cancelable biometric authentication system. Findings from our study are used to demonstrate the potential for the proposed approach to be deployed in real-world settings (i.e., the capability to authenticate client devices with high accuracy and minimal overhead without affecting the security of the sensitive biometric templates in the cloud environment). Both theoretical and experimental analyses suggest that the proposed approach has a minimal equal error rate compared with those of the state-of-the-art techniques. Moreover, the proposed approach has been proven to consume less time, making it suitable for IoT environments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ipm.2018.04.011,Journal,Information Processing and Management,scopus,2019-05-01,sciencedirect,Real-time processing of social media with SENTINEL: A syndromic surveillance system incorporating deep learning for health classification,https://api.elsevier.com/content/abstract/scopus_id/85048575075,"Interest in real-time syndromic surveillance based on social media data has greatly increased in recent years. The ability to detect disease outbreaks earlier than traditional methods would be highly useful for public health officials. This paper describes a software system which is built upon recent developments in machine learning and data processing to achieve this goal. The system is built from reusable modules integrated into data processing pipelines that are easily deployable and configurable. It applies deep learning to the problem of classifying health-related tweets and is able to do so with high accuracy. It has the capability to detect illness outbreaks from Twitter data and then to build up and display information about these outbreaks, including relevant news articles, to provide situational awareness. It also provides nowcasting functionality of current disease levels from previous clinical data combined with Twitter data.
                  The preliminary results are promising, with the system being able to detect outbreaks of influenza-like illness symptoms which could then be confirmed by existing official sources. The Nowcasting module shows that using social media data can improve prediction for multiple diseases over simply using traditional data sources.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mfglet.2019.05.003,Journal,Manufacturing Letters,scopus,2019-04-01,sciencedirect,A blockchain enabled Cyber-Physical System architecture for Industry 4.0 manufacturing systems,https://api.elsevier.com/content/abstract/scopus_id/85066168835,"Cyber-Physical Production Systems (CPPSs) are complex manufacturing systems which aim to integrate and synchronize machine world and manufacturing facility to the cyber computational space. However, having intensive interconnectivity and a computational platform is crucial for real-world implementation of CPPSs. In this paper, the potential impacts of blockchain technology in development and realization of real-world CPPSs are discussed. A unified three-level blockchain architecture is proposed as a guideline for researchers and industries to clearly identify the potentials of blockchain and adapt, develop, and incorporate this technology with their manufacturing developments towards Industry 4.0.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eng.2018.11.027,Journal,Engineering,scopus,2019-04-01,sciencedirect,The State of the Art of Data Science and Engineering in Structural Health Monitoring,https://api.elsevier.com/content/abstract/scopus_id/85062663661,"Structural health monitoring (SHM) is a multi-discipline field that involves the automatic sensing of structural loads and response by means of a large number of sensors and instruments, followed by a diagnosis of the structural health based on the collected data. Because an SHM system implemented into a structure automatically senses, evaluates, and warns about structural conditions in real time, massive data are a significant feature of SHM. The techniques related to massive data are referred to as data science and engineering, and include acquisition techniques, transition techniques, management techniques, and processing and mining algorithms for massive data. This paper provides a brief review of the state of the art of data science and engineering in SHM as investigated by these authors, and covers the compressive sampling-based data-acquisition algorithm, the anomaly data diagnosis approach using a deep learning algorithm, crack identification approaches using computer vision techniques, and condition assessment approaches for bridges using machine learning algorithms. Future trends are discussed in the conclusion.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.forsciint.2019.02.028,Journal,Forensic Science International,scopus,2019-04-01,sciencedirect,Chat Analysis Triage Tool: Differentiating contact-driven vs. fantasy-driven child sex offenders,https://api.elsevier.com/content/abstract/scopus_id/85062400557,"Investigating crimes against children, specifically sexual solicitations, are complicated because not all offenders are contact-driven, meaning they want to meet the minor for sex in the physical world; instead, some offenders are fantasy-driven, in that they are more interested in cybersex and role-play. In addition, the sheer volume of cases involving the online sexual solicitation of minors makes it difficult for law enforcement to determine whether an offender is contact-driven vs. fantasy-driven. However, research shows that there are language-based differences between minors and contact-driven offenders vs. fantasy driven-offenders. Thus, we developed the Chat Analysis Triage Tool (CATT), a forensically sound investigative tool that, based on natural language processing methods, analyzes and compares chats between minors and contact-driven vs. non-contract driven offenders. Using an SVM classifier, we were successful in differentiating the classes based on character trigrams. In a matter of seconds, the existing algorithms provide an identification of an offender’s risk level based on the likelihood of contact offending as inferred from the model, which assists law enforcement in their ability to triage and prioritize cases involving the sexual solicitation of minors.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2019.103138,Journal,Journal of Biomedical Informatics,scopus,2019-04-01,sciencedirect,Distributed learning from multiple EHR databases: Contextual embedding models for medical events,https://api.elsevier.com/content/abstract/scopus_id/85062392033,"Electronic health record (EHR) data provide promising opportunities to explore personalized treatment regimes and to make clinical predictions. Compared with regular clinical data, EHR data are known for their irregularity and complexity. In addition, analyzing EHR data involves privacy issues and sharing such data is often infeasible among multiple research sites due to regulatory and other hurdles. A recently published work uses contextual embedding models and successfully builds one predictive model for more than seventy common diagnoses. Despite of the high predictive power, the model cannot be generalized to other institutions without sharing data. In this work, a novel method is proposed to learn from multiple databases and build predictive models based on Distributed Noise Contrastive Estimation (Distributed NCE). We use differential privacy to safeguard the intermediary information sharing. The numerical study with a real dataset demonstrates that the proposed method not only can build predictive models in a distributed manner with privacy protection, but also preserve model structure well and achieve comparable prediction accuracy. The proposed methods have been implemented as a stand-alone Python library and the implementation is available on Github (https://github.com/ziyili20/DistributedLearningPredictor) with installation instructions and use-cases.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.mehy.2019.02.021,Journal,Medical Hypotheses,scopus,2019-04-01,sciencedirect,Percolation theory for the recognition of patterns in topographic images of the cortical activity,https://api.elsevier.com/content/abstract/scopus_id/85061357293,"Electroencephalogram (EEG) is one of the mechanisms used to collect complex data. Its use includes evaluating neurological disorders, investigating brain function and correlations between EEG signals and real or imagined movements. The Topographic Image of Cortical Activity (TICA) records obtained by the EEG make it possible to observe, through color discrimination, the cortical areas that represent greater or lesser activity. Percolation Theory (PT) reveals properties on the aspects of fluid spreading from a central point, these properties being related to the aspects of the medium, topological characteristics and ease of penetration of a fluid in materials. The hypothesis presented so far considers that synaptic activities originate in points and spread from them, causing different areas of the brain to interact in a diffusive associative behavior, generating electric and magnetic fields by the currents that spread through the brain tissue and have an effect on the scalp sensors. Brain areas spatially separated create large-scale dynamic networks that are described by functional and effective connectivity. The proposition is that this phenomenon behaves like a fluidic spreading, so we can use the PT, through the topological analysis we detect specific signatures related to neural phenomena that manifest changes in the behavior of synaptic diffusion. This signature must be characterized by the Fractal Dimension (FD) values of the scattering clusters, these values will be used as properties in the k-Nearest Neighbors (kNN) method, an TICA will be categorized according to the degree of similarity to the preexisting patterns. In this context, our hypothesis will consolidate as a more computational resource in the service of medicine and another way that opens with the possibility of analysis and detailed inferences of the brain through TICA that go beyond a simply visual observation, as it happens in the present day.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.encep.2018.08.002,Journal,Encephale,scopus,2019-04-01,sciencedirect,Toward a motor signature in autism: Studies from human-machine interaction,https://api.elsevier.com/content/abstract/scopus_id/85057386595,"Background
                  Autism spectrum disorder (ASD) is a heterogeneous group of neurodevelopmental disorders which core symptoms are impairments in socio-communication and repetitive symptoms and stereotypies. Although not cardinal symptoms per se, motor impairments are fundamental aspects of ASD. These impairments are associated with postural and motor control disabilities that we investigated using computational modeling and developmental robotics through human-machine interaction paradigms.
               
                  Method
                  First, in a set of studies involving a human–robot posture imitation, we explored the impact of 3 different groups of partners (including a group of children with ASD) on robot learning by imitation. Second, using an ecological task, i.e. a real-time motor imitation with a tightrope walker (TW) avatar, we investigated interpersonal synchronization, motor coordination and motor control during the task in children with ASD (n
                     =29), TD children (n
                     =39) and children with developmental coordination disorder (n
                     =17, DCD).
               
                  Results
                  From the human–robot experiments, we evidenced that motor signature at both groups’ and individuals’ levels had a key influence on imitation learning, posture recognition and identity recognition. From the more dynamic motor imitation paradigm with a TW avatar, we found that interpersonal synchronization, motor coordination and motor control were more impaired in children with ASD compared to both TD children and children with DCD. Taken together these results confirm the motor peculiarities of children with ASD despite imitation tasks were adequately performed.
               
                  Discussion
                  Studies from human-machine interaction support the idea of a behavioral signature in children with ASD. However, several issues need to be addressed. Is this behavioral signature motoric in essence? Is it possible to ascertain that these peculiarities occur during all motor tasks (e.g. posture, voluntary movement)? Could this motor signature be considered as specific to autism, notably in comparison to DCD that also display poor motor coordination skills? We suggest that more work comparing the two conditions should be implemented, including analysis of kinematics and movement smoothness with sufficient measurement quality to allow spectral analysis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmii.2018.09.007,Journal,"Journal of Microbiology, Immunology and Infection",scopus,2019-04-01,sciencedirect,Implementation of a national quality improvement program to enhance hand hygiene in nursing homes in Taiwan,https://api.elsevier.com/content/abstract/scopus_id/85054556655,"Background/purpose
                  This study investigated the cause of hand hygiene deficit, and further implemented a quality improvement program using WHO's hand-hygiene strategy to enhance the compliance of hand hygiene in the nursing home in Taiwan.
               
                  Methods
                  This prospective study was conducted in eleven nursing homes in Taiwan from January 2015 to December 2016. After intervention, we monitor the compliance, and accuracy of hand hygiene. In addition, we also calculated the number of episodes of infection per 1000 resident-days in each nursing home in the intervention period (July–December 2015) and post-intervention period (January–October 2016).
               
                  Results
                  Overall, the consumption of alcohol-based handrubs increased from 10.1 ml per resident-day in intervention period to 12.2 ml per resident-day in post intervention period. The compliance of hand hygiene increased from 74% in intervention period to 79% in post-intervention period and the rate of correct hand hygiene increased from 81% in intervention period to 87% in post-intervention period. Most importantly, the infection density decreased from 2.39 per 1000 resident-day in intervention period to 1.89 per 1000 resident-day.
               
                  Conclusions
                  A national quality-improvement program using WHO's hand-hygiene strategy to enhance hand hygiene and reduce healthcare associated infection is effective in nursing homes in Taiwan.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1053/j.semvascsurg.2018.12.006,Journal,Seminars in Vascular Surgery,scopus,2019-03-01,sciencedirect,The pathway to a national vascular skills examination and the role of simulation-based training in an increasingly complex specialty,https://api.elsevier.com/content/abstract/scopus_id/85068518473,"The evolving demands of surgical training have led to the successful implementation of skills examinations in the areas of laparoscopic and endoscopic surgery. Currently, there is no similar formal skills assessment in vascular surgery, despite endovascular intervention replacing open surgery in treatment of many vascular conditions. The adoption of less invasive techniques to treat aneurysm and occlusive disease has resulted in new training paradigms and technical challenges for trainees. The duty hour restriction for trainees and declining numbers of complex open vascular interventions have added to the challenges of vascular surgery training. Simulation is a promising avenue for both skills training and assessment. The ability to evaluate the fundamental skills of trainees would be an important step to ensure a degree of uniformity in trainees’ technical abilities. The role of simulation-based training in acquiring, testing, and refining these skills is still in its infancy in the vascular surgery training paradigm. This article aims to impart a deeper understanding of the conditions for developing and implementing the fundamentals of vascular and endovascular surgery, and to provide guidance regarding the role of simulation-based training in a rapidly evolving specialty. There are various forms of simulation available, including benchtop models, high-fidelity simulators, and virtual-reality simulators, and each requires a different method of proficiency assessment. Both open surgery and endovascular skills can be assessed and the application of successful implementation in academic vascular surgery training program is presented.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2019.01.014,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2019-03-01,sciencedirect,An analytical method for measuring the Parkinson's disease progression: A case on a Parkinson's telemonitoring dataset,https://api.elsevier.com/content/abstract/scopus_id/85060099109,"The use of machine learning techniques for early diseases diagnosis has attracted the attention of scholars worldwide. Parkinson’s Disease (PD) is one of themost common neurological and complicated diseases affecting the central nervous system. Unified Parkinson’s Disease Rating Scale (UPDRS) is widely used for tracking PD symptom progression. Motor- and Total-UPDRS are two important clinical scales of PD. The aim of this study is to predict UPDRS scores through analyzing the speech signal properties which is important in PD diagnosis. We take the advantages of ensemble learning and dimensionality reduction techniques and develop a new hybrid method to predict Total- and Motor-UPDRS. We accordingly improve the time complexity and accuracy of the PD diagnosis systems, respectively, by using Singular Value Decomposition (SVD) and ensembles of Adaptive Neuro-Fuzzy Inference System (ANFIS). We evaluate our method on a large PD dataset and present the results. The results showed that the proposed method is effective in predicting PD progression by improving the accuracy and computation time of the disease diagnosis. The method can be implemented as a medical decision support system for real-time PD diagnosis when big data from the patients is available in the medical datasets.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.09.033,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Life Model: A novel representation of life-long temporal sequences in health predictive analytics,https://api.elsevier.com/content/abstract/scopus_id/85054711685,"Predictive analytics in healthcare can prevent patients’ emergency health conditions, and reduce costs in the long term. Moreover, accurate and timely anomaly predictions by focusing on recent events can save lives. In real-time IoT predictive analytics, modeling historical temporal health records with missing values in diagnosis prediction is a major challenge. Recent studies have started using deep learning and data abstraction techniques to model health data. However, it is difficult to train a model to predict anomalies based on temporal sparse data, especially to classify all disease diagnosis classes. Modeling a lifetime of an individual’s medical history in a short, concise sequence is a challenge. Moreover, the model should be robust and preserve the concept of time for variety of examples despite the missing values; especially in an IoT system, in which real-time prediction depends on both recent data and historical records.
                  The proposed solution in this research for modelingtemporal pattern sequences is called as Life Model (LM). 
                        L
                        M
                      provides a concise sequence to represent the history or future, using the novel intensity temporal sequence (ITS) tensors. LM algorithms and properties enable ITS tensors to train long short-term memory (LSTM) recurrent neural networks (RNN) efficiently in order to predict anomalies and diagnosis in real-time, even in the absence of some values.
                  LM is used to predict mortality of 10,000 patients from MIMIC III dataset based on their diagnosis and procedures codes. The results show improvement in the model trained by LM-mapped data compared to fixed-sized intervals which achieved an accuracy of 99.6% with AUROC and brier score of 99.5% and of 0.00 respectively. In addition, the LM model can predict the approximate time of activities, with different granularity of seconds and up to years; tested on an activity dataset.
                  Furthermore, a new LM-powered predictive health analytics and real-time monitoring schema (PHARMS) is proposed to enable design and implementation of predictive health analytic systems. PHARMS uses deep learning for real-time minimally-invasive intelligent activity monitoring and predictive analysis in a medical IoT scheme.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2018.06.002,Journal,Information Fusion,scopus,2019-03-01,sciencedirect,Data fusion and multiple classifier systems for human activity detection and health monitoring: Review and open research directions,https://api.elsevier.com/content/abstract/scopus_id/85048959618,"Activity detection and classification using different sensor modalities have emerged as revolutionary technology for real-time and autonomous monitoring in behaviour analysis, ambient assisted living, activity of daily living (ADL), elderly care, rehabilitations, entertainments and surveillance in smart home environments. Wearable devices, smart-phones and ambient environments devices are equipped with variety of sensors such as accelerometers, gyroscopes, magnetometer, heart rate, pressure and wearable camera for activity detection and monitoring. These sensors are pre-processed and different feature sets such as time domain, frequency domain, wavelet transform are extracted and transform using machine learning algorithm for human activity classification and monitoring. Recently, deep learning algorithms for automatic feature representation have also been proposed to lessen the burden of reliance on handcrafted features and to increase performance accuracy. Initially, one set of sensor data, features or classifiers were used for activity recognition applications. However, there are new trends on the implementation of fusion strategies to combine sensors data, features and classifiers to provide diversity, offer higher generalization, and tackle challenging issues. For instances, combination of inertial sensors provide mechanism to differentiate activity of similar patterns and accurate posture identification while other multimodal sensor data are used for energy expenditure estimations, object localizations in smart homes and health status monitoring. Hence, the focus of this review is to provide in-depth and comprehensive analysis of data fusion and multiple classifier systems techniques for human activity recognition with emphasis on mobile and wearable devices. First, data fusion methods and modalities were presented and also feature fusion, including deep learning fusion for human activity recognition were critically analysed, and their applications, strengths and issues were identified. Furthermore, the review presents different multiple classifier system design and fusion methods that were recently proposed in literature. Finally, open research problems that require further research and improvements are identified and discussed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2018.02.011,Journal,Future Generation Computer Systems,scopus,2019-03-01,sciencedirect,Collaborative prognostics in Social Asset Networks,https://api.elsevier.com/content/abstract/scopus_id/85042391186,"With the spread of Internet of Things (IoT) technologies, assets have acquired communication, processing and sensing capabilities. In response, the field of Asset Management has moved from fleet-wide failure models to individualised asset prognostics. Individualised models are seldom truly distributed, and often fail to capitalise the processing power of the asset fleet. This leads to hardly scalable machine learning centralised models that often must find a compromise between accuracy and computational power. In order to overcome this, we present a novel theoretical approach to collaborative prognostics within the Social Internet of Things. We introduce the concept of Social Asset Networks, defined as networks of cooperating assets with sensing, communicating and computing capabilities. In the proposed approach, the information obtained from the medium by means of sensors is synthesised into a Health Indicator, which determines the state of the asset. The Health Indicator of each asset evolves according to an equation determined by a triplet of parameters. Assets are given the form of the equation but they ignore their parametric values. To obtain these values, assets use the equation in order to perform a non-linear least squares fit of their Health Indicator data. Using these estimated parameters, they are interconnected to a subset of collaborating assets by means of a similarity metric. We show how by simply interchanging their estimates, networked assets are able to precisely determine their Health Indicator dynamics and reduce maintenance costs. This is done in real time, with no centralised library, and without the need for extensive historical data. We compare Social Asset Networks with the typical self-learning and fleet-wide approaches, and show that Social Asset Networks have a faster convergence and lower cost. This study serves as a conceptual proof for the potential of collaborative prognostics for solving maintenance problems, and can be used to justify the implementation of such a system in a real industrial fleet.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.10.063,Journal,Neurocomputing,scopus,2019-02-15,sciencedirect,Deep convolutional extreme learning machines: Filters combination and error model validation,https://api.elsevier.com/content/abstract/scopus_id/85056670642,"In recent years, deep convolutional neural network models have been increasingly used in various computer vision tasks, like plate number recognition, object recognition, automatic digit recognition, and medical applications supporting diagnosis by signals or images. A disadvantage of these networks is the long training time. It can take days to adjust weights with iterative methods based on gradient descent. This can be an obstacle in applications that need frequent training or in real time. Fast convolutional networks avoid gradient-based methods by efficiently defining filters in feature extraction and weights in classification. The issue is how to set the convolutional filter banks, since they are not learned by the backpropagation of gradients? In this work we propose a deep fast convolutional neural network based on extreme learning machine and a fixed bank of filters. We demonstrate that our model is feasible to be used in cost-effective non-specialized computer hardware, performing the training task faster than models running on GPUs. Results were generated on EMNIST dataset representing the widely studied problem of digit recognition. We provide a deep convolutional extreme learning machine (CELM) with two feature extraction stages and combinations of selected filters. For the proposed network, we find that the empirical generalization error is explained by the error model based on a theorem by Rahimi and Retch. In comparison to the state-of-the-art, the proposed network resulted in superior accuracy as well as competitive training time, even in relation to approaches that employ processing in GPUs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.comnet.2018.11.024,Journal,Computer Networks,scopus,2019-02-11,sciencedirect,PAIN: A Passive Web performance indicator for ISPs,https://api.elsevier.com/content/abstract/scopus_id/85057533904,"Understanding the quality of web browsing enjoyed by users is key to optimize services and keep users’ loyalty. This is crucial for both Content Providers and Internet Service Providers (ISPs). Quality is intrinsically subjective, and the complexity of today’s websites challenges its measurement. Objective metrics like OnLoad time and SpeedIndex are notable attempts to quantify web performance. However, these metrics can only be computed by instrumenting the browser and, thus, are not available to ISPs.
                  PAIN (PAssive INdicator) is an automatic system to monitor the performance of websites from passive measurements. It is open source and available for download. It leverages only flow-level and DNS measurements which are still possible in the network despite the deployment of HTTPS. With unsupervised learning, PAIN automatically creates a model from the timeline of requests issued by browsers to render web pages, and uses it to measure website performance in real-time.
                  We compare PAIN to objective metrics based on in-browser instrumentation and find strong correlations between the approaches. PAIN correctly highlights worsening network conditions and provides visibility into websites performance. We let PAIN run on an operational ISP network, and find that it is able to pinpoint performance variations across time and groups of users.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.oceaneng.2019.01.003,Journal,Ocean Engineering,scopus,2019-02-01,sciencedirect,Data management for structural integrity assessment of offshore wind turbine support structures: data cleansing and missing data imputation,https://api.elsevier.com/content/abstract/scopus_id/85061324147,"Structural Health Monitoring (SHM) and Condition Monitoring (CM) Systems are currently utilised to collect data from offshore wind turbines (OWTs), to enhance the accurate estimation of their operational performance. However, industry accepted practices for effectively managing the information that these systems provide have not been widely established yet. This paper presents a four-step methodological framework for the effective data management of SHM systems of OWTs and illustrates its applicability in real-time continuous data collected from three operational units, with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures. Firstly, a time-efficient synchronisation method that enables the continuous monitoring of these systems is presented, followed by a novel approach to noise cleansing and the posterior missing data imputation (MDI). By the implementation of these techniques those data-points containing excessive noise are removed from the dataset (Step 2), advanced numerical tools are employed to regenerate missing data (Step 3) and fatigue is estimated for the results of these two methodologies (Step 4). Results show that after cleansing, missing data can be imputed with an average absolute error of 2.1%, while this error is kept within the [+ 15.2%−11.0%] range in 95% of cases. Furthermore, only 0.15% of the imputed data fell outside the noise thresholds. Fatigue is found to be underestimated both, when data cleansing does not take place and when it takes place but MDI does not. This makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.therap.2018.12.002,Journal,Therapie,scopus,2019-02-01,sciencedirect,"Early access to health products in France: Major advances of the French “Conseil stratégique des industries de santé” (CSIS) to be implemented (modalities, regulations, funding)",https://api.elsevier.com/content/abstract/scopus_id/85061149651,"In a context of perpetual evolution of treatments, access to therapeutic innovation is a major challenge for patients and the various players involved in the procedures of access to medicines. The revolutions in genomic and personalized medicine, artificial intelligence and biotechnology will transform the medicine of tomorrow and the organization of our health system. It is therefore fundamental that France prepares for these changes and supports the development of its companies in these new areas. The recent “Conseil stratégique des industries de santé” launched by Matignon makes it possible to propose a regulatory arsenal conducive to the implementation and diffusion of therapeutic innovations. In this workshop, we present a number of proposals, our approach having remained pragmatic with a permanent concern to be effective in the short term for the patients and to simplify the procedures as much as possible. This was achieved thanks to the participation in this workshop of most of the players involved (industrial companies, “Agence nationale de sécurité du médicament et des produits de santé”, “Haute Autorité de santé”, “Institut national du cancer”, “Les entreprises du médicament”, hospitals, “Observatoire du médicament, des dispositifs médicaux et de l’innovation thérapeutique”…). The main proposals tend to favor the implementation of clinical trials on our territory, especially the early phases, a wider access to innovations by favoring early access programs and setting up a process called “autorisation temporaire d’utilisation d’extension” (ATUext) that make it possible to prescribe a medicinal product even if the latter has a marketing authorisation in another indication. In addition, we propose a conditional reimbursement that will be available based on preliminary data but will require re-evaluation based on consolidated data from clinical trials and/or real-life data. Finally, in order to better carry out these assessments, with a view to access or care, we propose the establishment of partnership agreements with health agencies/hospitals in order to encourage the emergence of field experts, in order to prioritize an ascending expertise closer to patients’ needs and to real life.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dib.2018.12.063,Journal,Data in Brief,scopus,2019-02-01,sciencedirect,PADI-web corpus: Labeled textual data in animal health domain,https://api.elsevier.com/content/abstract/scopus_id/85059576151,"Monitoring animal health worldwide, especially the early detection of outbreaks of emerging pathogens, is one of the means of preventing the introduction of infectious diseases in countries (Collier et al., 2008) [3]. In this context, we developed PADI-web, a Platform for Automated extraction of animal Disease Information from the Web (Arsevska et al., 2016, 2018). PADI-web is a text-mining tool that automatically detects, categorizes and extracts disease outbreak information from Web news articles. PADI-web currently monitors the Web for five emerging animal infectious diseases, i.e., African swine fever, avian influenza including highly pathogenic and low pathogenic avian influenza, foot-and-mouth disease, bluetongue, and Schmallenberg virus infection. PADI-web collects Web news articles in near-real time through RSS feeds. Currently, PADI-web collects disease information from Google News because of its international and multiple language coverage. We implemented machine learning techniques to identify the relevant disease information in texts (i.e., location and date of an outbreak, affected hosts, their numbers and clinical signs). In order to train the model for Information Extraction (IE) from news articles, a corpus in English has been manually labeled by domain experts. This labeled corpus (Rabatel et al., 2017) is presented in this data paper.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gaitpost.2018.11.029,Journal,Gait and Posture,scopus,2019-02-01,sciencedirect,"Three-dimensional cameras and skeleton pose tracking for physical function assessment: A review of uses, validity, current developments and Kinect alternatives",https://api.elsevier.com/content/abstract/scopus_id/85057183966,"Background
                  Three-dimensional camera systems that integrate depth assessment with traditional two-dimensional images, such as the Microsoft Kinect, Intel Realsense, StereoLabs Zed and Orbecc, hold great promise as physical function assessment tools. When combined with point cloud and skeleton pose tracking software they can be used to assess many different aspects of physical function and anatomy. These assessments have received great interest over the past decade, and will likely receive further study as the integration of depth sensing and augmented reality smartphone cameras occurs more in everyday life.
               
                  Research Question
                  The aim of this review is to discuss how these devices work, what options are available, the best methods for performing assessments and how they can be used in the future.
               
                  Methods
                  Firstly, a review of the Microsoft Kinect devices and associated artificial intelligence, automated skeleton tracking algorithms is provided. This includes a narrative critique of the validity and clinical utility of these devices for assessing different aspects of physical function including spatiotemporal, kinematic and inverse dynamics data derived from gait and balance trials, and anatomical assessments performed using the depth sensor information. Methods for improving the accuracy of data are examined, including multiple-camera systems and sensor fusion with inertial monitoring units, model fitting, and marker tracking. Secondly, alternative hardware, including other structured light and time of flight methods, stereoscopic cameras and augmented reality leveraging smartphone and tablet cameras to perform measurements in three-dimensional space are summarised. Software options related to depth sensing cameras are then discussed, focussing on recent advances such as OpenPose and web-based methods such as PoseNet.
               
                  Results and Significance
                  The clinical and non-laboratory utility of these devices holds great promise for physical function assessment, and recent developments could strengthen their ability to provide important and impactful health-related data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2018.11.003,Journal,Medical Image Analysis,scopus,2019-02-01,sciencedirect,Motion artifact recognition and quantification in coronary CT angiography using convolutional neural networks,https://api.elsevier.com/content/abstract/scopus_id/85056852038,"Excellent image quality is a primary prerequisite for diagnostic non-invasive coronary CT angiography. Artifacts due to cardiac motion may interfere with detection and diagnosis of coronary artery disease and render subsequent treatment decisions more difficult. We propose deep-learning-based measures for coronary motion artifact recognition and quantification in order to assess the diagnostic reliability and image quality of coronary CT angiography images. More specifically, the application, steering and evaluation of motion compensation algorithms can be triggered by these measures. A Coronary Motion Forward Artifact model for CT data (CoMoFACT) is developed and applied to clinical cases with excellent image quality to introduce motion artifacts using simulated motion vector fields. The data required for supervised learning is generated by the CoMoFACT from 17 prospectively ECG-triggered clinical cases with controlled motion levels on a scale of 0–10. Convolutional neural networks achieve an accuracy of 93.3% ± 1.8% for the classification task of separating motion-free from motion-perturbed coronary cross-sectional image patches. The target motion level is predicted by a corresponding regression network with a mean absolute error of 1.12 ± 0.07. Transferability and generalization capabilities are demonstrated by motion artifact measurements on eight additional CCTA cases with real motion artifacts.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.wneu.2018.10.091,Journal,World Neurosurgery,scopus,2019-02-01,sciencedirect,Surgical Management of Isolated Fourth Ventricular Hydrocephalus Associated with Injury to the Guillain-Mollaret Triangle,https://api.elsevier.com/content/abstract/scopus_id/85056639302,"Background
                  The occurrence of isolated fourth ventricle and injury to the Guillain-Mollaret triangle in the setting of posterior fossa ependymoma represents a new association. In this case report, we discuss the clinical, theoretical, and therapeutic aspects of this problem. We describe a lateral transcerebellar trajectory and shunt valve configuration for safe fourth ventricle shunting in a patient with prior posterior fossa surgery.
               
                  Case Description
                  A 45-year-old woman underwent subtotal resection of a fourth ventricle ependymoma (World Health Organization grade III) followed by radiation therapy to control the residual tumor. Her course was complicated by a cerebral abscess and subsequent communicating hydrocephalus, for which she received a lateral ventriculoperitoneal shunt. After placement of the lateral ventricle shunt, there was a progressive increase in the volume of the fourth ventricle over the next 2 years, from 2.5 to 12.0 mL. She developed palatal myoclonus, hand incoordination, bilateral foot numbness, and progressive ataxia. Neuroimaging also revealed hypertrophic degeneration of the inferior olivary nuclei bilaterally. The isolated fourth ventricle was treated by a separate fourth ventriculoperitoneal shunt inserted through a lateral transcerebellar trajectory. A programmable variable pressure valve was implemented.
               
                  Conclusions
                  Development of an isolated fourth ventricle and injury to the Guillain-Mollaret triangle in the setting of fourth ventricular ependymoma is a newly encountered complication. Choice of treatment modality and timing of intervention should be carefully considered on a case-by-case basis. The data presented in this report may assist in the selection of surgical treatment for isolated fourth ventricle.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.scitotenv.2018.08.221,Journal,Science of the Total Environment,scopus,2019-01-15,sciencedirect,Design and implementation of a hybrid model based on two-layer decomposition method coupled with extreme learning machines to support real-time environmental monitoring of water quality parameters,https://api.elsevier.com/content/abstract/scopus_id/85051670088,"Accurate prediction of water quality parameters plays a crucial and decisive role in environmental monitoring, ecological systems sustainability, human health, aquaculture and improved agricultural practices. In this study a new hybrid two-layer decomposition model based on the complete ensemble empirical mode decomposition algorithm with adaptive noise (CEEMDAN) and the variational mode decomposition (VMD) algorithm coupled with extreme learning machines (ELM) and also least square support vector machine (LSSVM) was designed to support real-time environmental monitoring of water quality parameters, i.e. chlorophyll-a (Chl-a) and dissolved oxygen (DO) in a Lake reservoir. Daily measurements of Chl-a and DO for June 2012–May 2013 were employed where the partial autocorrelation function was applied to screen the relevant inputs for the model construction. The variables were then split into training, validation and testing subsets where the first stage of the model testing captured the superiority of the ELM over the LSSVM algorithm. To improve these standalone predictive models, a second stage implemented a two-layer decomposition with the model inputs decomposed in the form of high and low frequency oscillations, represented by the intrinsic mode function (IMF) through the CEEMDAN algorithm. The highest frequency component, IMF1 was further decomposed with the VMD algorithm to segregate key model input features, leading to a two-layer hybrid VMD-CEEMDAN model. The VMD-CEEMDAN-ELM model was able to reduce the root mean square and the mean absolute error by about 14.04% and 7.12% for the Chl-a estimation and about 5.33% and 4.30% for the DO estimation, respectively, compared with the standalone counterparts. Overall, the developed methodology demonstrates the robustness of the two-phase VMD-CEEMDAN-ELM model in identifying and analyzing critical water quality parameters with a limited set of model construction data over daily horizons, and thus, to actively support environmental monitoring tasks, especially in case of high-frequency, and relatively complex, real-time datasets.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-817356-5.00012-7,Book,Internet of Things in Biomedical Engineering,scopus,2019-01-01,sciencedirect,Internet of Things Application in Life Sciences,https://api.elsevier.com/content/abstract/scopus_id/85124928251,"Sensors, smart devices, and automated systems have been used in life sciences industries for the benefit of patients and medical personnel for the diagnosis of disease, monitoring of patient conditions, treatment of chronic conditions, and manufacturing and distribution of drugs. The Internet of Things (IoT) has been implemented for connecting sensors and networked devices and collecting and analyzing the experimental data obtained from those sensors and actuators. IoT-based devices and microchips have been used to collect patient health history and records, to understand the functions of the internal organs, and to capture pictures and videos of the human body from the inside. They have proven to be of great benefit in research and to facilitate patient treatment and efficient drug manufacturing. In recent years, inventions such as smart wheelchairs for disabled people to move around more easily; wristbands for analyzing oxygen levels and monitoring heartbeat, temperature, and blood pressure; a pill-shaped camera to capture pictures; and the linking of these devices with smartphone apps have made it possible to monitor, study, and keep track of the conditions of patients and their daily life in real time. With its recent advances, the application of IoT in the life sciences fields has provided better tools and devices to diagnose diseases in their initial stages, to study the effectiveness of a drug in the patient’s body, and to invent and test new drugs efficiently in less time and for less money. The IoT enables remote monitoring of patients and products connecting these sensors and devices. This provides real-time information on patients, which reduces effort and cost and improves treatment outcomes and efficiency. Also, the data collected from these devices have provided information for study and research into the betterment of human health in the field of life sciences. With the application of machine learning and deep learning approaches, vital conclusions can be drawn from big data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-817356-5.00014-0,Book,Internet of Things in Biomedical Engineering,scopus,2019-01-01,sciencedirect,Combining Predictive Analytics and Artificial Intelligence With Human Intelligence in IoT-Based Image-Guided Surgery,https://api.elsevier.com/content/abstract/scopus_id/85123886383,"When analyzing the history of medical surgery, we can see that humans have developed and refined instruments for surgical procedures. Evolution in medical advancements is on a par with that observed in the disease-causing agents and viruses. Starting from a medical era during which invasive surgeries were performed without anesthesia, the need for painless, safe, hygienic, and successful surgeries has led to the modern era of surgery, which has a relatively small mortality rate. The practical use of minimally invasive approaches that result in fewer wound-related complications, quick organ function return, and shorter hospitalizations has led to higher acceptance of image-guided surgical procedures. In our proposed system, we present an IoT-based surgical model that involves a virtual reality-based (VR-based) user interface, predictive analytics that predict the “what-ifs” for an activity to be performed during the surgery based on the data collected during similar previous surgeries, and artificial intelligence that learns from the same dataset used by predictive analytics to assist surgeons during the surgery. Virtual reality refers to an environment artificially created by the support of computer software. When humans access such an environment, they believe that they are actually there in the artificially created environment. Headsets and other navigators can be used along with the VR set-up in order to provide a more immersive environment. The experience obtained through the power of VR is no less than the actual reality. For a more immersive experience, the Oculus Rift VR system is to be used as part of the proposed model. The VR system is to be connected to the SAP IoT interface of the SAP Cloud system. Predictive analytics is one of the latest software paradigms that enables analysis of large datasets and prediction of future outcomes and behavior. It involves building a predictive analytics model by using big data and IoT sensors to uncover hidden risks, explore unforeseen opportunities, and reach a better understanding. In our proposed model, SAP predictive analytics is to be deployed to build a surgical predictive model that could provide real-time predictions during surgery based on the data collected during previous surgeries. Artificial intelligence is a computing paradigm used to create systems that automate intelligent processes. AI can be used for learning, problem solving, and decision-making processes and can work with a speed and precision that humans are able to achieve only with great effort. AI is to be deployed in our proposed surgical model to minimize the surgeons’ efforts in navigating the noninvasive surgical equipment and the camera. Often there is a difference between the intention with which a surgeon navigates and the actual navigation which happens internally during the surgery. The surgeon has to put in more effort to overcome this mismatch. In order to address this issue, formulating AI in the surgical internal device navigation could result in reduced manual effort by the surgeon, which in turn would help him in concentrating on comparatively more important surgical thoughts and activities. The SAP Leonardo Machine Learning feature is to be deployed in the proposed model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/C2018-0-04060-8,Book,Innovation in Health Informatics: A Smart Healthcare Primer,scopus,2019-01-01,sciencedirect,Innovation in health informatics: A smart healthcare primer,https://api.elsevier.com/content/abstract/scopus_id/85093486650,Unknown,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-819178-1.00035-6,Book,"Precision Medicine for Investigators, Practitioners and Providers",scopus,2019-01-01,sciencedirect,Precision medicine in ophthalmology: An evolving revolution in diagnostic and therapeutic tools,https://api.elsevier.com/content/abstract/scopus_id/85093483812,"Precision medicine refers to a stratification of patients using a wide array of individual-specific data to enable precise targeting of disease subgroups with the best available diagnostic and therapeutic approaches. Within ophthalmology, this strategy is being applied successfully and is most evident in the management of the inherited diseases. This paradigm shift in provision of care is accelerated by the emergence of novel imaging technologies, robotics, and artificial intelligence, as well as emerging technologies that integrate bioinformatics data into clinically relevant knowledge. This knowledge is used in turn to develop a system capable of supporting clinical decision-making and utilization of high-precision therapeutic options in both a personalized and cost-effective way. Examples of the diverse areas making rapid progress toward full implementation of precision medicine include, but are not limited to, ocular genetic diseases, robotic surgery, virtual reality simulations, modern imaging techniques, and the role of healthcare providers.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-818318-2.00009-X,Book,Handbook of Data Science Approaches for Biomedical Engineering,scopus,2019-01-01,sciencedirect,Semisupervised fuzzy clustering methods for X-ray image segmentation,https://api.elsevier.com/content/abstract/scopus_id/85084967350,"In the modern world, people care more about dental health care, and dentistry has an important role in our health. Using dental X-ray images, dentists can diagnose possible dental diseases and create an effective treatment for patients. In this chapter, we introduce several machine learning methods to segment the dental images to support dentists in dental disease diagnoses. The proposed methods have been implemented on the real dataset of radiography patients from Hanoi Medical University Hospital. The empirical results show that these methods have a higher performance than the related ones through various validity indices. The content of this chapter presents the results of our research that has been performed since 2015.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2020.01.333,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,Prognostic health management of production systems. New proposed approach and experimental evidences,https://api.elsevier.com/content/abstract/scopus_id/85082764769,"Prognostic Health Management (PHM) is a maintenance policy aimed at predicting the occurrence of a failure in components and consequently minimizing unexpected downtimes of complex systems. Recent developments in condition monitoring (CM) techniques and Artificial Intelligence (AI) tools enabled the collection of a huge amount of data in real-time and its transformation into meaningful information that will support the maintenance decision-making process. The emerging Cyber-Physical Systems (CPS) technologies connect distributed physical systems with their virtual representations in the cyber computational world. The PHM assumes a key role in the implementation of CPS in manufacturing contexts, since it allows to keep CPS and its machines in proper conditions. On the other hand, CPS-based PHM provide an efficient solution to maximize availability of machines and production systems. In this paper, evolving and unsupervised approaches for the implementation of PHM at a component level are described, which are able to process streaming data in real-time and with almost-zero prior knowledge about the monitored component. A case study from a real industrial context is presented. Different unsupervised and online anomaly detection methods are combined with evolving clustering models in order to detect anomalous behaviours in streaming vibration data and integrate the so-generated knowledge into supervised and adaptive models; then, the degradation model for each identified fault is built and the resulting RUL prediction model integrated into the online analysis. Supervised methods are applied to the same dataset, in batch mode, to validate the proposed procedure.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-815956-9.00006-5,Book,Technology in Supply Chain Management and Logistics: Current Practice and Future Applications,scopus,2019-01-01,sciencedirect,Emerging technologies in the health-care supply chain,https://api.elsevier.com/content/abstract/scopus_id/85082603106,"In this chapter, the background and organization of the health-care supply chain are reviewed, and the impact of emerging technologies is described. Maturing technologies, including optimization software, sensors/telematics, cloud computing, data warehouse systems, and automated storage and retrieval, are examined. Growth technologies, including mobility, wearable devices, data analytics, and social media, are examined as they potentially relate to the health-care supply chain. Emerging technologies, including 3D printing, drone delivery, and autonomous vehicles, are presented and examples provided on their use in the health-care supply chain. Exponential technologies, including blockchain, the Internet of Things, virtual/augmented reality, and artificial intelligence, are described with respect to potential applications in the health-care supply chain. Future changes in the external environment of health care, including decentralization, new competitors, and the increased use of telemedicine, are described with respect to impacts on the health-care supply chain.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.12.023,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Next generation IoT and its influence on decision-making. An illustrative case study,https://api.elsevier.com/content/abstract/scopus_id/85081057182,"The next generation of IoT is characterized by the usage of smart solutions with embedded intelligence at the edge that relies on high connectivity, processing capabilities for edge devices and real-time analysis of information. This evolution is based on the convergence of some key ICT technologies like hyperconnectivity and new network architectures, edge computing, artificial intelligence, and blockchain. Considering the high expectations regarding the wide use in various domains of the new, interoperable IoT platforms built on these technologies, it is assumed that they will influence also the decision-making processes specific to these domains. The paper provides a short overview of these technologies with the aim to identify such potential influences. Then a case study in the field of health monitoring is presented, which consists in proposing a new version of a current pilot solution built around the sensing service offer integrator role. This new version is compliant with the RO-Smart Ageing architecture and will provide specific support for all three decision levels implemented in the medical unit practice, with special emphases on risk evaluation in real time monitoring regime.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.12.226,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Unsupervised Neural Network for Homography Estimation in Capsule Endoscopy Frames,https://api.elsevier.com/content/abstract/scopus_id/85079875072,"Capsule endoscopy is becoming the major medical technique for the examination of the gastrointestinal tract, and the detection of small bowel lesions. With the growth of endoscopic capsules and the lack of an appropriate tracking system to allow the localization of lesions, the need to develop software-based techniques for the localisation of the capsule at any given frame is also increasing. With this in mind, and knowing the lack of availability of labelled endoscopic datasets, this work aims to develop a unsupervised method for homography estimation in video capsule endoscopy frames, to later be applied in capsule localisation systems. The pipeline is based on an unsupervised convolutional neural network, with a VGG Net architecture, that estimates the homography between two images. The overall error, using a synthetic dataset, was evaluated through the mean average corner error, which was 34 pixels, showing great promise for the real-life application of this technique, although there is still room for the improvement of its performance.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.09.442,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Unmanned aerial vehicle in the machine learning environment,https://api.elsevier.com/content/abstract/scopus_id/85079097933,"Unmanned Aerial Vehicles and machine learning have started gaining attentions of academic and industrial research. The Unmanned Aerial Vehicles have extended the freedom to operate and monitor the activities from remote locations. This study retrieved and synthesized research on the use of Unmanned Aerial Vehicles along with machine learning and its algorithms in different areas and regions. The objective was to synthesize the scope and importance of machine learning models in enhancing Unmanned Aerial Vehicles capabilities, solutions to problems, and numerous application areas.
                  The machine learning implementation has reduced numbers of challenges to Unmanned Aerial Vehicles besides enhancing the capabilities and opening the door to the different sectors. The Unmanned Aerial Vehicles and machine learning association has resulted in fast and reliable outputs. The combination of Unmanned Aerial Vehicles and machine learning has helped in real time monitoring, data collection and processing, and prediction in the computer/wireless networks, smart cities, military, agriculture, and mining.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.09.458,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,A comparative study of predictive approaches for load forecasting in smart buildings,https://api.elsevier.com/content/abstract/scopus_id/85079086707,"Predicting electricity consumption represents one of most important information for efficient energy management in smart buildings. It is mainly used for occupancy prediction and the development of optimized control approaches of building’s appliances (e.g., lighting and heating/air conditioning systems). Recently, several approaches have been proposed for load profiling, prediction and forecasting. The work presented in this paper is towards the development of load forecasting approaches for being integrated for occupancy prediction and context-driven control of building’s appliances. We mainly investigated the accuracy of various machine learning and statistical methods for forecasting energy consumption. An IoT and Big Data based platform was deployed for gathering near-real time data about electricity/load consumption. Recorded data were used to deploy predictive models using ARIMA, SARIMA, XGBoost, Random Forest (RF), and Long Short-Term Memory. Experiments have been conducted and results are reported to shed more light on the accuracy of these methods for load forecasting.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2019.09.143,Conference Proceeding,IFAC-PapersOnLine,scopus,2019-01-01,sciencedirect,Machine Learning approaches for Anomaly Detection in Multiphase Flow Meters,https://api.elsevier.com/content/abstract/scopus_id/85076262725,"Multiphase Flow Meters (MPFM) are important metering tools in the oil and gas industry. A MPFM provides real-time measurements of gas, oil and water flows of a well without the need to separate the phases, a time-consuming procedure that has been classically adopted in the industry. Evaluating the composition of the flow is fundamental for the well management and productivity prediction; therefore, procedures for measuring quality assessment are of crucial importance. In this work we propose an Anomaly Detection approach to MPFM that is effectively able to hand the complexity and variability associated with MPFM data. The proposed approach is designed for embedded implementation and it exploits unsupervised Anomaly Detection approaches like Cluster Based Local Outlier Factor and Isolation Forest.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.09.069,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,An Innovative Technology: Augmented Reality Based Information Systems,https://api.elsevier.com/content/abstract/scopus_id/85076255225,"In our generation the information systems evolve with new technologies: augmented reality (AR), IoT, artificial intelligence, blockchain etc. Anymore they perform information exchange by sensors. It is estimated that the systems will be in a state of extreme interaction and reach 50 billion devices connected in Internet in 2020. We know that everything around us will be in interaction and they will do everything without any need of human interference. For example, when our dishwasher is full, it will start to wash automatically, or when the run out of the gasoline, our car will drive to the nearest station, or even when a burglar is entered to our house, it will automatically be detected and be announced to the police office. In business life, the processes will be automatical in maximum level and this technology will increase productivity and efficiency. Next to mobile technology, it is thought that these new generation information systems (IS) will take the biggest place in our lives. AR also will be integrated to these systems to augment the information in real world. Humanity will augment its habitat in an innovative way thanks to these AR based IS. This paper surveys the current state-of-the-art AR systems related with aerospace & defense, industry, education, medical and gaming sectors. The connection of AR based IS and innovation is explained with a technological insight. In addition to international use cases HAVELSAN’s use cases are also given that are performed from the aspect of applied open innovation strategy. This strategy is addressed specific to the implemented activities of AR based IS.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2019.08.224,Conference Proceeding,Procedia Computer Science,scopus,2019-01-01,sciencedirect,Air pollution mapping using mobile sensor based on internet of things,https://api.elsevier.com/content/abstract/scopus_id/85073097835,"Air pollution is hazardous to our health, especially carbon monoxide. It can cause diseases such as cough, runny nose, eye irritation, and even death. The main objective of this research is to create a device capable of detecting carbon monoxide pollution levels by using mobile sensors and map the results into heatmaps overlayed on Google Maps. We have implemented an integrated pollution monitoring and mapping system that consists of MQ-7 sensor, GPS, GSM, display module, Arduino board, and web-server. We also evaluated two sampling methods, time-based and distance-based sampling. Based on our experiments, the distance-based sampling method produced well-distributed data and closer to the expected between-samples distances compared to the time-based method. We have also shown that our system can run in real time to monitor the carbon monoxide pollution levels.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2018.12.017,Conference Proceeding,Procedia Manufacturing,scopus,2019-01-01,sciencedirect,AI based injection molding process for consistent product quality,https://api.elsevier.com/content/abstract/scopus_id/85072584818,"In manufacturing processes, Injection Molding is widely used for producing plastic components with large lot size. So, continuous improvements in product quality consistency is crucial to maintaining a competitive edge in the injection molding industry. Various optimization techniques like ANN, GA, Iterative method, and simulation based are being used for optimization of Injection Molding process and obtaining optimal processing conditions. But still due to variation during molding cycles, quality failure occurs. As many constituents like process, Material, machine together yields product quality. This paper is focused on Real time AI based control of process parameters in injection molding cycle. Process parameters and their interrelationship with quality failure has been studied and later supposed to be used to generate algorithm for compensating the deviation of process parameters. Pressure and temperature sensor assisted monitoring system is used to collect data in real time and based on its comparison with the standard values an interrelationship is formed between parameters and plastic material properties. Algorithm generates new process parameter values to compensate the deviation and machine control follows the same. The entire process is supposed to be smart and automatic after being trained with AI and machine learning techniques. Simulation using Moldflow software and real industry collected data has been used for understanding whole molding process establishing relationship between failure and parameters. An automotive product in real industry is chosen for data acquisition, implementation and validation of entire AI based system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jagp.2019.05.013,Journal,American Journal of Geriatric Psychiatry,scopus,2019-01-01,sciencedirect,A Future Research Agenda for Digital Geriatric Mental Healthcare,https://api.elsevier.com/content/abstract/scopus_id/85067070294,"The proliferation of mobile, online, and remote monitoring technologies in digital geriatric mental health has the potential to lead to the next major breakthrough in mental health treatments. Unlike traditional mental health services, digital geriatric mental health has the benefit of serving a large number of older adults, and in many instances, does not rely on mental health clinics to offer real-time interventions. As technology increasingly becomes essential in the everyday lives of older adults with mental health conditions, these technologies will provide a fundamental service delivery strategy to support older adults’ mental health recovery. Although ample research on digital geriatric mental health is available, fundamental gaps in the scientific literature still exist. To begin to address these gaps, we propose the following recommendations for a future research agenda: 1) additional proof-of-concept studies are needed; 2) integrating engineering principles in methodologically rigorous research may help science keep pace with technology; 3) studies are needed that identify implementation issues; 4) inclusivity of people with a lived experience of a mental health condition can offer valuable perspectives and new insights; and 5) formation of a workgroup specific for digital geriatric mental health to set standards and principles for research and practice. We propose prioritizing the advancement of digital geriatric mental health research in several areas that are of great public health significance, including 1) simultaneous and integrated treatment of physical health and mental health conditions; 2) effectiveness studies that explore diagnostics and treatment of social determinants of health such as “social isolation” and “loneliness;” and 3) tailoring the development and testing of innovative strategies to minority older adult populations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.imu.2018.12.002,Journal,Informatics in Medicine Unlocked,scopus,2019-01-01,sciencedirect,Implementation of a TCM-based computational health informatics diagnostic tool for Sub-Saharan African students,https://api.elsevier.com/content/abstract/scopus_id/85058678042,"Health status checkup is a crucial step towards early detection of diseases. Health status diagnosis, in university health centers, within the sub-Saharan African region, can be cumbersome and time consuming. In many cases, facilities for health checkup are not available. Traditional Chinese Medicine (TCM) is a promising approach, when integrated with in-silico methods. This study was conducted to implement a TCM-based computational health informatics diagnostic tool. The tool was applied to diagnose African students. This study was also conducted to stimulate further research into in-silico TCM diagnostics. Besides developing a reliable biometric verification system, to ascertain the real identities of patients brought to university health centers, it is assistive to create a platform that provides automated and complementary support for preliminary health diagnostic activities. It also mitigates stress, by helping to efficiently decipher and provide quick objective opinion from the perspective of a computerized decision support system. The diagnostic module of the computational health informatics diagnostic tool adopts knowledge from a TCM facial color diagnosis.
                  A comprehensive literature search was conducted for relevant full-text research papers. Only research publications written in English language were reviewed. The present work was compared qualitatively and quantitatively with the existing works noted in the literature. Facial detection and matching algorithms were implemented for the TCM-based computational health informatics diagnostic tool by using Java programming language. Facial image acquisition processes were conducted. Captured facial images of African students were preprocessed. Facial feature extraction was performed by implementing feature extraction algorithms. An algorithm for the extraction of color information and measurement was also implemented. Knowledge of machine learning was applied to extract and collate facial features, and to machine learn from them. Facial classification and recognition algorithms were implemented. Finally, the results from the computational health informatics diagnostic tool were evaluated, by conducting a performance evaluation and validation.
                  This study provides qualitative and quantitative information on facial recognition, facial color information measurement, as well as prediction of health status, for some sub-Saharan African University students. Performance evaluation was shown using confusion matrix and ROC curves. Statistical analysis of the experimental results was presented. The parameters in each diagnostic illustration were shown with valid range. In order to justify the effectiveness of the computational tool, further explanations were provided from relevant methodology guides on the evaluation of diagnostic tests.
                  The computational health informatics diagnostic tool will complement the diagnostic efforts in university health centers of sub-Saharan African universities. It will also be useful for personal health diagnosis of interested individuals. The tool will also be viable for educating health professionals. TCM will be of immense benefit to developing countries by positively contributing towards diagnosing different non-communicable diseases and some infectious diseases in such countries.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.impact.2018.12.001,Journal,NanoImpact,scopus,2019-01-01,sciencedirect,SUNDS probabilistic human health risk assessment methodology and its application to organic pigment used in the automotive industry,https://api.elsevier.com/content/abstract/scopus_id/85058641247,"The increasing use of engineered nanomaterials (ENMs) in nano-enabled products (NEPs) has raised societal concerns about their possible health and ecological implications. To ensure a high level of human and environmental protection it is essential to properly estimate the risks of these new materials and to develop adequate risk management strategies. To this end, we propose a quantitative Human Health Risk Assessment (HHRA) methodology, which was developed in the European Seventh Framework research project SUN (Sustainable Nanotechnologies) and implemented in the web-based SUN Decision Support System (SUNDS). One of the major strengths of this probabilistic approach as compared to its deterministic alternatives is its ability to clearly communicate the uncertainties in the estimated risks in order to support better risk communication for more objective decision making by industries and regulators.
                  To demonstrate this methodology, we applied it in a real case study involving a nanoscale organic red pigment used in the automotive industry. Our analysis clearly showed that the main source of uncertainty was the extrapolation from (sub)acute in vivo toxicity data to long-term risk. This extrapolation was necessary due to a lack of (sub)chronic in vivo studies for the investigated nanomaterial. Despite the high uncertainty in the final results due to the conservative assumptions made in the risks assessment, the estimated risks are acceptable for all investigated exposure scenarios along the product lifecycle.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2018.10.019,Journal,Journal of Neuroscience Methods,scopus,2019-01-01,sciencedirect,Unsupervised and real-time spike sorting chip for neural signal processing in hippocampal prosthesis,https://api.elsevier.com/content/abstract/scopus_id/85055320745,"Background
                  Damage to the hippocampus will result in the loss of ability to form new long-term memories and cognitive disorders. At present, there is no effective medical treatment for this issue. Hippocampal cognitive prosthesis is proposed to replace damaged regions of the hippocampus to mimic the function of original biological tissue. This prosthesis requires a spike sorter to detect and classify spikes in the recorded neural signal.
               
                  New method
                  A 16-channel spike sorting processor is presented in this paper, where all channels are considered as independent. An automatic threshold estimation method suitable for hardware implementation is proposed for the Osort clustering algorithm. A new distance metric is also introduced to facilitate clustering. Bayes optimal template matching classification algorithm is optimized to reduce computational complexity by introducing a preselection mechanism.
               
                  Results
                  The chip was fabricated in 40-nm CMOS process with a core area of 0.0175 mm2/ch and power consumption of 19.0 μW/ch. Synthetic and realistic test data are used to evaluate the chip. The test result shows that it has high performance on both data.
               
                  Comparison with existing method(s)
                  Compared with the other three spike sorting processors, the proposed chip achieves the highest detection and classification accuracy. It also has the ability to deal with partially overlapping spikes, which is not reported in the other work.
               
                  Conclusions
                  We have developed a 16-channel spike sorting chip used in hippocampal prosthesis, which provides unsupervised clustering and real-time detection and classification. It also has the ability to deal with partially overlapping spikes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2468-1253(18)30282-6,Journal,The Lancet Gastroenterology and Hepatology,scopus,2019-01-01,sciencedirect,Artificial intelligence and computer-aided diagnosis in colonoscopy: current evidence and future directions,https://api.elsevier.com/content/abstract/scopus_id/85053729467,"Computer-aided diagnosis offers a promising solution to reduce variation in colonoscopy performance. Pooled miss rates for polyps are as high as 22%, and associated interval colorectal cancers after colonoscopy are of concern. Optical biopsy, whereby in-vivo classification of polyps based on enhanced imaging replaces histopathology, has not been incorporated into routine practice because it is limited by interobserver variability and generally only meets accepted standards in expert settings. Real-time decision-support software has been developed to detect and characterise polyps, and also to offer feedback on the technical quality of inspection. Some of the current algorithms, particularly with recent advances in artificial intelligence techniques, match human expert performance for optical biopsy. In this Review, we summarise the evidence for clinical applications of computer-aided diagnosis and artificial intelligence in colonoscopy.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.smhl.2018.07.008,Journal,Smart Health,scopus,2018-12-01,sciencedirect,Are you smoking? Automatic alert system helping people keep away from cigarettes,https://api.elsevier.com/content/abstract/scopus_id/85059789843,"Tobacco smoking is responsible for one out of every five deaths in the US, according to the Centers for Disease Control and Prevention (CDC). Recent advances in treatment delivery include technology-based mobile health approaches, which seek to deliver real-time feedback to smokers to aid quit attempts and mitigate lapses. With regard to the measurement of smoking, clinical trials rely on participant self-report and/or biochemical verification of smoking status to evaluate outcomes. Wearable sensors have the potential to improve current approaches by providing personalized feedback and objective verification of smoking status (Burns, 2000). In this paper, we describe the development of a novel smoking cessation system that combines motion detection and an Android software application to monitor smoking in real-time. In this system, a personalized smoking cessation plan will be created based on the goal of complete cessation or smoking reduction. Once the plan is created, the mobile system will monitor the users׳ smoking activity and provide feedback. An LSTM algorithm has been computed to train and test the motion data, which was collected from two armbands, to detect smoking and non-smoking motions. The internet message service will be used to remind users to stick to their plan when the sensor detects current smoking. Related video links are pushed and pulled to the users via Short Message Service (SMS) to support smoking cessation. Findings have implications for tobacco cessation treatment delivery and assessment of smoking status.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/S2213-2600(18)30300-X,Journal,The Lancet Respiratory Medicine,scopus,2018-12-01,sciencedirect,Machine learning for real-time prediction of complications in critical care: a retrospective study,https://api.elsevier.com/content/abstract/scopus_id/85059098244,"Background
                  The large amount of clinical signals in intensive care units can easily overwhelm health-care personnel and can lead to treatment delays, suboptimal care, or clinical errors. The aim of this study was to apply deep machine learning methods to predict severe complications during critical care in real time after cardiothoracic surgery.
               
                  Methods
                  We used deep learning methods (recurrent neural networks) to predict several severe complications (mortality, renal failure with a need for renal replacement therapy, and postoperative bleeding leading to operative revision) in post cardiosurgical care in real time. Adult patients who underwent major open heart surgery from Jan 1, 2000, to Dec 31, 2016, in a German tertiary care centre for cardiovascular diseases formed the main derivation dataset. We measured the accuracy and timeliness of the deep learning model's forecasts and compared predictive quality to that of established standard-of-care clinical reference tools (clinical rule for postoperative bleeding, Simplified Acute Physiology Score II for mortality, and the Kidney Disease: Improving Global Outcomes staging criteria for acute renal failure) using positive predictive value (PPV), negative predictive value, sensitivity, specificity, area under the curve (AUC), and the F1 measure (which computes a harmonic mean of sensitivity and PPV). Results were externally retrospectively validated with 5898 cases from the published MIMIC-III dataset.
               
                  Findings
                  Of 47 559 intensive care admissions (corresponding to 42 007 patients), we included 11 492 (corresponding to 9269 patients). The deep learning models yielded accurate predictions with the following PPV and sensitivity scores: PPV 0·90 and sensitivity 0·85 for mortality, 0·87 and 0·94 for renal failure, and 0·84 and 0·74 for bleeding. The predictions significantly outperformed the standard clinical reference tools, improving the absolute complication prediction AUC by 0·29 (95% CI 0·23–0·35) for bleeding, by 0·24 (0·19–0·29) for mortality, and by 0·24 (0·13–0·35) for renal failure (p<0·0001 for all three analyses). The deep learning methods showed accurate predictions immediately after patient admission to the intensive care unit. We also observed an increase in performance in our validation cohort when the machine learning approach was tested against clinical reference tools, with absolute improvements in AUC of 0·09 (95% CI 0·03–0·15; p=0·0026) for bleeding, of 0·18 (0·07–0·29; p=0·0013) for mortality, and of 0·25 (0·18–0·32; p<0·0001) for renal failure.
               
                  Interpretation
                  The observed improvements in prediction for all three investigated clinical outcomes have the potential to improve critical care. These findings are noteworthy in that they use routinely collected clinical data exclusively, without the need for any manual processing. The deep machine learning method showed AUC scores that significantly surpass those of clinical reference tools, especially soon after admission. Taken together, these properties are encouraging for prospective deployment in critical care settings to direct the staff's attention towards patients who are most at risk.
               
                  Funding
                  No specific funding.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2018.10.008,Journal,Journal of Biomedical Informatics,scopus,2018-12-01,sciencedirect,Toward analyzing and synthesizing previous research in early prediction of cardiac arrest using machine learning based on a multi-layered integrative framework,https://api.elsevier.com/content/abstract/scopus_id/85056849885,"Background
                  One of the significant problems in the field of healthcare is the low survival rate of people who have experienced sudden cardiac arrest. Early prediction of cardiac arrest can provide the time required for intervening and preventing its onset in order to reduce mortality. Traditional statistical methods have been used to predict cardiac arrest. They have often analyzed group-level differences using a limited number of variables. On the other hand, machine learning approach, which is part of a growing trend of predictive medical analysis, has provided personalized predictive analyses on more complex data and produced remarkable results.
               
                  Objective
                  This paper has two aims. First, it offers a systematic review to evaluate the capability and performance of machine learning techniques in predicting the risk of cardiac arrest. Second, it offers an integrative framework to synthesize the researches in this field.
               
                  Method
                  A systematic review of cardiac arrest prediction studies was carried out through Pubmed, ScienceDirect, Google Scholar and SpringerLink databases. These studies used machine learning techniques and were conducted between the years 2000 and 2018.
               
                  Results
                  From a total of 1617 papers retrieved from the literature search, 75 studies were included in the final analysis. In order to explore how machine learning techniques were employed to predict cardiac arrest, a multi-layered framework was proposed. Each layer of the framework represents a classification of the current literature and contains taxonomies of relevant observed information. The framework integrates these classifications and illustrates the relative influence of a layer on other layers. The included papers were analyzed and synthesized through this framework. The used machine learning techniques were evaluated in terms of application and efficiency. The results illustrated the prediction capability of machine learning methods in predicting cardiac arrest.
               
                  Conclusion
                  According to the results, machine learning techniques can improve the outcome of cardiac arrest prediction. However, future research should be carried out to evaluate the efficiency of rarely-used algorithms and to address the challenges of external validation, implementation and adoption of machine learning models in real clinical environments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neuroimage.2018.07.005,Journal,NeuroImage,scopus,2018-12-01,sciencedirect,Fully convolutional network ensembles for white matter hyperintensities segmentation in MR images,https://api.elsevier.com/content/abstract/scopus_id/85052893805,"White matter hyperintensities (WMH) are commonly found in the brains of healthy elderly individuals and have been associated with various neurological and geriatric disorders. In this paper, we present a study using deep fully convolutional network and ensemble models to automatically detect such WMH using fluid attenuation inversion recovery (FLAIR) and T1 magnetic resonance (MR) scans. The algorithm was evaluated and ranked 1st in the WMH Segmentation Challenge at MICCAI 2017. In the evaluation stage, the implementation of the algorithm was submitted to the challenge organizers, who then independently tested it on a hidden set of 110 cases from 5 scanners. Averaged dice score, precision and robust Hausdorff distance obtained on held-out test datasets were 80%, 84% and 6.30 mm respectively. These were the highest achieved in the challenge, suggesting the proposed method is the state-of-the-art. Detailed descriptions and quantitative analysis on key components of the system were provided. Furthermore, a study of cross-scanner evaluation is presented to discuss how the combination of modalities affect the generalization capability of the system. The adaptability of the system to different scanners and protocols is also investigated. A quantitative study is further presented to show the effect of ensemble size and the effectiveness of the ensemble model. Additionally, software and models of our method are made publicly available. The effectiveness and generalization capability of the proposed system show its potential for real-world clinical practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.vprsr.2018.08.002,Journal,Veterinary Parasitology: Regional Studies and Reports,scopus,2018-12-01,sciencedirect,Management practices associated with strongylid parasite prevalence on horse farms in rural counties of Kentucky,https://api.elsevier.com/content/abstract/scopus_id/85052492411,"Anthelmintic resistance among cyathostomin parasites is a wide-spread problem. The parasite control guidelines written by the American Association of Equine Practitioners (AAEP) encourages the preservation of anthelmintic efficacy by reducing treatment frequency, using targeted deworming, and implementing environmental management practices. While there is knowledge regarding parasite management practices of affluent horse farms in the United States, surveys rarely explore the rural and underserved regions. The purpose of this study was to observe the management practices of horse farms in rural regions Kentucky, including working Amish farms, and determine factors associated with strongyle prevalence. A total of 160 horses among 38 owners from 28 different farms were enrolled in this study. A questionnaire survey regarding equine information, farm management, and deworming history was performed with each owner. Fecal samples were collected to determine fecal egg counts, perform coprocultures for subsequent strongyle larvae identification, and Strongylus vulgaris specific PCR. Serum samples were collected for the S. vulgaris antibody specific ELISA. The mean number of deworming treatments given in the last year was 2.1 with a 95% confidence interval of 1.9–2.3 with ivermectin being the most common active used. Statistical analysis showed horses treated within the last three months with a macrocylic lactone (ML) drug had significantly lower egg counts than horses treated with a ML 7–9 months ago (p = .0005). Despite the AAEP recommendations to reduce the overall number of treatments by using a surveillance-based approach and to no longer rotate treatments, only 17 horses reportedly had a fecal sample submitted for a fecal egg count and 65 horses were dewormed in a rotational manner. Horses whose owners utilized an informative deworming source (i.e., veterinarian, internet, magazine, local feed store) also had significantly lower counts (p = .0026). All coprocultures were negative for S. vulgaris while five horses were PCR positive. Interestingly, 95 horses tested ELISA positive for S. vulgaris. The strongyle egg counts of the working Amish horses were not significantly different from the other horses in this study and deworming practices including the use of efficacious drugs and low treatment frequencies were in accordance with the AAEP guidelines. This study was the first to summarize deworming management practices of rural regions in Kentucky, including a working Amish community. Overall, horse owners employed deworming practices recommended by the AAEP, however rotational deworming is still commonly implemented and fecal egg counts are rarely used.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bdr.2018.05.005,Journal,Big Data Research,scopus,2018-12-01,sciencedirect,evoStream – Evolutionary Stream Clustering Utilizing Idle Times,https://api.elsevier.com/content/abstract/scopus_id/85047928365,"Clustering is an important field in data mining that aims to reveal hidden patterns in data sets. It is widely popular in marketing or medical applications and used to identify groups of similar objects. Clustering possibly unbounded and evolving data streams is of particular interest due to the widespread deployment of large and fast data sources such as sensors. The vast majority of stream clustering algorithms employ a two-phase approach where the stream is first summarized in an online phase. Upon request, an offline phase reclusters the aggregations into the final clusters. In this setup, the online component will idle and wait for the next observation in times where the stream is slow. This paper proposes a new stream clustering algorithm called evoStream which performs evolutionary optimization in the idle times of the online phase to incrementally build and refine the final clusters. Since the online phase would idle otherwise, our approach does not reduce the processing speed while effectively removing the computational overhead of the offline phase. In extensive experiments on real data streams we show that the proposed algorithm allows to output clusters of high quality at any time within the stream without the need for additional computational resources.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.snb.2018.07.056,Journal,Sensors and Actuators B: Chemical,scopus,2018-11-10,sciencedirect,An integrated IoT-Wi-Fi board for remote data acquisition and sharing from innovative immunosensors. Case of study: Diagnosis of celiac disease,https://api.elsevier.com/content/abstract/scopus_id/85049856052,"A new compact diagnostic device exploiting the integration of screen printed electrode-based immunosensors and remote-controlled IoT-WiFi acquisition board has been realized and validated for diagnosis of Celiac Disease as case of study. The immunodevice is based on chemisorption of open tissue transglutaminase enzyme on the surface of gold nanoparticles-functionalized carbon screen printed electrodes. IgA and IgG anti-tissue transglutaminase target antibodies are recognized by the immobilized bioreceptor as highly specific biomarkers related to Celiac Disease. The signal from the amperometric sensor is acquired and processed through on-purpose developed IoT-WiFi integrated board, allowing for real-time data sharing on cloud services to directly notify all users (physicians, caregivers, etc.) on device outcome. The proposed solution does not require customized hardware or software.
                  The analytical performances of the immunosensors were optimized by experimental design, obtaining diagnostically useful limit of detection (LOD) and limit of quantitation (LOQ) values (LODIgA = 3.2 AU mL−1; LODIgG = 1.4 AU mL−1; LOQIgA = 4.6 AU mL−1; LOQIgG  = 2.3 AU mL−1) as well as good intermediate precision (RSD < 5%).
                  The high discrimination capability of the IoT-Wi-Fi device between positive and negative serum control resulted to be suitable for diagnostic purposes, with outstanding statistical significance (p < 0,001)",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2018.10.006,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-11-01,sciencedirect,Automated detection and classification of liver fibrosis stages using contourlet transform and nonlinear features,https://api.elsevier.com/content/abstract/scopus_id/85054743325,"Background and objective
                  Liver fibrosis is a type of chronic liver injury that is characterized by an excessive deposition of extracellular matrix protein. Early detection of liver fibrosis may prevent further growth toward liver cirrhosis and hepatocellular carcinoma. In the past, the only method to assess liver fibrosis was through biopsy, but this examination is invasive, expensive, prone to sampling errors, and may cause complications such as bleeding. Ultrasound-based elastography is a promising tool to measure tissue elasticity in real time; however, this technology requires an upgrade of the ultrasound system and software. In this study, a novel computer-aided diagnosis tool is proposed to automatically detect and classify the various stages of liver fibrosis based upon conventional B-mode ultrasound images.
               
                  Methods
                  The proposed method uses a 2D contourlet transform and a set of texture features that are efficiently extracted from the transformed image. Then, the combination of a kernel discriminant analysis (KDA)-based feature reduction technique and analysis of variance (ANOVA)-based feature ranking technique was used, and the images were then classified into various stages of liver fibrosis.
               
                  Results
                  Our 2D contourlet transform and texture feature analysis approach achieved a 91.46% accuracy using only four features input to the probabilistic neural network classifier, to classify the five stages of liver fibrosis. It also achieved a 92.16% sensitivity and 88.92% specificity for the same model. The evaluation was done on a database of 762 ultrasound images belonging to five different stages of liver fibrosis.
               
                  Conclusions
                  The findings suggest that the proposed method can be useful to automatically detect and classify liver fibrosis, which would greatly assist clinicians in making an accurate diagnosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2018.09.009,Journal,Computers in Biology and Medicine,scopus,2018-11-01,sciencedirect,Arrhythmia detection using deep convolutional neural network with long duration ECG signals,https://api.elsevier.com/content/abstract/scopus_id/85053715332,"This article presents a new deep learning approach for cardiac arrhythmia (17 classes) detection based on long-duration electrocardiography (ECG) signal analysis. Cardiovascular disease prevention is one of the most important tasks of any health care system as about 50 million people are at risk of heart disease in the world. Although automatic analysis of ECG signal is very popular, current methods are not satisfactory. The goal of our research was to design a new method based on deep learning to efficiently and quickly classify cardiac arrhythmias. Described research are based on 1000 ECG signal fragments from the MIT - BIH Arrhythmia database for one lead (MLII) from 45 persons. Approach based on the analysis of 10-s ECG signal fragments (not a single QRS complex) is applied (on average, 13 times less classifications/analysis). A complete end-to-end structure was designed instead of the hand-crafted feature extraction and selection used in traditional methods. Our main contribution is to design a new 1D-Convolutional Neural Network model (1D-CNN). The proposed method is 1) efficient, 2) fast (real-time classification) 3) non-complex and 4) simple to use (combined feature extraction and selection, and classification in one stage). Deep 1D-CNN achieved a recognition overall accuracy of 17 cardiac arrhythmia disorders (classes) at a level of 91.33% and classification time per single sample of 0.015 s. Compared to the current research, our results are one of the best results to date, and our solution can be implemented in mobile devices and cloud computing.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jsurg.2018.06.004,Journal,Journal of Surgical Education,scopus,2018-11-01,sciencedirect,Novel Educational Information Management Platform Improves the Surgical Skill Evaluation Process of Surgical Residents,https://api.elsevier.com/content/abstract/scopus_id/85050826890,"Objective
                  We sought to increase compliance and timeliness of surgery resident operative evaluation, by providing faculty and residents with a Platform-linking evaluation to analytics and machine-learning-facilitated case logging.
               
                  Design
                  We built a HIPAA-compliant web-based Platform for comprehensive management of resident education information, including resident operative performance evaluations. To assess evaluation timeliness, we compared the lag time for Platform-based evaluations to that of end-of-rotation evaluations. We also assessed evaluation compliance, based on a time threshold of 5 days for Platform evaluations and 2 weeks for end-of-rotation evaluations.
               
                  Setting
                  University of Massachusetts, Baystate Medical Center, General Surgery Residency.
               
                  Participants
                  Twenty three attendings and 43 residents for the Platform cohort; 15 services and 45 residents for the end-of-rotation cohort.
               
                  Results
                  Three hundred and fifty-eight Platform evaluations were completed by 23 attendings for 43 residents for March through October 2017. Six hundred and ten end-of-rotation evaluations by 15 attendings for 45 residents were used for comparison (September 2015 through June 2017). Of Platform evaluations, 41.3% were completed within 24 hours of the operation (16.5% in 6 hours, 33.3% in 12 hours, and 62.2% in 48 hours), with 24.3% of evaluations completed within 3 hours after e-mail reminders. In the first 6 weeks (March 1 through April 12) 4.5 ± 3.7 evaluations were completed per week compared to 18.8 ± 5.8 in the last (September 18 through October 31). Evaluation lag times improved with the use of the Platform, both for median lag of 35 days earlier (1 ± 1.5 days Platform, 36 ± 28.2 days traditional, p < 0.0001) and a mean lag of 41 days earlier (3.0 ± 4.7 days Platform, 44.0 ± 32.6 days traditional, p < 0.0001).
               
                  Conclusions
                  Our comprehensive Platform facilitated faculty compliance with evaluation requirements and timeliness of availability of performance information (often in near real time) for both residents and residency leadership. The added value of the Platform's integration of evaluations with resident and attending case logging may account for the rapidly increasing number of operative skill evaluations over the short time span since implementation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ssci.2018.06.012,Journal,Safety Science,scopus,2018-11-01,sciencedirect,Occupational health and safety in the industry 4.0 era: A cause for major concern?,https://api.elsevier.com/content/abstract/scopus_id/85049323662,"Real-time communication, Big Data, human–machine cooperation, remote sensing, monitoring and process control, autonomous equipment and interconnectivity are becoming major assets in modern industry. As the fourth industrial revolution or Industry 4.0 becomes the predominant reality, it will bring new paradigm shifts, which will have an impact on the management of occupational health and safety (OHS).
                  In the midst of this new and accelerating industrial trend, are we giving due consideration to changes in OHS imperatives? Are the OHS consequences of Industry 4.0 being evaluated properly? Do we stand to lose any of the gains made through proactive approaches? Are there rational grounds for major concerns? In this article, we examine these questions in order to raise consciousness with regard to the integration of OHS into Industry4.0.
                  It is clear that if the technologies driving Industry 4.0 develop in silos and manufacturers’ initiatives are isolated and fragmented, the dangers will multiply and the net impact on OHS will be negative. As major changes are implemented, previous gains in preventive management of workplace health and safety will be at risk. If we are to avoid putting technological progress and OHS on a collision course, researchers, field experts and industrialists will have to collaborate on a smooth transition towards Industry 4.0.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eij.2018.03.003,Journal,Egyptian Informatics Journal,scopus,2018-11-01,sciencedirect,A contemporary feature selection and classification framework for imbalanced biomedical datasets,https://api.elsevier.com/content/abstract/scopus_id/85044607905,"Due to the availability of a large number of biomedical documents in the PubMed and Medline repositories, it is difficult to analyze, predict and interpret the document’s information using the traditional document clustering and classification models. Traditional document clustering and classification models were failed to analyze the document sets based on the user’s keyword and MESH terms. Due to the large number of feature sets, conventional models, such as SVM, Neural Networks, Multi-nominal naïve bayes have been used as feature classification, where additional text filtering measures are typically used as feature selection process. Also, as the size of the document’s increases, it becomes difficult to find the outliers using the document’s features and MESH terms. Biomedical document clustering and classification is one of the essential machine learning models for the knowledge extraction process of the real-time user recommended systems. In this paper, we developed a novel biomedical document feature clustering and classification model as a user recommended system for large document sets using the Hadoop framework. In this model, a novel gene feature clustering with ensemble document classification was implemented on biomedical repositories (PubMed and Medline) using the MapReduce framework. Experimental results show that the proposed model has a high computational cluster quality rate and true positive classification rate compared to traditional document clustering and classification models.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2015.09.006,Journal,Artificial Intelligence in Medicine,scopus,2018-11-01,sciencedirect,Pediatric decision support using adapted Arden Syntax,https://api.elsevier.com/content/abstract/scopus_id/84964998606,"Background
                  Pediatric guidelines based care is often overlooked because of the constraints of a typical office visit and the sheer number of guidelines that may exist for a patient's visit. In response to this problem, in 2004 we developed a pediatric computer based clinical decision support system using Arden Syntax medical logic modules (MLM).
               
                  Methods
                  The Child Health Improvement through Computer Automation system (CHICA) screens patient families in the waiting room and alerts the physician in the exam room. Here we describe adaptation of Arden Syntax to support production and consumption of patient specific tailored documents for every clinical encounter in CHICA and describe the experiments that demonstrate the effectiveness of this system.
               
                  Results
                  As of this writing CHICA has served over 44,000 patients at 7 pediatric clinics in our healthcare system in the last decade and its MLMs have been fired 6182,700 times in “produce” and 5334,021 times in “consume” mode. It has run continuously for over 10 years and has been used by 755 physicians, residents, fellows, nurse practitioners, nurses and clinical staff. There are 429 MLMs implemented in CHICA, using the Arden Syntax standard. Studies of CHICA's effectiveness include several published randomized controlled trials.
               
                  Conclusions
                  Our results show that the Arden Syntax standard provided us with an effective way to represent pediatric guidelines for use in routine care. We only required minor modifications to the standard to support our clinical workflow. Additionally, Arden Syntax implementation in CHICA facilitated the study of many pediatric guidelines in real clinical environments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jnca.2018.06.010,Journal,Journal of Network and Computer Applications,scopus,2018-10-15,sciencedirect,A framework for healthcare support in the rural and low income areas of the developing world,https://api.elsevier.com/content/abstract/scopus_id/85049924793,"Cyber-Healthcare is an emerging field of the healthcare domain that builds upon cyber physical health systems (CPHSs) to provide pervasive access to medical services any time and from anywhere in the world where medical expertise is available. It is expected to change the way healthcare is delivered in the developing world and enable both its rural and urban settings to leapfrog from poorly equipped to medically prepared environments capable of tackling some of its most challenging health issues. However, owing to their infancy stage in the developing world, CPHSs require substantial research and practical work to move from their theoretical boundaries into the development, deployment and exploitation phase. This paper proposes a Cyber-Healthcare framework and its implementation as a fog-based CPHS infrastructure using low-cost lightweight devices to achieve patients' condition recognition as a first step towards the implementation of digital healthcare support systems in the developing world. We propose a multi-layer architecture for the framework and consider a patients' condition recognition system that uses machine learning techniques as a key component of the framework. We present experimental results that reveal i) the relative efficiency of different machine learning algorithms used for patient condition recognition and ii) the storage and processing overheads incurred by two popular lightweight embedded devices when used as fog computing devices in the CPHS.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.vetmic.2018.08.026,Journal,Veterinary Microbiology,scopus,2018-10-01,sciencedirect,Detection of non-notifiable H4N6 avian influenza virus in poultry in Great Britain,https://api.elsevier.com/content/abstract/scopus_id/85053845094,"A 12-month pilot project for notifiable avian disease (NAD) exclusion testing in chicken and turkey flocks in Great Britain (GB) offered, in partnership with industry, opportunities to carry out differential diagnosis in flocks where NAD was not suspected, and to identify undetected or undiagnosed infections. In May 2014, clinical samples received from a broiler breeder chicken premises that had been experiencing health and production problems for approximately one week tested positive by avian influenza (AI) real-time reverse transcription polymerase chain reaction (RRT-PCR). Following immediate escalation to an official, statutory investigation to rule out the presence of notifiable AI virus (AIV; H5 or H7 subtypes), a non-notifiable H4N6 low pathogenicity (LP) AIV was detected through virus isolation in embryonated specific pathogen free (SPF) fowls’ eggs, neuraminidase inhibition test, cleavage site sequencing and AIV subtype H4-specific serology. Premises movement restrictions were lifted, and no further disease control measures were implemented as per the United Kingdom (UK) legislation. Phylogenetic analysis of the haemagglutinin and neuraminidase genes of the virus revealed closest relationships to viruses from Mallard ducks in Sweden during 2007 and 2009. In June 2014, clinical suspicion of NAD was reported in a flock of free-range laying chickens elsewhere in GB, due to increasing daily mortality and reduced egg production over a five-day period. An H4N6 LPAIV with an intravenous pathogenicity index of 0.50 was isolated. This virus was genetically highly similar, but not identical, to the virus detected during May 2014. Full viral genome analyses showed characteristics of a strain that had not recently transferred from wild birds, implying spread within the poultry sector had occurred. A stalk deletion in the neuraminidase gene sequence indicated an adaptation of the virus to poultry. Furthermore, there was unexpected evidence of systemic spread of the virus on post-mortem. No other cases were reported. Infection with LPAIVs often result in variable clinical presentation in poultry, making detection of disease more difficult.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2018.08.011,Journal,Journal of Biomedical Informatics,scopus,2018-10-01,sciencedirect,Semantic relation extraction aware of N-gram features from unstructured biomedical text,https://api.elsevier.com/content/abstract/scopus_id/85052882051,"Semantic relation extraction is a crucial step of automatically constructing a knowledge graph from unstructured biomedical text. Many real-world applications can benefit from it. As unsupervised relation extraction approaches, generative probabilistic models, Rel-LDA and Type-LDA, are receiving more attention in recent years. However, these two models inherit the bag-of-word assumption of the standard LDA model, which disable the exploitation of more distinguishable n-gram features. To overcome this limitation, two alternative models, named as Rel-TNG and Type-TNG, are proposed with the help of Topic N-Grams (TNG) model in this study, and collapsed Gibbs sampling algorithm is utilized for inference. Extensive experimental results on GENIA and EPI corpora indicate that Rel-TNG and Type-TNG models have similar performance with their unigram counterparts, but Rel-TNG and Type-TNG models outperform Rel-LDA and Type-LDA models when prior knowledge is available.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmgm.2018.07.007,Journal,Journal of Molecular Graphics and Modelling,scopus,2018-10-01,sciencedirect,Proposing novel TNFα direct inhibitor Scaffolds using fragment-docking based e-pharmacophore modeling and binary QSAR-based virtual screening protocols pipeline,https://api.elsevier.com/content/abstract/scopus_id/85052113589,"Tumor necrosis factor alpha (TNFα) is a homotrimer protein that plays a pivotal role for critical immune functions, including infection, inflammation and antitumor responses. It also plays a primary role in autoimmune diseases like rheumatoid arthritis (RA). So far, only biological therapeutics like infliximab, etanercept, and adalimumab are available as treatment of inflammatory diseases. They directly bind to TNFα and interrupt its binding to its receptor protein tumor necrosis factor receptor (TNFR). However, they may also cause serious side effects such as activating an autoimmune anti-antibody response or the weakening of the body's immune defenses. Thus, small molecule-based therapies can be considered as alternative methods. In this study, a novel method is applied to develop energetically optimized, structure-based pharmacophore models for rapid in silico drug screening. Fragment-based docking results were used in the construction of an universal e-pharmacophore model development. The developed model is then used for screening of small-molecule library Specs-screening compounds (Specs-SC) which includes more than 200.000 drug-like molecules. In another approach, binary QSAR-based models were used to screen Specs-SC, as well as Specs-natural products (NP) which has around 750 compounds, and a library of drugs registered or approved for use in humans NIH's NCGC pharmaceutical collection (NPC) which has around 7500 molecules. The MetaCore/MetaDrug platform was used for binary QSAR models for therapeutic activity prediction as well as pharmacokinetic and toxicity profile predictions of screening molecules. This platform is constructed based on a manually curated database of molecular interactions, molecular pathways, gene-disease associations, chemical metabolism, and toxicity information. Molecular docking and molecular dynamics (MD) simulations were performed for the selected hit molecules. As target protein, both homodimer and homotrimer forms of TNFα were considered. The screening results showed that indinavir and medroxalol from NPC chemical library and a set of compounds (AT-057/43115940, AP-970/42897107, AK-968/41925665, AI-204/31679053, AN-648/41666950, AN-698/42006940) from Specs-SC database were identified as safe and active direct inhibitors of TNFα.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2018.08.005,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-10-01,sciencedirect,Fast unsupervised nuclear segmentation and classification scheme for automatic allred cancer scoring in immunohistochemical breast tissue images,https://api.elsevier.com/content/abstract/scopus_id/85051670704,"Background and objective
                  This paper presents an improved scheme able to perform accurate segmentation and classification of cancer nuclei in immunohistochemical (IHC) breast tissue images in order to provide quantitative evaluation of estrogen or progesterone (ER/PR) receptor status that will assist pathologists in cancer diagnostic process.
               
                  Methods
                  The proposed segmentation method is based on adaptive local thresholding and an enhanced morphological procedure, which are applied to extract all stained nuclei regions and to split overlapping nuclei. In fact, a new segmentation approach is presented here for cell nuclei detection from the IHC image using a modified Laplacian filter and an improved watershed algorithm. Stromal cells are then removed from the segmented image using an adaptive criterion in order to get fast tumor nuclei recognition. Finally, unsupervised classification of cancer nuclei is obtained by the combination of four common color separation techniques for a subsequent Allred cancer scoring.
               
                  Results
                  Experimental results on various IHC tissue images of different cancer affected patients, demonstrate the effectiveness of the proposed scheme when compared to the manual scoring of pathological experts. A statistical analysis is performed on the whole image database between immuno-score of manual and automatic method, and compared with the scores that have reached using other state-of-art segmentation and classification strategies. According to the performance evaluation, we recorded more than 98% for both accuracy of detected nuclei and image cancer scoring over the truths provided by experienced pathologists which shows the best correlation with the expert's score (Pearson's correlation coefficient = 0.993, p-value < 0.005) and the lowest computational total time of 72.3 s/image (±1.9) compared to recent studied methods.
               
                  Conclusions
                  The proposed scheme can be easily applied for any histopathological diagnostic process that needs stained nuclear quantification and cancer grading. Moreover, the reduced processing time and manual interactions of our procedure can facilitate its implementation in a real-time device to construct a fully online evaluation system of IHC tissue images.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.diagmicrobio.2018.05.016,Journal,Diagnostic Microbiology and Infectious Disease,scopus,2018-10-01,sciencedirect,A new dual-targeting real-time RT-PCR assay for hepatitis D virus RNA detection,https://api.elsevier.com/content/abstract/scopus_id/85048886531,"In this study, a real-time reverse transcription–polymerase chain reaction (real time RT-PCR) assay targeting 2 genetic segments was established to detect HDV RNA. Utilizing the World Health Organization International Standard for Hepatitis D Virus RNA, the lower limit of detection was 575 IU/mL, and the linearity of quantification ranged from 575,000 IU/mL to 575 IU/mL. 384 HBsAg-positive samples collected from China were tested by this method and HDV antibody detection. Eleven samples were positive for anti-HDV IgG which may persist after HDV resolution, 6 samples were HDV RNA positive, and 5 samples were positive for anti-HDV IgM. This assay showed more sensitivity than the detection of anti-HDV IgM. These data demonstrate that the real-time RT-PCR assay for HDV RNA could be implemented in the clinical detection of HDV infection in chronic HBV-infected patients in China.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jhin.2018.04.004,Journal,Journal of Hospital Infection,scopus,2018-10-01,sciencedirect,Feasibility of a real-time hand hygiene notification machine learning system in outpatient clinics,https://api.elsevier.com/content/abstract/scopus_id/85046810779,"Background
                  Various technologies have been developed to improve hand hygiene (HH) compliance in inpatient settings; however, little is known about the feasibility of machine learning technology for this purpose in outpatient clinics.
               
                  Aim
                  To assess the effectiveness, user experiences, and costs of implementing a real-time HH notification machine learning system in outpatient clinics.
               
                  Methods
                  In our mixed methods study, a multi-disciplinary team co-created an infrared guided sensor system to automatically notify clinicians to perform HH just before first patient contact. Notification technology effects were measured by comparing HH compliance at baseline (without notifications) with real-time auditory notifications that continued till HH was performed (intervention I) or notifications lasting 15 s (intervention II). User experiences were collected during daily briefings and semi-structured interviews. Costs of implementation of the system were calculated and compared to the current observational auditing programme.
               
                  Findings
                  Average baseline HH performance before first patient contact was 53.8%. With real-time auditory notifications that continued till HH was performed, overall HH performance increased to 100% (P < 0.001). With auditory notifications of a maximum duration of 15 s, HH performance was 80.4% (P < 0.001). Users emphasized the relevance of real-time notification and contributed to technical feasibility improvements that were implemented in the prototype. Annual running costs for the machine learning system were estimated to be 46% lower than the observational auditing programme.
               
                  Conclusion
                  Machine learning technology that enables real-time HH notification provides a promising cost-effective approach to both improving and monitoring HH, and deserves further development in outpatient settings.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cell.2018.08.028,Journal,Cell,scopus,2018-09-20,sciencedirect,Intelligent Image-Activated Cell Sorting,https://api.elsevier.com/content/abstract/scopus_id/85054484004,"A fundamental challenge of biology is to understand the vast heterogeneity of cells, particularly how cellular composition, structure, and morphology are linked to cellular physiology. Unfortunately, conventional technologies are limited in uncovering these relations. We present a machine-intelligence technology based on a radically different architecture that realizes real-time image-based intelligent cell sorting at an unprecedented rate. This technology, which we refer to as intelligent image-activated cell sorting, integrates high-throughput cell microscopy, focusing, and sorting on a hybrid software-hardware data-management infrastructure, enabling real-time automated operation for data acquisition, data processing, decision-making, and actuation. We use it to demonstrate real-time sorting of microalgal and blood cells based on intracellular protein localization and cell-cell interaction from large heterogeneous populations for studying photosynthesis and atherothrombosis, respectively. The technology is highly versatile and expected to enable machine-based scientific discovery in biological, pharmaceutical, and medical sciences.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chroma.2018.06.035,Journal,Journal of Chromatography A,scopus,2018-09-14,sciencedirect,Tandem column isolation of zirconium-89 from cyclotron bombarded yttrium targets using an automated fluidic platform: Anion exchange to hydroxamate resin columns,https://api.elsevier.com/content/abstract/scopus_id/85051041242,"The development of a tandem column purification method for the preparation of high-purity 89Zr(IV) oxalate is presented. The primary column was a macroporous strongly basic anion exchange resin on styrene divinylbenzene co-polymer. The secondary column, with an internal volume of 33 μL, was packed with hydroxamate resin. A condition of inverted selectivity was developed, whereby the 89Zr eluent solution for the primary column is equivalent to the 89Zr load solution for the secondary column. The ability to transfer 89Zr from one column to the next allows two sequential column clean-up methods to be performed prior to the final elution of the 89Zr(IV) oxalate. This approach assures delivery of high purity 89Zr product and assures a 89Zr product that is eluted in a substantially smaller volume than is possible when using the traditionally-employed single hydroxamate resin column method. The tandem column purification process has been implemented into a prototype automated fluidic system. The system is configured with on-line gamma detection so column effluents can be monitored in near-real time. The automated method was tested using seven cyclotron bombarded Y foil targets. It was found that 95.1 ± 1.3% of the 89Zr present in the foils was recovered in the secondary column elution fraction. Furthermore, elution peak analysis of several 89Zr elution profile radiochromatograms made possible the determination of 89Zr recovery as a function of volume; a 89Zr product volume that contains 90% of the mean secondary column elution peak can be obtained in 0.29 ± 0.06 mL (representing 86 ± 5% of the 89Zr activity in the target). This product volume represents a significant improvement in radionuclide product concentration over the predominant method used in the field. In addition to the reduced 89Zr product elution volume, titrations of the 89Zr product with deferoxamine mesylate salt across two preparatory methods resulted in mean effective specific activity (ESA) values of 279 and 340 T Bq·mmole−1 and mean bindable metals concentrations ([MB]) of 13.5 and 16.7 nmole·g−1. These ESA and [MB] values infer that the 89Zr(IV) oxalate product resulting from this tandem column isolation method has the highest purity reported to date.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ergon.2018.06.005,Journal,International Journal of Industrial Ergonomics,scopus,2018-09-01,sciencedirect,Artificial intelligence models for predicting the performance of hydro-pneumatic suspension struts in large capacity dump trucks,https://api.elsevier.com/content/abstract/scopus_id/85049336711,"Large dump trucks are being matched with large shovels to achieve bulk economic production in surface mining operations. This process results in high impact shovel loading operations (HISLO) and exposes operators to severe levels of whole-body vibrations (WBV). The performance of the hydro-pneumatic suspension struts, responsible for vibration attenuation in large dump trucks, decreases as a truck age. There is a need for a system for monitoring and predicting the performance of the suspension struts in real time. Artificial intelligence (AI) has been applied for modeling and predicting the suspension system performance for light/smaller vehicles. However, no work has been done to implement AI for modeling and predicting the performance of hydro-pneumatic struts in large dump trucks. This paper is a pioneering effort towards developing AI models for solving this problem. These AI models would incorporate the Artificial Neural Networks (ANN), Mamdani Fuzzy Logic (MFL) and a hybrid system, the Hybrid Neural Fuzzy Interference System (HyFIS), for achieving this goal. Experiments were conducted using a 3D virtual simulator for the CAT 793D in MSC.ADMAS. RMS accelerations in the vertical and horizontal directions at the operator seat were recorded as the two main outputs for the suspension system performance. Eighty percent (80%) of the total experimental data was used in training and developing the models and the remaining 20% for testing and validating the developed models. With an R2 and RMSE of 0.98168505 and 0.00852251 for the training phase, respectively, and 0.9660429 and 0.0195620 for the testing phase, HyFIS model showed the best accuracy for predicting the hydro-pneumatic suspension struts performance for dump trucks. This is the first time that AI models have been developed for dump truck suspension system performance prediction. With the implementation of these models in the dump truck, maintenance personnel can monitor the performance of the suspension system in real-time and schedule proper maintenance and/or replacement. Implementation of such a system will improve the workplace safety, operator's health and the overall system efficiency.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2018.06.001,Journal,Artificial Intelligence in Medicine,scopus,2018-09-01,sciencedirect,Early anomaly detection in smart home: A causal association rule-based approach,https://api.elsevier.com/content/abstract/scopus_id/85049319216,"As the world's population grows older, an increasing number of people are facing health issues. For the elderly, living alone can be difficult and dangerous. Consequently, smart homes are becoming increasingly popular. A sensor-rich environment can be exploited for healthcare applications, in particular, anomaly detection (AD). The literature review for this paper showed that few works consider environmental factors to detect anomalies. Instead, the focus is on user activity and checking whether it is abnormal, i.e., does not conform to expected behavior. Furthermore, reducing the number of anomalies using early detection is a major issue in many applications. In this context, anomaly-cause discovery may be helpful in recommending actions that may prevent risk. In this paper, we present a novel approach for detecting the risk of anomalies occurring in the environment regarding user activities. The method relies on anomaly-cause extraction from a given dataset using causal association rules mining. These anomaly causes are utilized afterward for real-time analysis to detect the risk of anomalies using the Markov logic network machine learning method. The detected risk allows the method to recommend suitable actions to perform in order to avoid the occurrence of an actual anomaly. The proposed approach is implemented, tested, and evaluated for each contribution using real data obtained from an intelligent environment platform and real data from a clinical datasets. Experimental results prove our approach to be efficient in terms of recognition rate.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2018.06.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-09-01,sciencedirect,Fuzzy decision support systems to diagnose musculoskeletal disorders: A systematic literature review,https://api.elsevier.com/content/abstract/scopus_id/85048589929,"Background and objective
                  Musculoskeletal disorders (MSDs) are one of the most important causes of disability with a high prevalence. The accurate and timely diagnosis of these disorders is often difficult. Clinical decision support systems (CDSSs) can help physicians to diagnose diseases quickly and accurately. Given the ambiguous nature of MSDs, fuzzy logic can be helpful in designing the CDSSs knowledge bases. The present study aimed to review the studies on fuzzy CDSSs to diagnose MSDs.
               
                  Methods
                  A comprehensive search was conducted in Medline, Scopus, Cochrane Library, and ISI Web of Science databases to identify relevant studies published until March 15, 2016. Studies were included in which CDSSs were developed using fuzzy logic to diagnose MSDs, and tested their accuracy using real data from patients.
               
                  Results
                  Of the 3188 papers examined, 23 papers included according to the inclusion criteria. The results showed that among all the designed CDSSs only one (CADIAG-2) was implemented in the clinical environment. In about half of the included studies (52%), CDSSs were designed to diagnose inflammatory/infectious disorder of the bone and joint. In most of the included studies (70%), the knowledge was extracted using a combination of three methods (acquiring from experts, analyzing the data, and reviewing the literature). The median accuracy of fuzzy rule-based CDSSs was 91% and it was 90% for other fuzzy models. The most frequently used membership functions were triangular and trapezoidal functions, and the most used method for inference was the Mamdani.
               
                  Conclusions
                  In general, fuzzy CDSSs have a high accuracy to diagnose MSDs. Despite the high accuracy, these systems have been used to a limited extent in the clinical environments. To design of knowledge base for CDSSs to diagnose MSDs, rule-based methods are used more than other fuzzy methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.diin.2018.05.004,Journal,Digital Investigation,scopus,2018-09-01,sciencedirect,Laying foundations for effective machine learning in law enforcement. Majura – A labelling schema for child exploitation materials,https://api.elsevier.com/content/abstract/scopus_id/85047981760,"The health impacts of repeated exposure to distressing concepts such as child exploitation materials (CEM, aka ‘child pornography’) have become a major concern to law enforcement agencies and associated entities. Existing methods for ‘flagging’ materials largely rely upon prior knowledge, whilst predictive methods are unreliable, particularly when compared with equivalent tools used for detecting ‘lawful’ pornography. In this paper we detail the design and implementation of a deep-learning based CEM classifier, leveraging existing pornography detection methods to overcome infrastructure and corpora limitations in this field. Specifically, we further existing research through direct access to numerous contemporary, real-world, annotated cases taken from Australian Federal Police holdings, demonstrating the dangers of overfitting due to the influence of individual users' proclivities. We quantify the performance of skin tone analysis in CEM cases, showing it to be of limited use. We assess the performance of our classifier and show it to be sufficient for use in forensic triage and ‘early warning’ of CEM, but of limited efficacy for categorising against existing scales for measuring child abuse severity.
                  We identify limitations currently faced by researchers and practitioners in this field, whose restricted access to training material is exacerbated by inconsistent and unsuitable annotation schemas. Whilst adequate for their intended use, we show existing schemas to be unsuitable for training machine learning (ML) models, and introduce a new, flexible, objective, and tested annotation schema specifically designed for cross-jurisdictional collaborative use.
                  This work, combined with a world-first ‘illicit data airlock’ project currently under construction, has the potential to bring a ‘ground truth’ dataset and processing facilities to researchers worldwide without compromising quality, safety, ethics and legality.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jstrokecerebrovasdis.2018.05.004,Journal,Journal of Stroke and Cerebrovascular Diseases,scopus,2018-09-01,sciencedirect,Intravenous Thrombolysis in Patients with Acute Ischemic Stroke after a Reversal of Dabigatran Anticoagulation with Idarucizumab: A Real-World Clinical Experience,https://api.elsevier.com/content/abstract/scopus_id/85047416159,"Background
                  Intravenous thrombolysis (IVT) is contraindicated in patients with acute ischemic stroke (AIS) using oral anticoagulants. A specific human monoclonal antibody was introduced to reverse immediately the anticoagulation effect of the direct inhibitor of thrombin, dabigatran. Until now, mostly individual cases presenting with successful IVT after a reversal of dabigatran anticoagulation in patients with AIS were published. Thus, we aimed to report real-world data from clinical practice.
               
                  Methods
                  Patients with AIS on dabigatran treated with IVT after antidote reversal were enrolled in the retrospective nationwide study. Neurological deficit was scored using the National Institutes of Health Stroke Scale (NIHSS) and 90-day clinical outcome using modified Rankin scale (mRS) with a score 0-2 for a good outcome. Intracerebral hemorrhage (ICH) was defined as a presence of any sign of bleeding on control imaging after IVT, and symptomatic intracerebral hemorrhage (SICH) was assessed according to the Safe Implementation of Thrombolysis in Stroke-Monitoring Study (SITS-MOST) criteria.
               
                  Results
                  In total, 13 patients (7 men, mean age 70.0 ± 9.1 years) with a median NIHSS admission score of 7 points were analyzed. Of these patients, 61.5% used 2 × 150 mg of dabigatran daily. Antidote was administrated 427 ± 235 minutes after the last intake of dabigatran, with a mean activated prothrombin time of 38.1 ± 27.8 seconds and a mean thrombin time of 72.2 ± 56.1 seconds. Of the 13 patients, 2 had ICH and 1 had SICH, and no other bleeding complications were observed after IVT. Of the total number of patients, 76.9% had a good 3-month clinical outcome and 3 patients (23.1%) died. Recurrent ischemic stroke occurred in 2 patients (15.4%).
               
                  Conclusion
                  The data presented in the study support the safety and efficacy of IVT after the reversal of the anticoagulation effect of dabigatran with antidote in a real-world clinical practice.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bdr.2018.05.001,Journal,Big Data Research,scopus,2018-09-01,sciencedirect,Efficient In-Database Patient Similarity Analysis for Personalized Medical Decision Support Systems,https://api.elsevier.com/content/abstract/scopus_id/85047072435,"Patient similarity analysis is a precondition to apply machine learning technology on medical data. In this sense, patient similarity analysis harnesses the information wealth of electronic medical records (EMRs) to support medical decision making. A pairwise similarity computation can be used as the basis for personalized health prediction. With n patients the amount of 
                        (
                        
                           
                              
                                 n
                              
                           
                           
                              
                                 2
                              
                           
                        
                        )
                      similarity calculations is required. Thus, analyzing patient similarity leads to data explosion when exploiting big data. By increasing the data size the computational burden of this analysis increases. A real-life medical application may exceed the limits of current hardware in a fairly short amount of time. Finding ways to optimize patient similarity analysis and handling this data explosion is the topic of this paper.
                  Current implementations for patient similarity analysis require their users to have knowledge of complex data analysis tools. Moreover, data pre-processing and analysis are performed in synthetic conditions: the data are extracted from the EMR database and then the data preparation and analysis are processed in external tools. After all of this effort the users might not experience a superior performance of the patient similarity analysis. We propose methods to optimize the patient similarity analysis in order to make it scalable to big data. Our method was tested against two real datasets and a low execution time was accomplished. Our result hence benefits a comprehensive medical decision support system. Moreover, our implementation comprises a balance between performance and applicability: the majority of the workload is processed within a database management system to enable a direct implementation on an EMR database.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.inffus.2017.05.004,Journal,Information Fusion,scopus,2018-09-01,sciencedirect,Real-time activity monitoring with a wristband and a smartphone,https://api.elsevier.com/content/abstract/scopus_id/85020177947,"Activity monitoring is a very important task in lifestyle and health domains where physical activity of a person plays an important role in further reasoning or for providing personalized recommendations. To make such services available to a broader population, one should use devices that most users already have, such as smartphones. Since trends show an increasing popularity of wrist-worn wearables we also consider a sensor-rich wristband as an optional device in this research. We present a real-time activity monitoring algorithm which utilizes data from the smartphone sensors, wristband sensors or their fusion for activity recognition and estimation of energy expenditure of the user. The algorithm detects which devices are present and uses an interval of walking for gravity detection and normalization of the orientation of the devices. The normalized data is afterwards used for the detection of the location of the smartphone on the body, which serves as a context for the selection of location-specific classification model for activity recognition. The recognized activity is finally used for the selection of one or multiple regression models for the estimation of the user’s energy expenditure. To develop the machine-learning models, which can be deployed on the smartphone, we optimized the number and type of extracted features via automatic feature selection. We evaluated each step of the algorithm and each device configuration, and compared the human energy expenditure estimation results against the Bodymedia armband and Microsoft Band 2. We also evaluated the benefit of decision fusion where appropriate. The results show that we achieve a 87% ± 5% average accuracy for activity recognition and that we outperformed both competing devices in the estimation of human energy expenditure by achieving the mean absolute error of 0.6 ± 0.1 MET on average.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dib.2018.06.062,Journal,Data in Brief,scopus,2018-08-01,sciencedirect,"Data on groundwater quality, scaling potential and corrosiveness of water samples in Torbat-e-Heydariyeh rural drinking water resources, Khorasan-e-Razavi province, Iran",https://api.elsevier.com/content/abstract/scopus_id/85050157224,"According to World Health Organization guidelines, corrosion control is an important aspect of safe drinking-water supplies. The data presented is physical and chemical parameters of drinking water in the rural areas of Torbat-e-Heydariyeh city, also to determine corrosion indices. This cross-sectional study has carried out with 188 taken samples during 2014 with 13 parameters, which has been analyzed based on standard method. Also with regard to standard conditions, result of this paper is compared with Environmental Protection Agency and Iran national standards. Five indices, Langlier Saturation Index (LSI), Ryznar Stability Index (RSI), Puckorius Scaling Index (PSI), Larson-Skold Index (LS) and Aggressive Index (AI), programmed by using Microsoft Excel software. Owing to its simplicity, the program can easily be used by researchers and operators. Parameters included Sulfate, Sodium, Chloride, and Electrical Conductivity respectively was 13.5%, 28%, 10.5%, and 15% more than standard level. The amounts of Nitrate, in 98% of cases were in permissible limits and about 2% were more than standard level. Result of presented research indicate that water is corrosive at 10.6%, 89.4%, 87.2%, 59.6% and 14.9% of drinking water supply reservoirs, according to LSI, RSI, PSI, LS and AI, respectively.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2018.07.003,Journal,Journal of Biomedical Informatics,scopus,2018-08-01,sciencedirect,A decision support system for antibiotic prescription based on local cumulative antibiograms,https://api.elsevier.com/content/abstract/scopus_id/85049432919,"Background
                  Local cumulative antibiograms are useful tools with which to select appropriate empiric or directed therapies when treating infectious diseases at a hospital. However, data represented in traditional antibiograms are static, incomplete and not well adapted to decision-making.
               
                  Methods
                  We propose a decision support method for empiric antibiotic therapy based on the Number Needed to Fail (NNF) measure. NNF indicates the number of patients that would need to be treated with a specific antibiotic for one to be inadequately treated. We define two new measures, Accumulated Efficacy and Weighted Accumulated Efficacy in order to determine the efficacy of an antibiotic. We carried out two experiments: the first during which there was a suspicion of infection and the patient had empiric therapy, and the second by considering patients with confirmed infection and directed therapy. The study was performed with 15,799 cultures with 356,404 susceptibility tests carried out over a four-year period.
               
                  Results
                  The most efficient empiric antibiotics are Linezolid and Vancomycin for blood samples and Imipenem and Meropenem for urine samples. In both experiments, the efficacies of recommended antibiotics are all significantly greater than the efficacies of the antibiotics actually administered (P < 0.001). The highest efficacy is obtained when considering 2 years of antibiogram data and 80% of the cumulated prevalence of microorganisms.
               
                  Conclusion
                  This extensive study on real empiric therapies shows that the proposed method is a valuable alternative to traditional antibiograms as regards developing clinical decision support systems for antimicrobial stewardship.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jcv.2018.06.013,Journal,Journal of Clinical Virology,scopus,2018-08-01,sciencedirect,A fully automated system using transcription-mediated amplification for the molecular diagnosis of hepatitis E virus in human blood and faeces,https://api.elsevier.com/content/abstract/scopus_id/85048892338,"Background and objectives
                  We evaluated the performance of the Procleix HEV RNA assay implemented on the Panther automated platform for detecting HEV RNA.
               
                  Study design and results
                  Analytical specificity was 100% and there was no cross contamination, as assessed by assaying 122 plasma samples from HEV RNA-negative blood donors. The limits of detection were determined by Probit analysis with the WHO HEV standard (HEV subtype 3a) and subtype 3f and 3c reference strains. The limit of detection was 24 [CI 95%: 19–33] IU/ml for subtype 3a, 34 [28–44] IU/ml for subtype 3c and 53 [41–76] IU/ml for subtype 3f.
                  Inclusivity was assessed by testing 91 samples: HEV genotype 3 subtypes 3c (n = 29), 3e (n = 8), 3f (n = 50), genotype 4 (n = 3), and genotype 1 (n = 1). All the samples tested positive.
                  Clinical performance was determined by testing prospectively 500 consecutive plasma samples and 19 faecal samples with the Procleix assay and a reference accredited quantitative RT-PCR assay. The assays were concordant for 492/500 plasma samples (98.4%) and 18/19 (94.7%) fecal samples.
                  We also tested 92 IgM-positive/HEV RNA-negative samples with the reference assay. The IgM-positive samples included 43 (46%) that tested negative with the reference RT-PCR assay and positive with the Procleix HEV assay.
               
                  Conclusions
                  The Procleix HEV assay performed well and appears to be suitable for molecular diagnosis of HEV infection, monitoring HEV infections, and facilitating epidemiological investigations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.isatra.2018.05.003,Journal,ISA Transactions,scopus,2018-08-01,sciencedirect,Heart rate monitoring and therapeutic devices: A wavelet transform based approach for the modeling and classification of congestive heart failure,https://api.elsevier.com/content/abstract/scopus_id/85047250258,"Heart rate monitoring and therapeutic devices include real-time sensing capabilities reflecting the state of the heart. Current circuitry can be interpreted as a cardiac electrical signal compression algorithm representing the time signal information into a single event description of the cardiac activity. It is observed that some detection techniques developed for ECG signal detection like artificial neural network, genetic algorithm, Hilbert transform, hidden Markov model are some sophisticated algorithms which provide suitable results but their implementation on a silicon chip is very complicated. Due to less complexity and high performance, wavelet transform based approaches are widely used. In this paper, after a thorough analysis of various wavelet transforms, it is found that Biorthogonal wavelet transform is best suited to detect ECG signal's QRS complex. The main steps involved in ECG detection process consist of de-noising and locating different ECG peaks using adaptive slope prediction thresholding. Furthermore, the significant challenges involved in the wireless transmission of ECG data are data conversion and power consumption. As medical regulatory boards demand a lossless compression technique, lossless compression technique with a high bit compression ratio is highly required. Furthermore, in this work, LZMA based ECG data compression technique is proposed. The proposed methodology achieves the highest signal to noise ratio, and lowest root mean square error. Also, the proposed ECG detection technique is capable of distinguishing accurately between healthy, myocardial infarction, congestive heart failure and coronary artery disease patients with a detection accuracy, sensitivity, specificity, and error of 99.92%, 99.94%, 99.92% and 0.0013, respectively. The use of LZMA data compression of ECG data achieves a high compression ratio of 18.84. The advantages and effectiveness of the proposed algorithm are verified by comparing with the existing methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2018.04.030,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-08-01,sciencedirect,Computerized decision support for beneficial home-based exercise rehabilitation in patients with cardiovascular disease,https://api.elsevier.com/content/abstract/scopus_id/85046622771,"Background
                  Exercise-based rehabilitation plays a key role in improving the health and quality of life of patients with Cardiovascular Disease (CVD). Home-based computer-assisted rehabilitation programs have the potential to facilitate and support physical activity interventions and improve health outcomes.
               
                  Objectives
                  We present the development and evaluation of a computerized Decision Support System (DSS) for unsupervised exercise rehabilitation at home, aiming to show the feasibility and potential of such systems toward maximizing the benefits of rehabilitation programs.
               
                  Methods
                  The development of the DSS was based on rules encapsulating the logic according to which an exercise program can be executed beneficially according to international guidelines and expert knowledge. The DSS considered data from a prescribed exercise program, heart rate from a wristband device, and motion accuracy from a depth camera, and subsequently generated personalized, performance-driven adaptations to the exercise program. Communication interfaces in the form of RESTful web service operations were developed enabling interoperation with other computer systems.
               
                  Results
                  The DSS was deployed in a computer-assisted platform for exercise-based cardiac rehabilitation at home, and it was evaluated in simulation and real-world studies with CVD patients. The simulation study based on data provided from 10 CVD patients performing 45 exercise sessions in total, showed that patients can be trained within or above their beneficial HR zones for 67.1 ± 22.1% of the exercise duration in the main phase, when they are guided with the DSS. The real-world study with 3 CVD patients performing 43 exercise sessions through the computer-assisted platform, showed that patients can be trained within or above their beneficial heart rate zones for 87.9 ± 8.0% of the exercise duration in the main phase, with DSS guidance.
               
                  Conclusions
                  Computerized decision support systems can guide patients to the beneficial execution of their exercise-based rehabilitation program, and they are feasible.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2018.04.023,Journal,Energy and Buildings,scopus,2018-07-15,sciencedirect,rEMpy: a comprehensive software framework for residential energy management,https://api.elsevier.com/content/abstract/scopus_id/85046688433,"In this paper a comprehensive residential Energy Management in python, rEMpy, is presented. The framework has a modular structure and the Optimal Scheduler, featuring a task scheduling logic and a configuration structure to represent different subsystems, is the core. A dynamic configuration of the system and data visualization is allowed by the Web Interface. The required forecasts are delegated to the Prediction module. Moreover, the real-time validation of the controlled systems and devices is supported thought the Fault Diagnosis and Overload Manager modules. The cooperation among the modules and the manager capabilities are validated by performing evaluations on both tasks scheduling and storage management on real-case data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijantimicag.2018.02.018,Journal,International Journal of Antimicrobial Agents,scopus,2018-07-01,sciencedirect,Identification and bioevaluation of SRI-12742 as an antimicrobial agent against multidrug-resistant Acinetobacter baumannii,https://api.elsevier.com/content/abstract/scopus_id/85048519265,"Multidrug-resistant Acinetobacter baumannii (MDR-Ab) is one of the most significant nosocomial pathogens that is being increasingly isolated in healthcare settings worldwide. Owing to its inherent drug-resistant nature, coupled with its ability to readily acquire resistance to other antibiotic classes, there is a real dearth of antibiotics available to treat infections with MDR-Ab. A commercially available library was screened against MDR-Ab BAA-1605 to identify novel inhibitory molecules. The selectivity index of a hit was tested against Vero cells and in vitro efficacy was profiled against a panel of clinical MDR-Ab. The bacteriostatic or bactericidal nature was determined by time–kill experiments, and synergy with clinically approved drugs was determined by the chequerboard method. Additionally, in vivo efficacy was measured in a murine neutropenic A. baumannii thigh infection model. SRI-12742 was identified as a potent active hit, with a minimum inhibitory concentration (MIC) of 4 mg/L against BAA-1605. Its activity was then profiled against a MDR-Ab clinical strain panel (MICs 4 mg/L to >64 mg/L). SRI-12742 exhibited concentration-dependent bactericidal activity and caused an ca. 16 log10 CFU/mL reduction at 10 × MIC in 24 h, which is comparable with minocycline. In a murine neutropenic thigh infection model of A. baumannii infection, SRI-12742 reduced CFU counts by ca. 0.9 log10 CFU, which is comparable with polymyxin B. In addition, SRI-12742 synergised with all classes of antibiotics tested. SRI-12742 exhibits all of the criteria necessary to be positioned as a novel lead with potential to be deployed for the treatment of infections caused by MDR-Ab.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2018.05.004,Journal,Computers in Biology and Medicine,scopus,2018-07-01,sciencedirect,Evaluation of machine learning algorithms for improved risk assessment for Down's syndrome,https://api.elsevier.com/content/abstract/scopus_id/85046822586,"Prenatal screening generates a great amount of data that is used for predicting risk of various disorders. Prenatal risk assessment is based on multiple clinical variables and overall performance is defined by how well the risk algorithm is optimized for the population in question. This article evaluates machine learning algorithms to improve performance of first trimester screening of Down syndrome. Machine learning algorithms pose an adaptive alternative to develop better risk assessment models using the existing clinical variables. Two real-world data sets were used to experiment with multiple classification algorithms. Implemented models were tested with a third, real-world, data set and performance was compared to a predicate method, a commercial risk assessment software. Best performing deep neural network model gave an area under the curve of 0.96 and detection rate of 78% with 1% false positive rate with the test data. Support vector machine model gave area under the curve of 0.95 and detection rate of 61% with 1% false positive rate with the same test data. When compared with the predicate method, the best support vector machine model was slightly inferior, but an optimized deep neural network model was able to give higher detection rates with same false positive rate or similar detection rate but with markedly lower false positive rate. This finding could further improve the first trimester screening for Down syndrome, by using existing clinical variables and a large training data derived from a specific population.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2018.04.012,Journal,Artificial Intelligence in Medicine,scopus,2018-07-01,sciencedirect,An interoperable clinical decision-support system for early detection of SIRS in pediatric intensive care using openEHR,https://api.elsevier.com/content/abstract/scopus_id/85046668398,"Background
                  Clinical decision-support systems (CDSS) are designed to solve knowledge-intensive tasks for supporting decision-making processes. Although many approaches for designing CDSS have been proposed, due to high implementation costs, as well as the lack of interoperability features, current solutions are not well-established across different institutions. Recently, the use of standardized formalisms for knowledge representation as terminologies as well as the integration of semantically enriched clinical information models, as openEHR Archetypes, and their reuse within CDSS are theoretically considered as key factors for reusable CDSS.
               
                  Objective
                  We aim at developing and evaluating an openEHR based approach to achieve interoperability in CDSS by designing and implementing an exemplary system for automated systemic inflammatory response syndrome (SIRS) detection in pediatric intensive care.
               
                  Methods
                  We designed an interoperable concept, which enables an easy integration of the CDSS across different institutions, by using openEHR Archetypes, terminology bindings and the Archetype Query Language (AQL). The practicability of the approach was tested by (1) implementing a prototype, which is based on an openEHR based data repository of the Hannover Medical School (HaMSTR), and (2) conducting a first pilot study.
               
                  Results
                  We successfully designed and implemented a CDSS with interoperable knowledge bases and interfaces by reusing internationally agreed-upon Archetypes, incorporating LOINC terminology and creating AQL queries, which allowed retrieving dynamic facts in a standardized and unambiguous form. The technical capabilities of the system were evaluated by testing the prototype on 16 randomly selected patients with 129 days of stay, and comparing the results with the assessment of clinical experts (leading to a sensitivity of 1.00, a specificity of 0.94 and a Cohen’s kappa of 0.92).
               
                  Conclusions
                  We found the use of openEHR Archetypes and AQL a feasible approach to bridge the interoperability gap between local infrastructures and CDSS. The designed concept was successfully transferred into a clinically evaluated openEHR based CDSS. To the authors’ knowledge, this is the first openEHR based CDSS, which is technically reliable and capable in a real context, and facilitates clinical decision-support for a complex task. Further activities will comprise enrichments of the knowledge base, the reasoning processes and cross-institutional evaluations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enpol.2018.04.011,Journal,Energy Policy,scopus,2018-07-01,sciencedirect,Decision support system for Pradhan Mantri Ujjwala Yojana,https://api.elsevier.com/content/abstract/scopus_id/85045255236,"Pradhan Mantri Ujjwala Yojana (PMUY) is a flagship energy policy initiated by the government of India to provide women below poverty line (BPL) access to clean energy fuel, Liquefied Petroleum Gas (LPG). This policy has led to the empowerment of women and protection against health hazards. A decision support system (DSS) is proposed to quantitatively analyse the implementation of PMUY in real time. This approach is first of its kind for analysis of a national level energy policy. The system uses mixed integer linear programming approach to mathematically formulate the policy using input parameters, decision variables and their relationships. The DSS requires input parameters namely distributing capacity of a LPG dealer, subsidised cylinders available per connection, number of households, and LPG penetration required. We have analysed different scenarios varying the input parameters mentioned. The decision support system has deterministically found the number of dealers required and LPG penetration in a region projecting both BPL and aggregate household coverage. The system helps in making sound decisions based on quantitative modelling ensuring optimal implementation of the policy. This kind of decision support system can be formulated for various policies to make sound decisions based on strong quantitative evidences.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bdr.2018.02.004,Journal,Big Data Research,scopus,2018-07-01,sciencedirect,Scalable Machine Learning for Predicting At-Risk Profiles Upon Hospital Admission,https://api.elsevier.com/content/abstract/scopus_id/85043390972,"We show how the analysis of very large amounts of drug prescription data make it possible to detect, on the day of hospital admission, patients at risk of developing complications during their hospital stay. We explore, for the first time, to which extent volume and variety of big prescription data help in constructing predictive models for the automatic detection of at-risk profiles.
                  Our methodology is designed to validate our claims that: (1) drug prescription data on the day of admission contain rich information about the patient's situation and perspectives of evolution, and (2) the various perspectives of big medical data (such as veracity, volume, variety) help in extracting this information. We build binary classification models to identify at-risk patient profiles. We use a distributed architecture to ensure scalability of model construction with large volumes of medical records and clinical data.
                  We report on practical experiments with real data of millions of patients and hundreds of hospitals. We demonstrate how the fine-grained analysis of such big data can improve the detection of at-risk patients, making it possible to construct more accurate predictive models that significantly benefit from volume and variety, while satisfying important criteria to be deployed in hospitals.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2018.03.014,Journal,Neurocomputing,scopus,2018-06-14,sciencedirect,ACDIN: Bridging the gap between artificial and real bearing damages for bearing fault diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85044327325,"Data-driven algorithms for bearing fault diagnosis have achieved much success. However, it is difficult and even impossible to collect enough data containing real bearing damages to train the classifiers, which hinders the application of these methods in industrial environments. One feasible way to address the problem is training the classifiers with data generated from artificial bearing damages instead of real ones. In this way, the problem changes to how to extract common features shared by both kinds of data because the differences between the artificial one and the natural one always baffle the learning machine. In this paper, a novel model, deep inception net with atrous convolution (ACDIN), is proposed to cope with the problem. The contribution of this paper is threefold. First and foremost, ACDIN improves the accuracy from 75% (best results of conventional data-driven methods) to 95% on diagnosing the real bearing faults when trained with only the data generated from artificial bearing damages. Second, ACDIN takes raw temporal signals as inputs, which means that it is pre-processing free. Last, feature visualization is used to analyze the mechanism behind the high performance of the proposed model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jconrel.2018.04.017,Journal,Journal of Controlled Release,scopus,2018-06-10,sciencedirect,Overcoming safety challenges in CO therapy – Extracorporeal CO delivery under precise feedback control of systemic carboxyhemoglobin levels,https://api.elsevier.com/content/abstract/scopus_id/85046347956,"Carbon monoxide (CO) has demonstrated therapeutic potential in multiple inflammatory conditions including intensive care applications such as organ transplantation or sepsis. Approaches to translate these findings into future therapies, however, have been challenged by multiple hurdles including handling and toxicity issues associated with systemic CO delivery. Here, we describe a membrane-controlled Extracorporeal Carbon Monoxide Release System (ECCORS) for easy implementation into Extracorporeal Membrane Oxygenation (ECMO) setups, which are being used to treat cardiac and respiratory diseases in various intensive care applications. Functionalities of the ECCORS were investigated in a pig model of veno-arterial ECMO. By precisely controlling CO generation and delivery as a function of systemic carboxyhemoglobin levels, the system allows for an immediate onset of therapeutic CO-levels while preventing CO-toxicity. Systemic carboxyhemoglobin levels were profiled in real-time by monitoring exhaled CO levels as well as by pulse oximetry, enabling self-contained and automatic feedback control of CO generation within ECCORS. Machine learning based mathematical modeling was performed to increase the predictive power of this approach, laying foundation for high precision systemic CO delivery concepts of tomorrow.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.transci.2018.05.004,Journal,Transfusion and Apheresis Science,scopus,2018-06-01,sciencedirect,Artificial intelligence: A joint narrative on potential use in pediatric stem and immune cell therapies and regenerative medicine,https://api.elsevier.com/content/abstract/scopus_id/85047095825,"Artificial Intelligence (AI) reflects the intelligence exhibited by machines and software. It is a highly desirable academic field of many current fields of studies. Leading AI researchers describe the field as “the study and design of intelligent agents”. McCarthy invented this term in 1955 and defined it as “the science and engineering of making intelligent machines”. The central goals of AI research are reasoning, knowledge, planning, learning, natural language processing (communication), perception and the ability to move and manipulate objects. In fact the multidisplinary AI field is considered to be rather interdisciplinary covering numerous number of sciences and professions, including computer science, psychology, linguistics, philosophy and neurosciences. The field was founded on the claim that a central intellectual property of humans, intelligence-the sapience of Homo Sapiens “can be so precisely described that a machine can be made to simulate it”. This raises philosophical issues about the nature of the mind and the ethics of creating artificial beings endowed with human-like intelligence. Artificial Intelligence has been the subject of tremendous optimism but has also suffered stunning setbacks.
                  The goal of this narrative is to review the potential use of AI approaches and their integration into pediatric cellular therapies and regenerative medicine. Emphasis is placed on recognition and application of AI techniques in the development of predictive models for personalized treatments with engineered stem cells, immune cells and regenerated tissues in adults and children. These intelligent machines could dissect the whole genome and isolate the immune particularities of individual patient’s disease in a matter of minutes and create the treatment that is customized to patient’s genetic specificity and immune system capability. AI techniques could be used for optimization of clinical trials of innovative stem cell and gene therapies in pediatric patients by precise planning of treatments, predicting clinical outcomes, simplifying recruitment and retention of patients, learning from input data and applying to new data, thus lowering their complexity and costs. Complementing human intelligence with machine intelligence could have an exponentially high impact on continual progress in many fields of pediatrics. However how long before we could see the real impact still remains the big question. The most pertinent question that remains to be answered therefore, is can AI effectively and accurately predict properties of newer DDR strategies?
                  The goal of this article is to review the use of AI method for cellular therapy and regenerative medicine and emphasize its potential to further the progress in these fields of medicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2018.03.008,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,Decision support system for triage management: A hybrid approach using rule-based reasoning and fuzzy logic,https://api.elsevier.com/content/abstract/scopus_id/85044143487,"Objectives
                  Fast and accurate patient triage for the response process is a critical first step in emergency situations. This process is often performed using a paper-based mode, which intensifies workload and difficulty, wastes time, and is at risk of human errors. This study aims to design and evaluate a decision support system (DSS) to determine the triage level.
               
                  Methods
                  A combination of the Rule-Based Reasoning (RBR) and Fuzzy Logic Classifier (FLC) approaches were used to predict the triage level of patients according to the triage specialist’s opinions and Emergency Severity Index (ESI) guidelines. RBR was applied for modeling the first to fourth decision points of the ESI algorithm. The data relating to vital signs were used as input variables and modeled using fuzzy logic. Narrative knowledge was converted to If-Then rules using XML. The extracted rules were then used to create the rule-based engine and predict the triage levels.
               
                  Results
                  Fourteen RBR and 27 fuzzy rules were extracted and used in the rule-based engine. The performance of the system was evaluated using three methods with real triage data. The accuracy of the clinical decision support systems (CDSSs; in the test data) was 99.44%. The evaluation of the error rate revealed that, when using the traditional method, 13.4% of the patients were miss-triaged, which is statically significant. The completeness of the documentation also improved from 76.72% to 98.5%.
               
                  Conclusions
                  Designed system was effective in determining the triage level of patients and it proved helpful for nurses as they made decisions, generated nursing diagnoses based on triage guidelines. The hybrid approach can reduce triage misdiagnosis in a highly accurate manner and improve the triage outcomes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dib.2018.02.075,Journal,Data in Brief,scopus,2018-06-01,sciencedirect,Neuro-fuzzy inference system Prediction of stability indices and Sodium absorption ratio in Lordegan rural drinking water resources in west Iran,https://api.elsevier.com/content/abstract/scopus_id/85044120214,"According to World Health Organization guidelines, corrosion control is an important aspect of safe drinking-water supplies. Water always includes ingredients, dissolved gases and suspended materials. Although some of these water ingredients is indispensable for human beings, these elements more than permissible limits, could be endanger human health. The aim of this study is to assess physical and chemical parameters of drinking water in the rural areas of Lordegan city, also to determine corrosion indices. This cross-sectional study has carried out with 141 taken samples during 2017 with 13 parameters, which has been analyzed based on standard method and to estimate the water quality indices from groundwater using ANFIS. Also with regard to standard conditions, results of this paper are compared with Environmental Protection Agency and Iran national standards. Five indices, Ryznar Stability Index (RSI), Langlier Saturation Index (LSI), Larson-Skold Index (LS), Puckorius Scaling Index (PSI), and Aggressive Index (AI) programmed by using Microsoft Excel software. Owing to its simplicity, the program, can easily be used by researchers and operators. Parameters included Sulfate, Sodium, Chloride, and Electrical Conductivity respectively were 13.5, 28, 10.5, and 15% more than standard level. The amount of Nitrate, in 98% of cases were in permissible limits and about 2% were more than standard level. Result of presented research indicate that water is corrosive at 10.6%,89.4%,87.2%,59.6% and 14.9% of drinking water supply reservoirs, according to LSI, RSI, PSI, LS and AI, respectively.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2018.01.015,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,Humanitarian health computing using artificial intelligence and social media: A narrative literature review,https://api.elsevier.com/content/abstract/scopus_id/85040945850,"Introduction
                  According to the World Health Organization (WHO), over 130 million people are in constant need of humanitarian assistance due to natural disasters, disease outbreaks, and conflicts, among other factors. These health crises can compromise the resilience of healthcare systems, which are essential for achieving the health objectives of the sustainable development goals (SDGs) of the United Nations (UN). During a humanitarian health crisis, rapid and informed decision making is required. This is often challenging due to information scarcity, limited resources, and strict time constraints. Moreover, the traditional approach to digital health development, which involves a substantial requirement analysis, a feasibility study, and deployment of technology, is ill-suited for many crisis contexts. The emergence of Web 2.0 technologies and social media platforms in the past decade, such as Twitter, has created a new paradigm of massive information and misinformation, in which new technologies need to be developed to aid rapid decision making during humanitarian health crises.
               
                  Objective
                  Humanitarian health crises increasingly require the analysis of massive amounts of information produced by different sources, such as social media content, and, hence, they are a prime case for the use of artificial intelligence (AI) techniques to help identify relevant information and make it actionable. To identify challenges and opportunities for using AI in humanitarian health crises, we reviewed the literature on the use of AI techniques to process social media.
               
                  Methodology
                  We performed a narrative literature review aimed at identifying examples of the use of AI in humanitarian health crises. Our search strategy was designed to get a broad overview of the different applications of AI in a humanitarian health crisis and their challenges. A total of 1459 articles were screened, and 24 articles were included in the final analysis.
               
                  Results
                  Successful case studies of AI applications in a humanitarian health crisis have been reported, such as for outbreak detection. A commonly shared concern in the reviewed literature is the technical challenge of analyzing large amounts of data in real time. Data interoperability, which is essential to data sharing, is also a barrier with regard to the integration of online and traditional data sources.
                  Human and organizational aspects that might be key factors for the adoption of AI and social media remain understudied. There is also a publication bias toward high-income countries, as we identified few examples in low-income countries. Further, we did not identify any examples of certain types of major crisis, such armed conflicts, in which misinformation might be more common.
               
                  Conclusions
                  The feasibility of using AI to extract valuable information during a humanitarian health crisis is proven in many cases. There is a lack of research on how to integrate the use of AI into the work-flow and large-scale deployments of humanitarian aid during a health crisis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijmedinf.2017.12.021,Journal,International Journal of Medical Informatics,scopus,2018-06-01,sciencedirect,The ALMANACH Project: Preliminary results and potentiality from Afghanistan,https://api.elsevier.com/content/abstract/scopus_id/85040258127,"Introduction
                  ALMANACH (ALgorithms for the MANagement of Acute CHildhood illnesses) is an electronic version of IMCI (Integrated Management of Childhood Illness) running on tablets. ALMANACH enhances its concept, it integrates well into health staff's daily consultation work and facilitates diagnosis and treatment. ALMANACH informs when to refer a child or to perform a rapid diagnostic test (RDT), recommends the right treatment dosage and synchronizes collected data real time with a Health Management Information System (DHIS2) for epidemiological evaluation and decision making.
               
                  Objectives
                  Since May 2016, ALMANACH is under investigational deployment in three primary health care facilities in Afghanistan with the goal to improve the quality of care provided to children between 2 months and 5 years old.
               
                  Methods
                  IMCI's algorithms were updated in considering latest scientific publications, national guidelines, innovations in RDTs, the target population's epidemiological profile and the local resources available. Before the implementation of the project, a direct observation of 599 consultations was carried out to assess the daily performance at three selected health facilities in Kabul.
               
                  Results
                  The baseline survey showed that nutritional screening, vitamin A supplementation and deworming were not systematically performed: few patients were diagnosed for malnutrition (1.8%), received vitamin A (2.7%) or deworming (7.5%). Physical examination was appropriate only for 23.8% of the diagnoses of respiratory or gastrointestinal diseases, ear infection and sore throat. Respiratory rate was checked only in 33.5% of the children with fever and cough, dehydration status was assessed in only 16.5% of the diarrhoea cases. Forty-seven percent of patients received incorrect treatment. Sixty-four percent of the children, before the introduction of ALMANACH, received at least one antibiotic, although for 87.1% antibiotic therapy was unnecessary.
                  The review of 8′047 paediatric consultations between May 2016 and September 2017 showed that with ALMANACH, malnutrition detection, deworming and Vitamin A supplementation increased respectively to 4.4%, 50.2% and 27.5%. Antibiotic prescription decreased to 21.83% and all children were examined and treated in compliance with the protocols. Conclusion: A survey will be conducted one year after the implementation to validate these initial promising results. If the efficacy of the approach is confirmed, ALMANACH could establish as a powerful innovation for primary health care.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.snb.2018.01.117,Journal,"Sensors and Actuators, B: Chemical",scopus,2018-05-15,sciencedirect,Graphene oxide functionalized long period fiber grating for highly sensitive hemoglobin detection,https://api.elsevier.com/content/abstract/scopus_id/85041418010,"We present graphene oxide (GO) nanosheets functionalized long period grating (LPG) for ultrasensitive hemoglobin sensing. The sensing mechanism relies on the measurement of LPG resonant intensity change induced by the adsorption of hemoglobin molecules onto GO, where GO as a bio-interface linkage provides the significant light-matter interaction between evanescent field and target molecules. The deposition technique based on chemical-bonding associated with physical-adsorption was developed to immobilize GO nanosheets on cylindrical fiber device. The surface morphology was characterized by scanning electron microscope, atomic force microscopy, and Raman spectroscopy. With relatively thicker GO coating, the refractive index (RI) sensitivity of GO-LPG was extremely enhanced and achieved −76.5 dB/RIU, −234.2 dB/RIU and +1580.5 dB/RIU for RI region of 1.33–1.38, 1.40–1.44 and 1.45–1.46, respectively. The GO-LPG was subsequently implemented as an optical biosensor to detect human hemoglobin giving a sensitivity of 1.9 dB/(mg/mL) and a detectable concentration of 0.05 mg/mL, which was far below the hemoglobin threshold value for anemia defined by World Health Organization. The proposed GO-LPG architecture can be further developed as an optical biosensing platform for anemia diagnostics and biomedical applications.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jneumeth.2017.07.020,Journal,Journal of Neuroscience Methods,scopus,2018-04-15,sciencedirect,Automated face recognition of rhesus macaques,https://api.elsevier.com/content/abstract/scopus_id/85026478684,"Background
                  Rhesus macaques are widely used in biomedical research. Automated behavior monitoring can be useful in various fields (including neuroscience), as well as having applications to animal welfare but current technology lags behind that developed for other species. One difficulty facing developers is the reliable identification of individual macaques within a group especially as pair- and group-housing of macaques becomes standard. Current published methods require either implantation or wearing of a tracking device.
               
                  New method
                  I present face recognition, in combination with face detection, as a method to non-invasively identify individual rhesus macaques in videos. The face recognition method utilizes local-binary patterns in combination with a local discriminant classification algorithm.
               
                  Results
                  A classification accuracy of between 90 and 96% was achieved for four different groups. Group size, number of training images and challenging image conditions such as high contrast all had an impact on classification accuracy. I demonstrate that these methods can be applied in real time using standard affordable hardware and a potential application to studies of social structure.
               
                  Comparison with existing method(s)
                  Face recognition methods have been reported for humans and other primate species such as chimpanzees but not rhesus macaques. The classification accuracy with this method is comparable to that for chimpanzees. Face recognition has the advantage over other methods for identifying rhesus macaques such as tags and collars of being non-invasive.
               
                  Conclusions
                  This is the first reported method for face recognition of rhesus macaques, has high classification accuracy and can be implemented in real time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2018.02.004,Journal,Artificial Intelligence in Medicine,scopus,2018-04-01,sciencedirect,Personalized prediction of drug efficacy for diabetes treatment via patient-level sequential modeling with neural networks,https://api.elsevier.com/content/abstract/scopus_id/85042348967,"Patients with type 2 diabetes mellitus are generally under continuous long-term medical treatment based on anti-diabetic drugs to achieve the desired glucose level. Thus, each patient is associated with a sequence of multiple records for prescriptions and their efficacies. Sequential dependencies are embedded in these records as personal factors so that previous records affect the efficacy of the current prescription for each patient. In this study, we present a patient-level sequential modeling approach utilizing the sequential dependencies to render a personalized prediction of the prescription efficacy. The prediction models are implemented using recurrent neural networks that use the sequence of all the previous records as inputs to predict the prescription efficacy at the time the current prescription is provided for each patient. Through this approach, each patient's historical records are effectively incorporated into the prediction. The experimental results of both the regression and classification analyses on real-world data demonstrate improved prediction accuracy, particularly for those patients having multiple previous records.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.measurement.2018.01.022,Journal,Measurement: Journal of the International Measurement Confederation,scopus,2018-04-01,sciencedirect,A machine learning model for improving healthcare services on cloud computing environment,https://api.elsevier.com/content/abstract/scopus_id/85041465388,"Recently, cloud computing gained an important role in healthcare services (HCS) due to its ability to improve the HCS performance. However, the optimal selection of virtual machines (VMs) to process a medical request represents a big challenge. Optimal selection of VMs performs a significant enhancement of the performance through reducing the execution time of medical requests (tasks) coming from stakeholders (patients, doctors, etc.) and maximizing utilization of cloud resources. For that, this paper proposes a new model for HCS based on cloud environment using Parallel Particle Swarm Optimization (PPSO) to optimize the VMs selection. In addition, a new model for chronic kidney disease (CKD) diagnosis and prediction is proposed to measure the performance of our VMs model. The prediction model of CKD is implemented using two consecutive techniques, which are linear regression (LR) and neural network (NN). LR is used to determine critical factors that influence on CKD. NN is used to predict of CKD. The results show that, the proposed model outperforms the state-of-the art models in total execution time the rate of 50%. In addition, the system efficiency regarding real-time data retrieval is greatly improved by 5.2%. In addition, the accuracy of hybrid intelligent model in predicting of CKD is 97.8%. The proposed model is superior to most of the referred models in the related works by 64%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2018.01.029,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-04-01,sciencedirect,Using computational support in motor ability analysis of individuals with Down syndrome: Literature review,https://api.elsevier.com/content/abstract/scopus_id/85041425268,"Background
                  The lack of motor ability is one of the main Down syndrome (DS) effects. However, there are several types of motor disorders that can be attenuated or corrected if they are early identified and properly analyzed.
               
                  Objectives
                  The aim of our study is to support the local Physical Activity research group, which works with about 25 DS children, by means of computational resources for motor analysis. To that end, we first needed to identify the main computational approaches that support the motor analysis of DS individuals, if they are already connected to intervention programs, and potential opportunities to extend the current state of the art.
               
                  Method
                  We carried out a systematic review that identified 28 papers from the current literature. These papers were then analyzed to answer the research questions defined in our study.
               
                  Results
                  Our main findings were: (1) the temporal distribution of papers shows this area is new and it is starting to create a body of knowledge that in fact supports motor treatments of DS individuals; (2) there is a diversity of studies that consider different research directions such as comparisons of motor features of DS with non-DS individuals, characterization of DS motor features, and approaches for intervention programs to improve DS motor abilities; (3) there are several types of sensing hardware that enables the development of studies from different perspectives; (4) spatial monitoring is performed but only in laboratory conditions; (5); mathematical tools are largely used while strategies based on artificial intelligence for automated analysis are ignored; and (6) proposals for DS post-intervention monitoring are not found in the literature.
               
                  Conclusion
                  DS motor analysis is still a new research area and it is not mature yet. Thus, the use of computational resources is very pragmatic and focused only on mathematical tools that support the numerical analysis of the acquired data. The main proposals for motor analysis are performed in laboratory, so that there are several opportunities to create computational resources to obtain real-time data on the move. The integration of this data with intervention strategies is also a potential area for future researches.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cptl.2017.12.018,Journal,Currents in Pharmacy Teaching and Learning,scopus,2018-04-01,sciencedirect,Utilizing desirable difficulties for sterile compounding training in a skills-based laboratory course,https://api.elsevier.com/content/abstract/scopus_id/85040361754,"Background and purpose
                  Sterile compounding skills are essential components of a professional pharmacy curriculum. The theory of desirable difficulties has been used to facilitate deeper learning of material in other disciplines, but has not been described in pharmacy sterile compounding instruction. The purpose of this work was to evaluate whether challenges introduced in sterile compounding would act as desirable difficulties and result in greater student confidence in their sterile compounding competency.
               
                  Educational activity and setting
                  Students in the fourth semester of Pharmacy Skills and Applications, a laboratory-based skills course, were presented with challenges in sterile compounding and were asked to complete a questionnaire rating their confidence and describing their experience.
               
                  Findings
                  The majority (92.8%) of students reported that the activity increased their confidence in their sterile compounding skills. Students’ open-ended responses suggested that most of the knowledge gained was strategic in nature.
               
                  Discussion
                  The results of this activity met the instructors’ initial goals by positively impacting students’ confidence in their ability to overcome challenges with sterile products compounding. Course instructors may explore additional skills in which to introduce desirable difficulties in order to build student confidence.
               
                  Summary
                  Course instructors were pleased with the implementation and results of this desirable difficulties activity and plan to continue its use again in future semesters. Incorporating more real-world challenges throughout the skills-lab course may be beneficial to student learning and confidence. With thoughtful planning, faculty at other institutions can readily incorporate similar activities within their own courses.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2017.12.011,Journal,Engineering Applications of Artificial Intelligence,scopus,2018-03-01,sciencedirect,An Artificial Intelligence paradigm for troubleshooting software bugs,https://api.elsevier.com/content/abstract/scopus_id/85040456672,"Software bugs are prevalent and fixing them is time consuming, and therefore troubleshooting is an important part of software engineering. This paper presents a novel paradigm for incorporating Artificial Intelligence (AI) in the modern software troubleshooting process that can drastically reduce troubleshooting costs. In this paradigm, which we call Learn, Diagnose, and Plan (LDP), we integrate three AI technologies: (1) machine learning: learning from source-code structure, revisions history and past failures, which software components are more likely to contain bugs, (2) automated diagnosis: identifying the software components that need to be modified in order to fix an observed bug, and (3) automated planning: planning additional tests when such are needed to improve diagnostic accuracy. Importantly, these AI technologies are integrated in LDP in a synergistic manner: the diagnosis algorithm is modified to consider the learned fault predictions and the planner is modified to consider the possible diagnoses outputted by the diagnosis algorithm. The overall solution is demonstrated on real faults observed in four open source software projects.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2017.12.003,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-03-01,sciencedirect,Classification of cancer cells using computational analysis of dynamic morphology,https://api.elsevier.com/content/abstract/scopus_id/85039870009,"Background and Objective
                  Detection of metastatic tumor cells is important for early diagnosis and staging of cancer. However, such cells are exceedingly difficult to detect from blood or biopsy samples at the disease onset. It is reported that cancer cells, and especially metastatic tumor cells, show very distinctive morphological behavior compared to their healthy counterparts on aptamer functionalized substrates. The ability to quickly analyze the data and quantify the cell morphology for an instant real-time feedback can certainly contribute to early cancer diagnosis. A supervised machine learning approach is presented for identification and classification of cancer cell gestures for early diagnosis.
               
                  Methods
                  We quantified the morphologically distinct behavior of metastatic cells and their healthy counterparts captured on aptamer-functionalized glass substrates from time-lapse optical micrographs. As a proof of concept, the morphologies of human glioblastoma (hGBM) and astrocyte cells were used. The cells were captured and imaged with an optical microscope. Multiple feature vectors were extracted to quantify and differentiate the complex physical gestures of cancerous and non-cancerous cells. Three different classifier models, Support Vector Machine (SVM), Random Forest Tree (RFT), and Naïve Bayes Classifier (NBC) were trained with the known dataset using machine learning algorithms. The performances of the classifiers were compared for accuracy, precision, and recall measurements using five-fold cross-validation technique.
               
                  Results
                  All the classifier models detected the cancer cells with an average accuracy of at least 82%. The NBC performed the best among the three classifiers in terms of Precision (0.91), Recall (0.9), and F
                     1-score (0.89) for the existing dataset.
               
                  Conclusions
                  This paper presents a standalone system built on machine learning techniques for cancer screening based on cell gestures. The system offers rapid, efficient, and novel identification of hGBM brain tumor cells and can be extended to define single cell analysis metrics for many other types of tumor cells.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2017.12.001,Journal,Computer Methods and Programs in Biomedicine,scopus,2018-03-01,sciencedirect,A novel fuzzy rough selection of non-linearly extracted features for schizophrenia diagnosis using fMRI,https://api.elsevier.com/content/abstract/scopus_id/85038381014,"Background and objectives
                  Schizophrenia is a severe brain disorder primarily diagnosed through externally observed behavioural symptoms due to the dearth of established clinical tests. Functional magnetic resonance imaging (fMRI) can capture the distortions caused by schizophrenia in the brain activation. Hence, it can be useful for developing a decision model that performs computer-aided diagnosis of schizophrenia. But, fMRI data is huge in dimension. Therefore dimension reduction is indispensable. It is additionally required to identify the discriminative brain regions. Hence, we aim to build an effective decision model that incorporates suitable dimension reduction and also identifies discriminative brain regions.
               
                  Methods
                  We propose a three-phase dimension reduction. First phase involves spatially-constrained fuzzy clustering of 3-dimensional spatial maps (obtained from general linear model and independent component analysis). In the second phase, non-linear features are extracted from each cluster using a generalized discriminant analysis. In the third phase, a novel fuzzy rough feature selection is proposed. The features obtained after the third phase are used for learning a decision model by the help of support vector machine classifier. This complete method is implemented within leave-one-out cross-validation on two balanced datasets (respectively acquired on 1.5Tesla and 3Tesla scanners). Both these datasets are created using Function Biomedical Informatics Research Network multisite data and contain fMRI data acquired during auditory oddball task performed by age-matched schizophrenia patients and healthy subjects. A permutation test is also carried out to ensure that no bias is involved in the learning.
               
                  Results
                  The results indicate that the proposed method achieves maximum classification accuracy of 97.1% and 98.0% for the two datasets respectively. The proposed method outperforms the state-of-the-art methods. The results of the permutation test show that p-values are lesser than the significance level i.e. 0.05. Therefore, the classifier has found a significant class structure and does not involve any bias. Further, discriminative brain regions are identified and are in agreement with the findings in related literature.
               
                  Conclusion
                  The proposed method is able to derive suitable non-linear features and the related brain regions for effective computer-aided diagnosis. The fuzzy and rough set based approaches help in handling uncertainty and ambiguity in real data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.media.2017.12.003,Journal,Medical Image Analysis,scopus,2018-02-01,sciencedirect,Multi-hypothesis tracking of the tongue surface in ultrasound video recordings of normal and impaired speech,https://api.elsevier.com/content/abstract/scopus_id/85037537839,"Characterizing tongue shape and motion, as they appear in real-time ultrasound (US) images, is of interest to the study of healthy and impaired speech production. Quantitative anlaysis of tongue shape and motion requires that the tongue surface be extracted in each frame of US speech recordings. While the literature proposes several automated methods for this purpose, these either require large or very well matched training sets, or lack robustness in the presence of rapid tongue motion. This paper presents a new robust method for tongue tracking in US images that combines simple tongue shape and motion models derived from a small training data set with a highly flexible active contour (snake) representation and maintains multiple possible hypotheses as to the correct tongue contour via a particle filtering algorithm. The method was tested on a database of large free speech recordings from healthy and impaired speakers and its accuracy was measured against the manual segmentations obtained for every image in the database. The proposed method achieved mean sum of distances errors of 1.69 ± 1.10 mm, and its accuracy was not highly sensitive to training set composition. Furthermore, the proposed method showed improved accuracy, both in terms of mean sum of distances error and in terms of linguistically meaningful shape indices, compared to the three publicly available tongue tracking software packages Edgetrak, TongueTrack and Autotrace.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.chemolab.2017.12.005,Journal,Chemometrics and Intelligent Laboratory Systems,scopus,2018-01-15,sciencedirect,A new reconstruction-based auto-associative neural network for fault diagnosis in nonlinear systems,https://api.elsevier.com/content/abstract/scopus_id/85037701407,"Auto-associative neural network (AANN) is a typical nonlinear principal component analysis method, which is widely used in industry for fault diagnosis purposes, especially in nonlinear systems. However, the basic AANN often suffers from “smearing effects” problems that may lead to misdiagnosis, particularly with regards to the complex faults involving multiple variables. In this work, a new reconstruction-based AANN (RBAANN) method is proposed to enhance the capacity of fault diagnosis. In RBAANN, a generic derivative equation is developed to investigate the effects of AANN model inputs on the prediction error between model inputs and outputs. Based on the derivative equation, the reconstruction-based index for single or multiple variables, which is defined as the minimum prediction error, is obtained by tuning the corresponding model inputs iteratively. However, without the prior knowledge of the real faulty variables, all the possible variable sets need to be evaluated by the reconstruction-based index, and this may result in an exhaustive search and cause a huge computational burden. Thus, a branch and bound algorithm is introduced into RBAANN to solve the variable selection problem. Finally, an efficient fault diagnosis strategy by integrating RBAANN and branch and bound algorithm (BAB-RBAANN) is implemented to further pinpoint the source of the detected faults. This BAB-RBAANN method can handle both single and multiple variable(s) faults for nonlinear systems without prior knowledge efficiently. The effectiveness of the proposed methods is evaluated on a validation example and an industrial example. Comparisons with other methods, including principal component analysis techniques, are also presented.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-813068-1.00008-7,Book,Engineering in Medicine: Advances and Challenges,scopus,2018-01-01,sciencedirect,3D graphics to virtual reality in medicine: Opportunities and prospective,https://api.elsevier.com/content/abstract/scopus_id/85083262343,"Today, in medicine, performing a procedure on a human requires complex anatomical and physiological knowledge, including 3D relational and physical properties. All commonly employed imaging modalities attempt to recapitulate this information in some useable form. Each technique, however, can only retrieve a small slice of spatial, temporal, or conceptual knowledge of the body area of interest. Furthermore, in some cases like computed tomography, a large amount of information is gathered without a clear strategy for manual or automated analysis. Current software developments are slowly realizing a convergence of medical imaging methodologies toward one of greater realism. For the purposes of this chapter, this “coming together” of disciplines will be delineated as the field of 3D graphics. Although this is a simplification, 3D graphics will be the primary foundation for a much larger hybridized field whose aim will be the creation of informative and accurate medical spatial representations. To understand how this will affect the clinical fields, we will need to first explore 3D graphics more holistically, delving into areas of physical simulation, 3D movie rendering, video game development, and the expansion of 3D visualization hardware. As we explore these fields, we will relate each of these subdomains to analogous examples in the medical field, also documenting opportunities for commercialization and innovation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-1-4557-0760-7.00003-6,Book,Critical Heart Disease in Infants and Children,scopus,2018-01-01,sciencedirect,Streaming analytics in pediatric cardiac care,https://api.elsevier.com/content/abstract/scopus_id/85082263171,"The cardiac intensive care unit (ICU) is an analytic environment, one in which insight about a patient's condition and evolving trajectory is gleaned from data and information from monitoring systems, electronic health records, and other data repositories. That data, both structured and unstructured, presents rapidly to clinicians and must be effectively managed in a timely manner to meet goals for patient care. With advances in computer and information technology, the evolution of the fields of data science and biomedical informatics, and examples of high-impact experiences with advanced data analytics approaches inside and outside of health care, the ability to effectively process and utilize clinical data, particularly high-frequency data, is on the rise. In the ICU, real-time data analytics, including streaming analytics that employ refined and validated predictive algorithms, have the potential to improve our accuracy in assessing a patient's condition, to support better assessment of the patient's course and response to treatment, and eventually to guide decisions and actions toward achieving the best possible outcomes. In this chapter an introduction to streaming analytics is provided, and experience with a recently developed predictive analytics software platform is discussed as an example of the current state of data analytics applications in the pediatric cardiac care environment.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-813314-9.00011-6,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Unsupervised anomaly detection for high dimensional data-An exploratory analysis,https://api.elsevier.com/content/abstract/scopus_id/85081928867,"Context: Anomaly detection is a crucial area engaging the attention of many researchers. It is a process of finding an unusual point or pattern in a given dataset. It is useful in many real time applications such as industry damage detection, detection of fraudulent usage of credit card, detection of failures in sensor nodes, detection of abnormal health and network intrusion detection. Algorithms proposed for anomaly detection in low dimensional data are not suitable for high dimensional data due to the well-known “dimensionality curses”.
               
                  Motivation: To tackle this issue, a plethora of algorithms dedicated to high dimensional data has been proposed. However, unsupervised algorithms have many problems and challenges, as there is no predefined data label to predict anomaly.
               
                  Objective: We aim at providing a complete view of unsupervised anomaly detection for high dimensional data which gives a clear perception of the concept.
               
                  Contribution: In this paper, existing algorithms and real time applications of unsupervised anomaly detection for high dimensional data have been studied. Evaluation measures, datasets and tools used by different authors have been discussed in detail. In addition, a hybrid framework of unsupervised anomaly detection algorithm called DBN–K means applied two different disease dataset is also proposed.
               
                  Future work: As future work, the proposed framework could be implemented and analyzed in other applications. High dimensional streaming data is another interesting area for further investigation, following this research work.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procir.2018.09.067,Conference Proceeding,Procedia CIRP,scopus,2018-01-01,sciencedirect,A Conceptual Design for Smell Based Augmented Reality: Case Study in Maintenance Diagnosis,https://api.elsevier.com/content/abstract/scopus_id/85059916374,"The trend of Industry 4.0 encourages the next generation of manufacturing to be flexible, intelligent, and interoperable. The implementations of the Artificial Intelligence (AI) technology could potentially enhance maintenance in efficiency, and accuracy. However, it will not be a substitution to the human operator’s flexibility, decision-making and information received by the natural five senses. Augmented reality (AR) is commonly understood as a technology that overlays virtual information onto the existing environment to provide users a new and improved experience to assist their daily activities. However, AR can be used to enhance all human five senses rather than just overlay virtual imagery. In this paper, a design and a practical plan of smell augmentation for diagnosis is initialised, via a case study in maintenance. The aim of this paper is to evaluate the feasibilities, identify challenges, and summarise initial results of overlaying information through smell augmentations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.11.080,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Intelligent data processing received from radio frequency identification system,https://api.elsevier.com/content/abstract/scopus_id/85059469763,"The present article is devoted to the issue of improvement of utilization efficiency of modern information technologies in order to enhance the quality and safety of healthcare delivery. The introduction of Real-time Locating Systems (RTLS), in particular Radio Frequency Identification System (RFID), applied in conjunction with intelligent data processing system can reduce the severity of the consequences of event risks implementation, as well as avoidance of a number of such consequences. The authors of the present article suggest using mathematical tools of fuzzy logic theory for event analysis in online mode and recommendation formation on their basis for timely management decision-taking.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.10.169,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,A practical sensors software to manage fault signals' impact,https://api.elsevier.com/content/abstract/scopus_id/85058340895,"The closely detailed search of sensed feature quality to ensure fault detection from weak sensors, which can skew the application model results signals, is required. As principal component analysis (PCA) is limited to correct isolate faulty signals’ impact, unlike the relative performance of neural Kohonen self-organizing map’s model to monitor air quality on any real complex condition. Indeed, this unsupervised method is enhanced by itself (2-SOM) and SOM hierarchical clustering (SOMHC) with both learning types; sequential and batch. These former models are improved also with Bubble, Gaussian, Gaussian Cut and Epanichnikov Kernel neighborhood functions, in graphical user interface form. Therefore, the study demonstrates more eective and complete results showing in quantization and topography errors including responses classification accuracy as well as in the KSOM-HCs dendograms view. Furthermore, this tool is relevant to provide the credible informations of pollutant detection, dedicated to Human Health safety, despite the conditions complexity.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.10.168,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Towards security on internet of things: Applications and challenges in technology,https://api.elsevier.com/content/abstract/scopus_id/85058281610,"The Internet of Things (IoT) paradigm refers to the network of physical objects or ""things"" embedded with electronics, software, sensors, and connectivity to enable objects to exchange data with servers, centralized systems, and/or other connected devices based on a variety of communication infrastructures. IoT data collected from different sensors, nodes and collectors are transferred to the cloud over the internet. IoT devices are used by consumers, healthcare, businesses as well as by the governments. It is being forecast that 31 billion IoT devices will be deployed all over the world by the year 2020. As the use of IoT devices is increasing every moment several IoT vulnerabilities are introduced. The results and analysis indicate that massive deployment of IoT with an integration of new technologies are introducing new security challenges in IoT paradigm. In this paper, IoT security challenges and open issues are discussed which provides a ground for future research.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-813314-9.00003-7,Book,Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications,scopus,2018-01-01,sciencedirect,Patient facial emotion recognition and sentiment analysis using secure cloud with hardware acceleration,https://api.elsevier.com/content/abstract/scopus_id/85056616332,"This chapter conducts sentiment analysis of medical patients through facial emotion recognition. In this work, a patient's facial expression is dynamically captured from a video stream, recognized using machine learning-based image classifiers, and put into one of the result categories including angry, disgusted, fearful, happy, sad, surprised, and neural. The system design includes three primary components: a video processor, a face detector, and an image classifier. The video processor captures a frame with a patient face from its video feed, converting it to a grayscale image that is then passed to the face detector. The face detector performs face detection by cropping the image around the face. The cropped face image is then resized and fed into the image classifier that will eventually recognize the facial emotion.
               The current state-of-the-art facial emotion recognition model makes use of a convolutional neural network (CNN) with three hidden layers and a linear support vector machine as the output layer. The model presented in this chapter expands on the state-of-the-art model by using pre-processed video stream frames as the input to our CNN model. Face detection, RGB to grayscale color conversion, and Gaussian normalization are applied to the image before it is input to the CNN. Besides expanding on the architecture of the state-of-the-art model, this work also adds an additional optimization step during training that detects saturation in the validation accuracy and decreases the learning rate in an attempt to combat this saturation. This added optimization allows the model to “narrow-in” on the values of trainable parameters that minimize the output value of the error function. The implemented system shows inference accuracy comparable to state-of-the-art facial emotion classifiers. Furthermore, the proposed design is carried out on a remote, cloud-based GPU platform using programming techniques developed specifically for the GPU devices (i.e., the CUDA language). As a result, the model training is significantly accelerated compared to being run on a traditional CPU. This also enables the system to be run in real time.
               Finally, a case study has been conducted to automatically understand patients' pain intensity levels using the proposed facial emotion recognition system. This framework, named “DeepPain”, correlates the pain intensity with the probabilities that the patient image falls into different facial emotion categories. In particular, two emotion probabilities, “fearful” and “sad”, are determined to be closely related to the pain intensity level, and used as the input to the DeepPain framework. Detecting and understanding pain intensity at a fine-grained level, as performed by DeepPain, will play a crucial role in healthcare.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bbe.2018.06.005,Journal,Biocybernetics and Biomedical Engineering,scopus,2018-01-01,sciencedirect,Continuous blood glucose level prediction of Type 1 Diabetes based on Artificial Neural Network,https://api.elsevier.com/content/abstract/scopus_id/85052992188,"Recent technological advancements in diabetes technologies, such as Continuous Glucose Monitoring (CGM) systems, provide reliable sources to blood glucose data. Following its development, a new challenging area in the field of artificial intelligence has been opened and an accurate prediction method of blood glucose levels has been targeted by scientific researchers. This article proposes a new method based on Artificial Neural Networks (ANN) for blood glucose level prediction of Type 1 Diabetes (T1D) using only CGM data as inputs. To show the efficiency of our method and to validate our ANN, real CGM data of 13 patients were investigated. The accuracy of the strategy is discussed based on some statistical criteria such as the Root Mean Square Error (RMSE) and the Mean Absolute Percentage Error (MAPE). The obtained averages of RMSE are 6.43 mg/dL, 7.45 mg/dL, 8.13 mg/dL and 9.03 mg/dL for Prediction Horizon (PH) respectively 15 min, 30 min, 45 min and 60 min and the average of MAPE was 3.87% for PH = 15 min, knowing that the smaller is the RMSE and MAPE, the more accurate is the prediction. Experimental results show that the proposed ANN is accurate, adaptive, and very encouraging for a clinical implementation. Furthermore, while other studies have only focused on the prediction accuracy of blood glucose, this work aims to improve the quality of life of T1D patients by using only CGM data as inputs and by limiting human intervention.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bbe.2018.08.002,Journal,Biocybernetics and Biomedical Engineering,scopus,2018-01-01,sciencedirect,Fast statistical model-based classification of epileptic EEG signals,https://api.elsevier.com/content/abstract/scopus_id/85052519495,"This paper presents a supervised classification method to accurately detect epileptic brain activity in real-time from electroencephalography (EEG) data. The proposed method has three main strengths: it has low computational cost, making it suitable for real-time implementation in EEG devices; it performs detection separately for each brain rhythm or EEG spectral band, following the current medical practices; and it can be trained with small datasets, which is key in clinical problems where there is limited annotated data available. This is in sharp contrast with modern approaches based on machine learning techniques, which achieve very high sensitivity and specificity but require large training sets with expert annotations that may not be available. The proposed method proceeds by first separating EEG signals into their five brain rhythms by using a wavelet filter bank. Each brain rhythm signal is then mapped to a low-dimensional manifold by using a generalized Gaussian statistical model; this dimensionality reduction step is computationally straightforward and greatly improves supervised classification performance in problems with little training data available. Finally, this is followed by parallel linear classifications on the statistical manifold to detect if the signals exhibit healthy or abnormal brain activity in each spectral band. The good performance of the proposed method is demonstrated with an application to paediatric neurology using 39 EEG recordings from the Children's Hospital Boston database, where it achieves an average sensitivity of 98%, specificity of 88%, and detection latency of 4s, performing similarly to the best approaches from the literature.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.04.060,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Real-time Driver Drowsiness Detection for Android Application Using Deep Neural Networks Techniques,https://api.elsevier.com/content/abstract/scopus_id/85051265901,"Road crashes and related forms of accidents are a common cause of injury and death among the human population. According to 2015 data from the World Health Organization, road traffic injuries resulted in approximately 1.25 million deaths worldwide, i.e. approximately every 25 seconds an individual will experience a fatal crash. While the cost of traffic accidents in Europe is estimated at around 160 billion Euros, driver drowsiness accounts for approximately 100,000 accidents per year in the United States alone as reported by The American National Highway Traffic Safety Administration (NHTSA). In this paper, a novel approach towards real-time drowsiness detection is proposed. This approach is based on a deep learning method that can be implemented on Android applications with high accuracy. The main contribution of this work is the compression of heavy baseline model to a lightweight model. Moreover, minimal network structure is designed based on facial landmark key point detection to recognize whether the driver is drowsy. The proposed model is able to achieve an accuracy of more than 80%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-444-64241-7.50368-2,Book Series,Computer Aided Chemical Engineering,scopus,2018-01-01,sciencedirect,States Identification of Complex Chemical Process Based on Unsupervised Learning,https://api.elsevier.com/content/abstract/scopus_id/85050586579,"States identification is an important step of process safety management, and it can be an individual part or a precursor step of fault detection and diagnosis (FDD). Research on FDD have made good progress, but most of them are carried out on labelled data, which is hard to collect in real situation. In this paper, an unsupervised learning based state identification model is proposed to deal with unlabelled data.
                  Feature extraction or dimensionality reduction, and clustering are two main steps of the model. t-SNE is an outstanding tool to visualize high-dimensional data, and a deep auto-encoder network is used to reduce the dimensionality to a reasonable amount before t-SNE is implemented. Different clustering algorithm are tested on features to determine which one is better. The unlabeled data are divided into different clusters by this model. In the final part of this paper, the benchmarked Tennessee Eastman process is utilized to illustrate the performance of this unsupervised learning based model.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.05.047,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,Analysis of Fuzzification Process in Fuzzy Expert System,https://api.elsevier.com/content/abstract/scopus_id/85049088318,"The fuzzy expert systems are oriented towards handling uncertain or imprecise information. The fuzzy expert system is used in the domains where the input variables do not have fixed values. The success of fuzzy system depends upon the selection of appropriate membership function. The paper presents the analysis of fuzzification process of Fuzzy expert systems implemented in the domains of health care, education, career selection, real estate and finance. The parameters used for analyzing the systems are the input factors, type of membership function used for fuzzification, de-fuzzification of fuzzy sets generated. Based on analysis of the fuzzy expert system, the paper presents recommendations for selecting appropriate membership function. At the end paper presents guidelines for fuzzification process which can be useful in creating Fuzzy Expert System.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2018.05.005,Conference Proceeding,Procedia Computer Science,scopus,2018-01-01,sciencedirect,An Innovative Approach for Investigation and Diagnosis of Lung Cancer by Utilizing Average Information Parameters,https://api.elsevier.com/content/abstract/scopus_id/85049073855,"In this paper, an Average Information based approach for lung cancer analysis and diagnosis has been proposed. Suggested methodology is established on average information parameters by utilizing image processing tools for lung cancer investigation. The real issue for the lung cancer diagnosis is the time constrictions for physical diagnosis that expands the death possibilities. Henceforth essentially proposed technique is an approach that would help the medical practitioners for precise and superior decision against the lung cancer discovery. Microscopic lung images are taken for analysis and investigation by using digital image processing with MATLAB. The statistical and mathematical parameters under statistical analysis are selected on the basis of the principle working of Average information technique. The input parameters like Entropy, Standard Deviation, Mean, Variance and MSE for average information method are implemented over a large microscopic lung image database. The individual statistical and mathematical parameter analysis with its impact on lung cancer images is successfully carried out and finally the accuracy, selectivity, and sensitivity of the proposed method is calculated by implementing the standard diagnostic test on the proposed method. This method also successfully rejects null hypothesis test by implementing one of the standard statistical methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ebiom.2017.11.032,Journal,EBioMedicine,scopus,2018-01-01,sciencedirect,Epileptic Seizure Prediction Using Big Data and Deep Learning: Toward a Mobile System,https://api.elsevier.com/content/abstract/scopus_id/85037980011,"Background
                  Seizure prediction can increase independence and allow preventative treatment for patients with epilepsy. We present a proof-of-concept for a seizure prediction system that is accurate, fully automated, patient-specific, and tunable to an individual's needs.
               
                  Methods
                  Intracranial electroencephalography (iEEG) data of ten patients obtained from a seizure advisory system were analyzed as part of a pseudoprospective seizure prediction study. First, a deep learning classifier was trained to distinguish between preictal and interictal signals. Second, classifier performance was tested on held-out iEEG data from all patients and benchmarked against the performance of a random predictor. Third, the prediction system was tuned so sensitivity or time in warning could be prioritized by the patient. Finally, a demonstration of the feasibility of deployment of the prediction system onto an ultra-low power neuromorphic chip for autonomous operation on a wearable device is provided.
               
                  Results
                  The prediction system achieved mean sensitivity of 69% and mean time in warning of 27%, significantly surpassing an equivalent random predictor for all patients by 42%.
               
                  Conclusion
                  This study demonstrates that deep learning in combination with neuromorphic hardware can provide the basis for a wearable, real-time, always-on, patient-specific seizure warning system with low power consumption and reliable long-term performance.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2017.10.004,Journal,Artificial Intelligence in Medicine,scopus,2018-01-01,sciencedirect,Development of an intelligent surgical training system for Thoracentesis,https://api.elsevier.com/content/abstract/scopus_id/85035010472,"Surgical training improves patient care, helps to reduce surgical risks, increases surgeon’s confidence, and thus enhances overall patient safety. Current surgical training systems are more focused on developing technical skills, e.g. dexterity, of the surgeons while lacking the aspects of context-awareness and intra-operative real-time guidance. Context-aware intelligent training systems interpret the current surgical situation and help surgeons to train on surgical tasks. As a prototypical scenario, we chose Thoracentesis procedure in this work. We designed the context-aware software framework using the surgical process model encompassing ontology and production rules, based on the procedure descriptions obtained through textbooks and interviews, and ontology-based and marker-based object recognition, where the system tracked and recognised surgical instruments and materials in surgeon’s hands and recognised surgical instruments on the surgical stand. The ontology was validated using annotated surgical videos, where the system identified “Anaesthesia” and “Aspiration” phase with 100% relative frequency and “Penetration” phase with 65% relative frequency. The system tracked surgical swab and 50mL syringe with approximately 88.23% and 100% accuracy in surgeon’s hands and recognised surgical instruments with approximately 90% accuracy on the surgical stand. Surgical workflow training with the proposed system showed equivalent results as the traditional mentor-based training regime, thus this work is a step forward a new tool for context awareness and decision-making during surgical training.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compeleceng.2017.03.009,Journal,Computers and Electrical Engineering,scopus,2018-01-01,sciencedirect,Applying spark based machine learning model on streaming big data for health status prediction,https://api.elsevier.com/content/abstract/scopus_id/85015331423,"Machine learning is one of the driving forces of science and commerce, but the proliferation of Big Data demands paradigm shifts from traditional methods in the application of machine learning techniques on this voluminous data having varying velocity. With the availability of large health care datasets and progressions in machine learning techniques, computers are now well equipped in diagnosing many health issues. This work aims at developing a real time remote health status prediction system built around open source Big Data processing engine, the Apache Spark, deployed in the cloud which focus on applying machine learning model on streaming Big Data. In this scalable system, the user tweets his health attributes and the application receives the same in real time, extracts the attributes and applies machine learning model to predict user's health status which is then directly messaged to him/her instantly for taking appropriate action.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2017.01.055,Journal,Applied Soft Computing Journal,scopus,2017-12-01,sciencedirect,An application of belief merging for the diagnosis of oral cancer,https://api.elsevier.com/content/abstract/scopus_id/85049212663,"Machine learning employs a variety of statistical, probabilistic, fuzzy and optimization techniques that allow computers to “learn” from examples and to detect hard-to-discern patterns from large, noisy or complex datasets. This capability is well-suited to medical applications, and machine learning techniques have been frequently used in cancer diagnosis and prognosis. In general, machine learning techniques usually work in two phases: training and testing. Some parameters, with regards to the underlying machine learning technique, must be tuned in the training phase in order to best “learn” from the dataset. On the other hand, belief merging operators integrate inconsistent information, which may come from different sources, into a unique consistent belief set (base). Implementations of merging operators do not require tuning any parameters apart from the number of sources and the number of topics to be merged. This research introduces a new manner to “learn” from past examples using a non parametrised technique: belief merging. The proposed method has been used for oral cancer diagnosis using a real-world medical dataset. The results allow us to affirm the possibility of training (merging) a dataset without having to tune the parameters. The best results give an accuracy of greater than 75%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.biosystems.2017.10.001,Journal,BioSystems,scopus,2017-12-01,sciencedirect,Towards a first implementation of the WLIMES approach in living system studies advancing the diagnostics and therapy in personalized medicine,https://api.elsevier.com/content/abstract/scopus_id/85033459793,"The goal of this paper is to advance an extensible theory of living systems using an approach to biomathematics and biocomputation that suitably addresses self-organized, self-referential and anticipatory systems with multi-temporal multi-agents. Our first step is to provide foundations for modelling of emergent and evolving dynamic multi-level organic complexes and their sustentative processes in artificial and natural life systems. Main applications are in life sciences, medicine, ecology and astrobiology, as well as robotics, industrial automation, man-machine interface and creative design. Since 2011 over 100 scientists from a number of disciplines have been exploring a substantial set of theoretical frameworks for a comprehensive theory of life known as Integral Biomathics. That effort identified the need for a robust core model of organisms as dynamic wholes, using advanced and adequately computable mathematics. The work described here for that core combines the advantages of a situation and context aware multivalent computational logic for active self-organizing networks, Wandering Logic Intelligence (WLI), and a multi-scale dynamic category theory, Memory Evolutive Systems (MES), hence WLIMES. This is presented to the modeller via a formal augmented reality language as a first step towards practical modelling and simulation of multi-level living systems. Initial work focuses on the design and implementation of this visual language and calculus (VLC) and its graphical user interface. The results will be integrated within the current methodology and practices of theoretical biology and (personalized) medicine to deepen and to enhance the holistic understanding of life.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.pmcj.2017.06.013,Journal,Pervasive and Mobile Computing,scopus,2017-12-01,sciencedirect,Using big data analytics to extract disease surveillance information from point of care diagnostic machines,https://api.elsevier.com/content/abstract/scopus_id/85024112744,"This paper explains a novel approach for knowledge discovery from data generated by Point of Care (POC) devices. A very important element of this type of knowledge extraction is that the POC generated data would never be identifiable, thereby protecting the rights and the anonymity of the individual, whilst still allowing for vital population-level evidence to be obtained. This paper also reveals a real-world implementation of the novel approach in a big data analytics system. Using Internet of Things (IoT) enabled POC devices and the big data analytics system, the data can be collected, stored, and analyzed in batch and real-time modes to provide a detailed picture of a healthcare system as well to identify high-risk populations and their locations. In addition, the system offers benefits to national health authorities in forms of optimized resource allocation (from allocating consumables to finding the best location for new labs) thus supports efficient and timely decision-making processes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2017.05.073,Journal,Expert Systems with Applications,scopus,2017-11-15,sciencedirect,Medical image analysis using wavelet transform and deep belief networks,https://api.elsevier.com/content/abstract/scopus_id/85019982802,"This paper introduces a three-step framework for classifying multiclass radiography images. The first step utilizes a de-noising technique based on wavelet transform (WT) and the statistical Kolmogorov Smirnov (KS) test to remove noise and insignificant features of the images. An unsupervised deep belief network (DBN) is designed for learning the unlabelled features in the second step. Although small-scale DBNs have demonstrated significant potential, the computational cost of training the restricted Boltzmann machine is a major issue when scaling to large networks. Moreover, noise in radiography images can cause a significant corruption of information that hinders the performance of DBNs. The combination of WT and KS test in the first step helps improve performance of DBNs. Discriminative feature subsets obtained in the first two steps serve as inputs into classifiers in the third step for evaluations. Five frequently used classifiers including naive Bayes, radial basis function network, random forest, sequential minimal optimization, and support vector machine and four different case studies are implemented for experiments using the Image Retrieval in Medical Application data set. The experimental results show that the three-step framework has significantly reduced computational cost and yielded a great performance for multiclass radiography image classification. Along with effective applications in image processing in other fields published in the literature, deep learning network in this paper has again demonstrated its robustness in handling a complex set of medical images. This implies that the proposed approach can be implemented in real practice for analysing noisy radiography images, which have many useful medical applications such as diagnosis of diseases related to lung, breast, musculoskeletal or pediatric studies.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enconman.2017.09.019,Journal,Energy Conversion and Management,scopus,2017-11-01,sciencedirect,An enhanced machine learning based approach for failures detection and diagnosis of PV systems,https://api.elsevier.com/content/abstract/scopus_id/85034076834,"In this paper, a novel procedure for fault detection and diagnosis in the direct current (DC) side of PV system, based on probabilistic neural network (PNN) classifier, is proposed. The suggested procedure consists of four main stages: (i) PV module parameters extraction, (ii) PV array simulation and experimental validation (iii) elaboration of a relevant database of both healthy and faulty operations, and (iv) network construction, training and testing. In the first stage, the unknown electrical parameters of the one diode model (ODM) are accurately identified using the best-so-far ABC algorithm. Then, based on these parameters the PV array is simulated and experimentally validated by using a PSIM™/Matlab™ co-simulation. Finally, efficient fault detection and diagnosis procedure based on PNN classifier is implemented. Four operating cases were tested in a grid connected PV system of 9.54kWp: Healthy system, three modules short-circuited in one string, ten modules short-circuited in one string, and a string disconnected from the array. Moreover, the PNN method was compared, under real operating conditions, with the feed forward back-propagation Artificial Neural Network (ANN) classifiers method, for noiseless and noisy data to evaluate the suggested method’s accuracy and test its aptitude to support noisy data. The obtained results have demonstrated the high efficiency of the proposed method to detect and diagnose DC side anomalies for both noiseless and noisy data cases.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2017.05.007,Journal,Journal of Virological Methods,scopus,2017-10-01,sciencedirect,Cost-effective HIV-1 virological monitoring in resource-limited settings using a modified commercially available qPCR RNA assay,https://api.elsevier.com/content/abstract/scopus_id/85021225686,"Virological monitoring through plasma viral load (PVL) quantification is essential for clinical management of HIV patients undergoing antiretroviral treatment (ART), and for detecting treatment failure. Quantitative PCR (qPCR)-based tests are the gold standard for measuring PVL. Largely because of their high cost, however, implementation of these tests in low- and middle-income countries fails to cover the testing demand. In this study, we aimed at reducing the running cost of the commercially available Abbott RealTime™ HIV-1 assay by minimizing the reagent consumption. To this end, a modified version of the assay was obtained by reducing the assay’s reagents volume to about a half, and validated using a panel of 104 plasma samples. Compared to the standard version, the modified Abbott assay allowed for a 50% reduction in running costs. At the same time, it showed a 100% concordance in identifying samples with detectable viral load, strong correlation (Pearson’s r
                     =0.983, P
                     <0.0001), and a high agreement between PVL values (mean percent difference between PVL values±standard deviation=0.76±3.18%). In detecting viral failure (PVL>1000copiesmL−1), the modified assay showed a sensitivity of 94.6%, a specificity of 93.8%, and a negative and positive predictive values of 93.8% and 94.6%, respectively. The modified assay therefore reliably quantifies PVL, predicts viral failure, and allows for a ca. 50% reduction in the assay’s running costs. It may thus be implemented as an ART monitoring tool in resource-limited settings and for research purposes.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2017.03.047,Journal,Biosensors and Bioelectronics,scopus,2017-08-15,sciencedirect,Multiplexed nanoplasmonic biosensor for one-step simultaneous detection of Chlamydia trachomatis and Neisseria gonorrhoeae in urine,https://api.elsevier.com/content/abstract/scopus_id/85016288582,"Development of rapid and multiplexed diagnostic tools is a top priority to address the current epidemic problem of sexually transmitted diseases. Here we introduce a novel nanoplasmonic biosensor for simultaneous detection of the two most common bacterial infections: Chlamydia trachomatis and Neisseria gonorrhoeae. Our plasmonic microarray is composed of gold nanohole sensor arrays that exhibit the extraordinary optical transmission (EOT), providing highly sensitive analysis in a label-free configuration. The integration in a microfluidic system and the precise immobilization of specific antibodies on the individual sensor arrays allow for selective detection and quantification of the bacteria in real-time. We achieved outstanding sensitivities for direct immunoassay of urine samples, with a limit of detection of 300 colony forming units (CFU)/mL for C. trachomatis and 1500CFU/mL for N. gonorrhoeae. The multiplexing capability of our biosensor was demonstrated by analyzing different urine samples spiked with either C. trachomatis or N. gonorrhoeae, and also containing both bacteria. We could successfully detect, identify and quantify the levels of the two bacteria in a one-step assay, without the need for DNA extraction or amplification techniques. This work opens up new possibilities for the implementation of point-of-care biosensors that enable fast, simple and efficient diagnosis of sexually transmitted infections.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2017.06.021,Journal,Journal of Biomedical Informatics,scopus,2017-08-01,sciencedirect,An ontology-based approach to patient follow-up assessment for continuous and personalized chronic disease management,https://api.elsevier.com/content/abstract/scopus_id/85021747974,"Objective
                  Chronic diseases are complex and persistent clinical conditions that require close collaboration among patients and health care providers in the implementation of long-term and integrated care programs. However, current solutions focus partially on intensive interventions at hospitals rather than on continuous and personalized chronic disease management. This study aims to fill this gap by providing computerized clinical decision support during follow-up assessments of chronically ill patients at home.
               
                  Methods
                  We proposed an ontology-based framework to integrate patient data, medical domain knowledge, and patient assessment criteria for chronic disease patient follow-up assessments. A clinical decision support system was developed to implement this framework for automatic selection and adaptation of standard assessment protocols to suit patient personal conditions. We evaluated our method in the case study of type 2 diabetic patient follow-up assessments.
               
                  Results
                  The proposed framework was instantiated using real data from 115,477 follow-up assessment records of 36,162 type 2 diabetic patients. Standard evaluation criteria were automatically selected and adapted to the particularities of each patient. Assessment results were generated as a general typing of patient overall condition and detailed scoring for each criterion, providing important indicators to the case manager about possible inappropriate judgments, in addition to raising patient awareness of their disease control outcomes. Using historical data as the gold standard, our system achieved a rate of accuracy of 99.93% and completeness of 95.00%.
               
                  Conclusions
                  This study contributes to improving the accessibility, efficiency and quality of current patient follow-up services. It also provides a generic approach to knowledge sharing and reuse for patient-centered chronic disease management.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ajog.2017.04.005,Journal,American Journal of Obstetrics and Gynecology,scopus,2017-08-01,sciencedirect,Can 3-dimensional power Doppler indices improve the prenatal diagnosis of a potentially morbidly adherent placenta in patients with placenta previa?,https://api.elsevier.com/content/abstract/scopus_id/85019170855,"Background
                  Traditionally, 2-dimensional ultrasound parameters have been used for the diagnosis of a suspected morbidly adherent placenta previa. More objective techniques have not been well studied yet.
               
                  Objective
                  The objective of the study was to determine the ability of prenatal 3-dimensional power Doppler analysis of flow and vascular indices to predict the morbidly adherent placenta objectively.
               
                  Study Design
                  A prospective cohort study was performed in women between 28 and 32 gestational weeks with known placenta previa. Patients underwent a two-dimensional gray-scale ultrasound that determined management decisions. 3-Dimensional power Doppler volumes were obtained during the same examination and vascular, flow, and vascular flow indices were calculated after manual tracing of the viewed placenta in the sweep; data were blinded to obstetricians. Morbidly adherent placenta was confirmed by histology. Severe morbidly adherent placenta was defined as increta/percreta on histology, blood loss >2000 mL, and >2 units of PRBC transfused. Sensitivities, specificities, predictive values, and likelihood ratios were calculated. Student t and χ2 tests, logistic regression, receiver-operating characteristic curves, and intra- and interrater agreements using Kappa statistics were performed.
               
                  Results
                  The following results were found: (1) 50 women were studied: 23 had morbidly adherent placenta, of which 12 (52.2%) were severe morbidly adherent placenta; (2) 2-dimensional parameters diagnosed morbidly adherent placenta with a sensitivity of 82.6% (95% confidence interval, 60.4–94.2), a specificity of 88.9% (95% confidence interval, 69.7–97.1), a positive predictive value of 86.3% (95% confidence interval, 64.0–96.4), a negative predictive value of 85.7% (95% confidence interval, 66.4–95.3), a positive likelihood ratio of 7.4 (95% confidence interval, 2.5–21.9), and a negative likelihood ratio of 0.2 (95% confidence interval, 0.08–0.48); (3) mean values of the vascular index (32.8 ± 7.4) and the vascular flow index (14.2 ± 3.8) were higher in morbidly adherent placenta (P < .001); (4) area under the receiver-operating characteristic curve for the vascular and vascular flow indices were 0.99 and 0.97, respectively; (5) the vascular index ≥21 predicted morbidly adherent placenta with a sensitivity and a specificity of 95% (95% confidence interval, 88.2–96.9) and 91%, respectively (95% confidence interval, 87.5–92.4), 92% positive predictive value (95% confidence interval, 85.5–94.3), 90% negative predictive value (95% confidence interval, 79.9–95.3), positive likelihood ratio of 10.55 (95% confidence interval, 7.06–12.75), and negative likelihood ratio of 0.05 (95% confidence interval, 0.03–0.13); and (6) for the severe morbidly adherent placenta, 2-dimensional ultrasound had a sensitivity of 33.3% (95% confidence interval, 11.3–64.6), a specificity of 81.8% (95% confidence interval, 47.8–96.8), a positive predictive value of 66.7% (95% confidence interval, 24.1–94.1), a negative predictive value of 52.9% (95% confidence interval, 28.5–76.1), a positive likelihood ratio of 1.83 (95% confidence interval, 0.41-8.11), and a negative likelihood ratio of 0.81 (95% confidence interval, 0.52–1.26). A vascular index ≥31 predicted the diagnosis of a severe morbidly adherent placenta with a 100% sensitivity (95% confidence interval, 72–100), a 90% specificity (95% confidence interval, 81.7–93.8), an 88% positive predictive value (95% confidence interval, 55.0–91.3), a 100% negative predictive value (95% confidence interval, 90.9–100), a positive likelihood ratio of 10.0 (95% confidence interval, 3.93–16.13), and a negative likelihood ratio of 0 (95% confidence interval, 0–0.34). Intrarater and interrater agreements were 94% (P < .001) and 93% (P < .001), respectively.
               
                  Conclusion
                  The vascular index accurately predicts the morbidly adherent placenta in patients with placenta previa. In addition, 3-dimensional power Doppler vascular and vascular flow indices were more predictive of severe cases of morbidly adherent placenta compared with 2-dimensional ultrasound. This objective technique may limit the variations in diagnosing morbidly adherent placenta because of the subjectivity of 2-dimensional ultrasound interpretations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2017.02.022,Journal,Expert Systems with Applications,scopus,2017-07-15,sciencedirect,Improvement of newborn screening using a fuzzy inference system,https://api.elsevier.com/content/abstract/scopus_id/85013790845,"This paper presents a decision support system (DSS) called DSScreening to rapidly detect inborn errors of metabolism (IEMs) in newborn screening (NS). The system has been created using the Aide-DS framework, which uses techniques imported from model-driven software engineering (MDSE) and soft computing, and it is available through eGuider, a web portal for the enactment of computerised clinical practice guidelines and protocols.
                  MDSE provides the context and techniques to build new software artefacts based on models which conform to a specific metamodel. It also offers separation of concern, to disassociate medical from technological knowledge, thus allowing changes in one domain without affecting the other. The changes might include, for instance, the addition of new disorders to the DSS or new measures to the computation related to a disorder. Artificial intelligence and soft computing provide fuzzy logic to manage uncertainty and ambiguous situations. Fuzzy logic is embedded in an inference system to build a fuzzy inference system (FIS); specifically, a single-input rule modules connected zero-order Takagi-Sugeno FIS. The automatic creation of FISs is performed by the Aide-DS framework, which is capable of embedding the generated FISs in computerized clinical guidelines. It can also create a desktop application to execute the FIS. Technologically, it supports the addition of new target languages for the desktop applications and the inclusion of new ways of acquiring data.
                  DSScreening has been tested by comparing its predictions with the results of 152 real analyses from two groups: (1) NS samples and (2) clinical samples belonging to individuals of all ages with symptoms that do not necessarily correspond to an IEM. The system has reduced the time needed by 98.7% when compared to the interpretation time spent by laboratory professionals. Besides, it has correctly classified 100% of the NS samples and obtained an accuracy of 70% for samples belonging to individuals with clinical symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.infsof.2017.03.003,Journal,Information and Software Technology,scopus,2017-07-01,sciencedirect,Uncertainty-wise evolution of test ready models,https://api.elsevier.com/content/abstract/scopus_id/85015382293,"Context
                  Cyber-Physical Systems (CPSs), when deployed for operation, are inherently prone to uncertainty. Considering their applications in critical domains (e.g., healthcare), it is important that such CPSs are tested sufficiently, with the explicit consideration of uncertainty. Model-based testing (MBT) involves creating test ready models capturing the expected behavior of a CPS and its operating environment. These test ready models are then used for generating executable test cases. It is, therefore, necessary to develop methods that can continuously evolve, based on real operational data collected during the operation of CPSs, test ready models and uncertainty captured in them, all together termed as Belief Test Ready Models (BMs)
               
                  Objective
                  Our objective is to propose a model evolution framework that can interactively improve the quality of BMs, based on operational data. Such BMs are developed by one or more test modelers (belief agents) with their assumptions about the expected behavior of a CPS, its expected physical environment, and potential future deployments. Thus, these models explicitly contain subjective uncertainty of the test modelers.
               
                  Method
                  We propose a framework (named as UncerTolve) for interactively evolving BMs (specified with extended UML notations) of CPSs with subjective uncertainty developed by test modelers. The key inputs of UncerTolve include initial BMs of CPSs with known subjective uncertainty and real data collected from the operation of CPSs. UncerTolve has three key features: 1) Validating the syntactic correctness and conformance of BMs against real operational data via model execution, 2) Evolving objective uncertainty measurements of BMs via model execution, and 3) Evolving state invariants (modeling test oracles) and guards of transitions (modeling constraints for test data generation) of BMs with a machine learning technique.
               
                  Results
                  As a proof-of-concept, we evaluated UncerTolve with one industrial CPS case study, i.e., GeoSports from the healthcare domain. Using UncerTolve, we managed to evolve 51% of belief elements, 18% of states, and 21% of transitions as compared to the initial BM developed in an industrial setting.
               
                  Conclusion
                  
                     UncerTolve can successfully evolve model elements of the initial BM, in addition to objective uncertainty measurements using real operational data. The evolved model can be used to generate additional test cases covering evolved model elements and objective uncertainty. These additional test cases can be used to test the current and future deployments of a CPS to ensure that it will handle uncertainty gracefully during its operations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ajo.2017.03.026,Journal,American Journal of Ophthalmology,scopus,2017-06-01,sciencedirect,Using Electronic Health Records to Build an Ophthalmologic Data Warehouse and Visualize Patients' Data,https://api.elsevier.com/content/abstract/scopus_id/85017447877,"Purpose
                  To develop a near-real-time data warehouse (DW) in an academic ophthalmologic center to gain scientific use of increasing digital data from electronic medical records (EMR) and diagnostic devices.
               
                  Design
                  Database development.
               
                  Methods
                  Specific macular clinic user interfaces within the institutional hospital information system were created. Orders for imaging modalities were sent by an EMR-linked picture-archiving and communications system to the respective devices. All data of 325 767 patients since 2002 were gathered in a DW running on an SQL database. A data discovery tool was developed. An exemplary search for patients with age-related macular degeneration, performed cataract surgery, and at least 10 intravitreal (excluding bevacizumab) injections was conducted.
               
                  Results
                  Data related to those patients (3 142 204 diagnoses [including diagnoses from other fields of medicine], 720 721 procedures [eg, surgery], and 45 416 intravitreal injections) were stored, including 81 274 optical coherence tomography measurements. A web-based browsing tool was successfully developed for data visualization and filtering data by several linked criteria, for example, minimum number of intravitreal injections of a specific drug and visual acuity interval. The exemplary search identified 450 patients with 516 eyes meeting all criteria.
               
                  Conclusions
                  A DW was successfully implemented in an ophthalmologic academic environment to support and facilitate research by using increasing EMR and measurement data. The identification of eligible patients for studies was simplified. In future, software for decision support can be developed based on the DW and its structured data. The improved classification of diseases and semiautomatic validation of data via machine learning are warranted.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2017.06.002,Journal,Artificial Intelligence in Medicine,scopus,2017-05-01,sciencedirect,Automatic detection of surgical haemorrhage using computer vision,https://api.elsevier.com/content/abstract/scopus_id/85020769333,"Background and objectives
                  On occasions, a surgical intervention can be associated with serious, potentially life-threatening complications. One of these complications is a haemorrhage during the operation, an unsolved issue that could delay the intervention or even cause the patient's death. On laparoscopic surgery this complication is even more dangerous, due to the limited vision and mobility imposed by the minimally invasive techniques.
               
                  Methods
                  In this paper it is described a computer vision algorithm designed to analyse the images captured by a laparoscopic camera, classifying the pixels of each frame in blood pixels and background pixels and finally detecting a massive haemorrhage. The pixel classification is carried out by comparing the parameter B/R and G/R of the RGB space colour of each pixel with a threshold obtained using the global average of the whole frame of these parameters. The detection of and starting haemorrhage is achieved by analysing the variation of the previous parameters and the amount of pixel blood classified.
               
                  Results
                  When classifying in vitro images, the proposed algorithm obtains accuracy over 96%, but during the analysis of an in vivo images obtained from real operations, the results worsen slightly due to poor illumination, visual interferences or sudden moves of the camera, obtaining accuracy over 88%. The detection of haemorrhages directly depends of the correct classification of blood pixels, so the analysis achieves an accuracy of 78%.
               
                  Conclusions
                  The proposed algorithm turns out to be a good starting point for an automatic detection of blood and bleeding in the surgical environment which can be applied to enhance the surgeon vision, for example showing the last frame previous to a massive haemorrhage where the incision could be seen using augmented reality capabilities.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2017.02.016,Journal,Computer Methods and Programs in Biomedicine,scopus,2017-05-01,sciencedirect,A study of EMR-based medical knowledge network and its applications,https://api.elsevier.com/content/abstract/scopus_id/85014111750,"Background and Objective
                  Electronic medical records (EMRs) contain an amount of medical knowledge which can be used for clinical decision support. We attempt to integrate this medical knowledge into a complex network, and then implement a diagnosis model based on this network.
               
                  Methods
                  The dataset of our study contains 992 records which are uniformly sampled from different departments of the hospital. In order to integrate the knowledge of these records, an EMR-based medical knowledge network (EMKN) is constructed. This network takes medical entities as nodes, and co-occurrence relationships between the two entities as edges. Selected properties of this network are analyzed. To make use of this network, a basic diagnosis model is implemented. Seven hundred records are randomly selected to re-construct the network, and the remaining 292 records are used as test records. The vector space model is applied to illustrate the relationships between diseases and symptoms. Because there may exist more than one actual disease in a record, the recall rate of the first ten results, and the average precision are adopted as evaluation measures.
               
                  Results
                  Compared with a random network of the same size, this network has a similar average length but a much higher clustering coefficient. Additionally, it can be observed that there are direct correlations between the community structure and the real department classes in the hospital. For the diagnosis model, the vector space model using disease as a base obtains the best result. At least one accurate disease can be obtained in 73.27% of the records in the first ten results.
               
                  Conclusion
                  We constructed an EMR-based medical knowledge network by extracting the medical entities. This network has the small-world and scale-free properties. Moreover, the community structure showed that entities in the same department have a tendency to be self-aggregated. Based on this network, a diagnosis model was proposed. This model uses only the symptoms as inputs and is not restricted to a specific disease. The experiments conducted demonstrated that EMKN is a simple and universal technique to integrate different medical knowledge from EMRs, and can be used for clinical decision support.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmsy.2017.02.011,Journal,Journal of Manufacturing Systems,scopus,2017-04-01,sciencedirect,A fog computing-based framework for process monitoring and prognosis in cyber-manufacturing,https://api.elsevier.com/content/abstract/scopus_id/85013912214,"Small- and medium-sized manufacturers, as well as large original equipment manufacturers (OEMs), have faced an increasing need for the development of intelligent manufacturing machines with affordable sensing technologies and data-driven intelligence. Existing monitoring systems and prognostics approaches are not capable of collecting the large volumes of real-time data or building large-scale predictive models that are essential to achieving significant advances in cyber-manufacturing. The objective of this paper is to introduce a new computational framework that enables remote real-time sensing, monitoring, and scalable high performance computing for diagnosis and prognosis. This framework utilizes wireless sensor networks, cloud computing, and machine learning. A proof-of-concept prototype is developed to demonstrate how the framework can enable manufacturers to monitor machine health conditions and generate predictive analytics. Experimental results are provided to demonstrate capabilities and utility of the framework such as how vibrations and energy consumption of pumps in a power plant and CNC machines in a factory floor can be monitored using a wireless sensor network. In addition, a machine learning algorithm, implemented on a public cloud, is used to predict tool wear in milling operations.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2016.11.037,Journal,Expert Systems with Applications,scopus,2017-04-01,sciencedirect,A framework for modelling the biomechanical behaviour of the human liver during breathing in real time using machine learning,https://api.elsevier.com/content/abstract/scopus_id/85002844460,"Progress in biomechanical modelling of human soft tissue is the basis for the development of new clinical applications capable of improving the diagnosis and treatment of some diseases (e.g. cancer), as well as the surgical planning and guidance of some interventions. The finite element method (FEM) is one of the most popular techniques used to predict the deformation of the human soft tissue due to its high accuracy. However, FEM has an associated high computational cost, which makes it difficult its integration in real-time computer-aided surgery systems. An alternative for simulating the mechanical behaviour of human organs in real time comes from the use of machine learning (ML) techniques, which are much faster than FEM. This paper assesses the feasibility of ML methods for modelling the biomechanical behaviour of the human liver during the breathing process, which is crucial for guiding surgeons during interventions where it is critical to track this deformation (e.g. some specific kind of biopsies) or for the accurate application of radiotherapy dose to liver tumours. For this purpose, different ML regression models were investigated, including three tree-based methods (decision trees, random forests and extremely randomised trees) and other two simpler regression techniques (dummy model and linear regression). In order to build and validate the ML models, a labelled data set was constructed from modelling the deformation of eight ex-vivo human livers using FEM. The best prediction performance was obtained using extremely randomised trees, with a mean error of 0.07 mm and all the samples with an error under 1 mm. The achieved results lay the foundation for the future development of some real-time software capable of simulating the human liver deformation during the breathing process during clinical interventions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2016.12.005,Journal,Journal of Biomedical Informatics,scopus,2017-02-01,sciencedirect,Accuracy of an automated knowledge base for identifying drug adverse reactions,https://api.elsevier.com/content/abstract/scopus_id/85008622502,"Introduction
                  Drug safety researchers seek to know the degree of certainty with which a particular drug is associated with an adverse drug reaction. There are different sources of information used in pharmacovigilance to identify, evaluate, and disseminate medical product safety evidence including spontaneous reports, published peer-reviewed literature, and product labels. Automated data processing and classification using these evidence sources can greatly reduce the manual curation currently required to develop reference sets of positive and negative controls (i.e. drugs that cause adverse drug events and those that do not) to be used in drug safety research.
               
                  Methods
                  In this paper we explore a method for automatically aggregating disparate sources of information together into a single repository, developing a predictive model to classify drug-adverse event relationships, and applying those predictions to a real world problem of identifying negative controls for statistical method calibration.
               
                  Results
                  Our results showed high predictive accuracy for the models combining all available evidence, with an area under the receiver-operator curve of ⩾0.92 when tested on three manually generated lists of drugs and conditions that are known to either have or not have an association with an adverse drug event.
               
                  Conclusions
                  Results from a pilot implementation of the method suggests that it is feasible to develop a scalable alternative to the time-and-resource-intensive, manual curation exercise previously applied to develop reference sets of positive and negative controls to be used in drug safety research.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.simpat.2016.08.007,Journal,Simulation Modelling Practice and Theory,scopus,2017-02-01,sciencedirect,Intelligent simulation: Integration of SIMIO and MATLAB to deploy decision support systems to simulation environment,https://api.elsevier.com/content/abstract/scopus_id/84996798684,"Discrete-event simulation is a decision support tool which enables practitioners to model and analyze their own system behavior. Although simulation packages are capable of mimicking most tasks in a real-world system, there are some decision-making activities, which are beyond the reach of simulation packages. The Application Programmers Interface (API) of SIMIO provides a wide range of opportunities for researchers to develop their own logic and apply it during the simulation run. This paper illustrates how to deploy MATLAB, as a computational tool coupled with SIMIO, as a simulation package by using a new user-defined step instance named “CallMATLAB”. A manufacturing system case study is introduced where the CallMATLAB step instance is used to create an Iterative Optimization-based Simulation (IOS) model. This model is created to evaluate the performance of different optimizers. The benefits of this hybridization for other industries, including healthcare systems, supply chain management systems, and project management problems are discussed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bspc.2016.10.005,Journal,Biomedical Signal Processing and Control,scopus,2017-02-01,sciencedirect,DSP-based arrhythmia classification using wavelet transform and probabilistic neural network,https://api.elsevier.com/content/abstract/scopus_id/84994005199,"A large part of the biomedical research spectrum is dedicated to develop electrocardiogram (ECG) signal processing techniques to contribute to early diagnosis. However, it is common to find that ECG analysis methods reported are confined to off-line PC host operation. The authors present an arrhythmia classification method implemented on a Digital Signal Processing (DSP) platform intended for on-line, real-time ambulatory operation to classify eight heartbeat conditions: normal sinus rhythm (N), auricular fibrillation (AF), premature atrial contraction (PAC), left bundle branch block (LBBB), right bundle branch block (RBBB), premature ventricular contraction (PVC), sinoauricular heart block (SHB) and supraventricular tachycardia (SVT). The algorithm uses a wavelet transform process based on quadratic wavelets for identifying individual ECG waves and obtain a fiducial marker array. Classification is conducted by means of a Probabilistic Neural Network. The algorithm is tested with 17 ECG records obtained from the PhysioNet repository. The proposed classification procedure was tested initially on MATLAB and the results where compared with the equivalent analogue data fed to a DSP-based ECG data acquisition prototype through an arbitrary waveform generator. The results derived from confusion matrix tests yielded on-line classification accuracy of 92.69% (AF), 97.15% (N), 76.82% (PAC), 91.06% (LBBB), 87.5% (RBBB), 71.04% (PVC), 91.94% (SHB) and 95.45% (SVT), overall classification rate of 92.746% and 100% agreement between the MATLAB and on-line DSP implementations. The results suggest that the method and prototype presented may be suitable for being implemented on wearable sensing applications auxiliary for on-line, real-time diagnosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-12-809859-2.00014-0,Book,Smart Sensors Networks: Communication Technologies and Intelligent Applications,scopus,2017-01-01,sciencedirect,Approaching Hardware Solutions for Massive E-Health Sensor Data Analysis,https://api.elsevier.com/content/abstract/scopus_id/85032163664,"The increase of life expectation and low birth rates have deeply impacted on the worldwide demographic structure. These changes impact on the public budgets and growing demands and expectations from citizens for higher quality services and social care. Several research efforts are devoted to provide alternatives to the traditional management of patients with innovative and not-intrusive systems to monitor in real-time the state and behavior of patients. Remote health monitoring systems can be used to monitor several vital parameters within a variety of ranges. These systems rely on heterogeneous data acquisition from sensors, video, historical and simulated data, performing inferences, and data elaboration in order to provide alternatives to the traditional management of patients. Depending on the functionalities to implement, the amount of data that has to be elaborated could represent the bottleneck of a monitoring system and it is critical in real-time applications. In this chapter we present a layered architecture infrastructure, based on two Decision Tree predictor hardware implementations, suitable for medical data analysis in real-time and aimed at dealing with a wide data volume and preserving a good hardware resources efficiency. We show how we improved the classification components and feature selection in order to achieve high-level throughput and high-level accuracy for the classification task of big data.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2017.07.167,Journal,Procedia Manufacturing,scopus,2017-01-01,sciencedirect,Towards Robust Early Stage Data Knowledge-based Inference Engine to Support Zero-defect Strategies in Manufacturing Environment,https://api.elsevier.com/content/abstract/scopus_id/85029884694,"Decision Support Systems are considered as a robust technology able to provide an advantage to several manufacturing companies. As part of the Z-Fact0r EU project, an autonomous and self-adjusted inference engine; namely the Early Stage-Decision Support System (ES-DSS) will be deployed. The scope is to facilitate real-time inspection, condition monitoring and control - diagnosis at the shop-floor, utilizing continuously mine multiple data streams and run the suitable models to monitor operations and quality performance, to classify products on the basis of quality metrics, as well to predict occurrence of defects and deviations from production and quality requirements.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.promfg.2017.07.091,Conference Proceeding,Procedia Manufacturing,scopus,2017-01-01,sciencedirect,Machine Learning-based CPS for Clustering High throughput Machining Cycle Conditions,https://api.elsevier.com/content/abstract/scopus_id/85023607399,"Cyber-physical systems (CPS) have opened up a wide range of opportunities in terms of performance analysis that can be applied directly to the machine tool industry and are useful for maintenance systems and machine designers. High-speed communication capabilities enable the data to be gathered, pre-processed and processed for the purpose of machine diagnosis. This paper describes a complete real-world CPS implementation cycle, ranging from machine data acquisition to processing and interpretation. In fact, the aim of this paper is to propose a CPS for machine component knowledge discovery based on clustering algorithms using real data from a machining process. Therefore, it compares three clustering algorithms –k-means, hierarchical agglomerative and Gaussian mixture models– in terms of their contribution to spindle performance knowledge during high throughput machining operation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2017.01.100,Conference Proceeding,Procedia Computer Science,scopus,2017-01-01,sciencedirect,Diagnosis of Neuro-physiological State of a Person on the Biomechanical Parameters,https://api.elsevier.com/content/abstract/scopus_id/85016028949,"In this paper described the algorithm for registering the spatial parameters of the locomotors apparatus of man based on the accelerometric goniometry method and the subsequent transformation of acceleration signals in the angular settings through specialized algorithms and phase-measurement method. Revealed correlations in the system of “musculoskeletal system - the nervous system.” Based on the established relationship of the dynamic activity of neurons in the brain and the implementation of motor actions, it was identified the main informative neurophysiological parameters, largely responsible for motor function.
                  Algorithms synchronous processing of the patient's measured dynamic parameters in real time. In the process of registering the parameters proposed to build a dynamic model of the patient and to carry out its correction with the expansion of the database of measurement. The resulting model, after processing of the neural network will be entered into the database models, creating statistics and providing a choice of optimal system performance parameters for a particular patient. With the help of neural network algorithms and decision support system based on a database of goniometric measurements, DB evoked potentials of brain and the database of diseases, determined an approximate diagnosis of the patient.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.oceaneng.2017.02.026,Journal,Ocean Engineering,scopus,2017-01-01,sciencedirect,A real-time strategy-decision program for sailing yacht races,https://api.elsevier.com/content/abstract/scopus_id/85014101158,"Optimal decisions for a skipper competing in a match race depend on a number of factors, including wind speed and direction variations, behaviour of the opponent, sea state, currents, racing rules. Expert sailors are able to combine observations on these various factors and process them to take optimal decisions. This study presents an attempt at emulating this decision process through a computer code that can be used in real time to advise on race strategy. The novelty of the proposed method consists in combining various approaches for the multiple factors affecting the decision process.
                  The wind variability is modelled with the use of neural networks, to produce a short-term wind forecast. The willingness of the sailor to risk is modelled using coherent-risk measures. Experimental results are used to quantify the loss of speed due to the presence of a nearby opponent. Finally, all these factors are combined through dynamic programming to compute an optimal course, based also on information on the current and yachts performance. The program is tested modelling the last 13 races of the 34th America's Cup, and results show that the route computed is close to the shortest possible route computed assuming perfect knowledge of sea conditions.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpowsour.2017.01.105,Journal,Journal of Power Sources,scopus,2017-01-01,sciencedirect,Adaptive prognosis of lithium-ion batteries based on the combination of particle filters and radial basis function neural networks,https://api.elsevier.com/content/abstract/scopus_id/85011392342,"Lithium-Ion rechargeable batteries are widespread power sources with applications to consumer electronics, electrical vehicles, unmanned aerial and spatial vehicles, etc. The failure to supply the required power levels may lead to severe safety and economical consequences. Thus, in view of the implementation of adequate maintenance strategies, the development of diagnostic and prognostic tools for monitoring the state of health of the batteries and predicting their remaining useful life is becoming a crucial task. Here, we propose a method for predicting the end of discharge of Li-Ion batteries, which stems from the combination of particle filters with radial basis function neural networks. The major innovation lies in the fact that the radial basis function model is adaptively trained on-line, i.e., its parameters are identified in real time by the particle filter as new observations of the battery terminal voltage become available. By doing so, the prognostic algorithm achieves the flexibility needed to provide sound end-of-discharge time predictions as the charge-discharge cycles progress, even in presence of anomalous behaviors due to failures or unforeseen operating conditions. The method is demonstrated with reference to actual Li-Ion battery discharge data contained in the prognostics data repository of the NASA Ames Research Center database.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/B978-0-444-63663-8.00026-4,Book,"Current Developments in Biotechnology and Bioengineering: Bioprocesses, Bioreactors and Controls",scopus,2017-01-01,sciencedirect,Real-Time Knowledge-Based Systems,https://api.elsevier.com/content/abstract/scopus_id/85010903357,"Knowledge-based systems can model a system, assess its performance, detect abnormalities in its operation, and make suggestions for its safe, stable, and optimal operation by capturing quantitative and heuristic information about a system and using rule-based reasoning to make inferences. A knowledge-based system can interface algorithms and quantitative information with heuristics and rules to yield a powerful environment that can accommodate nonlinearities, uncertainties in information, and rapid shifts in process operation. This chapter introduces knowledge-based and agent-based systems. The latter relies on distributed artificial intelligence and is well-suited for systems with distributed or discrete elements. Three applications are presented to illustrate the capabilities of knowledge-based and agent-based systems: supervision of penicillin fermentation systems, development of a distributed process supervision and fault diagnosis system, and modeling of a mammalian cell bioreactor.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.aap.2016.10.014,Journal,Accident Analysis and Prevention,scopus,2017-01-01,sciencedirect,Classifying injury narratives of large administrative databases for surveillance—A practical approach combining machine learning ensembles and human review,https://api.elsevier.com/content/abstract/scopus_id/84995615058,"Injury narratives are now available real time and include useful information for injury surveillance and prevention. However, manual classification of the cause or events leading to injury found in large batches of narratives, such as workers compensation claims databases, can be prohibitive. In this study we compare the utility of four machine learning algorithms (Naïve Bayes, Single word and Bi-gram models, Support Vector Machine and Logistic Regression) for classifying narratives into Bureau of Labor Statistics Occupational Injury and Illness event leading to injury classifications for a large workers compensation database. These algorithms are known to do well classifying narrative text and are fairly easy to implement with off-the-shelf software packages such as Python. We propose human-machine learning ensemble approaches which maximize the power and accuracy of the algorithms for machine-assigned codes and allow for strategic filtering of rare, emerging or ambiguous narratives for manual review. We compare human-machine approaches based on filtering on the prediction strength of the classifier vs. agreement between algorithms.
                  Regularized Logistic Regression (LR) was the best performing algorithm alone. Using this algorithm and filtering out the bottom 30% of predictions for manual review resulted in high accuracy (overall sensitivity/positive predictive value of 0.89) of the final machine-human coded dataset. The best pairings of algorithms included Naïve Bayes with Support Vector Machine whereby the triple ensemble NBSW
                     =NBBI-GRAM
                     =SVM had very high performance (0.93 overall sensitivity/positive predictive value and high accuracy (i.e. high sensitivity and positive predictive values)) across both large and small categories leaving 41% of the narratives for manual review. Integrating LR into this ensemble mix improved performance only slightly.
                  For large administrative datasets we propose incorporation of methods based on human-machine pairings such as we have done here, utilizing readily-available off-the-shelf machine learning techniques and resulting in only a fraction of narratives that require manual review. Human-machine ensemble methods are likely to improve performance over total manual coding.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.engappai.2016.10.015,Journal,Engineering Applications of Artificial Intelligence,scopus,2017-01-01,sciencedirect,Fault diagnosis of marine 4-stroke diesel engines using a one-vs-one extreme learning ensemble,https://api.elsevier.com/content/abstract/scopus_id/84994718316,"This paper proposes a novel approach for intelligent fault diagnosis for stroke Diesel marine engines, which are commonly used in on-road and marine transportation. The safety and reliability of a ship's work rely strongly on the performance of such an engine; therefore, early detection of any type of failure that affects the engine is of crucial importance. Automatic diagnostic systems are of special importance because they can operate continuously in real time, thereby providing efficient monitoring of the engine's performance. We introduce a fully automatic machine learning-based system for engine fault detection. For this purpose, we monitor various signals that are emitted by the engine, and we use them as an input for a pattern classification algorithm. This action is realized by an ensemble of Extreme Learning Machines that work in a decomposition mode. Because we address 14 different faults and a correct operation mode, we must handle a 15-class problem. We tackle this task by binarization in one-vs-one mode, where each Extreme Learning Machine is trained on a pair of classes. Next, Error-Correcting Output Codes are used to reconstruct the original multi-class task. The results from experiments that were conducted on a real-life dataset demonstrate that the proposed approach delivers superior classification accuracy and a low response time in comparison with a number of state-of-the-art methods and thus is a suitable choice for a real-life implementation on board a ship.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ahj.2016.10.001,Journal,American Heart Journal,scopus,2017-01-01,sciencedirect,Validation of an automated electronic algorithm and “dashboard” to identify and characterize decompensated heart failure admissions across a medical center,https://api.elsevier.com/content/abstract/scopus_id/84994479812,"Background
                  We aim to validate the diagnostic performance of the first fully automatic, electronic heart failure (HF) identification algorithm and evaluate the implementation of an HF Dashboard system with 2 components: real-time identification of decompensated HF admissions and accurate characterization of disease characteristics and medical therapy.
               
                  Methods
                  We constructed an HF identification algorithm requiring 3 of 4 identifiers: B-type natriuretic peptide >400 pg/mL; admitting HF diagnosis; history of HF International Classification of Disease, Ninth Revision, diagnosis codes; and intravenous diuretic administration. We validated the diagnostic accuracy of the components individually (n = 366) and combined in the HF algorithm (n = 150) compared with a blinded provider panel in 2 separate cohorts. We built an HF Dashboard within the electronic medical record characterizing the disease and medical therapies of HF admissions identified by the HF algorithm. We evaluated the HF Dashboard's performance over 26 months of clinical use.
               
                  Results
                  Individually, the algorithm components displayed variable sensitivity and specificity, respectively: B-type natriuretic peptide >400 pg/mL (89% and 87%); diuretic (80% and 92%); and International Classification of Disease, Ninth Revision, code (56% and 95%). The HF algorithm achieved a high specificity (95%), positive predictive value (82%), and negative predictive value (85%) but achieved limited sensitivity (56%) secondary to missing provider-generated identification data. The HF Dashboard identified and characterized 3147 HF admissions over 26 months.
               
                  Conclusions
                  Automated identification and characterization systems can be developed and used with a substantial degree of specificity for the diagnosis of decompensated HF, although sensitivity is limited by clinical data input.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.future.2016.03.019,Journal,Future Generation Computer Systems,scopus,2017-01-01,sciencedirect,An intelligent cloud-based data processing broker for mobile e-health multimedia applications,https://api.elsevier.com/content/abstract/scopus_id/84992311878,"Mobile e-health applications provide users and healthcare practitioners with an insightful way to check users/patients’ status and monitor their daily calorie intake. Mobile e-health applications provide users and healthcare practitioners with an insightful way to check users/patients’ status and monitor their daily activities. This paper proposes a cloud-based mobile e-health calorie system that can classify food objects in the plate and further compute the overall calorie of each food object with high accuracy. The novelty in our system is that we are not only offloading heavy computational functions of the system to the cloud, but also employing an intelligent cloud-broker mechanism to strategically and efficiently utilize cloud instances to provide accurate and improved time response results. The broker system uses a dynamic cloud allocation mechanism that takes decisions on allocating and de-allocating cloud instances in real-time for ensuring the average response time stays within a predefined threshold. In this paper, we further demonstrate various scenarios to explain the workflow of the cloud components including: segmentation, deep learning, indexing food images, decision making algorithms, calorie computation, scheduling management as part of the proposed cloud broker model. The implementation results of our system showed that the proposed cloud broker results in a 45% gain in the overall time taken to process the images in the cloud. With the use of dynamic cloud allocation mechanism, we were able to reduce the average time consumption by 77.21% when 60 images were processed in parallel.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2016.05.004,Journal,Computerized Medical Imaging and Graphics,scopus,2017-01-01,sciencedirect,Retinal vessel segmentation in colour fundus images using Extreme Learning Machine,https://api.elsevier.com/content/abstract/scopus_id/84973514428,"Attributes of the retinal vessel play important role in systemic conditions and ophthalmic diagnosis. In this paper, a supervised method based on Extreme Learning Machine (ELM) is proposed to segment retinal vessel. Firstly, a set of 39-D discriminative feature vectors, consisting of local features, morphological features, phase congruency, Hessian and divergence of vector fields, is extracted for each pixel of the fundus image. Then a matrix is constructed for pixel of the training set based on the feature vector and the manual labels, and acts as the input of the ELM classifier. The output of classifier is the binary retinal vascular segmentation. Finally, an optimization processing is implemented to remove the region less than 30 pixels which is isolated from the retinal vascilar. The experimental results testing on the public Digital Retinal Images for Vessel Extraction (DRIVE) database demonstrate that the proposed method is much faster than the other methods in segmenting the retinal vessels. Meanwhile the average accuracy, sensitivity, and specificity are 0.9607, 0.7140 and 0.9868, respectively. Moreover the proposed method exhibits high speed and robustness on a new Retinal Images for Screening (RIS) database. Therefore it has potential applications for real-time computer-aided diagnosis and disease screening.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2016.08.050,Journal,Neurocomputing,scopus,2016-12-19,sciencedirect,Multi-category EEG signal classification developing time-frequency texture features based Fisher Vector encoding method,https://api.elsevier.com/content/abstract/scopus_id/84994168897,"Classification of electroencephalogram (EEG) signals plays an important role in the diagnosis and treatment of brain diseases in the biomedical field. Here, we introduce a different multi-category EEG signal processing technique, namely time-frequency (T-F) image representation of Gray Level Co-occurrence Matrix (GLCM) descriptors and Fisher Vector (FV) encoding for automatic classification of EEG signals. Firstly the EEG signals are converted into T-F representation by using spectrograms of Short Time Fourier Transform (STFT), which are used to obtain the T-F images. The obtained T-F images are then converted into 8-bits gray-scale images and then are divided into five sub-images corresponding to the frequency-bands of the rhythms. Then, the GLCM texture descriptors are employed to extract distinctive features which are fed into the FV encoding. Finally obtained features are fed to extreme learning machine (ELM) classifier as input for identifying abnormalities from EEG signals. The proposed method was applied to epileptic and sleep stages EEG datasets. The experimental outcomes are promising on both databases. It can be anticipated that upon its implementation in real-time practice, the proposed scheme will assist the researchers and physicians to advance the existing methods for detecting neurological diseases from EEG signals.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.conctc.2016.05.002,Journal,Contemporary Clinical Trials Communications,scopus,2016-12-15,sciencedirect,"A multicenter, longitudinal, interventional, double blind randomized clinical trial in hematopoietic cell transplant recipients residing in remote areas: Lessons learned from the late cytomegalovirus prevention trial",https://api.elsevier.com/content/abstract/scopus_id/84979609750,"Purpose
                  The logistics of conducting double-blinded phase III clinical trials with participants residing in remote locations are complex. Here we describe the implementation of an interventional trial for the prevention of late cytomegalovirus (CMV) disease in hematopoietic cell transplantation (HCT) subjects in a long-term follow-up environment.
               
                  Methods
                  A total of 184 subjects at risk for late CMV disease surviving 80 days following allogeneic HCT were randomized to receive six months of valganciclovir or placebo. Subjects were followed through day 270 post-transplant at their local physician's office within the United States. Anti-viral treatment interventions were based on CMV DNAemia as measured by polymerase chain reaction (PCR) (>1000 copies/mL) and granulocyte colony stimulating factor (G-CSF) was prescribed for neutropenia (absolute neutrophil count (ANC < 1.0 × 109 cells/L). Blood samples for viral testing and safety monitoring were shipped to a central laboratory by overnight carrier. Real-time communication was established between the coordinating center and study sites, primary care physicians, and study participants to facilitate starting, stopping and dose adjustments of antiviral drugs and G-CSF. The time required to make these interventions was analyzed.
               
                  Results
                  Of the 4169 scheduled blood specimens, 3832 (92%) were received and analyzed; the majority (97%) arriving at the central site within 2 days. Among subjects with positive CMV DNAemia (N = 46), over 50% received open label antiviral medication within one day. The median time to start G-CSF for neutropenia was <1 day after posting of laboratory results (range 0–6; N = 38). Study drug dose adjustments for abnormal renal function were implemented 203 times; within one day for 48% of cases and within 2 days for 80% of cases.
               
                  Conclusion
                  Complex randomized, double-blind, multicenter interventional trials with treatment decisions made at a central coordinating site can be conducted safely and effectively according to Good Clinical Practice (GCP) guidelines over a large geographic area.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2016.10.006,Journal,Computers in Biology and Medicine,scopus,2016-12-01,sciencedirect,CAFÉ-Map: Context Aware Feature Mapping for mining high dimensional biomedical data,https://api.elsevier.com/content/abstract/scopus_id/84995610155,"Feature selection and ranking is of great importance in the analysis of biomedical data. In addition to reducing the number of features used in classification or other machine learning tasks, it allows us to extract meaningful biological and medical information from a machine learning model. Most existing approaches in this domain do not directly model the fact that the relative importance of features can be different in different regions of the feature space. In this work, we present a context aware feature ranking algorithm called CAFÉ-Map. CAFÉ-Map is a locally linear feature ranking framework that allows recognition of important features in any given region of the feature space or for any individual example. This allows for simultaneous classification and feature ranking in an interpretable manner. We have benchmarked CAFÉ-Map on a number of toy and real world biomedical data sets. Our comparative study with a number of published methods shows that CAFÉ-Map achieves better accuracies on these data sets. The top ranking features obtained through CAFÉ-Map in a gene profiling study correlate very well with the importance of different genes reported in the literature. Furthermore, CAFÉ-Map provides a more in-depth analysis of feature ranking at the level of individual examples.
                  
                     Availability: CAFÉ-Map Python code is available at:
                  
                     http://faculty.pieas.edu.pk/fayyaz/software.html#cafemap .
                  The CAFÉ-Map package supports parallelization and sparse data and provides example scripts for classification. This code can be used to reconstruct the results given in this paper.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ajog.2016.07.004,Journal,American Journal of Obstetrics and Gynecology,scopus,2016-12-01,sciencedirect,A dynamic quality assessment tool for laparoscopic hysterectomy to measure surgical outcomes,https://api.elsevier.com/content/abstract/scopus_id/84994106439,"Background
                  The current health care system has an urgent need for tools to measure quality. A wide range of quality indicators have been developed in an attempt to differentiate between high-quality and low-quality health care processes. However, one of the main issues of currently used indicators is the lack of case-mix correction and improvement possibilities. Case-mix is defined as specific (patient) characteristics that are known to potentially affect (surgical) outcome. If these characteristics are not taken into consideration, comparisons of outcome among health care providers may not be valid.
               
                  Objective
                  The objective of the study was to develop and test a quality assessment tool for laparoscopic hysterectomy, which can serve as a new outcome quality indicator.
               
                  Study Design
                  This is a prospective, international, multicenter implementation study. A web-based application was developed with 3 main goals: (1) to measure the surgeon’s performance using 3 primary outcomes (blood loss, operative time, and complications); (2) to provide immediate individual feedback using cumulative observed-minus-expected graphs; and (3) to detect consistently suboptimal performance after correcting for case-mix characteristics. All gynecologists who perform laparoscopic hysterectomies were requested to register their procedures in the application. A patient safety risk factor checklist was used by the surgeon for reflection. Thereafter a prospective implementation study was performed, and the application was tested using a survey that included the System Usability Scale.
               
                  Results
                  A total of 2066 laparoscopic hysterectomies were registered by 81 gynecologists. Mean operative time was 100 ± 39 minutes, blood loss 127 ± 163 mL, and the complication rate 6.1%. The overall survey response rate was 75%, and the mean System Usability Scale was 76.5 ± 13.6, which indicates that the application was good to excellent. The majority of surgeons reported that the application made them more aware of their performance, the outcomes, and patient safety, and they noted that the application provided motivation for improving future performance.
               
                  Conclusion
                  We report the development and test of a real-time, dynamic, quality assessment tool for measuring individual surgical outcome for laparoscopic hysterectomy. Importantly, this tool provides opportunities for improving surgical performance. Our study provides a foundation for helping clinicians develop evidence-based quality indicators for other surgical procedures.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.watres.2016.10.020,Journal,Water Research,scopus,2016-12-01,sciencedirect,Enhanced detection of pathogenic enteric viruses in coastal marine environment by concentration using methacrylate monolithic chromatographic supports paired with quantitative PCR,https://api.elsevier.com/content/abstract/scopus_id/84991227463,"Currently, around 50% of the world's population lives in towns and cities within 100 km of the coast. Monitoring of viruses that are frequently present in contaminated coastal environments, such as rotavirus (RoV) and norovirus (NoV), which are also the major cause of human viral gastroenteritis, is essential to ensure the safe use of these water bodies. Since exposure to as few as 10–100 particles of RoV or NoV may induce gastrointestinal disease, there is a need to develop a rapid and sensitive diagnostic method for their detection in coastal water samples. In this study, we evaluate the application of methacrylate monolithic chromatographic columns, commercially available as convective interaction media (CIM®), to concentrate pathogenic enteric viruses from saline water samples prior to virus quantification by one-step reverse transcription quantitative PCR (RT-qPCR). Using RoV and NoV as model enteric viruses, we present our results on the most effective viral concentration conditions from saline water matrices using butyl (C4) hydrophobic interaction monolithic support (CIM® C4). C4 monolithic columns exhibit a good capacity to bind both RoV and NoV and both viruses can be eluted in a single step. Our protocol using a 1 ml C4 column enables processing of 400 ml saline water samples in less than 60 min and increases the sensitivity of RoV and NoV detection by approximately 50-fold and 10-fold respectively. The protocol was also scaled up using larger capacity 8 ml C4 columns to process 4000 ml of seawater samples with concentration factors of 300-fold for RoV and 40-fold for NoV, without any significant increase in processing time. Furthermore, C4 monolithic columns were adapted for field use in an on-site application of RoV concentration from seawater samples with performance equivalent to that of the reference laboratory setup. Overall, the results from successful deployment of CIM C4 columns for concentration of rotavirus and norovirus in seawater samples reiterate the utility of monolithic supports as efficient, scalable and modular preparative tools for processing environmental water samples to enhance viral detection using molecular methods.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2016.09.015,Journal,Journal of Biomedical Informatics,scopus,2016-12-01,sciencedirect,Smart environment architecture for emotion detection and regulation,https://api.elsevier.com/content/abstract/scopus_id/84989166008,"This paper introduces an architecture as a proof-of-concept for emotion detection and regulation in smart health environments. The aim of the proposal is to detect the patient’s emotional state by analysing his/her physiological signals, facial expression and behaviour. Then, the system provides the best-tailored actions in the environment to regulate these emotions towards a positive mood when possible. The current state-of-the-art in emotion regulation through music and colour/light is implemented with the final goal of enhancing the quality of life and care of the subject. The paper describes the three main parts of the architecture, namely “Emotion Detection”, “Emotion Regulation” and “Emotion Feedback Control”. “Emotion Detection” works with the data captured from the patient, whereas “Emotion Regulation” offers him/her different musical pieces and colour/light settings. “Emotion Feedback Control” performs as a feedback control loop to assess the effect of emotion regulation over emotion detection. We are currently testing the overall architecture and the intervention in real environments to achieve our final goal.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jmoldx.2016.07.001,Journal,Journal of Molecular Diagnostics,scopus,2016-11-01,sciencedirect,CNV-RF Is a Random Forest–Based Copy Number Variation Detection Method Using Next-Generation Sequencing,https://api.elsevier.com/content/abstract/scopus_id/84992517622,"Simultaneous detection of small copy number variations (CNVs) (<0.5 kb) and single-nucleotide variants in clinically significant genes is of great interest for clinical laboratories. The analytical variability in next-generation sequencing (NGS) and artifacts in coverage data because of issues with mappability along with lack of robust bioinformatics tools for CNV detection have limited the utility of targeted NGS data to identify CNVs. We describe the development and implementation of a bioinformatics algorithm, copy number variation–random forest (CNV-RF), that incorporates a machine learning component to identify CNVs from targeted NGS data. Using CNV-RF, we identified 12 of 13 deletions in samples with known CNVs, two cases with duplications, and identified novel deletions in 22 additional cases. Furthermore, no CNVs were identified among 60 genes in 14 cases with normal copy number and no CNVs were identified in another 104 patients with clinical suspicion of CNVs. All positive deletions and duplications were confirmed using a quantitative PCR method. CNV-RF also detected heterozygous deletions and duplications with a specificity of 50% across 4813 genes. The ability of CNV-RF to detect clinically relevant CNVs with a high degree of sensitivity along with confirmation using a low-cost quantitative PCR method provides a framework for providing comprehensive NGS-based CNV/single-nucleotide variant detection in a clinical molecular diagnostics laboratory.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jviromet.2016.09.005,Journal,Journal of Virological Methods,scopus,2016-11-01,sciencedirect,Field evaluation of an open and polyvalent universal HIV-1/SIVcpz/SIVgor quantitative RT-PCR assay for HIV-1 viral load monitoring in comparison to Abbott RealTime HIV-1 in Cameroon,https://api.elsevier.com/content/abstract/scopus_id/84986893126,"With the increasing demand of HIV viral load (VL) tests in resource-limited countries (RLCs) there is a need for assays at affordable cost and able to quantify all known HIV-1 variants. VLs obtained with a recently developed open and polyvalent universal HIV-1/SIVcpz/SIVgor RT-qPCR were compared to Abbott RealTime HIV-1 assay in Cameroon. On 474 plasma samples, characterized by a wide range of VLs and a broad HIV-1 group M genetic diversity, 97.5% concordance was observed when using the lower detection limit of each assay. When using the threshold of 3.00 log10 copies/mL, according to WHO guidelines to define virological failure (VF) in RLCs, the concordance was 94.7%, 360/474 versus 339/474 patients were identified with VF with the new assay and Abbott RealTime HIV-1, respectively. Higher VLs were measured with the new assay, +0.47 log10 copies/mL (95% CI; 0.42-0.52) as shown with Bland-Altman analysis. Eleven samples from patients on VF with drug resistance were not detected by Abbott RealTime HIV-1 versus two only with the new assay. Overall, our study showed that the new assay can be easily implemented in a laboratory in RLCs with VL experience and showed good performance on a wide diversity of HIV-1 group M variants.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2016.08.066,Journal,Energy and Buildings,scopus,2016-10-15,sciencedirect,Development of an outdoor lighting control system using expert system,https://api.elsevier.com/content/abstract/scopus_id/84986587867,"In this study, an intelligent energy-efficient outdoor lighting control system was developed that could be used in green buildings as well as intelligent building functions, and contribute to the reduction of carbon dioxide emissions by using more conservation of electric energy and daylight more efficiently. The intelligent energy-efficient lighting control system was based on expert system is one of the artificial intelligence techniques and has four functions running in real-time. The first function is controlling and monitoring of the lamp groups. The other functions are fault diagnosis in lambs and power lines connected to the lamp groups and the load estimation of lamp groups. The expert system was written in two separate computer and microcontroller based environments by using knowledge-based rules.
                  The rule base of real-time control and monitoring function contains 213 rules. During the education semester operation mode which real-time control and monitoring function was implemented, an average of 33% conservation was achieved in energy consumption.
                  The system is the first expert system application in which an expert system is used to control and monitor outdoor lighting as well as perform load estimate and fault diagnosis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2016.07.002,Journal,Journal of the American Society of Echocardiography,scopus,2016-10-01,sciencedirect,Using Anatomic Intelligence to Localize Mitral Valve Prolapse on Three-Dimensional Echocardiography,https://api.elsevier.com/content/abstract/scopus_id/84994189345,"Background
                  Accurate localization of mitral valve prolapse (MVP) is crucial for surgical planning. Despite improved visualization of the mitral valve by three-dimensional transesophageal echocardiography, image interpretation remains expertise dependent. Manual construction of mitral valve topographic maps improves diagnostic accuracy but is time-consuming and requires substantial manual input. A novel computer-learning technique called Anatomical Intelligence in ultrasound (AIUS) semiautomatically tracks the annulus and leaflet anatomy for parametric analysis. The aims of this study were to examine whether AIUS could improve accuracy and efficiency in localizing MVP among operators with different levels of experience.
               
                  Methods
                  Two experts and four intermediate-level echocardiographers (nonexperts) retrospectively performed analysis of three-dimensional transesophageal echocardiographic images to generate topographic mitral valve models in 90 patients with degenerative MVP. All echocardiographers performed both AIUS and manual segmentation in sequential weekly sessions. The results were compared with surgical findings.
               
                  Results
                  Manual segmentation by nonexperts had significantly lower sensitivity (60% vs 90%, P < .001), specificity (91% vs 97%, P = .001), and accuracy (83% vs 95%, P < .001) compared with experts. AIUS significantly improved the accuracy of nonexperts (from 83% to 89%, P = .003), particularly for lesions involving the A3 (from 81% to 94%, P = .006) and P1 (from 78% to 88%, P = .001) segments, presumably related to anatomic variants of the annulus that made tracking more challenging. AIUS required significantly less time for image analysis by both experts (1.9 ± 0.7 vs 9.9 ± 3.5 min, P < .0001) and nonexperts (5.0 ± 0.5 vs 13 ± 1.5 min, P < .0001), especially for complex lesions.
               
                  Conclusions
                  Anatomic assessment of mitral valve pathology by three-dimensional transesophageal echocardiography is experience dependent. A semiautomated algorithm using AIUS improves accuracy and efficiency in localizing MVP by less experienced operators.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jpowsour.2016.05.092,Journal,Journal of Power Sources,scopus,2016-08-30,sciencedirect,Prognostics of Proton Exchange Membrane Fuel Cells stack using an ensemble of constraints based connectionist networks,https://api.elsevier.com/content/abstract/scopus_id/84975104897,"Proton Exchange Membrane Fuel Cell (PEMFC) is considered the most versatile among available fuel cell technologies, which qualify for diverse applications. However, the large-scale industrial deployment of PEMFCs is limited due to their short life span and high exploitation costs. Therefore, ensuring fuel cell service for a long duration is of vital importance, which has led to Prognostics and Health Management of fuel cells. More precisely, prognostics of PEMFC is major area of focus nowadays, which aims at identifying degradation of PEMFC stack at early stages and estimating its Remaining Useful Life (RUL) for life cycle management. This paper presents a data-driven approach for prognostics of PEMFC stack using an ensemble of constraint based Summation Wavelet- Extreme Learning Machine (SW-ELM) models. This development aim at improving the robustness and applicability of prognostics of PEMFC for an online application, with limited learning data. The proposed approach is applied to real data from two different PEMFC stacks and compared with ensembles of well known connectionist algorithms. The results comparison on long-term prognostics of both PEMFC stacks validates our proposition.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jnca.2016.03.014,Journal,Journal of Network and Computer Applications,scopus,2016-08-01,sciencedirect,An IoT-based mobile gateway for intelligent personal assistants on mobile health environments,https://api.elsevier.com/content/abstract/scopus_id/84992301649,"The evolution of mobile devices has triggered the appearance of intelligent personal assistants (IPAs). IPAs are software agents used to support users to fulfill several daily actions. They are supposed to be intelligent in such a way that allows them to give their owners advices about many different subjects. To do so, IPAs must learn about their user behavior and routines. With the current state of the art technologies, scenarios of ubiquitous communication can be created. One of the potential enablers for those scenarios is the Internet of Things (IoT) paradigm where machines with decision support systems interact and communicate among them. In an IoT environment, IPAs can interact with other smart objects in order to gain new knowledge and awareness about their users. This paper proposes a novel IoT-based mobile gateway solution for mobile health (m-Health) scenarios. This gateway autonomously collects information about the user/patient location, heart rate, and possible fall detection. Moreover, it forwards the collected information to a caretaker IPA, in real time, that will manage a set of actions and alarms appropriately. The algorithms used for each mobile gateway service, and the scenarios where the mobile gateway acts as a communication channel or a smart object are also addressed on this paper.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cviu.2016.03.018,Journal,Computer Vision and Image Understanding,scopus,2016-07-01,sciencedirect,"Wize Mirror-a smart, multisensory cardio-metabolic risk monitoring system",https://api.elsevier.com/content/abstract/scopus_id/84963813154,"In the recent years personal health monitoring systems have been gaining popularity, both as a result of the pull from the general population, keen to improve well-being and early detection of possibly serious health conditions and the push from the industry eager to translate the current significant progress in computer vision and machine learning into commercial products. One of such systems is the Wize Mirror, built as a result of the FP7 funded SEMEOTICONS (SEMEiotic Oriented Technology for Individuals CardiOmetabolic risk self-assessmeNt and Self-monitoring) project. The project aims to translate the semeiotic code of the human face into computational descriptors and measures, automatically extracted from videos, multispectral images, and 3D scans of the face. The multisensory platform, being developed as the result of that project, in the form of a smart mirror, looks for signs related to cardio-metabolic risks. The goal is to enable users to self-monitor their well-being status over time and improve their life-style via tailored user guidance. This paper is focused on the description of the part of that system, utilising computer vision and machine learning techniques to perform 3D morphological analysis of the face and recognition of psycho-somatic status both linked with cardio-metabolic risks. The paper describes the concepts, methods and the developed implementations as well as reports on the results obtained on both real and synthetic datasets.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ymssp.2015.12.023,Journal,Mechanical Systems and Signal Processing,scopus,2016-06-15,sciencedirect,"Advanced diagnostic system for piston slap faults in IC engines, based on the non-stationary characteristics of the vibration signals",https://api.elsevier.com/content/abstract/scopus_id/84954338770,"Artificial Neural Networks (ANNs) have the potential to solve the problem of automated diagnostics of piston slap faults, but the critical issue for the successful application of ANN is the training of the network by a large amount of data in various engine conditions (different speed/load conditions in normal condition, and with different locations/levels of faults). On the other hand, the latest simulation technology provides a useful alternative in that the effect of clearance changes may readily be explored without recourse to cutting metal, in order to create enough training data for the ANNs. In this paper, based on some existing simplified models of piston slap, an advanced multi-body dynamic simulation software was used to simulate piston slap faults with different speeds/loads and clearance conditions. Meanwhile, the simulation models were validated and updated by a series of experiments. Three-stage network systems are proposed to diagnose piston faults: fault detection, fault localisation and fault severity identification. Multi Layer Perceptron (MLP) networks were used in the detection stage and severity/prognosis stage and a Probabilistic Neural Network (PNN) was used to identify which cylinder has faults. Finally, it was demonstrated that the networks trained purely on simulated data can efficiently detect piston slap faults in real tests and identify the location and severity of the faults as well.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2016.03.017,Journal,Computers in Biology and Medicine,scopus,2016-05-01,sciencedirect,Edge density based automatic detection of inflammation in colonoscopy videos,https://api.elsevier.com/content/abstract/scopus_id/84962307591,"Colon cancer is one of the deadliest diseases where early detection can prolong life and can increase the survival rates. The early stage disease is typically associated with polyps and mucosa inflammation. The often used diagnostic tools rely on high quality videos obtained from colonoscopy or capsule endoscope. The state-of-the-art image processing techniques of video analysis for automatic detection of anomalies use statistical and neural network methods. In this paper, we investigated a simple alternative model-based approach using texture analysis. The method can easily be implemented in parallel processing mode for real-time applications. A characteristic texture of inflamed tissue is used to distinguish between inflammatory and healthy tissues, where an appropriate filter kernel was proposed and implemented to efficiently detect this specific texture. The basic method is further improved to eliminate the effect of blood vessels present in the lower part of the descending colon. Both approaches of the proposed method were described in detail and tested in two different computer experiments. Our results show that the inflammatory region can be detected in real-time with an accuracy of over 84%. Furthermore, the experimental study showed that it is possible to detect certain segments of video frames containing inflammations with the detection accuracy above 90%.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.puhe.2016.01.006,Journal,Public Health,scopus,2016-05-01,sciencedirect,ID-Viewer: A visual analytics architecture for infectious diseases surveillance and response management in Pakistan,https://api.elsevier.com/content/abstract/scopus_id/84957716366,"Objectives
                  Globally, disease surveillance systems are playing a significant role in outbreak detection and response management of Infectious Diseases (IDs). However, in developing countries like Pakistan, epidemic outbreaks are difficult to detect due to scarcity of public health data and absence of automated surveillance systems. Our research is intended to formulate an integrated service-oriented visual analytics architecture for ID surveillance, identify key constituents and set up a baseline for easy reproducibility of such systems in the future.
               
                  Study design
                  This research focuses on development of ID-Viewer, which is a visual analytics decision support system for ID surveillance. It is a blend of intelligent approaches to make use of real-time streaming data from Emergency Departments (EDs) for early outbreak detection, health care resource allocation and epidemic response management.
               
                  Methods
                  We have developed a robust service-oriented visual analytics architecture for ID surveillance, which provides automated mechanisms for ID data acquisition, outbreak detection and epidemic response management. Classification of chief-complaints is accomplished using dynamic classification module, which employs neural networks and fuzzy-logic to categorize syndromes. Standard routines by Center for Disease Control (CDC), i.e. c1-c3 (c1-mild, c2-medium and c3-ultra), and spatial scan statistics are employed for detection of temporal and spatio-temporal disease outbreaks respectively. Prediction of imminent disease threats is accomplished using support vector regression for early warnings and response planning. Geographical visual analytics displays are developed that allow interactive visualization of syndromic clusters, monitoring disease spread patterns, and identification of spatio-temporal risk zones.
               
                  Results
                  We analysed performance of surveillance framework using ID data for year 2011–2015. Dynamic syndromic classifier is able to classify chief-complaints to appropriate syndromes with high classification accuracy. Outbreak detection methods are able to detect the ID outbreaks in start of epidemic time zones. Prediction model is able to forecast dengue trend for 20 weeks ahead with nominal normalized root mean square error of 0.29. Interactive geo-spatiotemporal displays, i.e. heat-maps, and choropleth are shown in respective sections.
               
                  Conclusion
                  The proposed framework will set a standard and provide necessary details for future implementation of such a system for resource-constrained regions. It will improve early outbreak detection attributable to natural and man-made biological threats, monitor spatio-temporal epidemic trends and provide assurance that an outbreak has, or has not occurred. Advanced analytics features will be beneficial in timely organization/formulation of health management policies, disease control activities and efficient health care resource allocation.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2016.01.020,Journal,Knowledge-Based Systems,scopus,2016-04-15,sciencedirect,A fuzzy framework for encoding uncertainty in clinical decision-making,https://api.elsevier.com/content/abstract/scopus_id/84969358914,"In recent decades, technological advances coupled with research efforts have made possible to develop very complex Decision Support Systems (DSSs) able to exhibit highly sophisticated reasoning capabilities in order to improve clinical decision-making, and, thus, promote more efficient care practices. One of the most significant factors influencing, and in particular limiting, the adoption of clinical DSSs is represented by the modality of representation and computerization of clinical guidelines in form of patient-specific recommendations. Until now, many knowledge representation formalisms have been developed, mainly focused on time-oriented guidelines. However, they can generate an unrealistic over-simplification of reality, since they are not able to completely handle uncertainty and imprecision typically affecting clinical guidelines. In this respect, this paper proposes a novel fuzzy framework expressly thought for building guideline-based DSSs, by efficiently modelling and handling the peculiarities of clinical knowledge affected by uncertainty and imprecision and encoded in the form of guidelines. This framework has been devised with the aim of: (i) offering a set of patterns for easily inserting and editing clinical recommendations belonging to a guideline as a group of one or more fuzzy rules expressing positive evidence and one fuzzy ELSE rule including negative evidence; (ii) defining a set of Fuzzy Guideline Systems (FGSs), one for each guideline encoded, characterized by ad-hoc configurations for the mathematical operators necessary to evaluate rules and generate the outcome expected; (iii) implementing a multi-level inference scheme able to treat different FGSs as a whole and efficiently enable their interconnection, i.e. the chaining among the groups of fuzzy rules belonging to each FGS; (iv) exposing a set of graphical facilities for guiding the definition of fuzzy rules to be embedded into a clinical DSS and enabling their automatic encoding and execution by using an XML-based machine executable language. A usability evaluation has been performed, showing a good satisfaction of medical users with respect to the framework implemented, and, thus, proving both its feasibility and usefulness.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2016.01.005,Journal,Journal of Biomedical Informatics,scopus,2016-04-01,sciencedirect,Toward rapid learning in cancer treatment selection: An analytical engine for practice-based clinical data,https://api.elsevier.com/content/abstract/scopus_id/84962787234,"Objective
                  Wide-scale adoption of electronic medical records (EMRs) has created an unprecedented opportunity for the implementation of Rapid Learning Systems (RLSs) that leverage primary clinical data for real-time decision support. In cancer, where large variations among patient features leave gaps in traditional forms of medical evidence, the potential impact of a RLS is particularly promising. We developed the Melanoma Rapid Learning Utility (MRLU), a component of the RLS, providing an analytical engine and user interface that enables physicians to gain clinical insights by rapidly identifying and analyzing cohorts of patients similar to their own.
               
                  Materials and methods
                  A new approach for clinical decision support in Melanoma was developed and implemented, in which patient-centered cohorts are generated from practice-based evidence and used to power on-the-fly stratified survival analyses. A database to underlie the system was generated from clinical, pharmaceutical, and molecular data from 237 patients with metastatic melanoma from two academic medical centers. The system was assessed in two ways: (1) ability to rediscover known knowledge and (2) potential clinical utility and usability through a user study of 13 practicing oncologists.
               
                  Results
                  The MRLU enables physician-driven cohort selection and stratified survival analysis. The system successfully identified several known clinical trends in melanoma, including frequency of BRAF mutations, survival rate of patients with BRAF mutant tumors in response to BRAF inhibitor therapy, and sex-based trends in prevalence and survival. Surveyed physician users expressed great interest in using such on-the-fly evidence systems in practice (mean response from relevant survey questions 4.54/5.0), and generally found the MRLU in particular to be both useful (mean score 4.2/5.0) and useable (4.42/5.0).
               
                  Discussion
                  The MRLU is an RLS analytical engine and user interface for Melanoma treatment planning that presents design principles useful in building RLSs. Further research is necessary to evaluate when and how to best use this functionality within the EMR clinical workflow for guiding clinical decision making.
               
                  Conclusion
                  The MRLU is an important component in building a RLS for data driven precision medicine in Melanoma treatment that could be generalized to other clinical disorders.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.talanta.2015.12.056,Journal,Talanta,scopus,2016-04-01,sciencedirect,Analytical approach to determining human biogenic amines and their metabolites using eVol microextraction in packed syringe coupled to liquid chromatography mass spectrometry method with hydrophilic interaction chromatography column,https://api.elsevier.com/content/abstract/scopus_id/84961178246,"Analysis of biogenic amines (BAs) in different human samples provides insight into the mechanisms of various biological processes, including pathological conditions, and thus may be very important in diagnosing and monitoring several neurological disorders and cancerous tumors. In this work, we developed a simple and fast procedure using a digitally controlled microextraction in packed syringe (MEPS) coupled to liquid chromatography mass spectrometry (LC–MS) method for simultaneous determination of biogenic amines, their precursors and metabolites in human plasma and urine samples. The separation of 12 low molecular weight and hydrophilic molecules with a wide range of polarities was achieved with hydrophilic interaction chromatography (HILIC) column without derivatization step in 12min. MEPS was implemented using the APS sorbent in semi-automated analytical syringe (eVol®) and small volume of urine and plasma samples, 50µL and 100μL, respectively. We evaluated important parameters influencing MEPS efficiency, including stationary phase selection, sample pH and volume, number of extraction cycles, and washing and elution volumes. In optimized MEPS conditions, the analytes were eluted by 3×50μL of methanol with 0.1% formic acid. The chromatographic separation of analytes was performed on XBridge Amide™ BEH analytical column (3.0mm×100mm, 3.5µm) using gradient elution with mobile phase consisting of phase A: 10mM ammonium formate buffer in water pH 3.0 and phase B: 10mM ammonium formate buffer in acetonitrile pH 3.0. The LC–HILIC–MS method was validated and, in optimum conditions, presented good linearity in concentration range within 10–2000ng/mL for all the analytes with a determination coefficient (r
                     2) higher than 0.999 for plasma and urine samples. Method recovery ranged within 87.6–104.3% for plasma samples and 84.2–98.6% for urine samples. The developed method utilizing polar APS sorbent along with polar HILIC column was applied for simultaneous bioanalysis of trace amounts of polar endogenous biogenic amines in real human urine and plasma samples.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.dss.2016.02.005,Journal,Decision Support Systems,scopus,2016-04-01,sciencedirect,A case-based reasoning system for aiding detection and classification of nosocomial infections,https://api.elsevier.com/content/abstract/scopus_id/84959377705,"Nowadays, it is recognized worldwide that healthcare-associated infections are responsible for an increase in patient morbidity, mortality, and higher costs related to prolonged hospital stays. As electronic health data are increasingly available today, there is a unique opportunity to implement real-time decision support systems for automating the surveillance of healthcare-associated infections. As a consequence, different electronic surveillance systems have been implemented to date with varying degrees of success. However, there have been few instances in which clinical data and physician narratives with the potential to significantly improve electronic surveillance alternatives have been adopted. In this context, the present work introduces a case-based reasoning system for the automatic surveillance and diagnosis of healthcare-associated infections. The developed system makes use of different machine learning techniques in order to (i) automatically extract evidence from different types of data including clinical unstructured documents, (ii) incorporate static a priori knowledge handled by infection preventionists, and (iii) dynamically generate new knowledge as well as understandable explanations about the system's decisions. Results obtained from a real deployment in a public hospital belonging to the Spanish National Health System trained with 2569 samples belonging to 1800 patients during more than 10 consecutive months recognize the usefulness of the system.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2016.02.003,Journal,Journal of Biomedical Informatics,scopus,2016-04-01,sciencedirect,Modeling healthcare data using multiple-channel latent Dirichlet allocation,https://api.elsevier.com/content/abstract/scopus_id/84958981150,"Information and communications technologies have enabled healthcare institutions to accumulate large amounts of healthcare data that include diagnoses, medications, and additional contextual information such as patient demographics. To gain a better understanding of big healthcare data and to develop better data-driven clinical decision support systems, we propose a novel multiple-channel latent Dirichlet allocation (MCLDA) approach for modeling diagnoses, medications, and contextual information in healthcare data. The proposed MCLDA model assumes that a latent health status group structure is responsible for the observed co-occurrences among diagnoses, medications, and contextual information. Using a real-world research testbed that includes one million healthcare insurance claim records, we investigate the utility of MCLDA. Our empirical evaluation results suggest that MCLDA is capable of capturing the comorbidity structures and linking them with the distribution of medications. Moreover, MCLDA is able to identify the pairing between diagnoses and medications in a record based on the assigned latent groups. MCLDA can also be employed to predict missing medications or diagnoses given partial records. Our evaluation results also show that, in most cases, MCLDA outperforms alternative methods such as logistic regressions and the k-nearest-neighbor (KNN) model for two prediction tasks, i.e., medication and diagnosis prediction. Thus, MCLDA represents a promising approach to modeling healthcare data for clinical decision support.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucir.2016.02.001,Journal,Neurocirugia,scopus,2016-03-01,sciencedirect,Competency-based Neurosurgery Residency Programme,https://api.elsevier.com/content/abstract/scopus_id/84978322490,"Se presenta una propuesta de programa de formación en Neurocirugía basado en competencias y adaptado al marco del proyecto de Troncalidad. Esta propuesta ha sido elaborada por un grupo de neurocirujanos comisionados por la Sociedad Española de Neurocirugía (SENEC) y podría ser modificada para generar una versión definitiva que estaría operativa coincidiendo con implantación del sistema troncal. El presente escrito pretende facilitar el examen del nuevo programa adjuntado en la versión on-line de nuestra revista.
               
                  Duración del programa
                  El periodo total de formación es de 6 años; los 2 primeros se enmarcan en el tronco de Cirugía y los restantes 4 se adscriben al periodo específico.
               
                  Estructura del programa
                  Se trata de un programa basado en competencias referidas al mapa utilizado por el Accreditation Council for Graduate Medical Education (ACGME) en los EE. UU. que incluye los siguientes dominios competenciales: Conocimiento médico, Cuidado del paciente, Comunicación, Profesionalismo, Aprendizaje basado en la práctica y perfeccionamiento, Sistemas de Salud, Colaboración interprofesional y Desarrollo profesional y personal. El mapa de subcompetencias en los dominios de Conocimiento y Cuidado del paciente (incluidas las competencias quirúrgicas) se adaptó del propuesto por la AANS y el CNS (anexo 1 del programa). Se utiliza además un mapa de subcompetencias para las rotaciones troncales.
               
                  Métodos de instrucción
                  El aprendizaje del residente se basa en el estudio personal (autoaprendizaje) apoyado en el uso eficiente de las fuentes de información y una práctica clínica supervisada, incluyendo además la instrucción en bioética, gestión clínica, investigación y técnicas docentes
               
                  Métodos de evaluación
                  La propuesta de evaluación del residente incluye, entre otros instrumentos, test teóricos de conocimiento, evaluación objetiva y estructurada del nivel de competencia clínica con enfermo real o estandarizado, escalas globales de competencia, evaluación 360°, «audits» de registros clínicos, señalizadores del progreso del residente («milestones») y autoevaluación (anexo 2). Además, el residente evalúa periódicamente la dedicación docente de los neurocirujanos del servicio y otros docentes implicados en las rotaciones, y valora anualmente el funcionamiento global del programa. Los resultados de las evaluaciones se registran, junto con otros datos de interés, en el Libro del Residente.
               
                  Comité nacional de programa
                  Se propone la creación de un Comité de Programa adscrito directamente a la SENEC (Comisión Nacional) que, aparte de generar la versión definitiva del programa, se ocupe de monitorizar su implementación (nivel de adherencia al mismo y funcionamiento en los diferentes servicios), asuma la creación de bancos de preguntas y la administración centralizada de los test de conocimiento (en el ecuador de la residencia y/o al final de la misma) y centralice información recabada por los tutores que podría ser utilizada para la de reacreditación de los servicios.
               
                  A programme proposal for competency-based Neurosurgery training adapted to the specialization project is presented. This proposal has been developed by a group of neurosurgeons commissioned by the SENEC (Spanish Society of Neurosurgery) and could be modified to generate a final version that could come into force coinciding with the implementation of the specialization programme. This document aims to facilitate the test of the new programme included in the online version of our journal.
               
                  Duration of the programme
                  Total training period is 6 years; initial 2 years belong to the surgery specialization and remaining 4 years belong to core specialty period.
               
                  Structure of the programme
                  It is a competency-based programmed based on the map used by the US Accreditation Council for Graduate Medical Education (ACGME) including the following domains of clinical competency: Medical knowledge, patient care, communication skills, professionalism, practice-based learning and improvement, health systems, interprofessional collaboration and professional and personal development. Subcompetencies map in the domains of Knowledge and Patient care (including surgical competencies) was adapted to the one proposed by AANS and CNS (annex 1 of the programme). A subcompetency map was also used for the specialization rotations.
               
                  Instruction methods
                  Resident's training is based on personal study (self-learning) supported by efficient use of information sources and supervised clinical practice, including bioethical instruction, clinical management, research and learning techniques.
               
                  Evaluation methods
                  Resident evaluation proposal includes, among other instruments, theoretical knowledge tests, objective and structured evaluation of the level of clinical competency with real or standardised patients, global competency scales, 360-degree evaluation, clinical record audits, milestones for residents progress and self-assessment (annex 2). Besides, residents periodically assess the teaching commitment of the department's neurosurgeons and other professors participating in rotations, and annually assess the overall operation of the programme. Results of evaluations are registered, together with other relevant data, in the Resident's Book.
               
                  Programme's National Committee
                  The creation of a Programme Committee directly attached to the SENEC (National Commission) that, aside from generating a final version of the programme, monitors its implementation (level of adherence and operation in the different departments), assumes the creation of test banks and the centralized administration of knowledge tests (in the middle of the residency and/or at the end of it) and centralizes information collected by tutors that could be used for re-accreditation of the services, is proposed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2015.11.026,Journal,Neurocomputing,scopus,2016-02-12,sciencedirect,Digital implementations of thalamocortical neuron models and its application in thalamocortical control using FPGA for Parkinson's disease,https://api.elsevier.com/content/abstract/scopus_id/84959510221,"Due to the relay ability of sensory information and communication between cortical regions, the thalamocortical (TC) relay neuron plays an essential role in the therapy of Parkinson׳s disease. This paper first explores a series of efficient methods for the hardware implementation of TC relay neuron models, aiming to reproduce relevant biological behaviors and present appropriate feedback control in neural dynamics in thalamic systems. In addition, a modified two-dimensional TC neuron model is presented for convenient realization to decrease the complexity of the original model and promote the feasibility of the digital design, which shows significance for the large-scale network simulation of TC-based networks and the establishment of digital thalamus. A system-on-a-chip model-based control system is implemented on an FPGA using the modified TC neuron model, which is aimed at the real-time feedback control of tremor dominant Parkinsonian state. In this paper, the hardware syntheses and theoretical researches are given to illustrate the outstanding performance of the presented hardware implementation. The presented platform can be applied in both the brain-machine interface and the robotic control projects, and the proposed modular hardware framework can be extended to the real-time closed-loop treatments of other dyskinesia diseases.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2015.12.001,Journal,Artificial Intelligence in Medicine,scopus,2016-02-01,sciencedirect,SmartFABER: Recognizing fine-grained abnormal behaviors for early detection of mild cognitive impairment,https://api.elsevier.com/content/abstract/scopus_id/84994662260,"Objective
                  In an ageing world population more citizens are at risk of cognitive impairment, with negative consequences on their ability of independent living, quality of life and sustainability of healthcare systems. Cognitive neuroscience researchers have identified behavioral anomalies that are significant indicators of cognitive decline. A general goal is the design of innovative methods and tools for continuously monitoring the functional abilities of the seniors at risk and reporting the behavioral anomalies to the clinicians. SmartFABER is a pervasive system targeting this objective.
               
                  Methods
                  A non-intrusive sensor network continuously acquires data about the interaction of the senior with the home environment during daily activities. A novel hybrid statistical and knowledge-based technique is used to analyses this data and detect the behavioral anomalies, whose history is presented through a dashboard to the clinicians. Differently from related works, SmartFABER can detect abnormal behaviors at a fine-grained level.
               
                  Results
                  We have fully implemented the system and evaluated it using real datasets, partly generated by performing activities in a smart home laboratory, and partly acquired during several months of monitoring of the instrumented home of a senior diagnosed with MCI. Experimental results, including comparisons with other activity recognition techniques, show the effectiveness of SmartFABER in terms of recognition rates.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.apjtm.2016.01.006,Journal,Asian Pacific Journal of Tropical Medicine,scopus,2016-02-01,sciencedirect,Monitoring of renal ischemia reperfusion injury in rabbits by ultrasonic contrast and its relationship with expression of VEGF in renal tissue,https://api.elsevier.com/content/abstract/scopus_id/84959921599,"Objective
                  To evaluate the renal ischemia reperfusion injury (IRI) in rabbits using the ultrasonic contrast technique and discuss the clinical value of ultrasonic contrast technique in the diagnosis of renal IRI by comparing the time-intensity curve of renal cortex and the expression of vascular endothelial growth factor (VEGF) of renal tissue.
               
                  Methods
                  Twenty 3-month-old New Zealand rabbits were randomly divided into 4 groups, namely Ctrl group, IRI-12 h, IRI-24 h and IRI-48 h groups. The two dimensional gray-scale ultrasonography was employed to determine and mark the position of rabbit kidney. Rabbits were given the intraperitoneal anesthesia with 20% urethane with the dosage of 5 mL/kg. The aseptic operation was performed after the local skin disinfection in the area of both kidneys. The right kidney of animals in the control group was excised without any treatment for the left kidney. After excising the right kidney of animals in groups of IRI-12 h, IRI-24 h and IRI-48 h, the aneurysm clip was used to clip the renal pedicle vessel of left kidney, in order to simulate the ischemia. Because of the tissue ischemia, it could be seen that the color of kidney was changed from bright red to dark red, which indicated the successful modeling of ischemia. The aneurysm clip was released after one hour of maintaining the ischemia. Then the kidney turned out to be bright red from dark red, which indicated that the reperfusion was completed. Taking this moment as the time of ischemia reperfusion, the wound was stitched up. A total of 12, 24 and 36 h after the operation, the two-dimensional and color Doppler flow imaging and ultrasonic contrast were employed for the examination. The dynamic changes of ultrasonic contrast were recorded. The quantitative analysis software (QontraXt) was adopted to analyze the time-intensity curve of echo at different positions of renal cortex. After the ultrasonic contrast testing, rabbits were put to death. The renal cortex tissue was isolated and the tissue RNA and total protein were extracted respectively. Real-time PCR and western blotting were used to detect the VEGF and the Pearson product moment correlation coefficient was used to measure the linear relationship between these two variables.
               
                  Results
                  The ultrasonic contrast could clearly reflect the process of IRI. The results of testing at mRNA and protein level indicated that the expression of VEGF in IRI groups was significantly increased (P < 0.05) and the expression of VEGF was also increased by the time of reperfusion.
               
                  Conclusions
                  There is the certain correlation between the expression of VEGF and process of IRI. The correlation coefficient between the ultrasonic contrast parameters of AT and TTP and the relative expression of VEGF is over 0.9, which indicates the relatively high correlation. But there is no significant difference in the change of perfusion peak intensity between groups, which has no correlation with the expression of VEGF.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2015.08.015,Journal,Computers in Biology and Medicine,scopus,2016-02-01,sciencedirect,Real-time prediction of acute cardiovascular events using hardware-implemented Bayesian networks,https://api.elsevier.com/content/abstract/scopus_id/84957840284,"This paper presents a decision support system that aims to estimate a patient׳s general condition and detect situations which pose an immediate danger to the patient׳s health or life. The use of this system might be especially important in places such as accident and emergency departments or admission wards, where a small medical team has to take care of many patients in various general conditions. Particular stress is laid on cardiovascular and pulmonary conditions, including those leading to sudden cardiac arrest. The proposed system is a stand-alone microprocessor-based device that works in conjunction with a standard vital signs monitor, which provides input signals such as temperature, blood pressure, pulseoxymetry, ECG, and ICG. The signals are preprocessed and analysed by a set of artificial intelligence algorithms, the core of which is based on Bayesian networks. The paper focuses on the construction and evaluation of the Bayesian network, both its structure and numerical specification.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2016.11.160,Conference Proceeding,IFAC-PapersOnLine,scopus,2016-01-01,sciencedirect,Neural networks as a diagnosing tool for industrial level measurement through non-contacting radar type and support to the decision for its better application,https://api.elsevier.com/content/abstract/scopus_id/85006454620,"The aim of this study was to develop an analysis tool based on artificial neural networks (ANN) to detect level measurement problems with free wave propagation radars. The trend of using this type of radar has been growing in the last ten years mainly because of its easy installation on the top of tanks and reservoirs, and for its low rate maintenance comparing to other level measurement technologies. For the experiments, a Rosemount radar was used and the training of the neural network was based on the data from the software Radar Master. Therefore, some network topologies in different scenarios were tested and it was possible to demonstrate the efficiency of the ANN with accuracy rate between 94.44 to 100% for the first experiment with networks using 10, 20 or 50 neurons in the hidden layer. This technique was applied in a real industrial application, a sugar and ethanol mill, and accuracy rate was about 87,0 to 96,1%. This methodology can be applied to asset management software for diagnosis report or troubleshooting which would increase the level measurement reliability and plant safety.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/bs.host.2016.07.003,Book Series,Handbook of Statistics,scopus,2016-01-01,sciencedirect,Cognitive Systems for the Food–Water–Energy Nexus,https://api.elsevier.com/content/abstract/scopus_id/84994682733,"Providing for the food, water, and energy needs of a growing world population is a grand challenge. The way we choose to address this challenge as a society will have far-reaching impacts, for instance, on public health, national security, and the global climate. The interactions between the food, water, and energy systems offer us an opportunity to improve efficiency, but can also make the system more complex. Cognitive systems can help mitigate this complexity and thus improve efficiency.
                  What food, water, and energy have in common is that they are often not produced where they are consumed, they are costly to transport, and they are hard to store efficiently in large quantities. And this is where cognitive computing comes in: if you cannot store a resource you must have good forecasts of supply and demand. This requires handling large scale datasets from multiple sources, using machine learning methods to build forecasting models, and leveraging optimization techniques to help incorporate forecasting results into a decision-making process.
                  We will use energy as an example throughout the bulk of this chapter with the understanding that the same methods, challenges, and solutions can be applied more broadly to food, water, and other constrained resources.
                  
                     Sense: We will first discuss methods to make the most of sensor data. For example, it is expensive to deploy large networks of ground sensors (e.g., weather stations), and it is therefore beneficial to make use of sensors that can cover large areas, like radar or satellite images. However, it is challenging to estimate ground conditions based on satellite measurements alone. We will discuss machine learning algorithms that can learn the mapping from wide area sensor data to local conditions based on only a few ground-truth measurements. Applications include, for example, to estimate rainfall based on radar measurements, or to estimate solar power generation based on satellite images of clouds.
                  
                     Predict: Next, we will discuss forecasting methods ranging from a few minutes ahead to days or even years ahead. We will discuss forecasting methods for energy demand, solar energy generation, and wind generation. Different methods are effective for these different technologies as well as different forecasting horizons. Very short-range forecasts might use autoregressive models, while mid- to long-range forecasts may require physical models. We also discuss hybrid methods that combine expert knowledge with machine learning.
                  
                     React: Finally, we will discuss how to use the outputs of these analytics tools to serve decision-making processes. How optimization can help improve infrastructure planning and economic dispatch of power generation. And how cognitive systems can help system operators to make sense of messy data from multiple sources, provide recommended actions, and enable better decision making.
                  We will highlight several different mathematical methods, including autoregressive models, generalized additive models, fully connected neural networks, deep learning, convolutional neural networks, and nonlinear optimization in the context of energy. We will conclude the chapter with an outlook on how current trends in the cognitive computing will impact the broader challenge of managing constrained resources.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.proeng.2016.08.064,Conference Proceeding,Procedia Engineering,scopus,2016-01-01,sciencedirect,Primer for image informatics in personalized medicine,https://api.elsevier.com/content/abstract/scopus_id/84993990077,"Image informatics encompasses the concept of extracting and quantifying information contained in image data. Scenes, what an image contains, come from many imager devices such as consumer electronics, medical imaging systems, 3D laser scanners, microscopes, or satellites. There is a marked increase in image informatics applications as there have been simultaneous advances in imaging platforms, data availability due to social media, and big data analytics. An area ready to take advantage of these developments is personalized medicine, the concept where the goal is tailor healthcare to the individual. Patient health data is computationally profiled against a large of pool of feature-rich data from other patients to ideally optimize how a physician chooses care. One of the daunting challenges is how to effectively utilize medical image data in personalized medicine. Reliable data analytics products require as much automation as possible, which is a difficulty for data like histopathology and radiology images because we require highly trained expert physicians to interpret the information. This review targets biomedical scientists interested in getting started on tackling image analytics. We present high level discussions of sample preparation and image acquisition; data formats; storage and databases; image processing; computer vision and machine learning; and visualization and interactive programming. Examples will be covered using existing open-source software tools such as ImageJ, CellProfiler, and IPython Notebook. We discuss how difficult real-world challenges faced by image informatics and personalized medicine are being tackled with open-source biomedical data and software.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2016.09.042,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,"Capturing, Annotating and Processing Practical Knowledge by Using Decision Trees",https://api.elsevier.com/content/abstract/scopus_id/84992428461,"Practical knowledge describes the knowledge resulted from experience of a person. Capturing and processing practical knowledge is usually difficult, because it is only available in a persons head. However, this knowledge would help inexperienced persons to obtain practical knowledge in a fast way. Approaches so far have only considered how already formalized knowledge can be shared and integrated across different systems. However, capturing and formalizing practical knowledge and working around with incomplete data have not yet been considered. To address this problem we 1.) developed an open-source extension for Semantic MediaWiki that supports the graphical modeling of practical knowledge; 2.) enable to enrich the formalized practical knowledge with semantics from ontologies and knowledge graphs with references to external data sources and rules and 3.) present a technical infrastructure to automatically execute the created decision trees and thus to retrieve recommendations of the practical knowledge in real-time.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2016.09.052,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,Designing and Testing HealthTracker for Activity Recognition and Energy Expenditure Estimation within the DAPHNE Platform,https://api.elsevier.com/content/abstract/scopus_id/84992317444,"This paper describes the design and evaluation of a mobile software library, HealthTracker, which aims to produce activity and energy expenditure estimations in real-time from accelerometer and gyroscope data provided by wearable sensors. Using feature extraction together with a classifier trained using machine learning, the system will automatically and periodically send all the produced estimations to a cloud-based platform that will allow later evaluation by both the user and a physician or caretaker. The system is presented within the DAPHNE platform, an ICT ecosystem designed to provide a means for remote health and lifestyle monitoring and guidance between physicians and their patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2016.09.045,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,Improving the Utilization of AAL Devices through Semantic Web Technologies and Web of Things Concepts,https://api.elsevier.com/content/abstract/scopus_id/84992315819,"The software-driven assistance of elderly and impaired people in their every day life requires the integration of heterogeneous devices and assistive services. The lack of interoperability hampers the integration and usage of these devices and services. Furthermore, one objective in the field of Ambient Intelligence and Human Machine Interaction is the adaption of assistive services to the user 5. This is deeply rooted in the idea that the usage of ambient technologies still means a barrier for elderly and impaired people and prevents them to trust and use these technologies. But as these technologies aim at supporting and not restricting elderly and impaired people, a methodology is needed to overcome the barrier of using ambient assistive technologies. In this paper, we present an approach to a) enable a simplified integration of heterogeneous devices and services by the Web of Things recommendation and b) a lightweight AAL ontology together with a rule-based engine called Sherlock in order to demonstrate the advantages in representing and linking user intentions to device capabilities using Semantic Web technologies. Moreover, we show how this semantic representation in the context-aware Sherlock engine is used to derive user intentions by recognising device events. The practical applicability of the presented approach is demonstrated in a real-world use case from the AICASys project
                        1
                     .
                        1
                        See: http://www.mtidw.de/ueberblick-bekanntmachungen/ALS/aicasys",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2016.07.343,Conference Proceeding,Procedia Computer Science,scopus,2016-01-01,sciencedirect,A Neuro-fuzzy Based Model for Analysis of an ECG Signal Using Wavelet Packet Tree,https://api.elsevier.com/content/abstract/scopus_id/84983455757,"Detection and classification of electrocardiogram (ECG) signals are critically linked to the diagnosis abnormalities. Any abnormality in the wave shape and duration of the wave features of the ECG is considered as arrhythmia. This paper presents a diagnostic system for classification of cardiac arrhythmia from ECG data, using hybrid model of Artificial Neural Network and Fuzzy Logic. In an ECG, clinically useful information is obtained from the intervals and amplitudes of the cardiac waves. In an ECG, the non-stationary signal commonly changed its statistical property with time. In the proposed paper an algorithm based on wavelet packet tree classifier (for detection of QRS complex) has been implemented for the comparative study of automatic real-time ECG data. The amplitude and duration of the characteristic waves of the ECG can be more accurately obtained using Wavelet Packet Tree (WPT) analysis. WPT techniques have been employed to extract a set of linear (time and frequency domain) characteristics. Neuro-fuzzy techniques have been employed to extract a set of non-linear characteristic features from the transformed ECG signals. The real-time signals are obtained from various diagnostic centers. The hybrid model of Wavelet Packet Tree and Neuro-fuzzy network is proposed for the analysis and comparative study of an ECG signal.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2015.02.090,Journal,Neurocomputing,scopus,2015-12-25,sciencedirect,A framework for classification of non-linear loads in smart grids using Artificial Neural Networks and Multi-Agent Systems,https://api.elsevier.com/content/abstract/scopus_id/84940614843,"This paper proposes a general framework that uses the Artificial Neural Networks (ANNs) as a classification tool of nonlinear loads in a simulated smart grid environment by using Multi-Agent Systems (MAS). The increasing of communication and computation infrastructure on devices installed on modern power distribution systems allows new automated and coordinated control actions. This is mainly due to the ability to manage and process information and deploy actions in real-time mode. One important measurement tool is the smart meter, which will be present with all customers. Besides the measurement function, it has the communication feature and also some computational processing capability. Considering this base structure, the objective is to present methods to classify/identify nonlinear loads based only on current or voltage profiles measured by smart meters in this distributed computing environment. In this work, the MAS will manage the data and the tasks related to the classification and the ANN will perform the classification, both tools have been developed in JADE/JAVA and Matlab environment, respectively. Test case using 4000 input signals distributed in eight classes corresponding to nonlinear medical electromedical loads have been used and 98.7% of the samples have been identified correctly.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compmedimag.2015.09.005,Journal,Computerized Medical Imaging and Graphics,scopus,2015-12-01,sciencedirect,Telemedicine as a special case of machine translation,https://api.elsevier.com/content/abstract/scopus_id/84983187666,"Machine translation is evolving quite rapidly in terms of quality. Nowadays, we have several machine translation systems available in the web, which provide reasonable translations. However, these systems are not perfect, and their quality may decrease in some specific domains. This paper examines the effects of different training methods when it comes to Polish–English Statistical Machine Translation system used for the medical data. Numerous elements of the EMEA parallel text corpora and not related OPUS Open Subtitles project were used as the ground for creation of phrase tables and different language models including the development, tuning and testing of these translation systems. The BLEU, NIST, METEOR, and TER metrics have been used in order to evaluate the results of various systems. Our experiments deal with the systems that include POS tagging, factored phrase models, hierarchical models, syntactic taggers, and other alignment methods. We also executed a deep analysis of Polish data as preparatory work before automatized data processing such as true casing or punctuation normalization phase. Normalized metrics was used to compare results. Scores lower than 15% mean that Machine Translation engine is unable to provide satisfying quality, scores greater than 30% mean that translations should be understandable without problems and scores over 50 reflect adequate translations. The average results of Polish to English translations scores for BLEU, NIST, METEOR, and TER were relatively high and ranged from 7058 to 8272. The lowest score was 6438. The average results ranges for English to Polish translations were little lower (6758–7897). The real-life implementations of presented high quality Machine Translation Systems are anticipated in general medical practice and telemedicine.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.egypro.2015.12.072,Conference Proceeding,Energy Procedia,scopus,2015-12-01,sciencedirect,Validation of neural network-based fault diagnosis for multi-stack fuel cell systems: Stack voltage deviation detection,https://api.elsevier.com/content/abstract/scopus_id/84961825697,"This paper presents (i) an algorithm for the detection of unexpected stack voltage deviations in an Solid Oxide Fuel Cells (SOFC)-based power system with multiple stacks and (ii) its validation in a simulated online environment. The algorithm is based on recurrent neural networks (RNNs) and is validated by using operating data from the Wärtsilä WFC20 multi-stack SOFC system. The voltage deviation detection is based on statistical testing. Instead of a hardware implementation in the actual power plant, the algorithm is validated in a simulated online environment that provides data I/O communication based on the OPC (i.e. Object Linking and Embedding (OLE) for Process Control) protocol, which is also the technology utilized in the real hardware environment. The validation tests show that the RNN-based algorithm effectively detects unwanted stack voltage deviations and also that it is online-viable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2015.08.003,Journal,Artificial Intelligence in Medicine,scopus,2015-11-01,sciencedirect,A fuzzy-ontology-oriented case-based reasoning framework for semantic diabetes diagnosis,https://api.elsevier.com/content/abstract/scopus_id/84983487369,"Objective
                  Case-based reasoning (CBR) is a problem-solving paradigm that uses past knowledge to interpret or solve new problems. It is suitable for experience-based and theory-less problems. Building a semantically intelligent CBR that mimic the expert thinking can solve many problems especially medical ones.
               
                  Methods
                  Knowledge-intensive CBR using formal ontologies is an evolvement of this paradigm. Ontologies can be used for case representation and storage, and it can be used as a background knowledge. Using standard medical ontologies, such as SNOMED CT, enhances the interoperability and integration with the health care systems. Moreover, utilizing vague or imprecise knowledge further improves the CBR semantic effectiveness. This paper proposes a fuzzy ontology-based CBR framework. It proposes a fuzzy case-base OWL2 ontology, and a fuzzy semantic retrieval algorithm that handles many feature types.
               
                  Material
                  This framework is implemented and tested on the diabetes diagnosis problem. The fuzzy ontology is populated with 60 real diabetic cases. The effectiveness of the proposed approach is illustrated with a set of experiments and case studies.
               
                  Results
                  The resulting system can answer complex medical queries related to semantic understanding of medical concepts and handling of vague terms. The resulting fuzzy case-base ontology has 63 concepts, 54 (fuzzy) object properties, 138 (fuzzy) datatype properties, 105 fuzzy datatypes, and 2640 instances. The system achieves an accuracy of 97.67%. We compare our framework with existing CBR systems and a set of five machine-learning classifiers; our system outperforms all of these systems.
               
                  Conclusion
                  Building an integrated CBR system can improve its performance. Representing CBR knowledge using the fuzzy ontology and building a case retrieval algorithm that treats different features differently improves the accuracy of the resulting systems.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.compbiomed.2015.07.015,Journal,Computers in Biology and Medicine,scopus,2015-11-01,sciencedirect,"Implementation of a web based universal exchange and inference language for medicine: Sparse data, probabilities and inference in data mining of clinical data repositories",https://api.elsevier.com/content/abstract/scopus_id/84941884468,"We extend Q-UEL, our universal exchange language for interoperability and inference in healthcare and biomedicine, to the more traditional fields of public health surveys. These are the type associated with screening, epidemiological and cross-sectional studies, and cohort studies in some cases similar to clinical trials. There is the challenge that there is some degree of split between frequentist notions of probability as (a) classical measures based only on the idea of counting and proportion and on classical biostatistics as used in the above conservative disciplines, and (b) more subjectivist notions of uncertainty, belief, reliability, or confidence often used in automated inference and decision support systems. Samples in the above kind of public health survey are typically small compared with our earlier “Big Data” mining efforts. An issue addressed here is how much impact on decisions should sparse data have. We describe a new Q-UEL compatible toolkit including a data analytics application DiracMiner that also delivers more standard biostatistical results, DiracBuilder that uses its output to build Hyperbolic Dirac Nets (HDN) for decision support, and HDNcoherer that ensures that probabilities are mutually consistent. Use is exemplified by participating in a real word health-screening project, and also by deployment in a industrial platform called the BioIngine, a cognitive computing platform for health management.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.micpro.2015.07.013,Journal,Microprocessors and Microsystems,scopus,2015-10-29,sciencedirect,ARM-based arrhythmia beat monitoring system,https://api.elsevier.com/content/abstract/scopus_id/84940459857,"This paper aims for accurate diagnosis of arrhythmia beats in real time to enhance the health care service for cardiovascular diseases. The proposed methodology for the diagnosis involves the integration of the R-peak detection algorithm, FFT (fast fourier transform) based discrete wavelet transform for feature extraction and feedforward based Neural Network Architecture to classify generic cardiac beat classes into eight categories namely Right Bundled Block, Left Bundled Block, Preventricular Contraction (PVC), Atrial Premature Contraction (APC), Ventricular Flutter wave (VF), Paced Beat, Ventricular Escape (VE) and Normal beat. The paper contributes the development, prototyping and analysis of proposed methodology on ARM (Advanced RISC Machine) based SoC (System-on-Chip) in laboratory setup. This system is validated by generating real-time ECG signals using MIT-BIH database while the output of the system is monitored on the displaying device. The performance analysis of the proposed methodology implemented on the microcontroller based system is computed by performing the experiment which achieves a high overall accuracy of 97.4% with average sensitivity (
                        
                           
                              
                                 S
                              
                              
                                 e
                              
                           
                        
                     ) of 97.57%, specificity (
                        
                           
                              
                                 S
                              
                              
                                 p
                              
                           
                        
                     ) of 99.59% and positive predictivity (
                        
                           
                              
                                 P
                              
                              
                                 p
                              
                           
                        
                     ) of 97.93%. The system provides an assistive diagnostic solution to the users to lead a healthy lifestyle. Moreover, the ARM-based system can be fabricated into a handheld device for reliable automatic monitoring of the condition of heart by patients.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jacc.2015.08.006,Journal,Journal of the American College of Cardiology,scopus,2015-09-29,sciencedirect,"Moving from Digitalization to Digitization in Cardiovascular Care Why Is it Important, and What Could it Mean for Patients and Providers?",https://api.elsevier.com/content/abstract/scopus_id/84942094681,"So far, the digitization of health care is best exemplified by electronic medical records, which have been far from favorably or uniformly accepted. However, properly implemented digitization can enable better patient outcomes, improve convenience, potentially lower healthcare costs, and possibly lead to much greater physician satisfaction. Precision (also known as personalized or individualized) medicine is frequently discussed today, but, in reality, it is what physicians have attempted to do as best they could for millennia. But now we have new tools that can begin to give us a much more high-definition view of our patients; from affordable and rapid genetic testing to wearable sensors that track a wide range of important physiologic parameters continuously. Although seemingly counterintuitive, the digitization of health care can also markedly improve the physician-patient relationship, allowing more time for human interaction when care is bolstered by digital technologies that better individualize diagnostics and treatments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ijhydene.2015.06.115,Journal,International Journal of Hydrogen Energy,scopus,2015-09-07,sciencedirect,Fault Tolerant Control Strategy applied to PEMFC water management,https://api.elsevier.com/content/abstract/scopus_id/84938210137,"In this paper, a Fault Tolerant Control Strategy (FTCS) dedicated to PEMFC (Polymer Electrolyte Membrane Fuel Cell) water management is implemented and validated online on a real PEMFC system. Thanks to coupling a Fault Detection and Isolation (FDI), an adjustable controller and a reconfiguration mechanism, FTCS allows addressing the important challenge of Fuel Cell (FC) reliability improvement. Only few works have already been conducted on FTCS applied to FC actuators faults, and none of them on FC water management faults. In this work, a neural-based diagnosis tool is computed online as FDI component and is coupled to a self-tuning PID controller. This diagnosis tool shows low computational time and high detection performance. The self-tuning PID controller shows robustness against noise measurements and model uncertainties. Its low computational cost makes it a suitable control method for real-time FTCS. Performed on a PEMFC system, the FTCS shows promising results on fault diagnosis and performance recovery.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1074/mcp.M114.047050,Journal,Molecular and Cellular Proteomics,scopus,2015-09-01,sciencedirect,"Large-scale interlaboratory study to develop, analytically validate and apply highly multiplexed, quantitative peptide assays to measure cancer-relevant proteins in plasma",https://api.elsevier.com/content/abstract/scopus_id/84929586811,"There is an increasing need in biology and clinical medicine to robustly and reliably measure tens to hundreds of peptides and proteins in clinical and biological samples with high sensitivity, specificity, reproducibility, and repeatability. Previously, we demonstrated that LC-MRM-MS with isotope dilution has suitable performance for quantitative measurements of small numbers of relatively abundant proteins in human plasma and that the resulting assays can be transferred across laboratories while maintaining high reproducibility and quantitative precision. Here, we significantly extend that earlier work, demonstrating that 11 laboratories using 14 LC-MS systems can develop, determine analytical figures of merit, and apply highly multiplexed MRM-MS assays targeting 125 peptides derived from 27 cancer-relevant proteins and seven control proteins to precisely and reproducibly measure the analytes in human plasma. To ensure consistent generation of high quality data, we incorporated a system suitability protocol (SSP) into our experimental design. The SSP enabled real-time monitoring of LC-MRM-MS performance during assay development and implementation, facilitating early detection and correction of chromatographic and instrumental problems. Low to subnanogram/ml sensitivity for proteins in plasma was achieved by one-step immunoaffinity depletion of 14 abundant plasma proteins prior to analysis. Median intra- and interlaboratory reproducibility was <20%, sufficient for most biological studies and candidate protein biomarker verification. Digestion recovery of peptides was assessed and quantitative accuracy improved using heavy-isotope-labeled versions of the proteins as internal standards. Using the highly multiplexed assay, participating laboratories were able to precisely and reproducibly determine the levels of a series of analytes in blinded samples used to simulate an interlaboratory clinical study of patient samples. Our study further establishes that LC-MRM-MS using stable isotope dilution, with appropriate attention to analytical validation and appropriate quality control measures, enables sensitive, specific, reproducible, and quantitative measurements of proteins and peptides in complex biological matrices such as plasma.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.patcog.2015.03.017,Journal,Pattern Recognition,scopus,2015-09-01,sciencedirect,IODA: An input/output deep architecture for image labeling,https://api.elsevier.com/content/abstract/scopus_id/84929516076,"In this paper, we propose a deep neural network (DNN) architecture called Input Output Deep Architecture (IODA) for solving the problem of image labeling. IODA directly links a whole image to a whole label map, assigning a label to each pixel using a single neural network forward step. Instead of designing a handcrafted a priori model on labels (such as an atlas in the medical domain), we propose to automatically learn the dependencies between labels. The originality of IODA is to transpose DNN input pre-training trick to the output space, in order to learn a high level representation of labels. It allows a fast image labeling inside a fully neural network framework, without the need of any preprocessing such as feature designing or output coding.
                  In this paper, IODA is applied on both a toy texture problem and a real-world medical image dataset, showing promising results. We provide an open source implementation of IODA.
                        1
                     
                     
                        1
                        
                           http://mloss.org/software/view/562/
                        
                     
                     ,
                     
                        2
                     
                     
                        2
                        
                           https://github.com/jlerouge/crino",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2015.07.010,Journal,Applied Soft Computing Journal,scopus,2015-08-24,sciencedirect,ECG heart beat classification method based on modified ABC algorithm,https://api.elsevier.com/content/abstract/scopus_id/84939801770,"Electrocardiogram is the most commonly used tool for the diagnosis of cardiologic diseases. In order to help cardiologists to diagnose the arrhythmias automatically, new methods for automated, computer aided ECG analysis are being developed. In this paper, a Modified Artificial Bee Colony (MABC) algorithm for ECG heart beat classification is introduced. It is applied to ECG data set which is obtained from MITBIH database and the result of MABC is compared with seventeen other classifier's accuracy.
                  In classification problem, some features have higher distinctiveness than others. In this study, in order to find higher distinctive features, a detailed analysis has been done on time domain features. By using the right features in MABC algorithm, high classification success rate (99.30%) is obtained. Other methods generally have high classification accuracy on examined data set, but they have relatively low or even poor sensitivities for some beat types. Different data sets, unbalanced sample numbers in different classes have effect on classification result. When a balanced data set is used, MABC provided the best result as 97.96% among all classifiers.
                  Not only part of the records from examined MITBIH database, but also all data from selected records are used to be able to use developed algorithm on a real time system in the future by using additional software modules and making adaptation on a specific hardware.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.asoc.2015.03.024,Journal,Applied Soft Computing Journal,scopus,2015-08-22,sciencedirect,A consensus model for Delphi processes with linguistic terms and its application to chronic pain in neonates definition,https://api.elsevier.com/content/abstract/scopus_id/84939650749,"This paper proposes a new model of consensus based on linguistic terms to be implemented in Delphi processes. The model of consensus involves qualitative reasoning techniques and is based on the concept of entropy. The proposed model has the ability to reach consensus automatically without the need for either a moderator or a final interaction among panelists. In addition, it permits panelists to answer with different levels of precision depending on their knowledge on each question. The model defined has been used to establish the relevant features for the definition of a type of chronic disease. A real-case application conducted in the Department of Neonatology of Máxima Medical Center in The Netherlands is presented. This application considers the opinions of stakeholders of neonate health-care in order to reach a final consensual definition of chronic pain in neonates.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.enbuild.2015.05.056,Journal,Energy and Buildings,scopus,2015-07-15,sciencedirect,Electrical consumption forecasting in hospital facilities: An application case,https://api.elsevier.com/content/abstract/scopus_id/84937550487,"The topic of energy efficiency applied to buildings represents one of the key aspects in today's international energy policies. Emissions reduction and the achievement of the targets set by the Kyoto Protocol are becoming a fundamental concern in the work of engineers and technicians operating in the energy management field. Optimal energy management practices need to deal with uncertainties in generation and demand, hence the development of reliable forecasting methods is an important priority area of research in electric energy systems. This paper presents a load forecasting model and the way it was applied to a real case study, to forecast the electrical consumption of the Cellini medical clinic of Turin. The model can be easily integrated into a Building Management System or into a real time monitoring system. The load forecasting is performed through the implementation of an artificial neural network (ANN). The proposed multi-layer perceptron ANN, based on a back propagation training algorithm, is able to take as inputs: loads, data concerning the type of day (e.g. weekday/holiday), time of the day and weather data. In particular, this work focuses on providing a detailed analysis and an innovative formal procedure for the selection of all the ANN parameters.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2015.06.036,Journal,Expert Systems with Applications,scopus,2015-07-14,sciencedirect,Optimum steepest descent higher level learning radial basis function network,https://api.elsevier.com/content/abstract/scopus_id/84936984582,"Dynamically changing real world applications, demands for rapid and accurate machine learning algorithm. In neural network based machine learning algorithms, radial basis function (RBF) network is a simple supervised learning feed forward network. With its simplicity, this network is highly suitable to model and control the nonlinear systems. Existing RBF networks in literature are applied to static applications and also faces challenges such as increased model size, neuron removal, improper center selection etc leading to erroneous output. To overcome the challenges and handle complex real world problems, this paper proposes a new optimum steepest descent based higher level learning radial basis function network (OSDHL-RBFN). The proposed OSDHL-RBFN implements major components inspired from the human brain for efficient learning, adaptive structure and accurate classification. Higher level learning and thinking components of the proposed network are sample deletion, neuron addition, neuron migration, sample navigation and neuroplasticity. These components helps the classifier to think before learning the samples and regulates the learning strategy. The knowledge gained from the trained samples are used by the network to identify the incomplete sample, optimal center and bond strength of hidden & output neurons. Adaptive network structure is employed to minimize classification error. The proposed work also uses optimum steepest descent method for weight parameter update to minimize the sum square error. OSDHL-RBFN is tested and evaluated in both static and dynamic environments on nine benchmark classification (binary and multiclass) problems for balanced, unbalanced, small, large, low dimensional and high dimensional datasets. The overall and class wise efficiency of OSDHL-RBFN is improved when compared to other RBFN’s in the literature. The performance results clearly show that the proposed OSDHL-RBFN reduces the architecture complexity and computation time compared to other RBFN’s. Overall, the proposed OSDHL-RBFN is efficient and suitable for dynamic real world applications in terms of detection time and accuracy. As a case study, OSDHL-RBFN is implemented in real time remote health monitoring application for classifying the various abnormality levels in vital parameters.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.gie.2014.11.040,Journal,Gastrointestinal Endoscopy,scopus,2015-07-01,sciencedirect,Quantitative contrast-enhanced harmonic EUS in differential diagnosis of focal pancreatic masses (with videos),https://api.elsevier.com/content/abstract/scopus_id/84930926788,"Background
                  The role of EUS with contrast agents can be expanded through the use of time-intensity curve (TIC) analysis and computer-aided interpretation.
               
                  Objective
                  To validate the use of parameters derived from TIC analysis in an artificial neural network (ANN) classification model designed to diagnose pancreatic carcinoma (PC) and chronic pancreatitis (CP).
               
                  Setting
                  Prospective, multicenter, observational trial—endoscopy units from Romania, Denmark, Germany, and Spain.
               
                  Patients
                  A total of 167 consecutive patients with PC or CP.
               
                  Interventions
                  Contrast-enhanced harmonic EUS (CEH-EUS) and EUS-guided FNA (EUS-FNA), TIC analysis, and ANN processing.
               
                  Main Outcome Measurements
                  Sensitivity, specificity, positive and negative predictive values (PPV, NPV) for EUS-FNA, CEH-EUS, and the ANN.
               
                  Results
                  After excluding all of the recordings that did not meet the technical and procedural criteria, 112 cases of PC and 55 cases of CP were included. EUS-FNA was performed in 129 patients, and the diagnosis was confirmed by surgery (n = 15) or follow-up (n = 23) in the remaining cases. Its sensitivity and specificity were 84.82% and 100%, respectively, whereas the PPV and NPV were 100% and 76.63%, respectively. The sensitivity of real-time quantitative assessment of CEH-EUS was 87.5%, specificity 92.72%, PPV 96.07%, and NPV 78.46%. Peak enhancement, wash-in area under the curve, wash-in rate, and the wash-in perfusion index were significantly different between the groups. No significant differences were found between rise time, mean transit time, and time to peak. For the ANN, sensitivity was 94.64%, specificity 94.44%, PPV 97.24%, and NPV 89.47%.
               
                  Limitations
                  Only PC and CP lesions were included.
               
                  Conclusion
                  Parameters obtained through TIC analysis can differentiate between PC and CP cases and can be used in an automated computer-aided diagnostic system with good diagnostic results. (Clinical trial registration number: NCT01315548.)",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2015.07.010,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-06-01,sciencedirect,Development of handheld cardiac event monitoring system,https://api.elsevier.com/content/abstract/scopus_id/84992490572,"This paper contributes the development, prototyping and analysis of proposed methodology on ARM (Advanced RISC Machine) in laboratory for automatic detection of arrhythmia beat in real-time for diagnosis of cardiovascular diseases. The methodology involves the integration of R peak detection algorithm, Principal Component Analysis for feature extraction and feedforward neural network architecture to classify generic heartbeats into six classes. The proposed methodology is implemented on ARM-based SoC (System-on-Chip) platform for diagnosis of six heartbeats. This developed system is validated by generating realtime ECG beats using MIT-BIH database and the output of the proposed system is monitored in the displaying device. The performance metrics of the developed system yields an overall accuracy of 92.81% with average sensitivity, specificity and positive predictivity of 92.68%, 98.51% and 92.42% respectively. Moreover, the developed system can be fabricated into a handheld device for automatic ECG beat monitoring.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.eswa.2015.04.024,Journal,Expert Systems with Applications,scopus,2015-05-30,sciencedirect,Nonintrusive system for assistance and guidance in smart homes based on electrical devices identification,https://api.elsevier.com/content/abstract/scopus_id/84930181462,"Recently, sensors and actuators have quickly spread throughout our everyday life. These devices are robust, cheap, accessible, connected to the Internet, etc. With the growing needs in terms of human and medical resources to help cognitively-impaired people to remain at home, researchers are investing in new ways to exploit this technology with artificial intelligence, in order to build expert systems to assist the residents in their daily activities. Several systems have been proposed in the last few years, mostly based on binary sensors, cameras and other sensors such as Radio-frequency identification (RFID) tags. Cameras are very intrusive, binary sensors (such as movement detectors) give only basic information, and other types of sensors (such as RFID) need complex deployment. In this context, this paper presents a new assistive expert system based on electric device identification to address the problem of guidance and supervision in the performance of activities for people with cognitive disorders living in a smart home. This system is solely based on a single power analyzer placed in the electric panel. We propose an algorithmic approach used to recognize erratic behaviors related to cognitive deficits and provides cues to guide the person in the completion of an ongoing task. This is achieved through load signatures study of appliances represented by three features (active power (P), reactive power (Q) and line-to-neutral), which allows to determine the errors committed by the resident. We implemented this system within a genuine smart-home prototype equipped with household appliances used by the patient during his morning routines. Different multimedia prompting devices (iPad, screen, speakers, etc.) were used. We tested the system with real-case scenarios modeled from former clinical trials, allowing demonstration of accuracy and effectiveness of our system in assisting a cognitively-impaired resident in the completion of daily activities.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.08.018,Journal,Biosensors and Bioelectronics,scopus,2015-05-05,sciencedirect,Integrated potentiostat for electrochemical sensing of urinary 3-hydroxyanthranilic acid with molecularly imprinted poly(ethylene-co-vinyl alcohol),https://api.elsevier.com/content/abstract/scopus_id/84922318833,"Changing demographics, the rise of personalized medicine and increased identification of biomarkers for diagnosis and management of chronic disease have increased the demand for portable bioanalytical instrumentation and point-of-care. The recent development of molecularly imprinted polymers enables production of low cost and highly stable sensing chips; however, the commercially available and full functional instruments employed for electrochemical analysis have shortcomings in actual homecare applications. In this work, integrated circuits (ICs) for monolithic implementation of voltammeter potentiostat with a large dynamic current range (5nA to 1.2mA) and short conversion time (10ms) were fabricated in a 0.35μm complementary metal-oxide-semiconductor (CMOS) process. The new instrumentation was tested with molecular imprinted sensors for 3-hydroxyanthranilic acid (3HAA) in urine. The sensor consisted of molecular imprinted of poly(ethylene-co-vinyl alcohol)s (abbreviated as EVALs) for implementation in a flow injection analysis system. The EVAL containing 32 ethylene mol% had the highest imprinting effectiveness for the target molecules. Fit-for-purpose figures of merit were achieved with a limit-of-detection (LOD) of 3.06pg/mL. The measurements obtained in real undiluted urine samples fell within the reference concentration range of 50–550ng/mL.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.07.084,Journal,Biosensors and Bioelectronics,scopus,2015-05-05,sciencedirect,"Lytic enzymes as selectivity means for label-free, microfluidic and impedimetric detection of whole-cell bacteria using ALD-Al<inf>2</inf>O<inf>3</inf> passivated microelectrodes",https://api.elsevier.com/content/abstract/scopus_id/84922271489,"Point-of-care (PoC) diagnostics for bacterial detection offer tremendous prospects for public health care improvement. However, such tools require the complex combination of the following performances: rapidity, selectivity, sensitivity, miniaturization and affordability. To meet these specifications, this paper presents a new selectivity method involving lysostaphin together with a CMOS-compatible impedance sensor for genus-specific bacterial detection. The method enables the sample matrix to be directly flown on the polydopamine-covered sensor surface without any pre-treatment, and considerably reduces the background noise. Experimental proof-of-concept, explored by simulations and confirmed through a setup combining simultaneous optical and electrical real-time monitoring, illustrates the selective and capacitive detection of Staphylococcus epidermidis in synthetic urine also containing Enterococcus faecium. While providing capabilities for miniaturization and system integration thanks to CMOS compatibility, the sensors show a detection limit of ca. 108 (CFU/mL).min in a 1.5μL microfluidic chamber with an additional setup time of 50min. The potentials, advantages and limitations of the method are also discussed.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ifacol.2015.06.162,Conference Proceeding,IFAC-PapersOnLine,scopus,2015-05-01,sciencedirect,Supporting urban home health care in daily business and times of disasters,https://api.elsevier.com/content/abstract/scopus_id/84953882203,"Home health care (HHC) services are of vital importance for today's society. They allow old and frail people a self-determined living in their familiar environment. Due to the current demographic and social developments further increases in demand for HHC must be expected. Additionally, people with limited mobility or relying on medical supply usually need consistent care. Thus, HHC service providers will be faced with two challenges: an increased organizational effort due to the rising demand and the need for an anticipatory risk management. Previous research combining optimization and risk management in the field of HHC limits itself to rural regions, where nurses are solely using cars. The presented work specifically aims to deal with the peculiarities of urban regions. Together with the Austrian Red Cross (ARC), a vulnerability analysis has been conducted in order to identify the critical success factors and processes of HHC as well as potential threats. To support the daily scheduling, a Tabu Search (TS) based metaheuristic has been implemented. As nurses can choose between different transport modes (public transport, car, bike, and walking), time-dependent multimodal transport has been considered. The TS has been tested with real-world data from the ARC in Vienna to support both, daily business and scheduling in times of disasters. Significant reductions of travel and waiting times can be obtained, such that more time remains for serving the clients. Through sensitivity analysis the effects of disasters (esp. blackout, pandemics, and heat waves) are visualized and the operational limits during such events are shown.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2014.12.005,Journal,Neurocomputing,scopus,2015-04-22,sciencedirect,A real-time topography of maximum contact pressure distribution at medial tibiofemoral knee implant during gait: Application to knee rehabilitation,https://api.elsevier.com/content/abstract/scopus_id/84924943676,"Knee contact pressure is a crucial factor in the knee rehabilitation programs. Although contact pressure can be estimated using finite element analysis, this approach is generally time-consuming and does not satisfy the real-time requirements of a clinical set-up. Therefore, a real-time surrogate method to estimate the contact pressure would be advantageous.
                  This study implemented a novel computational framework using wavelet time delay neural network (WTDNN) to provide a real-time estimation of contact pressure at the medial tibiofemoral interface of a knee implant. For a number of experimental gait trials, joint kinematics/kinetics and the resultant contact pressure were computed through multi-body dynamic and explicit finite element analyses to establish a training database for the proposed WTDNN. The trained network was then tested by predicting the maximum contact pressure at the medial tibiofemoral knee implant for two different knee rehabilitation patterns; “medial thrust” and “trunk sway”. WTDNN predictions were compared against the calculations from an explicit finite element analysis (gold standard).
                  Results showed that the proposed WTDNN could accurately calculate the maximum contact pressure at the medial tibiofemoral knee implant for medial thrust (
                        
                           
                              R
                              M
                              S
                              E
                           
                           
                              ¯
                           
                        
                     =1.7MPa, 
                        
                           
                              N
                              R
                              M
                              S
                              E
                           
                           
                              ¯
                           
                        
                     =6.2% and 
                        
                           ρ
                           ¯
                        
                     =0.98) and trunk sway (
                        
                           
                              R
                              M
                              S
                              E
                           
                           
                              ¯
                           
                        
                     
                     =2.6MPa, 
                        
                           
                              N
                              R
                              M
                              S
                              E
                           
                           
                              ¯
                           
                        
                     =9.3%, 
                        
                           ρ
                           ¯
                        
                     =0.96) much faster than the finite element method. The proposed methodology could therefore serve as a cost-effective surrogate model to provide real-time evaluation of the gait retraining programs in terms of the resultant maximum contact pressures.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jep.2015.01.030,Journal,Journal of Ethnopharmacology,scopus,2015-04-02,sciencedirect,Reporting effectiveness of an extract of three traditional Cretan herbs on upper respiratory tract infection: Results from a double-blind randomized controlled trial,https://api.elsevier.com/content/abstract/scopus_id/84922793641,"Ethnopharmacological relevance
                  Observations from the island of Crete, Greece suggest that infusions of traditional Cretan aromatic plants, well known for their ethnopharmacological use in Eastern Mediterranean region and Near East, could be effective in the prevention and treatment of upper respiratory tract infections, including viral-induced infections. The aim of this study was to report the effectiveness of an essential-oil extract of three Cretan aromatic plants in the treatment of cases with an upper respiratory tract infection.
               
                  Materials and methods
                  A double blind randomized controlled trial was implemented between October 2013 and February 2014. An essential-oil extract of Cretan aromatic plants in olive oil (total volume of 15ml of essential oil per litre of olive oil) was administered as 0.5ml soft gel capsules, twice a day, for 7 days. Placebo treatment was 0.5ml olive oil in soft gel capsules. Eligible patients were those presenting for clinical examination in the selected setting with signs and symptoms of upper respiratory tract infection that had begun within the previous 24hours. Real-Time Polymerase Chain Reaction (PCR) was used for the detection of respiratory viruses. The primary outcome was the severity and duration of symptoms of upper respiratory tract infection, assessed using the Wisconsin Upper Respiratory System Survey (WURSS-21) questionnaire. A secondary outcome of interest was the change in C-reactive protein (CRP) status.
               
                  Results
                  One hundred and five patients completed the study: 51 in the placebo group, and 54 in the intervention (treated) group. Baseline characteristics were similar in the two groups. No statistically significant differences were found in symptom duration or severity between the two groups, although small and clinically favorable effects were observed. When the analysis was restricted to subjects with a laboratory-documented viral infection, the percentage of patients with cessation of symptoms after 6 days of treatment was 91% in the intervention group and 70% in the control group (p=0.089). At baseline, one third of the patients in each group had elevated CRP levels. At follow-up, the respective proportions were 0% in the intervention group and 15% in the placebo group (p=0.121). The data were also in a favorable direction when 50% and 80% symptom reduction points were considered for specific virus types.
               
                  Conclusions
                  Compared with placebo the essential-oil extract of three Cretan aromatic plants provided no detectable statistically significant benefit or harm in the patients with upper respiratory illness, although descriptive differences were identified in favorable direction mainly in the virus-positive population.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.cmpb.2015.02.002,Journal,Computer Methods and Programs in Biomedicine,scopus,2015-04-01,sciencedirect,GPU-based parallel group ICA for functional magnetic resonance data,https://api.elsevier.com/content/abstract/scopus_id/84924548399,"The goal of our study is to develop a fast parallel implementation of group independent component analysis (ICA) for functional magnetic resonance imaging (fMRI) data using graphics processing units (GPU). Though ICA has become a standard method to identify brain functional connectivity of the fMRI data, it is computationally intensive, especially has a huge cost for the group data analysis. GPU with higher parallel computation power and lower cost are used for general purpose computing, which could contribute to fMRI data analysis significantly. In this study, a parallel group ICA (PGICA) on GPU, mainly consisting of GPU-based PCA using SVD and Infomax-ICA, is presented. In comparison to the serial group ICA, the proposed method demonstrated both significant speedup with 6–11 times and comparable accuracy of functional networks in our experiments. This proposed method is expected to perform the real-time post-processing for fMRI data analysis.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.acvd.2014.09.010,Journal,Archives of Cardiovascular Diseases,scopus,2015-03-01,sciencedirect,Left atrial volume is not an index of left ventricular diastolic dysfunction in patients with sickle cell anaemia,https://api.elsevier.com/content/abstract/scopus_id/84925335536,"Background
                  Left ventricular diastolic dysfunction (LVDD) is common in sickle cell anaemia (SCA). Left atrial (LA) size is widely used as an index of LVDD; however, LA enlargement in SCA might also be due to chronic volume overload.
               
                  Aim
                  To investigate whether LA size can be used to diagnose LVDD in SCA.
               
                  Methods
                  One hundred and twenty-seven adults with stable SCA underwent echocardiographic assessment. LA volume was measured by the area–length method and indexed to body surface area (LAVi). Left ventricular (LV) filling pressures were assessed using the ratio of early peak diastolic velocities of mitral inflow and septal annular mitral plane (E/e′). Using mitral inflow profile and E/e′, LV diastolic function was classified as normal or abnormal. LAVi>28mL/m2 was used as the threshold to define LA enlargement.
               
                  Results
                  The mean age was 28.6±8.5years; there were 83 women. Mean LAVi was 48.3±11.1mL/m2 and 124 (98%) patients had LA dilatation. In multivariable analysis, age, haemoglobin concentration and LV end-diastolic volume index were independent determinants of LAVi (R
                     2
                     =0.51; P
                     <0.0001). E/e′ was not linked to LAVi (P
                     =0.43). Twenty patients had LVDD; when compared with patients without LVDD, they had a similar LAVi (52.2±14.7 and 47.5±10.2mL/m2, respectively; P
                     =0.29). Receiver operating characteristics curve analysis showed that LAVi could not be used to diagnose LVDD (area under curve=0.58; P
                     =0.36).
               
                  Conclusion
                  LA enlargement is common in SCA but appears not to be linked to LVDD. LAVi in this population is related to age, haemoglobin concentration and LV morphology.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.ejvs.2014.12.003,Journal,European Journal of Vascular and Endovascular Surgery,scopus,2015-03-01,sciencedirect,Safety and accuracy of endovascular aneurysm repair without pre-operative and intra-operative contrast agent,https://api.elsevier.com/content/abstract/scopus_id/84924209498,"Background
                  Severe chronic kidney disease is a major limitation for endovascular aortic aneurysm repair (EVAR). The aim of this study is to assess the safety and accuracy of fusion imaging, when performing EVAR in the absence of pre- and intra-operative contrast agents.
               
                  Methods
                  From October 2013 to February 2014, every patient requiring EVAR and presenting with severe chronic renal impairment underwent a specific pre-operative imaging assessment, based on a non-enhanced CT scan. Centrelines were manually extracted and key points were placed at the landing zones. In house software makes it possible to artificially enhance the contrast between vascular structures and the surrounding tissue, by increasing the values attributed to the vascular structure voxels (500 Hounsfield units). EVAR was performed in a hybrid room (Zeego, Siemens), and the artificially enhanced CT scan was used for the construction of fusion imaging. The 3D vascular volume, together with the centrelines and key points, was overlaid onto the 2D live fluoroscopic image.
               
                  Results
                  Six patients (mean age 77.1 years) were treated by EVAR (5 abdominal aneurysms and 1 thoracic aneurysm), using fusion imaging without a contrast agent. The median pre-operative estimated glomerular filtration rate (eGFR) was 17.5 mL/min/1.73 m2. No contrast was used during the procedure. No intra-operative endoleak was observed on the duplex scan. No deterioration was observed in the eGFR at 1 week (eGFR = 21.7, p = .49), nor at 1 month follow up (eGFR = 21, p = .28). The stent graft positioning error was assessed in terms of the difference between the effective and planned landing zones, measured on pre- and post-operative CT scans. The mean error was 1.3 mm at the proximal landing zone, and 6.5 mm at the distal landing zone.
               
                  Conclusion
                  EVAR without the use of pre-operative and intra-operative contrast agents appears to be safe and accurate for patients with severe chronic kidney disease.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.artmed.2014.08.006,Journal,Artificial Intelligence in Medicine,scopus,2015-02-01,sciencedirect,"A systems approach to healthcare: Agent-based modeling, community mental health, and population well-being",https://api.elsevier.com/content/abstract/scopus_id/84928207619,"Purpose
                  Explore whether agent-based modeling and simulation can help healthcare administrators discover interventions that increase population wellness and quality of care while, simultaneously, decreasing costs. Since important dynamics often lie in the social determinants outside the health facilities that provide services, this study thus models the problem at three levels (individuals, organizations, and society).
               
                  Methods
                  The study explores the utility of translating an existing (prize winning) software for modeling complex societal systems and agent's daily life activities (like a Sim City style of software), into a desired decision support system. A case study tests if the 3 levels of system modeling approach is feasible, valid, and useful. The case study involves an urban population with serious mental health and Philadelphia's Medicaid population (n
                     =527,056), in particular.
               
                  Results
                  Section 3 explains the models using data from the case study and thereby establishes feasibility of the approach for modeling a real system. The models were trained and tuned using national epidemiologic datasets and various domain expert inputs. To avoid co-mingling of training and testing data, the simulations were then run and compared (Section 4.1) to an analysis of 250,000 Philadelphia patient hospital admissions for the year 2010 in terms of re-hospitalization rate, number of doctor visits, and days in hospital. Based on the Student t-test, deviations between simulated vs. real world outcomes are not statistically significant. Validity is thus established for the 2008–2010 timeframe. We computed models of various types of interventions that were ineffective as well as 4 categories of interventions (e.g., reduced per-nurse caseload, increased check-ins and stays, etc.) that result in improvement in well-being and cost.
               
                  Conclusions
                  The 3 level approach appears to be useful to help health administrators sort through system complexities to find effective interventions at lower costs.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.jbi.2014.10.009,Journal,Journal of Biomedical Informatics,scopus,2015-02-01,sciencedirect,Quantifying the determinants of outbreak detection performance through simulation and machine learning,https://api.elsevier.com/content/abstract/scopus_id/84924493147,"Objective
                  To develop a probabilistic model for discovering and quantifying determinants of outbreak detection and to use the model to predict detection performance for new outbreaks.
               
                  Materials and methods
                  We used an existing software platform to simulate waterborne disease outbreaks of varying duration and magnitude. The simulated data were overlaid on real data from visits to emergency department in Montreal for gastroenteritis. We analyzed the combined data using biosurveillance algorithms, varying their parameters over a wide range. We then applied structure and parameter learning algorithms to the resulting data set to build a Bayesian network model for predicting detection performance as a function of outbreak characteristics and surveillance system parameters. We evaluated the predictions of this model through 5-fold cross-validation.
               
                  Results
                  The model predicted performance metrics of commonly used outbreak detection methods with an accuracy greater than 0.80. The model also quantified the influence of different outbreak characteristics and parameters of biosurveillance algorithms on detection performance in practically relevant surveillance scenarios. In addition to identifying characteristics expected a priori to have a strong influence on detection performance, such as the alerting threshold and the peak size of the outbreak, the model suggested an important role for other algorithm features, such as adjustment for weekly patterns.
               
                  Conclusion
                  We developed a model that accurately predicts how characteristics of disease outbreaks and detection methods will influence on detection. This model can be used to compare the performance of detection methods under different surveillance scenarios, to gain insight into which characteristics of outbreaks and biosurveillance algorithms drive detection performance, and to guide the configuration of surveillance systems.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.knosys.2014.11.029,Journal,Knowledge-Based Systems,scopus,2015-02-01,sciencedirect,"Collaborator recommendation in interdisciplinary computer science using degrees of collaborative forces, temporal evolution of research interest, and comparative seniority status",https://api.elsevier.com/content/abstract/scopus_id/84920525842,"Currently, the research in computer science has been exponentially expanded beyond its own fields into the other research fields such as medical science, business, and social science in forms of collaborative researches. This collaborative researches stimulate a new recommending algorithm for determining a potential research collaborator under the interdisciplinary environment. Unlike other research fields, the research problems in computer science can be transformed to other known and solvable problems. In this paper, a new hybrid algorithm based on dynamic collaboration over time was proposed for recommending an appropriate collaborator. Besides considering only three basic factors concerning social proximity, friendship, and complementarity skill as employed by others’, three new additional factors related to research interest, up-to-date publication data, and seniority of researcher are involved in our analysis. A set of new measures for all six recommending factors were proposed. The experiments were conducted with real bibliographic data within six continuous years of publication and over six topics in computer science. Our results were significantly higher than the results of the other methods at 90% confidence level.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2015.08.456,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Neural-based Machine Translation for Medical Text Domain. Based on European Medicines Agency Leaflet Texts,https://api.elsevier.com/content/abstract/scopus_id/84962870250,"The quality of machine translation is rapidly evolving. Today one can find several machine translation systems on the web that provide reasonable translations, although the systems are not perfect. In some specific domains, the quality may decrease. A recently proposed approach to this domain is neural machine translation. It aims at building a jointly-tuned single neural network that maximizes translation performance, a very different approach from traditional statistical machine translation. Recently proposed neural machine translation models often belong to the encoder-decoder family in which a source sentence is encoded into a fixed length vector that is, in turn, decoded to generate a translation. The present research examines the effects of different training methods on a Polish-English Machine Translation system used for medical data. The European Medicines Agency parallel text corpus was used as the basis for training of neural and statistical network-based translation systems. The main machine translation evaluation metrics have also been used in analysis of the systems. A comparison and implementation of a real-time medical translator is the main focus of our experiments.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.procs.2015.08.504,Conference Proceeding,Procedia Computer Science,scopus,2015-01-01,sciencedirect,Fitness based position update in spider monkey optimization algorithm,https://api.elsevier.com/content/abstract/scopus_id/84962597795,Spider Monkey Optimization (SMO) technique is most recent member in the family of swarm optimization algorithms.SMO algorithm fall in class of Nature Inspired Algorithm (NIA). SMO algorithm is good in exploration and exploitation of local search space and it is well balanced algorithm most of the times. This paper presents a new strategy to update position of solution during local leader phase using fitness of individuals. The proposed algorithm is named as Fitness based Position Update in SMO (FPSMO) algorithm as it updates position of individuals based on their fitness. The anticipated strategy enhances the rate of convergence. The planned FPSMO approach tested over nineteen benchmark functions and for one real world problem so as to establish superiority of it over basic SMO algorithm.,health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.neucom.2014.06.032,Journal,Neurocomputing,scopus,2014-12-25,sciencedirect,Decisional DNA for modeling and reuse of experiential clinical assessments in breast cancer diagnosis and treatment,https://api.elsevier.com/content/abstract/scopus_id/84906951104,"Clinical Decision Support Systems (CDSS) are active knowledge resources that use patient data to generate case specific advice. The fast pace of change of clinical knowledge imposes to CDSS the continuous update of the domain knowledge and decision criteria. Traditional approaches require costly tedious manual maintenance of the CDSS knowledge bases and repositories. Often, such an effort cannot be assumed by medical teams, hence maintenance is often faulty. In this paper, we propose a (semi-)automatic update process of the underlying knowledge bases and decision criteria of CDSS, following a learning paradigm based on previous experiences, such as the continuous learning that clinicians carry out in real life. In this process clinical decisional events are acquired and formalized inside the system by the use of the SOEKS and Decisional DNA experiential knowledge representation techniques. We propose three algorithms processing clinical experience to: (a) provide a weighting of the different decision criteria, (b) obtain their fine-tuning, and (c) achieve the formalization of new decision criteria. Finally, we present an implementation instance of a CDSS for the domain of breast cancer diagnosis and treatment.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.brat.2014.07.010,Journal,Behaviour Research and Therapy,scopus,2014-11-01,sciencedirect,First steps in using machine learning on fMRI data to predict intrusive memories of traumatic film footage,https://api.elsevier.com/content/abstract/scopus_id/84910069559,"After psychological trauma, why do some only some parts of the traumatic event return as intrusive memories while others do not? Intrusive memories are key to cognitive behavioural treatment for post-traumatic stress disorder, and an aetiological understanding is warranted. We present here analyses using multivariate pattern analysis (MVPA) and a machine learning classifier to investigate whether peri-traumatic brain activation was able to predict later intrusive memories (i.e. before they had happened). To provide a methodological basis for understanding the context of the current results, we first show how functional magnetic resonance imaging (fMRI) during an experimental analogue of trauma (a trauma film) via a prospective event-related design was able to capture an individual's later intrusive memories. Results showed widespread increases in brain activation at encoding when viewing a scene in the scanner that would later return as an intrusive memory in the real world. These fMRI results were replicated in a second study. While traditional mass univariate regression analysis highlighted an association between brain processing and symptomatology, this is not the same as prediction. Using MVPA and a machine learning classifier, it was possible to predict later intrusive memories across participants with 68% accuracy, and within a participant with 97% accuracy; i.e. the classifier could identify out of multiple scenes those that would later return as an intrusive memory. We also report here brain networks key in intrusive memory prediction. MVPA opens the possibility of decoding brain activity to reconstruct idiosyncratic cognitive events with relevance to understanding and predicting mental health symptoms.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.echo.2014.05.008,Journal,Journal of the American Society of Echocardiography,scopus,2014-10-01,sciencedirect,Knowledge-based reconstruction of right ventricular volumes using real-time three-dimensional echocardiographic as well as cardiac magnetic resonance images: Comparison with a cardiac magnetic resonance standard,https://api.elsevier.com/content/abstract/scopus_id/84907674562,"Background
                  Right ventricular volume quantification using real-time three-dimensional echocardiographic (RT3DE) imaging is limited by technical shortcomings of acquisition and quantification. In this study, a two-step approach was used to overcome these limitations. First, a modified acquisition technique for RT3DE imaging was applied, and second, a software tool using knowledge-based reconstruction (KBR) was used. The approach was validated against the gold standard, cardiac magnetic resonance (CMR) imaging, using CMR and RT3DE data sets from healthy children and from patients with congenital heart disease.
               
                  Methods
                  Sixty individuals (20 healthy persons, 40 with congenital heart defects; age range, 2.3–43.9 years; median age, 11.3 years) consecutively underwent investigation by CMR and RT3DE imaging. CMR data sets were first quantified by the method of disks (MOD) as the standard. Then CMR and RT3DE data sets were quantified using KBR software and compared with the MOD.
               
                  Results
                  CMR was more feasible than echocardiography (100% vs 88%). Compared with the MOD (CMRMOD), there were trivial volume overestimations of KBR for CMR data (CMRKBR), of end-diastolic volume (EDV) (−1.3 ± 8.6%, r = 0.984) and end-systolic volume (ESV) (−3.4 ± 13.3%, r = 0.985), resulting in a 0.7 ± 8.7% difference in ejection fraction (EF) (r = 0.882). Comparing CMRMOD and RT3DE imaging, EDV (1.1 ± 7.4%, r = 0.990) and EF (0.8 ± 9.2%, r = 0.871) were slightly underestimated by RT3DE imaging, with a slight overestimation of ESV (−1.5 ± 13.3%, r = 0.977). Intraobserver variability was excellent for KBR of CMR and RT3DE data, with interclass coefficients of correlation of 0.995 and 0.997 for EDV, 0.995 and 0.994 for ESV, and 0.915 and 0.912 for EF. Interobserver variability provided intraclass correlation coefficients of 0.992 and 0.990 for EDV, 0.997 and 0.992 for ESV, and 0.953 and 0.933 for EF. The KBR analysis required a mean time of 5 min.
               
                  Conclusions
                  KBR is an accurate, versatile, and time-saving method for right ventricular three-dimensional volumetry; it shows excellent reproducibility for RT3DE and CMR data sets. These results suggest that this tool is clinically valuable.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1016/j.bios.2014.02.002,Journal,Biosensors and Bioelectronics,scopus,2014-08-15,sciencedirect,High-throughput real-time electrochemical monitoring of LAMP for pathogenic bacteria detection,https://api.elsevier.com/content/abstract/scopus_id/84895954727,"One of the significant challenges in healthcare is the development of point-of-care (POC) diagnostics. POC diagnostics require low-cost devices that offer portability, simplicity in operation and the ability for high-throughput and quantitative analysis. Here, we present a novel roll-to-roll ribbon fluid-handling device for electrochemical real-time monitoring of nucleic acid (NA) amplification and bacteria detection. The device rendered loop-mediated isothermal amplification (LAMP) and real-time electrochemical detection based on the interaction between LAMP amplicon and the redox-reactive osmium complex. We have shown the detection of 30CFU/ml of Escherichia coli (in the range between 30 and 3×107
                     CFU/ml) and 200CFU/ml of Staphylococcus aureus (in the range of 200–2×105
                     CFU/ml) cultured samples in both real-time and end point detection. This device can be used for the detection of various Gram-negative and a number of Gram-positive bacterial pathogens with high sensitivity and specificity in a high-throughput format. Using a roll-to-roll cassette approach, we could detect 12 samples in one assay. Since the LAMP and electrochemical analysis are implemented within sealed flexible biochips, time-consuming processing steps are not required and the risk of contamination is significantly reduced.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
10.1186/1939-4551-7-15,Journal,World Allergy Organization Journal,scopus,2014-06-25,sciencedirect,"Allergenius, an expert system for the interpretation of allergen microarray results",https://api.elsevier.com/content/abstract/scopus_id/84910666431,"Background An in vitro procedure based on a microarray containing many different allergen components has recently been introduced for use in allergy diagnosis. Recombinant and highly purified allergens belonging to different allergenic sources (inhalants, food, latex and hymenoptera) are present in the array. These components can either be genuine or cross-reactive, resistant or susceptible to heat and low pH, and innocuous or potentially dangerous. A large number of complex and heterogeneous relationships among these components has emerged, such that sometimes these interactions cannot be effectively managed by the allergist. In the 1960s, specialized languages and environments were developed to support the replacement of human experts with dedicated decision-making information systems. Currently, expert systems (ES) are advanced informatics tools that are widely used in medicine, engineering, finance and trading.
                  
                     Methods We developed an ES, named Allergenius ®, to support the interpretation of allergy tests based on microarray technology (ImmunoCAP ISAC ®). The ES was implemented using Flex, a LPA Win-Prolog shell. Rules representing the knowledge base (KB) were derived from the literature and specialized databases. The input data included the patient’s ID and disease(s), the results of either a skin prick test or specific IgE assays and ISAC results. The output was a medical report.
                  
                     Results The ES was first validated using artificial and real life cases and passed all in silico validations. Then, the opinions of allergists with experience in molecular diagnostics were compared with the ES reports. The Allergenius reports included all of the allergists’ opinions and considerations, as well as any additional information.
                  
                     Conclusions Allergenius is a trustable ES dedicated to molecular tests for allergy. In the present version, it provides a powerful method to understand ISAC results and to obtain a comprehensive interpretation of the patient’s IgE profiling.",health,'health' AND 'machine learning' AND ('real-world' AND 'deploy')
