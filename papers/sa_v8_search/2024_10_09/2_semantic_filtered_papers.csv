doi,type,query_name,query_value,publication,publisher,publication_date,database,title,url,abstract,status,id,semantic_score
10.1016/j.giq.2022.101722,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85132505364,scopus,2022-10-01,scopus,public ai canvas for ai-enabled public value: a design science approach,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85132505364&origin=inward,"
                  Public agencies have a strong interest in artificial intelligence (AI) systems. However, many public agencies lack tools and frameworks to articulate a viable business model and evaluate public value as they consider investing in AI systems. The business model canvas used extensively in the private sector offers us a foundation for designing a public AI canvas (PAIC). Employing a design science approach, this study reports on the design and evaluation of PAIC. The PAIC comprises three distinctive layers: (1) the public value-oriented AI-enablement layer; (2) the public value logic layer; and (3) the public value-oriented social guidance layer. PAIC offers guidance on innovating the business models of public agencies to create and capture AI-enabled value. For practitioners, PAIC presents a validated tool to guide AI deployment in public agencies.
               ",unknown,296,0.9426229000091552
10.1017/dap.2024.13,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Data & Policy,2000-01-01 00:00:00,semantic_scholar,exploring citizens’ stances on ai in public services: a social contract perspective,https://www.semanticscholar.org/paper/58b7ea14464538f5a7ea31df0e518df1c3efd0e6,"Abstract This paper explores citizens’ stances toward the use of artificial intelligence (AI) in public services in Norway. Utilizing a social contract perspective, the study analyzes the government–citizen relationship at macro, meso, and micro levels. A prototype of an AI-enabled public welfare service was designed and presented to 20 participants who were interviewed to investigate their stances on the described AI use. We found a generally positive attitude and identified three factors contributing to this: (a) the high level of trust in government (macro level); (b) the balanced value proposition between individual and collective needs (meso level); and (c) the reassurance provided by having humans in the loop and providing transparency into processes, data, and model’s logic (microlevel). The findings provide valuable insights into citizens’ stances for socially responsible AI in public services. These insights can inform policy and guide the design and implementation of AI systems in the public sector by foregrounding the government–citizen relationship.",unknown,122,0.9021365642547609
10.1109/mc.2020.3010043,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Computer,2020-01-01 00:00:00,semantic_scholar,artificial intelligence in government,https://www.semanticscholar.org/paper/5bca0d47912b214890e9ca6ee7a76f4deb8de815,"The articles in this special section focus on government applications that use artificial intelligence (AI). The repercussions of artificial intelligence (AI) in government are broad and significant. The characteristics of these technologies will have an impact on almost everything in public organizations, from governance or the multidimensional perspective of interoperability, to the organizational or social implications linked to concepts like public value, transparency, or accountability. This special issue seeks to shed light on foundations and key elements to be taken into account for AI adoption by public organizations. Governments are the primary enablers of technology and market stimulators and regulators of general activities in our society. Governments have always sought the common good and, therefore, the advancement of public and collective interests. This is key to understanding, as a first step, why the principles of public-sector organizations do not always match those of the private sector. Public and private perspectives are very different, whether they be management, strategy, or policy.",unknown,13,0.9018988609313964
10.59476/ilpmt2024.100-106,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Innovations in Publishing, Printing and Multimedia Technologies",2000-01-01 00:00:00,semantic_scholar,criteria for selecting artificial intelligence tools,https://www.semanticscholar.org/paper/2d88f0f218151f6f38f3888024ccff9e8c3ed0f7,"Artificial Intelligence (AI) represents a transformative force across numerous sectors, from healthcare and finance to automotive and public services. The selection and deployment of AI tools are critical to leveraging this technology’s potential while adhering to ethical standards, regulatory compliance, and ensuring societal benefit. The European Union (EU) has been at the forefront of establishing frameworks and criteria to guide the development, deployment, and selection of AI systems to foster innovation while protecting citizens’ rights and societal values. The EU’s proactive stance in establishing these criteria aims to balance innovation with ethical considerations and societal welfare, setting a benchmark for responsible AI development and deployment globally. The aim of the article is to present general criteria for the selection of artificial intelligence tools, as well as those specific to the field of publishing. The research was carried out based on the analysis of scientific and other sources. The results of the study can be useful for organizations and individuals that must be interested in selecting and using the right AI tools.",unknown,124,0.8998203277587891
10.1108/tg-06-2024-0131,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Transforming Government: People, Process and Policy",2000-01-01 00:00:00,semantic_scholar,"artificial intelligence and decision-making in government functions: opportunities, challenges and future research",https://www.semanticscholar.org/paper/305eeffe0bee53fa400a8ecad024f1c18c1280b8,"Purpose
Artificial intelligence (AI) has received much attention due to its promethean-like powers to transform the management and delivery of public sector services. Due to the proliferation of research articles in this context, research to date is fragmented into research streams based on different types of AI technologies or a specific government function of the public sector (e.g. health, education). The purpose of this study is to synthesize this literature, identify challenges and opportunities, and offer a research agenda that guides future inquiry.

Design/methodology/approach
This paper aggregates this fragmented body of knowledge by conducting a systematic literature review of AI research in public sector organisations in the Chartered Association of Business Schools (CABS)-ranked journals between 2012 and 2023.

Findings
The search strategy resulted in the retrieval of 2,870 papers, of which 61 were identified as primary papers relevant to this research. These primary papers are mapped to the ten classifications of the functions of government as classified by the Organisation for Economic Co-operation and Development (OECD), and the reported challenges and benefits aggregated.

Originality/value
This study advances knowledge by providing a state-of-the-art of AI research based the OECD classifications of government functions, reporting of claimed benefits and challenges and providing a research agenda for future research.
",unknown,119,0.8944896459579468
10.1177/09520767231170321,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Policy and Administration,2000-01-01 00:00:00,semantic_scholar,systematic and axiological capacities in artificial intelligence applied in the public sector,https://www.semanticscholar.org/paper/33be6d7c2d61bfac798a29e22ea0267e9fe16b05,"Artificial Intelligence (AI) as a technological development is being implemented in the public sector with the intention of improving service delivery, as well as to help solve complex problems. However, there is a wide range of capabilities that AI can perform and that public officials perceive and implement in different ways. This paper aims to describe and analyze some categories into which AI capabilities in the public sector are divided. Using an Exploratory Factor Analysis (EFA), our results show that the capabilities of AI from the perspective of public officials can be classified into two aspects: systematic factors and axiological factors. Systematic factors are related to the analysis and behavior of data, including monitoring, analyzing, interacting, remembering, and anticipation. Axiological factors refer to the impacts of values, ethics, and decisions, including acting, feeling, moralizing, creating, and deciding capacities. This categorization of AI capabilities in the public sector sheds light on the perception of public officials about the implementation of this technological development.",unknown,46,0.89023357629776
10.1108/dts-03-2023-0018,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Transformation and Society,2000-01-01 00:00:00,semantic_scholar,"artificial intelligence, task complexity and uncertainty: analyzing the advantages and disadvantages of using algorithms in public service delivery under public administration theories",https://www.semanticscholar.org/paper/34ca9b143e721bfd8dc8eb29d6352a68b9c82a19,"PurposeThis article revisits some theories and concepts of public administration, including those related to public value, transaction costs and social equity, to analyze the advantages and disadvantages of using artificial intelligence (AI) algorithms in public service delivery. The author seeks to mobilize theory to guide AI-era public management practitioners and researchers.Design/methodology/approachThe author uses an existing task classification model to mobilize and juxtapose public management theories against artificial intelligence potential impacts in public service delivery. Theories of social equity and transaction costs as well as some concepts such as red tape, efficiency and economy are used to argue that the discipline of public administration provides a foundation to ensure algorithms are used in a way that improves service delivery.FindingsAfter presenting literature on the challenges and promises of using AI in public service, the study shows that while the adoption of algorithms in public service has benefits, some serious challenges still exist when looked at under the lenses of theory. Additionally, the author mobilizes the public administration concepts of agenda setting and coproduction and finds that designing AI-enabled public services should be centered on citizens who are not mere customers. As an implication for public management practice, this study shows that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Research limitations/implicationsAs a fast-growing subject, artificial intelligence research in public management is yet to empirically test some of the theories that the study presented.Practical implicationsThe paper vulgarizes some theories of public administration which practitioners can consider in the design and implementation of AI-enabled public services. Additionally, the study shows practitioners that bringing citizens to the forefront of designing and implementing AI-delivered services is key to reducing the reproduction of social biases.Social implicationsThe paper informs a broad audience who might not be familiar with public administration theories and how those theories can be taken into consideration when adopting AI systems in service delivery.Originality/valueThis research is original, as, to the best of the author’s knowledge, no prior work has combined these concepts in analyzing AI in the public sector.",unknown,55,0.8899549245834351
http://arxiv.org/abs/2410.01819v1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',arxiv,arxiv,2024-09-16 00:00:00,arxiv,strategic ai governance: insights from leading nations,http://arxiv.org/abs/2410.01819v1,"Artificial Intelligence (AI) has the potential to revolutionize various
sectors, yet its adoption is often hindered by concerns about data privacy,
security, and the understanding of AI capabilities. This paper synthesizes AI
governance approaches, strategic themes, and enablers and challenges for AI
adoption by reviewing national AI strategies from leading nations. The key
contribution is the development of an EPIC (Education, Partnership,
Infrastructure, Community) framework, which maps AI implementation requirements
to fully realize social impacts and public good from successful and sustained
AI deployment. Through a multi-perspective content analysis of the latest AI
strategy documents, this paper provides a structured comparison of AI
governance strategies across nations. The findings offer valuable insights for
governments, academics, industries, and communities to enable responsible and
trustworthy AI deployments. Future work should focus on incorporating specific
requirements for developing countries and applying the strategies to specific
AI applications, industries, and the public sector.",unknown,0,0.8899304270744324
10.1108/ijoes-05-2023-0107,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Journal of Ethics and Systems,2000-01-01 00:00:00,semantic_scholar,ethical issues in the development of artificial intelligence: recognizing the risks,https://www.semanticscholar.org/paper/00c3e0b19febce5d401c5955482e95dadaf184c0,"
Purpose
This study aims to analyse the ethical implications associated with the development of artificial intelligence (AI) technologies and to examine the potential ethical ramifications of AI technologies.


Design/methodology/approach
This study undertakes a thorough examination of existing academic literature pertaining to the ethical considerations surrounding AI. Additionally, it conducts in-depth interviews with individuals to explore the potential benefits and drawbacks of AI technology operating as autonomous ethical agents. A total of 20 semi-structured interviews were conducted, and the data were transcribed using grounded theory methodology.


Findings
The study asserts the importance of fostering an ethical environment in the progress of AI and suggests potential avenues for further investigation in the field of AI ethics. The study finds privacy and security, bias and fairness, trust and reliability, transparency and human–AI interactions as major ethical concerns.


Research limitations/implications
The implications of the study are far-reaching and span across various domains, including policy development, design of AI systems, establishment of trust, education and training, public awareness and further research. Notwithstanding the potential biases inherent in purposive sampling, the constantly evolving landscape of AI ethics and the challenge of extrapolating findings to all AI applications and contexts, limitations may still manifest.


Originality/value
The novelty of the study is attributed to its comprehensive methodology, which encompasses a wide range of stakeholder perspectives on the ethical implications of AI in the corporate sector. The ultimate goal is to promote the development of AI systems that exhibit responsibility, transparency and accountability.
",unknown,66,0.8874778747558594
10.1145/3636550,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digit. Gov. Res. Pract.,2000-01-01 00:00:00,semantic_scholar,introduction to the issue on artificial intelligence in the public sector: risks and benefits of ai for governments,https://www.semanticscholar.org/paper/37eb0c2177acf85c74ace80a9365d610523bc64b,"Artificial Intelligence (AI) is increasingly adopted by public sector organizations to provide better public services and to transform their internal processes. AI is now considered a key enabler for digital innovation and transformation in the public sector. However, AI is still relatively a new research area in the field of digital government. The term, AI, captures a wide range of technologies, techniques, and tools such as machine/deep learning, natural language processing, robotics, computer vision, and more recently Generative AI. While these AI technologies afford different applications and benefits in the government context, they also create social, ethical, and legal challenges. These challenges require solutions combining both technical (e.g., data and algorithmic solutions to minimize bias) and institutional (e.g., governance structures and processes) mechanisms. The special issue is a collection of articles that contribute to a better understanding of the issues associated with AI deployment in different areas of government operations. They cover AI applications in the areas of emergency response, policy analysis, public bids, and citizen participation. The contributions also address the challenge of realizing a legal transparency regime for AI in government and the effect of AI in bureaucratic decision-making.",unknown,92,0.8825056552886963
10.48550/arxiv.2210.17218,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Grid Computing,2022-01-01 00:00:00,semantic_scholar,"artificial intelligence in government: concepts, standards, and a unified framework",https://www.semanticscholar.org/paper/2afd1d3199326dc8a9184a5152616f5cfda1e2e6,"Recent advances in artificial intelligence (AI), especially in generative language modelling, hold the promise of transforming government. Given the advanced capabilities of new AI systems, it is critical that these are embedded using standard operational procedures, clear epistemic criteria, and behave in alignment with the normative expectations of society. Scholars in multiple domains have subsequently begun to conceptualize the different forms that AI applications may take, highlighting both their potential benefits and pitfalls. However, the literature remains fragmented, with researchers in social science disciplines like public administration and political science, and the fast-moving fields of AI, ML, and robotics, all developing concepts in relative isolation. Although there are calls to formalize the emerging study of AI in government, a balanced account that captures the full depth of theoretical perspectives needed to understand the consequences of embedding AI into a public sector context is lacking. Here, we unify efforts across social and technical disciplines by first conducting an integrative literature review to identify and cluster 69 key terms that frequently co-occur in the multidisciplinary study of AI. We then build on the results of this bibliometric analysis to propose three new multifaceted concepts for understanding and analysing AI-based systems for government (AI-GOV) in a more unified way: (1) operational fitness, (2) epistemic alignment, and (3) normative divergence. Finally, we put these concepts to work by using them as dimensions in a conceptual typology of AI-GOV and connecting each with emerging AI technical measurement standards to encourage operationalization, foster cross-disciplinary dialogue, and stimulate debate among those aiming to rethink government with AI.",unknown,26,0.8791075944900513
10.1145/3657054.3657278,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,examining public sector ai adoption: mechanisms for ai adoption in the absence of authoritative strategic direction,https://www.semanticscholar.org/paper/b29a09098db3c5e67bba3b50ea8627a27258f65b,"Artificial Intelligence (AI) is recognized to bring great benefits to the organizations that can successfully adopt this emerging technological domain into their operations. This paper examines the impact of governance and strategic direction on AI adoption and diffusion in a public sector setting. By presenting contextual conditions, mechanisms, and outcomes within a large government agency this work contributes to the understanding of how the absence of appropriate governance structures and strategies impact the development and adoption of AI. Findings show that balancing exploitation and exploration in the capillaries of the organization proved crucial to the adoption and diffusion of AI. This manifested itself through three mechanisms, Cross-domain learning, Legal priming, and Ecosystem growth, which enabled the organization to obtain both value creation and value capture.",unknown,99,0.8780696988105774
10.1016/bs.adcom.2023.08.001,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85174467151,scopus,2024-01-01,scopus,why is implementing computational intelligence for social good so challenging? principles and its application,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85174467151&origin=inward,"
                  Computational intelligence (CI) has the potential to help tackle some of the world's most challenging social problems. Real-life examples of AI are already being applied in about one-third of these use cases They range from diagnosing cancer to helping blind people navigate their surroundings, identifying victims of online sexual exploitation, and aiding disaster-relief efforts etc. AI is only part of a much broader tool kit of measures that can be used to tackle societal issues, however. For now, issues such as data accessibility and shortages of AI talent constrain its application for social good. This chapter has grouped use cases into 10 social-impact domains based on taxonomies in use among social-sector organizations. Each use case highlights a type of meaningful problem that can be solved by one or more AI capability. The cost of human suffering, and the value of alleviating it, are impossible to gauge and compare. Nonetheless, employing usage frequency as a proxy, we measure the potential impact of different AI capabilities.
               ",unknown,238,0.8778115510940552
10.37417/rdp/vol_8_2023_1949,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Revista de Derecho Público: Teoría y método,2000-01-01 00:00:00,semantic_scholar,artificial intelligence challenging core state functions,https://www.semanticscholar.org/paper/5a392bc0fd61b7e062d95d6ed819bd347bae4480,"The use of AI in the public sector is emerging around the world and its spread affects the core States functions: the administrative, the judiciary, and the legislative. Nevertheless, a comprehensive approach to AI in the life-cycle of rules - from the proposal of a new rule to its implementation, monitoring and review- is currently lacking in the rich panorama of studies from different disciplines. The analysis shows that AI has the power to play a crucial role in the life-cycle of rules, by performing time-consuming tasks, increasing access to knowledge base, and enhancing the ability of institutions to draft effective rules and to declutter the regulatory stock. However, it is not without risks, ranging from discrimination to challenges to democratic representation. In order to play a role in achieving law effectiveness while limiting the risks, a complementarity between human and AI should be reached both at the level of the AI architecture and ex post. Moreover, an incremental and experimental approach is suggested, as well as the elaboration of a general framework, to be tailored by each regulator to the specific features of its tasks, aimed at setting the rationale, the role, and adequate guardrails to AI in the life-cycle of rules. This agile approach would allow the AI revolution to display its benefits while preventing potential harms or side effects.",unknown,51,0.8755556344985962
http://arxiv.org/abs/1906.05684v1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',arxiv,arxiv,2019-06-11 00:00:00,arxiv,understanding artificial intelligence ethics and safety,http://arxiv.org/abs/1906.05684v1,"A remarkable time of human promise has been ushered in by the convergence of
the ever-expanding availability of big data, the soaring speed and stretch of
cloud computing platforms, and the advancement of increasingly sophisticated
machine learning algorithms. Innovations in AI are already leaving a mark on
government by improving the provision of essential social goods and services
from healthcare, education, and transportation to food supply, energy, and
environmental management. These bounties are likely just the start. The
prospect that progress in AI will help government to confront some of its most
urgent challenges is exciting, but legitimate worries abound. As with any new
and rapidly evolving technology, a steep learning curve means that mistakes and
miscalculations will be made and that both unanticipated and harmful impacts
will occur.
  This guide, written for department and delivery leads in the UK public sector
and adopted by the British Government in its publication, 'Using AI in the
Public Sector,' identifies the potential harms caused by AI systems and
proposes concrete, operationalisable measures to counteract them. It stresses
that public sector organisations can anticipate and prevent these potential
harms by stewarding a culture of responsible innovation and by putting in place
governance processes that support the design and implementation of ethical,
fair, and safe AI systems. It also highlights the need for algorithmically
supported outcomes to be interpretable by their users and made understandable
to decision subjects in clear, non-technical, and accessible ways. Finally, it
builds out a vision of human-centred and context-sensitive implementation that
gives a central role to communication, evidence-based reasoning, situational
awareness, and moral justifiability.",unknown,2,0.8733505010604858
10.1145/3643690.3648235,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,2024 IEEE/ACM International Workshop on Software-Intensive Business (IWSiB),2000-01-01 00:00:00,semantic_scholar,artificial intelligence in the public sector - an agenda for responsible innovation through learning,https://www.semanticscholar.org/paper/b727d48a8a9ce8ac56fc3a164c2a7a4628093550,"The optimism about the benefits of using artificial intelligence to innovate public services is tempered by concerns about its risks, limitations, and disbenefits. Given the rapid changes in the technol-ogy itself, the opportunities and needs for cross-sectional solutions, and the nascency of the field of AI-based innovation, we contend that policy, strategy, and implementation must include feedback loops that enable institutional learning for the entire public sec-tor. The scope of challenges creates and imperative to facilitate learning must transcend functional, organizational, geographic, and national boundaries. We propose a learning agenda that in-cludes 1) alignment of strategy and policy; 2) initial understanding of goals, benefits, disbenefits, limitations, and risks; 3) data sharing across jurisdictions; 4) technical robustness and societal alignment in governmental oversight; 5) convergence of architecture for AI support; and 6) a portfolio approach to selecting and learning from enabling service innovation with AI.",unknown,96,0.8725483417510986
10.28995/2782-2222-2024-1-56-69,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Science and art of management / Bulletin of the Institute of Economics, Management and Law of the Russian State University for the Humanities",2000-01-01 00:00:00,semantic_scholar,"artificial intelligence in russia. history, status, trends and limitations",https://www.semanticscholar.org/paper/c3dcdb50f9979d435a3999fc6a7737b22b368cbe,"A new stage in the introduction of artificial intelligence into everyday life in Russia will be the mass introduction of its technologies and products based on it into the public administration system and the government sector. Today, AI is used in most spheres of public life, but its level of development is still not high enough. In that regard, the issues considered in the publication are modern and relevant and can be used at the stages of development and use of AI. The authors clarified the definition of “artificial intelligence”, analyzed the directions of AI development and identified promising areas of the most accelerated technological development of intelligent systems: generative, voice and language, explicable and peripheral AI with characteristics of the stages up to the present. Two main criteria of AI are analyzed: “strong AI” and “weak AI” and their fundamental differences are considered. The article presents results of a brief analysis of the state and plans for the development of AI in Russia. The level of AI implementation in economic sectors reaches 20% and that is not enough to ensure accelerated economic growth. It is assumed that the introduction of AI should provide an additional 1.2% increase in global GDP by 2030, and our country plans to gain more than 11 trillion rubles from its use by 2025. The future of artificial intelligence in Russia was determined by the President of the country at the St. Petersburg International Forum (PEMF-2023). The announced directions will make it possible to unlock the potential of AI more widely and ensure its mass implementation for the formation of Russia’s sovereignty.",unknown,106,0.8715535402297974
10.31516/2410-5325.083.02,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Culture of Ukraine,2000-01-01 00:00:00,semantic_scholar,artificial intelligence through the prism of thematic research on researchgate web portal,https://www.semanticscholar.org/paper/2ca8e568a7c9cf3ad7368fd8b6b6a327f0eb35f1,"Different instances of generative artificial intelligence (GenAI) in a short time have made a significant impact on the world’s economic and political scene. Before October 2022, processes of automatization and robotization of manufacturing didn’t have an immediate connection with artificial intelligence in the minds of most people. But mass and sudden infiltration of GenAI into the everyday life of many people around the world caused an immediate reaction from scientists, public figures, politicians, managers and heads of whole sectors of the economy. Thousands of scientific articles on related topics were published in the last two years: everyone at once started talking about fantastic possibilities, and also threats, which this new technology can usher in for our societies. Thus, for public thinking GenAI finally linked automatization with artificial intelligence. 
This paper provides an analysis of problems and prospects, through which scientists are trying to understand different societal processes linked to adoption of AI. For this purpose, the author of this paper analyzed the contents of papers published on this topic on the ResearchGate web portal in 2023, with the choice of the source for representative material motivated by scientific credibility of ResearchGate combined with its wide reach. Ten most popular articles were specifically targeted for final analysis, through which societal trends brought on by AI adoption were described. Although a selective meta-analysis of articles published during the first year after ChatGPT release can’t provide a full understanding of AI potential and possible threats to society, the conclusion can still be reached that a cardinal shift in society’s attitudes towards its own future is required. 
From the ten articles analyzed, four are related to changes required to the education system, four are about AI’s influence on the labour market, one article talks about the possibility of AI-human competition and one is about the AI potential in agriculture. Most articles mention the need for legislative changes in terms of labor protection and education reforms in-line with new digital reality.",unknown,123,0.8710179328918457
10.1145/3514094.3539563,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"AAAI/ACM Conference on AI, Ethics, and Society",2022-01-01 00:00:00,semantic_scholar,the opacity of automated decision-making systems (adms) and its challenges for political legitimacy in a democracy,https://www.semanticscholar.org/paper/4d14d554a9d6359f1faba70abb530ae03fe7eb89,"This paper focuses specifically on Automated Decision-Making Systems (ADMS) based on Artificial Intelligence (AI). Since the last decades, AI systems are increasingly deployed by governments across the planet to manage public infrastructures and resources, as well as to engage with citizens for the provision of public services. Their introduction is advertised as a cost-cutting tool, as well as an instrument to combat traditional institutional disfunctions such as inefficiency, understaffing, corruption and human bias. While AI offers an incredible potential for progress, an emerging body of literature highlights the challenges that AI-driven decision-making may raise for a public sector ethics. A common trait of these challenges is their being related to some form of ""epistemological opacity"" that undermines the capacity of humans to explain and justify decisions based on AI systems, detect errors or unfairness and adopt corrective actions. The situation may entail public officers and citizens taking the outcomes of AI systems at face value, thus basing their actions (wholly or in part) on pieces of information that cannot be scrutinized and/or corrected if necessary. This paper intends to contribute to an emerging but still underdeveloped trend in normative political theory that study how AI-driven decision-making is reshaping the conceptualization and assessment of interactions between citizens and public officials. The overall goal of the paper is to analyze how various sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) affecting AI systems, may undermine the democratic legitimacy of public decisions based on them. Broadly speaking, legitimacy is the property that grounds the exercise of political authority, where authority standardly means the right to rule [1]. In this paper, democratic legitimacy is understood as a distinctive form of political authority grounded in the recognition of citizens as joint legislators. The paper offers a conception of democratic legitimacy conditional on the capacity of decision-making procedures and outcomes to realize the principle of public equality, which requires citizens' control over public decision-making, as well as respect for their equal status as political decision-makers. Specifically, the paper argues that the ""epistemological opacity"" affecting AI-driven decision-making systems, brings about a mistreatment of citizens as coauthors of public decisions, which is a premise of the idea of democratic citizenship. The main conjecture is that different sources of ""epistemological opacity"" (algorithmic/legal/illiteracy/discursive) are causing the disengagement of citizens and public officers from public decision-making, either because they directly undermine necessary conditions for the realization of public equality (co-authorship/accountability/publicity), or because they hide from the public eye instances of illegitimate automation and privatization of decisional power. The paper offers a normative conception of democratic legitimacy that may contribute to efforts in various fields, including ""AI fairness"" and ""Explainable AI"", to better adapt technological tools to equality requirements distinctive of public decision-making within democratic societies.",unknown,37,0.8702366352081299
10.1016/j.giq.2021.101596,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85108562674,scopus,2022-10-01,scopus,enabling ai capabilities in government agencies: a study of determinants for european municipalities,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85108562674&origin=inward,"Artificial Intelligence (AI) is gradually becoming an integral part of the digital strategy of organizations. Yet, the use of AI in public organizations in still lagging significantly compared to private organizations. Prior literature looking into aspects that facilitate adoption and use of AI has concentrated on challenges concerning technical aspects of AI technologies, providing little insight regarding the organizational deployment of AI, particularly in public organizations. Building on this gap, this study seeks to examine what aspects enable public organizations to develop AI capabilities. To answer this question, we built an integrated and extended model from the Technology-Organization-Environment framework (TOE) and asked high-level technology managers from municipalities in Europe about factors that influence their development of AI capabilities. We collected data from 91 municipalities from three European countries (i.e., Germany, Norway, and Finland) and analyzed responses by means of structural equation modeling. Our findings indicate that five factors – i.e. perceived financial costs, organizational innovativeness, perceived governmental pressure, government incentives, regulatory support – have an impact on the development of AI capabilities. We also find that perceived citizen pressure and perceived value of AI solutions are not important determinants of AI capability formation. Our findings bear the potential to stimulate a more reflected adoption of AI supporting managers in public organizations to develop AI capabilities.",unknown,297,0.8688088655471802
10.48550/arxiv.2401.01291,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,arXiv.org,2000-01-01 00:00:00,semantic_scholar,generative ai is already widespread in the public sector,https://www.semanticscholar.org/paper/6d67a918707f0c20cb847d4d4611b34877ccd5e6,"Generative AI has the potential to transform how public services are delivered by enhancing productivity and reducing time spent on bureaucracy. Furthermore, unlike other types of artificial intelligence, it is a technology that has quickly become widely available for bottom-up adoption: essentially anyone can decide to make use of it in their day to day work. But to what extent is generative AI already in use in the public sector? Our survey of 938 public service professionals within the UK (covering education, health, social work and emergency services) seeks to answer this question. We find that use of generative AI systems is already widespread: 45% of respondents were aware of generative AI usage within their area of work, while 22% actively use a generative AI system. Public sector professionals were positive about both current use of the technology and its potential to enhance their efficiency and reduce bureaucratic workload in the future. For example, those working in the NHS thought that time spent on bureaucracy could drop from 50% to 30% if generative AI was properly exploited, an equivalent of one day per week (an enormous potential impact). Our survey also found a high amount of trust (61%) around generative AI outputs, and a low fear of replacement (16%). While respondents were optimistic overall, areas of concern included feeling like the UK is missing out on opportunities to use AI to improve public services (76%), and only a minority of respondents (32%) felt like there was clear guidance on generative AI usage in their workplaces. In other words, it is clear that generative AI is already transforming the public sector, but uptake is happening in a disorganised fashion without clear guidelines. The UK's public sector urgently needs to develop more systematic methods for taking advantage of the technology.",unknown,93,0.8637311458587646
10.48550/arxiv.2408.00965,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,arXiv.org,2000-01-01 00:00:00,semantic_scholar,integrating esg and ai: a comprehensive responsible ai assessment framework,https://www.semanticscholar.org/paper/15b153e0f6342ad455bfb5e2b6090b89c8066340,"Artificial Intelligence (AI) is a widely developed and adopted technology across entire industry sectors. Integrating environmental, social, and governance (ESG) considerations with AI investments is crucial for ensuring ethical and sustainable technological advancement. Particularly from an investor perspective, this integration not only mitigates risks but also enhances long-term value creation by aligning AI initiatives with broader societal goals. Yet, this area has been less explored in both academia and industry. To bridge the gap, we introduce a novel ESG-AI framework, which is developed based on insights from engagements with 28 companies and comprises three key components. The framework provides a structured approach to this integration, developed in collaboration with industry practitioners. The ESG-AI framework provides an overview of the environmental and social impacts of AI applications, helping users such as investors assess the materiality of AI use. Moreover, it enables investors to evaluate a company's commitment to responsible AI through structured engagements and thorough assessment of specific risk areas. We have publicly released the framework and toolkit in April 2024, which has received significant attention and positive feedback from the investment community. This paper details each component of the framework, demonstrating its applicability in real-world contexts and its potential to guide ethical AI investments.",unknown,146,0.8637049794197083
10.1177/0266382120923962,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Business Information Review,2020-01-01 00:00:00,semantic_scholar,regulation and ethics in artificial intelligence and machine learning technologies: where are we now? who is responsible? can the information professional play a role?,https://www.semanticscholar.org/paper/4ae7b75e7b0fdf00a687c8f308ceccbe26c24e8d,"Artificial intelligence (AI) and machine learning (ML) technologies are rapidly maturing and proliferating through all public and private sectors. The potential for these technologies to do good and to help us in our everyday lives is immense. But there is a risk that unless managed and controlled AI can also cause us harm. Questions about regulation, what form it takes and who is responsible for governance are only just beginning to be answered. In May 2019, 42 countries came together to support a global governance framework for AI. The Organisation for Economic Co-operation and Development (OECD) Principles on Artificial Intelligence (OECD (2019) OECD principles on AI. Available at: https://www.oecd.org/going-digital/ai/principles/ (accessed 2 March 2020)) saw like-minded democracies of the world commit to common AI values of trust and respect. In Europe, the European Commission’s (EC) new president, Ursula von der Leyen has made calls for a General Data Protection Regulation style. As a first step the EC has published a white paper: ‘On Artificial Intelligence – A European Approach to Excellence and Trust’ (European Commission (2020) Report, Europa, February). In February 2020, the UK government has published a report on ‘Artificial Intelligence in the Public Sector’ (The Committee on Standards in Public Life (2020) Artificial intelligence and public standards. Report, UK Government, February). This article discusses some of the potential threats AI may hold if left unregulated. It provides a brief overview of the regulatory activities for AI worldwide, and in more detail the current UK AI regulatory landscape. Finally, the article looks at the role that the information professional might play in AI and ML.",unknown,16,0.8626872301101685
10.1016/j.giq.2023.101828,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85151401656,scopus,2023-06-01,scopus,whether ai adoption challenges matter for public managers? the case of polish cities,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85151401656&origin=inward,"
                  A growing body of literature shows that despite the significant benefits of artificial intelligence (AI), its adoption has many unknowns and challenges. However, theoretical studies dominate this topic. Completing the recent works, this article aims to identify challenges faced by public organizations when adopting AI based on the PRISMA Framework and an empirical assessment of these challenges in the opinion of public managers using survey research. The adopted research procedure is also an added value because it could be replicated in other context scenarios. To achieve this paper's aim, the Systematic Literature Review (SLR) and survey research among authorities in 414 Polish cities were carried out. As a result, a list of 15 challenges and preventive activities proposed by researchers to prevent these challenges have been identified. Empirical verification of identified challenges allows us to determine which of them limit AI adoption to the greatest extent in public managers' opinion. These include a lack of strategy or plans to initial adoption / continued usage of AI; no ensuring that AI is used in line with human values; employees' insufficient knowledge of how to use AI; insufficient AI policies, laws, and regulations; and different expectations of stakeholders and partners about AI. These findings could help practitioners to prioritize AI adoption activities and add value to digital government theory.
               ",unknown,266,0.8619892001152039
10.1145/3657054.3657125,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,comparative analysis of generative ai risks in the public sector,https://www.semanticscholar.org/paper/cf2a8c29efde5517cc86378ade038d6974930b6a,"The landscape of artificial intelligence (AI) has experienced a monumental shift with the emerging of Generative AI (GenAI), which has demonstrated to be a transformative tool across diverse sectors. GenAI outputs can span various digital formats, including text, images, videos, and audio, generating particular interest in the public sector. The growing interest of governments in integrating GenAI technologies in public sector operations is marked by the creation of emerging governance instruments and the formulation of soft laws, like standards, principles, and guidelines. This study aims to delve into the intricacies and potential risks associated with the deployment of GenAI within government. Through a qualitative content analysis, the research meticulously examines GenAI usage guidelines issued by Australia, Canada, New Zealand, the United Kingdom, and South Korea. The objective is to discern the risks acknowledged by these countries' soft laws and compare them with the risks identified by scholars in the field. The performed comparative analysis across countries suggest that the use of GenAI in the public sector raises common risks such as information leakage, data privacy, security, and concerns over public trust. By elucidating the varied risk perceptions across different national contexts, this study provides theoretical and practical implications related to the risks of GenAI within the public sector. Moreover, it sets a foundation for future research and policy development, ensuring that generative AI is used as a force for good in public governance.",unknown,94,0.8618203401565552
10.5937/napredak5-52069,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Napredak,2000-01-01 00:00:00,semantic_scholar,the transformative potential of generative artificial intelligence,https://www.semanticscholar.org/paper/2e6e0c741d6c83f12dfac4e02b570c64b9aa0bf7,"This paper analyses the transformative potential of generative artificial intelligence at macro, meso, and micro levels of social and economic structures. The aim is to determine the impact of these technologies on various aspects of society and economy, including business operations and the labour market. The potential of new technologies to increase productivity, transform business models, and create new professional roles has been examined through a comprehensive analysis of data and studies. It has been concluded that generative artificial intelligence can fundamentally change the labour market, globally increase gross domestic product, and improve both the public and private sectors. The paper provides insights into future trends and regulatory and structural changes that are necessary for optimising the application of generative AI.",unknown,110,0.8583669066429138
10.1145/3219819.3226071,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Knowledge Discovery and Data Mining,2018-01-01 00:00:00,semantic_scholar,societal impact of data science and artificial intelligence,https://www.semanticscholar.org/paper/9dacbc65c23215f79a9a966abf8c403175e56aa8,"The explosion of interest in KDD and other Data Science/Machine Learning/AI conferences is just one of the many signs that these technologies are no longer confined to the realms of academia and a hand-full of tech companies. As our daily lives seamlessly integrate more and more data-driven applications, people's excitement is tempered by worry about the technologies' potential to disrupt their existence. Having worked for almost 30 years to design and develop these technologies, the KDD community now should examine and debate the impact of Machine Learning & AI on the broader world. Beyond the hype, where do we stand with respect to the dangers? What role can our community play to alleviate concerns around AI taking jobs, or taking over? How can the value derived from data be distributed fairly? Are concerns about inequity well-founded or rather largely problems of perception? What can be done to bring data hunger and data sharing concerns to a level of equilibrium? How do we prepare people to interact with intelligent systems at scale? Can we unleash the incredible responsiveness of the KDD community toward longer-term more impactful projects across sectors that are essential for social good, such as Health, Environmental Sustainability, and Public Welfare.",unknown,6,0.8575162887573242
10.1016/j.procs.2022.01.308,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85127772806,scopus,2022-01-01,scopus,human-centered artificial intelligence for the public sector: the gate keeping role of the public procurement professional,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85127772806&origin=inward,"The increasing deployment of artificial intelligence (AI) powered solutions for the public sector is hoped to change how developing countries deliver services in key sectors such as agriculture, healthcare, education, and social sectors. And yet AI has a high potential for abuse and creates risks, which if not managed and monitored will jeopardize respect and dignity of the most vulnerable in society. In this study, we argue for delineating public procurements’ role in the human-centred AI (HCAI) discourses, focusing on the developing countries. The study is based on an exploratory inquiry and gathered data among procurement practitioners in Uganda and Kenya, which have similar country procurement regimes: where traditional forms of competition in procurement apply compared to more recent pre-commercial procurement mechanisms that suit AI procurement. We found limited customization in AI technologies, a lack of developed governance frameworks, and little knowledge and distinction between AI procurement and other typical technology procurement processes. We proposed a framework, which in absence of good legal frameworks can allow procurement professionals to embed HCAI principles in AI procurement processes.",unknown,326,0.8569608926773071
10.1145/3325112.3325261,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2019-01-01 00:00:00,semantic_scholar,a realist perspective on ai-era public management*,https://www.semanticscholar.org/paper/ed5fbb58585ae1e9154ade1b4639060ace9c45ec,"Recent years have witnessed a number of significant ideas and approaches to addressing the shortcomings of the New Public Management paradigm. Three of these recent ideas, which include Digital Era Governance, Public Value Management, and New Public Governance, emphasise partnerships collaboration and engagement of citizens; performance governance and innovation and recognize the transformational potentials of digital technologies. Artificial Intelligence (AI) is one of the digital technologies attracting the greatest interest in public administration in terms of its potential impact. There are already a number of reports on how AI is being deployed in the public sector with good outcomes. By employing a realist review approach, this study investigates the specific mechanisms across post-NPM, organisational, individual and innovation contexts which are associated with positive outcomes from AI initiatives in the public sector. The study further examined the specific applications of AI initiatives within Post-NPM agendas. Our findings provide some empirical evidence for a better understanding of the conditions and where to target AI-based solutions in post-NPM context for positive outcomes.",unknown,8,0.8486554622650146
10.1109/mts.2023.3341463,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',core,core,2024-01-22T00:00:00,core,the stuff we swim in: regulation alone will not lead to justifiable trust in ai,https://core.ac.uk/download/598038913.pdf,"Recent activity in the field of artificial intelligence (AI) has given rise to large language models (LLMs) such as GPT-4 and Bard. These are undoubtedly impressive achievements, but they raise serious questions about appropriation, accuracy, explainability, accessibility, responsibility, and more. There have been pusillanimous and self-exculpating calls for a halt in development by senior researchers in the field and largely self-serving comments by industry leaders around the potential of AI systems, good or bad. Many of these commentaries leverage misguided conceptions, in the popular imagination, of the competence of machine intelligence, based on some sort of Frankenstein or Terminator-like fiction: however, this leaves it entirely unclear what exactly the relationship between human(ity) and AI, as represented by LLMs or what comes after, is or could be",unknown,446,0.8464511632919312
10.61969/jai.1512906,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of AI,2000-01-01 00:00:00,semantic_scholar,"super ai, generative ai, narrow ai and chatbots: an assessment of artificial intelligence technologies for the public sector and public administration",https://www.semanticscholar.org/paper/be2fc5c4d3e7774f9bccdab34ad9f3e5fb7fff51,"Artificial intelligence encompasses a wide range of approaches, methodologies, and techniques aimed at mimicking human intelligence in machines. In recent times, the concepts of Generative Artificial Intelligence (AI), Super AI, and Narrow AI have attracted considerable attention. Undoubtedly, the success of ChatGPT in capturing all attention has played a significant role in this. Artificial intelligence technology has a profound impact on all sectors, and sector representatives are striving to adapt to this technology more quickly. It is projected that artificial intelligence could generate an economic size of 13 trillion American dollars by 2030. Developments in artificial intelligence technologies undoubtedly lead to significant improvements in the functioning of public institutions and access for citizens. Artificial intelligence has the potential to be used in many public services, including security and defense, healthcare services, education, transportation and infrastructure, environmental and natural resource management, law and justice systems, among others. Therefore, evaluating the types of artificial intelligence, Narrow AI applications, and chatbots for public use is seen as highly beneficial from the perspective of public administration and the public sector. In our study, the topics of super artificial intelligence, generative artificial intelligence, narrow artificial intelligence, and chatbots have been extensively evaluated within the context of the public sector and public administration. Utilizing findings from both Turkish and English literature reviews, the importance and potential impacts of artificial intelligence within the public sector, along with current trends, have been comprehensively assessed. This research delves into the concepts of artificial intelligence and its subsets—super AI, generative AI, narrow AI, and chatbots—within the general framework of the public sector. China and the United States are pioneering and leading countries in terms of investment. Although the U.S. stands out in many areas regarding investment, China's integration of artificial intelligence with national strategies and its policies indicate that it may play a more dominant role in the future. There are four main implementation areas of artificial intelligence in the public sector: efficiency and automation, service delivery, data-driven governance, and ethical and regulatory challenges. A review of the literature reveals that the ethical, legal, and social implications of implementing artificial intelligence in the public sector require more careful consideration. The study makes a significant contribution to the field of artificial intelligence discussions in public administration and the public sector, providing a comprehensive assessment of current discussions on artificial intelligence in the literature.",unknown,91,0.8452226519584656
10.1080/15265161.2022.2135875,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,American Journal of Bioethics,2022-01-01 00:00:00,semantic_scholar,an ai bill of rights: implications for health care ai and machine learning—a bioethics lens,https://www.semanticscholar.org/paper/6a16d761ca5f28fca358b64db53f3cedbd4d83a1,"Just last week (October 4, 2022), the U.S. White House released a blueprint for an A.I. Bill of Rights, consisting of “five principles and associated practices to help guide the design, use, and deployment of automated systems to protect the rights of the American public in the age of artificial intelligence.” The white paper states, “Developed through extensive consultation with the American public, these principles are a blueprint for building and deploying automated systems that are aligned with democratic values and protect civil rights, civil liberties, and privacy.” It further articulates that, “this framework provides a national values statement and toolkit that is sector-agnostic to inform building these protections into policy, practice, or the technological design process. Where existing law or policy—such as sector-specific privacy laws and oversight requirements—do not already provide guidance, the Blueprint for an AI Bill of Rights should be used to inform policy decisions” (Office of Science and Technology 2022). I applaud the development of this blueprint, but, after briefly describing each principle, highlight some challenges and questions that bioethicists working on AI and machine learning in health care ought to consider.",unknown,34,0.8439810872077942
10.1016/j.techsoc.2024.102471,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85184027069,scopus,2024-03-01,scopus,trustworthy ai in the public sector: an empirical analysis of a swedish labor market decision-support system,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85184027069&origin=inward,"This paper investigates the deployment of Artificial Intelligence (AI) in the Swedish Public Employment Service (PES), focusing on the concept of trustworthy AI in public decision-making. Despite Sweden's advanced digitalization efforts and the widespread application of AI in the public sector, our study reveals significant gaps between theoretical ambitions and practical outcomes, particularly in the context of AI's trustworthiness. We employ a robust theoretical framework comprising Institutional Theory, the Resource-Based View (RBV), and Ambidexterity Theory, to analyze the challenges and discrepancies in AI implementation within PES. Our analysis shows that while AI promises enhanced decision-making efficiency, the reality is marred by issues of transparency, interpretability, and stakeholder engagement. The opacity of the neural network used by the agency to assess jobseekers’ need for support and the lack of comprehensive technical understanding among PES management contribute to the challenges in achieving transparent and interpretable AI systems. Economic pressures for efficiency often overshadow the need for ethical considerations and stakeholder involvement, leading to decisions that may not be in the best interest of jobseekers. We propose recommendations for enhancing AI's trustworthiness in public services, emphasizing the importance of stakeholder engagement, particularly involving jobseekers in the decision-making process. Our study advocates for a more nuanced balance between the use of advanced AI technologies and the leveraging of internal resources such as skilled personnel and organizational knowledge. We also highlight the need for improved AI literacy among both management and personnel to effectively navigate AI's integration into public decision-making processes. Our findings contribute to the ongoing debate on trustworthy AI, offering a detailed case study that bridges the gap between theoretical exploration and practical application. By scrutinizing the AI implementation in the Swedish PES, we provide valuable insights and guidelines for other public sector organizations grappling with the integration of AI into their decision-making processes.",unknown,225,0.8432661294937134
10.1145/3657054.3657126,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,gai as a catalyst in national technology sovereignty: evaluating the influence of gai on government policy,https://www.semanticscholar.org/paper/c37fd9c1303cce61ad8e84b8c4fb8bf36ba8fa70,"As a result of the prominence of generative artificial intelligence across diverse fields, it has become necessary for governments to develop national strategies for directing the ethical use of artificial intelligence to respect fundamental human values. This paper explores the role of Generative Artificial Intelligence (GAI) in technology sovereignty, its contributions, and benefits for the government, associated risks, and challenges, and how it influences government policies. It begins with examining GAI's capabilities to comprehend how it understands natural language, trains on existing data, and generates realistic outputs, followed by a discussion of its potential benefits for governments that enable them to act independently and autonomously in diverse sectors. It highlights how it can empower them to administer technological ecosystems, promote domestic innovation, and facilitate policy-making processes. However, contrary to its benefits, GAI is also capable of inflicting negative consequences on society. Therefore, the paper also addresses the risks and challenges associated with GAI that necessitate reflection on existing policies and developing new ones that align with a nation's legal frameworks. Exploring the influence of GAI on government policies, the paper highlights the significance of collaboration in policy-making endeavors to ensure ethical future developments and bring value to public interest and democratic values. This comprehensive analysis aims to shed light on the responsible and ethical use of GAI to preserve human rights, promote economic growth, sustain social justice, and inform the responsible use of GAI within the framework of technology sovereignty.",unknown,154,0.8426830768585205
10.1108/ijebr-02-2023-0169,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Journal of Entrepreneurial Behavior &amp; Research,2000-01-01 00:00:00,semantic_scholar,stand-alone or run together: artificial intelligence as an enabler for other technologies,https://www.semanticscholar.org/paper/76c0930edff3d28590c89523c8d96501cf12909f,"PurposeThe purpose of this study is to examine the role of artificial intelligence (AI) in transforming the healthcare sector, with a focus on how AI contributes to entrepreneurship and value creation. This study also aims to explore the potential of combining AI with other technologies, such as cloud computing, blockchain, IoMT, additive manufacturing and 5G, in the healthcare industry.Design/methodology/approachExploratory qualitative methodology was chosen to analyze 22 case studies from the USA, EU, Asia and South America. The data source was public and specialized podcast platforms.FindingsThe findings show that combining technologies can create a competitive advantage for technology entrepreneurs and bring about transitions from simple consumer devices to actionable healthcare applications. The results of this research identified three main entrepreneurship areas: 1. Analytics, including staff reduction, patient prediction and decision support; 2. Security, including protection against cyberattacks and detection of atypical cases; 3. Performance optimization, which, in addition to reducing the time and costs of medical procedures, includes staff training, reducing capital costs and working with new markets.Originality/valueThis study demonstrates how AI can be used with other technologies to cocreate value in the healthcare industry. This study provides a conceptual framework, “AI facilitators – AI achievers,” based on the findings and offer several theoretical contributions to academic literature in technology entrepreneurship and technology management and industry recommendations for practical implication.",unknown,52,0.8415228128433228
10.1145/3531146.3533097,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Conference on Fairness, Accountability and Transparency",2022-01-01 00:00:00,semantic_scholar,how different groups prioritize ethical values for responsible ai,https://www.semanticscholar.org/paper/d821e5bdf1ab94bcd0e1a9e11fe1c296a01e3f02,"Private companies, public sector organizations, and academic groups have outlined ethical values they consider important for responsible artificial intelligence technologies. While their recommendations converge on a set of central values, little is known about the values a more representative public would find important for the AI technologies they interact with and might be affected by. We conducted a survey examining how individuals perceive and prioritize responsible AI values across three groups: a representative sample of the US population (N=743), a sample of crowdworkers (N=755), and a sample of AI practitioners (N=175). Our results empirically confirm a common concern: AI practitioners’ value priorities differ from those of the general public. Compared to the US-representative sample, AI practitioners appear to consider responsible AI values as less important and emphasize a different set of values. In contrast, self-identified women and black respondents found responsible AI values more important than other groups. Surprisingly, more liberal-leaning participants, rather than participants reporting experiences with discrimination, were more likely to prioritize fairness than other groups. Our findings highlight the importance of paying attention to who gets to define “responsible AI.”",unknown,32,0.8399959206581116
10.22495/cocv21i1art5,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Corporate Ownership and Control,2000-01-01 00:00:00,semantic_scholar,aligning artificial intelligence with ethical accountancy: a global perspective on emerging frameworks,https://www.semanticscholar.org/paper/b7aafd56e7263ad9b8b693d6009742c84633d0db,"This study meticulously examines the integration of artificial intelligence (AI) into the accounting sector, revealing transformative opportunities alongside emerging ethical challenges. Drawing inspiration from established principles of the American Institute of Certified Public Accountants (AICPA) Code of Professional Conduct (AICPA, 2016), an innovative Accounting Framework for AI Ethics (AFAIE) is introduced. This framework aims to provide a tailored approach that ensures that the adoption of AI technologies aligns with the fundamental professional values of trust and integrity. It aims to address the concerns and potential risks associated with the use of AI and establish guidelines that promote accountability and transparency in the development and deployment of AI systems. The essence of this research is underscored by the advocacy for resilient ethical paradigms that are instrumental in navigating the complexities introduced by AI in accounting. Emphasizing a global perspective, this study advocates universal ethical guidelines, ensuring adaptability to specific regional and professional contexts (Association of Chartered Certified Accountants [ACCA], 2016; Bertucci et al., 2021). This synthesis of technology and ethics aims to foster an environment in which innovation thrives alongside steadfast adherence to professional integrity and responsibility.",unknown,120,0.8398961424827576
10.1051/shsconf/202317904024,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,SHS Web of Conferences,2000-01-01 00:00:00,semantic_scholar,ethical considerations in artificial intelligence: a comprehensive disccusion from the perspective of computer vision,https://www.semanticscholar.org/paper/59664744a90437583c2911fc17273670435e0774,"This paper delves deeply into the multifaceted ethical challenges within the realm of computer vision, focusing intently on various ethical dimensions inherent in this cutting-edge field. It emphasizes the pressing need to address ethical concerns related to AI technologies, including algorithmic fairness, informed consent, public engagement, robust privacy protocols, transparency, and the integration of human judgment through human-in-the-loop systems. The study underscores the vital importance of collaboration among diverse stakeholders, including governments, businesses, academia, and society, to promote responsible and equitable AI practices within computer vision.Through meticulous examination, the paper highlights the urgency of balancing technological advancement with ethical considerations. It advocates for the development and implementation of ethical principles, ensuring that AI technologies align with societal values and promote fairness, transparency, and accountability. The collaborative efforts among various sectors are crucial to fostering an ethical framework that guides the responsible deployment of AI in the field of computer vision. By integrating ethical consciousness into the core of technological innovation, this approach aims to create a symbiotic relationship between artificial intelligence and society, ultimately benefiting humanity as a whole.",unknown,63,0.8396750688552856
10.1145/3657054.3657124,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,mitigating the risks of generative ai in government through algorithmic governance,https://www.semanticscholar.org/paper/c22e4a437e3d7659c8257a7f4babe63d6fca05ee,"The launch of the generative artificial intelligence (gen AI) application ChatGPT by OpenAI launched artificial intelligence into public discourse and led to a wave of mass uptake of this technology in organizations in the private sector. At the same time, AI is increasingly incorporated into government functions and the public sector. We propose that governments and the public sector can set an example for the responsible use of AI technologies by following the principles of algorithmic governance traditionally recommended to the private sector. Algorithmic governance has traditionally been defined in the literature as governance by algorithms, or how artificial intelligence is used to make governance decisions and affect social ordering. However, we take an alternative approach; instead, we conceptualize algorithmic governance as the governance of algorithms. We begin by summarizing the risks of generative AI use in government, then outline algorithmic governance principles, a step-by-step approach to implementing algorithmic governance into government or public sector projects, opportunities for inter-sector collaboration, and final conclusions.",unknown,101,0.8392841815948486
10.26883/2010.241.5985,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Education and Technologies Journal,2000-01-01 00:00:00,semantic_scholar,"world’s first law for artificial intelligence. legal, ethical and economic aspects",https://www.semanticscholar.org/paper/34270a7b96d494461465e72c55c1cc84f6417e30,"The European Parliament has enacted the first comprehensive AI law, garnering widespread public interest and varied reactions. This regulation addresses the specific challenges posed by AI systems, aiming to ensure their safety, legal compliance, and alignment with EU fundamental rights and values. Key goals include fostering legal certainty to boost AI investments and innovations, enhancing governance, and preventing market fragmentation. The law employs a risk-based framework, categorizing AI systems into four risk levels: unacceptable, high, limited, and minimal. Unacceptable risk systems, like real-time biometric identification in public spaces, are banned. High-risk systems, such as those used in critical infrastructure or employment, require stringent oversight. Limited risk systems must maintain transparency, informing users when they are interacting with AI. Minimal risk systems, including AI spam filters, are allowed with minimal regulation but still require transparency. Significantly, the law emphasizes ethical AI development, particularly regarding copyright issues in generative AI. It mandates compliance with copyright laws, transparency about training data, and robust cybersecurity measures. Non-compliant companies face severe fines, up to 35 million euros or 7% of annual global revenue. The EU’s AI law sets a pioneering regulatory standard, potentially influencing global AI governance. It aims to balance protecting citizens’ rights with fostering a competitive and innovative AI market in Europe, potentially serving as a model for other democratic nations.",unknown,125,0.8387705087661743
10.1145/3322640.3326722,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Conference on Artificial Intelligence and Law,2019-01-01 00:00:00,semantic_scholar,artificial intelligence and law: what do people really want?: example of a french multidisciplinary working group,https://www.semanticscholar.org/paper/b4fcc459433d2fc35b0214f81a2145bcbc74fe5f,"This paper addresses issues related to the ethical consequences of using AI technologies in court decisions. With the prodigious technological leap made in the field of artificial intelligence in recent years, disruptive innovations have affected many business sectors, with economic, social and ethical consequences. But what do people really want about the application of artificial intelligence technologies in the law system? This article presents a general methodological approach to take into account the ethical aspect of the introduction of a new technology in a given domain. We apply this methodology in the specific case of the introduction of AI technologies in the law system. As a multidisciplinary working group interested in this application in the case of France, we have organized a series of workshops to discuss this topic and highlight the respective values and interests of each stakeholder. The result of this work in presented in the form of an ethical matrix that can be used as a tool by the public authorities to help decision-making on the subject with a prioritization of certain values in order to reflect the respect for fundamental rights.",unknown,10,0.8384205102920532
10.52458/23492589.2023.v10.iss1.kp.a1,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Kaav International Journal of Law, Finance &amp; Industrial Relations",2000-01-01 00:00:00,semantic_scholar,changing landscape of artificial intelligence on indian corporate sectors and governance: special reference to smes,https://www.semanticscholar.org/paper/6d0644272448fde31f868f87d25110a74fb48ff7,"Artificial intelligence (AI) has the likely to start a new industrial upheaval that will primarily alter market forces at work and working circumstances. This study tries to clarify what artificial intelligence (AI) is, how it could affect corporate sectors and SME operations, and India's adoption challenges. Governments can help SMEs develop their risk supervision procedures. Most industries can benefit from using AI, although some are more likely to do so than others. AI may be used in several business areas and can alter the internal value chain of the company. The areas of business where artificial intelligence (AI) are expected to have the most effects. Objective: It is necessary to create the circumstances for a reliable transition and increase knowledge of the benefits of AI among SME managers and employees. A participative approach should be taken when revamping work processes and training AI models, and national and local governments should coordinate efforts to reskill SME managers and employees. Then, until AI can fulfil its full potential, mechanisms for bridging the financing gap should be identified. Research Methodology: The study's foundations include both qualitative and quantitative research. Regulators and policymakers should make sure that knowledge markets that offer cloud solutions with embedded AI technologies are operating smoothly. Findings: The findings of the research are based on the role and impact of AI on different aspects of governance like public administration, tax compliances, market competition, infrastructure, finances, labor market etc. Conclusion: AI lowers prediction costs significantly and makes decision-making easier. To map uncertainties and reduce risk exposure, SMEs may use predictive analytics. They can also automate business estimates, including sales and budget forecasts, or improve the effectiveness of asset maintenance and management. Greater market segmentation and price differentiation are made possible by improved prediction capabilities, which also provide SMEs the chance to innovate since they are better able to foresee customer behavior and price sensitivity as well as demand changes.",unknown,65,0.838018536567688
10.1145/3657054.3657086,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,public value principles for secure and trusted ai,https://www.semanticscholar.org/paper/d6133f0fb81ce4779a78835b4af01ef3b55bbeeb,"The objective of this paper is to establish the fundamental public value principles that should govern safe and trusted artificial intelligence (AI). Public value is a dynamic concept that encompasses several dimensions. AI itself has evolved quite rapidly in the last few years, especially with the swift escalation of Generative AI. Governments around the world are grappling with how to govern AI, just as technologists ring alarm bells about the future consequences of AI. Our paper extends the debate on AI governance that is focused on ethical values of beneficence to that of economic values of public good. Viewed as a public good, AI use is beyond the control of the creators. Towards this end, the paper examined AI policies in the United States and Europe. We postulate three principles from a public values perspective: (i) ensuring security and privacy of each individual (or entity); (ii) ensuring trust in AI systems is verifiable; and (iii) ensuring fair and balanced AI protocols, wherein the underlying components of data and algorithms are contestable and open to public debate.",unknown,97,0.8370463848114014
10.1145/3657054.3657129,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,tribal knowledge cocreation in generative artificial intelligence systems,https://www.semanticscholar.org/paper/3fbf70a03073fd04f2293044076b5e84afef66f7,"Generative Artificial Intelligence (AI) systems bring innovative ways of information provision and knowledge delivery. In the public sector, generative AI has the potential to decrease bureaucratic discretion in the decision-making process. Increasing reliance on this technology brings challenges of unfair treatment, colonized responses from the system, and data governance. Because of historical interaction, tribal communities are the most underrepresented in policy planning and implementation. Indigenous communities suffer from the neglect of tribal sovereignty by the U.S. federal government and limited accessibility and literacy in the digital world. Generative AI systems exacerbate these challenges with insufficient tribal input. However, the negative impact can be alleviated with digital equity and knowledge cocreation. Digital equity emphasizes the importance of tribal knowledge representation, and knowledge cocreation focuses on the collaboration between Indigenous communities and relevant actors in data governance for generative AI systems. This study proposes two research questions to discuss tribal knowledge cocreation in generative AI systems: (1) what are the biases in the system responses from the tribal perspective? (2) what are the potential resolutions for these problems? The findings from in-depth interviews with tribal members in the U.S. indicate that the insufficient articulation of tribal culture, the lack of crucial tribal historical events, and the inappropriate appellation of tribal nations are the primary drawbacks in the system responses. From the Indigenous perspective, tribal oral traditions, native publications and documents, and collaboration with tribal governments can address the problems of generative AI responses. This study contributes to the theory development of digital equity and knowledge cocreation in tribal generative AI system responses. Policy recommendations and future research agendas are included in this research.",unknown,95,0.836939811706543
10.60087/jaigs.v3i1.119,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,2000-01-01 00:00:00,semantic_scholar,examining ethical aspects of ai: addressing bias and equity in the discipline,https://www.semanticscholar.org/paper/9b688157f467a83b7f4f6ac4eae7754241018aef,"he rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",unknown,141,0.8362134099006653
10.60087/jaigs.vol03.issue01.p124,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023,2000-01-01 00:00:00,semantic_scholar,exploring ethical dimensions in ai: navigating bias and fairness in the field,https://www.semanticscholar.org/paper/ffa5a275be9ea886dff66494c821f2b2db2f091d,"The rapid progress in implementing Artificial Intelligence (AI) across various domains such as healthcare decision-making, medical diagnosis, and others has raised significant concerns regarding the fairness and bias embedded within AI systems. This is particularly crucial in sectors like healthcare, employment, criminal justice, credit scoring, and the emerging field of generative AI models (GenAI) producing synthetic media. Such systems can lead to unfair outcomes and perpetuate existing inequalities, including biases ingrained in the synthetic data representation of individuals.This survey paper provides a concise yet comprehensive examination of fairness and bias in AI, encompassing their origins, ramifications, and potential mitigation strategies. We scrutinize sources of bias, including data, algorithmic, and human decision biases, shedding light on the emergent issue of generative AI bias where models may replicate and amplify societal stereotypes. Assessing the societal impact of biased AI systems, we spotlight the perpetuation of inequalities and the reinforcement of harmful stereotypes, especially as generative AI gains traction in shaping public perception through generated content.Various proposed mitigation strategies are explored, with an emphasis on the ethical considerations surrounding their implementation. We stress the necessity of interdisciplinary collaboration to ensure the effectiveness of these strategies. Through a systematic literature review spanning multiple academic disciplines, we define AI bias and its various types, delving into the nuances of generative AI bias. We discuss the adverse effects of AI bias on individuals and society, providing an overview of current approaches to mitigate bias, including data preprocessing, model selection, and post-processing. Unique challenges posed by generative AI models are highlighted, underscoring the importance of tailored strategies to address them effectively.Addressing bias in AI necessitates a holistic approach, involving diverse and representative datasets, enhanced transparency, and accountability in AI systems, and exploration of alternative AI paradigms prioritizing fairness and ethical considerations. This survey contributes to the ongoing discourse on developing fair and unbiased AI systems by outlining the sources, impacts, and mitigation strategies related to AI bias, with a particular focus on the burgeoning field of generative AI.",unknown,139,0.8359202146530151
10.1215/2834703x-11205231,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Critical AI,2000-01-01 00:00:00,semantic_scholar,the fumes of ai,https://www.semanticscholar.org/paper/041b29a4f27cbbff34140e58f2f0f32a61d9207b,"
 With the emergence of generative artificial intelligence (GenAI), it is increasingly clear that the environmental impacts of these technologies are significant, and worth exposing to the public. This article discusses the environmental impacts of generative artificial intelligence and the political underpinnings of extractivist technologies such as cloud companies. It highlights the centralized system of power that demands subservience to its foundational values despite being touted as the most environmentally friendly cloud infrastructure globally.",unknown,135,0.8352036476135254
10.1108/tg-02-2024-0038,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Transforming Government: People, Process and Policy",2000-01-01 00:00:00,semantic_scholar,the use of ai in government and its risks: lessons from the private sector,https://www.semanticscholar.org/paper/2ef758da3f0043f05fb4e89a6c65c610cbd1d43c,"
Purpose
This study aims to understand the perceived emotions of human–artificial intelligence (AI) interactions in the private sector. Moreover, this research discusses the transferability of these lessons to the public sector.


Design/methodology/approach
This research analysed the comments posted between June 2022 and June 2023 in the global open Reddit online community. A data mining approach was conducted, including a sentiment analysis technique and a qualitative approach.


Findings
The results show a prevalence of positive emotions. In addition, a pertinent percentage of negative emotions were found, such as hate, anger and frustration, due to human–AI interactions.


Practical implications
The insights from human–AI interactions in the private sector can be transferred to the governmental sector to leverage organisational performance, governmental decision-making, public service delivery and the creation of economic and social value.


Originality/value
Beyond the positive impacts of AI in government strategies, implementing AI can elicit negative emotions in users and potentially negatively impact the brand of private and government organisations. To the best of the authors’ knowledge, this is the first research bridging the gap by identifying the predominant negative emotions after a human–AI interaction.
",unknown,116,0.8347876667976379
10.1108/tg-01-2024-0006,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Transforming Government: People, Process and Policy",2000-01-01 00:00:00,semantic_scholar,unlocking the power and future potential of generative ai in government transformation,https://www.semanticscholar.org/paper/efca4ec65048fae6d934f3c17dc70aa6803555a8,"
Purpose
This paper aims to investigate whether the implementation of generative artificial intelligence (GAI) impacts government functionality. The study will analyse GAI’s positive attributes across different dimensions to comprehensively understand its value proposition for public organisations. Furthermore, the paper will outline the strategic interventions required to integrate GAI effectively within the organisational context of government transformation.


Design/methodology/approach
This study measures “government functionality” and “GAI implementation” using abstract macro variables as a second-order formative model. It also includes first-order measurable micro-variables to better understand the concept. In addition, the study introduces “organisational context” as a moderating factor to explain the complex dynamics of integrating GAI to improve government functionality. The study proposes a conceptual framework, which was analysed using exploratory data analysis, with primary data collected through questionnaires.


Findings
The study finds a positive correlation between the implementation of GAI and improved government functionality. Furthermore, it found that organisational contextualisation significantly moderates this relationship. All the empirical outcomes align with the prescribed statistical thresholds, concluding that the articulated conceptual framework holds significance.


Research limitations/implications
The study has significant implications for managers, researchers and anyone involved in making, implementing or evaluating decisions related to digital government through GAI. However, the study has limitations, including a limited sample size and contextualisation of the Indian public sector.


Originality/value
The study contributes to existing knowledge by showing that implementing GAI positively correlates with improving government functionality. It further highlights the significance of GAI implementation according to the specific organisational context.
",unknown,103,0.8331548571586609
10.1109/icccis60361.2023.10425428,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',"2023 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)",IEEE,2023-11-04 00:00:00,ieeexplore,modelling the domains of artificial intelligence on social good: a study on analytic-based hierarchy,https://ieeexplore.ieee.org/document/10425428/,"AI is the technology that has transformed many industries and various sectors which include healthcare, finance education, agriculture etc. The purpose of this study is to explore the impact of AI on social good. More specifically, this research prioritizes the domains and subdomains of AI. Initially, the literature has been extensively reviewed to identify the uncharted implications of AI. To conduct the study authors have adopted the secondary research and a theoretical model has been developed to prioritize the domains at the time of contingency; for that purpose, an Analytical Hierarchical Process, a tool of MCDM, is used. The findings of the study concluded with a theoretical model presenting the rankings and maximum global weights. The current study has been conducted in the Indian context. Therefore, this can be considered as a limitation of research. Current study significantly contributes to the body of literature in this field and presents a hierarchical model of artificial intelligence domains and sub domains impacting social good.",unknown,169,0.8315267562866211
10.1177/09520767231188229,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Policy and Administration,2000-01-01 00:00:00,semantic_scholar,making governance agile: exploring the role of artificial intelligence in china’s local governance,https://www.semanticscholar.org/paper/3cc1411a425b6a61bdd8a6bdd8f76ddcff4f869b,"As the key to digital transformation, artificial intelligence is believed to help achieve the goal of government as a platform and the agile development of digital services. Yet we know little about its potential role in local governance, especially the advances that AI-supported services for the public sector in local governance have ventured and the public value they have created. Combining the digital transformation concepts and public value theory, we fill the gap by examining artificial intelligence (AI) deployment in the public sector of a pilot city of digital transformation in China. Using a mixed-method approach, we show how AI configurations facilitate public value creation in the digital era and identify four dimensions of AI deployment in the public sector: data integration, policy innovation, smart application, and collaboration. Our case analysis on these four dimensions demonstrates two roles that AI technology plays in local governance—“AI cage” and “AI colleague.” The former builds the technology infrastructure and platform in each stage of service delivery, regulating the behaviors of frontline workers, while the latter helps frontline workers make decisions, thus improving the agility of public service provision.",unknown,48,0.831282377243042
10.1145/3657054.3657063,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2000-01-01 00:00:00,semantic_scholar,beyond principles: embedding ethical ai risks in public sector risk management practice,https://www.semanticscholar.org/paper/3488e7b86f16c0d93b7b151eca0d7e7526e6d44b,"Artificial intelligence (AI) adoption by public sector organizations (PSOs) introduces various ethical risks stemming from a lack of integrating human values into AI design. Addressing these ethical risks is a complex collective responsibility among designers, developers, risk experts, and public sector managers. Embedding these risks in existing risk management practices is crucial for responsible AI adoption, as emphasized by the legal requirements of the EU AI Act. However, the responsibility for managing these ethical risks is often unclear. Public sector organizations face unique challenges due to the complex, uncertain, and rapidly evolving nature of AI technologies, further complicating the management of ethical risks. This paper explores using the Three Lines of Defense (TLoD) risk management model to understand and address these ethical risks in public sector AI adoption. The TLoD model structures risk management across three lines: operational management, risk oversight and compliance, and internal audit. This framework helps to distribute and integrate the collective responsibility for ethical AI risk management within public sector organizations, emphasizing alignment and collaboration among different actors. Through an exploratory study involving a survey and semi-structured interviews with professionals responsible for AI-related risk management in Dutch public sector organizations, we assess the TLoD model's usefulness in addressing ethical AI risks. The study examines the challenges and opportunities in applying the TLoD model to manage ethical risks and identifies the potential gaps in responsibility and oversight. The findings suggest that while the TLoD model offers a valuable lens for distributing risk management responsibilities, there are limitations in addressing the emergent and complex nature of ethical risks in AI adoption.",unknown,112,0.8306326866149902
10.2196/47847,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,JMIR Formative Research,2000-01-01 00:00:00,semantic_scholar,the adoption of ai in mental health care–perspectives from mental health professionals: qualitative descriptive study,https://www.semanticscholar.org/paper/59b6218ff63c469469402502fa19a7fbd0ba717f,"Background Artificial intelligence (AI) is transforming the mental health care environment. AI tools are increasingly accessed by clients and service users. Mental health professionals must be prepared not only to use AI but also to have conversations about it when delivering care. Despite the potential for AI to enable more efficient and reliable and higher-quality care delivery, there is a persistent gap among mental health professionals in the adoption of AI. Objective A needs assessment was conducted among mental health professionals to (1) understand the learning needs of the workforce and their attitudes toward AI and (2) inform the development of AI education curricula and knowledge translation products. Methods A qualitative descriptive approach was taken to explore the needs of mental health professionals regarding their adoption of AI through semistructured interviews. To reach maximum variation sampling, mental health professionals (eg, psychiatrists, mental health nurses, educators, scientists, and social workers) in various settings across Ontario (eg, urban and rural, public and private sector, and clinical and research) were recruited. Results A total of 20 individuals were recruited. Participants included practitioners (9/20, 45% social workers and 1/20, 5% mental health nurses), educator scientists (5/20, 25% with dual roles as professors/lecturers and researchers), and practitioner scientists (3/20, 15% with dual roles as researchers and psychiatrists and 2/20, 10% with dual roles as researchers and mental health nurses). Four major themes emerged: (1) fostering practice change and building self-efficacy to integrate AI into patient care; (2) promoting system-level change to accelerate the adoption of AI in mental health; (3) addressing the importance of organizational readiness as a catalyst for AI adoption; and (4) ensuring that mental health professionals have the education, knowledge, and skills to harness AI in optimizing patient care. Conclusions AI technologies are starting to emerge in mental health care. Although many digital tools, web-based services, and mobile apps are designed using AI algorithms, mental health professionals have generally been slower in the adoption of AI. As indicated by this study’s findings, the implications are 3-fold. At the individual level, digital professionals must see the value in digitally compassionate tools that retain a humanistic approach to care. For mental health professionals, resistance toward AI adoption must be acknowledged through educational initiatives to raise awareness about the relevance, practicality, and benefits of AI. At the organizational level, digital professionals and leaders must collaborate on governance and funding structures to promote employee buy-in. At the societal level, digital and mental health professionals should collaborate in the creation of formal AI training programs specific to mental health to address knowledge gaps. This study promotes the design of relevant and sustainable education programs to support the adoption of AI within the mental health care sphere.",unknown,80,0.827087938785553
10.1016/j.ijinfomgt.2021.102401,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85112007685,scopus,2021-12-01,scopus,public and private value creation using artificial intelligence: an empirical study of ai voice robot users in chinese public sector,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85112007685&origin=inward,"
                  Despite significant theoretical and empirical attention on public value creation in the public sector, the relationship between artificial intelligence (AI) use and value creation from the citizen perspective remains poorly understood. We ground our study in Moore’s public value management to examine the relationship between AI use and value creation. We conceptually categorize public service value into public value and private value. We use procedural justice and trust in government as indicators of public value and, based on motivation theory, we use perceived usefulness and perceived enjoyment as indicators of private value. A field survey of 492 AI voice robot users in China was conducted to test our model. The results indicated that the effective use of AI voice robots was significantly associated with private value and procedural justice. However, the relationship between the effective use of AI and trust in government was not found to be significant. Surprisingly, the respondents indicated that private value had a greater effect on overall value creation than public value. This contrasts with the common idea that value creation from the government perspective suggests that social objectives requiring public value are more important to citizens. The results also show that gender and citizens with different experiences show different AI usage behaviors.
               ",unknown,332,0.827034592628479
10.3390/su16177724,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Sustainability,2000-01-01 00:00:00,semantic_scholar,procurement of artificial intelligence systems in uae public sectors: an interpretive structural modeling of critical success factors,https://www.semanticscholar.org/paper/eced54e0bfcf41cbad64157ed5683138764a2d2c,"This study investigates the critical success factors (CSFs) influencing the procurement of artificial intelligence (AI) systems within the United Arab Emirates (UAE) public sector. While AI holds immense potential to enhance public service delivery, its successful integration hinges on critical factors. This research utilizes Interpretive Structural Modeling (ISM) to analyze the CSFs impacting AI procurement within the UAE public sector. Through ISM, a structural model is developed to highlight the interrelationships between these CSFs and their influence on the procurement process, outlining the key elements for successful AI procurement within the UAE public sector. Based on the literature review and expert validation from the UAE public sector, ten CSFs were identified. This study found that clear needs assessment is the most influential CSF, while the long-term value of AI systems or services is the least influential. This study provides policymakers and public sector leaders with valuable insights, enabling them to formulate effective strategies to optimize the procurement process and establish a strong foundation for AI adoption. Finally, this will lead to an improved and more efficient public service delivery in the UAE.",unknown,102,0.8262104392051697
10.3390/app14188259,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Applied Sciences,2000-01-01 00:00:00,semantic_scholar,"enhancing e-government services through state-of-the-art, modular, and reproducible architecture over large language models",https://www.semanticscholar.org/paper/282d499f97460e32efae0b0107480d75872bbc5d,"Integrating Large Language Models (LLMs) into e-government applications has the potential to improve public service delivery through advanced data processing and automation. This paper explores critical aspects of a modular and reproducible architecture based on Retrieval-Augmented Generation (RAG) for deploying LLM-based assistants within e-government systems. By examining current practices and challenges, we propose a framework ensuring that Artificial Intelligence (AI) systems are modular and reproducible, essential for maintaining scalability, transparency, and ethical standards. Our approach utilizing Haystack demonstrates a complete multi-agent Generative AI (GAI) virtual assistant that facilitates scalability and reproducibility by allowing individual components to be independently scaled. This research focuses on a comprehensive review of the existing literature and presents case study examples to demonstrate how such an architecture can enhance public service operations. This framework provides a valuable case study for researchers, policymakers, and practitioners interested in exploring the integration of advanced computational linguistics and LLMs into e-government services, although it could benefit from further empirical validation.",unknown,132,0.8260036110877991
10.48550/arxiv.2405.13606,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Conference on Electronic Government,2000-01-01 00:00:00,semantic_scholar,from the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies,https://www.semanticscholar.org/paper/770b35d725e52eb3846ca0ea9b465fc6cbc3cf4b,"Public data ecosystems (PDEs) represent complex socio-technical systems crucial for optimizing data use in the public sector and outside it. Recognizing their multifaceted nature, previous research pro-posed a six-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed as a result of a systematic literature review on the topic spanning three decade, this model, while theoretically robust, necessitates empirical validation to enhance its practical applicability. This study addresses this gap by validating the theoretical model through a real-life examination in five European countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This empirical validation provides insights into PDEs dynamics and variations of implementations across contexts, particularly focusing on the 6th generation of forward-looking PDE generation named""Intelligent Public Data Generation""that represents a paradigm shift driven by emerging technologies such as cloud computing, Artificial Intelligence, Natural Language Processing tools, Generative AI, and Large Language Models (LLM) with potential to contribute to both automation and augmentation of business processes within these ecosystems. By transcending their traditional status as a mere component, evolving into both an actor and a stakeholder simultaneously, these technologies catalyze innovation and progress, enhancing PDE management strategies to align with societal, regulatory, and technical imperatives in the digital era.",unknown,144,0.8257863521575928
10.1145/3325112.3325245,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2019-01-01 00:00:00,semantic_scholar,the data firehose and ai in government: why data management is a key to value and ethics,https://www.semanticscholar.org/paper/9eacf62f1e546748428c7e4843731b1595294200,"Technical and organizational innovations such as Open Data, Internet of Things and Big Data have fueled renewed interest in policy analytics in the public sector. This revamped version of policy analysis continues the long-standing tradition of applying statistical modeling to better understand policy effects and decision making, but also incorporates other computational approaches such as artificial intelligence (AI) and computer simulation. Although much attention has been given to the development of capabilities for data analysis, there is much less attention to understanding the role of data management in a context of AI in government. In this paper, we argue that data management capabilities are foundational to data analysis of any kind, but even more important in the present AI context. This is so because without proper data management, simply acquiring data or systems will not produce desired outcomes. We also argue that realizing the potential of AI for social good relies on investments specifically focused on this social outcome, investments in the processes of building trust in government data, and ensuring the data are ready and suitable for use, for both immediate and future uses.",unknown,9,0.8257639408111572
10.1145/3600211.3604744,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"AAAI/ACM Conference on AI, Ethics, and Society",2000-01-01 00:00:00,semantic_scholar,the eliza defect: constructing the right users for generative ai,https://www.semanticscholar.org/paper/c4b45d26f2b04634a6b8456c83ab3f114f5ebb26,"Artificial intelligence (AI) is at the center of debates on what kind of future we want and how to bring it about. But AI ethics is not only a technical risk assessment and accounting effort, or an application of general principles to stable artifacts. It is also a social self-diagnosis, a contested and contestable assertion of values and desirable futures, and a selective understanding of the nature of AI in its different forms. In expressions of concern and efforts at preparation for increasingly powerful AI tools, we can trace the ways we imagine ourselves and our society to be compatible with AI's promises and susceptible to its dangers. The problems we notice, and the solutions we offer, arise from the interaction of these imagined elements. The socially embedded efficacy of AI tools leads many commentators to imagine their risks specifically in conjunction with understandings of society as it currently is and imaginations of how it can and should exist in the future [1]. The sense-making moves performed in the wake of developments in generative AI are thus a site to examine the movement and uses of different concepts brought together in this domain: the human, rationality, and the place of expertise. As these sense-making efforts are carried out, they become constraints on how the risks of generative AI can be noticed and understood. The problems raised by generative AI are so fundamentally tied to its performance as a simulator of human interpersonal acts that we should ask: where is the risk of generative AI located, such that the utility and the safety of the tools can be preserved after troubling cases? Boundaries between malicious deception and magnificent design are unclear without an answer to this question. Thus, to fit generative AI into our world, we are trying to answer it; this is one goal of efforts at regulation which seeks to allow the benefits of imitation to arrive while avoiding the harms of deception. In the current regulation, reporting, and corporate responses to generative AI, the challenge of safely introducing generative AI is being approached in large part as a challenge of producing the right kind of knowledge in its users. Below is a summary of my findings from three cases, chosen to investigate the following question: What ways, or whose ways, of using, knowing, and understanding generative AI are being offered as appropriate? I examine the EU AI Act language reflecting disclosure requirements for interactions with generative AI, responses to a chatbot-facilitated suicide in Belgium, and reactions to expert claims of a chatbot's sentience. In the first two cases, AI-generated content is problematic insofar as users are uninformed about its provenance or maliciously deceived by it, while users who know they are interacting with AI but behave problematically are designated as deluded or irrational. In the third case, a Google engineer who presents evidence to support claims that AI is sentient is censured as nationwide reporting denounces his claim against an expert consensus from which he is ejected. In all three cases, challenges facing widespread generative AI development and use are avoided by attending to the knowledge and understanding of those who use them rather than the functioning of the tools themselves. The EU AI Act is illuminating as a general and authoritative account of how AI interactions can be made safe, requiring first and foremost that users are informed. [2, 3] The AI Act is useful in the present paper as it shows the effort to match and reconcile a new technology with an extant set of values, chief among which is autonomy. Its reliance on disclosure reflects a general sense that harms are acceptable or unacceptable not on the basis of outcomes but based on the degree of autonomy possessed by the actors in question. Rational actors in a simulated environment are responsible for the effects of the simulation, so long as they are informed of the nature of that environment and have essentially consented to consume deceptive or false content. The other two cases I examine explore this very issue, of problematic understandings and behavior on the part of knowing users. The first of these is the case of the Belgian man. After his suicide responses from the company which provided the chatbot, media [4, 5, 6] and government [5], and prominent expert AI ethics commentary [7] characterized it as arising because the user was vulnerable and consequently did not relate to the bot in the right way. While the chatbot's emotionally charged language was seen as a part of the problem, in the reporting on this event the unanimous emphasis on the man's mental state presents the risk as arising in an interaction, in a pathological mistake of the user, rather than in the tool. Locating risk is a necessary and immensely powerful, if often unexamined step which precedes intervention in a worrisome state of affairs: where we locate risk is where we intervene. If the risk accompanying generative AI is located in the minds of uninformed or misapprehending users, disclosures and disclaimers are indeed sensible interventions. In this conception, when knowledge fails to protect the user, it is not a failed safeguard but a bad user. Problematizing user understandings in this way provides an exonerating resource for the companies providing these tools and suggests the rectitude of expert authority on the nature of these tools, by linking delays and dangers in generative AI to users who do not abide by the (strategically underdetermined) expert consensus on generative AI's accuracy, capabilities, and nature. My third case examines how the expert consensus around generative AI is maintained through the story of Blake Lemoine, who publicly announced his belief that Google's LaMDA model had become sentient and was presented by major media outlets and experts as deluded [8, 9, 10, 11, 12, 13]. In the media and corporate response to Lemoine, wherein Google questioned his sanity before firing him [13], we see his ejection from the community of experts permitted to call for greater scrutiny based on qualitative changes in the nature of these models. He becomes a layperson on account of his anthropomorphizing error. In this act of boundary work [14], policing who is in the body of experts qualified to decide on the sentience of the chatbot, and the nature of AI models in general, we must notice how small this group truly is and what Lemoine's ejection preserves. If safeguards like those Lemoine called for should follow on the kind of change he claimed to detect, and those outside Google's leadership could determine when such changes have arrived, Google would cease to lead the conversation on regulation by defining the nature of its technology. This state of affairs leaves the right relations with generative AI underdetermined but maintains that positions which challenge the expert consensus are the result of misunderstandings so significant as to disqualify the concerned party's thoughts on the matter from rational consideration. In the three cases examined here, events and concerns which threaten to depict generative AI as in need of significant scrutiny or changes are defused not by intervening in the company's technology, but by delineating between user understandings which are empowered and exploitative, safe and vulnerable, rational and deluded. Named after an early chatbot, the ELIZA effect refers to the readiness with which users anthropomorphize computer systems [15]. Reporting on both Lemoine [11] and the Belgian man cited this effect [6]. The chatbot which encouraged the Belgian man to commit suicide was named Eliza. One way of summarizing the change I trace in the cases described above is a transition away from the Turing test and towards the ELIZA effect as the conceptual frame for AI which imitates humans. While the Turing test implies the layperson's relevance to the discussion and regulation of AI, the ELIZA effect implies their irrelevance. This project will continue as an effort to follow popular, expert, and regulatory perceptions of the risk of generative AI as the tools themselves and the public concern surrounding them continue to develop. The resources of science and technology studies (STS) enable crucial perspectives on numerous ways of thinking about AI and the challenges of its development and regulation such as the common citations of law lag, invocations of self-regulation in the mode of the Asilomar Conference on rDNA, collective action problem framings, and more. The STS literature on sociotechnical imaginaries [1] and public understandings of science [16] contribute to the present insight as to how the efforts of tech-society reconciliation and risk-benefit balancing presented as appropriate for AI reveal and produce our understandings of the technology, even as they reproduce and reshape social norms. There is an urgent need for work which extends this powerful scholarly tradition for understanding science, technology, and society to AI, as one of the most important and concerning technological developments of our moment.",unknown,62,0.8252045512199402
10.17705/1pais.14304,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Pacific Asia Journal of the Association for Information Systems,2022-01-01 00:00:00,semantic_scholar,strengthening public institutions and social inclusion of vulnerable groups in a developing country - innovation in organizations and artificial intelligence implications,https://www.semanticscholar.org/paper/be49e6c6ff3488433b44a0b542e4cf8f2429800d,"Background: In the context of a developing nation, children's participation in communal life is almost non-existent. The goal of the study is to contribute to national policies for local development that should prioritize the safety and well-being of the most vulnerable populations, particularly children under the age of 18. Innovating, including children in decision-making and maintaining local services in three pilot municipalities in order to prevent and combat all forms of exploitation to which they are exposed. How can Youth engagement in social and political community life be improved through better understanding of their needs and interests, and what are the artificial intelligence implications? Method: The methodology was used and designed to re-validate an existing program using pre-defined components of an agreement between the Italian and Lebanese governments. A needs study on the socio-demographic profile of youth and a situational analysis was conducted answering three objectives in the program of the Child Friendly City initiative. Results: Assuring the long-term viability and social inclusion of a significant socio-demographic group was successfully implemented: a free call center, software applications, a library, a digital network center, and the involvement of children on the municipal board of directors were established. The findings need to be adapted to various locations using artificial intelligence (AI) solutions and strategies for social awareness and behavior analysis. Conclusion: The importance of this study was underscored during the Covid-19 sanitary crisis, when some of these technologies enabled young people in impacted areas to integrate and become aware of the pandemic's risk. The case was based on theories such as Gender Inequalities and Children's Inclusion, Municipal Governance & Reform, Organizational Innovation (Public Sector), and Social Inclusion, and it demonstrates the value of innovating in the public sector and protecting vulnerable populations through the use of AI.",unknown,29,0.8246391415596008
10.18178/jaai.2023.1.2.103-116,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of Advances in Artificial Intelligence,2000-01-01 00:00:00,semantic_scholar,use of domain engineering in hyperautomation applied to decision making in government,https://www.semanticscholar.org/paper/87d110893ac357209247502dfdd2d5312ec44cfd,"This article presents the domain engineering process carried out to obtain the requirements for the implementation of an Artificial Intelligence (AI) compliance framework aimed at the public sector. Owing to the current competitive and fast economy, which generates huge demand for increasingly efficient, reliable, and transparent intelligent systems, decision-support architectures should also be developed under strong restrictions of cost and time. Such a context requires adequate structures, processes, and technologies for coping with the complexity of building such intelligent systems. Currently, many public organizations have adopted applications for process automation, with the aim of refraining from repetitive work and producing more efficient results. However, what is not so often observed is the development of intelligent engines to support complex public decision-making. Possible explanations are the plethora of available data sources and the number of legal norms to be abided by. Moreover, it is important to highlight the need to incorporate transparency, auditability, reusability, and flexibility into such systems. Thus, they can be safely utilized in various analogous situations, reducing the need to develop new applications from scratch. An architecture suitable for supporting public decision-making with so many features and increasingly unstructured data, as well as abundant regulation, needs well-crafted formal specifications. This article aims to analyze three existing frameworks and carry out domain engineering studies in three cases to produce some guidance for future public applications and services based on AI. Next, we provide a conceptual preliminary architectural definition for the public sector. The proposed architecture targets were identified in the three cases studied, namely, frequent tasks of process mining requirements, detection of anomalies, and extraction of rules and public policies for helping public servants. All these aim at expedient AI development for public decision-making.",unknown,79,0.8242796063423157
10.1109/ecai46879.2019.9042157,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,European Conference on Artificial Intelligence,2019-01-01 00:00:00,semantic_scholar,intelligent solutions - based framework for digital public services. a case study for smart transportation,https://www.semanticscholar.org/paper/3d863678d53ef04773b3e6052995b85db1903e28,"Digital technology landscape is continuously improving, dragging along both the transformation of public services and new demands of citizens. Emerging new technologies like Artificial Intelligence, Machine Learning, Deep Learning or Internet of Things provide tremendous means to implement intelligent solutions for reshaping digital public services. This paper aims to disclose the most important features of several intelligent technologies and of these types of public services that can be integrated for providing new capabilities. An AI-based architecture for supporting digital public services in the smart transportation sector is presented in order to demonstrate the highlighted ideas and concepts.",unknown,12,0.8241714835166931
10.1145/3396956.3396965,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Digital Government Research,2020-01-01 00:00:00,semantic_scholar,public decision making: connecting artificial intelligence and crowds,https://www.semanticscholar.org/paper/14c12f9d44ef23a8c2d39bcf1e3ab1a13d684054,"The recent breakthrough of artificial intelligence, as well as the wide adoption of the wisdom of the crowd, also known as collective intelligence, across sectors, has received attention and excitement across disciplines. In addition to the scientific breakthrough, recent public sector studies recognize AI's potential contributions in public services, such as big data for decision making, the development of smart cities, and social and health care. Studies have also recognized crowdsourcing's potential for service provisions, innovation, information generation, and policymaking. However, we have only a limited understanding of the connections between these two types of intelligence and adoption conditions to properly utilize them for the public sector. To understand what roles AI and crowds can play in enhancing public services and policymaking, we adopt a bibliometric analysis to identify emerging themes and interconnections between these two streams of literature. Our study provides key themes and significance for each cluster. Our first examination of AI and crowd literature regarding connection to public values, complementary in public decision making, as well as future potential for joint adoption by governments provides some implications for future considerations.",unknown,15,0.8230819702148438
10.3233/ip-200249,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Inf. Polity,2020-01-01 00:00:00,semantic_scholar,administration by algorithm: a risk management framework,https://www.semanticscholar.org/paper/8d03df21807637482739cbfe140b260aa8f1907b,"Algorithmic decision-making is neither a recent phenomenon nor one necessarily associated with artificial intelligence (AI), though advances in AI are increasingly resulting in what were heretofore human decisions being taken over by, or becoming dependent on, algorithms and technologies like machine learning. Such developments promise many potential benefits, but are not without certain risks. These risks are not always well understood. It is not just a question of machines making mistakes; it is the embedding of values, biases and prejudices in software which can discriminate against both individuals and groups in society. Such biases are often hard either to detect or prove, particularly where there are problems with transparency and accountability and where such systems are outsourced to the private sector. Consequently, being able to detect and categorise these risks is essential in order to develop a systematic and calibrated response. This paper proposes a simple taxonomy of decision-making algorithms in the public sector and uses this to build a risk management framework with a number of components including an accountability structure and regulatory governance. This framework is designed to assist scholars and practitioners interested in ensuring structured accountability and legal regulation of AI in the public sphere.",unknown,19,0.8210262060165405
10.1016/j.clsr.2024.106050,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85203147962,scopus,2024-11-01,scopus,fair and efficient asylum procedures and artificial intelligence: quo vadis due process?,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85203147962&origin=inward,"
                  In a context of high pressure on national asylum systems and a strive for efficiency, public authorities in Europe are increasingly exploring the potential of artificial intelligence-driven technologies in the asylum process. The use of this technology in the field of asylum is a growing but contentious topic, which raises important normative questions and concerns. In this context, this paper aims to analyse the potential implications for fair asylum procedures when artificial intelligence (AI) assists decision-making. Fair asylum procedures, or due process, are a central condition for guaranteeing the right to asylum and preventing unlawful refoulement, and overall ensuring trust in the asylum adjudication system. After revisiting the theoretical foundations of the concept of fair procedures, this paper develops a normative framework that can guide further reflection on the use of AI in asylum procedures. It thereby analyses the concepts that are key to the debate on the use of AI in decision-making: accuracy, efficiency but also participation. Then, drawing on scholarship in both political science and computer science, it explores potential challenges for the core values of fair procedures, considering both technical and non-technical challenges. This paper concludes that while AI promises efficiency gains for the administration, it identifies important challenges for accuracy and participation. On the basis of these considerations, it highlights the questions that should be asked and answered in order to protect the core values of fair asylum procedures.
               ",unknown,180,0.8182188272476196
10.1177/0952076718780537,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Policy and Administration,2018-01-01 00:00:00,semantic_scholar,"big data and ai – a transformational shift for government: so, what next for research?",https://www.semanticscholar.org/paper/2eedf3d19edacc862bf7ab324a74172bb35a14e1,"Big Data and artificial intelligence will have a profound transformational impact on governments around the world. Thus, it is important for scholars to provide a useful analysis on the topic to public managers and policymakers. This study offers an in-depth review of the Policy and Administration literature on the role of Big Data and advanced analytics in the public sector. It provides an overview of the key themes in the research field, namely the application and benefits of Big Data throughout the policy process, and challenges to its adoption and the resulting implications for the public sector. It is argued that research on the subject is still nascent and more should be done to ensure that the theory adds real value to practitioners. A critical assessment of the strengths and limitations of the existing literature is developed, and a future research agenda to address these gaps and enrich our understanding of the topic is proposed.",unknown,7,0.8166110515594482
10.35940/ijeat.a4282.1013123,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,International Journal of Engineering and Advanced Technology,2000-01-01 00:00:00,semantic_scholar,transforming organizational development with ai: navigating change and innovation for success,https://www.semanticscholar.org/paper/51791a95c6ba077072018ce8c0d294102953cc6a,"Effective change management emerges as a deciding element for an organization's survival and success in the changing terrain of today's fiercely competitive business climate. The variety of change management theories and approaches that are currently available, however, paints a complicated picture that is plagued by inconsistencies, a lack of strong empirical support, and unproven assumptions about contemporary organizational dynamics. This essay seeks to set the basis for a fresh paradigm for effective change administration by critically analyzing popular change management ideas. The gap between theory and practice is addressed in the paper, which concludes with suggestions for more research. In parallel, artificial intelligence (AI) has made incredible progress, giving rise to computers that mimic human autonomy and cognition. Industry-wide excitement has been sparked by the enthusiasm among academics, executives, and the general public, which has resulted in significant investments in utilizing AI's potential through creative business models. However, the lack of thorough academic guidance forces managers to struggle with AI integration issues, increasing the risk of project failure. An in-depth analysis of AI's complexities and its function as a spark for revolutionary business model innovation is provided in this article. A thorough literature assessment, which involves sifting through a sizable library of published works, combines up-to-date information on how AI is affecting the development of new business models. The findings come together to form a roadmap for seamless AI integration that includes four steps: understanding the fundamentals of AI and the skills needed for digital transformation, understanding current business models and their innovation potential, nurturing key proficiencies for AI assimilation, and gaining organizational acceptance while developing internal competencies. This article combines the fields of organizational change management and AI-driven business model innovation with ease, providing a thorough explanation to assist businesses in undergoing a successful transformation and innovation. These disciplines' confluence offers a practical vantage point for successfully adapting to, thriving in, and profiting within a dynamic business environment. Artificial intelligence (AI), a massively disruptive force that is altering international businesses, is at the vanguard of this revolution. The ability of AI to make decisions automatically, based on data analysis and observation, opens up hitherto untapped possibilities for value creation and competitive dominance, with broad consequences spanning several industries. With its quick scaling, ongoing improvement, and self-learning capabilities, this evolutionary invention functions as an agile capital-labor hybrid. Significantly, AI's architecture serves as the cornerstone for data-driven decision support by deftly sifting through large and complicated datasets to extract insights. Thus, the symbiotic marriage of organizational change management and AI-driven business model innovation gives a thorough narrative, directing businesses towards not just surviving, but thriving in an ever-evolving business environment. It is underlined how business models (BMs) interact with technology to affect how well business’s function, underlining the need of taking BMs into account while using AI. Business model innovation (BMI) that AI unlocks may improve goods, streamline processes, and save costs. However, there is a void between technological improvements and their operationalization via BMs. Successful AI integration depends on a well-structured BM, which promotes agility and makes the most of technological resources. BMI is accelerated by AI, which reshapes sectors via innovation. Although interest in AI is high, strategic, cultural, and technological constraints sometimes prevent large investments from producing positive economic results. To fully utilize AI's capabilities, structured BMs are required. Despite an increase in research, there is still little cohesive information about the business uses of AI. In an effort to close this gap, we examine implementation-related AI problems. Analyzing AI-driven BM transformation and risk management is aided by a study on BMI and digital transformation at the same time. The purpose of this study is to further our understanding of AI-driven business model innovation and to provide a useful framework to help practitioners navigate the potential and difficulties of AI implementation. The suggested roadmap aims to identify current knowledge gaps and future research initiatives.",unknown,78,0.8155456185340881
10.1016/j.jsis.2024.101848,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85198122860,scopus,2024-09-01,scopus,fusing domain knowledge with machine learning: a public sector perspective,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85198122860&origin=inward,"Machine learning (ML) offers widely-recognized, but complex, opportunities for both public and private sector organizations to generate value from data. A key requirement is that organizations must find ways to develop new knowledge by merging crucial ‘domain knowledge’ of experts in relevant fields with ‘machine knowledge’, i.e., data that can be used to inform predictive models. In this paper, we argue that understanding the process of generating such knowledge is essential to strategically develop ML. In efforts to contribute to such understanding, we examine the generation of new knowledge from domain knowledge through ML via an exploratory study of two cases in the Swedish public sector. The findings reveal the roles of three mechanisms – dubbed consolidation, algorithmic mediation, and naturalization – in tying domain knowledge to machine knowledge. The study contributes a theory of knowledge production related to organizational use of ML, with important implications for its strategic governance, particularly in the public sector.",unknown,193,0.8137473464012146
10.1108/jices-12-2022-0108,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,"Journal of Information, Communication and Ethics in Society",2000-01-01 00:00:00,semantic_scholar,from big data epistemology to ai politics: rescuing the public dimension over data-driven technologies,https://www.semanticscholar.org/paper/df57622f13676a4a8185df9424bea75243d8fc9e,"
Purpose
The purpose of this paper is to explore the epistemological tensions embedded within big data and data-driven technologies to advance a socio-political reconsideration of the public dimension in the assessment of their implementation.


Design/methodology/approach
This paper builds upon (and revisits) the European Union’s (EU) normative understanding of artificial intelligence (AI) and data-driven technologies, blending reflections rooted in philosophy of technology with issues of democratic participation in tech-related matters.


Findings
This paper proposes the conceptual design of sectorial and/or local-level e-participation platforms to ignite an ongoing discussion – involving experts, private actors, as well as cognizant citizens – over the implementation of data-driven technologies, to avoid siloed, tech-solutionist decisions.


Originality/value
This paper inscribes the EU’s normative approach to AI and data-driven technologies, as well as critical work on the governance of these technologies, into a broader political dimension, suggesting a way to democratically and epistocratically opening up the decisional processes over the development and implementation of these technologies and turn such processes into a systemic civic involvement.
",unknown,67,0.8134329319000244
10.3897/jucs.94155,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Journal of universal computer science (Online),2022-01-01 00:00:00,semantic_scholar,ai empowered big data analytics for industrial applications,https://www.semanticscholar.org/paper/fbf4872593d24a7d5f24e98f662ab85962a2f2d7,"We proposed the idea of editing a special issue that would compile the fruitful research that resulted from the stimulating discussions that occurred during the workshop that was held during the 5th International Conference on Intelligent Computing, Chennai on 25th & 26th March 2022. The objective of this special issue is to call for high-quality papers covering the latest data analytic concepts and technologies of big data and artificial intelligence. This special issue serves as a forum for researchers across the globe to discuss their work and recent advances in this field. The best papers from Artificial intelligence and Big Data Analytics (BAM) in the domains of Product, Finance, Health, and Environment were invited, peer-reviewed. The best high-quality papers were selected based on the innovativeness and relevance of the theme. The amount of data being generated and stored in various fields such as education, energy, environment, healthcare, fraud detection, and traffic is increasing exponentially in the modern era of Big Data. Simultaneously, there is a significant paradigm shift in business and society worldwide due to rapid advancements in fields such as artificial intelligence, machine learning, deep learning, and data analytics. This creates significant challenges for decision-making and the potential for transformation in areas such as the economy, government, and industry. Artificial Intelligence tools, techniques, and technologies, in conjunction with Big Data, improve the predictive power of the systems created and allow the government, public, and private sectors to discover new patterns and trends, as well as improve public values such as accountability, safety, security, and transparency to enable better decision-making, policies, and governance. They also have a wide range of capabilities to perform complex tasks that humans cannot. They could be used to collect, organize, and analyze large, diverse data sets to discover patterns and trends that address a variety of problems related to the development of the economy, such as identifying new sources of revenue, expanding the customer base for business, product reviews, and promotion, disease prediction and prevention, climatic variation prediction, and the provision of energy solutions. The wide variety of subject areas discussed at the 5th International Conference on Intelligent Computing is reflected in the seven accepted papers presented in the following section.",unknown,35,0.8119127750396729
10.53116/pgaflr.7068,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Public Governance Administration and Finances Law Review,2000-01-01 00:00:00,semantic_scholar,e-government in nigeria: can generative ai serve as a tool for civic engagement?,https://www.semanticscholar.org/paper/a854b495502cf6b6f627bf9ebdc5e8f357272e98,"This paper examines the potential for using generative artificial intelligence (AI) to boost civic participation in Nigeria’s developing e-government ecosystem. Emerging generative technologies like ChatGPT demonstrate intriguing capabilities to make governance more interactive and engaging through conversational interfaces. Thoughtfully implemented AI tools could increase access and understanding of e-government, particularly for underserved groups. However, risks around bias, privacy, security and capability limitations pose challenges for public sector applications. Additionally, Nigeria’s substantial digital divides and defective trust in government institutions hamper e-government participation currently. This paper analyses opportunities and limitations for applying generative AI to advance civic engagement given Nigeria’s unique socio-cultural context. Findings suggest that while AI holds promise, targeted strategies focused on inclusion, accessibility, education and institutional legitimacy building are critical to realise benefits. Cautious optimism, human-centric design and responsible governance frameworks are needed to employ generative systems successfully. If challenges are addressed, AI could open innovative possibilities for energising civic participation. But further research and controlled pilot applications are required to determine optimal implementation.",unknown,100,0.8113049268722534
10.1109/meco62516.2024.10577936,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Mediterranean Conference on Embedded Computing,2000-01-01 00:00:00,semantic_scholar,"opportunities of gen ai in the banking industry with regards to the ai act, gdpr, data act and dora",https://www.semanticscholar.org/paper/a738d0916ccf3b8970dabe488a3de88f6d2dd4af,"Generative Artificial Intelligence (Gen AI) stands at the forefront of the banking sector's technological revolution, promising enhancements in decision-making, risk management, and customer interaction. This paper examines Gen AI's potential to inject innovation and efficiency into banking services, with an estimated value addition of up to $340 billion annually. Grounded in advancements in NLP through Transformer architecture and evolving GPT models, Gen AI's applications in the banking industry are extensive. They range from personalizing customer service with AI-driven chatbots to revolutionizing credit scoring and trading strategies. However, alongside these opportunities, the paper addresses the significant challenges of regulatory compliance, ethical data usage, and the technical integration of AI systems. With the impending release of the EU's AI Act and existing GDPR and DORA, financial institutions must strategize to align with new standards while harnessing Gen AI's capabilities for process optimization and enhanced service delivery. The role of international standards such as ISO/IEC 42001:2023, ISO 31000:2018, ISO/IEC 23894:2023, NIST AI 600-1 and ISO/IEC 23053:2022 is considered to be beneficial in establishing a common framework for managing AI systems, ensuring data integrity and promoting transparency. By adopting these standards, banks can facilitate compliance across various jurisdictions, enhancing operational consistency and reliability – but certain significant limitations in addressing specific regulatory requirements must be taken into account. The paper concludes that Gen AI's future in banking will be transformative, driven by the industry's need to balance technological innovation with ethical and regulatory requirements and process standardization, which will lead to more transparent, personalized and efficient banking services.",unknown,131,0.810728907585144
10.1177/08944393241235175,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Social science computer review,2000-01-01 00:00:00,semantic_scholar,"artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization",https://www.semanticscholar.org/paper/9679559aa9ed7c017dcf33f6e07021a83c83b1ce,"In this paper, we first frame the use of artificial intelligence (AI) systems in the public sector as a continuation and intensification of long-standing rationalization and bureaucratization processes. Drawing on Weber, we understand the core of these processes to be the replacement of traditions with instrumental rationality, that is, the most calculable and efficient way of achieving any given policy objective. Second, we demonstrate how much of the criticisms, both among the public and in scholarship, directed towards AI systems spring from well-known tensions at the heart of Weberian rationalization. To illustrate this point, we introduce a thought experiment whereby AI systems are used to optimize tax policy to advance a specific normative end: reducing economic inequality. Our analysis shows that building a machine-like tax system that promotes social and economic equality is possible. However, our analysis also highlights that AI-driven policy optimization (i) comes at the exclusion of other competing political values, (ii) overrides citizens’ sense of their (non-instrumental) obligations to each other, and (iii) undermines the notion of humans as self-determining beings. Third, we observe that contemporary scholarship and advocacy directed towards ensuring that AI systems are legal, ethical, and safe build on and reinforce central assumptions that underpin the process of rationalization, including the modern idea that science can sweep away oppressive systems and replace them with a rule of reason that would rescue humans from moral injustices. That is overly optimistic: science can only provide the means – it cannot dictate the ends. Nonetheless, the use of AI in the public sector can also benefit the institutions and processes of liberal democracies. Most importantly, AI-driven policy optimization demands that normative ends are made explicit and formalized, thereby subjecting them to public scrutiny, deliberation, and debate.",unknown,104,0.8104324340820312
10.1371/journal.pone.0295277,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,PLoS ONE,2000-01-01 00:00:00,semantic_scholar,population preferences for ai system features across eight different decision-making contexts,https://www.semanticscholar.org/paper/c644063a31a9377b069e5f8568db83e24e4f35ff,"Artificial intelligence systems based on deep learning architectures are being investigated as decision-support systems for human decision-makers across a wide range of decision-making contexts. It is known from the literature on AI in medicine that patients and the public hold relatively strong preferences in relation to desirable features of AI systems and their implementation, e.g. in relation to explainability and accuracy, and in relation to the role of the human decision-maker in the decision chain. The features that are preferred can be seen as ‘protective’ of the patient’s interests. These types of preferences may plausibly vary across decision-making contexts, but the research on this question has so far been almost exclusively performed in relation to medical AI. In this cross-sectional survey study we investigate the preferences of the adult Danish population for five specific protective features of AI systems and implementation across a range of eight different use cases in the public and commercial sectors ranging from medical diagnostics to the issuance of parking tickets. We find that all five features are seen as important across all eight contexts, but that they are deemed to be slightly less important when the implications of the decision made are less significant to the respondents.",unknown,77,0.8102613687515259
10.1016/j.procs.2024.05.101,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85195417875,scopus,2024-01-01,scopus,artificial intelligence as an innovative element of support in policing,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85195417875&origin=inward,"Currently, the public security sector is faced with an increasing administrative burden that limits the ability of police officers to focus on core security tasks. This paper focuses on the possibility of using large-scale language models (LSMs) as an innovative tool to address this challenge. Based on a careful literature review and analysis of current trends in artificial intelligence, the author team develops a concept for integrating GPTs into police practice, with an emphasis on the potential for reducing administrative burden and supporting efficient processing of relevant information. As part of this research, we have identified key areas of policing where AI could bring significant value, including data analysis and document production assistance. However, it should be emphasized that this technology is still in its early stages of development and its implementation would require a carefully considered approach involving interdisciplinary collaboration and further research to test the theoretical assumptions presented in this study. Thus, this paper contributes to a deeper understanding of the potential benefits and challenges of integrating GPT into policing practice and outlines a path towards future innovative solutions in the field of public safety.",unknown,235,0.8092496395111084
10.1080/0312407x.2023.2247833,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Australian Social Work,2000-01-01 00:00:00,semantic_scholar,artificial intelligence and implications for the australian social work journal,https://www.semanticscholar.org/paper/d4e771b2e4ef85be2edf99fa9c3047e528c2bc18,"Social work is a profession committed to integrity and social justice. The AASW Social Work Practice Standards (AASW, 2023) calls on social workers to be critically reflective, ethical practitioners engaged in lifelong professional development and learning. Equally, social work education seeks to prepare students for research-informed, culturally-responsive practice across a diverse range of contexts, and in this Issue, we showcase critical social work education and practice diversity. However, a different ethical challenge to integrity and practice standards is the focus of this Editorial. Here, we highlight some of the concerns and implications of generative Artificial Intelligence (generative AI) for social work education, research, practice, and scholarly publishing. In November 2022, OpenAI released ChatGPT, a generative AI Large Language Model (LLM) that could generate realistic and natural text outputs from simple prompts. This technology had been in development for some time but had not been released to the public for general use. Since then, there has been a proliferation of different AI models that can generate and augment text, images, video, and audio. Generative AI is being used to perform analytical and interpretive tasks such as language translation; responding to queries on specific data sources, coding, and interpreting code; summarising documents and webpages; and creating case assessments and plans. This technology can be used to construct legal documents; machine learning for facial recognition; and for undertaking medical, mental health, and other diagnostic assessments. These are just some examples. In this fast-moving field, the uses and applications seem endless. The open-sourcing of generative AI models and their underlying architecture means developers are starting to create a myriad of practical applications and tools that rapidly increase the depth and scale of automation, potentially replacing or augmenting many everyday tasks normally performed by humans. The implications for social work education, practice, research, and scholarship are extensive. As with any new technology, there are a range of stances, from early adopters to positions that have resonance with luddism. This adds to the complexities of responding to AI as a whole profession. Nevertheless, what is clear is that the rise and integration of generative AI systems, at scale, will yield a wide range of practical, ethical, and epistemological problems for many professions, including social work. It is to some of these problems we turn our attention below. Beginning with social work education, generative AI will have profound effects on assessment and learning for higher education providers. It is likely to cause educators to re-evaluate their educational practices, assessments, and assumptions about what is core to a social work curriculum. Social work will need to refine and reappraise its ideas about critical thinking, ethical decision making, professional judgement, and reflective practice—all skills that are considered core to effective social work practice as outlined in the AASW Practice Standards (AASW, 2023). How will we ensure students have an educational environment that promotes",unknown,60,0.8070840835571289
10.1108/cr-06-2023-0144,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Competitiveness Review: An International Business Journal,2000-01-01 00:00:00,semantic_scholar,factors affecting citizen intention toward ai acceptance and adoption: the moderating role of government regulations,https://www.semanticscholar.org/paper/7d474e635b35f0915a71d3010b0635b03b367767,"
Purpose
This paper aims to explore factors impacting citizen intention toward artificial intelligence (AI) adoption, considering government regulation as a moderating variable. It focuses on the Palestinian Cellular Communications Sector in Gaza Strip, providing insights into the citizen-AI relationship dynamics. The research contributes to enhancing comprehension of AI technology from clients’ perspective.


Design/methodology/approach
To test the hypotheses, a questionnaire was used in an empirical study to collect primary data. In total, 347 Palestinian citizens responded to the survey.


Findings
The findings of this paper reveal that perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns significantly influence citizen intention toward AI adoption. Furthermore, government regulations as a moderating variable strengthen the impact of perceived usefulness, perceived ease of use, perceived risks, social influence, user experience and privacy and security concerns on citizen intention toward AI acceptance and adoption. Thus, further research should explore specific domains and cultural contexts to gain a more comprehensive understanding of the factors shaping acceptance and adoption.


Research limitations/implications
The findings of the study should be understood in the context of their limitations. First, the study ignored cultural or domain-specific subtleties in favor of generic characteristics, which calls for more research in these particular circumstances. Second, relying on self-reported data might result in biases and limitations due to subjectivity in reporting, indicating the necessity for alternate data gathering methods and approaches in future research.


Practical implications
Policymakers, developers and organizations working to promote the acceptability and implementation of AI applications should consider the practical implications of this study’s results. To secure the long-term use of AI technologies in a responsible and user-centric way, policymakers should give priority to public education and awareness, user-centered design and ethical AI development techniques. They should also stimulate partnerships and create monitoring systems.


Originality/value
This paper investigates the originality of factors that influence citizen intention toward AI acceptance and adoption. It uniquely examines the moderating role of government regulations in shaping this intention. By addressing this novel aspect, the paper contributes to advancing our understanding of the complex dynamics surrounding citizen intentions toward AI applications.
",unknown,142,0.805072009563446
10.15439/2023f5494,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Conference on Computer Science and Information Systems,2000-01-01 00:00:00,semantic_scholar,towards community-driven generative ai,https://www.semanticscholar.org/paper/52aaea84c922c27c35260aaca8ff43f8debd1a2d,"—While the emerging market of Generative Artiﬁcial Intelligence (AI) is increasingly dominated and controlled by the Tech Giants, there is also a growing interest in open-source AI code and models from smaller companies, research organisations and individual users. They often have valuable data that could be used for training, but their computing resources are limited, while data privacy concerns prevent them from sharing this data for public training. A possible solution to overcome these two issues is to utilise the crowd-souring principles and apply federated learning techniques to build a distributed privacy-preserving architecture for training Generative AI. This paper discusses how these two key enablers, together with some other emerging technologies, can be effectively combined to build a community-driven Generative AI ecosystem, allowing even small actors to participate in the training of Generative AI models by securely contributing their training data. The paper also discusses related non-technical issues, such as the role of the community and intellectual property rights, and outlines further research directions associated with AI moderation.",unknown,45,0.8050459027290344
10.2139/ssrn.3880779,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',semantic_scholar,Social Science Research Network,2021-01-01 00:00:00,semantic_scholar,"the role of social movements, coalitions, and workers in resisting harmful artificial intelligence and contributing to the development of responsible ai",https://www.semanticscholar.org/paper/826a19bda59aa7ce8a33235b35c0480aac827ea1,"The rapid spread of artificial intelligence (AI) systems has precipitated a rise in ethical and rights-based frameworks intended to guide the development and use of these technologies. Despite the proliferation of these ""AI principles"", there is mounting public concern over the influence that the AI systems have in our society, and coalitions in all sectors are organizing to resist harmful applications of AI worldwide. Responses from peoples everywhere, from workers protesting unethical conduct and applications of AI, to student's protesting MIT's relationships with donor, sex trafficker, and pedophile Jeffery Epstein, to the healthcare community, to indigenous people addressing “the twin problems of a lack of reliable data and information on indigenous peoples and biopiracy and misuse of their traditional knowledge and cultural heritage”, to smart city stakeholders, to many others. Like corporations, governments around the world have adopted strategies for becoming leaders in the development and use of Artificial Intelligence, fostering environments congenial to AI innovators. Neither corporations nor policymakers have sufficiently addressed how the rights of children fit into their AI strategies or products. The role of artificial intelligence in children’s lives—from how children play, to how they are educated, to how they consume information and learn about the world—is expected to increase exponentially over the coming years. Thus, it’s imperative that stakeholders evaluate the risks and assess opportunities to use artificial intelligence to maximize children’s wellbeing in a thoughtful and systematic manner. This paper discusses AI and children's rights in the context of social media platforms such as YouTube, smart toys, and AI education applications. The Hello Barbie, Cloud Pets, and Cayla smart toys case studies are analyzed, as well as the ElsaGate social media hacks and education's new Intelligent Tutoring Systems and surveillance of students apps. Though AI has valuable benefits for children, it presents some particular challenges around important issues including child safety, privacy, data privacy, device security and consent. Technology giants, all of whom are heavily investing in and profiting from AI, must not dominate the public discourse on responsible use of AI. We all need to shape the future of our core values and democratic institutions. As artificial intelligence continues to find its way into our daily lives, its propensity to interfere with our rights only gets more severe. Many of the issues mentioned in this examination of harmful AI are not new, but they are greatly exacerbated and threatened by the scale, proliferation, and real-life impact that artificial intelligence facilitates. The potential of artificial intelligence to both help and harm people is much greater than earlier technologies. Continuing to examine what safeguards and structures can address AI’s problems and harms, including those that disproportionately impact marginalized people, is a critical activity. There are assumptions embedded in the AI algorithms that will shape how our world is realized. Many of these algorithms are wrongful and biased, they must get locked-in. Our best human judgment is needed to contain AI's harmful impacts. Perhaps one of the greatest contributions of AI will be to make us ultimately understand how important human wisdom truly is in life on earth.",unknown,22,0.8019897937774658
10.1016/j.giq.2024.101962,to_check,architecture,'architecture' AND ('generative ai' OR 'artificial intelligence') AND 'public sector' AND 'public value',SCOPUS_ID:85199797451,scopus,2024-09-01,scopus,toward a person-environment fit framework for artificial intelligence implementation in the public sector,https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85199797451&origin=inward,"
                  Using an embedded mixed method design, we compared a nationally representative sample of US adults and a sample of US-based emergency managers (EM) on their attitudes toward artificial intelligence (AI) and their intentions to rely on AI in a set of decision-making scenarios relevant to emergency management. Emergency managers reported significantly less positive attitudes toward AI and were less likely to rely on AI for decisions compared to the nationally representative sample. Our analysis of EMs' open-ended responses explaining their choices to use or not use AI-based solutions reflected specific concerns about implementation rather than wariness toward AI generally. These concerns included the complexity of the potential outcomes in the scenarios, the value they placed on human input and their own extensive experience, procedural concerns, collaborative decision-making, team-building, training, and the ethical implications of decisions, rather than a rejection of AI more generally. Managers' insights integrated with our quantitative findings led to a person-environment fit framework for AI implementation in the public sector. Our findings and framework have implications for how AI systems should be introduced and integrated in emergency managerial contexts and in public sector organizations more generally. Public managers' perceptions and intentions to use AI and organizational oversight processes are at least as important as technology design considerations when public sector organizations are considering the deployment of AI.
               ",unknown,192,0.8007835745811462
