id,status,doi,publisher,database,query_name,query_value,url,publication_date,title,abstract
1,included,10.1109/netsoft48620.2020.9165443,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9165443/,2020-07-03 00:00:00,ani: abstracted network inventory for streamlined service placement in distributed clouds,"Scenarios for distributed cloud with multiple edge clouds and centralized data centers are being investigated as the computing and networking underpinnings of next-generation network services such as augmented reality, self-driving vehicles, drones, and more. In such distributed environments, service providers will typically face tens, hundreds, or thousands of compute location candidates (edge, regional, and central) where network service components can be placed. To take optimized placement decisions of network services and execute the management workflows, orchestration systems require up-to-date and accurate resource availability representation, in the form of a network inventory that can be immense in distributed cloud scenarios. As a result, the service management and placement problems may become not tractable. In this work, we propose the Abstracted Network Inventory (ANI) component to generate service-optimized network views over the same network inventory. ANI implements a novel abstraction method where network service requirements are used as an input to generate an optimized abstract network inventory representation, called Logical Network Inventory (LNI). We also provide a formal definition of the network model and problem statement along with the development of three algorithms to efficiently build an LNI. Results show the potential benefits of using an LNI to streamline service management and placement: (i) the relationship between compute nodes and links (i.e., density) in an LNI is reduced between 1.8-2.7x compared to a full network inventory topology; and (ii) up to 50% of time can be saved for service placement after abstracting around 20% of the compute nodes."
2,included,10.1109/globecom46510.2021.9685091,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9685091/,2021-12-11 00:00:00,blockchain and fl-based network resource management for interactive immersive services,"Advanced services leveraged for future smart cities have played a significant role in the advancement of 5G networks towards the 6G vision. Interactive immersive applications are an example of those enabled services. Such applications allow for the interaction between multiple users in a 3D environment created by virtual presentations of real objects and participants using various technologies such as Virtual Reality (VR), Augmented Reality (AR), Extended Reality (XR), Digital Twin (DT) and holography. These applications require advanced computing models which allow for the processing of massive gathered amounts of data. Motions, gestures and object modification should be captured, added to the virtual environment, and shared with all the participants. Relying only on the cloud to process this data can cause significant delays. Therefore, a hybrid cloud/edge architecturewith an intelligent resource orchestration mechanism, that is able to allocate the available capacities efficiently is necessary. In this paper, a blockchain and federated learning-enabled predicted edge-resource allocation (FLP-RA) algorithm is introduced to manage the allocation of computing resources in B5G networks. It allows for smart edge nodes to train their local data and share it with other nodes to create a global estimation of future network loads. As such, nodes are able to make accurate decisions to distribute the available resources to provide the lowest computing delay."
3,included,10.1109/access.2021.3085370,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9445114/,2021-01-01 00:00:00,service placement for latency reduction in the fog using application profiles,"The Cloud-Fog-Internet of Things continuum combines different paradigms to provide connectivity and ubiquity for end-users, while also granting low latency and low jitter to cope with different challenges, including the requirements of latency-sensitive applications, such as virtual/augmented reality and online gaming. This constitutes a complex and dynamic environment with heterogeneous resources that need to be managed or orchestrated, in order to accomplish application requirements for low latency. Common orchestration solutions make placement decisions based only on the resources of the underlying network and the application resource requests; however, using the profiles of applications to make placement decisions has the potential to enhance the final performance perceived by the end-users. This paper proposes the use of application profiles according to their popularity to guide their placement. To corroborate the effectiveness of the use of the profiles, two placement mechanisms are presented, one based on Genetic Algorithm and the other inspired on graph partitions. Simulation results show that it is possible to reduce the latency and jitter of applications via a service placement guided by the profiles. The mechanism based on graph partitions showed better results for all scenarios, followed closely by the Genetic Algorithm in the scenarios with lower load."
4,included,http://arxiv.org/abs/2201.11067v3,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2201.11067v3,2022-01-26 00:00:00,roma: resource orchestration for microservices-based 5g applications,"With the growth of 5G, Internet of Things (IoT), edge computing and cloud
computing technologies, the infrastructure (compute and network) available to
emerging applications (AR/VR, autonomous driving, industry 4.0, etc.) has
become quite complex. There are multiple tiers of computing (IoT devices, near
edge, far edge, cloud, etc.) that are connected with different types of
networking technologies (LAN, LTE, 5G, MAN, WAN, etc.). Deployment and
management of applications in such an environment is quite challenging. In this
paper, we propose ROMA, which performs resource orchestration for
microservices-based 5G applications in a dynamic, heterogeneous, multi-tiered
compute and network fabric. We assume that only application-level requirements
are known, and the detailed requirements of the individual microservices in the
application are not specified. As part of our solution, ROMA identifies and
leverages the coupling relationship between compute and network usage for
various microservices and solves an optimization problem in order to
appropriately identify how each microservice should be deployed in the complex,
multi-tiered compute and network fabric, so that the end-to-end application
requirements are optimally met. We implemented two real-world 5G applications
in video surveillance and intelligent transportation system (ITS) domains.
Through extensive experiments, we show that ROMA is able to save up to 90%, 55%
and 44% compute and up to 80%, 95% and 75% network bandwidth for the
surveillance (watchlist) and transportation application (person and car
detection), respectively. This improvement is achieved while honoring the
application performance requirements, and it is over an alternative scheme that
employs a static and overprovisioned resource allocation strategy by ignoring
the resource coupling relationships."
5,included,http://arxiv.org/abs/2205.14188v1,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2205.14188v1,2022-05-27 00:00:00,"introducing k4.0s: a model for mixed-criticality container orchestration
  in industry 4.0","Time predictable edge cloud is seen as the answer for many arising needs in
Industry 4.0 environments, since it is able to provide flexible, modular, and
reconfigurable services with low latency and reduced costs. Orchestration
systems are becoming the core component of clouds since they take decisions on
the placement and lifecycle of software components. Current solutions start
introducing real-time containers support for time predictability; however,
these approaches lack of determinism as well as support for workloads requiring
multiple levels of assurance/criticality.
  In this paper, we present k4.0s, an orchestration model for real-time and
mixed-criticality environments, which includes timeliness, criticality and
network requirements. The model leverages new abstractions for both node and
jobs, e.g., node assurance, and requires novel monitoring strategies. We sketch
an implementation of the proposal based on Kubernetes, and present an
experimentation motivating the need for node assurance levels and adequate
monitoring."
6,included,http://arxiv.org/abs/2104.14392v3,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2104.14392v3,2021-04-29 00:00:00,"cosco: container orchestration using co-simulation and gradient based
  optimization for fog computing environments","Intelligent task placement and management of tasks in large-scale fog
platforms is challenging due to the highly volatile nature of modern workload
applications and sensitive user requirements of low energy consumption and
response time. Container orchestration platforms have emerged to alleviate this
problem with prior art either using heuristics to quickly reach scheduling
decisions or AI driven methods like reinforcement learning and evolutionary
approaches to adapt to dynamic scenarios. The former often fail to quickly
adapt in highly dynamic environments, whereas the latter have run-times that
are slow enough to negatively impact response time. Therefore, there is a need
for scheduling policies that are both reactive to work efficiently in volatile
environments and have low scheduling overheads. To achieve this, we propose a
Gradient Based Optimization Strategy using Back-propagation of gradients with
respect to Input (GOBI). Further, we leverage the accuracy of predictive
digital-twin models and simulation capabilities by developing a Coupled
Simulation and Container Orchestration Framework (COSCO). Using this, we create
a hybrid simulation driven decision approach, GOBI*, to optimize Quality of
Service (QoS) parameters. Co-simulation and the back-propagation approaches
allow these methods to adapt quickly in volatile environments. Experiments
conducted using real-world data on fog applications using the GOBI and GOBI*
methods, show a significant improvement in terms of energy consumption,
response time, Service Level Objective and scheduling time by up to 15, 40, 4,
and 82 percent respectively when compared to the state-of-the-art algorithms."
7,included,10.1109/access.2022.3190857,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9829747/,2022-01-01 00:00:00,collaborative resource sharing game based cloud-edge offload computing orchestration scheme,"In the foreseeable future, the rapid growth of mobile communications and cloud systems has substantially promoted edge computing paradigm. Although edge computing technology has been attracting much interest, most current research is application-specific without considering a control perspective of cloud providers that provides general-purpose edge services. In this study, we present a new cloud-edge computing orchestration scheme that integrates the different resource sharing problems to maximize benefits for offloading computing services. Specifically, we focus on two cooperative game solutions -<i>Sim bargaining solution</i> and <i>interval Banzhaf Value</i>- to effectively share the computing, communication and cache resources in the cloud-edge system platform. In the proposed scheme, we formalize two different cooperative games, and they work together and act cooperatively to satisfy contradictory requirements. Under widely different service request situations, we aim at accelerating an efficient resource orchestration through dynamic workload balancing. The primary goal of our cooperative game approach is to find optimal control decisions toward the appropriate system operation. Finally, we evaluate the proposed scheme in terms of several performance criteria from the numerical simulations. Experimental results show that we can achieve a mutually desirable solution with a good system performance balance while enhancing the resource efficiency better than the existing cloud-edge control protocols."
