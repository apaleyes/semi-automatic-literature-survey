id,status,doi,publisher,database,query_name,query_value,url,publication_date,title,abstract
1,excluded,10.1007/978-3-030-69893-5_21,Springer,springer,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://dx.doi.org/10.1007/978-3-030-69893-5_21,2021-01-01 00:00:00,application design and service provisioning for multi-access edge cloud (mec),"The edge cloud is attractive to provide low latency services to mobile users. It overcomes computation, storage, and energy limitations of mobile devices through computation offloading. It also avoids long delays in migration of big data from the point of their generation by IoT devices to the centralized data centers. Context-aware edge cloud design provides mobile users with more personalized and customized services that improve their over-all experience. It manages the cloud infrastructure for resource provisioning, scheduling, and load balancing. The latency constraints of MEC applications need light-weight container service in the edge cloud. Kubernetes container orchestration is popular in the industry that is supported by all major edge cloud platforms. Container migration is important for ensuring low latency to new mobile applications of connected vehicles and drones. In this chapter we present the current state of research and development in the application design and service provisioning for edge cloud."
2,excluded,10.1016/j.comnet.2021.108157,scopus,sciencedirect,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://api.elsevier.com/content/abstract/scopus_id/85106478878,2021-08-04,"a genetic algorithm approach for service function chain placement in 5g and beyond, virtualized edge networks","Network Function Virtualization (NFV) is already considered as a structural enabler of today’s networking technology and particularly the 5th Generation of Broadband and Cellular Networks (5G). NFV provides the means to flexibly and dynamically manage and allocate resources, without being restricted to the hardware limitations of the network/cloud infrastructure. Resource orchestration for specific 5G vertical industries and use case families, such as Industry 4.0 and Industrial Internet of Things (IIoT), often introduce very strict requirements in terms of network performance. In such a dynamic environment, the challenge is to efficiently place directed graphs of Virtual Network Functions (VNFs), named as SFCs (Service Function Chains), to the underlying network topology and to dynamically allocate the required resources. To this end, this work presents a novel framework, which makes use of a delay and location aware Genetic Algorithm (GA)-based approach, in order to perform optimized sequential SFC placement. Evaluation results clearly demonstrate the effectiveness of the proposed framework in terms of producing solutions that approximate well the global optimal, as well as achieving low execution time due to the employed GA-based approach and the incorporation of an early stopping criterion. The performance benefits of the proposed framework are evaluated in the context of an extensive set of simulation-based scenarios, under diverse network configurations and scales."
3,excluded,10.1109/tvt.2021.3126803,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9610993/,2022-02-01 00:00:00,mobility-aware controller orchestration in multi-tier service-oriented architecture for iot,"This work addresses the problem of controller orchestration in Internet of Things (IoT)-based Service-Oriented Architecture. It focuses on the fundamental issues of heterogeneity and dynamism of hybrid edge-cloud networks involving both static and mobile IoT devices for provisioning IoT-based services. Due to the limited capacity of IoT devices, IoT-cloud services require the support of edge networks, termed as ‘Service Edge,’ for meeting their ultra-low latency requirements. In such complex and dynamic networks, software-defined networking (SDN) paradigm is utilized for efficient resource utilization and service-oriented network management. A significant problem in SDN is the controller placement problem. Although researchers proposed several controller placement schemes for SDN, the problem of multi-tier controller placement in hybrid cloud-edge networks has not yet been addressed. In this work, this problem is formulated mathematically and shown to be a variant of the well-known two-level capacitated facility location problem, which is NP-hard. Thereafter, COMET, a scheme based on coalitional game and social choice theory, is proposed to solve the problem in polynomial time. COMET is designed while considering varying loads on the switches due to the presence of mobile IoT devices. Simulations depict that COMET reduces network delay by 49.02% with a significant increase in resiliency compared to the state-of-the-art."
4,included,http://arxiv.org/abs/2201.11067v3,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2201.11067v3,2022-01-26 00:00:00,roma: resource orchestration for microservices-based 5g applications,"With the growth of 5G, Internet of Things (IoT), edge computing and cloud
computing technologies, the infrastructure (compute and network) available to
emerging applications (AR/VR, autonomous driving, industry 4.0, etc.) has
become quite complex. There are multiple tiers of computing (IoT devices, near
edge, far edge, cloud, etc.) that are connected with different types of
networking technologies (LAN, LTE, 5G, MAN, WAN, etc.). Deployment and
management of applications in such an environment is quite challenging. In this
paper, we propose ROMA, which performs resource orchestration for
microservices-based 5G applications in a dynamic, heterogeneous, multi-tiered
compute and network fabric. We assume that only application-level requirements
are known, and the detailed requirements of the individual microservices in the
application are not specified. As part of our solution, ROMA identifies and
leverages the coupling relationship between compute and network usage for
various microservices and solves an optimization problem in order to
appropriately identify how each microservice should be deployed in the complex,
multi-tiered compute and network fabric, so that the end-to-end application
requirements are optimally met. We implemented two real-world 5G applications
in video surveillance and intelligent transportation system (ITS) domains.
Through extensive experiments, we show that ROMA is able to save up to 90%, 55%
and 44% compute and up to 80%, 95% and 75% network bandwidth for the
surveillance (watchlist) and transportation application (person and car
detection), respectively. This improvement is achieved while honoring the
application performance requirements, and it is over an alternative scheme that
employs a static and overprovisioned resource allocation strategy by ignoring
the resource coupling relationships."
5,included,http://arxiv.org/abs/2104.14392v3,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2104.14392v3,2021-04-29 00:00:00,"cosco: container orchestration using co-simulation and gradient based
  optimization for fog computing environments","Intelligent task placement and management of tasks in large-scale fog
platforms is challenging due to the highly volatile nature of modern workload
applications and sensitive user requirements of low energy consumption and
response time. Container orchestration platforms have emerged to alleviate this
problem with prior art either using heuristics to quickly reach scheduling
decisions or AI driven methods like reinforcement learning and evolutionary
approaches to adapt to dynamic scenarios. The former often fail to quickly
adapt in highly dynamic environments, whereas the latter have run-times that
are slow enough to negatively impact response time. Therefore, there is a need
for scheduling policies that are both reactive to work efficiently in volatile
environments and have low scheduling overheads. To achieve this, we propose a
Gradient Based Optimization Strategy using Back-propagation of gradients with
respect to Input (GOBI). Further, we leverage the accuracy of predictive
digital-twin models and simulation capabilities by developing a Coupled
Simulation and Container Orchestration Framework (COSCO). Using this, we create
a hybrid simulation driven decision approach, GOBI*, to optimize Quality of
Service (QoS) parameters. Co-simulation and the back-propagation approaches
allow these methods to adapt quickly in volatile environments. Experiments
conducted using real-world data on fog applications using the GOBI and GOBI*
methods, show a significant improvement in terms of energy consumption,
response time, Service Level Objective and scheduling time by up to 15, 40, 4,
and 82 percent respectively when compared to the state-of-the-art algorithms."
6,excluded,10.1007/s13369-022-06563-5,Springer,springer,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://dx.doi.org/10.1007/s13369-022-06563-5,2022-01-29 00:00:00,optimized resource allocation for fog network using neuro-fuzzy offloading approach,"Fog computing has emerged as one of the most important Internet infrastructures for improving service quality, particularly in real-time applications. Due to the convergence in technologies, the scope of the Internet of things (IoT) has evolved to a new dimension, it expands from data collection to device interconnections, and to pre-processing. This acceleration involves cloud and fog computing layers into the system which plays an integral role in IoT data storage and computing. Due to the diversity present in IoT devices, selection of computation devices and allocation of resources are major challenges to be addressed for efficient utilization of resources. In this paper, we presented the offloading and resource allocation model to address the solution to the above challenge. Firstly, a 5-layered neuro-fuzzy model is introduced to retrieve the fuzzy sets and rules which further passes to the fuzzy inference system to model an orchestration decision system. Additionally, to improve the system performance, we have presented the modified least loaded resource allocation algorithm which is adaptively required to reduce the failure rate of the applications. To showcase the efficacy of the model, 4 healthcare applications (augmented reality, patient pre-monitoring, record analysis, and billing systems) are evaluated with their heterogeneous parameters. The simulation findings show that our suggested model improves system performance by lowering network latency by 2.23–9.68 %, computation delay by 3.40–13.66 %, and system performance by 1.03–11.55%. The simulation results demonstrated the suggested model’s resilience in terms of network latency, computation time, and failure rate."
7,included,10.1109/globecom46510.2021.9685091,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9685091/,2021-12-11 00:00:00,blockchain and fl-based network resource management for interactive immersive services,"Advanced services leveraged for future smart cities have played a significant role in the advancement of 5G networks towards the 6G vision. Interactive immersive applications are an example of those enabled services. Such applications allow for the interaction between multiple users in a 3D environment created by virtual presentations of real objects and participants using various technologies such as Virtual Reality (VR), Augmented Reality (AR), Extended Reality (XR), Digital Twin (DT) and holography. These applications require advanced computing models which allow for the processing of massive gathered amounts of data. Motions, gestures and object modification should be captured, added to the virtual environment, and shared with all the participants. Relying only on the cloud to process this data can cause significant delays. Therefore, a hybrid cloud/edge architecturewith an intelligent resource orchestration mechanism, that is able to allocate the available capacities efficiently is necessary. In this paper, a blockchain and federated learning-enabled predicted edge-resource allocation (FLP-RA) algorithm is introduced to manage the allocation of computing resources in B5G networks. It allows for smart edge nodes to train their local data and share it with other nodes to create a global estimation of future network loads. As such, nodes are able to make accurate decisions to distribute the available resources to provide the lowest computing delay."
8,excluded,10.1109/tnsm.2021.3050009,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9316983/,2021-03-01 00:00:00,managing chains of application functions over multi-technology edge networks,"Next-generation networks are expected to provide higher data rates and ultra-low latency in support of demanding applications, such as virtual and augmented reality, robots and drones, etc. To meet these stringent requirements of applications, edge computing constitutes a central piece of the solution architecture wherein functional components of an application can be deployed over the edge network to reduce bandwidth demand over the core network while providing ultra-low latency communication to users. In this article, we provide solutions to resource orchestration and management for applications over a virtualized client-edge-server infrastructure. We investigate the problem of optimal placement of pipelines of application functions (virtual service chains) and the steering of traffic through them, over a multi-technology edge network model consisting of both wired and wireless millimeter-wave (mmWave) links. This problem is NP-hard. We provide a comprehensive “microscopic” binary integer program to model the system, along with a heuristic that is one order of magnitude faster than optimally solving the problem. Extensive evaluations demonstrate the benefits of orchestrating virtual service chains (by distributing them over the edge network) compared to a baseline “middlebox” approach in terms of overall admissible virtual capacity. Moreover, we observe significant gains when deploying a small number of mmWave links that complement the Wire physical infrastructure in high node density networks."
9,excluded,http://arxiv.org/abs/2205.01944v1,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2205.01944v1,2022-05-04 00:00:00,"joint compute-caching-communication control for online data-intensive
  service delivery","Emerging Metaverse applications, designed to deliver highly interactive and
immersive experiences that seamlessly blend physical reality and digital
virtuality, are accelerating the need for distributed compute platforms with
unprecedented storage, computation, and communication requirements. To this
end, the integrated evolution of next-generation networks (e.g., 5G and beyond)
and distributed cloud technologies (e.g., fog and mobile edge computing), have
emerged as a promising paradigm to address the interaction- and
resource-intensive nature of Metaverse applications. In this paper, we focus on
the design of control policies for the joint orchestration of compute, caching,
and communication (3C) resources in next-generation distributed cloud networks
for the efficient delivery of Metaverse applications that require the real-time
aggregation, processing, and distribution of multiple live media streams and
pre-stored digital assets. We describe Metaverse applications via directed
acyclic graphs able to model the combination of real-time stream-processing and
content distribution pipelines. We design the first throughput-optimal control
policy that coordinates joint decisions around (i) routing paths and processing
locations for live data streams, together with (ii) cache selection and
distribution paths for associated data objects. We then extend the proposed
solution to include a max-throughput database placement policy and two
efficient replacement policies. In addition, we characterize the network
stability regions for all studied scenarios. Numerical results demonstrate the
superior performance obtained via the novel multi-pipeline flow control and 3C
resource orchestration mechanisms of the proposed policy, compared with
state-of-the-art algorithms that lack full 3C integrated control."
10,excluded,10.1186/s13677-020-00211-9,Springer,springer,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://dx.doi.org/10.1186/s13677-020-00211-9,2020-11-25 00:00:00,flexible computation offloading in a fuzzy-based mobile edge orchestrator for iot applications,"In the Internet of Things (IoT) era, the capacity-limited Internet and uncontrollable service delays for various new applications, such as video streaming analysis and augmented reality, are challenges. Cloud computing systems, also known as a solution that offloads energy-consuming computation of IoT applications to a cloud server, cannot meet the delay-sensitive and context-aware service requirements. To address this issue, an edge computing system provides timely and context-aware services by bringing the computations and storage closer to the user. The dynamic flow of requests that can be efficiently processed is a significant challenge for edge and cloud computing systems. To improve the performance of IoT systems, the mobile edge orchestrator (MEO), which is an application placement controller, was designed by integrating end mobile devices with edge and cloud computing systems. In this paper, we propose a flexible computation offloading method in a fuzzy-based MEO for IoT applications in order to improve the efficiency in computational resource management. Considering the network, computation resources, and task requirements, a fuzzy-based MEO allows edge workload orchestration actions to decide whether to offload a mobile user to local edge, neighboring edge, or cloud servers. Additionally, increasing packet sizes will affect the failed-task ratio when the number of mobile devices increases. To reduce failed tasks because of transmission collisions and to improve service times for time-critical tasks, we define a new input crisp value, and a new output decision for a fuzzy-based MEO. Using the EdgeCloudSim simulator, we evaluate our proposal with four benchmark algorithms in augmented reality, healthcare, compute-intensive, and infotainment applications. Simulation results show that our proposal provides better results in terms of WLAN delay, service times, the number of failed tasks, and VM utilization."
11,included,10.1109/access.2022.3190857,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9829747/,2022-01-01 00:00:00,collaborative resource sharing game based cloud-edge offload computing orchestration scheme,"In the foreseeable future, the rapid growth of mobile communications and cloud systems has substantially promoted edge computing paradigm. Although edge computing technology has been attracting much interest, most current research is application-specific without considering a control perspective of cloud providers that provides general-purpose edge services. In this study, we present a new cloud-edge computing orchestration scheme that integrates the different resource sharing problems to maximize benefits for offloading computing services. Specifically, we focus on two cooperative game solutions -<i>Sim bargaining solution</i> and <i>interval Banzhaf Value</i>- to effectively share the computing, communication and cache resources in the cloud-edge system platform. In the proposed scheme, we formalize two different cooperative games, and they work together and act cooperatively to satisfy contradictory requirements. Under widely different service request situations, we aim at accelerating an efficient resource orchestration through dynamic workload balancing. The primary goal of our cooperative game approach is to find optimal control decisions toward the appropriate system operation. Finally, we evaluate the proposed scheme in terms of several performance criteria from the numerical simulations. Experimental results show that we can achieve a mutually desirable solution with a good system performance balance while enhancing the resource efficiency better than the existing cloud-edge control protocols."
12,excluded,10.1007/978-981-15-3607-6_50,Springer,springer,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://dx.doi.org/10.1007/978-981-15-3607-6_50,2020-01-01 00:00:00,orchestration-based task offloading for mobile edge computing in small-cell networks,"To execute computation-intensive applications and stringent latency-critical tasks at resource constraints smart mobile devices, mobile edge computing (MEC) in small-cell networks is one of the leading thought, where mobile devices will offload their computation-intensive tasks to the adjacent small-cell network for faster processing. Currently, some research work has been done for combining mobile edge computing and small-cell networks together. Existing researches mostly concentrate on the user to small base station (SBS) offloading and improving the radio access performance using optimization, while the computing capability of SBS-MEC server is ignored. In order to acquire superior performance, an efficient orchestration-based task offloading for mobile edge computing in small-cell networks is proposed in this paper where edge orchestrator collects all the information from the neighboring small-cell SBS-MEC server to decide for forwarding the workloads from overloaded SBS-MEC to nearby SBS-MEC with a light workload. Simulation results affirm that orchestration-based task offloading scheme offers the best results not only by reducing the task failure but also with a smaller task completion time compared to other approaches in small-cell networks."
13,excluded,http://arxiv.org/abs/1812.00300v1,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/1812.00300v1,2018-12-02 00:00:00,"containers orchestration with cost-efficient autoscaling in cloud
  computing environments","Containers are standalone, self-contained units that package software and its
dependencies together. They offer lightweight performance isolation, fast and
flexible deployment, and fine-grained resource sharing. They have gained
popularity in better application management and deployment in recent years and
are being widely used by organizations to deploy their increasingly diverse
workloads such as web services, big data, and IoT in either proprietary
clusters or cloud data centres. This has led to the emergence of container
orchestration platforms, which are designed to manage the deployment of
containerized applications in large-scale clusters. The majority of these
platforms are tailored to optimize the scheduling of containers on a
fixed-sized private cluster but are not enabled to autoscale the size of the
cluster nor to consider features specific to public cloud environments. In this
work, we propose a comprehensive container resource management approach that
has three different objectives. The first one is to optimize the initial
placement of containers by efficiently scheduling them on existing resources.
The second one is to autoscale the number of resources at runtime based on the
current cluster's workload. The third one is a rescheduling mechanism to
further support the efficient use of resources by consolidating applications
into fewer VMs when possible. Our algorithms are implemented as a
plugin-scheduler for Kubernetes platform. We evaluated our framework and the
effectiveness of the proposed algorithms on an Australian national cloud
infrastructure. Our experiments demonstrate that considerable cost savings can
be achieved by dynamically managing the cluster size and placement of
applications. We find that our proposed approaches are capable of reducing the
cost by 58% when compared to the default Kubernetes scheduler."
14,included,10.1109/netsoft48620.2020.9165443,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9165443/,2020-07-03 00:00:00,ani: abstracted network inventory for streamlined service placement in distributed clouds,"Scenarios for distributed cloud with multiple edge clouds and centralized data centers are being investigated as the computing and networking underpinnings of next-generation network services such as augmented reality, self-driving vehicles, drones, and more. In such distributed environments, service providers will typically face tens, hundreds, or thousands of compute location candidates (edge, regional, and central) where network service components can be placed. To take optimized placement decisions of network services and execute the management workflows, orchestration systems require up-to-date and accurate resource availability representation, in the form of a network inventory that can be immense in distributed cloud scenarios. As a result, the service management and placement problems may become not tractable. In this work, we propose the Abstracted Network Inventory (ANI) component to generate service-optimized network views over the same network inventory. ANI implements a novel abstraction method where network service requirements are used as an input to generate an optimized abstract network inventory representation, called Logical Network Inventory (LNI). We also provide a formal definition of the network model and problem statement along with the development of three algorithms to efficiently build an LNI. Results show the potential benefits of using an LNI to streamline service management and placement: (i) the relationship between compute nodes and links (i.e., density) in an LNI is reduced between 1.8-2.7x compared to a full network inventory topology; and (ii) up to 50% of time can be saved for service placement after abstracting around 20% of the compute nodes."
15,excluded,10.1016/j.jnca.2020.102785,scopus,sciencedirect,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://api.elsevier.com/content/abstract/scopus_id/85090340458,2020-11-15,scalable edge cloud platforms for iot services,"Nowadays, online applications are moving to the cloud, and for delay-sensitive ones, the cloud is being extended with edge/fog domains. Emerging cloud platforms that tightly integrate compute and network resources enable novel services, such as versatile IoT (Internet of Things), augmented reality or Tactile Internet applications. Virtual infrastructure managers (VIMs), network controllers and upper-level orchestrators are in charge of managing these distributed resources. A key and challenging task of these orchestrators is to find the proper placement for software components of the services. As the basic variant of the related theoretical problem (Virtual Network Embedding) is known to be 
                        NP
                     -hard, heuristic solutions and approximations can be addressed. In this paper, we propose two architecture options together with proof-of-concept prototypes and corresponding embedding algorithms, which enable the provisioning of delay-sensitive IoT applications. On the one hand, we extend the VIM itself with network-awareness, typically not available in today's VIMs. On the other hand, we propose a multi-layer orchestration system where an orchestrator is added on top of VIMs and network controllers to integrate different resource domains. We argue that the large-scale performance and feasibility of the proposals can only be evaluated with complete prototypes, including all relevant components. Therefore, we implemented fully-fledged solutions and conducted large-scale experiments to reveal the scalability characteristics of both approaches. We found that our VIM extension can be a valid option for single-provider setups encompassing even 100 edge domains (Points of Presence equipped with multiple servers) and serving a few hundreds of customers. Whereas, our multi-layer orchestration system showed better scaling characteristics in a wider range of scenarios at the cost of a more complex control plane including additional entities and novel APIs (Application Programming Interfaces)."
16,excluded,http://arxiv.org/abs/2002.05531v1,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2002.05531v1,2020-02-12 00:00:00,modelling fog offloading performance,"Fog computing has emerged as a computing paradigm aimed at addressing the
issues of latency, bandwidth and privacy when mobile devices are communicating
with remote cloud services. The concept is to offload compute services closer
to the data. However many challenges exist in the realisation of this approach.
During offloading, (part of) the application underpinned by the services may be
unavailable, which the user will experience as down time. This paper describes
work aimed at building models to allow prediction of such down time based on
metrics (operational data) of the underlying and surrounding infrastructure.
Such prediction would be invaluable in the context of automated Fog offloading
and adaptive decision making in Fog orchestration. Models that cater for four
container-based stateless and stateful offload techniques, namely Save and
Load, Export and Import, Push and Pull and Live Migration, are built using four
(linear and non-linear) regression techniques. Experimental results comprising
over 42 million data points from multiple lab-based Fog infrastructure are
presented. The results highlight that reasonably accurate predictions (measured
by the coefficient of determination for regression models, mean absolute
percentage error, and mean absolute error) may be obtained when considering 25
metrics relevant to the infrastructure."
17,excluded,10.1016/j.comnet.2018.06.006,scopus,sciencedirect,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://api.elsevier.com/content/abstract/scopus_id/85048725858,2018-09-04,optimal orchestration of virtual network functions,"The emergence of Network Functions Virtualization (NFV) is bringing a set of novel algorithmic challenges in the operation of communication networks. NFV introduces volatility in the management of network functions, which can be dynamically orchestrated, i.e., placed, resized, etc. Virtual Network Functions (VNFs) can belong to VNF chains, where nodes in a chain can serve multiple demands coming from the network edges. In this paper, we formally define the VNF placement and routing (VNF-PR) problem, proposing a versatile linear programming formulation that is able to accommodate specific features and constraints of NFV infrastructures, and that is substantially different from existing virtual network embedding formulations in the state of the art. We also design a math-heuristic able to scale with multiple objectives and large instances. By extensive simulations, we draw conclusions on the trade-off achievable between classical traffic engineering (TE) and NFV infrastructure efficiency goals, evaluating both Internet access and Virtual Private Network (VPN) demands. We do also quantitatively compare the performance of our VNF-PR heuristic with the classical Virtual Network Embedding (VNE) approach proposed for NFV orchestration, showing the computational differences, and how our approach can provide a more stable and closer-to-optimum solution."
18,included,10.1109/access.2021.3085370,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9445114/,2021-01-01 00:00:00,service placement for latency reduction in the fog using application profiles,"The Cloud-Fog-Internet of Things continuum combines different paradigms to provide connectivity and ubiquity for end-users, while also granting low latency and low jitter to cope with different challenges, including the requirements of latency-sensitive applications, such as virtual/augmented reality and online gaming. This constitutes a complex and dynamic environment with heterogeneous resources that need to be managed or orchestrated, in order to accomplish application requirements for low latency. Common orchestration solutions make placement decisions based only on the resources of the underlying network and the application resource requests; however, using the profiles of applications to make placement decisions has the potential to enhance the final performance perceived by the end-users. This paper proposes the use of application profiles according to their popularity to guide their placement. To corroborate the effectiveness of the use of the profiles, two placement mechanisms are presented, one based on Genetic Algorithm and the other inspired on graph partitions. Simulation results show that it is possible to reduce the latency and jitter of applications via a service placement guided by the profiles. The mechanism based on graph partitions showed better results for all scenarios, followed closely by the Genetic Algorithm in the scenarios with lower load."
19,excluded,10.1109/vtc2021-fall52928.2021.9625307,IEEE,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://ieeexplore.ieee.org/document/9625307/,2021-09-30 00:00:00,machine learning based mmwave orchestration for edge gaming qoe enhancement,"Millimeter wave (mmWave) is a crucial component in 5G and beyond 5G communications. However, the dense deployment of mmWave transceivers imposes a heavy burden on the management of radio access network (RAN). This challenge increases the need for autonomous network management methods leveraging machine learning (ML) techniques. In particular, mmWave beam selection is a critical issue for the management of RAN due to the large training overhead on mmWave transceivers. To this end, a new beam tracking method based on sequence-to-sequence (Seq2Seq) learning is proposed. Besides, thanks to edge computing technologies, network management algorithms and delay-sensitive user applications can be hosted on edge servers in close proximity. Due to limited resources on the edge server, the resource allocation problem for beam tracking and edge gaming is investigated with the aim of maximizing game quality of experience (QoE). Simulation results verify the effectiveness of the proposed orchestration scheme."
20,included,http://arxiv.org/abs/2205.14188v1,arxiv,arxiv,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',http://arxiv.org/abs/2205.14188v1,2022-05-27 00:00:00,"introducing k4.0s: a model for mixed-criticality container orchestration
  in industry 4.0","Time predictable edge cloud is seen as the answer for many arising needs in
Industry 4.0 environments, since it is able to provide flexible, modular, and
reconfigurable services with low latency and reduced costs. Orchestration
systems are becoming the core component of clouds since they take decisions on
the placement and lifecycle of software components. Current solutions start
introducing real-time containers support for time predictability; however,
these approaches lack of determinism as well as support for workloads requiring
multiple levels of assurance/criticality.
  In this paper, we present k4.0s, an orchestration model for real-time and
mixed-criticality environments, which includes timeliness, criticality and
network requirements. The model leverages new abstractions for both node and
jobs, e.g., node assurance, and requires novel monitoring strategies. We sketch
an implementation of the proposal based on Kubernetes, and present an
experimentation motivating the need for node assurance levels and adequate
monitoring."
21,excluded,10.1016/j.comcom.2020.04.054,scopus,sciencedirect,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',https://api.elsevier.com/content/abstract/scopus_id/85084309752,2020-05-15,edge caching and computing in 5g for mobile augmented reality and haptic internet,"Deploying cache and computing resources in 5G mobile communication networks is considered an important way to reduce network transmission delay and redundant content transmission, improve content distribution efficiency and network computing processing capabilities. Through the construction of 5G user experience models for mobile augmented reality and tactile internet, the subjective expected experience of 5G users in mobile augmented reality applications is investigated. Based on the experimental results, the composition of mobile augmented reality, and the factors that affect 5G user, mobile 5G user experience model for augmented reality is as a design goal for mobile augmented reality. And research on mobile edge cloud computing powered by renewable energy. Based on the analysis of renewable energy, a 5G user computing task delay and power grid power consumption minimization model was established. It is decomposed into two sub-problems of computational resource allocation and task placement using alternating optimization. The sub-problems of computing tasks under renewable energy supply are obtained by solving the sub-problems. The experimental results show that the offload mode proposed in this paper is superior to the other two modes when the processing ratio before and after the task is less than 1, and the user contact frequency is greater than 0.0014. At the same time, it is obtained that the service node with higher mobility and larger computing power is allocated. The more workload, the more energy can be reduced in the network, thereby improving the performance of the system."
