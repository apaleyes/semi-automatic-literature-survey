doi,type,query_name,query_value,publication,publisher,publication_date,database,title,url,abstract,id,status
10.1186/s13677-020-00211-9,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',Journal of Cloud Computing,Springer,2020-11-25,springer,flexible computation offloading in a fuzzy-based mobile edge orchestrator for iot applications,http://dx.doi.org/10.1186/s13677-020-00211-9,"In the Internet of Things (IoT) era, the capacity-limited Internet and uncontrollable service delays for various new applications, such as video streaming analysis and augmented reality, are challenges. Cloud computing systems, also known as a solution that offloads energy-consuming computation of IoT applications to a cloud server, cannot meet the delay-sensitive and context-aware service requirements. To address this issue, an edge computing system provides timely and context-aware services by bringing the computations and storage closer to the user. The dynamic flow of requests that can be efficiently processed is a significant challenge for edge and cloud computing systems. To improve the performance of IoT systems, the mobile edge orchestrator (MEO), which is an application placement controller, was designed by integrating end mobile devices with edge and cloud computing systems. In this paper, we propose a flexible computation offloading method in a fuzzy-based MEO for IoT applications in order to improve the efficiency in computational resource management. Considering the network, computation resources, and task requirements, a fuzzy-based MEO allows edge workload orchestration actions to decide whether to offload a mobile user to local edge, neighboring edge, or cloud servers. Additionally, increasing packet sizes will affect the failed-task ratio when the number of mobile devices increases. To reduce failed tasks because of transmission collisions and to improve service times for time-critical tasks, we define a new input crisp value, and a new output decision for a fuzzy-based MEO. Using the EdgeCloudSim simulator, we evaluate our proposal with four benchmark algorithms in augmented reality, healthcare, compute-intensive, and infotainment applications. Simulation results show that our proposal provides better results in terms of WLAN delay, service times, the number of failed tasks, and VM utilization.",1,unknown
10.1109/netsoft48620.2020.9165443,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',2020 6th IEEE Conference on Network Softwarization (NetSoft),IEEE,2020-07-03,ieeexplore,ani: abstracted network inventory for streamlined service placement in distributed clouds,https://ieeexplore.ieee.org/document/9165443/,"Scenarios for distributed cloud with multiple edge clouds and centralized data centers are being investigated as the computing and networking underpinnings of next-generation network services such as augmented reality, self-driving vehicles, drones, and more. In such distributed environments, service providers will typically face tens, hundreds, or thousands of compute location candidates (edge, regional, and central) where network service components can be placed. To take optimized placement decisions of network services and execute the management workflows, orchestration systems require up-to-date and accurate resource availability representation, in the form of a network inventory that can be immense in distributed cloud scenarios. As a result, the service management and placement problems may become not tractable. In this work, we propose the Abstracted Network Inventory (ANI) component to generate service-optimized network views over the same network inventory. ANI implements a novel abstraction method where network service requirements are used as an input to generate an optimized abstract network inventory representation, called Logical Network Inventory (LNI). We also provide a formal definition of the network model and problem statement along with the development of three algorithms to efficiently build an LNI. Results show the potential benefits of using an LNI to streamline service management and placement: (i) the relationship between compute nodes and links (i.e., density) in an LNI is reduced between 1.8-2.7x compared to a full network inventory topology; and (ii) up to 50% of time can be saved for service placement after abstracting around 20% of the compute nodes.",2,unknown
10.1109/tnsm.2021.3050009,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',IEEE Transactions on Network and Service Management,IEEE,2021-03-01,ieeexplore,managing chains of application functions over multi-technology edge networks,https://ieeexplore.ieee.org/document/9316983/,"Next-generation networks are expected to provide higher data rates and ultra-low latency in support of demanding applications, such as virtual and augmented reality, robots and drones, etc. To meet these stringent requirements of applications, edge computing constitutes a central piece of the solution architecture wherein functional components of an application can be deployed over the edge network to reduce bandwidth demand over the core network while providing ultra-low latency communication to users. In this article, we provide solutions to resource orchestration and management for applications over a virtualized client-edge-server infrastructure. We investigate the problem of optimal placement of pipelines of application functions (virtual service chains) and the steering of traffic through them, over a multi-technology edge network model consisting of both wired and wireless millimeter-wave (mmWave) links. This problem is NP-hard. We provide a comprehensive “microscopic” binary integer program to model the system, along with a heuristic that is one order of magnitude faster than optimally solving the problem. Extensive evaluations demonstrate the benefits of orchestrating virtual service chains (by distributing them over the edge network) compared to a baseline “middlebox” approach in terms of overall admissible virtual capacity. Moreover, we observe significant gains when deploying a small number of mmWave links that complement the Wire physical infrastructure in high node density networks.",3,unknown
http://arxiv.org/abs/2205.14188v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2022-05-27,arxiv,"introducing k4.0s: a model for mixed-criticality container orchestration
  in industry 4.0",http://arxiv.org/abs/2205.14188v1,"Time predictable edge cloud is seen as the answer for many arising needs in
Industry 4.0 environments, since it is able to provide flexible, modular, and
reconfigurable services with low latency and reduced costs. Orchestration
systems are becoming the core component of clouds since they take decisions on
the placement and lifecycle of software components. Current solutions start
introducing real-time containers support for time predictability; however,
these approaches lack of determinism as well as support for workloads requiring
multiple levels of assurance/criticality.
  In this paper, we present k4.0s, an orchestration model for real-time and
mixed-criticality environments, which includes timeliness, criticality and
network requirements. The model leverages new abstractions for both node and
jobs, e.g., node assurance, and requires novel monitoring strategies. We sketch
an implementation of the proposal based on Kubernetes, and present an
experimentation motivating the need for node assurance levels and adequate
monitoring.",4,unknown
http://arxiv.org/abs/2205.01944v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2022-05-04,arxiv,"joint compute-caching-communication control for online data-intensive
  service delivery",http://arxiv.org/abs/2205.01944v1,"Emerging Metaverse applications, designed to deliver highly interactive and
immersive experiences that seamlessly blend physical reality and digital
virtuality, are accelerating the need for distributed compute platforms with
unprecedented storage, computation, and communication requirements. To this
end, the integrated evolution of next-generation networks (e.g., 5G and beyond)
and distributed cloud technologies (e.g., fog and mobile edge computing), have
emerged as a promising paradigm to address the interaction- and
resource-intensive nature of Metaverse applications. In this paper, we focus on
the design of control policies for the joint orchestration of compute, caching,
and communication (3C) resources in next-generation distributed cloud networks
for the efficient delivery of Metaverse applications that require the real-time
aggregation, processing, and distribution of multiple live media streams and
pre-stored digital assets. We describe Metaverse applications via directed
acyclic graphs able to model the combination of real-time stream-processing and
content distribution pipelines. We design the first throughput-optimal control
policy that coordinates joint decisions around (i) routing paths and processing
locations for live data streams, together with (ii) cache selection and
distribution paths for associated data objects. We then extend the proposed
solution to include a max-throughput database placement policy and two
efficient replacement policies. In addition, we characterize the network
stability regions for all studied scenarios. Numerical results demonstrate the
superior performance obtained via the novel multi-pipeline flow control and 3C
resource orchestration mechanisms of the proposed policy, compared with
state-of-the-art algorithms that lack full 3C integrated control.",5,unknown
http://arxiv.org/abs/2201.00994v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2022-01-04,arxiv,toward a utm-based service orchestration for uavs in mec-nfv environment,http://arxiv.org/abs/2201.00994v1,"The increased use of Unmanned Aerial Vehicles (UAVs) in numerous domains will
result in high traffic densities in the low-altitude airspace. Consequently,
UAVs Traffic Management (UTM) systems that allow the integration of UAVs in the
low-altitude airspace are gaining a lot of momentum. Furthermore, the 5th
generation of mobile networks (5G) will most likely provide the underlying
support for UTM systems by providing connectivity to UAVs, enabling the
control, tracking and communication with remote applications and services.
However, UAVs may need to communicate with services with different
communication Quality of Service (QoS) requirements, ranging form best-effort
services to Ultra-Reliable Low-Latency Communications (URLLC) services. Indeed,
5G can ensure efficient Quality of Service (QoS) enhancements using new
technologies, such as network slicing and Multi-access Edge Computing (MEC). In
this context, Network Functions Virtualization (NFV) is considered as one of
the pillars of 5G systems, by providing a QoS-aware Management and
Orchestration (MANO) of softwarized services across cloud and MEC platforms.
The MANO process of UAV's services can be enhanced further using the
information provided by the UTM system, such as the UAVs'flight plans. In this
paper,we propose an extended framework for the management and orchestration of
UAVs'services in MECNFV environment by combining the functionalities provided
by the MEC-NFV management and orchestration framework with the functionalities
of a UTM system. Moreover, we propose an Integer Linear Programming (ILP) model
of the placement scheme of our framework and we evaluate its performances.",6,unknown
10.1186/s13638-021-02067-2,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',EURASIP Journal on Wireless Communications and Networking,Springer,2021-12-04,springer,"beyond private 5g networks: applications, architectures, operator models and technological enablers",http://dx.doi.org/10.1186/s13638-021-02067-2,"Private networks will play a key role in 5G and beyond to enable smart factories with the required better deployment, operation and flexible usage of available resource and infrastructure. 5G private networks will offer a lean and agile solution to effectively deploy and operate services with stringent and heterogeneous constraints in terms of reliability, latency, re-configurability and re-deployment of resources as well as issues related to governance and ownership of 5G components, and elements. In this paper, we present a novel approach to operator models, specifically targeting 5G and beyond private networks. We apply the proposed operator models to different network architecture options and to a selection of relevant use cases offering mixed private–public network operator governance and ownership. Moreover, several key enabling technologies have been identified for 5G private networks. Before the deployment, stakeholders should consider spectrum allocation and on-site channel measurements in order to fully understand the propagation characteristic of a given environment and to set up end-to-end system parameters. During the deployment, a monitoring tools will support to validate the deployment and to make sure that the end-to-end system meet the target KPI. Finally, some optimization can be made individually for service placement, network slicing and orchestration or jointly at radio access, multi-access edge computing or core network level.",7,unknown
10.1109/tvt.2021.3126803,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',IEEE Transactions on Vehicular Technology,IEEE,2022-02-01,ieeexplore,mobility-aware controller orchestration in multi-tier service-oriented architecture for iot,https://ieeexplore.ieee.org/document/9610993/,"This work addresses the problem of controller orchestration in Internet of Things (IoT)-based Service-Oriented Architecture. It focuses on the fundamental issues of heterogeneity and dynamism of hybrid edge-cloud networks involving both static and mobile IoT devices for provisioning IoT-based services. Due to the limited capacity of IoT devices, IoT-cloud services require the support of edge networks, termed as ‘Service Edge,’ for meeting their ultra-low latency requirements. In such complex and dynamic networks, software-defined networking (SDN) paradigm is utilized for efficient resource utilization and service-oriented network management. A significant problem in SDN is the controller placement problem. Although researchers proposed several controller placement schemes for SDN, the problem of multi-tier controller placement in hybrid cloud-edge networks has not yet been addressed. In this work, this problem is formulated mathematically and shown to be a variant of the well-known two-level capacitated facility location problem, which is NP-hard. Thereafter, COMET, a scheme based on coalitional game and social choice theory, is proposed to solve the problem in polynomial time. COMET is designed while considering varying loads on the switches due to the presence of mobile IoT devices. Simulations depict that COMET reduces network delay by 49.02% with a significant increase in resiliency compared to the state-of-the-art.",8,unknown
10.1002/ett.3536,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',semantic_scholar,Trans. Emerg. Telecommun. Technol.,2018-01-01,semantic_scholar,"sdn, nfv, and mobile edge computing with qoe support for 5g",https://www.semanticscholar.org/paper/d46992ca7ac9f9d81a16ed1a385da30b3d3a3029,"With the proliferation of latency and bandwidth sensitive mobile applications, the need for new telecommunications standards, with high capacities (eg, 1000 x) to support massive number of connections with diverse requirements, become a crucial need. Such new standards must be capable of serving large number of devices, especially mobile and wearable devices, with the best quality-of-experience (QoE) possible including highly crowded areas. The 5G standard, which is not just an extension to 4G, has emerged as a viable solution to fulfill the aforementioned needs. In this context, 5G promises a paradigm shift, in telecommunication systems and services, by focusing not only on providing high-speed connections with higher data rates, but also in serving large number of devices/users while maintaining high QoE. 5G is regarded as capable of satisfying the resource requirements for the emerging mobile applications such as virtual and augmented reality, vehicular networks (VANETs), and the internet-of-things (IoT) applications. 5G will support emerging communications including machine-to-machine (M2M) communications with low cost, low latency, high bandwidth, and energy efficiency. The deployment of 5G-based systems, which is expected to be available by 2020, will require the integration of multiple new technologies to achieve its goals. Such technologies include Mobile Edge Comping (MEC), wireless virtualization, and software defined systems or networks (SDNs) and Network Function Virtualization (NFV) among others. In addition, methodologies for resource manipulation and sensing as well as allocation for optimized performance so that QoE of the end-users is maximized. Due to the nonlinearity of the QoE model, the resource manipulation with solution provision within the context of SDN for MEC devices should be solved concurrently so that the associated performance can be assessed and evaluated. The inclusion of MEC, SDN, and NFV, and its possible support for 5G systems is emerging as one of the highly active research areas with a large room for improvements. One specific aspect of great importance is the continuously increasing processing, caching, and storage capabilities required by the emerging applications such as IoT and virtual reality. Considering the aforementioned needs, we arranged a special issue in European Transactions on Telecommunications (ETT). In response to the call for contribution of this special issue, we received 19 paper submissions. After a careful review process, 11 outstanding papers were selected for this special section. The first article is entitled “EdgePlace: Availability-aware Placement for Chained Mobile Edge Applications,” co-authored by Zhu, He and Huang, Changcheng. The authors proposed a novel model to track the availability and cost impact from placement policy changes of the mobile edge applications. The authors formulated their model as a stochastic programming problem. To minimize the complexity challenge, they also propose a heuristic algorithm called EdgePlace. The second article is entitled “A Collaborative Mobile Edge Computing and User Solution for Service Composition in 5G Systems,” co-authored by Al Ridhawi, Ismaeel; Aloqaily, Moayad; Kotb, Yehia; Al Ridhawi, Yousif; and Jararweh, Yaser. The authors envision a real-time context-aware service-composition collaborative framework that lies at the edge of the network, comprising MEC and user devices for fast composite service delivery. The proposed solution decomposes cloud data into a set of files and services, which are then replicated to MEC nodes. The third article is entitled “Sub-Carriers Assignment Scheme for Multiple Secondary Users in OFDMA Based IEEE 802.22 WRAN: A Game Theoretic Approach,” co-authored by Gupta, Nitin; Dhurandher, Sanjay; and Woungang, Isaac. The paper developed a suboptimal algorithm in which initially optimal number of subcarriers are found considering the equal power distribution. The problem is formulated as an oligopoly market competition and a noncooperative Cournot game is used in which different unlicensed secondary users (SUs) compete for the number of subcarriers based upon the data rate they are getting from current channel condition. The fair distribution of subcarriers is ensured by finding the Nash equilibrium. The fourth article is entitled “Reinforcement Learning based QoS/QoE-aware Service Function Chaining in Software-Driven 5G Slices,” co-authored by Chen, Xi; Li, Zonghang; Zhang, Yupeng; Long, Ruiming; Yu, Hongfang; Du,",9,unknown
http://arxiv.org/abs/1909.05530v2,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2019-09-12,arxiv,"reinforcing edge computing with multipath tcp enabled mobile device
  clouds",http://arxiv.org/abs/1909.05530v2,"In recent years, enormous growth has been witnessed in the computational and
storage capabilities of mobile devices. However, much of this computational and
storage capabilities are not always fully used. On the other hand, popularity
of mobile edge computing which aims to replace the traditional centralized
powerful cloud with multiple edge servers is rapidly growing. In particular,
applications having strict latency requirements can be best served by the
mobile edge clouds due to a reduced round-trip delay. In this paper we propose
a Multi-Path TCP (MPTCP) enabled mobile device cloud (MDC) as a replacement to
the existing TCP based or D2D device cloud techniques, as it effectively makes
use of the available bandwidth by providing much higher throughput as well as
ensures robust wireless connectivity. We investigate the congestion in
mobile-device cloud formation resulting mainly due to the message passing for
service providing nodes at the time of discovery, service continuity and
formation of cloud composition. We propose a user space agent called congestion
handler that enable offloading of packets from one sub-flow to the other under
link quality constraints. Further, we discuss the benefits of this design and
perform preliminary analysis of the system.",10,not included
http://arxiv.org/abs/1004.3099v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2010-04-19,arxiv,"controlled growth, patterning and placement of carbon nanotube thin
  films",http://arxiv.org/abs/1004.3099v1,"Controlled growth, patterning and placement of carbon nanotube (CNT) thin
films for electronic applications are demonstrated. The density of CNT films is
controlled by optimizing the feed gas composition as well as the concentration
of growth catalyst in a chemical vapor deposition process. Densities of CNTs
ranging from 0.02 CNTs/{\mu}m^2 to 1.29 CNTs/{\mu}m^2 are obtained. The
resulting pristine CNT thin films are then successfully patterned using either
pre-growth or post-growth techniques. By developing a layered photoresist
process that is compatible with ferric nitrate catalyst, significant
improvements over popular pre-growth patterning methods are obtained.
Limitations of traditional post-growth patterning methods are circumvented by
selective transfer printing of CNTs with either thermoplastic or metallic
stamps. Resulting as-grown patterns of CNT thin films have edge roughness (< 1
{\mu}m) and resolution (< 5 {\mu}m) comparable to standard photolithography.
Bottom gate CNT thin film devices are fabricated with field-effect mobilities
up to 20 cm^2/Vs and on/off ratios of the order of 10^3. The patterning and
transfer printing methods discussed here have a potential to be generalized to
include other nanomaterials in new device configurations.",11,unknown
http://arxiv.org/abs/1901.04280v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2019-01-14,arxiv,"sdn-enabled mimo heterogeneous cooperative networks with flexible cell
  association",http://arxiv.org/abs/1901.04280v1,"Small-cell densification is a strategy enabling the offloading of users from
macro base stations (MBSs), in order to alleviate their load and increase the
coverage, especially, for cell-edge users. In parallel, as the network
increases in density, the BS cooperation emerges as an efficient design method
towards the demands for drastic improvement of the system performance against
the detrimental overall interference. In addition, the tiers are enhanced with
cell association policies by introducing the concept of the association
probability. Above this and motivated by the advantages of cooperation among
BSs, the small base stations (SBSs) are enriched with this property in their
design. SBS cooperation allows shedding light into its impact on the cell
selection rules in multi-antenna HetNets. Under these settings,
software-defined networking (SDN) is introduced smoothly to play the leading
role in the orchestration of the network. {In particular, heavy operations such
as the coordination and the cell association are undertaken by virtue of an SDN
controller performing and managing efficiently the corresponding computations
due to its centralized adaptability and dynamicity towards the enhancement and
potential scalability of the network}. In this context, we derive the coverage
probability and the mean achievable rate. Not only we show the outperformance
of BS cooperation over uncoordinated BSs, but we also demonstrate that the SBS
cooperation enables the admittance of more users from the macro-cell BSs
(MBSs). Moreover, we investigate the performance of different transmission
techniques, and we identify the optimal bias in each case when SBSs cooperate.
Finally, we depict that the SBS densification is beneficial until a specific
density value since a further increase does not increase the coverage
probability.",12,unknown
10.1007/978-3-030-69893-5_21,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',Mobile Edge Computing,Springer,2021-01-01,springer,application design and service provisioning for multi-access edge cloud (mec),http://dx.doi.org/10.1007/978-3-030-69893-5_21,"The edge cloud is attractive to provide low latency services to mobile users. It overcomes computation, storage, and energy limitations of mobile devices through computation offloading. It also avoids long delays in migration of big data from the point of their generation by IoT devices to the centralized data centers. Context-aware edge cloud design provides mobile users with more personalized and customized services that improve their over-all experience. It manages the cloud infrastructure for resource provisioning, scheduling, and load balancing. The latency constraints of MEC applications need light-weight container service in the edge cloud. Kubernetes container orchestration is popular in the industry that is supported by all major edge cloud platforms. Container migration is important for ensuring low latency to new mobile applications of connected vehicles and drones. In this chapter we present the current state of research and development in the application design and service provisioning for edge cloud.",13,included
10.1007/978-981-15-3607-6_50,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',Proceedings of International Joint Conference on Computational Intelligence,Springer,2020-01-01,springer,orchestration-based task offloading for mobile edge computing in small-cell networks,http://dx.doi.org/10.1007/978-981-15-3607-6_50,"To execute computation-intensive applications and stringent latency-critical tasks at resource constraints smart mobile devices, mobile edge computing (MEC) in small-cell networks is one of the leading thought, where mobile devices will offload their computation-intensive tasks to the adjacent small-cell network for faster processing. Currently, some research work has been done for combining mobile edge computing and small-cell networks together. Existing researches mostly concentrate on the user to small base station (SBS) offloading and improving the radio access performance using optimization, while the computing capability of SBS-MEC server is ignored. In order to acquire superior performance, an efficient orchestration-based task offloading for mobile edge computing in small-cell networks is proposed in this paper where edge orchestrator collects all the information from the neighboring small-cell SBS-MEC server to decide for forwarding the workloads from overloaded SBS-MEC to nearby SBS-MEC with a light workload. Simulation results affirm that orchestration-based task offloading scheme offers the best results not only by reducing the task failure but also with a smaller task completion time compared to other approaches in small-cell networks.",14,unknown
10.1109/access.2022.3190857,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',IEEE Access,IEEE,2022-01-01,ieeexplore,collaborative resource sharing game based cloud-edge offload computing orchestration scheme,https://ieeexplore.ieee.org/document/9829747/,"In the foreseeable future, the rapid growth of mobile communications and cloud systems has substantially promoted edge computing paradigm. Although edge computing technology has been attracting much interest, most current research is application-specific without considering a control perspective of cloud providers that provides general-purpose edge services. In this study, we present a new cloud-edge computing orchestration scheme that integrates the different resource sharing problems to maximize benefits for offloading computing services. Specifically, we focus on two cooperative game solutions -<i>Sim bargaining solution</i> and <i>interval Banzhaf Value</i>- to effectively share the computing, communication and cache resources in the cloud-edge system platform. In the proposed scheme, we formalize two different cooperative games, and they work together and act cooperatively to satisfy contradictory requirements. Under widely different service request situations, we aim at accelerating an efficient resource orchestration through dynamic workload balancing. The primary goal of our cooperative game approach is to find optimal control decisions toward the appropriate system operation. Finally, we evaluate the proposed scheme in terms of several performance criteria from the numerical simulations. Experimental results show that we can achieve a mutually desirable solution with a good system performance balance while enhancing the resource efficiency better than the existing cloud-edge control protocols.",15,unknown
10.1109/fmec.2018.8364042,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',2018 Third International Conference on Fog and Mobile Edge Computing (FMEC),IEEE,2018-04-26,ieeexplore,formal definition of edge computing: an emphasis on mobile cloud and iot composition,https://ieeexplore.ieee.org/document/8364042/,"Under the Edge computing umbrella, mobile cloud computing is an emerging area where two trends come together to compose its major pillars. On one hand, the virtualization affecting the data centers hypervisors. On the other hand, device's mobility, especially Smart Phones, which proved to be the most effective and convenient tools in human life. This emerging area is then changing the game in terms of mobility of workspaces and the interaction with the connected devices and sensors. This paper provides a formal specification of the Mobile cloud component using the n-calculus. The proposed model defines the mobile cloud component, the virtual device representation, and interaction that leads to application offloading and device composition. This paper describe our contribution that enables the composition of virtual devices from physical devices, sensors, and actuators available on the network. Moreover, we present a model of application offloading and virtual devices networking on mobile clouds. Our architectural model is inspired from the Cloudlet based system. In addition to the formal specifications and architecture this paper presents a case studies showing the structural congruence between a locally executed application and an offloaded version of that same application.",16,not included
10.1109/globecom46510.2021.9685091,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',2021 IEEE Global Communications Conference (GLOBECOM),IEEE,2021-12-11,ieeexplore,blockchain and fl-based network resource management for interactive immersive services,https://ieeexplore.ieee.org/document/9685091/,"Advanced services leveraged for future smart cities have played a significant role in the advancement of 5G networks towards the 6G vision. Interactive immersive applications are an example of those enabled services. Such applications allow for the interaction between multiple users in a 3D environment created by virtual presentations of real objects and participants using various technologies such as Virtual Reality (VR), Augmented Reality (AR), Extended Reality (XR), Digital Twin (DT) and holography. These applications require advanced computing models which allow for the processing of massive gathered amounts of data. Motions, gestures and object modification should be captured, added to the virtual environment, and shared with all the participants. Relying only on the cloud to process this data can cause significant delays. Therefore, a hybrid cloud/edge architecturewith an intelligent resource orchestration mechanism, that is able to allocate the available capacities efficiently is necessary. In this paper, a blockchain and federated learning-enabled predicted edge-resource allocation (FLP-RA) algorithm is introduced to manage the allocation of computing resources in B5G networks. It allows for smart edge nodes to train their local data and share it with other nodes to create a global estimation of future network loads. As such, nodes are able to make accurate decisions to distribute the available resources to provide the lowest computing delay.",17,unknown
http://arxiv.org/abs/2201.11067v3,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2022-01-26,arxiv,roma: resource orchestration for microservices-based 5g applications,http://arxiv.org/abs/2201.11067v3,"With the growth of 5G, Internet of Things (IoT), edge computing and cloud
computing technologies, the infrastructure (compute and network) available to
emerging applications (AR/VR, autonomous driving, industry 4.0, etc.) has
become quite complex. There are multiple tiers of computing (IoT devices, near
edge, far edge, cloud, etc.) that are connected with different types of
networking technologies (LAN, LTE, 5G, MAN, WAN, etc.). Deployment and
management of applications in such an environment is quite challenging. In this
paper, we propose ROMA, which performs resource orchestration for
microservices-based 5G applications in a dynamic, heterogeneous, multi-tiered
compute and network fabric. We assume that only application-level requirements
are known, and the detailed requirements of the individual microservices in the
application are not specified. As part of our solution, ROMA identifies and
leverages the coupling relationship between compute and network usage for
various microservices and solves an optimization problem in order to
appropriately identify how each microservice should be deployed in the complex,
multi-tiered compute and network fabric, so that the end-to-end application
requirements are optimally met. We implemented two real-world 5G applications
in video surveillance and intelligent transportation system (ITS) domains.
Through extensive experiments, we show that ROMA is able to save up to 90%, 55%
and 44% compute and up to 80%, 95% and 75% network bandwidth for the
surveillance (watchlist) and transportation application (person and car
detection), respectively. This improvement is achieved while honoring the
application performance requirements, and it is over an alternative scheme that
employs a static and overprovisioned resource allocation strategy by ignoring
the resource coupling relationships.",18,included
http://arxiv.org/abs/2109.07999v2,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2021-09-16,arxiv,"learning from peers: deep transfer reinforcement learning for joint
  radio and cache resource allocation in 5g ran slicing",http://arxiv.org/abs/2109.07999v2,"Radio access network (RAN) slicing is an important pillar in cross-domain
network slicing which covers RAN, edge, transport and core slicing. The
evolving network architecture requires the orchestration of multiple network
resources such as radio and cache resources. In recent years, machine learning
(ML) techniques have been widely applied for network management. However, most
existing works do not take advantage of the knowledge transfer capability in
ML. In this paper, we propose a deep transfer reinforcement learning (DTRL)
scheme for joint radio and cache resource allocation to serve 5G RAN slicing.
We first define a hierarchical architecture for the joint resource allocation.
Then we propose two DTRL algorithms: Q-value-based deep transfer reinforcement
learning (QDTRL) and action selection-based deep transfer reinforcement
learning (ADTRL). In the proposed schemes, learner agents utilize expert
agents' knowledge to improve their performance on target tasks. The proposed
algorithms are compared with both the model-free exploration bonus deep
Q-learning (EB-DQN) and the model-based priority proportional fairness and
time-to-live (PPF-TTL) algorithms. Compared with EB-DQN, our proposed DTRL
based method presents 21.4% lower delay for Ultra Reliable Low Latency
Communications (URLLC) slice and 22.4% higher throughput for enhanced Mobile
Broad Band (eMBB) slice, while achieving significantly faster convergence than
EB-DQN. Moreover, 40.8% lower URLLC delay and 59.8% higher eMBB throughput are
observed with respect to PPF-TTL.",19,unknown
10.1109/atnac.2017.8215347,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',2017 27th International Telecommunication Networks and Applications Conference (ITNAC),IEEE,2017-11-24,ieeexplore,keynote topic: network cloudification: sdn-nfv and 5g-mec with edge and fog computing,https://ieeexplore.ieee.org/document/8215347/,"The second wave of cloud computing, named network cloudification, in the forms of SDN (Software Defined Networking), NFV (Network Function Virtualization), and 5G-MEC (Mobile Edge Computing), is to centralize and virtualize networking into data centers. It enables operators to offer NaaS (Networking as a Service) with much lower CAPEX and OPEX with larger flexibility because devices become simpler, the number of administrators is less, and service orchestration is easier. It turns parts of communications currently done in hardware into computing done in software. However, the host of these data centers would not be Google-like super data centers as they are too far away from subscribers. The latency requirement of 10ms and 1ms decentralizes cloud computing down to edge and fog computing with CORD (central offices re-architected as data centers) and cellular base stations for SDN-NFV and 5G-MEC, respectively. In this talk, we first argue why, where and when SDN, NFV, 5G-MEC would prevail, and then illustrate how to make it happen with OpenFlow, SC (Service Chaining), NSH (Network Service header), etc. Then we examine how latency requirement dominates this virtualization game by listing key questions to answer in resource allocation in the architectures of SDN, NFV, and 5G-MEC. Their answers are mostly unknown now but would benefit the architects and developers of OpenFlow switches, SDN controllers, SDN-NFV apps, NFV data centers, MEC-enabled base stations, and operator's infrastructure in general.",20,not included
10.1109/vtc2021-fall52928.2021.9625307,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall),IEEE,2021-09-30,ieeexplore,machine learning based mmwave orchestration for edge gaming qoe enhancement,https://ieeexplore.ieee.org/document/9625307/,"Millimeter wave (mmWave) is a crucial component in 5G and beyond 5G communications. However, the dense deployment of mmWave transceivers imposes a heavy burden on the management of radio access network (RAN). This challenge increases the need for autonomous network management methods leveraging machine learning (ML) techniques. In particular, mmWave beam selection is a critical issue for the management of RAN due to the large training overhead on mmWave transceivers. To this end, a new beam tracking method based on sequence-to-sequence (Seq2Seq) learning is proposed. Besides, thanks to edge computing technologies, network management algorithms and delay-sensitive user applications can be hosted on edge servers in close proximity. Due to limited resources on the edge server, the resource allocation problem for beam tracking and edge gaming is investigated with the aim of maximizing game quality of experience (QoE). Simulation results verify the effectiveness of the proposed orchestration scheme.",21,included
10.1007/s13369-022-06563-5,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',Arabian Journal for Science and Engineering,Springer,2022-01-29,springer,optimized resource allocation for fog network using neuro-fuzzy offloading approach,http://dx.doi.org/10.1007/s13369-022-06563-5,"Fog computing has emerged as one of the most important Internet infrastructures for improving service quality, particularly in real-time applications. Due to the convergence in technologies, the scope of the Internet of things (IoT) has evolved to a new dimension, it expands from data collection to device interconnections, and to pre-processing. This acceleration involves cloud and fog computing layers into the system which plays an integral role in IoT data storage and computing. Due to the diversity present in IoT devices, selection of computation devices and allocation of resources are major challenges to be addressed for efficient utilization of resources. In this paper, we presented the offloading and resource allocation model to address the solution to the above challenge. Firstly, a 5-layered neuro-fuzzy model is introduced to retrieve the fuzzy sets and rules which further passes to the fuzzy inference system to model an orchestration decision system. Additionally, to improve the system performance, we have presented the modified least loaded resource allocation algorithm which is adaptively required to reduce the failure rate of the applications. To showcase the efficacy of the model, 4 healthcare applications (augmented reality, patient pre-monitoring, record analysis, and billing systems) are evaluated with their heterogeneous parameters. The simulation findings show that our suggested model improves system performance by lowering network latency by 2.23–9.68 %, computation delay by 3.40–13.66 %, and system performance by 1.03–11.55%. The simulation results demonstrated the suggested model’s resilience in terms of network latency, computation time, and failure rate.",22,included
http://arxiv.org/abs/2002.05531v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2020-02-12,arxiv,modelling fog offloading performance,http://arxiv.org/abs/2002.05531v1,"Fog computing has emerged as a computing paradigm aimed at addressing the
issues of latency, bandwidth and privacy when mobile devices are communicating
with remote cloud services. The concept is to offload compute services closer
to the data. However many challenges exist in the realisation of this approach.
During offloading, (part of) the application underpinned by the services may be
unavailable, which the user will experience as down time. This paper describes
work aimed at building models to allow prediction of such down time based on
metrics (operational data) of the underlying and surrounding infrastructure.
Such prediction would be invaluable in the context of automated Fog offloading
and adaptive decision making in Fog orchestration. Models that cater for four
container-based stateless and stateful offload techniques, namely Save and
Load, Export and Import, Push and Pull and Live Migration, are built using four
(linear and non-linear) regression techniques. Experimental results comprising
over 42 million data points from multiple lab-based Fog infrastructure are
presented. The results highlight that reasonably accurate predictions (measured
by the coefficient of determination for regression models, mean absolute
percentage error, and mean absolute error) may be obtained when considering 25
metrics relevant to the infrastructure.",23,unknown
10.1007/978-3-030-48340-1_11,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',Euro-Par 2019: Parallel Processing Workshops,Springer,2020-01-01,springer,mf2c: the evolution of cloud computing towards an open and coordinated ecosystem of fogs and clouds,http://dx.doi.org/10.1007/978-3-030-48340-1_11,"Fog computing brings cloud computing capabilities closer to the end-devices and users, while enabling location-dependent resource allocation, low latency services, and extending significantly the IoT services portfolio as well as market and business opportunities in the cloud and IoT sectors. With the number of devices growing exponentially globally, new cloud and fog models are expected to emerge, paving the way for shared, collaborative, extensible mobile, volatile and dynamic compute, storage and network infrastructure. When put together, cloud and fog computing create a new stack of resources, which we refer to as Fog-to-Cloud (F2C), creating the need for a new, open and coordinated management ecosystem. The EU Horizon 2020 program has recently funded a new research initiative (mF2C) bringing together relevant industry and academic players in the cloud arena, aimed at designing an open, secure, decentralized, multistakeholder management framework for F2C computing, including novel programming models, privacy and security, data storage techniques, service creation, brokerage solutions, SLA policies, and resource orchestration methods. This paper introduces the main mF2C concepts, illustrates the need for a coordinated management ecosystem, proposes a preliminary design of its foundational building blocks and presents results that show the benefits mF2C may have on three key real-world scenarios.",24,unknown
10.1109/access.2021.3085370,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',IEEE Access,IEEE,2021-01-01,ieeexplore,service placement for latency reduction in the fog using application profiles,https://ieeexplore.ieee.org/document/9445114/,"The Cloud-Fog-Internet of Things continuum combines different paradigms to provide connectivity and ubiquity for end-users, while also granting low latency and low jitter to cope with different challenges, including the requirements of latency-sensitive applications, such as virtual/augmented reality and online gaming. This constitutes a complex and dynamic environment with heterogeneous resources that need to be managed or orchestrated, in order to accomplish application requirements for low latency. Common orchestration solutions make placement decisions based only on the resources of the underlying network and the application resource requests; however, using the profiles of applications to make placement decisions has the potential to enhance the final performance perceived by the end-users. This paper proposes the use of application profiles according to their popularity to guide their placement. To corroborate the effectiveness of the use of the profiles, two placement mechanisms are presented, one based on Genetic Algorithm and the other inspired on graph partitions. Simulation results show that it is possible to reduce the latency and jitter of applications via a service placement guided by the profiles. The mechanism based on graph partitions showed better results for all scenarios, followed closely by the Genetic Algorithm in the scenarios with lower load.",25,unknown
http://arxiv.org/abs/2104.14392v3,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2021-04-29,arxiv,"cosco: container orchestration using co-simulation and gradient based
  optimization for fog computing environments",http://arxiv.org/abs/2104.14392v3,"Intelligent task placement and management of tasks in large-scale fog
platforms is challenging due to the highly volatile nature of modern workload
applications and sensitive user requirements of low energy consumption and
response time. Container orchestration platforms have emerged to alleviate this
problem with prior art either using heuristics to quickly reach scheduling
decisions or AI driven methods like reinforcement learning and evolutionary
approaches to adapt to dynamic scenarios. The former often fail to quickly
adapt in highly dynamic environments, whereas the latter have run-times that
are slow enough to negatively impact response time. Therefore, there is a need
for scheduling policies that are both reactive to work efficiently in volatile
environments and have low scheduling overheads. To achieve this, we propose a
Gradient Based Optimization Strategy using Back-propagation of gradients with
respect to Input (GOBI). Further, we leverage the accuracy of predictive
digital-twin models and simulation capabilities by developing a Coupled
Simulation and Container Orchestration Framework (COSCO). Using this, we create
a hybrid simulation driven decision approach, GOBI*, to optimize Quality of
Service (QoS) parameters. Co-simulation and the back-propagation approaches
allow these methods to adapt quickly in volatile environments. Experiments
conducted using real-world data on fog applications using the GOBI and GOBI*
methods, show a significant improvement in terms of energy consumption,
response time, Service Level Objective and scheduling time by up to 15, 40, 4,
and 82 percent respectively when compared to the state-of-the-art algorithms.",26,unknown
http://arxiv.org/abs/1812.00300v1,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',arxiv,arxiv,2018-12-02,arxiv,"containers orchestration with cost-efficient autoscaling in cloud
  computing environments",http://arxiv.org/abs/1812.00300v1,"Containers are standalone, self-contained units that package software and its
dependencies together. They offer lightweight performance isolation, fast and
flexible deployment, and fine-grained resource sharing. They have gained
popularity in better application management and deployment in recent years and
are being widely used by organizations to deploy their increasingly diverse
workloads such as web services, big data, and IoT in either proprietary
clusters or cloud data centres. This has led to the emergence of container
orchestration platforms, which are designed to manage the deployment of
containerized applications in large-scale clusters. The majority of these
platforms are tailored to optimize the scheduling of containers on a
fixed-sized private cluster but are not enabled to autoscale the size of the
cluster nor to consider features specific to public cloud environments. In this
work, we propose a comprehensive container resource management approach that
has three different objectives. The first one is to optimize the initial
placement of containers by efficiently scheduling them on existing resources.
The second one is to autoscale the number of resources at runtime based on the
current cluster's workload. The third one is a rescheduling mechanism to
further support the efficient use of resources by consolidating applications
into fewer VMs when possible. Our algorithms are implemented as a
plugin-scheduler for Kubernetes platform. We evaluated our framework and the
effectiveness of the proposed algorithms on an Australian national cloud
infrastructure. Our experiments demonstrate that considerable cost savings can
be achieved by dynamically managing the cluster size and placement of
applications. We find that our proposed approaches are capable of reducing the
cost by 58% when compared to the default Kubernetes scheduler.",27,unknown
10.23919/wons.2018.8311675,filtered,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement',2018 14th Annual Conference on Wireless On-demand Network Systems and Services (WONS),IEEE,2018-02-08,ieeexplore,an agent-based network resource management concept for smart city services,https://ieeexplore.ieee.org/document/8311675/,"Massive data generation with the introduction of IoT devices and new technologies in smart cities require a flexible network management architecture to meet the dynamic demands of smart city services. In project ISCO (Intelligent Framework for Service Discovery and Composition), we envision a smart city network operator that is tenant to multiple smart city services, and it can provide network resources and network functions on-demand to satisfy the connectivity requirements of these services. To explain this structure, we present an augmented sightseeing scenario that reflects various smart city service requirements. Then, we give an insight into the technological enablers of ISCO network management platform and explain how these technologies can satisfy the needs of the smart city scenario. Finally, we briefly present our ISCO network architecture and network resource management approach, which uses a distributed game-theory based learning algorithm to solve a multi-agent decision problem, and discuss how autonomous network management concept can be used to optimize resource allocation in our smart city communication platform.",28,unknown
