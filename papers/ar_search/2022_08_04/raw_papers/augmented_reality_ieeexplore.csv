doi,title,publisher,content_type,abstract,html_url,publication_title,publication_date,database,query_name,query_value
,A Rank-based Mechanism for Service Placement in the Fog,IEEE,Conferences,"As communications evolve to give space to new applications, such as augmented reality and virtual reality, new paradigms arise to provide essential characteristics like lower latency levels, mobility support, and location awareness. Such is the case of Fog computing, which extends from the well-known Cloud computing paradigm by bringing processing, communications, and storage capabilities to the edge of the network. By offering these novel features, also new challenges emerge that call for the design and implementation of orchestration mechanisms to deal with resource management. One of these mechanisms is related to the service placement, which consists in the selection of the appropriate execution node for the applications according to a specific optimization objective. In this paper, an Integer Linear Programming model for service placement aimed at latency reduction of popular applications is proposed. Furthermore, a heuristic based on the PageRank algorithm, called Popularity Ranked Placement, is also introduced. Simulation results show that the heuristic has lower execution times and is able to better balance the load in the network nodes, while being close to the ILP-based solution latency levels.",https://ieeexplore.ieee.org/document/9142750/,2020 IFIP Networking Conference (Networking),22-26 June 2020,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/NetSoft48620.2020.9165443,ANI: Abstracted Network Inventory for Streamlined Service Placement in Distributed Clouds,IEEE,Conferences,"Scenarios for distributed cloud with multiple edge clouds and centralized data centers are being investigated as the computing and networking underpinnings of next-generation network services such as augmented reality, self-driving vehicles, drones, and more. In such distributed environments, service providers will typically face tens, hundreds, or thousands of compute location candidates (edge, regional, and central) where network service components can be placed. To take optimized placement decisions of network services and execute the management workflows, orchestration systems require up-to-date and accurate resource availability representation, in the form of a network inventory that can be immense in distributed cloud scenarios. As a result, the service management and placement problems may become not tractable. In this work, we propose the Abstracted Network Inventory (ANI) component to generate service-optimized network views over the same network inventory. ANI implements a novel abstraction method where network service requirements are used as an input to generate an optimized abstract network inventory representation, called Logical Network Inventory (LNI). We also provide a formal definition of the network model and problem statement along with the development of three algorithms to efficiently build an LNI. Results show the potential benefits of using an LNI to streamline service management and placement: (i) the relationship between compute nodes and links (i.e., density) in an LNI is reduced between 1.8-2.7x compared to a full network inventory topology; and (ii) up to 50% of time can be saved for service placement after abstracting around 20% of the compute nodes.",https://ieeexplore.ieee.org/document/9165443/,2020 6th IEEE Conference on Network Softwarization (NetSoft),29 June-3 July 2020,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/ICTAI52525.2021.00137,Adaptive Workload Orchestration in Pure Edge Computing: A Reinforcement-Learning Model,IEEE,Conferences,"Edge computing is a promising paradigm that can address the requirements of compute-intensive tasks generated by delay-sensitive applications, through bringing processing and storage to the edge of the network. Task offloading is challenging in open and dynamic environments where applications with various Service Level Agreement (SLA) and Quality of Service (QoS) requirements frequently produce a fluctuated workload at the edge of a network with heterogeneous, mobile, and geodistributed nodes.The current literature has addressed this challenge by offloading tasks to fog or Mobile Edge Computing (MEC) servers. However, in strictly delay-sensitive applications such as augmented reality, autonomous driving, or remote surgery, a Pure Edge Computing (PEC) paradigm that allows peer-to-peer communication and cooperation is more reasonable.This paper proposes a novel learning-based task offloading model that enables a pure edge-based system with mobile and resource-constrained nodes to accommodate fluctuating workload generated by applications with various SLAs and QoS. The results show a better utilization of resources and tasks success rate when compared to the state-of-the-art algorithms.",https://ieeexplore.ieee.org/document/9643374/,2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI),1-3 Nov. 2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/GLOBECOM46510.2021.9685091,Blockchain and FL-based Network Resource Management for Interactive Immersive Services,IEEE,Conferences,"Advanced services leveraged for future smart cities have played a significant role in the advancement of 5G networks towards the 6G vision. Interactive immersive applications are an example of those enabled services. Such applications allow for the interaction between multiple users in a 3D environment created by virtual presentations of real objects and participants using various technologies such as Virtual Reality (VR), Augmented Reality (AR), Extended Reality (XR), Digital Twin (DT) and holography. These applications require advanced computing models which allow for the processing of massive gathered amounts of data. Motions, gestures and object modification should be captured, added to the virtual environment, and shared with all the participants. Relying only on the cloud to process this data can cause significant delays. Therefore, a hybrid cloud/edge architecturewith an intelligent resource orchestration mechanism, that is able to allocate the available capacities efficiently is necessary. In this paper, a blockchain and federated learning-enabled predicted edge-resource allocation (FLP-RA) algorithm is introduced to manage the allocation of computing resources in B5G networks. It allows for smart edge nodes to train their local data and share it with other nodes to create a global estimation of future network loads. As such, nodes are able to make accurate decisions to distribute the available resources to provide the lowest computing delay.",https://ieeexplore.ieee.org/document/9685091/,2021 IEEE Global Communications Conference (GLOBECOM),7-11 Dec. 2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/INFCOMW.2019.8845035,Demo Abstract: Turning OpenStack into a Fog Orchestrator,IEEE,Conferences,"5G networks are expected to enable revolutionary services to be established, such as tactile Internet and online augmented reality applications. These services require a dynamically programmable back-haul network topology in order to serve large amount of network traffic and to guarantee near real-time response times. For high flexibility of service capabilities service functions will be deployed in virtualized environments instead of the currently used special purpose hardware. The most widely used Virtual Infrastructure Manager (VIM) is OpenStack, which is responsible for managing compute, storage and virtual network resources. As the current scheduler of OpenStack does not take into account the underlying physical network characteristics, in order to deploy network services (NS) in a geographically distributed infrastructure, multiple VIMs and an orchestrator on top of them, are necessary for resource management. In contrast to today's setups we show a novel solution that merges these functionalities under one common OpenStack domain: our solution is capable of i) measuring the bandwidth and delay characteristics of the underlying physical network among compute nodes, ii) creating a topology model that contains both compute-, and network-related features, iii) mapping the incoming service requests, and re-mapping already deployed services to the underlying resources with our novel orchestration algorithm, iv) deploying and migrating services via OpenStack API calls.",https://ieeexplore.ieee.org/document/8845035/,IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),29 April-2 May 2019,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/TNSM.2021.3050009,Managing Chains of Application Functions Over Multi-Technology Edge Networks,IEEE,Journals,"Next-generation networks are expected to provide higher data rates and ultra-low latency in support of demanding applications, such as virtual and augmented reality, robots and drones, etc. To meet these stringent requirements of applications, edge computing constitutes a central piece of the solution architecture wherein functional components of an application can be deployed over the edge network to reduce bandwidth demand over the core network while providing ultra-low latency communication to users. In this article, we provide solutions to resource orchestration and management for applications over a virtualized client-edge-server infrastructure. We investigate the problem of optimal placement of pipelines of application functions (virtual service chains) and the steering of traffic through them, over a multi-technology edge network model consisting of both wired and wireless millimeter-wave (mmWave) links. This problem is NP-hard. We provide a comprehensive “microscopic” binary integer program to model the system, along with a heuristic that is one order of magnitude faster than optimally solving the problem. Extensive evaluations demonstrate the benefits of orchestrating virtual service chains (by distributing them over the edge network) compared to a baseline “middlebox” approach in terms of overall admissible virtual capacity. Moreover, we observe significant gains when deploying a small number of mmWave links that complement the Wire physical infrastructure in high node density networks.",https://ieeexplore.ieee.org/document/9316983/,IEEE Transactions on Network and Service Management,March 2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/ACCESS.2021.3085370,Service Placement for Latency Reduction in the Fog Using Application Profiles,IEEE,Journals,"The Cloud-Fog-Internet of Things continuum combines different paradigms to provide connectivity and ubiquity for end-users, while also granting low latency and low jitter to cope with different challenges, including the requirements of latency-sensitive applications, such as virtual/augmented reality and online gaming. This constitutes a complex and dynamic environment with heterogeneous resources that need to be managed or orchestrated, in order to accomplish application requirements for low latency. Common orchestration solutions make placement decisions based only on the resources of the underlying network and the application resource requests; however, using the profiles of applications to make placement decisions has the potential to enhance the final performance perceived by the end-users. This paper proposes the use of application profiles according to their popularity to guide their placement. To corroborate the effectiveness of the use of the profiles, two placement mechanisms are presented, one based on Genetic Algorithm and the other inspired on graph partitions. Simulation results show that it is possible to reduce the latency and jitter of applications via a service placement guided by the profiles. The mechanism based on graph partitions showed better results for all scenarios, followed closely by the Genetic Algorithm in the scenarios with lower load.",https://ieeexplore.ieee.org/document/9445114/,IEEE Access,2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/ACCESS.2019.2948399,"What the Fog? Edge Computing Revisited: Promises, Applications and Future Challenges",IEEE,Journals,"Edge computing brings computing and storage resources closer to (mobile) end users and data sources, thus bypassing expensive and slow links to distant cloud computing infrastructures. Often leveraged opportunistically, these heterogeneous resources can be used to offload data and computations, enabling upcoming demanding applications such as augmented reality and autonomous driving. Research in this direction has addressed various challenges, from architectural concerns to runtime optimizations. As of today, however, we lack a widespread availability of edge computing-partly because it remains unclear which of the promised benefits of edge computing are relevant for what types of applications. This article provides a comprehensive snapshot of the current edge computing landscape, with a focus on the application perspective. We outline the characteristics of edge computing and its postulated benefits and drawbacks. To understand the functional composition of applications, we first define common application components that are relevant w.r.t. edge computing. We then present a classification of proposed use cases and analyze them according to their expected benefits from edge computing and which components they use. Furthermore, we illustrate existing products and industry solutions that have recently surfaced and outline future research challenges.",https://ieeexplore.ieee.org/document/8877785/,IEEE Access,2019,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.23919/CNSM52442.2021.9615539,Efficient Orchestration of Service Chains in Fog Computing for Immersive Media,IEEE,Conferences,"Immersive media services, such as Augmented and Virtual Reality (AR/VR) are getting significant attention in recent years with the promise of bringing immersive experiences to end users. However, despite the remarkable advances in the field, AR/VR applications are mostly local and individual experiences. The main obstacle between current technology and future remote, multi-user AR/VR applications is the stringent end-to-end (E2E) latency requirement, which cannot exceed 20 ms to avoid motion sickness. Emerging AR/VR services put even more pressure on current network infrastructures, calling for considerable advancements toward fully cloud-native architectures. Cloud-based VR services, where participants can virtually interact across vast distances, remain a distant dream. Several challenges still arise concerning the deployment and management of VR services. This paper presents a Mixed-Integer Linear Programming (MILP) formulation for the efficient orchestration of VR services in fog-cloud infrastructures. The model considers Fog Computing (FC), an extension of cloud computing, and Segment Routing (SR), which leverages the source routing paradigm. The evaluation of realistic VR container-based service chains shows that deploying VR components hosted in a fog-cloud infrastructure can satisfy the 20 ms latency boundary.",https://ieeexplore.ieee.org/document/9615539/,2021 17th International Conference on Network and Service Management (CNSM),25-29 Oct. 2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/NOMS54207.2022.9789821,ROMA: Resource Orchestration for Microservices-based 5G Applications,IEEE,Conferences,"With the growth of 5G, Internet of Things (IoT), edge computing and cloud computing technologies, the infrastructure (compute and network) available to emerging applications (AR/VR, autonomous driving, industry 4.0, etc.) has become quite complex. There are multiple tiers of computing (IoT devices, near edge, far edge, cloud, etc.) that are connected with different types of networking technologies (LAN, LTE, 5G, MAN, WAN, etc.). Deployment and management of applications in such an environment is quite challenging. In this paper, we propose ROMA, which performs resource orchestration for microservices-based 5G applications in a dynamic, heterogeneous, multi-tiered compute and network fabric. We assume that only application-level requirements are known, and the detailed requirements of the individual microservices in the application are not specified. As part of our solution, ROMA identifies and leverages the coupling relationship between compute and network usage for various microservices and solves an optimization problem in order to appropriately identify how each microservice should be deployed in the complex, multi-tiered compute and network fabric, so that the end-to-end application requirements are optimally met. We implemented two real-world 5G applications in video surveillance and intelligent transportation system (ITS) domains. Through extensive experiments, we show that ROMA is able to save up to 90%, 55% and 44% compute and up to 80%, 95% and 75% network bandwidth for the surveillance (watchlist) and transportation application (person and car detection), respectively. This improvement is achieved while honoring the application performance requirements, and it is over an alternative scheme that employs a static and overprovisioned resource allocation strategy by ignoring the resource coupling relationships.",https://ieeexplore.ieee.org/document/9789821/,NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium,25-29 April 2022,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/INFOCOM.2018.8486021,"Dynamic, Latency-Optimal vNF Placement at the Network Edge",IEEE,Conferences,"Future networks are expected to support low-latency, context-aware and user-specific services in a highly flexible and efficient manner. One approach to support emerging use cases such as, e.g., virtual reality and in-network image processing is to introduce virtualized network functions (vNF)s at the edge of the network, placed in close proximity to the end users to reduce end-to-end latency, time-to-response, and unnecessary utilisation in the core network. While placement of vNFs has been studied before, it has so far mostly focused on reducing the utilisation of server resources (i.e., minimising the number of servers required in the network to run a specific set of vNFs), and not taking network conditions into consideration such as, e.g., end-to-end latency, the constantly changing network dynamics, or user mobility patterns. In this paper, we formulate the Edge vNF placement problem to allocate vNFs to a distributed edge infrastructure, minimising end-to-end latency from all users to their associated vNFs. We present a way to dynamically re-schedule the optimal placement of vNFs based on temporal network-wide latency fluctuations using optimal stopping theory. We then evaluate our dynamic scheduler over a simulated nation-wide backbone network using real-world ISP latency characteristics. We show that our proposed dynamic placement scheduler minimises vNF migrations compared to other schedulers (e.g., periodic and always-on scheduling of a new placement), and offers Quality of Service guarantees by not exceeding a maximum number of latency violations that can be tolerated by certain applications.",https://ieeexplore.ieee.org/document/8486021/,IEEE INFOCOM 2018 - IEEE Conference on Computer Communications,16-19 April 2018,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/ACCESS.2022.3190857,Collaborative Resource Sharing Game Based Cloud-Edge Offload Computing Orchestration Scheme,IEEE,Journals,"In the foreseeable future, the rapid growth of mobile communications and cloud systems has substantially promoted edge computing paradigm. Although edge computing technology has been attracting much interest, most current research is application-specific without considering a control perspective of cloud providers that provides general-purpose edge services. In this study, we present a new cloud-edge computing orchestration scheme that integrates the different resource sharing problems to maximize benefits for offloading computing services. Specifically, we focus on two cooperative game solutions -<i>Sim bargaining solution</i> and <i>interval Banzhaf Value</i>- to effectively share the computing, communication and cache resources in the cloud-edge system platform. In the proposed scheme, we formalize two different cooperative games, and they work together and act cooperatively to satisfy contradictory requirements. Under widely different service request situations, we aim at accelerating an efficient resource orchestration through dynamic workload balancing. The primary goal of our cooperative game approach is to find optimal control decisions toward the appropriate system operation. Finally, we evaluate the proposed scheme in terms of several performance criteria from the numerical simulations. Experimental results show that we can achieve a mutually desirable solution with a good system performance balance while enhancing the resource efficiency better than the existing cloud-edge control protocols.",https://ieeexplore.ieee.org/document/9829747/,IEEE Access,2022,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/IWCMC51323.2021.9498596,A NFV-based Resource Orchestration Algorithm for DDoS Mitigation in MEC,IEEE,Conferences,"With the emergence of computationally intensive and delay sensitive applications, mobile edge computing(MEC) has become more and more popular. Simultaneously, MEC paradigm is faced with security challenges, the most harmful of which is DDoS attack. In this paper, we focus on the resource orchestration algorithm in MEC scenario to mitigate DDoS attack. Most of existing works on resource orchestration algorithm barely take into account DDoS attack. Moreover, they assume that MEC nodes are unselfish, while in practice MEC nodes are selfish and try to maximize their individual utility only, as they usually belong to different network operators. To solve such problems, we propose a price-based resource orchestration algorithm(PROA) using game theory and convex optimization, which aims at mitigating DDoS attack while maximizing the utility of each participant. Pricing resources to simulate market mechanisms, which is national to make rational decisions for all participants. Finally, we conduct experiment using Matlab and show that the proposed PROA can effectively mitigate DDoS attack on the attacked MEC node.",https://ieeexplore.ieee.org/document/9498596/,2021 International Wireless Communications and Mobile Computing (IWCMC),28 June-2 July 2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.23919/WONS.2018.8311675,An agent-based network resource management concept for smart city services,IEEE,Conferences,"Massive data generation with the introduction of IoT devices and new technologies in smart cities require a flexible network management architecture to meet the dynamic demands of smart city services. In project ISCO (Intelligent Framework for Service Discovery and Composition), we envision a smart city network operator that is tenant to multiple smart city services, and it can provide network resources and network functions on-demand to satisfy the connectivity requirements of these services. To explain this structure, we present an augmented sightseeing scenario that reflects various smart city service requirements. Then, we give an insight into the technological enablers of ISCO network management platform and explain how these technologies can satisfy the needs of the smart city scenario. Finally, we briefly present our ISCO network architecture and network resource management approach, which uses a distributed game-theory based learning algorithm to solve a multi-agent decision problem, and discuss how autonomous network management concept can be used to optimize resource allocation in our smart city communication platform.",https://ieeexplore.ieee.org/document/8311675/,2018 14th Annual Conference on Wireless On-demand Network Systems and Services (WONS),6-8 Feb. 2018,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/FMEC.2018.8364042,Formal definition of edge computing: An emphasis on mobile cloud and IoT composition,IEEE,Conferences,"Under the Edge computing umbrella, mobile cloud computing is an emerging area where two trends come together to compose its major pillars. On one hand, the virtualization affecting the data centers hypervisors. On the other hand, device's mobility, especially Smart Phones, which proved to be the most effective and convenient tools in human life. This emerging area is then changing the game in terms of mobility of workspaces and the interaction with the connected devices and sensors. This paper provides a formal specification of the Mobile cloud component using the n-calculus. The proposed model defines the mobile cloud component, the virtual device representation, and interaction that leads to application offloading and device composition. This paper describe our contribution that enables the composition of virtual devices from physical devices, sensors, and actuators available on the network. Moreover, we present a model of application offloading and virtual devices networking on mobile clouds. Our architectural model is inspired from the Cloudlet based system. In addition to the formal specifications and architecture this paper presents a case studies showing the structural congruence between a locally executed application and an offloaded version of that same application.",https://ieeexplore.ieee.org/document/8364042/,2018 Third International Conference on Fog and Mobile Edge Computing (FMEC),23-26 April 2018,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/ATNAC.2017.8215347,Keynote topic: Network cloudification: SDN-NFV and 5G-MEC with edge and fog computing,IEEE,Conferences,"The second wave of cloud computing, named network cloudification, in the forms of SDN (Software Defined Networking), NFV (Network Function Virtualization), and 5G-MEC (Mobile Edge Computing), is to centralize and virtualize networking into data centers. It enables operators to offer NaaS (Networking as a Service) with much lower CAPEX and OPEX with larger flexibility because devices become simpler, the number of administrators is less, and service orchestration is easier. It turns parts of communications currently done in hardware into computing done in software. However, the host of these data centers would not be Google-like super data centers as they are too far away from subscribers. The latency requirement of 10ms and 1ms decentralizes cloud computing down to edge and fog computing with CORD (central offices re-architected as data centers) and cellular base stations for SDN-NFV and 5G-MEC, respectively. In this talk, we first argue why, where and when SDN, NFV, 5G-MEC would prevail, and then illustrate how to make it happen with OpenFlow, SC (Service Chaining), NSH (Network Service header), etc. Then we examine how latency requirement dominates this virtualization game by listing key questions to answer in resource allocation in the architectures of SDN, NFV, and 5G-MEC. Their answers are mostly unknown now but would benefit the architects and developers of OpenFlow switches, SDN controllers, SDN-NFV apps, NFV data centers, MEC-enabled base stations, and operator's infrastructure in general.",https://ieeexplore.ieee.org/document/8215347/,2017 27th International Telecommunication Networks and Applications Conference (ITNAC),22-24 Nov. 2017,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/VTC2021-Fall52928.2021.9625307,Machine Learning Based mmWave Orchestration for Edge Gaming QoE Enhancement,IEEE,Conferences,"Millimeter wave (mmWave) is a crucial component in 5G and beyond 5G communications. However, the dense deployment of mmWave transceivers imposes a heavy burden on the management of radio access network (RAN). This challenge increases the need for autonomous network management methods leveraging machine learning (ML) techniques. In particular, mmWave beam selection is a critical issue for the management of RAN due to the large training overhead on mmWave transceivers. To this end, a new beam tracking method based on sequence-to-sequence (Seq2Seq) learning is proposed. Besides, thanks to edge computing technologies, network management algorithms and delay-sensitive user applications can be hosted on edge servers in close proximity. Due to limited resources on the edge server, the resource allocation problem for beam tracking and edge gaming is investigated with the aim of maximizing game quality of experience (QoE). Simulation results verify the effectiveness of the proposed orchestration scheme.",https://ieeexplore.ieee.org/document/9625307/,2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall),27-30 Sept. 2021,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
10.1109/TVT.2021.3126803,Mobility-Aware Controller Orchestration in Multi-Tier Service-Oriented Architecture for IoT,IEEE,Journals,"This work addresses the problem of controller orchestration in Internet of Things (IoT)-based Service-Oriented Architecture. It focuses on the fundamental issues of heterogeneity and dynamism of hybrid edge-cloud networks involving both static and mobile IoT devices for provisioning IoT-based services. Due to the limited capacity of IoT devices, IoT-cloud services require the support of edge networks, termed as ‘Service Edge,’ for meeting their ultra-low latency requirements. In such complex and dynamic networks, software-defined networking (SDN) paradigm is utilized for efficient resource utilization and service-oriented network management. A significant problem in SDN is the controller placement problem. Although researchers proposed several controller placement schemes for SDN, the problem of multi-tier controller placement in hybrid cloud-edge networks has not yet been addressed. In this work, this problem is formulated mathematically and shown to be a variant of the well-known two-level capacitated facility location problem, which is NP-hard. Thereafter, COMET, a scheme based on coalitional game and social choice theory, is proposed to solve the problem in polynomial time. COMET is designed while considering varying loads on the switches due to the presence of mobile IoT devices. Simulations depict that COMET reduces network delay by 49.02% with a significant increase in resiliency compared to the state-of-the-art.",https://ieeexplore.ieee.org/document/9610993/,IEEE Transactions on Vehicular Technology,Feb. 2022,ieeexplore,augmented reality,'augmented reality' AND 'edge' AND 'orchestration' AND 'placement'
