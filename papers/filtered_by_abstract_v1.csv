id,doi,publisher,database,url,domain,algorithm_type,training_schema,algorithm_goal,architecture,title,abstract
1,10.1016/J.ROBOT.2020.103472,North-Holland,project-academic,project-academic,robotics,supervised,batch,classification,not defined,deploying mavs for autonomous navigation in dark underground mine environments," Abstract None None Operating Micro Aerial Vehicles (MAVs) in subterranean environments is becoming more and more relevant in the field of aerial robotics. Despite the large spectrum of technological advances in the field, flying in such challenging environments is still an ongoing quest that requires the combination of multiple sensor modalities like visual/thermal cameras as well as 3D and 2D lidars. Nevertheless, there exist cases in subterranean environments where the aim is to deploy fast and lightweight aerial robots for area reckoning purposes after an event (e.g. blasting in production areas). This work proposes a novel baseline approach for the navigation of resource constrained robots, introducing the aerial underground scout, with the main goal to rapidly explore unknown areas and provide a feedback to the operator. The main proposed framework focuses on the navigation, control and vision capabilities of the aerial platforms with low-cost sensor suites, contributing significantly towards real-life applications. The merit of the proposed control architecture is that it considers the flying platform as a floating object, composing a velocity controller on the None None None x None None , None None None y None None None axes and altitude control to navigate along the tunnel. Two novel approaches make up the cornerstone of the proposed contributions for the task of navigation: (1) a vector geometry method based on 2D lidar, and (2) a Deep Learning (DL) method through a classification process based on an on-board image stream, where both methods correct the heading towards the center of the mine tunnel. Finally, the framework has been evaluated in multiple field trials in an underground mine in Sweden."
2,10.1109/PerCom.2014.6813937,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/6813937/,multimedia,supervised,batch,classification,centralised,"kintense: a robust, accurate, real-time and evolving system for detecting aggressive actions from streaming 3d skeleton data","Kintense is a robust, accurate, real-time, and evolving system for detecting aggressive actions such as hitting, kicking, pushing, and throwing from streaming 3D skeleton joint coordinates obtained from Kinect sensors. Kintense uses a combination of: (1) an array of supervised learners to recognize a predefined set of aggressive actions, (2) an unsupervised learner to discover new aggressive actions or refine existing actions, and (3) human feedback to reduce false alarms and to label potential aggressive actions. This paper describes the design and implementation of Kintense and provides empirical evidence that the system is 11% - 16% more accurate and 10% - 54% more robust to changes in distance, body orientation, speed, and person when compared to standard techniques such as dynamic time warping (DTW) and posture based gesture recognizers. We deploy Kintense in two multi-person households and demonstrate how it evolves to discover and learn unseen actions, achieves up to 90% accuracy, runs in real-time, and reduces false alarms with up to 13 times fewer user interactions than a typical system."
3,10.1109/FUZZ48607.2020.9177654,IEEE,project-academic,project-academic,robotics,not defined,not defined,not defined,not defined,ai fml agent for robotic game of go and aiot real world co learning applications," In this paper, we propose an AI-FML agent for robotic game of Go and AIoT real-world co-learning applications. The fuzzy machine learning mechanisms are adopted in the proposed model, including fuzzy markup language (FML)-based genetic learning (GFML), eXtreme Gradient Boost (XGBoost), and a seven-layered deep fuzzy neural network (DFNN) with backpropagation learning, to predict the win rate of the game of Go as Black or White. This paper uses Google AlphaGo Master sixty games as the dataset to evaluate the performance of the fuzzy machine learning, and the desired output dataset were predicted by Facebook AI Research (FAIR) ELF Open Go AI bot. In addition, we use IEEE 1855 standard for FML to describe the knowledge base and rule base of the Open Go Darkforest (OGD) prediction platform in order to infer the win rate of the game. Next, the proposed AI-FML agent publishes the inferred result to communicate with the robot Kebbi Air based on MQTT protocol to achieve the goal of human and smart machine co-learning. From Sept. 2019 to Jan. 2020, we introduced the AI-FML agent into the teaching and learning fields in Taiwan. The experimental results show the robots and students can co-learn AI tools and FML applications effectively. In addition, XGBoost outperforms the other machine learning methods but DFNN has the most obvious progress after learning. In the future, we hope to deploy the AI-FML agent to more available robot and human co-learning platforms through the established AI-FML International Academy in the world."
4,10.1109/SACI.2007.375494,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/4262496/,robotics,not defined,not defined,not defined,not defined,fpga parallel implementation of cmac type neural network with on chip learning,"The hardware implementation of neural networks is a new step in the evolution and use of neural networks in practical applications. The CMAC cerebellar model articulation controller is intended especially for hardware implementation, and this type of network is used successfully in the areas of robotics and control, where the real time capabilities of the network are of particular importance. The implementation of neural networks on FPGA's has several benefits, with emphasis on parallelism and the real time capabilities. This paper discusses the hardware implementation of the CMAC type neural network, the architecture and parameters and the functional modules of the hardware implemented neuro-processor."
5,10.1109/TRO.2021.3084374,'Institute of Electrical and Electronics Engineers (IEEE)',core,http://arxiv.org/abs/2106.09357,robotics,supervised,batch,classification,not defined,"cat-like jumping and landing of legged robots in low-gravity using deep
  reinforcement learning","In this article, we show that learned policies can be applied to solve legged
locomotion control tasks with extensive flight phases, such as those
encountered in space exploration. Using an off-the-shelf deep reinforcement
learning algorithm, we trained a neural network to control a jumping quadruped
robot while solely using its limbs for attitude control. We present tasks of
increasing complexity leading to a combination of three-dimensional
(re-)orientation and landing locomotion behaviors of a quadruped robot
traversing simulated low-gravity celestial bodies. We show that our approach
easily generalizes across these tasks and successfully trains policies for each
case. Using sim-to-real transfer, we deploy trained policies in the real world
on the SpaceBok robot placed on an experimental testbed designed for
two-dimensional micro-gravity experiments. The experimental results demonstrate
that repetitive, controlled jumping and landing with natural agility is
possible.Comment: Published in IEEE Transactions on Robotics:
  https://ieeexplore.ieee.org/document/9453856 Video:
  https://youtu.be/KQhlZa42fe"
6,10.1109/JBHI.2020.3035776,,project-academic,project-academic,health,supervised,batch,classification,centralised,wearable respiration monitoring interpretable inference with context and sensor biomarkers," Breathing rate (BR), minute ventilation (VE), and other respiratory parameters are essential for real-time patient monitoring in many acute health conditions, such as asthma. The clinical standard for measuring respiration, namely Spirometry, is hardly suitable for continuous use. Wearables can track many physiological signals, like ECG and motion, yet not respiration. Deriving respiration from other modalities has become an area of active research. In this work, we infer respiratory parameters from wearable ECG and wrist motion signals. We propose a modular and generalizable classification-regression pipeline to utilize available context information, such as physical activity, in learning context-conditioned inference models. Morphological and power domain novel features from the wearable ECG are extracted to use with these models. Exploratory feature selection methods are incorporated in this pipeline to discover application-specific interpretable biomarkers. Using data from 15 subjects, we evaluate two implementations of the proposed pipeline: for inferring BR and VE. Each implementation compares generalized linear model, random forest, support vector machine, Gaussian process regression, and neighborhood component analysis as contextual regression models. Permutation, regularization, and relevance determination methods are used to rank the ECG features to identify robust ECG biomarkers across models and activities. This work demonstrates the potential of wearable sensors not only in continuous monitoring, but also in designing biomarker-driven preventive measures."
7,10.1109/MOCAST49295.2020.9200283,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9200283/,smart cities,supervised,batch,classification,centralised,a cloud based smart recycling bin for waste classification,"Due to the Earth's population rapid growth along with the modern lifestyle the urban waste constantly increases. People consume more and the products are designed to have shorter lifespans. Recycling is the only way to make a sustainable environment. The process of recycling requires the separation of waste materials, which is a time consuming procedure. However, most of the proposed research works found in literature are neither budget-friendly nor effective to be practical in real world applications. In this paper, we propose a solution: a low-cost and effective Smart Recycling Bin that utilizes the power of cloud to assist with waste classification. A centralized Information System (IS) collects measurements from smart bins that are deployed all around the city and classifies the waste of each bin using Artificial Intelligence and neural networks. Our implementation is capable of classifying different types of waste with an accuracy of 93.4% while keeping deployment cost and power consumption very low."
8,10.1109/ICRIS52159.2020.00072,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9523937/,health,supervised,batch,classification,centralised,design and implementation of sitting posture monitoring system,"In order to remind the sedentary workers to count the health data, a sitting posture monitoring system is designed. The single chip microcomputer collects the sensor array data, uploads the data to the server through Wi Fi, carries on the sensor array data fusion in the server, and the software displays the sitting posture information and the statistical results. The feedforward neural network is used as classifier to recognize nine kinds of sitting posture. The recognition rate is 90.643%. It can prompt the user's sitting posture in real time and count the sitting posture data."
9,10.1016/j.compbiomed.2020.104004,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85091921119,health,supervised,batch,classification,not defined,scalable and energy efficient seizure detection based on direct use of compressively-sensed eeg data on an ultra low power multi-core architecture,"Extracting information from dense multi-channel neural sensors for accurate diagnosis of brain disorders necessitates computationally expensive and advanced signal processing approaches to analyze the massive volume of recorded data. Compressive Sensing (CS) is an efficient method for reducing the computational complexity and power consumption in the resource-constrained multi-site neural systems. However, reconstructing the signal from compressed measurements is computationally intensive, making it unsuitable for real-time applications such as seizure detection. In this paper, a seizure detection algorithm is proposed to overcome these limitations by circumventing the reconstruction phase and directly processing the compressively sampled EEG signals. The Lomb-Scargle Periodogram (LSP) is used to extract the spectral energy features of the compressed data. Performance of the seizure detector using non-linear support vector machine (SVM) classifier, tested on 24 patients of the CHB-MIT data-set for compression ratios (CR) of 1–64x, is 96–93%, 92-87%, 0.95–0.91, and <1 s for sensitivity, accuracy, the area under the curve, and latency, respectively. A power-efficient classification method based on the utilization of dual linear SVM classifiers is proposed. The proposed classification method based on the dual linear SVM classification achieved better classification performance compared to commonly used classifiers, such as K-nearest neighbor, random forest, artificial neural network, and linear SVM, while consuming low power in comparison to non-linear SVM kernels. The hardware-optimized implementation of this algorithm is proposed on a low-power multi-core SoC for near-sensor data analytics: Mr. Wolf. Optimized implementation of this algorithm on Mr. Wolf platform leads to detecting a seizure with an energy budget of 18.4 μJ and 3.9 μJ for a compression ratio of 24x using non-linear SVM classifier and the dual linear SVM based classification method, respectively."
10,10.1109/DASIP.2016.7853831,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/7853831/,multimedia,supervised,batch,classification,centralised,demo: helicoid tool demonstrator for real-time brain cancer detection,"In this paper, a demonstrator of three different elements of the EU FET HELICoiD project is introduced. The goal of this demonstration is to show how the combination of hyperspectral imaging and machine learning can be a potential solution to precise real-time detection of tumor tissues during surgical operations. The HELICoiD setup consists of two hyperspectral cameras, a scanning unit, an illumination system, a data processing system and an EMB01 accelerator platform, which hosts an MPPA-256 manycore chip. All the components are mounted fulfilling restrictions from surgical environments, as shown in the accompanying video recorded at the operating room. An in-vivo human brain hyperspectral image data base, obtained at the University Hospital Doctor Negrin in Las Palmas de Gran Canaria, has been employed as input to different supervised classification algorithms (SVM, RF, NN) and to a spatial-spectral filtering stage (SVM-KNN). The resulting classification maps are shown in this demo. In addition, the implementation of the SVM-KNN classification algorithm on the MPPA EMB01 platform is demonstrated in the live demo."
11,10.1109/RTSS.2018.00029,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/8603205/,industry,not defined,not defined,not defined,hybrid,work-in-progress: making machine learning real-time predictable,"Machine learning (ML) on edge computing devices is becoming popular in the industry as a means to make control systems more intelligent and autonomous. The new trend is to utilize embedded edge devices, as they boast higher computational power and larger memories than before, to perform ML tasks that had previously been limited to cloud-hosted deployments. In this work, we assess the real-time predictability and consider data privacy concerns by comparing traditional cloud services with edge-based ones for certain data analytics tasks. We identify the subset of ML problems appropriate for edge devices by investigating if they result in real-time predictable services for a set of widely used ML libraries. We specifically enhance the Caffe library to make it more suitable for real-time predictability. We then deploy ML models with high accuracy scores on an embedded system, exposing it to industry sensor data from the field, to demonstrates its efficacy and suitability for real-time processing."
12,10.1016/j.apenergy.2021.117853,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85114985028,smart cities,supervised,batch,regression,not defined,transferable representation modelling for real-time energy management of the plug-in hybrid vehicle based on k-fold fuzzy learning and gaussian process regression,"Electric vehicles, including plug-in hybrids, are important for achieving net-zero emission and will dominate road transportation in the future. Energy management, which optimizes the onboard energy usage, is a critical functionality of electric vehicles. It is usually developed following the model-based routine, which is conventionally costly and time-consuming and is hard to meet the increasing market competition in the digital era. To reduce the development workload for the energy management controller, this paper studies an innovative transfer learning routine. A new transferable representation control model is proposed by incorporating two promising artificial intelligence technologies, adaptive neural fuzzy inference system and Gaussian process regression, where the former applies k-fold cross valudation to build a neural fuzzy system for real-time implementation of offline optimization result, and the later connects the neural fuzzy system with a ‘deeper’ architecture to transfer the offline optimization knowledge learnt at source domain to new target domains. By introducing a concept of control utility that evaluates vehicle energy efficiency with a penalty on usage of battery energy, experimental evaluations based on the hardware-in-the-loop testing platform are conducted. Competitive real-time control ultility values (as much as 90% of offline benchmarking results) can be achieved by the proposed control method. They are over 27% higher than that achieved by the neural-network-based model."
13,10.1109/ACCESS.2020.2970178,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/8974224/,health,not defined,not defined,not defined,not defined,a novel software engineering approach toward using machine learning for improving the efficiency of health systems,"Recently, machine learning has become a hot research topic. Therefore, this study investigates the interaction between software engineering and machine learning within the context of health systems. We proposed a novel framework for health informatics: the framework and methodology of software engineering for machine learning in health informatics (SEMLHI). The SEMLHI framework includes four modules (software, machine learning, machine learning algorithms, and health informatics data) that organize the tasks in the framework using a SEMLHI methodology, thereby enabling researchers and developers to analyze health informatics software from an engineering perspective and providing developers with a new road map for designing health applications with system functions and software implementations. Our novel approach sheds light on its features and allows users to study and analyze the user requirements and determine both the function of objects related to the system and the machine learning algorithms that must be applied to the dataset. Our dataset used in this research consists of real data and was originally collected from a hospital run by the Palestine government covering the last three years. The SEMLHI methodology includes seven phases: designing, implementing, maintaining and defining workflows; structuring information; ensuring security and privacy; performance testing and evaluation; and releasing the software applications."
14,10.1016/j.matpr.2020.03.363,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85085555603,industry,supervised,batch,regression,not defined,real-time thermal error compensation strategy for precision machine tools,"Present manufacturing trend is towards producing precision components with better accuracy. Machine errors like geometrical, thermal and process errors affect the component accuracy. Among these errors, thermal error contributes more than 50-60% of the total machining error. This paper mainly focuses on the development of a real-time thermal error compensation module for precision machine tools and talks about effective modeling of thermal errors, development of thermal error compensation model using feed-forward backpropagation neural network and also simplified model using regression analysis technique, algorithm development for real-time compensation and implementation of module onto the open architecture CNC controller. The developed module has been successfully tested on a Diamond Turning Machine (DTM) by machining the precision component and also verified the effectiveness of the module"
15,10.3390/jpm11040244,,core,,health,supervised,batch,classification,centralised,'mdpi ag',"Clinical trials in cancer treatment are imperative in enhancing patients\u2019 survival and quality of life outcomes. The lack of communication among professionals may produce a non-optimization of patients\u2019 accrual in clinical trials. We developed a specific platform, called \u201cDigital Research Assistant\u201d (DRA), to report real-time every available clinical trial and support clinician. Healthcare professionals involved in breast cancer working group agreed nine minimal fields of interest to preliminarily classify the characteristics of patients\u2019 records (including omic data, such as genomic mutations). A progressive web app (PWA) was developed to implement a cross-platform software that was scalable on several electronic devices to share the patients\u2019 records and clinical trials. A specialist is able to use and populate the platform. An AI algorithm helps in the matchmaking between patient\u2019s data and clinical trial\u2019s inclusion criteria to personalize patient enrollment. At the same time, an easy configuration allows the application of the DRA in different oncology working groups (from breast cancer to lung cancer). The DRA might represent a valid research tool supporting clinicians and scientists, in order to optimize the enrollment of patients in clinical trials. User Experience and Technology The acceptance of participants using the DRA is topic of a future analysis"
16,10.1109/DTPI52967.2021.9540195,IEEE,project-academic,project-academic,autonomous vehicle,not defined,not defined,not defined,not defined,parallel mining operating systems from digital twins to mining intelligence," With the rapid development and modernization requirement of global coal industry, there is an emerging need for intelligent and unmanned mining systems. In this paper, the Intelligent Mining Operating System (IMOS) is proposed and developed, based on the parallel management and control of mining operating infrastructure that integrates the intelligent mining theory, the ACP-based (Artificial societies, Computational experiments, Parallel execution) parallel intelligence approaches, and the new generation of artificial intelligence (AI) technologies. To satisfy the intelligent and unmanned demand of open-pit mines, the IMOS architecture is developed by integrating the theory of digital quadruplets. The main subsystems and functions of IMOS are elaborated in detail, including a single-vehicle operating subsystem, multi-vehicle collaboration subsystem, vehicle-road collaboration subsystem, unmanned intelligent subsystem, dispatch management subsystem, parallel management and control subsystem, supervisory subsystem, remote takeover subsystem, and communication subsystem. The IMOS presented in this paper is the first integrated solution for intelligent and unmanned mines in China, and has been implemented over ten main open pits in the past few years. Its deployment and utilization will effectively improve the production efficiency and safety level of open-pit mines, promote the construction of ecological mines, and bring great significance to the realization of sustainable mining development."
17,10.1109/ICRA48506.2021.9561722,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/9561722/,robotics,rl,not defined,decision making,not defined,a scavenger hunt for service robots,"Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts."
18,10.1109/ICRA.2016.7487351,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/7487351/,robotics,supervised,not defined,decision making,not defined,object discovery and grasp detection with a shared convolutional neural network,"Grasp an object from a stack of objects in real-time is still a challenge in robotics. This requires the robot to have the ability of both fast object discovery and grasp detection: a target object should be picked out from the stack first and then a proper grasp configuration is applied to grasp the object. In this paper, we propose a shared convolutional neural network (CNN) which can simultaneously implement these two tasks in real-time. The processing speed of the model is about 100 frames per second on a GPU which largely satisfies the requirement. Meanwhile, we also establish a labeled RGBD dataset which contains scenes of stacked objects for robotic grasping. At last, we demonstrate the implementation of our shared CNN model on a real robotic platform and show that the robot can accurately discover a target object from the stack and successfully grasp it."
19,10.1007/978-3-030-28925-6_1,Springer,springer,http://link.springer.com/openurl/fulltext?id=doi:10.1007/978-3-030-28925-6_1,smart cities,not defined,not defined,not defined,not defined,cityflow: supporting spatial-temporal edge computing for urban machine learning applications,"A growing trend in smart cities is the use of machine learning techniques to gather city data, formulate learning tasks and models, and use these to develop solutions to city problems. However, although these processes are sufficient for theoretical experiments, they often fail when they meet the reality of city data and processes, which by their very nature are highly distributed, heterogeneous, and exhibit high degrees of spatial and temporal variance. In order to address those problems, we have designed and implemented an integrated development environment called CityFlow that supports developing machine learning applications. With CityFlow, we can develop, deploy, and maintain machine learning applications easily by using an intuitive data flow model. To verify our approach, we conducted two case studies: deploying a road damage detection application to help monitor transport infrastructure and an automatic labeling application in support of a participatory sensing application. These applications show both the generic applicability of our approach, and its ease of use; both critical if we wish to deploy sophisticated ML based applications to smart cities."
20,10.1109/JIOT.2019.2917066,,project-academic,project-academic,robotics,supervised,batch,classification,centralised,a 64mw dnn based visual navigation engine for autonomous nano drones," Fully-autonomous miniaturized robots (e.g., drones), with artificial intelligence (AI) based visual navigation capabilities are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nanodrones with size of a few cm${}^\mathrm{2}$. In this work, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on-bard of resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultra-low-power computing platform, and a 27 g commercial, open-source CrazyFlie 2.0 nano-quadrotor. As part of our general methodology we discuss the software mapping techniques that enable the state-of-the-art deep convolutional neural network presented in [1] to be fully executed on-board within a strict 6 fps real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner it achieves 18 fps while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft."
21,http://arxiv.org/abs/2001.09938v1,arxiv,arxiv,http://arxiv.org/abs/2001.09938v1,science,supervised,batch,classification,centralised,"autonomous discovery of battery electrolytes with robotic
  experimentation and machine-learning","Innovations in batteries take years to formulate and commercialize, requiring
extensive experimentation during the design and optimization phases. We
approached the design and selection of a battery electrolyte through a
black-box optimization algorithm directly integrated into a robotic test-stand.
We report here the discovery of a novel battery electrolyte by this experiment
completely guided by the machine-learning software without human intervention.
Motivated by the recent trend toward super-concentrated aqueous electrolytes
for high-performance batteries, we utilize Dragonfly - a Bayesian
machine-learning software package - to search mixtures of commonly used lithium
and sodium salts for super-concentrated aqueous electrolytes with wide
electrochemical stability windows. Dragonfly autonomously managed the robotic
test-stand, recommending electrolyte designs to test and receiving experimental
feedback in real time. In 40 hours of continuous experimentation over a
four-dimensional design space with millions of potential candidates, Dragonfly
discovered a novel, mixed-anion aqueous sodium electrolyte with a wider
electrochemical stability window than state-of-the-art sodium electrolyte. A
human-guided design process may have missed this optimal electrolyte. This
result demonstrates the possibility of integrating robotics with
machine-learning to rapidly and autonomously discover novel battery materials."
22,10.1016/j.microc.2020.105038,scopus,sciencedirect,https://api.elsevier.com/content/abstract/scopus_id/85085341749,health,supervised,batch,classification,not defined,a smartphone-based rapid quantitative detection platform for lateral flow strip of human chorionic gonadotropin with optimized image algorithm,"Colloidal gold immunochromatographic test strip has been widely used as a rapid, simple and low-cost correct detection technology. However, its detection is often qualitative or semi-quantitative, which limits its clinical application to some extent. Herein, a portable test strip quantitative detection device based on smartphone to detect human chorionic gonadotropin (HCG) is developed. In experiment, a colloidal gold HCG detection strip based on antigen antibody immune response is constructed, and the quantitative results of three different image processing methods on the same strip detection are compared, including the threshold processing algorithm based on location information, the RGB color component extraction algorithm and the grayscale projection value processing algorithm, the results show that the last algorithm can realize the best recognition of the region of interest of strip. The mobile phone application software (App) based on this design shows that the detection limit of constructed colloidal gold HCG strip is 3 ng/mL with a linear range of 6–300 ng/mL. The detection result of real urine sample is consistent with the spiked concentration (R2 = 0.988), indicating that the concentration of HCG can be accurately measured in urine with this method, presenting the potential for instant diagnosis."
23,10.1109/TSMC.2020.2967936,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/8989970/,robotics,unsupervised,not defined,decision making,not defined,deep q-learning with q-matrix transfer learning for novel fire evacuation environment,"Deep reinforcement learning (RL) is achieving significant success in various applications like control, robotics, games, resource management, and scheduling. However, the important problem of emergency evacuation, which clearly could benefit from RL, has been largely unaddressed. Indeed, emergency evacuation is a complex task that is difficult to solve with RL. An emergency situation is highly dynamic, with a lot of changing variables and complex constraints that make it challenging to solve. Also, there is no standard benchmark environment available that can be used to train RL agents for evacuation. A realistic environment can be complex to design. In this article, we propose the first fire evacuation environment to train RL agents for evacuation planning. The environment is modeled as a graph capturing the building structure. It consists of realistic features like fire spread, uncertainty, and bottlenecks. The implementation of our environment is in the OpenAI gym format, to facilitate future research. We also propose a new RL approach that entails pretraining the network weights of a DQN-based agent [DQN/Double-DQN (DDQN)/Dueling-DQN] to incorporate information on the shortest path to the exit. We achieved this by using tabular <inline-formula> <tex-math notation=""LaTeX"">$Q$ </tex-math></inline-formula>-learning to learn the shortest path on the building model’s graph. This information is transferred to the network by deliberately overfitting it on the <inline-formula> <tex-math notation=""LaTeX"">$Q$ </tex-math></inline-formula>-matrix. Then, the pretrained DQN model is trained on the fire evacuation environment to generate the optimal evacuation path under time varying conditions due to fire spread, bottlenecks, and uncertainty. We perform comparisons of the proposed approach with state-of-the-art RL algorithms like DQN, DDQN, Dueling-DQN, PPO, VPG, state-action-reward-state-action (SARSA), actor–critic method, and ACKTR. The results show that our method is able to outperform state-of-the-art models by a huge margin including the original DQN-based models. Finally, our model is tested on a large and complex real building consisting of 91 rooms, with the possibility to move to any other room, hence giving 8281 actions. In order to reduce the action space, we propose a strategy that involves one step simulation. That is, an action importance vector is added to the final output of the pretrained DQN and acts like an attention mechanism. Using this strategy, the action space is reduced by 90.1%. In this manner, the model is able to deal with large action spaces. Hence, our model achieves near optimal performance on the real world emergency environment."
24,http://arxiv.org/abs/1411.6326v1,arxiv,arxiv,http://arxiv.org/abs/1411.6326v1,autonomous vehicle,not defined,not defined,not defined,not defined,vision and learning for deliberative monocular cluttered flight,"Cameras provide a rich source of information while being passive, cheap and
lightweight for small and medium Unmanned Aerial Vehicles (UAVs). In this work
we present the first implementation of receding horizon control, which is
widely used in ground vehicles, with monocular vision as the only sensing mode
for autonomous UAV flight in dense clutter. We make it feasible on UAVs via a
number of contributions: novel coupling of perception and control via relevant
and diverse, multiple interpretations of the scene around the robot, leveraging
recent advances in machine learning to showcase anytime budgeted cost-sensitive
feature selection, and fast non-linear regression for monocular depth
prediction. We empirically demonstrate the efficacy of our novel pipeline via
real world experiments of more than 2 kms through dense trees with a quadrotor
built from off-the-shelf parts. Moreover our pipeline is designed to combine
information from other modalities like stereo and lidar as well if available."
25,10.1109/BigData.2017.8258195,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/8258195/,multimedia,not defined,not defined,not defined,not defined,a study of a video analysis framework using kafka and spark streaming,"As the use of various sensors and cloud computing technologies has spread, many life-log analysis applications for safety services for the elderly and children have been developed. However, it is difficult to perform real-time large data processing in clouds due to the computational complexity of the analysis because efficient deployment schemes of streaming computing components over cloud resources have not been well-investigated. In this study, we propose a video analysis framework that collects videos from multiple cameras and analyzes them using Apache Kafka and Apache Spark Streaming. We first investigate the data transfer performance of Apache Kafka and examine efficient cluster configuration and parameter settings. We then apply this configuration to the proposed framework and measure the data analysis throughput. The experimental results show that the overall throughput varies depending on the number of broker nodes that store data, the number of topic partitions of data, and the number of nodes that conduct analysis processing. In addition, it is confirmed that the number of cores is needed to consider for the efficient cluster configuration, and that the network bandwidth between the nodes becomes a bottleneck as the amount of data and the number of components increase."
26,'Frontiers Media SA',,core,10.3389/frobt.2018.00067,smart cities,not defined,not defined,not defined,not defined,oncilla robot: a versatile open-source quadruped research robot with compliant pantograph legs,"Sprowitz AT, Tuleu A, Ajallooeian M, et al. Oncilla Robot: A Versatile Open-Source Quadruped Research Robot With Compliant Pantograph Legs. FRONTIERS IN ROBOTICS AND AI. 2018;5: 18.We present Oncilla robot, a novel mobile, quadruped legged locomotion machine. This large-cat sized, 5.1 kg robot is one of a kind of a recent, bioinspired legged robot class designed with the capability of model-free locomotion control. Animal legged locomotion in rough terrain is clearly shaped by sensor feedback systems. Results with Oncilla robot show that agile and versatile locomotion is possible without sensory signals to some extend, and tracking becomes robust when feedback control is added (Ajallooeian, 2015). By incorporating mechanical and control blueprints inspired from animals, and by observing the resulting robot locomotion characteristics, we aim to understand the contribution of individual components. Legged robots have a wide mechanical and control design parameter space, and a unique potential as research tools to investigate principles of biomechanics and legged locomotion control. But the hardware and controller design can be a steep initial hurdle for academic research. To facilitate the easy start and development of legged robots, Oncilla-robot's blueprints are available through open-source. The robot's locomotion capabilities are shown in several scenarios. Specifically, its spring-loaded pantographic leg design compensates for overdetermined body and leg postures, i.e., during turning maneuvers, locomotion outdoors, or while going up and down slopes. The robot's active degree of freedom allow tight and swift direction changes, and turns on the spot. Presented hardware experiments are conducted in an open-loop manner, with little control and computational effort. For more versatile locomotion control, Oncilla-robot can sense leg joint rotations, and leg-trunk forces. Additional sensors can be included for feedback control with an open communication protocol interface. The robot's customized actuators are designed for robust actuation, and efficient locomotion. It trots with a cost of transport of 3.2 J/(Nm),at a speed of 0.63 m s(-1) (Froude number 0.25). The robot trots inclined slopes up to 10 degrees, at 0.25 m s(-1). The multi-body Webots model of Oncilla robot, and Oncilla robot's extensive software architecture enables users to design and test scenarios in simulation. Controllers can directly be transferred to the real robot. Oncilla robot's blueprints are open-source published (hardware GLP v3, software LGPL v3)"
22,10.1109/access.2018.2868268,IEEE,project-academic,project-academic,multimedia,supervised,batch,classification,not defined,micro hand gesture recognition system using ultrasonic active sensing," In this paper, we propose a micro hand gesture recognition system and methods using ultrasonic active sensing. This system uses micro dynamic hand gestures for recognition to achieve human–computer interaction (HCI). The implemented system, called hand-ultrasonic gesture (HUG), consists of ultrasonic active sensing, pulsed radar signal processing, and time-sequence pattern recognition by machine learning. We adopt lower frequency (300 kHz) ultrasonic active sensing to obtain high resolution range-Doppler image features. Using high quality sequential range-Doppler features, we propose a state-transition-based hidden Markov model for gesture classification. This method achieves a recognition accuracy of nearly 90% by using symbolized range-Doppler features and significantly reduces the computational complexity and power consumption. Furthermore, to achieve higher classification accuracy, we utilize an end-to-end neural network model and obtain a recognition accuracy of 96.32%. In addition to offline analysis, a real-time prototype is released to verify our method’s potential for application in the real world."
23,http://arxiv.org/abs/2007.11404v1,arxiv,arxiv,http://arxiv.org/abs/2007.11404v1,smart cities,supervised,batch,classification,not defined,"a hybrid neuromorphic object tracking and classification framework for
  real-time systems","Deep learning inference that needs to largely take place on the 'edge' is a
highly computational and memory intensive workload, making it intractable for
low-power, embedded platforms such as mobile nodes and remote security
applications. To address this challenge, this paper proposes a real-time,
hybrid neuromorphic framework for object tracking and classification using
event-based cameras that possess properties such as low-power consumption (5-14
mW) and high dynamic range (120 dB). Nonetheless, unlike traditional approaches
of using event-by-event processing, this work uses a mixed frame and event
approach to get energy savings with high performance. Using a frame-based
region proposal method based on the density of foreground events, a
hardware-friendly object tracking scheme is implemented using the apparent
object velocity while tackling occlusion scenarios. The object track input is
converted back to spikes for TrueNorth classification via the energy-efficient
deep network (EEDN) pipeline. Using originally collected datasets, we train the
TrueNorth model on the hardware track outputs, instead of using ground truth
object locations as commonly done, and demonstrate the ability of our system to
handle practical surveillance scenarios. As an optional paradigm, to exploit
the low latency and asynchronous nature of neuromorphic vision sensors (NVS),
we also propose a continuous-time tracker with C++ implementation where each
event is processed individually. Thereby, we extensively compare the proposed
methodologies to state-of-the-art event-based and frame-based methods for
object tracking and classification, and demonstrate the use case of our
neuromorphic approach for real-time and embedded applications without
sacrificing performance. Finally, we also showcase the efficacy of the proposed
system to a standard RGB camera setup when evaluated over several hours of
traffic recordings."
24,10.1109/bigdata.2018.8622065,IEEE,ieeexplore,https://ieeexplore.ieee.org/document/8622065/,industry,supervised,batch,regression,not defined,parallel large-scale neural network training for online advertising,"Neural networks have shown great successes in many fields. Due to the complexity of the training pipeline, however, using them in an industrial setting is challenging. In online advertising, the complexity arises from the immense size of the training data, and the dimensionality of the sparse feature space (both can be hundreds of billions). To tackle these challenges, we built TrainSparse (TS), a system that parallelizes the training of neural networks with a focus on efficiently handling large-scale sparse features. In this paper, we present the design and implementation of TS, and show the effectiveness of the system by applying it to predict the ad conversion rate (pCVR), one of the key problems in online advertising. We also compare several methods for dimensionality reduction on sparse features in the pCVR task. Experiments on real-world industry data show that TS achieves outstanding performance and scalability."
24,10.1111/0885-9507.00150,Blackwell Publishers Inc.,project-academic,project-academic,smart cities,supervised,batch,classification,not defined,on line and off line routing and scheduling of dial a ride paratransit vehicles," This article presents the general concepts , mod- els, and computational techniques applied in a new dial-a- ride vehicle routing and scheduling system . The objective of this system is to improve the responsiveness , reliability, and productivity of dial-a-ride paratransit services . The de- veloped software integrates dial-a-ride routing and schedul- ing principles and practical experience and explicitly con- siders travel time variability in urban roadway networks . Such extensive and complex integration has been made pos- sible by improved data acquisition and processing capabil- ities of computer, telecommunications, and vehicle location technologies. Advanced computational methods applied in the system, such as the artificial neural network technique , which allows heuristic estimation of origin-destination travel times in a dynamic and stochastic fashion , contribute to the processing speed required to respond expeditiously and effi- ciently to paratransit user requests. A real scheduling prob- lem from the city of Edmonton , Alberta, where the system was tested, is used to illustrate the positive computational expe- rience and the capability of the developed software to handle both off-line and on-line operations ."
